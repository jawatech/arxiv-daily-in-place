
### LLM
|Publish Date|Title|Authors|PDF|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-04-29**|**Stylus: Automatic Adapter Selection for Diffusion Models**|Michael Luo et.al.|[2404.18928v1](http://arxiv.org/abs/2404.18928v1)|null|
|**2024-04-29**|**Holmes: Benchmark the Linguistic Competence of Language Models**|Andreas Waldis et.al.|[2404.18923v1](http://arxiv.org/abs/2404.18923v1)|null|
|**2024-04-29**|**DPO Meets PPO: Reinforced Token Optimization for RLHF**|Han Zhong et.al.|[2404.18922v1](http://arxiv.org/abs/2404.18922v1)|null|
|**2024-04-29**|**Kangaroo: Lossless Self-Speculative Decoding via Double Early Exiting**|Fangcheng Liu et.al.|[2404.18911v1](http://arxiv.org/abs/2404.18911v1)|null|
|**2024-04-29**|**IPixMatch: Boost Semi-supervised Semantic Segmentation with Inter-Pixel Relation**|Kebin Wu et.al.|[2404.18891v1](http://arxiv.org/abs/2404.18891v1)|null|
|**2024-04-29**|**A Survey on Diffusion Models for Time Series and Spatio-Temporal Data**|Yiyuan Yang et.al.|[2404.18886v1](http://arxiv.org/abs/2404.18886v1)|null|
|**2024-04-29**|**Spivavtor: An Instruction Tuned Ukrainian Text Editing Model**|Aman Saini et.al.|[2404.18880v1](http://arxiv.org/abs/2404.18880v1)|null|
|**2024-04-29**|**OpenStreetView-5M: The Many Roads to Global Visual Geolocation**|Guillaume Astruc et.al.|[2404.18873v1](http://arxiv.org/abs/2404.18873v1)|null|
|**2024-04-29**|**More RLHF, More Trust? On The Impact of Human Preference Alignment On Language Model Trustworthiness**|Aaron J. Li et.al.|[2404.18870v1](http://arxiv.org/abs/2404.18870v1)|null|
|**2024-04-29**|**Truth-value judgment in language models: belief directions are context sensitive**|Stefan F. Schouten et.al.|[2404.18865v1](http://arxiv.org/abs/2404.18865v1)|null|
|**2024-04-29**|**Performance-Aligned LLMs for Generating Fast Code**|Daniel Nichols et.al.|[2404.18864v1](http://arxiv.org/abs/2404.18864v1)|null|
|**2024-04-29**|**A Comprehensive Rubric for Annotating Pathological Speech**|Mario Corrales-Astorgano et.al.|[2404.18851v1](http://arxiv.org/abs/2404.18851v1)|null|
|**2024-04-29**|**FeDeRA:Efficient Fine-tuning of Language Models in Federated Learning Leveraging Weight Decomposition**|Yuxuan Yan et.al.|[2404.18848v1](http://arxiv.org/abs/2404.18848v1)|null|
|**2024-04-29**|**It's Difficult to be Neutral -- Human and LLM-based Sentiment Annotation of Patient Comments**|Petter Mæhlum et.al.|[2404.18832v1](http://arxiv.org/abs/2404.18832v1)|null|
|**2024-04-29**|**Harmonic Machine Learning Models are Robust**|Nicholas S. Kersting et.al.|[2404.18825v1](http://arxiv.org/abs/2404.18825v1)|null|
|**2024-04-29**|**Benchmarking Benchmark Leakage in Large Language Models**|Ruijie Xu et.al.|[2404.18824v1](http://arxiv.org/abs/2404.18824v1)|null|
|**2024-04-29**|**Control Policy Correction Framework for Reinforcement Learning-based Energy Arbitrage Strategies**|Seyed Soroush Karimi Madahi et.al.|[2404.18821v1](http://arxiv.org/abs/2404.18821v1)|null|
|**2024-04-29**|**Unknown Script: Impact of Script on Cross-Lingual Transfer**|Wondimagegnhue Tsegaye Tufa et.al.|[2404.18810v1](http://arxiv.org/abs/2404.18810v1)|null|
|**2024-04-29**|**Replacing Judges with Juries: Evaluating LLM Generations with a Panel of Diverse Models**|Pat Verga et.al.|[2404.18796v1](http://arxiv.org/abs/2404.18796v1)|null|
|**2024-04-29**|**Certification of Speaker Recognition Models to Additive Perturbations**|Dmitrii Korzh et.al.|[2404.18791v1](http://arxiv.org/abs/2404.18791v1)|null|
|**2024-04-29**|**Where on Earth Do Users Say They Are?: Geo-Entity Linking for Noisy Multilingual User Input**|Tessa Masis et.al.|[2404.18784v1](http://arxiv.org/abs/2404.18784v1)|null|
|**2024-04-29**|**Saliency Suppressed, Semantics Surfaced: Visual Transformations in Neural Networks and the Brain**|Gustaw Opiełka et.al.|[2404.18772v1](http://arxiv.org/abs/2404.18772v1)|null|
|**2024-04-29**|**PECC: Problem Extraction and Coding Challenges**|Patrick Haller et.al.|[2404.18766v1](http://arxiv.org/abs/2404.18766v1)|null|
|**2024-04-29**|**Towards A Structured Overview of Use Cases for Natural Language Processing in the Legal Domain: A German Perspective**|Juraj Vladika et.al.|[2404.18759v1](http://arxiv.org/abs/2404.18759v1)|null|
|**2024-04-29**|**Evaluating the Effectiveness of Video Anomaly Detection in the Wild: Online Learning and Inference for Real-world Deployment**|Shanle Yao et.al.|[2404.18747v1](http://arxiv.org/abs/2404.18747v1)|null|
|**2024-04-29**|**Towards Dog Bark Decoding: Leveraging Human Speech Processing for Automated Bark Classification**|Artem Abzaliev et.al.|[2404.18739v1](http://arxiv.org/abs/2404.18739v1)|null|
|**2024-04-29**|**The Constant in HATE: Analyzing Toxicity in Reddit across Topics and Languages**|Wondimagegnhue Tsegaye Tufa et.al.|[2404.18726v1](http://arxiv.org/abs/2404.18726v1)|null|
|**2024-04-29**|**Improving Automatic Text Recognition with Language Models in the PyLaia Open-Source Library**|Solène Tarride et.al.|[2404.18722v1](http://arxiv.org/abs/2404.18722v1)|null|
|**2024-04-29**|**Iconic Gesture Semantics**|Andy Lücking et.al.|[2404.18708v1](http://arxiv.org/abs/2404.18708v1)|null|
|**2024-04-29**|**Work Smarter...Not Harder: Efficient Minimization of Dependency Length in SOV Languages**|Sidharth Ranjan et.al.|[2404.18684v1](http://arxiv.org/abs/2404.18684v1)|null|
|**2024-04-29**|**Graph Convolutional Networks and Graph Attention Networks for Approximating Arguments Acceptability -- Technical Report**|Paul Cibier et.al.|[2404.18672v1](http://arxiv.org/abs/2404.18672v1)|null|
|**2024-04-29**|**Bootstrap 3D Reconstructed Scenes from 3D Gaussian Splatting**|Yifei Gao et.al.|[2404.18669v1](http://arxiv.org/abs/2404.18669v1)|null|
|**2024-04-29**|**Revealing the Parametric Knowledge of Language Models: A Unified Framework for Attribution Methods**|Haeun Yu et.al.|[2404.18655v1](http://arxiv.org/abs/2404.18655v1)|null|
|**2024-04-29**|**Towards Quantitative Evaluation of Explainable AI Methods for Deepfake Detection**|Konstantinos Tsigos et.al.|[2404.18649v1](http://arxiv.org/abs/2404.18649v1)|null|
|**2024-04-29**|**Reinforcement Learning Problem Solving with Large Language Models**|Sina Gholamian et.al.|[2404.18638v1](http://arxiv.org/abs/2404.18638v1)|null|
|**2024-04-29**|**Do Vision & Language Decoders use Images and Text equally? How Self-consistent are their Explanations?**|Letitia Parcalabescu et.al.|[2404.18624v1](http://arxiv.org/abs/2404.18624v1)|null|
|**2024-04-29**|**The SAMER Arabic Text Simplification Corpus**|Bashar Alhafni et.al.|[2404.18615v1](http://arxiv.org/abs/2404.18615v1)|null|
|**2024-04-29**|**CSTalk: Correlation Supervised Speech-driven 3D Emotional Facial Animation Generation**|Xiangyu Liang et.al.|[2404.18604v1](http://arxiv.org/abs/2404.18604v1)|null|
|**2024-04-29**|**FREB-TQA: A Fine-Grained Robustness Evaluation Benchmark for Table Question Answering**|Wei Zhou et.al.|[2404.18585v1](http://arxiv.org/abs/2404.18585v1)|null|
|**2024-04-29**|**Analyzing Semantic Change through Lexical Replacements**|Francesco Periti et.al.|[2404.18570v1](http://arxiv.org/abs/2404.18570v1)|null|
|**2024-04-29**|**Injecting Salesperson's Dialogue Strategies in Large Language Models with Chain-of-Thought Reasoning**|Wen-Yu Chang et.al.|[2404.18564v1](http://arxiv.org/abs/2404.18564v1)|null|
|**2024-04-29**|**LangBiTe: A Platform for Testing Bias in Large Language Models**|Sergio Morales et.al.|[2404.18558v1](http://arxiv.org/abs/2404.18558v1)|null|
|**2024-04-29**|**Can GPT-4 do L2 analytic assessment?**|Stefano Bannò et.al.|[2404.18557v1](http://arxiv.org/abs/2404.18557v1)|null|
|**2024-04-29**|**Evaluating the effectiveness of predicting covariates in LSTM Networks for Time Series Forecasting**|Gareth Davies et.al.|[2404.18553v1](http://arxiv.org/abs/2404.18553v1)|null|
|**2024-04-29**|**SIDBench: A Python Framework for Reliably Assessing Synthetic Image Detection Methods**|Manos Schinas et.al.|[2404.18552v1](http://arxiv.org/abs/2404.18552v1)|null|
|**2024-04-29**|**Time Machine GPT**|Felix Drinkall et.al.|[2404.18543v1](http://arxiv.org/abs/2404.18543v1)|null|
|**2024-04-29**|**Enhancing Boundary Segmentation for Topological Accuracy with Skeleton-based Methods**|Chuni Liu et.al.|[2404.18539v1](http://arxiv.org/abs/2404.18539v1)|null|
|**2024-04-29**|**Evaluating and Mitigating Linguistic Discrimination in Large Language Models**|Guoliang Dong et.al.|[2404.18534v1](http://arxiv.org/abs/2404.18534v1)|null|
|**2024-04-29**|**Evaluating Readability and Faithfulness of Concept-based Explanations**|Meng Li et.al.|[2404.18533v1](http://arxiv.org/abs/2404.18533v1)|null|
|**2024-04-29**|**MileBench: Benchmarking MLLMs in Long Context**|Dingjie Song et.al.|[2404.18532v1](http://arxiv.org/abs/2404.18532v1)|null|
|**2024-04-29**|**A Framework to Model ML Engineering Processes**|Sergio Morales et.al.|[2404.18531v1](http://arxiv.org/abs/2404.18531v1)|null|
|**2024-04-29**|**Bridging Data Barriers among Participants: Assessing the Potential of Geoenergy through Federated Learning**|Weike Peng et.al.|[2404.18527v1](http://arxiv.org/abs/2404.18527v1)|null|
|**2024-04-29**|**On the Impact of Data Heterogeneity in Federated Learning Environments with Application to Healthcare Networks**|Usevalad Milasheuski. Luca Barbieri et.al.|[2404.18519v1](http://arxiv.org/abs/2404.18519v1)|null|
|**2024-04-29**|**From ChatGPT, DALL-E 3 to Sora: How has Generative AI Changed Digital Humanities Research and Services?**|Jiangfeng Liu et.al.|[2404.18518v1](http://arxiv.org/abs/2404.18518v1)|null|
|**2024-04-29**|**Explainability of Machine Learning Approaches in Forensic Linguistics: A Case Study in Geolinguistic Authorship Profiling**|Dana Roemling et.al.|[2404.18510v1](http://arxiv.org/abs/2404.18510v1)|null|
|**2024-04-29**|**Scalable Event-by-event Processing of Neuromorphic Sensory Signals With Deep State-Space Models**|Mark Schöne et.al.|[2404.18508v1](http://arxiv.org/abs/2404.18508v1)|null|
|**2024-04-29**|**ECC Analyzer: Extract Trading Signal from Earnings Conference Calls using Large Language Model for Stock Performance Prediction**|Yupeng Cao et.al.|[2404.18470v1](http://arxiv.org/abs/2404.18470v1)|null|
|**2024-04-29**|**HFT: Half Fine-Tuning for Large Language Models**|Tingfeng Hui et.al.|[2404.18466v1](http://arxiv.org/abs/2404.18466v1)|null|
|**2024-04-29**|**M3oE: Multi-Domain Multi-Task Mixture-of Experts Recommendation Framework**|Zijian Zhang et.al.|[2404.18465v1](http://arxiv.org/abs/2404.18465v1)|null|
|**2024-04-29**|**Ethical Reasoning and Moral Value Alignment of LLMs Depend on the Language we Prompt them in**|Utkarsh Agarwal et.al.|[2404.18460v1](http://arxiv.org/abs/2404.18460v1)|null|
|**2024-04-29**|**U-Nets as Belief Propagation: Efficient Classification, Denoising, and Diffusion in Generative Hierarchical Models**|Song Mei et.al.|[2404.18444v1](http://arxiv.org/abs/2404.18444v1)|null|
|**2024-04-29**|**BMRetriever: Tuning Large Language Models as Better Biomedical Text Retrievers**|Ran Xu et.al.|[2404.18443v1](http://arxiv.org/abs/2404.18443v1)|null|
|**2024-04-29**|**Unsupervised Dynamics Prediction with Object-Centric Kinematics**|Yeon-Ji Song et.al.|[2404.18423v1](http://arxiv.org/abs/2404.18423v1)|null|
|**2024-04-29**|**Capabilities of Gemini Models in Medicine**|Khaled Saab et.al.|[2404.18416v1](http://arxiv.org/abs/2404.18416v1)|null|
|**2024-04-29**|**3AM: An Ambiguity-Aware Multi-Modal Machine Translation Dataset**|Xinyu Ma et.al.|[2404.18413v1](http://arxiv.org/abs/2404.18413v1)|null|
|**2024-04-29**|**Mixture-of-Instructions: Comprehensive Alignment of a Large Language Model through the Mixture of Diverse System Prompting Instructions**|Bowen Xu et.al.|[2404.18410v1](http://arxiv.org/abs/2404.18410v1)|null|
|**2024-04-29**|**LLM-SR: Scientific Equation Discovery via Programming with Large Language Models**|Parshin Shojaee et.al.|[2404.18400v1](http://arxiv.org/abs/2404.18400v1)|null|
|**2024-04-29**|**MM-TTS: A Unified Framework for Multimodal, Prompt-Induced Emotional Text-to-Speech Synthesis**|Xiang Li et.al.|[2404.18398v1](http://arxiv.org/abs/2404.18398v1)|null|
|**2024-04-29**|**Equivalence: An analysis of artists' roles with Image Generative AI from Conceptual Art perspective through an interactive installation design practice**|Yixuan Li et.al.|[2404.18385v1](http://arxiv.org/abs/2404.18385v1)|null|
|**2024-04-29**|**Exploring the Limits of Fine-grained LLM-based Physics Inference via Premise Removal Interventions**|Jordan Meadows et.al.|[2404.18384v1](http://arxiv.org/abs/2404.18384v1)|null|
|**2024-04-29**|**QANA: LLM-based Question Generation and Network Analysis for Zero-shot Key Point Analysis and Beyond**|Tomoki Fukuma et.al.|[2404.18371v1](http://arxiv.org/abs/2404.18371v1)|null|
|**2024-04-29**|**FoundaBench: Evaluating Chinese Fundamental Knowledge Capabilities of Large Language Models**|Wei Li et.al.|[2404.18359v1](http://arxiv.org/abs/2404.18359v1)|null|
|**2024-04-29**|**Do Neutral Prompts Produce Insecure Code? FormAI-v2 Dataset: Labelling Vulnerabilities in Code Generated by Large Language Models**|Norbert Tihanyi et.al.|[2404.18353v1](http://arxiv.org/abs/2404.18353v1)|null|
|**2024-04-29**|**Post-hoc and manifold explanations analysis of facial expression data based on deep learning**|Yang Xiao et.al.|[2404.18352v1](http://arxiv.org/abs/2404.18352v1)|null|
|**2024-04-28**|**Multi-stage Attack Detection and Prediction Using Graph Neural Networks: An IoT Feasibility Study**|Hamdi Friji et.al.|[2404.18328v1](http://arxiv.org/abs/2404.18328v1)|null|
|**2024-04-28**|**SAFE-RL: Saliency-Aware Counterfactual Explainer for Deep Reinforcement Learning Policies**|Amir Samadi et.al.|[2404.18326v1](http://arxiv.org/abs/2404.18326v1)|null|
|**2024-04-28**|**Trends and Challenges of Real-time Learning in Large Language Models: A Critical Review**|Mladjan Jovanovic et.al.|[2404.18311v1](http://arxiv.org/abs/2404.18311v1)|null|
|**2024-04-28**|**Retrieval-Oriented Knowledge for Click-Through Rate Prediction**|Huanshuo Liu et.al.|[2404.18304v1](http://arxiv.org/abs/2404.18304v1)|null|
|**2024-04-28**|**Using Deep Q-Learning to Dynamically Toggle between Push/Pull Actions in Computational Trust Mechanisms**|Zoi Lygizou et.al.|[2404.18296v1](http://arxiv.org/abs/2404.18296v1)|null|
|**2024-04-28**|**Comparing LLM prompting with Cross-lingual transfer performance on Indigenous and Low-resource Brazilian Languages**|David Ifeoluwa Adelani et.al.|[2404.18286v1](http://arxiv.org/abs/2404.18286v1)|null|
|**2024-04-28**|**Bias Neutralization Framework: Measuring Fairness in Large Language Models with Bias Intelligence Quotient (BiQ)**|Malur Narayan et.al.|[2404.18276v1](http://arxiv.org/abs/2404.18276v1)|null|
|**2024-04-28**|**Parameter-Efficient Tuning Large Language Models for Graph Representation Learning**|Qi Zhu et.al.|[2404.18271v1](http://arxiv.org/abs/2404.18271v1)|null|
|**2024-04-28**|**Pragmatic Formal Verification of Sequential Error Detection and Correction Codes (ECCs) used in Safety-Critical Design**|Aman Kumar et.al.|[2404.18270v1](http://arxiv.org/abs/2404.18270v1)|null|
|**2024-04-28**|**Modeling Orthographic Variation Improves NLP Performance for Nigerian Pidgin**|Pin-Jie Lin et.al.|[2404.18264v1](http://arxiv.org/abs/2404.18264v1)|null|
|**2024-04-28**|**Generating Situated Reflection Triggers about Alternative Solution Paths: A Case Study of Generative AI for Computer-Supported Collaborative Learning**|Atharva Naik et.al.|[2404.18262v1](http://arxiv.org/abs/2404.18262v1)|null|
|**2024-04-28**|**Mapping 'when'-clauses in Latin American and Caribbean languages: an experiment in subtoken-based typology**|Nilo Pedrazzini et.al.|[2404.18257v1](http://arxiv.org/abs/2404.18257v1)|null|
|**2024-04-28**|**PatentGPT: A Large Language Model for Intellectual Property**|Zilong Bai et.al.|[2404.18255v1](http://arxiv.org/abs/2404.18255v1)|null|
|**2024-04-28**|**LEGENT: Open Platform for Embodied Agents**|Zhili Cheng et.al.|[2404.18243v1](http://arxiv.org/abs/2404.18243v1)|null|
|**2024-04-28**|**SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning**|Jinghan Jia et.al.|[2404.18239v1](http://arxiv.org/abs/2404.18239v1)|[link](https://github.com/optml-group/soul)|
|**2024-04-28**|**From Persona to Personalization: A Survey on Role-Playing Language Agents**|Jiangjie Chen et.al.|[2404.18231v1](http://arxiv.org/abs/2404.18231v1)|null|
|**2024-04-28**|**TextGram: Towards a better domain-adaptive pretraining**|Sharayu Hiwarkhedkar et.al.|[2404.18228v1](http://arxiv.org/abs/2404.18228v1)|null|
|**2024-04-28**|**L3Cube-MahaNews: News-based Short Text and Long Document Classification Datasets in Marathi**|Saloni Mittal et.al.|[2404.18216v1](http://arxiv.org/abs/2404.18216v1)|[link](https://github.com/l3cube-pune/MarathiNLP)|
|**2024-04-28**|**Contrastive Learning Method for Sequential Recommendation based on Multi-Intention Disentanglement**|Zeyu Hu et.al.|[2404.18214v1](http://arxiv.org/abs/2404.18214v1)|null|
|**2024-04-28**|**S$^2$Mamba: A Spatial-spectral State Space Model for Hyperspectral Image Classification**|Guanchun Wang et.al.|[2404.18213v1](http://arxiv.org/abs/2404.18213v1)|null|
|**2024-04-28**|**Paint by Inpaint: Learning to Add Image Objects by Removing Them First**|Navve Wasserman et.al.|[2404.18212v1](http://arxiv.org/abs/2404.18212v1)|null|
|**2024-04-28**|**LMM-PCQA: Assisting Point Cloud Quality Assessment with LMM**|Zicheng Zhang et.al.|[2404.18203v1](http://arxiv.org/abs/2404.18203v1)|null|
|**2024-04-28**|**WorldGPT: Empowering LLM as Multimodal World Model**|Zhiqi Ge et.al.|[2404.18202v1](http://arxiv.org/abs/2404.18202v1)|[link](https://github.com/dcdmllm/worldgpt)|
|**2024-04-28**|**Exploring the Robustness of In-Context Learning with Noisy Labels**|Chen Cheng et.al.|[2404.18191v1](http://arxiv.org/abs/2404.18191v1)|[link](https://github.com/inezyu0928/in-context-learning)|
|**2024-04-28**|**Ranked List Truncation for Large Language Model-based Re-Ranking**|Chuan Meng et.al.|[2404.18185v1](http://arxiv.org/abs/2404.18185v1)|[link](https://github.com/chuanmeng/rlt4reranking)|
|**2024-04-28**|**EkoHate: Abusive Language and Hate Speech Detection for Code-switched Political Discussions on Nigerian Twitter**|Comfort Eseohen Ilevbare et.al.|[2404.18180v1](http://arxiv.org/abs/2404.18180v1)|null|

#### Abstracts
##### **Stylus: Automatic Adapter Selection for Diffusion Models**
2404.18928v1 by Michael Luo,Justin Wong,Brandon Trabucco,Yanping Huang,Joseph E. Gonzalez,Zhifeng Chen,Ruslan Salakhutdinov,Ion Stoica

Beyond scaling base models with more data or parameters, fine-tuned adapters
provide an alternative way to generate high fidelity, custom images at reduced
costs. As such, adapters have been widely adopted by open-source communities,
accumulating a database of over 100K adapters-most of which are highly
customized with insufficient descriptions. This paper explores the problem of
matching the prompt to a set of relevant adapters, built on recent work that
highlight the performance gains of composing adapters. We introduce Stylus,
which efficiently selects and automatically composes task-specific adapters
based on a prompt's keywords. Stylus outlines a three-stage approach that first
summarizes adapters with improved descriptions and embeddings, retrieves
relevant adapters, and then further assembles adapters based on prompts'
keywords by checking how well they fit the prompt. To evaluate Stylus, we
developed StylusDocs, a curated dataset featuring 75K adapters with
pre-computed adapter embeddings. In our evaluation on popular Stable Diffusion
checkpoints, Stylus achieves greater CLIP-FID Pareto efficiency and is twice as
preferred, with humans and multimodal models as evaluators, over the base
model. See stylus-diffusion.github.io for more.

摘要：除了使用更多資料或參數調整基本模型外，微調的適配器提供了一種替代方法，可以降低成本產生高保真度、自訂影像。因此，適配器已被開源社群廣泛採用，累積了一個超過 10 萬個適配器的資料庫，其中大部分都經過高度自訂，但說明不足。本文探討了將提示與一組相關適配器配對的問題，建立在最近工作的基礎上，這些工作強調了組合適配器的效能提升。我們引入了 Stylus，它根據提示的關鍵字，有效地選擇並自動組合特定於任務的適配器。Stylus 概述了一個三階段方法，首先使用改進的說明和嵌入來總結適配器，擷取相關適配器，然後根據提示的關鍵字進一步組裝適配器，方法是檢查它們與提示的契合程度。為了評估 Stylus，我們開發了 StylusDocs，這是一個精選的資料集，包含 75K 個適配器和預先計算的適配器嵌入。在我們對流行的 Stable Diffusion 檢查點的評估中，Stylus 達到了更高的 CLIP-FID Pareto 效率，並且在人類和多模態模型作為評估者時，它的偏好度是基本模型的兩倍。請參閱 stylus-diffusion.github.io 以了解更多資訊。

##### **Holmes: Benchmark the Linguistic Competence of Language Models**
2404.18923v1 by Andreas Waldis,Yotam Perlitz,Leshem Choshen,Yufang Hou,Iryna Gurevych

We introduce Holmes, a benchmark to assess the linguistic competence of
language models (LMs) - their ability to grasp linguistic phenomena. Unlike
prior prompting-based evaluations, Holmes assesses the linguistic competence of
LMs via their internal representations using classifier-based probing. In doing
so, we disentangle specific phenomena (e.g., part-of-speech of words) from
other cognitive abilities, like following textual instructions, and meet recent
calls to assess LMs' linguistic competence in isolation. Composing Holmes, we
review over 250 probing studies and feature more than 200 datasets to assess
syntax, morphology, semantics, reasoning, and discourse phenomena. Analyzing
over 50 LMs reveals that, aligned with known trends, their linguistic
competence correlates with model size. However, surprisingly, model
architecture and instruction tuning also significantly influence performance,
particularly in morphology and syntax. Finally, we propose FlashHolmes, a
streamlined version of Holmes designed to lower the high computation load while
maintaining high-ranking precision.

摘要：我們介紹 Holmes，一個基準來評估語言模型 (LM) 的語言能力，也就是它們掌握語言現象的能力。與先前的提示式評估不同，Holmes 使用基於分類器的探測，透過其內部表示來評估 LM 的語言能力。在這樣做的過程中，我們將特定現象（例如字詞的詞性）從其他認知能力（例如遵循文字說明）中區分出來，並回應近期呼籲，要獨立評估 LM 的語言能力。在編制 Holmes 時，我們檢視了超過 250 項探測研究，並採用超過 200 個資料集來評估句法、形態、語意、推理和話語現象。分析超過 50 個 LM 後發現，與已知趨勢一致，它們的語言能力與模型大小相關。然而，令人驚訝的是，模型架構和說明調整也會顯著影響效能，特別是在形態和句法方面。最後，我們提出 FlashHolmes，一個簡化的 Holmes 版本，旨在降低高運算負載，同時維持高排名精準度。

##### **DPO Meets PPO: Reinforced Token Optimization for RLHF**
2404.18922v1 by Han Zhong,Guhao Feng,Wei Xiong,Li Zhao,Di He,Jiang Bian,Liwei Wang

In the classical Reinforcement Learning from Human Feedback (RLHF) framework,
Proximal Policy Optimization (PPO) is employed to learn from sparse,
sentence-level rewards -- a challenging scenario in traditional deep
reinforcement learning. Despite the great successes of PPO in the alignment of
state-of-the-art closed-source large language models (LLMs), its open-source
implementation is still largely sub-optimal, as widely reported by numerous
research studies. To address these issues, we introduce a framework that models
RLHF problems as a Markov decision process (MDP), enabling the capture of
fine-grained token-wise information. Furthermore, we provide theoretical
insights that demonstrate the superiority of our MDP framework over the
previous sentence-level bandit formulation. Under this framework, we introduce
an algorithm, dubbed as Reinforced Token Optimization (\texttt{RTO}), which
learns the token-wise reward function from preference data and performs policy
optimization based on this learned token-wise reward signal. Theoretically,
\texttt{RTO} is proven to have the capability of finding the near-optimal
policy sample-efficiently. For its practical implementation, \texttt{RTO}
innovatively integrates Direct Preference Optimization (DPO) and PPO. DPO,
originally derived from sparse sentence rewards, surprisingly provides us with
a token-wise characterization of response quality, which is seamlessly
incorporated into our subsequent PPO training stage. Extensive real-world
alignment experiments verify the effectiveness of the proposed approach.

摘要：在經典的人類回饋強化學習 (RLHF) 架構中，
採用近端策略最佳化 (PPO) 來從稀疏的句子層級獎勵中學習，這在傳統的深度強化學習中是一個具有挑戰性的場景。儘管 PPO 在對齊最先進的閉源大型語言模型 (LLM) 方面取得了巨大的成功，但眾多研究報告廣泛指出，其開源實作在很大程度上仍未達到最佳狀態。為了解決這些問題，我們引入了一個框架，將 RLHF 問題建模為馬可夫決策過程 (MDP)，從而能夠擷取細粒度的標記資訊。此外，我們提供了理論見解，證明了我們的 MDP 框架優於先前的句子層級多臂老虎機公式。在此框架下，我們引入了一個演算法，稱為強化標記最佳化 (\texttt{RTO})，它從偏好資料中學習標記層級的獎勵函數，並根據這個學習到的標記層級獎勵訊號執行策略最佳化。理論上，\texttt{RTO} 被證明有能力以近乎最佳的策略樣本有效率地進行尋找。對於其實際實作，\texttt{RTO} 創新地整合了直接偏好最佳化 (DPO) 和 PPO。DPO 最初來自稀疏的句子獎勵，令人驚訝地為我們提供了回應品質的標記層級表徵，它無縫地整合到我們後續的 PPO 訓練階段。廣泛的真實世界對齊實驗驗證了所提出的方法的有效性。

##### **Kangaroo: Lossless Self-Speculative Decoding via Double Early Exiting**
2404.18911v1 by Fangcheng Liu,Yehui Tang,Zhenhua Liu,Yunsheng Ni,Kai Han,Yunhe Wang

Speculative decoding has demonstrated its effectiveness in accelerating the
inference of large language models while maintaining a consistent sampling
distribution. However, the conventional approach of training a separate draft
model to achieve a satisfactory token acceptance rate can be costly. Drawing
inspiration from early exiting, we propose a novel self-speculative decoding
framework \emph{Kangaroo}, which uses a fixed shallow sub-network as a
self-draft model, with the remaining layers serving as the larger target model.
We train a lightweight and efficient adapter module on top of the sub-network
to bridge the gap between the sub-network and the full model's representation
ability. It is noteworthy that the inference latency of the self-draft model
may no longer be negligible compared to the large model, necessitating
strategies to increase the token acceptance rate while minimizing the drafting
steps of the small model. To address this challenge, we introduce an additional
early exiting mechanism for generating draft tokens. Specifically, we halt the
small model's subsequent prediction during the drafting phase once the
confidence level for the current token falls below a certain threshold.
Extensive experiments on the Spec-Bench demonstrate the effectiveness of
Kangaroo. Under single-sequence verification, Kangaroo achieves speedups up to
$1.68\times$ on Spec-Bench, outperforming Medusa-1 with 88.7\% fewer additional
parameters (67M compared to 591M). The code for Kangaroo is available at
https://github.com/Equationliu/Kangaroo.

摘要：<paragraph>推論式解碼已證明其在加速大型語言模型推論的同時，還能維持一致的取樣分佈。然而，訓練一個獨立的草稿模型以達到滿意的 token 接受率的傳統方法可能會很昂貴。從早期退出中汲取靈感，我們提出了一個新穎的自推論式解碼框架「袋鼠」，它使用一個固定的淺層子網路作為自草稿模型，其餘層則作為較大的目標模型。我們在子網路的頂部訓練了一個輕量級且高效的適配器模組，以彌補子網路和完整模型的表示能力之間的差距。值得注意的是，與大型模型相比，自草稿模型的推論延遲可能不再可以忽略不計，因此需要策略來提高 token 接受率，同時將小型模型的起草步驟減至最低。為了應對這一挑戰，我們引入了一種額外的早期退出機制來產生草稿 token。具體來說，一旦當前 token 的信心水準低於某個閾值，我們就會在起草階段暫停小型模型的後續預測。Spec-Bench 上的廣泛實驗證明了袋鼠的有效性。在單序列驗證下，袋鼠在 Spec-Bench 上實現了高達 $1.68\times$ 的加速，優於美杜莎 1，額外參數減少了 88.7%（與 591M 相比為 67M）。袋鼠的程式碼可在 https://github.com/Equationliu/Kangaroo 獲得。</paragraph>

##### **IPixMatch: Boost Semi-supervised Semantic Segmentation with Inter-Pixel Relation**
2404.18891v1 by Kebin Wu,Wenbin Li,Xiaofei Xiao

The scarcity of labeled data in real-world scenarios is a critical bottleneck
of deep learning's effectiveness. Semi-supervised semantic segmentation has
been a typical solution to achieve a desirable tradeoff between annotation cost
and segmentation performance. However, previous approaches, whether based on
consistency regularization or self-training, tend to neglect the contextual
knowledge embedded within inter-pixel relations. This negligence leads to
suboptimal performance and limited generalization. In this paper, we propose a
novel approach IPixMatch designed to mine the neglected but valuable
Inter-Pixel information for semi-supervised learning. Specifically, IPixMatch
is constructed as an extension of the standard teacher-student network,
incorporating additional loss terms to capture inter-pixel relations. It shines
in low-data regimes by efficiently leveraging the limited labeled data and
extracting maximum utility from the available unlabeled data. Furthermore,
IPixMatch can be integrated seamlessly into most teacher-student frameworks
without the need of model modification or adding additional components. Our
straightforward IPixMatch method demonstrates consistent performance
improvements across various benchmark datasets under different partitioning
protocols.

摘要：在真实世界场景中标记数据稀缺是深度学习效率的一个关键瓶颈。半监督语义分割一直是实现注释成本和分割性能之间理想权衡的典型解决方案。然而，先前的做法，无论是基于一致性正则化还是自训练，往往忽略了像素间关系中嵌入的上下文知识。这种疏忽导致次优性能和有限的泛化。在本文中，我们提出了一种新的方法 IPixMatch，旨在挖掘半监督学习中被忽视但有价值的像素间信息。具体来说，IPixMatch 被构建为标准师生网络的扩展，加入了额外的损失项来捕获像素间关系。它通过有效利用有限的标记数据和从可用的未标记数据中提取最大效用，在低数据模式中表现出色。此外，IPixMatch 可以无缝集成到大多数师生框架中，而无需模型修改或添加额外的组件。我们直接的 IPixMatch 方法在不同的分区协议下，在各种基准数据集上展示了一致的性能改进。

##### **A Survey on Diffusion Models for Time Series and Spatio-Temporal Data**
2404.18886v1 by Yiyuan Yang,Ming Jin,Haomin Wen,Chaoli Zhang,Yuxuan Liang,Lintao Ma,Yi Wang,Chenghao Liu,Bin Yang,Zenglin Xu,Jiang Bian,Shirui Pan,Qingsong Wen

The study of time series data is crucial for understanding trends and
anomalies over time, enabling predictive insights across various sectors.
Spatio-temporal data, on the other hand, is vital for analyzing phenomena in
both space and time, providing a dynamic perspective on complex system
interactions. Recently, diffusion models have seen widespread application in
time series and spatio-temporal data mining. Not only do they enhance the
generative and inferential capabilities for sequential and temporal data, but
they also extend to other downstream tasks. In this survey, we comprehensively
and thoroughly review the use of diffusion models in time series and
spatio-temporal data, categorizing them by model category, task type, data
modality, and practical application domain. In detail, we categorize diffusion
models into unconditioned and conditioned types and discuss time series data
and spatio-temporal data separately. Unconditioned models, which operate
unsupervised, are subdivided into probability-based and score-based models,
serving predictive and generative tasks such as forecasting, anomaly detection,
classification, and imputation. Conditioned models, on the other hand, utilize
extra information to enhance performance and are similarly divided for both
predictive and generative tasks. Our survey extensively covers their
application in various fields, including healthcare, recommendation, climate,
energy, audio, and transportation, providing a foundational understanding of
how these models analyze and generate data. Through this structured overview,
we aim to provide researchers and practitioners with a comprehensive
understanding of diffusion models for time series and spatio-temporal data
analysis, aiming to direct future innovations and applications by addressing
traditional challenges and exploring innovative solutions within the diffusion
model framework.

摘要：時間序列資料的研究對於理解趨勢和異常現象至關重要，並能針對各個產業提供預測性見解。另一方面，時空資料對於分析時空現象至關重要，能提供複雜系統互動的動態觀點。最近，擴散模型已被廣泛應用於時間序列和時空資料探勘。它們不僅能增強序列和時間資料的生成和推論能力，還能延伸至其他下游任務。在本次調查中，我們全面深入地探討了擴散模型在時間序列和時空資料中的應用，並根據模型類別、任務類型、資料模式和實際應用領域對其進行分類。詳細來說，我們將擴散模型分為無條件和條件類型，並分別討論時間序列資料和時空資料。無條件模型以非監督方式運作，細分為基於機率和基於評分的模型，用於預測和生成任務，例如預測、異常偵測、分類和插補。另一方面，條件模型利用額外資訊來增強效能，並針對預測和生成任務進行類似的區分。我們的調查廣泛涵蓋了它們在醫療保健、推薦、氣候、能源、音訊和運輸等領域的應用，提供了這些模型如何分析和生成資料的基本理解。透過這個結構化的概觀，我們旨在為研究人員和實務工作者提供對時間序列和時空資料分析的擴散模型的全面理解，並透過解決傳統挑戰和探索擴散模型架構內的創新解決方案，引領未來的創新和應用。

##### **Spivavtor: An Instruction Tuned Ukrainian Text Editing Model**
2404.18880v1 by Aman Saini,Artem Chernodub,Vipul Raheja,Vivek Kulkarni

We introduce Spivavtor, a dataset, and instruction-tuned models for text
editing focused on the Ukrainian language. Spivavtor is the Ukrainian-focused
adaptation of the English-only CoEdIT model. Similar to CoEdIT, Spivavtor
performs text editing tasks by following instructions in Ukrainian. This paper
describes the details of the Spivavtor-Instruct dataset and Spivavtor models.
We evaluate Spivavtor on a variety of text editing tasks in Ukrainian, such as
Grammatical Error Correction (GEC), Text Simplification, Coherence, and
Paraphrasing, and demonstrate its superior performance on all of them. We
publicly release our best-performing models and data as resources to the
community to advance further research in this space.

摘要：我們介紹 Spivavtor，一個專注於烏克蘭語的資料集和指令調整模型，用於文字編輯。Spivavtor 是僅限英文的 CoEdIT 模型的烏克蘭語版本。與 CoEdIT 類似，Spivavtor 透過遵循烏克蘭語的指令來執行文字編輯任務。本文說明了 Spivavtor-Instruct 資料集和 Spivavtor 模型的詳細資訊。我們在烏克蘭語的各種文字編輯任務中評估 Spivavtor，例如文法錯誤更正 (GEC)、文字簡化、連貫性和改寫，並展示其在所有任務中的卓越效能。我們公開發布我們效能最佳的模型和資料，作為資源提供給社群，以促進此領域的進一步研究。

##### **OpenStreetView-5M: The Many Roads to Global Visual Geolocation**
2404.18873v1 by Guillaume Astruc,Nicolas Dufour,Ioannis Siglidis,Constantin Aronssohn,Nacim Bouia,Stephanie Fu,Romain Loiseau,Van Nguyen Nguyen,Charles Raude,Elliot Vincent,Lintao XU,Hongyu Zhou,Loic Landrieu

Determining the location of an image anywhere on Earth is a complex visual
task, which makes it particularly relevant for evaluating computer vision
algorithms. Yet, the absence of standard, large-scale, open-access datasets
with reliably localizable images has limited its potential. To address this
issue, we introduce OpenStreetView-5M, a large-scale, open-access dataset
comprising over 5.1 million geo-referenced street view images, covering 225
countries and territories. In contrast to existing benchmarks, we enforce a
strict train/test separation, allowing us to evaluate the relevance of learned
geographical features beyond mere memorization. To demonstrate the utility of
our dataset, we conduct an extensive benchmark of various state-of-the-art
image encoders, spatial representations, and training strategies. All
associated codes and models can be found at https://github.com/gastruc/osv5m.

摘要：確定地球上任何地方的影像位置是一項複雜的視覺任務，這使得它特別適用於評估電腦視覺演算法。然而，缺乏標準、大規模、開放存取且具有可靠定位影像的資料集，限制了它的潛力。為了解決這個問題，我們引進 OpenStreetView-5M，一個大規模、開放存取的資料集，包含超過 510 萬個地理參考街景影像，涵蓋 225 個國家和地區。與現有的基準不同，我們強制執行嚴格的訓練/測試分離，讓我們能夠評估學習到的地理特徵與單純記憶的關聯性。為了證明我們資料集的效用，我們對各種最先進的影像編碼器、空間表示和訓練策略進行廣泛的基準測試。所有相關程式碼和模型都可以在 https://github.com/gastruc/osv5m 找到。

##### **More RLHF, More Trust? On The Impact of Human Preference Alignment On Language Model Trustworthiness**
2404.18870v1 by Aaron J. Li,Satyapriya Krishna,Himabindu Lakkaraju

The surge in Large Language Models (LLMs) development has led to improved
performance on cognitive tasks as well as an urgent need to align these models
with human values in order to safely exploit their power. Despite the
effectiveness of preference learning algorithms like Reinforcement Learning
From Human Feedback (RLHF) in aligning human preferences, their assumed
improvements on model trustworthiness haven't been thoroughly testified. Toward
this end, this study investigates how models that have been aligned with
general-purpose preference data on helpfulness and harmlessness perform across
five trustworthiness verticals: toxicity, stereotypical bias, machine ethics,
truthfulness, and privacy. For model alignment, we focus on three widely used
RLHF variants: Supervised Finetuning (SFT), Proximal Policy Optimization (PPO),
and Direct Preference Optimization (DPO). Through extensive empirical
investigations, we discover that the improvement in trustworthiness by RLHF is
far from guaranteed, and there exists a complex interplay between preference
data, alignment algorithms, and specific trustworthiness aspects. Together, our
results underscore the need for more nuanced approaches for model alignment. By
shedding light on the intricate dynamics of these components within model
alignment, we hope this research will guide the community towards developing
language models that are both capable and trustworthy.

摘要：大型語言模型 (LLM) 的開發激增，導致認知任務的效能提升，以及迫切需要將這些模型與人類價值觀相符，以安全地利用其力量。儘管像強化學習從人類回饋 (RLHF) 中的偏好學習演算法的有效性在調整人類偏好方面，其假設的模型可信度改進尚未得到徹底證實。為此，本研究探討了已與對有幫助性和無害性的通用偏好資料相符的模型，在五個可信度垂直領域：毒性、刻板印象偏差、機器倫理、真實性和隱私方面的表現。對於模型對齊，我們專注於三種廣泛使用的 RLHF 變體：監督微調 (SFT)、近端策略最佳化 (PPO) 和直接偏好最佳化 (DPO)。透過廣泛的實證調查，我們發現 RLHF 對可信度的改善遠非有保證的，而且偏好資料、對齊演算法和特定可信度方面之間存在複雜的交互作用。我們的結果共同強調了對模型對齊需要更細緻方法的必要性。透過闡明模型對齊中這些組成部分的複雜動態，我們希望這項研究將引導社群開發既有能力又可信賴的語言模型。

##### **Truth-value judgment in language models: belief directions are context sensitive**
2404.18865v1 by Stefan F. Schouten,Peter Bloem,Ilia Markov,Piek Vossen

Recent work has demonstrated that the latent spaces of large language models
(LLMs) contain directions predictive of the truth of sentences. Multiple
methods recover such directions and build probes that are described as getting
at a model's "knowledge" or "beliefs". We investigate this phenomenon, looking
closely at the impact of context on the probes. Our experiments establish where
in the LLM the probe's predictions can be described as being conditional on the
preceding (related) sentences. Specifically, we quantify the responsiveness of
the probes to the presence of (negated) supporting and contradicting sentences,
and score the probes on their consistency. We also perform a causal
intervention experiment, investigating whether moving the representation of a
premise along these belief directions influences the position of the hypothesis
along that same direction. We find that the probes we test are generally
context sensitive, but that contexts which should not affect the truth often
still impact the probe outputs. Our experiments show that the type of errors
depend on the layer, the (type of) model, and the kind of data. Finally, our
results suggest that belief directions are (one of the) causal mediators in the
inference process that incorporates in-context information.

摘要：最近的研究表明，大型语言模型（LLM）的潜在空间包含预测句子真实性的方向。多种方法恢复此类方向并构建探针，这些探针被描述为获取模型的“知识”或“信念”。我们调查了这种现象，仔细研究了上下文对探针的影响。我们的实验确定了 LLM 中探针的预测可以被描述为有条件地依赖于前面的（相关）句子。具体来说，我们量化了探针对（否定）支持和矛盾句子的存在做出响应的能力，并根据其一致性对探针进行评分。我们还执行了一项因果干预实验，调查了沿这些信念方向移动前提表示是否会影响沿同一方向的假设位置。我们发现我们测试的探针通常对上下文敏感，但那些不应该影响真实性的上下文通常仍然会影响探针输出。我们的实验表明，错误类型取决于层、模型（类型）和数据类型。最后，我们的结果表明，信念方向是推理过程中（之一）因果中介，该过程纳入了上下文信息。

##### **Performance-Aligned LLMs for Generating Fast Code**
2404.18864v1 by Daniel Nichols,Pranav Polasam,Harshitha Menon,Aniruddha Marathe,Todd Gamblin,Abhinav Bhatele

Optimizing scientific software is a difficult task because codebases are
often large and complex, and performance can depend upon several factors
including the algorithm, its implementation, and hardware among others. Causes
of poor performance can originate from disparate sources and be difficult to
diagnose. Recent years have seen a multitude of work that use large language
models (LLMs) to assist in software development tasks. However, these tools are
trained to model the distribution of code as text, and are not specifically
designed to understand performance aspects of code. In this work, we introduce
a reinforcement learning based methodology to align the outputs of code LLMs
with performance. This allows us to build upon the current code modeling
capabilities of LLMs and extend them to generate better performing code. We
demonstrate that our fine-tuned model improves the expected speedup of
generated code over base models for a set of benchmark tasks from 0.9 to 1.6
for serial code and 1.9 to 4.5 for OpenMP code.

摘要：優化科學軟體是一項艱難的任務，因為程式碼庫通常龐大且複雜，而效能可能取決於演算法、其實作以及硬體等多項因素。效能不佳的原因可能來自不同的來源，且難以診斷。近年來，有許多使用大型語言模型 (LLM) 來協助軟體開發任務的研究。然而，這些工具經過訓練，可以將程式碼的分布建模為文字，但並未特別設計用於了解程式碼的效能面向。在這項研究中，我們引入了一種基於強化學習的方法，以將程式碼 LLM 的輸出與效能結合。這讓我們得以建構在 LLM 目前程式碼建模能力的基礎上，並延伸它們以產生效能更好的程式碼。我們證明，我們微調過的模型改善了生成程式碼的預期加速，針對一組基準任務，序列程式碼從 0.9 到 1.6，OpenMP 程式碼從 1.9 到 4.5，都優於基本模型。

##### **A Comprehensive Rubric for Annotating Pathological Speech**
2404.18851v1 by Mario Corrales-Astorgano,David Escudero-Mancebo,Lourdes Aguilar,Valle Flores-Lucas,Valentín Cardeñoso-Payo,Carlos Vivaracho-Pascual,César González-Ferreras

Rubrics are a commonly used tool for labeling voice corpora in speech quality
assessment, although their application in the context of pathological speech
remains relatively limited. In this study, we introduce a comprehensive rubric
based on various dimensions of speech quality, including phonetics, fluency,
and prosody. The objective is to establish standardized criteria for
identifying errors within the speech of individuals with Down syndrome, thereby
enabling the development of automated assessment systems. To achieve this
objective, we utilized the Prautocal corpus. To assess the quality of
annotations using our rubric, two experiments were conducted, focusing on
phonetics and fluency. For phonetic evaluation, we employed the Goodness of
Pronunciation (GoP) metric, utilizing automatic segmentation systems and
correlating the results with evaluations conducted by a specialized speech
therapist. While the obtained correlation values were not notably high, a
positive trend was observed. In terms of fluency assessment, deep learning
models like wav2vec were used to extract audio features, and we employed an SVM
classifier trained on a corpus focused on identifying fluency issues to
categorize Prautocal corpus samples. The outcomes highlight the complexities of
evaluating such phenomena, with variability depending on the specific type of
disfluency detected.

摘要：評分法是標籤語音語料庫的常用工具，用於評估語音品質，儘管它們在病理性語音的應用中仍然相對有限。在本研究中，我們引入了一個基於語音品質的各種維度的綜合評分法，包括語音、流利度和韻律。目標是為識別唐氏症患者的語音中的錯誤建立標準化的標準，從而實現自動化評估系統的開發。為實現這一目標，我們利用了 Prautocal 語料庫。為了評估使用我們評分法的註釋的品質，進行了兩次實驗，重點關注語音和流利度。對於語音評估，我們採用了發音優良度 (GoP) 指標，利用自動分段系統，並將結果與專門的言語治療師進行的評估相關聯。雖然獲得的相關性值並不太高，但觀察到了積極的趨勢。在流利度評估方面，深度學習模型（如 wav2vec）被用於提取音訊特徵，我們採用了在專注於識別流利度問題的語料庫上訓練的 SVM 分類器對 Prautocal 語料庫樣本進行分類。結果突出了評估此類現象的複雜性，變異性取決於檢測到的特定類型的不流利度。

##### **FeDeRA:Efficient Fine-tuning of Language Models in Federated Learning Leveraging Weight Decomposition**
2404.18848v1 by Yuxuan Yan,Shunpu Tang,Zhiguo Shi,Qianqian Yang

Pre-trained Language Models (PLMs) have shown excellent performance on
various downstream tasks after fine-tuning. Nevertheless, the escalating
concerns surrounding user privacy have posed significant challenges to
centralized training reliant on extensive data collection. Federated
learning(FL), which only requires training on the clients and aggregates
weights on the server without sharing data, has emerged as a solution. However,
the substantial parameter size of PLMs places a significant burden on the
computational resources of client devices, while also leading to costly
communication expenses. Introducing Parameter-Efficient Fine-Tuning(PEFT) into
FL can effectively address this problem. However, we observe that the non-IID
data in federated learning leads to a gap in performance between the PEFT
method and full parameter fine-tuning(FT). To overcome this, we propose FeDeRA,
an improvement over the LoRA method in FL. FeDeRA uses the same adapter module
as LoRA. However, the difference lies in FeDeRA's initialization of the adapter
module by performing Singular Value Decomposition (SVD) on the pre-trained
matrix and selecting its principal components. We conducted extensive
experiments, using RoBERTa and DeBERTaV3, on three tasks and six datasets,
comparing the methods including FT and the other three different PEFT methods.
FeDeRA outperforms all other PEFT methods and is comparable to or even
surpasses the performance of FT methods. We also deployed federated learning on
Jetson AGX Orin and compared the time required by different methods to achieve
the target accuracy on specific tasks. Compared to FT, FeDeRA reduces the
training time by 95.9%, 97.9%, 96.9%, and 97.3%, 96.5%, and 96.5% respectively
on three tasks using RoBERTa and DeBERTaV3. The overall experiments indicate
that FeDeRA achieves good performance while also maintaining efficiency.

摘要：預先訓練好的語言模型 (PLM) 在經過微調後，在各種下游任務中表現優異。然而，圍繞使用者隱私的日益升高的擔憂對依賴於廣泛數據收集的集中式訓練構成了重大挑戰。聯合學習 (FL) 只需要在用戶端上進行訓練，並在伺服器上彙總權重而無需共享數據，已成為一種解決方案。然而，PLM 巨大的參數規模對用戶端設備的計算資源造成重大負擔，同時也導致昂貴的通信開銷。在 FL 中引入參數高效微調 (PEFT) 可以有效解決此問題。然而，我們觀察到聯合學習中的非 IID 數據導致 PEFT 方法和完全參數微調 (FT) 之間的性能差距。為了克服這個問題，我們提出了 FeDeRA，這是 FL 中 LoRA 方法的改進。FeDeRA 使用與 LoRA 相同的適配器模組。然而，不同之處在於 FeDeRA 透過對預訓練矩陣執行奇異值分解 (SVD) 並選擇其主成分來初始化適配器模組。我們使用 RoBERTa 和 DeBERTaV3 在三個任務和六個資料集上進行了廣泛的實驗，比較了包括 FT 和其他三種不同的 PEFT 方法在內的方法。FeDeRA 優於所有其他 PEFT 方法，並且與 FT 方法的性能相當甚至超越。我們還在 Jetson AGX Orin 上部署了聯合學習，並比較了不同方法在特定任務上達到目標準確度所需的時間。與 FT 相比，FeDeRA 使用 RoBERTa 和 DeBERTaV3 在三個任務上分別將訓練時間減少了 95.9%、97.9%、96.9% 和 97.3%、96.5% 和 96.5%。整體實驗表明，FeDeRA 在保持效率的同時實現了良好的性能。

##### **It's Difficult to be Neutral -- Human and LLM-based Sentiment Annotation of Patient Comments**
2404.18832v1 by Petter Mæhlum,David Samuel,Rebecka Maria Norman,Elma Jelin,Øyvind Andresen Bjertnæs,Lilja Øvrelid,Erik Velldal

Sentiment analysis is an important tool for aggregating patient voices, in
order to provide targeted improvements in healthcare services. A prerequisite
for this is the availability of in-domain data annotated for sentiment. This
article documents an effort to add sentiment annotations to free-text comments
in patient surveys collected by the Norwegian Institute of Public Health
(NIPH). However, annotation can be a time-consuming and resource-intensive
process, particularly when it requires domain expertise. We therefore also
evaluate a possible alternative to human annotation, using large language
models (LLMs) as annotators. We perform an extensive evaluation of the approach
for two openly available pretrained LLMs for Norwegian, experimenting with
different configurations of prompts and in-context learning, comparing their
performance to human annotators. We find that even for zero-shot runs, models
perform well above the baseline for binary sentiment, but still cannot compete
with human annotators on the full dataset.

摘要：情緒分析是彙整病患心聲的重要工具，用以提供醫療服務的目標性改善。這項工作的前提是擁有標記情緒的領域內資料。本文檔記錄一項工作，將情緒標記加入挪威公共衛生研究院 (NIPH) 所收集的病患調查中的自由文字評論。然而，標記可能是一個耗時且資源密集的程序，特別是在需要領域專業知識時。因此，我們也評估了人工標記的可能替代方案，使用大型語言模型 (LLM) 作為標記者。我們對兩種開放可用的挪威語預訓練 LLM 執行廣泛評估，實驗使用提示和情境學習的不同配置，將其表現與人工標記者進行比較。我們發現，即使是零次學習，模型在二元情緒的基準表現也很好，但仍無法在完整資料集上與人工標記者競爭。

##### **Harmonic Machine Learning Models are Robust**
2404.18825v1 by Nicholas S. Kersting,Yi Li,Aman Mohanty,Oyindamola Obisesan,Raphael Okochu

We introduce Harmonic Robustness, a powerful and intuitive method to test the
robustness of any machine-learning model either during training or in black-box
real-time inference monitoring without ground-truth labels. It is based on
functional deviation from the harmonic mean value property, indicating
instability and lack of explainability. We show implementation examples in
low-dimensional trees and feedforward NNs, where the method reliably identifies
overfitting, as well as in more complex high-dimensional models such as
ResNet-50 and Vision Transformer where it efficiently measures adversarial
vulnerability across image classes.

摘要：我們引入了和諧穩健性，這是一種強大且直觀的方法，可以在訓練期間或在黑盒子實時推理監控中測試任何機器學習模型的穩健性，而無需真實標籤。它是基於與調和平均值屬性的函數偏差，表示不穩定性和缺乏可解釋性。我們展示了低維樹和前饋神經網路中的實現範例，其中該方法可以可靠地識別過擬合，以及在更複雜的高維模型（例如 ResNet-50 和 Vision Transformer）中，它可以有效測量跨圖像類別的對抗性漏洞。

##### **Benchmarking Benchmark Leakage in Large Language Models**
2404.18824v1 by Ruijie Xu,Zengzhi Wang,Run-Ze Fan,Pengfei Liu

Amid the expanding use of pre-training data, the phenomenon of benchmark
dataset leakage has become increasingly prominent, exacerbated by opaque
training processes and the often undisclosed inclusion of supervised data in
contemporary Large Language Models (LLMs). This issue skews benchmark
effectiveness and fosters potentially unfair comparisons, impeding the field's
healthy development. To address this, we introduce a detection pipeline
utilizing Perplexity and N-gram accuracy, two simple and scalable metrics that
gauge a model's prediction precision on benchmark, to identify potential data
leakages. By analyzing 31 LLMs under the context of mathematical reasoning, we
reveal substantial instances of training even test set misuse, resulting in
potentially unfair comparisons. These findings prompt us to offer several
recommendations regarding model documentation, benchmark setup, and future
evaluations. Notably, we propose the "Benchmark Transparency Card" to encourage
clear documentation of benchmark utilization, promoting transparency and
healthy developments of LLMs. we have made our leaderboard, pipeline
implementation, and model predictions publicly available, fostering future
research.

摘要：隨著預訓練資料的廣泛使用，基準資料集洩漏的現象變得越來越明顯，並因不透明的訓練過程和當代大型語言模型 (LLM) 中經常未公開包含監督式資料而惡化。此問題會扭曲基準效能並助長潛在不公平的比較，阻礙該領域的健康發展。為了解決此問題，我們引入一個偵測管道，利用困惑度和 N-gram 精確度，這兩個用於評估模型在基準上的預測精確度的簡單且可擴充的指標，以識別潛在的資料洩漏。透過在數學推理的背景下分析 31 個 LLM，我們揭露了大量的訓練甚至測試集誤用案例，導致潛在不公平的比較。這些發現促使我們針對模型文件、基準設定和未來評估提出多項建議。值得注意的是，我們提出「基準透明度卡」，以鼓勵清楚記錄基準使用情況，促進 LLM 的透明度和健康發展。我們已公開我們的排行榜、管道實作和模型預測，以促進未來的研究。

##### **Control Policy Correction Framework for Reinforcement Learning-based Energy Arbitrage Strategies**
2404.18821v1 by Seyed Soroush Karimi Madahi,Gargya Gokhale,Marie-Sophie Verwee,Bert Claessens,Chris Develder

A continuous rise in the penetration of renewable energy sources, along with
the use of the single imbalance pricing, provides a new opportunity for balance
responsible parties to reduce their cost through energy arbitrage in the
imbalance settlement mechanism. Model-free reinforcement learning (RL) methods
are an appropriate choice for solving the energy arbitrage problem due to their
outstanding performance in solving complex stochastic sequential problems.
However, RL is rarely deployed in real-world applications since its learned
policy does not necessarily guarantee safety during the execution phase. In
this paper, we propose a new RL-based control framework for batteries to obtain
a safe energy arbitrage strategy in the imbalance settlement mechanism. In our
proposed control framework, the agent initially aims to optimize the arbitrage
revenue. Subsequently, in the post-processing step, we correct (constrain) the
learned policy following a knowledge distillation process based on properties
that follow human intuition. Our post-processing step is a generic method and
is not restricted to the energy arbitrage domain. We use the Belgian imbalance
price of 2023 to evaluate the performance of our proposed framework.
Furthermore, we deploy our proposed control framework on a real battery to show
its capability in the real world.

摘要：隨著可再生能源的滲透率持續上升，加上單一失衡定價的使用，為平衡責任方透過失衡結算機制中的能源套利來降低成本提供了新的機會。無模型強化學習 (RL) 方法由於其在解決複雜隨機順序問題上的出色表現，因此是解決能源套利問題的適當選擇。然而，RL 很少部署在實際應用中，因為其學習到的策略並不能保證在執行階段的安全。在本文中，我們針對電池提出一個新的基於 RL 的控制架構，以在失衡結算機制中取得安全的能源套利策略。在我們提出的控制架構中，代理最初旨在優化套利收益。隨後，在後處理步驟中，我們根據遵循人類直覺的屬性，透過知識萃取流程修正（約束）學習到的策略。我們的後處理步驟是一種通用方法，並不限於能源套利領域。我們使用 2023 年比利時失衡價格來評估我們提出的架構的性能。此外，我們在真實電池上部署我們提出的控制架構，以展示其在現實世界中的能力。

##### **Unknown Script: Impact of Script on Cross-Lingual Transfer**
2404.18810v1 by Wondimagegnhue Tsegaye Tufa,Ilia Markov,Piek Vossen

Cross-lingual transfer has become an effective way of transferring knowledge
between languages. In this paper, we explore an often-overlooked aspect in this
domain: the influence of the source language of the base language model on
transfer performance. We conduct a series of experiments to determine the
effect of the script and tokenizer used in the pre-trained model on the
performance of the downstream task. Our findings reveal the importance of the
tokenizer as a stronger factor than the sharing of the script, the language
typology match, and the model size.

摘要：跨語言轉移已成為在語言之間傳遞知識的有效途徑。在本文中，我們探索這個領域中經常被忽視的一面：基礎語言模型的源語言對轉移效能的影響。我們進行了一系列實驗，以確定預訓練模型中使用的腳本和分詞器對下游任務效能的影響。我們的研究結果揭示了分詞器作為一個比腳本共享、語言類型匹配和模型大小更強大的因素的重要性。

##### **Replacing Judges with Juries: Evaluating LLM Generations with a Panel of Diverse Models**
2404.18796v1 by Pat Verga,Sebastian Hofstatter,Sophia Althammer,Yixuan Su,Aleksandra Piktus,Arkady Arkhangorodsky,Minjie Xu,Naomi White,Patrick Lewis

As Large Language Models (LLMs) have become more advanced, they have outpaced
our abilities to accurately evaluate their quality. Not only is finding data to
adequately probe particular model properties difficult, but evaluating the
correctness of a model's freeform generation alone is a challenge. To address
this, many evaluations now rely on using LLMs themselves as judges to score the
quality of outputs from other LLMs. Evaluations most commonly use a single
large model like GPT4. While this method has grown in popularity, it is costly,
has been shown to introduce intramodel bias, and in this work, we find that
very large models are often unnecessary. We propose instead to evaluate models
using a Panel of LLm evaluators (PoLL). Across three distinct judge settings
and spanning six different datasets, we find that using a PoLL composed of a
larger number of smaller models outperforms a single large judge, exhibits less
intra-model bias due to its composition of disjoint model families, and does so
while being over seven times less expensive.

摘要：隨著大型語言模型 (LLM) 變得更加先進，它們已經超越了我們準確評估其品質的能力。不僅難以找到資料來充分探測特定模型屬性，而且單獨評估模型自由形式生成的正確性也是一項挑戰。為了解決這個問題，許多評估現在依賴於使用 LLM 本身作為評審員來評分其他 LLM 的輸出品質。評估最常使用像 GPT4 這樣的單一大型模型。儘管這種方法越來越受歡迎，但它成本高昂，已被證明會引入模型內部偏見，而且在這項工作中，我們發現非常大的模型通常是不必要的。我們建議改用 LLM 評估小組 (PoLL) 來評估模型。在三個不同的評審員設定中，並橫跨六個不同的資料集，我們發現使用由更多較小模型組成的 PoLL 優於單一大型評審員，由於其由不相交的模型系列組成，因此表現出較少的模型內部偏見，而且在成本上還低了七倍以上。

##### **Certification of Speaker Recognition Models to Additive Perturbations**
2404.18791v1 by Dmitrii Korzh,Elvir Karimov,Mikhail Pautov,Oleg Y. Rogov,Ivan Oseledets

Speaker recognition technology is applied in various tasks ranging from
personal virtual assistants to secure access systems. However, the robustness
of these systems against adversarial attacks, particularly to additive
perturbations, remains a significant challenge. In this paper, we pioneer
applying robustness certification techniques to speaker recognition, originally
developed for the image domain. In our work, we cover this gap by transferring
and improving randomized smoothing certification techniques against
norm-bounded additive perturbations for classification and few-shot learning
tasks to speaker recognition. We demonstrate the effectiveness of these methods
on VoxCeleb 1 and 2 datasets for several models. We expect this work to improve
voice-biometry robustness, establish a new certification benchmark, and
accelerate research of certification methods in the audio domain.

摘要：語音辨識技術應用於各種任務，從個人虛擬助理到安全存取系統。然而，這些系統對於對抗攻擊的穩健性，特別是對加法擾動的穩健性，仍然是一項重大挑戰。在本文中，我們率先將穩健性認證技術應用於語音辨識，最初是為影像領域開發的。在我們的研究中，我們透過將針對分類和少量學習任務的範數約束加法擾動的隨機平滑認證技術轉移並加以改進，來填補這個差距。我們在多個模型的 VoxCeleb 1 和 2 資料集上展示了這些方法的有效性。我們預期這項研究將提升語音生物識別的穩健性，建立新的認證基準，並加速音訊領域認證方法的研究。

##### **Where on Earth Do Users Say They Are?: Geo-Entity Linking for Noisy Multilingual User Input**
2404.18784v1 by Tessa Masis,Brendan O'Connor

Geo-entity linking is the task of linking a location mention to the
real-world geographic location. In this paper we explore the challenging task
of geo-entity linking for noisy, multilingual social media data. There are few
open-source multilingual geo-entity linking tools available and existing ones
are often rule-based, which break easily in social media settings, or
LLM-based, which are too expensive for large-scale datasets. We present a
method which represents real-world locations as averaged embeddings from
labeled user-input location names and allows for selective prediction via an
interpretable confidence score. We show that our approach improves geo-entity
linking on a global and multilingual social media dataset, and discuss progress
and problems with evaluating at different geographic granularities.

摘要：地理實體連結是將位置資訊連結到真實世界地理位置的任務。在本文中，我們探討了社群媒體資料中多語言、雜訊的地理實體連結的挑戰性任務。目前只有少數開放原始碼多語言地理實體連結工具可用，而現有的工具通常是基於規則的，在社群媒體設定中容易中斷，或基於 LLM 的，對於大規模資料集而言太昂貴。我們提出了一種方法，將真實世界的位置表示為標記使用者輸入位置名稱的平均內嵌，並允許透過可解釋的信心分數進行選擇性預測。我們表明，我們的做法改善了全球和多語言社群媒體資料集上的地理實體連結，並討論了在不同地理粒度下評估的進展和問題。

##### **Saliency Suppressed, Semantics Surfaced: Visual Transformations in Neural Networks and the Brain**
2404.18772v1 by Gustaw Opiełka,Jessica Loke,Steven Scholte

Deep learning algorithms lack human-interpretable accounts of how they
transform raw visual input into a robust semantic understanding, which impedes
comparisons between different architectures, training objectives, and the human
brain. In this work, we take inspiration from neuroscience and employ
representational approaches to shed light on how neural networks encode
information at low (visual saliency) and high (semantic similarity) levels of
abstraction. Moreover, we introduce a custom image dataset where we
systematically manipulate salient and semantic information. We find that
ResNets are more sensitive to saliency information than ViTs, when trained with
object classification objectives. We uncover that networks suppress saliency in
early layers, a process enhanced by natural language supervision (CLIP) in
ResNets. CLIP also enhances semantic encoding in both architectures. Finally,
we show that semantic encoding is a key factor in aligning AI with human visual
perception, while saliency suppression is a non-brain-like strategy.

摘要：深度學習演算法缺乏人類可解釋的說明，說明它們如何將原始視覺輸入轉換為強健的語意理解，這阻礙了不同架構、訓練目標和人腦之間的比較。在這項工作中，我們從神經科學中汲取靈感，並採用表徵方法來闡明神經網路如何在低（視覺顯著性）和高（語意相似性）抽象層級編碼資訊。此外，我們引進一個自訂影像資料集，系統性地處理顯著和語意資訊。我們發現，當以物件分類目標訓練時，ResNet 比 ViT 對顯著性資訊更敏感。我們發現網路會在早期層級抑制顯著性，這個過程在 ResNet 中透過自然語言監督 (CLIP) 得到加強。CLIP 也增強了這兩種架構中的語意編碼。最後，我們證明語意編碼是將人工智慧與人類視覺感知對齊的關鍵因素，而顯著性抑制是一種非大腦策略。

##### **PECC: Problem Extraction and Coding Challenges**
2404.18766v1 by Patrick Haller,Jonas Golde,Alan Akbik

Recent advancements in large language models (LLMs) have showcased their
exceptional abilities across various tasks, such as code generation,
problem-solving and reasoning. Existing benchmarks evaluate tasks in isolation,
yet the extent to which LLMs can understand prose-style tasks, identify the
underlying problems, and then generate appropriate code solutions is still
unexplored. Addressing this gap, we introduce PECC, a novel benchmark derived
from Advent Of Code (AoC) challenges and Project Euler, including 2396
problems. Unlike conventional benchmarks, PECC requires LLMs to interpret
narrative-embedded problems, extract requirements, and generate executable
code. A key feature of our dataset is the complexity added by natural language
prompting in chat-based evaluations, mirroring real-world instruction
ambiguities. Results show varying model performance between narrative and
neutral problems, with specific challenges in the Euler math-based subset with
GPT-3.5-Turbo passing 50% of the AoC challenges and only 8% on the Euler
problems. By probing the limits of LLMs' capabilities, our benchmark provides a
framework to monitor and assess the subsequent progress of LLMs as a universal
problem solver.

摘要：大型語言模型 (LLM) 最近的進展展示了它們在各種任務中的卓越能力，例如程式碼生成、問題解決和推理。現有的基準會單獨評估任務，但 LLM 了解散文式任務、找出潛在問題，然後產生適當程式碼解決方案的能力範圍仍未探索。為了解決這個差距，我們引入了 PECC，一個源自 Advent Of Code (AoC) 挑戰和 Project Euler 的新基準，其中包含 2396 個問題。與傳統基準不同，PECC 要求 LLM 解釋嵌入敘述的問題、提取需求並產生可執行的程式碼。我們資料集的一個關鍵特徵是自然語言在聊天式評估中提示所增加的複雜性，反映了真實世界的指令模糊性。結果顯示，在敘述性和中立問題之間，模型效能有所不同，在基於歐拉數學的子集中，GPT-3.5-Turbo 通過 50% 的 AoC 挑戰，而在歐拉問題中僅通過 8%。透過探討 LLM 能力的極限，我們的基準提供了一個架構，用於監控和評估 LLM 作為通用問題解決者的後續進展。

##### **Towards A Structured Overview of Use Cases for Natural Language Processing in the Legal Domain: A German Perspective**
2404.18759v1 by Juraj Vladika,Stephen Meisenbacher,Martina Preis,Alexandra Klymenko,Florian Matthes

In recent years, the field of Legal Tech has risen in prevalence, as the
Natural Language Processing (NLP) and legal disciplines have combined forces to
digitalize legal processes. Amidst the steady flow of research solutions
stemming from the NLP domain, the study of use cases has fallen behind, leading
to a number of innovative technical methods without a place in practice. In
this work, we aim to build a structured overview of Legal Tech use cases,
grounded in NLP literature, but also supplemented by voices from legal practice
in Germany. Based upon a Systematic Literature Review, we identify seven
categories of NLP technologies for the legal domain, which are then studied in
juxtaposition to 22 legal use cases. In the investigation of these use cases,
we identify 15 ethical, legal, and social aspects (ELSA), shedding light on the
potential concerns of digitally transforming the legal domain.

摘要：近年來，法律科技領域的普及率上升，因為自然語言處理 (NLP) 和法律學科已結合力量來數位化法律程序。在源自 NLP 領域的穩定研究解決方案中，使用案例的研究落後，導致許多創新的技術方法無法實務應用。在這項工作中，我們旨在建立法律科技使用案例的結構化概述，以 NLP 文獻為基礎，但同時也補充了來自德國法律實務的意見。根據系統性文獻回顧，我們找出七類適用於法律領域的 NLP 技術，接著在與 22 個法律使用案例並置的情況下進行研究。在調查這些使用案例時，我們找出 15 個道德、法律和社會面向 (ELSA)，揭示了數位轉型法律領域的潛在疑慮。

##### **Evaluating the Effectiveness of Video Anomaly Detection in the Wild: Online Learning and Inference for Real-world Deployment**
2404.18747v1 by Shanle Yao,Ghazal Alinezhad Noghre,Armin Danesh Pazho,Hamed Tabkhi

Video Anomaly Detection (VAD) identifies unusual activities in video streams,
a key technology with broad applications ranging from surveillance to
healthcare. Tackling VAD in real-life settings poses significant challenges due
to the dynamic nature of human actions, environmental variations, and domain
shifts. Many research initiatives neglect these complexities, often
concentrating on traditional testing methods that fail to account for
performance on unseen datasets, creating a gap between theoretical models and
their real-world utility. Online learning is a potential strategy to mitigate
this issue by allowing models to adapt to new information continuously. This
paper assesses how well current VAD algorithms can adjust to real-life
conditions through an online learning framework, particularly those based on
pose analysis, for their efficiency and privacy advantages. Our proposed
framework enables continuous model updates with streaming data from novel
environments, thus mirroring actual world challenges and evaluating the models'
ability to adapt in real-time while maintaining accuracy. We investigate three
state-of-the-art models in this setting, focusing on their adaptability across
different domains. Our findings indicate that, even under the most challenging
conditions, our online learning approach allows a model to preserve 89.39% of
its original effectiveness compared to its offline-trained counterpart in a
specific target domain.

摘要：視訊異常偵測 (VAD) 可識別視訊串流中的異常活動，
這項關鍵技術的應用範圍廣泛，從監控到
醫療保健。在現實生活中應對 VAD 會帶來重大挑戰，因為
人類行為的動態特性、環境變化和領域轉移。許多研究計畫忽略了這些複雜性，通常
專注於傳統的測試方法，無法考量在未見過的資料集上的效能，造成理論模型與
實際效用之間的差距。線上學習是一種潛在策略，可透過持續讓模型適應新資訊來減輕
此問題。這篇論文評估目前 VAD 演算法在線上學習架構中適應實際情況的表現，特別是那些基於
姿勢分析的演算法，因為它們具有效率和隱私優勢。我們提出的
架構能透過來自新環境的串流資料持續更新模型，因此能反映實際世界的挑戰，並評估模型在保持準確性的同時適應即時環境的能力。我們在此設定中研究了三種最先進的模型，重點關注它們在不同領域的適應性。我們的研究結果表明，即使在最具挑戰性的
條件下，我們的線上學習方法也能讓模型保留 89.39% 的原始效能，高於在特定目標領域中以離線方式訓練的模型。

##### **Towards Dog Bark Decoding: Leveraging Human Speech Processing for Automated Bark Classification**
2404.18739v1 by Artem Abzaliev,Humberto Pérez Espinosa,Rada Mihalcea

Similar to humans, animals make extensive use of verbal and non-verbal forms
of communication, including a large range of audio signals. In this paper, we
address dog vocalizations and explore the use of self-supervised speech
representation models pre-trained on human speech to address dog bark
classification tasks that find parallels in human-centered tasks in speech
recognition. We specifically address four tasks: dog recognition, breed
identification, gender classification, and context grounding. We show that
using speech embedding representations significantly improves over simpler
classification baselines. Further, we also find that models pre-trained on
large human speech acoustics can provide additional performance boosts on
several tasks.

摘要：與人類類似，動物廣泛使用語言和非語言形式的溝通，包括大量的音訊訊號。在本文中，我們探討狗的發聲，並探索使用在人類語言上預先訓練的自監督式語言表徵模型，以解決狗吠聲分類任務，這些任務與以人類為中心的語言辨識任務有相似之處。我們特別探討四項任務：狗隻辨識、品種辨識、性別分類和脈絡基礎。我們證明使用語言嵌入表徵顯著優於較簡單的分類基準。此外，我們也發現預先在大量人類語言聲學上訓練的模型，可以在多項任務中提供額外的效能提升。

##### **The Constant in HATE: Analyzing Toxicity in Reddit across Topics and Languages**
2404.18726v1 by Wondimagegnhue Tsegaye Tufa,Ilia Markov,Piek Vossen

Toxic language remains an ongoing challenge on social media platforms,
presenting significant issues for users and communities. This paper provides a
cross-topic and cross-lingual analysis of toxicity in Reddit conversations. We
collect 1.5 million comment threads from 481 communities in six languages:
English, German, Spanish, Turkish,Arabic, and Dutch, covering 80 topics such as
Culture, Politics, and News. We thoroughly analyze how toxicity spikes within
different communities in relation to specific topics. We observe consistent
patterns of increased toxicity across languages for certain topics, while also
noting significant variations within specific language communities.

摘要：有毒言論仍然是社群媒體平台上持續的挑戰，對使用者和社群造成重大問題。本文提供 Reddit 對話中針對毒性的跨主題和跨語言分析。我們從六種語言的 481 個社群中收集了 150 萬個留言串：英語、德語、西班牙語、土耳其語、阿拉伯語和荷蘭語，涵蓋了 80 個主題，例如文化、政治和新聞。我們徹底分析了毒性如何在不同社群內針對特定主題激增。我們觀察到，在某些主題上，跨語言的毒性會持續增加，同時也注意到特定語言社群內的顯著差異。

##### **Improving Automatic Text Recognition with Language Models in the PyLaia Open-Source Library**
2404.18722v1 by Solène Tarride,Yoann Schneider,Marie Generali-Lince,Mélodie Boillet,Bastien Abadie,Christopher Kermorvant

PyLaia is one of the most popular open-source software for Automatic Text
Recognition (ATR), delivering strong performance in terms of speed and
accuracy. In this paper, we outline our recent contributions to the PyLaia
library, focusing on the incorporation of reliable confidence scores and the
integration of statistical language modeling during decoding. Our
implementation provides an easy way to combine PyLaia with n-grams language
models at different levels. One of the highlights of this work is that language
models are completely auto-tuned: they can be built and used easily without any
expert knowledge, and without requiring any additional data. To demonstrate the
significance of our contribution, we evaluate PyLaia's performance on twelve
datasets, both with and without language modelling. The results show that
decoding with small language models improves the Word Error Rate by 13% and the
Character Error Rate by 12% in average. Additionally, we conduct an analysis of
confidence scores and highlight the importance of calibration techniques. Our
implementation is publicly available in the official PyLaia repository at
https://gitlab.teklia.com/atr/pylaia, and twelve open-source models are
released on Hugging Face.

摘要：PyLaia 是最受歡迎的自動文字辨識 (ATR) 開源軟體之一，在速度和準確度方面表現優異。在本文中，我們概述了我們對 PyLaia 程式庫的最新貢獻，重點在於納入可靠的信心分數，以及在解碼過程中整合統計語言模型。我們的實作提供了一個簡單的方法，可以在不同層級將 PyLaia 與 n-grams 語言模型結合。這項工作的亮點之一是語言模型完全自動調整：它們可以輕鬆建立和使用，無需任何專家知識，也不需要任何額外資料。為了證明我們貢獻的重要性，我們評估了 PyLaia 在十二個資料集上的效能，有使用語言模型和沒有使用語言模型的狀況。結果顯示，使用小型語言模型進行解碼，平均可將字元錯誤率降低 13%，將字元錯誤率降低 12%。此外，我們對信心分數進行分析，並強調校準技術的重要性。我們的實作公開在 https://gitlab.teklia.com/atr/pylaia 的官方 PyLaia 存放庫中，並在 Hugging Face 上釋出了十二個開源模型。

##### **Iconic Gesture Semantics**
2404.18708v1 by Andy Lücking,Alexander Henlein,Alexander Mehler

The "meaning" of an iconic gesture is conditioned on its informational
evaluation. Only informational evaluation lifts a gesture to a quasi-linguistic
level that can interact with verbal content. Interaction is either vacuous or
regimented by usual lexicon-driven inferences. Informational evaluation is
spelled out as extended exemplification (extemplification) in terms of
perceptual classification of a gesture's visual iconic model. The iconic model
is derived from Frege/Montague-like truth-functional evaluation of a gesture's
form within spatially extended domains. We further argue that the perceptual
classification of instances of visual communication requires a notion of
meaning different from Frege/Montague frameworks. Therefore, a heuristic for
gesture interpretation is provided that can guide the working semanticist. In
sum, an iconic gesture semantics is introduced which covers the full range from
kinematic gesture representations over model-theoretic evaluation to
inferential interpretation in dynamic semantic frameworks.

摘要：手勢圖像的「意義」取決於其資訊評估。只有資訊評估才能將手勢提升至與語言內容互動的準語言層級。互動不是空洞的，就是由常見的詞彙驅動推論所規範。資訊評估在手勢視覺圖像模型的感知分類中被表述為延伸例證（extemplification）。圖像模型源自於手勢形式在空間延伸領域中的 Frege/Montague 型真值函數評估。我們進一步主張，視覺溝通實例的感知分類需要一個與 Frege/Montague 架構不同的意義概念。因此，提供了一個手勢詮釋啟發法，可以指導工作語義學家。總之，引入了一個圖像手勢語義，涵蓋了從運動手勢表示到模型理論評估再到動態語義框架中的推論詮釋的完整範圍。

##### **Work Smarter...Not Harder: Efficient Minimization of Dependency Length in SOV Languages**
2404.18684v1 by Sidharth Ranjan,Titus von der Malsburg

Dependency length minimization is a universally observed quantitative
property of natural languages. However, the extent of dependency length
minimization, and the cognitive mechanisms through which the language processor
achieves this minimization remain unclear. This research offers mechanistic
insights by postulating that moving a short preverbal constituent next to the
main verb explains preverbal constituent ordering decisions better than global
minimization of dependency length in SOV languages. This approach constitutes a
least-effort strategy because it's just one operation but simultaneously
reduces the length of all preverbal dependencies linked to the main verb. We
corroborate this strategy using large-scale corpus evidence across all seven
SOV languages that are prominently represented in the Universal Dependency
Treebank. These findings align with the concept of bounded rationality, where
decision-making is influenced by 'quick-yet-economical' heuristics rather than
exhaustive searches for optimal solutions. Overall, this work sheds light on
the role of bounded rationality in linguistic decision-making and language
evolution.

摘要：依存關係長度最小化是自然語言普遍觀察到的量化屬性。然而，依存關係長度最小化的程度，以及語言處理器達成此最小化的認知機制仍不明確。本研究透過假設將一個短的動詞前成分移至主要動詞旁邊，比 SOV 語言中依存關係長度的整體最小化，能更好地說明動詞前成分排序的決策，從而提供機械論的見解。這種方法構成一個最省力的策略，因為它只是一個操作，但同時減少了連結至主要動詞的所有動詞前依存關係的長度。我們使用在 Universal Dependency Treebank 中顯著呈現的所有七種 SOV 語言中的大規模語料庫證據，來證實此策略。這些發現與受限理性的概念相符，其中決策制定受到「快速卻經濟」的啟發式影響，而非對最佳解的窮舉搜尋。總體而言，這項工作闡明了受限理性在語言決策制定和語言演化中的角色。

##### **Graph Convolutional Networks and Graph Attention Networks for Approximating Arguments Acceptability -- Technical Report**
2404.18672v1 by Paul Cibier,Jean-Guy Mailly

Various approaches have been proposed for providing efficient computational
approaches for abstract argumentation. Among them, neural networks have
permitted to solve various decision problems, notably related to arguments
(credulous or skeptical) acceptability. In this work, we push further this
study in various ways. First, relying on the state-of-the-art approach AFGCN,
we show how we can improve the performances of the Graph Convolutional Networks
(GCNs) regarding both runtime and accuracy. Then, we show that it is possible
to improve even more the efficiency of the approach by modifying the
architecture of the network, using Graph Attention Networks (GATs) instead.

摘要：在提供抽象論證的有效運算方法方面，已經提出了各種方法。其中，神經網路允許解決各種決策問題，特別是與論證（輕信或懷疑）的可接受性相關的問題。在這項工作中，我們以各種方式進一步推動這項研究。首先，依賴於最先進的方法 AFGCN，我們展示了如何改進圖卷積網路 (GCN) 在執行時間和準確性方面的效能。然後，我們展示了通過修改網路架構，使用圖注意力網路 (GAT) 代替，可以進一步提高方法的效率。

##### **Bootstrap 3D Reconstructed Scenes from 3D Gaussian Splatting**
2404.18669v1 by Yifei Gao,Jie Ou,Lei Wang,Jun Cheng

Recent developments in neural rendering techniques have greatly enhanced the
rendering of photo-realistic 3D scenes across both academic and commercial
fields. The latest method, known as 3D Gaussian Splatting (3D-GS), has set new
benchmarks for rendering quality and speed. Nevertheless, the limitations of
3D-GS become pronounced in synthesizing new viewpoints, especially for views
that greatly deviate from those seen during training. Additionally, issues such
as dilation and aliasing arise when zooming in or out. These challenges can all
be traced back to a single underlying issue: insufficient sampling. In our
paper, we present a bootstrapping method that significantly addresses this
problem. This approach employs a diffusion model to enhance the rendering of
novel views using trained 3D-GS, thereby streamlining the training process. Our
results indicate that bootstrapping effectively reduces artifacts, as well as
clear enhancements on the evaluation metrics. Furthermore, we show that our
method is versatile and can be easily integrated, allowing various 3D
reconstruction projects to benefit from our approach.

摘要：近來神經渲染技術的發展大幅提升了學術界和商業領域中逼真 3D 場景的渲染效果。最新的方法稱為 3D 高斯潑濺（3D-GS），已為渲染品質和速度樹立新的基準。儘管如此，3D-GS 的限制在合成新的視點時變得明顯，特別是對於與訓練期間所見視點差異很大的視點。此外，在放大或縮小時會出現膨脹和鋸齒等問題。這些挑戰都可以追溯到單一的基本問題：採樣不足。在我們的論文中，我們提出了一種引導方法，可以大幅解決這個問題。此方法採用擴散模型，以使用訓練過的 3D-GS 增強新視圖的渲染，從而簡化訓練流程。我們的結果顯示，引導有效減少了人工製品，並在評估指標上顯著提升。此外，我們證明了我們的方法用途廣泛且易於整合，讓各種 3D 重建專案都能受益於我們的方法。

##### **Revealing the Parametric Knowledge of Language Models: A Unified Framework for Attribution Methods**
2404.18655v1 by Haeun Yu,Pepa Atanasova,Isabelle Augenstein

Language Models (LMs) acquire parametric knowledge from their training
process, embedding it within their weights. The increasing scalability of LMs,
however, poses significant challenges for understanding a model's inner
workings and further for updating or correcting this embedded knowledge without
the significant cost of retraining. This underscores the importance of
unveiling exactly what knowledge is stored and its association with specific
model components. Instance Attribution (IA) and Neuron Attribution (NA) offer
insights into this training-acquired knowledge, though they have not been
compared systematically. Our study introduces a novel evaluation framework to
quantify and compare the knowledge revealed by IA and NA. To align the results
of the methods we introduce the attribution method NA-Instances to apply NA for
retrieving influential training instances, and IA-Neurons to discover important
neurons of influential instances discovered by IA. We further propose a
comprehensive list of faithfulness tests to evaluate the comprehensiveness and
sufficiency of the explanations provided by both methods. Through extensive
experiments and analysis, we demonstrate that NA generally reveals more diverse
and comprehensive information regarding the LM's parametric knowledge compared
to IA. Nevertheless, IA provides unique and valuable insights into the LM's
parametric knowledge, which are not revealed by NA. Our findings further
suggest the potential of a synergistic approach of combining the diverse
findings of IA and NA for a more holistic understanding of an LM's parametric
knowledge.

摘要：語言模型 (LM) 從其訓練過程中獲取參數知識，並將其嵌入其權重中。然而，LM 的可擴展性不斷提高，對理解模型的內部運作以及進一步更新或更正此嵌入式知識提出了重大挑戰，而無需付出重新訓練的顯著成本。這強調了準確揭示儲存的知識及其與特定模型組件的關聯的重要性。實例歸因 (IA) 和神經元歸因 (NA) 提供了對這種訓練獲取的知識的見解，儘管它們尚未經過系統比較。我們的研究引入了一個新的評估框架，以量化和比較 IA 和 NA 揭示的知識。為了對齊方法的結果，我們引入了歸因方法 NA-Instances，以應用 NA 檢索有影響力的訓練實例，以及 IA-Neurons，以發現 IA 發現的有影響力實例的重要神經元。我們進一步提出了全面的忠實度測試清單，以評估這兩種方法提供的解釋的全面性和充分性。通過廣泛的實驗和分析，我們證明 NA 通常揭示了與 IA 相比更多樣化且更全面的有關 LM 參數知識的信息。儘管如此，IA 仍提供對 LM 參數知識的獨特且有價值的見解，而這些見解並未被 NA 揭示。我們的研究結果進一步表明，結合 IA 和 NA 的不同發現以更全面地了解 LM 的參數知識的協同方法的潛力。

##### **Towards Quantitative Evaluation of Explainable AI Methods for Deepfake Detection**
2404.18649v1 by Konstantinos Tsigos,Evlampios Apostolidis,Spyridon Baxevanakis,Symeon Papadopoulos,Vasileios Mezaris

In this paper we propose a new framework for evaluating the performance of
explanation methods on the decisions of a deepfake detector. This framework
assesses the ability of an explanation method to spot the regions of a fake
image with the biggest influence on the decision of the deepfake detector, by
examining the extent to which these regions can be modified through a set of
adversarial attacks, in order to flip the detector's prediction or reduce its
initial prediction; we anticipate a larger drop in deepfake detection accuracy
and prediction, for methods that spot these regions more accurately. Based on
this framework, we conduct a comparative study using a state-of-the-art model
for deepfake detection that has been trained on the FaceForensics++ dataset,
and five explanation methods from the literature. The findings of our
quantitative and qualitative evaluations document the advanced performance of
the LIME explanation method against the other compared ones, and indicate this
method as the most appropriate for explaining the decisions of the utilized
deepfake detector.

摘要：在本文中，我们提出了一个新的框架，用于评估解释方法在深度造假检测器决策上的性能。此框架评估解释方法识别深度造假检测器决策中影响最大的虚假图像区域的能力，方法是检查通过一组对抗性攻击修改这些区域的程度，以翻转检测器的预测或降低其初始预测；我们预期，对于更准确地识别这些区域的方法，深度造假检测准确性和预测会大幅下降。基于此框架，我们使用针对 FaceForensics++ 数据集训练过的深度造假检测的最新模型和文献中的五种解释方法进行比较研究。我们的定量和定性评估结果记录了 LIME 解释方法相对于其他比较方法的先进性能，并表明此方法最适合解释所用深度造假检测器的决策。

##### **Reinforcement Learning Problem Solving with Large Language Models**
2404.18638v1 by Sina Gholamian,Domingo Huh

Large Language Models (LLMs) encapsulate an extensive amount of world
knowledge, and this has enabled their application in various domains to improve
the performance of a variety of Natural Language Processing (NLP) tasks. This
has also facilitated a more accessible paradigm of conversation-based
interactions between humans and AI systems to solve intended problems. However,
one interesting avenue that shows untapped potential is the use of LLMs as
Reinforcement Learning (RL) agents to enable conversational RL problem solving.
Therefore, in this study, we explore the concept of formulating Markov Decision
Process-based RL problems as LLM prompting tasks. We demonstrate how LLMs can
be iteratively prompted to learn and optimize policies for specific RL tasks.
In addition, we leverage the introduced prompting technique for episode
simulation and Q-Learning, facilitated by LLMs. We then show the practicality
of our approach through two detailed case studies for "Research Scientist" and
"Legal Matter Intake" workflows.

摘要：大型語言模型 (LLM) 囊括了大量的世界知識，這使得它們能夠應用於各種領域，以提升各種自然語言處理 (NLP) 任務的效能。這也促成了人類與 AI 系統之間更易於存取的對話式互動模式，以解決預期的問題。然而，一個顯示出未開發潛力的有趣途徑是將 LLM 用作強化學習 (RL) 代理，以實現對話式 RL 問題解決。因此，在本研究中，我們探索了將基於馬可夫決策過程的 RL 問題制定為 LLM 提示任務的概念。我們展示了如何反覆提示 LLM 以學習和最佳化特定 RL 任務的策略。此外，我們利用導入的提示技術進行由 LLM 促成的章節模擬和 Q 學習。然後，我們透過兩個針對「研究科學家」和「法律事務處理」工作流程的詳細案例研究，展示了我們方法的實用性。

##### **Do Vision & Language Decoders use Images and Text equally? How Self-consistent are their Explanations?**
2404.18624v1 by Letitia Parcalabescu,Anette Frank

Vision and language models (VLMs) are currently the most generally performant
architectures on multimodal tasks. Next to their predictions, they can also
produce explanations, either in post-hoc or CoT settings. However, it is not
clear how much they use the vision and text modalities when generating
predictions or explanations. In this work, we investigate if VLMs rely on
modalities differently when generating explanations as opposed to when they
provide answers. We also evaluate the self-consistency of VLM decoders in both
post-hoc and CoT explanation settings, by extending existing tests and measures
to VLM decoders. We find that VLMs are less self-consistent than LLMs. The text
contributions in VL decoders are much larger than the image contributions
across all measured tasks. And the contributions of the image are significantly
larger for explanation generations than for answer generation. This difference
is even larger in CoT compared to the post-hoc explanation setting. We also
provide an up-to-date benchmarking of state-of-the-art VL decoders on the VALSE
benchmark, which to date focused only on VL encoders. We find that VL decoders
are still struggling with most phenomena tested by VALSE.

摘要：視覺和語言模型 (VLM) 目前是多模態任務中表現最全面的架構。除了其預測之外，它們還能產生解釋，無論是在事後或 CoT 設定中。然而，尚不清楚它們在生成預測或解釋時使用了多少視覺和文本模式。在這項工作中，我們探討 VLM 在生成解釋時是否與在提供答案時不同地依賴模式。我們還透過將現有測試和測量擴展到 VLM 解碼器，評估 VLM 解碼器在事後和 CoT 解釋設定中的自我一致性。我們發現 VLM 的自我一致性不如 LLM。在所有測量任務中，VLM 解碼器中的文本貢獻遠大於影像貢獻。而且，影像的貢獻對於解釋生成顯著大於答案生成。與事後解釋設定相比，這種差異在 CoT 中更大。我們還對 VALSE 基準上的最新 VLM 解碼器進行了最新基準測試，該基準迄今僅關注 VLM 編碼器。我們發現 VLM 解碼器仍在與 VALSE 測試的大多數現象作鬥爭。

##### **The SAMER Arabic Text Simplification Corpus**
2404.18615v1 by Bashar Alhafni,Reem Hazim,Juan Piñeros Liberato,Muhamed Al Khalil,Nizar Habash

We present the SAMER Corpus, the first manually annotated Arabic parallel
corpus for text simplification targeting school-aged learners. Our corpus
comprises texts of 159K words selected from 15 publicly available Arabic
fiction novels most of which were published between 1865 and 1955. Our corpus
includes readability level annotations at both the document and word levels, as
well as two simplified parallel versions for each text targeting learners at
two different readability levels. We describe the corpus selection process, and
outline the guidelines we followed to create the annotations and ensure their
quality. Our corpus is publicly available to support and encourage research on
Arabic text simplification, Arabic automatic readability assessment, and the
development of Arabic pedagogical language technologies.

摘要：我們提出 SAMER 語料庫，這是第一個針對學齡學習者而進行手動標註的阿拉伯語平行簡化語料庫。我們的語料庫包含從 15 部公開的阿拉伯語小說中選出的 159K 字詞，其中大部分於 1865 年至 1955 年間出版。我們的語料庫包含在文件和字詞層級的閱讀難易度標註，以及針對兩個不同閱讀難易度學習者的兩個簡化平行版本。我們描述語料庫的選擇過程，並概述我們用來建立標註並確保其品質的準則。我們的語料庫公開供使用，以支持並鼓勵阿拉伯語簡化文本、阿拉伯語自動閱讀難易度評估以及阿拉伯語教學語言技術的發展。

##### **CSTalk: Correlation Supervised Speech-driven 3D Emotional Facial Animation Generation**
2404.18604v1 by Xiangyu Liang,Wenlin Zhuang,Tianyong Wang,Guangxing Geng,Guangyue Geng,Haifeng Xia,Siyu Xia

Speech-driven 3D facial animation technology has been developed for years,
but its practical application still lacks expectations. The main challenges lie
in data limitations, lip alignment, and the naturalness of facial expressions.
Although lip alignment has seen many related studies, existing methods struggle
to synthesize natural and realistic expressions, resulting in a mechanical and
stiff appearance of facial animations. Even with some research extracting
emotional features from speech, the randomness of facial movements limits the
effective expression of emotions. To address this issue, this paper proposes a
method called CSTalk (Correlation Supervised) that models the correlations
among different regions of facial movements and supervises the training of the
generative model to generate realistic expressions that conform to human facial
motion patterns. To generate more intricate animations, we employ a rich set of
control parameters based on the metahuman character model and capture a dataset
for five different emotions. We train a generative network using an autoencoder
structure and input an emotion embedding vector to achieve the generation of
user-control expressions. Experimental results demonstrate that our method
outperforms existing state-of-the-art methods.

摘要：語音驅動的 3D 臉部動畫技術已經發展多年，
但其實際應用仍然未達預期。主要的挑戰在於資料限制、嘴唇對齊和臉部表情的自然度。
儘管嘴唇對齊已經有許多相關研究，現有方法仍難以合成自然且逼真的表情，導致臉部動畫呈現機械且僵硬的外觀。即使有些研究從語音中提取情緒特徵，但臉部動作的隨機性限制了情緒的有效表達。為了解決這個問題，本文提出一個名為 CSTalk（相關監督）的方法，它對臉部動作的不同區域之間的相關性進行建模，並監督生成模型的訓練，以生成符合人類臉部運動模式的逼真表情。為了產生更精細的動畫，我們採用基於超人類角色模型的豐富控制參數集，並擷取一個包含五種不同情緒的資料集。我們使用自編碼器結構訓練一個生成網路，並輸入情緒嵌入向量，以實現使用者控制表情的生成。實驗結果表明，我們的模型優於現有的最先進模型。

##### **FREB-TQA: A Fine-Grained Robustness Evaluation Benchmark for Table Question Answering**
2404.18585v1 by Wei Zhou,Mohsen Mesgar,Heike Adel,Annemarie Friedrich

Table Question Answering (TQA) aims at composing an answer to a question
based on tabular data. While prior research has shown that TQA models lack
robustness, understanding the underlying cause and nature of this issue remains
predominantly unclear, posing a significant obstacle to the development of
robust TQA systems. In this paper, we formalize three major desiderata for a
fine-grained evaluation of robustness of TQA systems. They should (i) answer
questions regardless of alterations in table structure, (ii) base their
responses on the content of relevant cells rather than on biases, and (iii)
demonstrate robust numerical reasoning capabilities. To investigate these
aspects, we create and publish a novel TQA evaluation benchmark in English. Our
extensive experimental analysis reveals that none of the examined
state-of-the-art TQA systems consistently excels in these three aspects. Our
benchmark is a crucial instrument for monitoring the behavior of TQA systems
and paves the way for the development of robust TQA systems. We release our
benchmark publicly.

摘要：表格問答 (TQA) 旨在根據表格資料撰寫問題的答案。雖然先前的研究顯示 TQA 模型缺乏穩健性，但了解此問題的根本原因和性質仍然主要不明確，這對穩健 TQA 系統的開發構成重大障礙。在本文中，我們正式制定了對 TQA 系統的穩健性進行細粒度評估的三個主要條件。它們應 (i) 不論表格結構如何變更都能回答問題，(ii) 將其回應建立在相關儲存格的內容上，而不是偏見，以及 (iii) 展示穩健的數值推理能力。為了調查這些面向，我們建立並發布了一個新穎的英文 TQA 評估基準。我們廣泛的實驗分析顯示，沒有任何已檢查的最先進 TQA 系統在這些三個面向都持續表現卓越。我們的基準是監控 TQA 系統行為的關鍵工具，並為穩健 TQA 系統的開發鋪路。我們公開發布我們的基準。

##### **Analyzing Semantic Change through Lexical Replacements**
2404.18570v1 by Francesco Periti,Pierluigi Cassotti,Haim Dubossarsky,Nina Tahmasebi

Modern language models are capable of contextualizing words based on their
surrounding context. However, this capability is often compromised due to
semantic change that leads to words being used in new, unexpected contexts not
encountered during pre-training. In this paper, we model \textit{semantic
change} by studying the effect of unexpected contexts introduced by
\textit{lexical replacements}. We propose a \textit{replacement schema} where a
target word is substituted with lexical replacements of varying relatedness,
thus simulating different kinds of semantic change. Furthermore, we leverage
the replacement schema as a basis for a novel \textit{interpretable} model for
semantic change. We are also the first to evaluate the use of LLaMa for
semantic change detection.

摘要：現代語言模型能夠根據周圍的語境對詞彙進行語境化。然而，由於語義變化導致詞彙在預訓練期間未遇到的新穎且意外的語境中使用，因此這種能力常常受到影響。在本文中，我們通過研究由詞彙替換引發的意外語境影響來建模語義變化。我們提出了一個替換模式，其中目標詞彙被不同相關性的詞彙替換替換，從而模擬不同類型的語義變化。此外，我們利用替換模式作為語義變化新穎的可解釋模型的基礎。我們也是第一個評估 LLaMa 在語義變化檢測中的使用。

##### **Injecting Salesperson's Dialogue Strategies in Large Language Models with Chain-of-Thought Reasoning**
2404.18564v1 by Wen-Yu Chang,Yun-Nung Chen

Recent research in dialogue systems and corpora has focused on two main
categories: task-oriented (TOD) and open-domain (chit-chat) dialogues. TOD
systems help users accomplish specific tasks, while open-domain systems aim to
create engaging conversations. However, in real-world scenarios, user intents
are often revealed during interactions. A recent study introduced SalesBot,
which simulates dialogues transitioning from chit-chat to task-oriented
scenarios to train sales agents. Unfortunately, the initial data lacked smooth
transitions and coherent long-turn dialogues, resulting in poor naturalness in
sales-customer interactions. To address these issues, this paper presents
SalesBot 2.0, an improved dataset. It leverages commonsense knowledge from
large language models (LLMs) through strategic prompting. Additionally, we
introduce a novel model called SalesAgent, trained on salesperson's
interactions, using chain-of-thought (CoT) reasoning. This model excels in
transitioning topics, understanding user intents, and selecting appropriate
strategies. Experiments using diverse user simulations validate the
effectiveness of our method in controlling dialogue strategies in LLMs.
Furthermore, SalesBot 2.0 enhances coherence and reduces aggression,
facilitating better model learning for sales-customer interactions.

摘要：最近對話系統和語料庫的研究主要集中在兩個範疇：任務導向 (TOD) 和開放領域 (閒聊) 對話。TOD 系統幫助使用者完成特定任務，而開放領域系統旨在建立引人入勝的對話。然而，在現實世界中，使用者意圖通常在互動過程中才會揭曉。最近的一項研究引入了 SalesBot，它模擬了從閒聊轉換到任務導向場景的對話，以訓練銷售代理。遺憾的是，初始資料缺乏流暢的轉換和連貫的長輪對話，導致銷售人員與客戶互動的自然度不佳。為了解決這些問題，本文提出了 SalesBot 2.0，一個改良的資料集。它透過策略提示，利用來自大型語言模型 (LLM) 的常識知識。此外，我們引入了一個名為 SalesAgent 的新模型，使用思想鏈 (CoT) 推理，在銷售人員的互動中進行訓練。此模型擅長轉換主題、理解使用者意圖，以及選擇適當的策略。使用多樣化使用者模擬的實驗驗證了我們的方法在控制 LLM 中對話策略的有效性。此外，SalesBot 2.0 增強了連貫性並減少了攻擊性，促進了銷售人員與客戶互動的模型學習。

##### **LangBiTe: A Platform for Testing Bias in Large Language Models**
2404.18558v1 by Sergio Morales,Robert Clarisó,Jordi Cabot

The integration of Large Language Models (LLMs) into various software
applications raises concerns about their potential biases. Typically, those
models are trained on a vast amount of data scrapped from forums, websites,
social media and other internet sources, which may instill harmful and
discriminating behavior into the model. To address this issue, we present
LangBiTe, a testing platform to systematically assess the presence of biases
within an LLM. LangBiTe enables development teams to tailor their test
scenarios, and automatically generate and execute the test cases according to a
set of user-defined ethical requirements. Each test consists of a prompt fed
into the LLM and a corresponding test oracle that scrutinizes the LLM's
response for the identification of biases. LangBite provides users with the
bias evaluation of LLMs, and end-to-end traceability between the initial
ethical requirements and the insights obtained.

摘要：大型語言模型 (LLM) 整合到各種軟體應用程式中，引發了人們對其潛在偏見的擔憂。通常，這些模型是根據從論壇、網站、社群媒體和其他網路來源中擷取的大量資料進行訓練，這可能會在模型中灌輸有害且具歧視性的行為。為了解決這個問題，我們提出了 LangBiTe，一個測試平台，用於系統性地評估 LLM 中偏見的存在。LangBiTe 使開發團隊能夠客製化他們的測試情境，並根據一組使用者定義的道德要求自動產生和執行測試案例。每個測試都包含一個輸入 LLM 的提示，以及一個對應的測試預言，用於審查 LLM 的回應，以識別偏見。LangBiTe 為使用者提供 LLM 的偏見評估，以及初始道德要求和獲得的見解之間的端對端可追溯性。

##### **Can GPT-4 do L2 analytic assessment?**
2404.18557v1 by Stefano Bannò,Hari Krishna Vydana,Kate M. Knill,Mark J. F. Gales

Automated essay scoring (AES) to evaluate second language (L2) proficiency
has been a firmly established technology used in educational contexts for
decades. Although holistic scoring has seen advancements in AES that match or
even exceed human performance, analytic scoring still encounters issues as it
inherits flaws and shortcomings from the human scoring process. The recent
introduction of large language models presents new opportunities for automating
the evaluation of specific aspects of L2 writing proficiency. In this paper, we
perform a series of experiments using GPT-4 in a zero-shot fashion on a
publicly available dataset annotated with holistic scores based on the Common
European Framework of Reference and aim to extract detailed information about
their underlying analytic components. We observe significant correlations
between the automatically predicted analytic scores and multiple features
associated with the individual proficiency components.

摘要：自動化論文評分 (AES) 用於評估第二語言 (L2) 能力，數十年來已成為教育環境中穩固確立的技術。儘管整體評分在 AES 中已見進展，可與人工評分表現相匹配甚至超越，但分析評分仍會遭遇問題，因其繼承了人工評分過程中的缺陷和不足。大型語言模型的近期引入為自動評估 L2 寫作能力的特定面向提供了新的契機。在本文中，我們針對一個公開可用的資料集進行一系列使用 GPT-4 的零次學習實驗，該資料集根據歐洲共同參考架構標註了整體評分，旨在萃取其底層分析組成的詳細資訊。我們觀察到自動預測的分析評分與與個別能力組成相關的多項特徵之間有顯著相關性。

##### **Evaluating the effectiveness of predicting covariates in LSTM Networks for Time Series Forecasting**
2404.18553v1 by Gareth Davies

Autoregressive Recurrent Neural Networks are widely employed in time-series
forecasting tasks, demonstrating effectiveness in univariate and certain
multivariate scenarios. However, their inherent structure does not readily
accommodate the integration of future, time-dependent covariates. A proposed
solution, outlined by Salinas et al 2019, suggests forecasting both covariates
and the target variable in a multivariate framework. In this study, we
conducted comprehensive tests on publicly available time-series datasets,
artificially introducing highly correlated covariates to future time-step
values. Our evaluation aimed to assess the performance of an LSTM network when
considering these covariates and compare it against a univariate baseline. As
part of this study we introduce a novel approach using seasonal time segments
in combination with an RNN architecture, which is both simple and extremely
effective over long forecast horizons with comparable performance to many state
of the art architectures. Our findings from the results of more than 120 models
reveal that under certain conditions jointly training covariates with target
variables can improve overall performance of the model, but often there exists
a significant performance disparity between multivariate and univariate
predictions. Surprisingly, even when provided with covariates informing the
network about future target values, multivariate predictions exhibited inferior
performance. In essence, compelling the network to predict multiple values can
prove detrimental to model performance, even in the presence of informative
covariates. These results suggest that LSTM architectures may not be suitable
for forecasting tasks where predicting covariates would typically be expected
to enhance model accuracy.

摘要：自迴歸遞迴神經網路廣泛用於時間序列預測任務，證明在單變量和某些多變量場景中具有有效性。然而，它們的內部結構並未輕易容納未來與時間相關的協變數的整合。Salinas 等人在 2019 年概述的建議解決方案，建議在多變量架構中預測協變數和目標變數。在此研究中，我們對公開的時間序列資料集進行了全面的測試，人為地將高度相關的協變數引入未來的時間步驟值。我們的評估旨在評估 LSTM 網路在考慮這些協變數時的效能，並將其與單變量基準進行比較。作為此研究的一部分，我們引入了一種新穎的方法，將季節性時間區段與 RNN 架構結合使用，這種方法既簡單又極其有效，在與許多最先進的架構相當的效能下，擁有較長的預測範圍。我們從 120 多個模型的結果中發現，在某些條件下，協變數與目標變數的聯合訓練可以改善模型的整體效能，但多變量和單變量預測之間通常存在顯著的效能差異。令人驚訝的是，即使在提供了告知網路未來目標值的協變數時，多變量預測仍表現出較差的效能。實質上，強迫網路預測多個值可能會損害模型效能，即使在存在有意義的協變數的情況下也是如此。這些結果表明，LSTM 架構可能不適合於預測任務，在這種任務中，預測協變數通常預期會提高模型準確度。

##### **SIDBench: A Python Framework for Reliably Assessing Synthetic Image Detection Methods**
2404.18552v1 by Manos Schinas,Symeon Papadopoulos

The generative AI technology offers an increasing variety of tools for
generating entirely synthetic images that are increasingly indistinguishable
from real ones. Unlike methods that alter portions of an image, the creation of
completely synthetic images presents a unique challenge and several Synthetic
Image Detection (SID) methods have recently appeared to tackle it. Yet, there
is often a large gap between experimental results on benchmark datasets and the
performance of methods in the wild. To better address the evaluation needs of
SID and help close this gap, this paper introduces a benchmarking framework
that integrates several state-of-the-art SID models. Our selection of
integrated models was based on the utilization of varied input features, and
different network architectures, aiming to encompass a broad spectrum of
techniques. The framework leverages recent datasets with a diverse set of
generative models, high level of photo-realism and resolution, reflecting the
rapid improvements in image synthesis technology. Additionally, the framework
enables the study of how image transformations, common in assets shared online,
such as JPEG compression, affect detection performance. SIDBench is available
on https://github.com/mever-team/sidbench and is designed in a modular manner
to enable easy inclusion of new datasets and SID models.

摘要：生成式 AI 技術提供越來越多樣的工具，用來生成完全合成的影像，這些影像與真實影像越來越難以區分。與改變影像部分區域的方法不同，完全合成影像的建立提出獨特的挑戰，且最近出現多種合成影像偵測 (SID) 方法來解決此問題。然而，基準資料集的實驗結果與方法在實際應用中的效能之間，通常存在很大的差距。為了更妥善地滿足 SID 的評估需求，並協助縮小此差距，本文介紹一個整合多種最先進 SID 模型的基準架構。我們選擇整合的模型，是根據使用不同的輸入特徵，以及不同的網路架構，目標是涵蓋廣泛的技術。此架構利用最近的資料集，其中包含多樣化的生成模型、高階寫實主義與解析度，反映影像合成技術的快速進步。此外，此架構能研究影像轉換（例如 JPEG 壓縮）在網路上分享資產時很常見，如何影響偵測效能。SIDBench 可在 https://github.com/mever-team/sidbench 取得，並以模組化方式設計，以便輕鬆納入新的資料集與 SID 模型。

##### **Time Machine GPT**
2404.18543v1 by Felix Drinkall,Eghbal Rahimikia,Janet B. Pierrehumbert,Stefan Zohren

Large language models (LLMs) are often trained on extensive, temporally
indiscriminate text corpora, reflecting the lack of datasets with temporal
metadata. This approach is not aligned with the evolving nature of language.
Conventional methods for creating temporally adapted language models often
depend on further pre-training static models on time-specific data. This paper
presents a new approach: a series of point-in-time LLMs called Time Machine GPT
(TiMaGPT), specifically designed to be nonprognosticative. This ensures they
remain uninformed about future factual information and linguistic changes. This
strategy is beneficial for understanding language evolution and is of critical
importance when applying models in dynamic contexts, such as time-series
forecasting, where foresight of future information can prove problematic. We
provide access to both the models and training datasets.

摘要：大型語言模型 (LLM) 通常在廣泛且在時間上不加區分的文本語料庫上進行訓練，這反映了缺乏具有時間元數據的資料集。這種方法與語言的演化性質不符。建立時間適應語言模型的傳統方法通常依賴於在特定時間的資料上進一步預訓練靜態模型。本文提出了一種新方法：一系列稱為時光機 GPT (TiMaGPT) 的時間點 LLM，專門設計為非預測性的。這確保了它們對未來的實際資訊和語言變化保持不知情。這種策略有助於理解語言演化，並且在動態環境中應用模型時至關重要，例如時間序列預測，其中對未來資訊的前瞻性可能會造成問題。我們提供對模型和訓練資料集的存取。

##### **Enhancing Boundary Segmentation for Topological Accuracy with Skeleton-based Methods**
2404.18539v1 by Chuni Liu,Boyuan Ma,Xiaojuan Ban,Yujie Xie,Hao Wang,Weihua Xue,Jingchao Ma,Ke Xu

Topological consistency plays a crucial role in the task of boundary
segmentation for reticular images, such as cell membrane segmentation in neuron
electron microscopic images, grain boundary segmentation in material
microscopic images and road segmentation in aerial images. In these fields,
topological changes in segmentation results have a serious impact on the
downstream tasks, which can even exceed the misalignment of the boundary
itself. To enhance the topology accuracy in segmentation results, we propose
the Skea-Topo Aware loss, which is a novel loss function that takes into
account the shape of each object and topological significance of the pixels. It
consists of two components. First, the skeleton-aware weighted loss improves
the segmentation accuracy by better modeling the object geometry with
skeletons. Second, a boundary rectified term effectively identifies and
emphasizes topological critical pixels in the prediction errors using both
foreground and background skeletons in the ground truth and predictions.
Experiments prove that our method improves topological consistency by up to 7
points in VI compared to 13 state-of-art methods, based on objective and
subjective assessments across three different boundary segmentation datasets.
The code is available at https://github.com/clovermini/Skea_topo.

摘要：拓撲一致性在網狀影像的邊界分割任務中扮演著至關重要的角色，例如神經元電子顯微鏡影像中的細胞膜分割、材料顯微鏡影像中的晶界分割，以及航照影像中的道路分割。在這些領域中，分割結果的拓撲變化會對下游任務造成嚴重的影響，甚至會超過邊界本身的不對齊。為了提升分割結果的拓撲精確度，我們提出了 Skea-Topo Aware 損失，這是一種新穎的損失函數，它考慮了每個物件的形狀和像素的拓撲意義。它包含兩個組成部分。首先，骨架感知加權損失透過使用骨架更好地建模物件幾何，來提升分割精確度。其次，邊界校正項有效地識別並強調預測誤差中拓撲臨界像素，同時使用真實值和預測中的前景和背景骨架。實驗證明，與 13 種最先進的方法相比，我們的模型在 VI 中將拓撲一致性提升了多達 7 個百分點，這是根據三個不同的邊界分割資料集的客觀和主觀評估得出的。程式碼可在 https://github.com/clovermini/Skea_topo 取得。

##### **Evaluating and Mitigating Linguistic Discrimination in Large Language Models**
2404.18534v1 by Guoliang Dong,Haoyu Wang,Jun Sun,Xinyu Wang

By training on text in various languages, large language models (LLMs)
typically possess multilingual support and demonstrate remarkable capabilities
in solving tasks described in different languages. However, LLMs can exhibit
linguistic discrimination due to the uneven distribution of training data
across languages. That is, LLMs are hard to keep the consistency of responses
when faced with the same task but depicted in different languages.
  In this study, we first explore the consistency in the LLMs' outputs
responding to queries in various languages from two aspects: safety and
quality. We conduct this analysis with two datasets (AdvBench and NQ) based on
four LLMs (Llama2-13b, Gemma-7b, GPT-3.5-turbo and Gemini-pro). The results
show that LLMs exhibit stronger human alignment capabilities with queries in
English, French, Russian, and Spanish (only 1.04\% of harmful queries
successfully jailbreak on average) compared to queries in Bengali, Georgian,
Nepali and Maithili (27.7\% of harmful queries jailbreak successfully on
average). Moreover, for queries in English, Danish, Czech and Slovenian, LLMs
tend to produce responses with a higher quality (with 0.1494 $F_1$ score on
average) compared to the other languages. Upon these findings, we propose
LDFighter, a similarity-based voting, to mitigate the linguistic discrimination
in LLMs. LDFighter ensures consistent service for different language speakers.
We evaluate LDFighter with both benign queries and harmful queries. The results
show that LDFighter not only significantly reduces the jailbreak success rate
but also improve the response quality on average, demonstrating its
effectiveness.

摘要：<paragraph>大型語言模型 (LLM) 透過訓練各種語言的文字，通常具備多語言支援，並展現解決以不同語言描述任務的卓越能力。然而，LLM 會因訓練資料在各語言中的分佈不均而出現語言歧視。也就是說，LLM 在面對相同任務時，但以不同語言描述時，難以保持回應的一致性。本研究首先從安全性和品質兩個面向探討 LLM 回應不同語言查詢時輸出的相容性。我們針對四個 LLM（Llama2-13b、Gemma-7b、GPT-3.5-turbo 和 Gemini-pro）使用兩個資料集（AdvBench 和 NQ）進行分析。結果顯示，LLM 對英語、法語、俄語和西班牙語查詢展現較強的人類對齊能力（平均僅 1.04% 的有害查詢成功越獄），相較於孟加拉語、喬治亞語、尼泊爾語和邁蒂利語（平均 27.7% 的有害查詢成功越獄）。此外，對於英語、丹麥語、捷克語和斯洛維尼亞語查詢，LLM 傾向產生品質較高的回應（平均 0.1494 $F_1$ 分數），相較於其他語言。根據這些發現，我們提出基於相似性的投票機制 LDFighter，以減輕 LLM 中的語言歧視。LDFighter 可確保為不同語言使用者提供一致的服務。我們使用良性查詢和有害查詢評估 LDFighter。結果顯示，LDFighter 不僅顯著降低越獄成功率，也平均提升回應品質，證明其有效性。</paragraph>

##### **Evaluating Readability and Faithfulness of Concept-based Explanations**
2404.18533v1 by Meng Li,Haoran Jin,Ruixuan Huang,Zhihao Xu,Defu Lian,Zijia Lin,Di Zhang,Xiting Wang

Despite the surprisingly high intelligence exhibited by Large Language Models
(LLMs), we are somehow intimidated to fully deploy them into real-life
applications considering their black-box nature. Concept-based explanations
arise as a promising avenue for explaining what the LLMs have learned, making
them more transparent to humans. However, current evaluations for concepts tend
to be heuristic and non-deterministic, e.g. case study or human evaluation,
hindering the development of the field. To bridge the gap, we approach
concept-based explanation evaluation via faithfulness and readability. We first
introduce a formal definition of concept generalizable to diverse concept-based
explanations. Based on this, we quantify faithfulness via the difference in the
output upon perturbation. We then provide an automatic measure for readability,
by measuring the coherence of patterns that maximally activate a concept. This
measure serves as a cost-effective and reliable substitute for human
evaluation. Finally, based on measurement theory, we describe a meta-evaluation
method for evaluating the above measures via reliability and validity, which
can be generalized to other tasks as well. Extensive experimental analysis has
been conducted to validate and inform the selection of concept evaluation
measures.

摘要：儘管大型語言模型 (LLM) 展現了驚人的高智慧，但我們在將它們完全部署到實際應用中時，卻因其黑箱本質而感到有些恐懼。基於概念的解釋作為一種有前途的方法出現，用於解釋 LLM 學到了什麼，讓它們對人類來說更加透明。然而，當前對概念的評估往往是啟發式的且非確定性的，例如個案研究或人類評估，這阻礙了該領域的發展。為了彌補這一差距，我們透過忠實度和可讀性來探討基於概念的解釋評估。我們首先引入一個概念的形式定義，該定義可以推廣到各種基於概念的解釋。基於此，我們透過擾動時的輸出差異來量化忠實度。然後，我們提供一個自動的可讀性測量，透過測量最大程度激活概念的模式的相干性。此測量作為人類評估的一種經濟有效且可靠的替代方案。最後，基於測量理論，我們描述了一種元評估方法，透過信度和效度評估上述測量，這也可以推廣到其他任務。已經進行了廣泛的實驗分析，以驗證和告知概念評估測量的選擇。

##### **MileBench: Benchmarking MLLMs in Long Context**
2404.18532v1 by Dingjie Song,Shunian Chen,Guiming Hardy Chen,Fei Yu,Xiang Wan,Benyou Wang

Despite the advancements and impressive performance of Multimodal Large
Language Models (MLLMs) on benchmarks, their effectiveness in real-world,
long-context, and multi-image tasks is unclear due to the benchmarks' limited
scope. Existing benchmarks often focus on single-image and short-text samples,
and when assessing multi-image tasks, they either limit the image count or
focus on specific task (e.g time-series captioning), potentially obscuring the
performance challenges of MLLMs. To address these limitations, we introduce
MileBench, a pioneering benchmark designed to test the MultImodal Long-contExt
capabilities of MLLMs. This benchmark comprises not only multimodal long
contexts, but also multiple tasks requiring both comprehension and generation.
We establish two distinct evaluation sets, diagnostic and realistic, to
systematically assess MLLMs' long-context adaptation capacity and their ability
to complete tasks in long-context scenarios. Our experimental results, obtained
from testing 20 models, revealed that while the closed-source GPT-4(Vision) and
Gemini 1.5 outperform others, most open-source MLLMs struggle in long-context
situations. Interestingly, the performance gap tends to widen with an increase
in the number of images. We strongly encourage an intensification of research
efforts towards enhancing MLLMs' long-context capabilities, especially in
scenarios involving multiple images.

摘要：儘管多模態大型語言模型 (MLLM) 在基準測試中表現優異且進步神速，但由於基準測試的範圍有限，它們在真實世界、長語境和多圖像任務中的有效性仍不清楚。現有的基準測試通常側重於單一圖像和短文本範例，並且在評估多圖像任務時，它們會限制圖像數量或專注於特定任務（例如時間序列標題），這可能會模糊 MLLM 的效能挑戰。為了解決這些限制，我們引入了 MileBench，這是一個先驅基準測試，旨在測試 MLLM 的多模態長語境能力。此基準測試不僅包含多模態長語境，還包含需要理解和生成的各種任務。我們建立了兩個不同的評估集（診斷和實際），以系統地評估 MLLM 的長語境適應能力以及它們在長語境場景中完成任務的能力。我們從測試 20 個模型中獲得的實驗結果顯示，雖然閉源 GPT-4(Vision) 和 Gemini 1.5 優於其他模型，但大多數開源 MLLM 在長語境情況下表現不佳。有趣的是，效能差距會隨著圖像數量的增加而擴大。我們強烈鼓勵加強研究工作，以增強 MLLM 的長語境能力，特別是在涉及多張圖像的場景中。

##### **A Framework to Model ML Engineering Processes**
2404.18531v1 by Sergio Morales,Robert Clarisó,Jordi Cabot

The development of Machine Learning (ML) based systems is complex and
requires multidisciplinary teams with diverse skill sets. This may lead to
communication issues or misapplication of best practices. Process models can
alleviate these challenges by standardizing task orchestration, providing a
common language to facilitate communication, and nurturing a collaborative
environment. Unfortunately, current process modeling languages are not suitable
for describing the development of such systems. In this paper, we introduce a
framework for modeling ML-based software development processes, built around a
domain-specific language and derived from an analysis of scientific and gray
literature. A supporting toolkit is also available.

摘要：機器學習 (ML) 為基礎的系統開發複雜且需要具備多元技能的多領域團隊。這可能會導致溝通問題或最佳實務的錯誤應用。流程模型可透過標準化任務編排、提供一種促進溝通的共同語言，以及培養協作環境來緩解這些挑戰。遺憾的是，目前的流程建模語言並不適合用來描述此類系統的開發。在本文中，我們介紹了一個用於建模基於 ML 的軟體開發流程的架構，其建構於一個特定領域的語言，並源自對科學和灰色文獻的分析。還提供了一個支援工具包。

##### **Bridging Data Barriers among Participants: Assessing the Potential of Geoenergy through Federated Learning**
2404.18527v1 by Weike Peng,Jiaxin Gao,Yuntian Chen,Shengwei Wang

Machine learning algorithms emerge as a promising approach in energy fields,
but its practical is hindered by data barriers, stemming from high collection
costs and privacy concerns. This study introduces a novel federated learning
(FL) framework based on XGBoost models, enabling safe collaborative modeling
with accessible yet concealed data from multiple parties. Hyperparameter tuning
of the models is achieved through Bayesian Optimization. To ascertain the
merits of the proposed FL-XGBoost method, a comparative analysis is conducted
between separate and centralized models to address a classical binary
classification problem in geoenergy sector. The results reveal that the
proposed FL framework strikes an optimal balance between privacy and accuracy.
FL models demonstrate superior accuracy and generalization capabilities
compared to separate models, particularly for participants with limited data or
low correlation features and offers significant privacy benefits compared to
centralized model. The aggregated optimization approach within the FL agreement
proves effective in tuning hyperparameters. This study opens new avenues for
assessing unconventional reservoirs through collaborative and
privacy-preserving FL techniques.

摘要：機器學習演算法在能源領域中，作為一種有前景的方法出現，
但其實務受到資料障礙的阻礙，這源自於高昂的收集成本和隱私問題。本研究提出一個新的聯邦學習 (FL) 架構，它基於 XGBoost 模型，透過取得多方可存取但隱藏的資料，實現安全的協作建模。模型的超參數調整是透過貝氏最佳化來達成。為了確認所提出的 FL-XGBoost 方法的優點，在不同的和集中式模型之間進行比較分析，以解決地熱能領域中的經典二元分類問題。結果顯示，所提出的 FL 架構在隱私和準確性之間取得最佳平衡。與不同的模型相比，FL 模型展現出優異的準確性和概化能力，特別是對於資料有限或關聯性特徵較低的參與者，並且與集中式模型相比，提供了顯著的隱私優勢。FL 協議中的聚合最佳化方法，證明了在調整超參數時是有效的。本研究為透過協作和隱私保護的 FL 技術評估非常規儲層，開啟了新的途徑。

##### **On the Impact of Data Heterogeneity in Federated Learning Environments with Application to Healthcare Networks**
2404.18519v1 by Usevalad Milasheuski. Luca Barbieri,Bernardo Camajori Tedeschini,Monica Nicoli,Stefano Savazzi

Federated Learning (FL) allows multiple privacy-sensitive applications to
leverage their dataset for a global model construction without any disclosure
of the information. One of those domains is healthcare, where groups of silos
collaborate in order to generate a global predictor with improved accuracy and
generalization. However, the inherent challenge lies in the high heterogeneity
of medical data, necessitating sophisticated techniques for assessment and
compensation. This paper presents a comprehensive exploration of the
mathematical formalization and taxonomy of heterogeneity within FL
environments, focusing on the intricacies of medical data. In particular, we
address the evaluation and comparison of the most popular FL algorithms with
respect to their ability to cope with quantity-based, feature and label
distribution-based heterogeneity. The goal is to provide a quantitative
evaluation of the impact of data heterogeneity in FL systems for healthcare
networks as well as a guideline on FL algorithm selection. Our research extends
beyond existing studies by benchmarking seven of the most common FL algorithms
against the unique challenges posed by medical data use cases. The paper
targets the prediction of the risk of stroke recurrence through a set of
tabular clinical reports collected by different federated hospital silos: data
heterogeneity frequently encountered in this scenario and its impact on FL
performance are discussed.

摘要：聯邦學習 (FL) 允許多個注重隱私的應用程式利用其資料集來建構全球模型，而無需公開資訊。其中一個領域是醫療保健，其中孤島群組會合作以產生具有改進準確度和概括性的全球預測器。然而，其內在挑戰在於醫療資料的高度異質性，需要複雜的技術來進行評估和補償。本文全面探討了 FL 環境中異質性的數學形式化和分類，重點在於醫療資料的複雜性。特別是，我們針對最熱門的 FL 演算法進行評估和比較，以了解其因應基於數量、特徵和標籤分佈的異質性的能力。目標是提供 FL 系統中資料異質性對醫療保健網路影響的量化評估，以及 FL 演算法選擇的準則。我們的研究擴展到現有研究，針對醫療資料使用案例提出的獨特挑戰對七種最常見的 FL 演算法進行基準測試。本文針對由不同聯邦醫院孤島收集的一組表格臨床報告來預測中風復發的風險：此情境中經常遇到的資料異質性及其對 FL 性能的影響將會有所探討。

##### **From ChatGPT, DALL-E 3 to Sora: How has Generative AI Changed Digital Humanities Research and Services?**
2404.18518v1 by Jiangfeng Liu,Ziyi Wang,Jing Xie,Lei Pei

Generative large-scale language models create the fifth paradigm of
scientific research, organically combine data science and computational
intelligence, transform the research paradigm of natural language processing
and multimodal information processing, promote the new trend of AI-enabled
social science research, and provide new ideas for digital humanities research
and application. This article profoundly explores the application of
large-scale language models in digital humanities research, revealing their
significant potential in ancient book protection, intelligent processing, and
academic innovation. The article first outlines the importance of ancient book
resources and the necessity of digital preservation, followed by a detailed
introduction to developing large-scale language models, such as ChatGPT, and
their applications in document management, content understanding, and
cross-cultural research. Through specific cases, the article demonstrates how
AI can assist in the organization, classification, and content generation of
ancient books. Then, it explores the prospects of AI applications in artistic
innovation and cultural heritage preservation. Finally, the article explores
the challenges and opportunities in the interaction of technology, information,
and society in the digital humanities triggered by AI technologies.

摘要：生成式大规模语言模型创造了科学研究的第五范式，有机地结合了数据科学和计算智能，转变了自然语言处理和多模态信息处理的研究范式，促进了人工智能驱动的社会科学研究的新趋势，并为数字人文研究和应用提供了新思路。本文深刻探讨了大规模语言模型在数字人文研究中的应用，揭示了它们在古籍保护、智能处理和学术创新方面的巨大潜力。文章首先概述了古籍资源的重要性以及数字化保存的必要性，然后详细介绍了大规模语言模型（如 ChatGPT）的开发及其在文档管理、内容理解和跨文化研究中的应用。通过具体案例，文章展示了人工智能如何协助古籍的组织、分类和内容生成。然后，它探讨了人工智能应用在艺术创新和文化遗产保护中的前景。最后，文章探讨了人工智能技术引发的数字人文领域中技术、信息和社会相互作用中的挑战和机遇。

##### **Explainability of Machine Learning Approaches in Forensic Linguistics: A Case Study in Geolinguistic Authorship Profiling**
2404.18510v1 by Dana Roemling,Yves Scherrer,Aleksandra Miletic

Forensic authorship profiling uses linguistic markers to infer
characteristics about an author of a text. This task is paralleled in dialect
classification, where a prediction is made about the linguistic variety of a
text based on the text itself. While there have been significant advances in
the last years in variety classification (Jauhiainen et al., 2019) and
state-of-the-art approaches reach accuracies of up to 100% depending on the
similarity of varieties and the scope of prediction (e.g., Milne et al., 2012;
Blodgett et al., 2017), forensic linguistics rarely relies on these approaches
due to their lack of transparency (see Nini, 2023), amongst other reasons. In
this paper we therefore explore explainability of machine learning approaches
considering the forensic context. We focus on variety classification as a means
of geolinguistic profiling of unknown texts. For this we work with an approach
proposed by Xie et al. (2024) to extract the lexical items most relevant to the
variety classifications. We find that the extracted lexical features are indeed
representative of their respective varieties and note that the trained models
also rely on place names for classifications.

摘要：法醫作者分析使用語言標記來推斷文字作者的特徵。此任務與方言分類類似，其中根據文字本身對文字的語言變體進行預測。儘管在過去幾年方言分類（Jauhiainen 等人，2019 年）方面取得了重大進展，並且最先進的方法可以根據變體的相似性和預測範圍（例如 Milne 等人，2012 年；Blodgett 等人，2017 年）達到高達 100% 的準確度，但由於缺乏透明度（見 Nini，2023 年），法醫語言學很少依賴這些方法。因此，在本文中，我們探討了考慮法醫背景的機器學習方法的可解釋性。我們專注於方言分類作為對未知文字進行地理語言分析的一種手段。為此，我們採用 Xie 等人 (2024) 提出的一種方法來提取與方言分類最相關的詞彙項目。我們發現提取的詞彙特徵確實代表了它們各自的變體，並注意到訓練模型也依賴於地名進行分類。

##### **Scalable Event-by-event Processing of Neuromorphic Sensory Signals With Deep State-Space Models**
2404.18508v1 by Mark Schöne,Neeraj Mohan Sushma,Jingyue Zhuge,Christian Mayr,Anand Subramoney,David Kappel

Event-based sensors are well suited for real-time processing due to their
fast response times and encoding of the sensory data as successive temporal
differences. These and other valuable properties, such as a high dynamic range,
are suppressed when the data is converted to a frame-based format. However,
most current methods either collapse events into frames or cannot scale up when
processing the event data directly event-by-event. In this work, we address the
key challenges of scaling up event-by-event modeling of the long event streams
emitted by such sensors, which is a particularly relevant problem for
neuromorphic computing. While prior methods can process up to a few thousand
time steps, our model, based on modern recurrent deep state-space models,
scales to event streams of millions of events for both training and
inference.We leverage their stable parameterization for learning long-range
dependencies, parallelizability along the sequence dimension, and their ability
to integrate asynchronous events effectively to scale them up to long event
streams.We further augment these with novel event-centric techniques enabling
our model to match or beat the state-of-the-art performance on several event
stream benchmarks. In the Spiking Speech Commands task, we improve
state-of-the-art by a large margin of 6.6% to 87.1%. On the DVS128-Gestures
dataset, we achieve competitive results without using frames or convolutional
neural networks. Our work demonstrates, for the first time, that it is possible
to use fully event-based processing with purely recurrent networks to achieve
state-of-the-art task performance in several event-based benchmarks.

摘要：<paragraph>由於事件感測器反應時間快，且會將感測資料編碼為連續時間差，因此非常適合用於即時處理。當資料轉換為基於幀的格式時，這些和其他有價值的特性（例如高動態範圍）就會被抑制。然而，目前大多數方法會將事件壓縮到幀中，或在直接逐一處理事件資料時無法擴充。在這項工作中，我們解決了逐一擴充事件流建模的主要挑戰，這些事件流是由此類感測器發出的，這對於神經形態運算是一個特別相關的問題。雖然先前的許多方法可以處理數千個時間步驟，但我們基於現代遞迴深度狀態空間模型的模型，可以擴充到數百萬個事件的事件流，用於訓練和推理。我們利用其穩定的參數化來學習長程依賴性、序列維度的並行性，以及有效整合非同步事件的能力，以將其擴充到長事件流。我們進一步使用新穎的以事件為中心的技術來擴充這些模型，使我們的模型能夠在多個事件流基準測試中匹配或超越最先進的效能。在 Spiking Speech Commands 任務中，我們將最先進的技術大幅提升了 6.6% 至 87.1%。在 DVS128-Gestures 資料集上，我們在不使用幀或卷積神經網路的情況下，達到了競爭力的結果。我們的這項工作首次證明，可以使用純遞迴網路進行完全基於事件的處理，在多個基於事件的基準測試中達成最先進的任務效能。</paragraph>

##### **ECC Analyzer: Extract Trading Signal from Earnings Conference Calls using Large Language Model for Stock Performance Prediction**
2404.18470v1 by Yupeng Cao,Zhi Chen,Qingyun Pei,Prashant Kumar,K. P. Subbalakshmi,Papa Momar Ndiaye

In the realm of financial analytics, leveraging unstructured data, such as
earnings conference calls (ECCs), to forecast stock performance is a critical
challenge that has attracted both academics and investors. While previous
studies have used deep learning-based models to obtain a general view of ECCs,
they often fail to capture detailed, complex information. Our study introduces
a novel framework: \textbf{ECC Analyzer}, combining Large Language Models
(LLMs) and multi-modal techniques to extract richer, more predictive insights.
The model begins by summarizing the transcript's structure and analyzing the
speakers' mode and confidence level by detecting variations in tone and pitch
for audio. This analysis helps investors form an overview perception of the
ECCs. Moreover, this model uses the Retrieval-Augmented Generation (RAG) based
methods to meticulously extract the focuses that have a significant impact on
stock performance from an expert's perspective, providing a more targeted
analysis. The model goes a step further by enriching these extracted focuses
with additional layers of analysis, such as sentiment and audio segment
features. By integrating these insights, the ECC Analyzer performs multi-task
predictions of stock performance, including volatility, value-at-risk (VaR),
and return for different intervals. The results show that our model outperforms
traditional analytic benchmarks, confirming the effectiveness of using advanced
LLM techniques in financial analytics.

摘要：在金融分析領域中，利用非結構化數據（例如收益會議電話 (ECC)）來預測股票表現是一項關鍵挑戰，吸引了學者和投資者。雖然先前的研究已使用基於深度學習的模型來獲得 ECC 的一般觀點，但它們通常無法擷取詳細且複雜的資訊。我們的研究引入了一個新框架：**ECC 分析器**，結合大型語言模型 (LLM) 和多模態技術，以提取更豐富、更具預測性的見解。該模型首先總結轉錄的結構，並透過偵測音調和音高的變化來分析說話者的模式和信心等級。此分析有助於投資者對 ECC 形成概觀認知。此外，此模型使用基於檢索增強生成 (RAG) 的方法，從專家的角度細緻地提取對股票表現有重大影響的重點，提供更具針對性的分析。該模型進一步透過豐富這些提取的重點，例如情緒和音訊片段特徵，來更進一步。透過整合這些見解，ECC 分析器執行股票表現的多任務預測，包括波動性、風險價值 (VaR) 和不同區間的報酬。結果顯示，我們的模型優於傳統的分析基準，證實了在金融分析中使用先進 LLM 技術的有效性。

##### **HFT: Half Fine-Tuning for Large Language Models**
2404.18466v1 by Tingfeng Hui,Zhenyu Zhang,Shuohuan Wang,Weiran Xu,Yu Sun,Hua Wu

Large language models (LLMs) with one or more fine-tuning phases have become
a necessary step to unlock various capabilities, enabling LLMs to follow
natural language instructions or align with human preferences. However, it
carries the risk of catastrophic forgetting during sequential training, the
parametric knowledge or the ability learned in previous stages may be
overwhelmed by incoming training data. In this paper, we find that by regularly
resetting partial parameters, LLMs can restore some of the original knowledge.
Inspired by this, we introduce Half Fine-Tuning (HFT) for LLMs, as a substitute
for full fine-tuning (FFT), to mitigate the forgetting issues, where half of
the parameters are selected to learn new tasks while the other half are frozen
to remain previous knowledge. We provide a feasibility analysis from the
perspective of optimization and interpret the parameter selection operation as
a regularization term. Without changing the model architecture, HFT could be
seamlessly integrated into existing fine-tuning frameworks. Extensive
experiments and analysis on supervised fine-tuning, direct preference
optimization, and continual learning consistently demonstrate the
effectiveness, robustness, and efficiency of HFT. Compared with FFT, HFT not
only significantly alleviates the forgetting problem, but also achieves the
best performance in a series of downstream benchmarks, with an approximately
30% reduction in training time.

摘要：大型語言模型 (LLM) 搭配一個或多個微調階段已成為解鎖各種功能的必要步驟，使 LLM 能夠遵循自然語言指令或與人類偏好保持一致。然而，在順序訓練期間，它有災難性遺忘的風險，在先前階段學習到的參數知識或能力可能會被輸入的訓練資料淹沒。在本文中，我們發現透過定期重設部分參數，LLM 可以恢復部分原始知識。受此啟發，我們為 LLM 引入了半微調 (HFT)，作為完全微調 (FFT) 的替代方案，以減輕遺忘問題，其中一半參數被選來學習新任務，而另一半則凍結以保留先前的知識。我們從最佳化的角度提供了可行性分析，並將參數選擇操作解釋為正則化項。在不改變模型架構的情況下，HFT 可以無縫整合到現有的微調框架中。對監督式微調、直接偏好最佳化和持續學習的廣泛實驗和分析一致地證明了 HFT 的有效性、穩健性和效率。與 FFT 相比，HFT 不僅顯著緩解了遺忘問題，而且在一系列下游基準測試中取得了最佳效能，訓練時間減少了約 30%。

##### **M3oE: Multi-Domain Multi-Task Mixture-of Experts Recommendation Framework**
2404.18465v1 by Zijian Zhang,Shuchang Liu,Jiaao Yu,Qingpeng Cai,Xiangyu Zhao,Chunxu Zhang,Ziru Liu,Qidong Liu,Hongwei Zhao,Lantao Hu,Peng Jiang,Kun Gai

Multi-domain recommendation and multi-task recommendation have demonstrated
their effectiveness in leveraging common information from different domains and
objectives for comprehensive user modeling. Nonetheless, the practical
recommendation usually faces multiple domains and tasks simultaneously, which
cannot be well-addressed by current methods. To this end, we introduce M3oE, an
adaptive multi-domain multi-task mixture-of-experts recommendation framework.
M3oE integrates multi-domain information, maps knowledge across domains and
tasks, and optimizes multiple objectives. We leverage three mixture-of-experts
modules to learn common, domain-aspect, and task-aspect user preferences
respectively to address the complex dependencies among multiple domains and
tasks in a disentangled manner. Additionally, we design a two-level fusion
mechanism for precise control over feature extraction and fusion across diverse
domains and tasks. The framework's adaptability is further enhanced by applying
AutoML technique, which allows dynamic structure optimization. To the best of
the authors' knowledge, our M3oE is the first effort to solve multi-domain
multi-task recommendation self-adaptively. Extensive experiments on two
benchmark datasets against diverse baselines demonstrate M3oE's superior
performance. The implementation code is available to ensure reproducibility.

摘要：多領域推薦和多任務推薦已被證明有效利用來自不同領域和目標的共同資訊進行全面使用者建模。儘管如此，實際推薦通常同時面對多個領域和任務，這無法透過目前的辦法妥善解決。為此，我們引進 M3oE，一種適應性多領域多任務專家混合推薦架構。M3oE 整合多領域資訊、對跨領域和任務的知識進行對應，並最佳化多重目標。我們利用三個專家混合模組分別學習共用的、領域面向和任務面向的使用者偏好，以解開多個領域和任務之間的複雜依存關係。此外，我們設計一個兩層級融合機制，精準控制跨不同領域和任務的特徵萃取和融合。透過套用 AutoML 技術，進一步提升架構的適應性，這允許動態結構最佳化。根據作者的了解，我們的 M3oE 是第一個努力以自適應方式解決多領域多任務推薦的方法。針對兩個基準資料集進行的廣泛實驗，對照不同的基準，證明了 M3oE 的優異效能。實作程式碼可供取得，以確保可重製性。

##### **Ethical Reasoning and Moral Value Alignment of LLMs Depend on the Language we Prompt them in**
2404.18460v1 by Utkarsh Agarwal,Kumar Tanmay,Aditi Khandelwal,Monojit Choudhury

Ethical reasoning is a crucial skill for Large Language Models (LLMs).
However, moral values are not universal, but rather influenced by language and
culture. This paper explores how three prominent LLMs -- GPT-4, ChatGPT, and
Llama2-70B-Chat -- perform ethical reasoning in different languages and if
their moral judgement depend on the language in which they are prompted. We
extend the study of ethical reasoning of LLMs by Rao et al. (2023) to a
multilingual setup following their framework of probing LLMs with ethical
dilemmas and policies from three branches of normative ethics: deontology,
virtue, and consequentialism. We experiment with six languages: English,
Spanish, Russian, Chinese, Hindi, and Swahili. We find that GPT-4 is the most
consistent and unbiased ethical reasoner across languages, while ChatGPT and
Llama2-70B-Chat show significant moral value bias when we move to languages
other than English. Interestingly, the nature of this bias significantly vary
across languages for all LLMs, including GPT-4.

摘要：道德推理對於大型語言模型 (LLM) 來說是一項至關重要的技能。
然而，道德價值觀並非普世，而是受到語言和
文化影響。本文探討了三種著名的 LLM —— GPT-4、ChatGPT 和
Llama2-70B-Chat——在不同語言中的道德推理表現，以及它們的道德判斷是否取決於提示它們的語言。我們擴展了 Rao 等人 (2023) 對 LLM 道德推理的研究，採用了他們的框架，用來自規範倫理學三個分支的道德困境和政策對 LLM 進行探測：義務論、美德論和後果論。我們使用六種語言進行實驗：英語、西班牙語、俄語、漢語、印地語和斯瓦希里語。我們發現 GPT-4 在不同語言中是最一致且最公正的道德推理者，而 ChatGPT 和 Llama2-70B-Chat 在我們轉向英語以外的語言時表現出顯著的道德價值觀偏差。有趣的是，這種偏差的性質在所有 LLM（包括 GPT-4）中都因語言而異。

##### **U-Nets as Belief Propagation: Efficient Classification, Denoising, and Diffusion in Generative Hierarchical Models**
2404.18444v1 by Song Mei

U-Nets are among the most widely used architectures in computer vision,
renowned for their exceptional performance in applications such as image
segmentation, denoising, and diffusion modeling. However, a theoretical
explanation of the U-Net architecture design has not yet been fully
established.
  This paper introduces a novel interpretation of the U-Net architecture by
studying certain generative hierarchical models, which are tree-structured
graphical models extensively utilized in both language and image domains. With
their encoder-decoder structure, long skip connections, and pooling and
up-sampling layers, we demonstrate how U-Nets can naturally implement the
belief propagation denoising algorithm in such generative hierarchical models,
thereby efficiently approximating the denoising functions. This leads to an
efficient sample complexity bound for learning the denoising function using
U-Nets within these models. Additionally, we discuss the broader implications
of these findings for diffusion models in generative hierarchical models. We
also demonstrate that the conventional architecture of convolutional neural
networks (ConvNets) is ideally suited for classification tasks within these
models. This offers a unified view of the roles of ConvNets and U-Nets,
highlighting the versatility of generative hierarchical models in modeling
complex data distributions across language and image domains.

摘要：U-Net 是電腦視覺中使用最廣泛的架構之一，以其在影像分割、去噪和擴散建模等應用中傑出的效能而聞名。然而，對於 U-Net 架構設計的理論解釋尚未完全確立。
本文透過研究某些生成式階層模型，介紹了 U-Net 架構的新穎詮釋，這些模型是廣泛用於語言和影像領域的樹狀結構圖形模型。透過其編碼器-解碼器結構、長跳躍連接，以及池化和上採樣層，我們展示了 U-Net 如何在這些生成式階層模型中自然地實作信念傳播去噪演算法，從而有效地近似去噪函數。這導致在這些模型中使用 U-Net 學習去噪函數的有效樣本複雜度界限。此外，我們討論了這些發現對生成式階層模型中擴散模型的更廣泛影響。我們還展示了卷積神經網路 (ConvNet) 的傳統架構非常適合這些模型中的分類任務。這提供了 ConvNet 和 U-Net 角色的統一觀點，強調了生成式階層模型在語言和影像領域中建模複雜資料分佈的多功能性。

##### **BMRetriever: Tuning Large Language Models as Better Biomedical Text Retrievers**
2404.18443v1 by Ran Xu,Wenqi Shi,Yue Yu,Yuchen Zhuang,Yanqiao Zhu,May D. Wang,Joyce C. Ho,Chao Zhang,Carl Yang

Developing effective biomedical retrieval models is important for excelling
at knowledge-intensive biomedical tasks but still challenging due to the
deficiency of sufficient publicly annotated biomedical data and computational
resources. We present BMRetriever, a series of dense retrievers for enhancing
biomedical retrieval via unsupervised pre-training on large biomedical corpora,
followed by instruction fine-tuning on a combination of labeled datasets and
synthetic pairs. Experiments on 5 biomedical tasks across 11 datasets verify
BMRetriever's efficacy on various biomedical applications. BMRetriever also
exhibits strong parameter efficiency, with the 410M variant outperforming
baselines up to 11.7 times larger, and the 2B variant matching the performance
of models with over 5B parameters. The training data and model checkpoints are
released at \url{https://huggingface.co/BMRetriever} to ensure transparency,
reproducibility, and application to new domains.

摘要：開發有效的生物醫學檢索模型對於在知識密集型的生物醫學任務中表現出色非常重要，但由於缺乏足夠的公開註釋生物醫學數據和計算資源，這仍然具有挑戰性。我們展示了 BMRetriever，這是一系列密集檢索器，用於通過在大型生物醫學語料庫上進行無監督預訓練來增強生物醫學檢索，然後在標籤數據集和合成對的組合上進行指令微調。在 11 個數據集上的 5 項生物醫學任務的實驗驗證了 BMRetriever 在各種生物醫學應用中的功效。BMRetriever 還表現出強大的參數效率，其中 410M 變體的表現優於大 11.7 倍的基線，而 2B 變體則與超過 5B 參數的模型的性能相匹配。訓練數據和模型檢查點在 \url{https://huggingface.co/BMRetriever} 發布，以確保透明度、可複製性和對新領域的應用。

##### **Unsupervised Dynamics Prediction with Object-Centric Kinematics**
2404.18423v1 by Yeon-Ji Song,Suhyung Choi,Jaein Kim,Jin-Hwa Kim,Byoung-Tak Zhang

Human perception involves discerning complex multi-object scenes into
time-static object appearance (\ie, size, shape, color) and time-varying object
motion (\ie, location, velocity, acceleration). This innate ability to
unconsciously understand the environment is the motivation behind the success
of dynamics modeling. Object-centric representations have emerged as a
promising tool for dynamics prediction, yet they primarily focus on the
objects' appearance, often overlooking other crucial attributes. In this paper,
we propose Object-Centric Kinematics (OCK), a framework for dynamics prediction
leveraging object-centric representations. Our model utilizes a novel component
named object kinematics, which comprises low-level structured states of
objects' position, velocity, and acceleration. The object kinematics are
obtained via either implicit or explicit approaches, enabling comprehensive
spatiotemporal object reasoning, and integrated through various transformer
mechanisms, facilitating effective object-centric dynamics modeling. Our model
demonstrates superior performance when handling objects and backgrounds in
complex scenes characterized by a wide range of object attributes and dynamic
movements. Moreover, our model demonstrates generalization capabilities across
diverse synthetic environments, highlighting its potential for broad
applicability in vision-related tasks.

摘要：人類感知包含將複雜的多物件場景區分為時間靜態物件外觀（例如大小、形狀、顏色）和時間變動的物件動作（例如位置、速度、加速度）。這種無意識理解環境的本能能力是動態建模成功的背後動機。以物件為中心的表示法已成為動態預測的強大工具，但它們主要關注物件的外觀，常常忽略其他關鍵屬性。在本文中，我們提出以物件為中心的運動學 (OCK)，一個利用以物件為中心的表示法的動態預測架構。我們的模型利用一個名為物件運動學的新元件，它包含物件位置、速度和加速度的低階結構化狀態。物件運動學是透過內隱或外顯方法取得，能進行全面的時空物件推理，並透過各種變壓器機制整合，促進有效的以物件為中心的動態建模。我們的模型在處理複雜場景中的物件和背景時展現出優異的效能，這些場景的特徵是具有廣泛的物件屬性和動態動作。此外，我們的模型在多樣化的合成環境中展現出泛化能力，突顯其在視覺相關任務中廣泛適用的潛力。

##### **Capabilities of Gemini Models in Medicine**
2404.18416v1 by Khaled Saab,Tao Tu,Wei-Hung Weng,Ryutaro Tanno,David Stutz,Ellery Wulczyn,Fan Zhang,Tim Strother,Chunjong Park,Elahe Vedadi,Juanma Zambrano Chaves,Szu-Yeu Hu,Mike Schaekermann,Aishwarya Kamath,Yong Cheng,David G. T. Barrett,Cathy Cheung,Basil Mustafa,Anil Palepu,Daniel McDuff,Le Hou,Tomer Golany,Luyang Liu,Jean-baptiste Alayrac,Neil Houlsby,Nenad Tomasev,Jan Freyberg,Charles Lau,Jonas Kemp,Jeremy Lai,Shekoofeh Azizi,Kimberly Kanada,SiWai Man,Kavita Kulkarni,Ruoxi Sun,Siamak Shakeri,Luheng He,Ben Caine,Albert Webson,Natasha Latysheva,Melvin Johnson,Philip Mansfield,Jian Lu,Ehud Rivlin,Jesper Anderson,Bradley Green,Renee Wong,Jonathan Krause,Jonathon Shlens,Ewa Dominowska,S. M. Ali Eslami,Claire Cui,Oriol Vinyals,Koray Kavukcuoglu,James Manyika,Jeff Dean,Demis Hassabis,Yossi Matias,Dale Webster,Joelle Barral,Greg Corrado,Christopher Semturs,S. Sara Mahdavi,Juraj Gottweis,Alan Karthikesalingam,Vivek Natarajan

Excellence in a wide variety of medical applications poses considerable
challenges for AI, requiring advanced reasoning, access to up-to-date medical
knowledge and understanding of complex multimodal data. Gemini models, with
strong general capabilities in multimodal and long-context reasoning, offer
exciting possibilities in medicine. Building on these core strengths of Gemini,
we introduce Med-Gemini, a family of highly capable multimodal models that are
specialized in medicine with the ability to seamlessly use web search, and that
can be efficiently tailored to novel modalities using custom encoders. We
evaluate Med-Gemini on 14 medical benchmarks, establishing new state-of-the-art
(SoTA) performance on 10 of them, and surpass the GPT-4 model family on every
benchmark where a direct comparison is viable, often by a wide margin. On the
popular MedQA (USMLE) benchmark, our best-performing Med-Gemini model achieves
SoTA performance of 91.1% accuracy, using a novel uncertainty-guided search
strategy. On 7 multimodal benchmarks including NEJM Image Challenges and MMMU
(health & medicine), Med-Gemini improves over GPT-4V by an average relative
margin of 44.5%. We demonstrate the effectiveness of Med-Gemini's long-context
capabilities through SoTA performance on a needle-in-a-haystack retrieval task
from long de-identified health records and medical video question answering,
surpassing prior bespoke methods using only in-context learning. Finally,
Med-Gemini's performance suggests real-world utility by surpassing human
experts on tasks such as medical text summarization, alongside demonstrations
of promising potential for multimodal medical dialogue, medical research and
education. Taken together, our results offer compelling evidence for
Med-Gemini's potential, although further rigorous evaluation will be crucial
before real-world deployment in this safety-critical domain.

摘要：<paragraph>在各种医疗应用中追求卓越对 AI 来说构成了相当大的挑战，需要高级推理、获取最新的医疗知识和理解复杂的多模态数据。Gemini 模型在多模态和长上下文推理方面拥有强大的通用能力，为医学领域带来了激动人心的可能性。在 Gemini 的这些核心优势的基础上，我们引入了 Med-Gemini，这是一个高度专业化的多模态模型系列，专门用于医学领域，能够无缝使用网络搜索，并且可以使用自定义编码器有效地定制为新颖的模态。我们在 14 个医学基准上评估了 Med-Gemini，在其中 10 个基准上建立了新的最先进 (SoTA) 性能，并且在每个基准上都超过了 GPT-4 模型系列，其中直接比较是可行的，并且通常差距很大。在流行的 MedQA (USMLE) 基准上，我们表现最好的 Med-Gemini 模型使用新颖的不确定性引导搜索策略，实现了 91.1% 准确度的 SoTA 性能。在包括 NEJM 图像挑战和 MMMU（健康与医学）在内的 7 个多模态基准上，Med-Gemini 相对于 GPT-4V 的平均相对优势提高了 44.5%。我们通过在从长期去识别化健康记录和医学视频问答中进行大海捞针式检索任务上实现 SoTA 性能，展示了 Med-Gemini 的长上下文能力的有效性，仅使用上下文学习就超过了先前的定制方法。最后，Med-Gemini 的性能表明了现实世界的效用，它在医学文本摘要等任务上超越了人类专家，同时展示了在多模态医学对话、医学研究和教育方面具有广阔的潜力。综上所述，我们的研究结果为 Med-Gemini 的潜力提供了令人信服的证据，尽管在该安全关键领域进行实际部署之前，进一步严格的评估至关重要。</paragraph>

##### **3AM: An Ambiguity-Aware Multi-Modal Machine Translation Dataset**
2404.18413v1 by Xinyu Ma,Xuebo Liu,Derek F. Wong,Jun Rao,Bei Li,Liang Ding,Lidia S. Chao,Dacheng Tao,Min Zhang

Multimodal machine translation (MMT) is a challenging task that seeks to
improve translation quality by incorporating visual information. However,
recent studies have indicated that the visual information provided by existing
MMT datasets is insufficient, causing models to disregard it and overestimate
their capabilities. This issue presents a significant obstacle to the
development of MMT research. This paper presents a novel solution to this issue
by introducing 3AM, an ambiguity-aware MMT dataset comprising 26,000 parallel
sentence pairs in English and Chinese, each with corresponding images. Our
dataset is specifically designed to include more ambiguity and a greater
variety of both captions and images than other MMT datasets. We utilize a word
sense disambiguation model to select ambiguous data from vision-and-language
datasets, resulting in a more challenging dataset. We further benchmark several
state-of-the-art MMT models on our proposed dataset. Experimental results show
that MMT models trained on our dataset exhibit a greater ability to exploit
visual information than those trained on other MMT datasets. Our work provides
a valuable resource for researchers in the field of multimodal learning and
encourages further exploration in this area. The data, code and scripts are
freely available at https://github.com/MaxyLee/3AM.

摘要：多模態機器翻譯 (MMT) 是一項艱鉅的任務，旨在透過納入視覺資訊來提升翻譯品質。然而，最近的研究指出，現有 MMT 資料集提供的視覺資訊不足，導致模型忽略這些資訊並高估其能力。這個問題對 MMT 研究的發展構成重大障礙。本文提出了一個創新的解決方案來解決這個問題，方法是引入 3AM，一個具備歧義感知的 MMT 資料集，包含 26,000 個英文和中文的平行句子對，每個句子對都有對應的影像。我們的資料集特別設計為包含更多歧義，以及比其他 MMT 資料集更多樣化的標題和影像。我們利用字詞義消歧模型從視覺和語言資料集中選取歧義資料，進而產生一個更具挑戰性的資料集。我們進一步在我們提出的資料集上對幾個最先進的 MMT 模型進行基準測試。實驗結果顯示，在我們的資料集上訓練的 MMT 模型展現出比在其他 MMT 資料集上訓練的模型更強大的利用視覺資訊的能力。我們的研究為多模態學習領域的研究人員提供了寶貴的資源，並鼓勵進一步探索這個領域。資料、程式碼和指令碼可於 https://github.com/MaxyLee/3AM 免費取得。

##### **Mixture-of-Instructions: Comprehensive Alignment of a Large Language Model through the Mixture of Diverse System Prompting Instructions**
2404.18410v1 by Bowen Xu,Shaoyu Wu,Kai Liu,Lulu Hu

With the proliferation of large language models (LLMs), the comprehensive
alignment of such models across multiple tasks has emerged as a critical area
of research. Existing alignment methodologies primarily address single task,
such as multi-turn dialogue, coding, mathematical problem-solving, and tool
usage. However, AI-driven products that leverage language models usually
necessitate a fusion of these abilities to function effectively in real-world
scenarios. Moreover, the considerable computational resources required for
proper alignment of LLMs underscore the need for a more robust, efficient, and
encompassing approach to multi-task alignment, ensuring improved generative
performance. In response to these challenges, we introduce a novel technique
termed Mixture-of-Instructions (MoI), which employs a strategy of instruction
concatenation combined with diverse system prompts to boost the alignment
efficiency of language models. We have also compiled a diverse set of seven
benchmark datasets to rigorously evaluate the alignment efficacy of the
MoI-enhanced language model. Our methodology was applied to the open-source
Qwen-7B-chat model, culminating in the development of Qwen-SFT-MoI. This
enhanced model demonstrates significant advancements in generative capabilities
across coding, mathematics, and tool use tasks.

摘要：隨著大型語言模型 (LLM) 的激增，跨多項任務的此類模型的全面對齊已成為研究的重要領域。現有的對齊方法主要針對單一任務，例如多輪對話、編碼、數學問題解決和工具使用。然而，利用語言模型的人工智慧驅動產品通常需要融合這些能力才能在實際場景中有效運作。此外，適當對齊 LLM 所需的大量運算資源強調了對多任務對齊採取更強健、更有效率且更全面的方法的需求，以確保改善生成效能。為了解決這些挑戰，我們引入了一種稱為混合指令 (MoI) 的新技術，它採用指令串接策略，結合不同的系統提示，以提升語言模型的對齊效率。我們還編制了一組包含七個基準資料集，以嚴格評估 MoI 增強語言模型的對齊效果。我們的技術應用於開源 Qwen-7B-chat 模型，最終開發出 Qwen-SFT-MoI。此增強模型在編碼、數學和工具使用任務中展現出生成能力的顯著進步。

##### **LLM-SR: Scientific Equation Discovery via Programming with Large Language Models**
2404.18400v1 by Parshin Shojaee,Kazem Meidani,Shashank Gupta,Amir Barati Farimani,Chandan K Reddy

Mathematical equations have been unreasonably effective in describing complex
natural phenomena across various scientific disciplines. However, discovering
such insightful equations from data presents significant challenges due to the
necessity of navigating extremely high-dimensional combinatorial and nonlinear
hypothesis spaces. Traditional methods of equation discovery largely focus on
extracting equations from data alone, often neglecting the rich domain-specific
prior knowledge that scientists typically depend on. To bridge this gap, we
introduce LLM-SR, a novel approach that leverages the extensive scientific
knowledge and robust code generation capabilities of Large Language Models
(LLMs) to discover scientific equations from data in an efficient manner.
Specifically, LLM-SR treats equations as programs with mathematical operators
and combines LLMs' scientific priors with evolutionary search over equation
programs. The LLM iteratively proposes new equation skeletons, drawing from its
physical understanding, which are then optimized against data to estimate
skeleton parameters. We demonstrate LLM-SR's effectiveness across three diverse
scientific domains, where it discovers physically accurate equations that
provide significantly better fits to in-domain and out-of-domain data compared
to the well-established equation discovery baselines

摘要：數學方程式在描述各種科學領域中複雜的自然現象方面具有不合理的效果。然而，由於必須在極高維度的組合和非線性假設空間中導航，從數據中發現這種有見地的方程式會帶來重大挑戰。傳統的方程式發現方法主要專注於僅從數據中提取方程式，通常忽略科學家通常依賴的豐富領域特定先驗知識。為了彌合這一差距，我們引入了 LLM-SR，這是一種新穎的方法，它利用大型語言模型 (LLM) 廣泛的科學知識和強大的程式碼生成能力，以有效的方式從數據中發現科學方程式。具體來說，LLM-SR 將方程式視為具有數學運算子的程式，並將 LLM 的科學先驗與方程式程式的演化搜尋結合起來。LLM 反覆提出新的方程式架構，從其物理理解中汲取，然後根據數據進行優化以估計架構參數。我們在三個不同的科學領域展示了 LLM-SR 的有效性，它發現了物理上準確的方程式，與完善的方程式發現基準相比，這些方程式對域內和域外數據提供了顯著更好的擬合。

##### **MM-TTS: A Unified Framework for Multimodal, Prompt-Induced Emotional Text-to-Speech Synthesis**
2404.18398v1 by Xiang Li,Zhi-Qi Cheng,Jun-Yan He,Xiaojiang Peng,Alexander G. Hauptmann

Emotional Text-to-Speech (E-TTS) synthesis has gained significant attention
in recent years due to its potential to enhance human-computer interaction.
However, current E-TTS approaches often struggle to capture the complexity of
human emotions, primarily relying on oversimplified emotional labels or
single-modality inputs. To address these limitations, we propose the Multimodal
Emotional Text-to-Speech System (MM-TTS), a unified framework that leverages
emotional cues from multiple modalities to generate highly expressive and
emotionally resonant speech. MM-TTS consists of two key components: (1) the
Emotion Prompt Alignment Module (EP-Align), which employs contrastive learning
to align emotional features across text, audio, and visual modalities, ensuring
a coherent fusion of multimodal information; and (2) the Emotion
Embedding-Induced TTS (EMI-TTS), which integrates the aligned emotional
embeddings with state-of-the-art TTS models to synthesize speech that
accurately reflects the intended emotions. Extensive evaluations across diverse
datasets demonstrate the superior performance of MM-TTS compared to traditional
E-TTS models. Objective metrics, including Word Error Rate (WER) and Character
Error Rate (CER), show significant improvements on ESD dataset, with MM-TTS
achieving scores of 7.35% and 3.07%, respectively. Subjective assessments
further validate that MM-TTS generates speech with emotional fidelity and
naturalness comparable to human speech. Our code and pre-trained models are
publicly available at https://anonymous.4open.science/r/MMTTS-D214

摘要：情感文本到語音 (E-TTS) 合成近年來備受關注，原因在於它有潛力增強人機互動。然而，現有的 E-TTS 方法常常難以捕捉人類情緒的複雜性，主要依賴過於簡化的情緒標籤或單一模式輸入。為了解決這些限制，我們提出了多模式情感文本到語音系統 (MM-TTS)，一個統一的框架，利用來自多個模式的情緒線索來產生高表現力和情感共鳴的語音。MM-TTS 包含兩個關鍵組成部分：(1) 情緒提示對齊模組 (EP-Align)，採用對比學習來對齊文本、音訊和視覺模式之間的情緒特徵，確保多模式資訊的融合一致；(2) 情緒嵌入誘導 TTS (EMI-TTS)，將對齊的情緒嵌入與最先進的 TTS 模型整合，以合成準確反映預期情緒的語音。在各種資料集上的廣泛評估顯示，與傳統 E-TTS 模型相比，MM-TTS 的效能更勝一籌。客觀指標，包括字元錯誤率 (WER) 和字元錯誤率 (CER)，在 ESD 資料集上顯示出顯著的改善，MM-TTS 分別達到 7.35% 和 3.07% 的分數。主觀評估進一步驗證，MM-TTS 產生的語音具有與人類語音相當的情緒保真度和自然度。我們的程式碼和預訓練模型可在 https://anonymous.4open.science/r/MMTTS-D214 公開取得。

##### **Equivalence: An analysis of artists' roles with Image Generative AI from Conceptual Art perspective through an interactive installation design practice**
2404.18385v1 by Yixuan Li,Dan C. Baciu,Marcos Novak,George Legrady

Over the past year, the emergence of advanced text-to-image Generative AI
models has significantly impacted the art world, challenging traditional
notions of creativity and the role of artists. This study explores how artists
interact with these technologies, using a 5P model (Purpose, People, Process,
Product, and Press) based on Rhodes' creativity framework to compare the
artistic processes behind Conceptual Art and Image Generative AI. To exemplify
this framework, a practical case study titled "Equivalence", a multi-screen
interactive installation that converts users' speech input into continuously
evolving paintings developed based on Stable Diffusion and NLP algorithms, was
developed. Through comprehensive analysis and the case study, this work aims to
broaden our understanding of artists' roles and foster a deeper appreciation
for the creative aspects inherent in artwork created with Image Generative AI.

摘要：在過去的一年，先進文字轉圖像生成式 AI 模型的出現對藝術界產生了重大影響，挑戰了傳統的創造力概念和藝術家的角色。本研究探討藝術家如何與這些技術互動，使用基於 Rhodes 創造力框架的 5P 模型（目的、人、過程、產品和新聞）來比較概念藝術和圖像生成式 AI 背後的藝術過程。為了說明這個框架，開發了一個名為「等價性」的實用案例研究，這是一個多螢幕互動式裝置，將使用者的語音輸入轉換成持續演化的繪畫，這些繪畫是基於 Stable Diffusion 和 NLP 演算法開發的。透過全面的分析和案例研究，這項工作旨在擴展我們對藝術家角色的理解，並培養對使用圖像生成式 AI 創作的藝術作品中固有的創造層面的更深入的欣賞。

##### **Exploring the Limits of Fine-grained LLM-based Physics Inference via Premise Removal Interventions**
2404.18384v1 by Jordan Meadows,Tamsin James,Andre Freitas

Language models can hallucinate when performing complex and detailed
mathematical reasoning. Physics provides a rich domain for assessing
mathematical reasoning capabilities where physical context imbues the use of
symbols which needs to satisfy complex semantics (\textit{e.g.,} units,
tensorial order), leading to instances where inference may be algebraically
coherent, yet unphysical. In this work, we assess the ability of Language
Models (LMs) to perform fine-grained mathematical and physical reasoning using
a curated dataset encompassing multiple notations and Physics subdomains. We
improve zero-shot scores using synthetic in-context examples, and demonstrate
non-linear degradation of derivation quality with perturbation strength via the
progressive omission of supporting premises. We find that the models'
mathematical reasoning is not physics-informed in this setting, where physical
context is predominantly ignored in favour of reverse-engineering solutions.

摘要：語言模型在執行複雜且詳細的數學推理時可能會出現幻覺。物理學提供了一個豐富的領域來評估數學推理能力，其中物理語境賦予了符號的使用，需要滿足複雜的語義（例如單位、張量順序），導致推理在代數上可能是一致的，但卻不符合物理。在這項工作中，我們評估語言模型 (LM) 使用精心策劃的涵蓋多種符號和物理子領域的資料集執行細緻的數學和物理推理的能力。我們使用合成的語境範例改進了零次學習分數，並透過逐步省略支持的前提來證明推導品質隨著擾動強度而出現非線性下降。我們發現，在這種情況下，模型的數學推理並未受到物理學的影響，其中物理語境主要被忽略，取而代之的是逆向工程解決方案。

##### **QANA: LLM-based Question Generation and Network Analysis for Zero-shot Key Point Analysis and Beyond**
2404.18371v1 by Tomoki Fukuma,Koki Noda,Toshihide Ubukata Kousuke Hoso,Yoshiharu Ichikawa,Kyosuke Kambe,Yu Masubuch,Fujio Toriumi

The proliferation of social media has led to information overload and
increased interest in opinion mining. We propose "Question-Answering Network
Analysis" (QANA), a novel opinion mining framework that utilizes Large Language
Models (LLMs) to generate questions from users' comments, constructs a
bipartite graph based on the comments' answerability to the questions, and
applies centrality measures to examine the importance of opinions. We
investigate the impact of question generation styles, LLM selections, and the
choice of embedding model on the quality of the constructed QA networks by
comparing them with annotated Key Point Analysis datasets. QANA achieves
comparable performance to previous state-of-the-art supervised models in a
zero-shot manner for Key Point Matching task, also reducing the computational
cost from quadratic to linear. For Key Point Generation, questions with high
PageRank or degree centrality align well with manually annotated key points.
Notably, QANA enables analysts to assess the importance of key points from
various aspects according to their selection of centrality measure. QANA's
primary contribution lies in its flexibility to extract key points from a wide
range of perspectives, which enhances the quality and impartiality of opinion
mining.

摘要：社群媒體的激增導致資訊過載，並提高了人們對意見探勘的興趣。我們提出「問答網路分析」(QANA)，這是一個新穎的意見探勘架構，它利用大型語言模型 (LLM) 從使用者的留言中產生問題，根據留言對問題的可回答性建構一個二部圖，並應用中心性測量來檢驗意見的重要性。我們透過將問答網路與標記關鍵點分析資料集進行比較，調查問題產生風格、LLM 選擇和嵌入模型的選擇對建構的問答網路品質的影響。QANA 在關鍵點比對任務中以零次學習的方式，達到了與先前最先進的監督模型相當的效能，同時也將運算成本從二次方降低到一次方。對於關鍵點產生，PageRank 或度中心性高的問題與手動標記的關鍵點非常吻合。值得注意的是，QANA 讓分析師能夠根據他們選擇的中心性測量來評估關鍵點從各個面向的重要性。QANA 的主要貢獻在於它可以從廣泛的觀點中提取關鍵點的靈活性，這提升了意見探勘的品質和公正性。

##### **FoundaBench: Evaluating Chinese Fundamental Knowledge Capabilities of Large Language Models**
2404.18359v1 by Wei Li,Ren Ma,Jiang Wu,Chenya Gu,Jiahui Peng,Jinyang Len,Songyang Zhang,Hang Yan,Dahua Lin,Conghui He

In the burgeoning field of large language models (LLMs), the assessment of
fundamental knowledge remains a critical challenge, particularly for models
tailored to Chinese language and culture. This paper introduces FoundaBench, a
pioneering benchmark designed to rigorously evaluate the fundamental knowledge
capabilities of Chinese LLMs. FoundaBench encompasses a diverse array of 3354
multiple-choice questions across common sense and K-12 educational subjects,
meticulously curated to reflect the breadth and depth of everyday and academic
knowledge. We present an extensive evaluation of 12 state-of-the-art LLMs using
FoundaBench, employing both traditional assessment methods and our CircularEval
protocol to mitigate potential biases in model responses. Our results highlight
the superior performance of models pre-trained on Chinese corpora, and reveal a
significant disparity between models' reasoning and memory recall capabilities.
The insights gleaned from FoundaBench evaluations set a new standard for
understanding the fundamental knowledge of LLMs, providing a robust framework
for future advancements in the field.

摘要：在蓬勃發展的大型語言模型（LLM）領域中，基礎知識的評估仍然是一項嚴峻的挑戰，特別是針對專為中文語言和文化量身打造的模型。本文介紹了 FoundaBench，這是一個先驅基準，旨在嚴格評估中文 LLM 的基礎知識能力。FoundaBench 涵蓋了 3354 個多元化的選擇題，涵蓋常識和 K-12 教育科目，經過精心策劃，以反映日常和學術知識的廣度和深度。我們使用 FoundaBench 對 12 個最先進的 LLM 進行了廣泛的評估，採用傳統評估方法和我們的 CircularEval 協議來減輕模型回應中潛在的偏差。我們的結果突出了在中文語料庫上預先訓練的模型的優異性能，並揭示了模型的推理和記憶召回能力之間的顯著差異。從 FoundaBench 評估中收集的見解為理解 LLM 的基礎知識設定了新的標準，為該領域的未來進步提供了穩健的框架。

##### **Do Neutral Prompts Produce Insecure Code? FormAI-v2 Dataset: Labelling Vulnerabilities in Code Generated by Large Language Models**
2404.18353v1 by Norbert Tihanyi,Tamas Bisztray,Mohamed Amine Ferrag,Ridhi Jain,Lucas C. Cordeiro

This study provides a comparative analysis of state-of-the-art large language
models (LLMs), analyzing how likely they generate vulnerabilities when writing
simple C programs using a neutral zero-shot prompt. We address a significant
gap in the literature concerning the security properties of code produced by
these models without specific directives. N. Tihanyi et al. introduced the
FormAI dataset at PROMISE '23, containing 112,000 GPT-3.5-generated C programs,
with over 51.24% identified as vulnerable. We expand that work by introducing
the FormAI-v2 dataset comprising 265,000 compilable C programs generated using
various LLMs, including robust models such as Google's GEMINI-pro, OpenAI's
GPT-4, and TII's 180 billion-parameter Falcon, to Meta's specialized 13
billion-parameter CodeLLama2 and various other compact models. Each program in
the dataset is labelled based on the vulnerabilities detected in its source
code through formal verification using the Efficient SMT-based Context-Bounded
Model Checker (ESBMC). This technique eliminates false positives by delivering
a counterexample and ensures the exclusion of false negatives by completing the
verification process. Our study reveals that at least 63.47% of the generated
programs are vulnerable. The differences between the models are minor, as they
all display similar coding errors with slight variations. Our research
highlights that while LLMs offer promising capabilities for code generation,
deploying their output in a production environment requires risk assessment and
validation.

摘要：本研究提供了最先進大型語言模型 (LLM) 的比較分析，分析了在使用中立零次提示編寫簡單 C 程式時，它們產生漏洞的可能性。我們解決了關於這些模型在沒有具體指令的情況下產生的程式碼的安全性屬性的文獻中的重大差距。N. Tihanyi 等人在 PROMISE '23 上介紹了 FormAI 資料集，其中包含 112,000 個 GPT-3.5 生成的 C 程式，其中超過 51.24% 被標識為有漏洞。我們通過引入 FormAI-v2 資料集來擴展這項工作，該資料集包含 265,000 個使用各種 LLM 生成的可編譯 C 程式，包括 Google 的 GEMINI-pro、OpenAI 的 GPT-4 和 TII 的 1800 億參數 Falcon 等強大的模型，以及 Meta 的專門 130 億參數 CodeLLama2 和各種其他小型模型。資料集中的每個程式都根據使用基於 SMT 的高效上下文限制模型檢查器 (ESBMC) 的形式驗證在其原始程式碼中檢測到的漏洞進行標記。此技術通過提供反例來消除假陽性，並通過完成驗證過程來確保排除假陰性。我們的研究表明，至少有 63.47% 的生成程式存在漏洞。模型之間的差異很小，因為它們都顯示出類似的編碼錯誤，略有不同。我們的研究強調，儘管 LLM 為程式碼生成提供了有希望的功能，但在生產環境中部署其輸出需要風險評估和驗證。

##### **Post-hoc and manifold explanations analysis of facial expression data based on deep learning**
2404.18352v1 by Yang Xiao

The complex information processing system of humans generates a lot of
objective and subjective evaluations, making the exploration of human cognitive
products of great cutting-edge theoretical value. In recent years, deep
learning technologies, which are inspired by biological brain mechanisms, have
made significant strides in the application of psychological or cognitive
scientific research, particularly in the memorization and recognition of facial
data. This paper investigates through experimental research how neural networks
process and store facial expression data and associate these data with a range
of psychological attributes produced by humans. Researchers utilized deep
learning model VGG16, demonstrating that neural networks can learn and
reproduce key features of facial data, thereby storing image memories.
Moreover, the experimental results reveal the potential of deep learning models
in understanding human emotions and cognitive processes and establish a
manifold visualization interpretation of cognitive products or psychological
attributes from a non-Euclidean space perspective, offering new insights into
enhancing the explainability of AI. This study not only advances the
application of AI technology in the field of psychology but also provides a new
psychological theoretical understanding the information processing of the AI.
The code is available in here: https://github.com/NKUShaw/Psychoinformatics.

摘要：人類複雜的資訊處理系統，產生大量的客觀與主觀的評價，使得探討人類認知產物具有極大的前沿理論價值。近年來，深受生物腦機制啟發的深度學習技術，在心理學或認知科學研究的應用上，特別是在人臉資料的記憶與辨識上，有長足的進展。本文透過實驗研究探討神經網路如何處理與儲存人臉表情資料，並將這些資料與人類產生的各種心理屬性做連結。研究者利用深度學習模型 VGG16，驗證神經網路可以學習與重現人臉資料的關鍵特徵，進而儲存影像記憶。此外，實驗結果揭示深度學習模型在理解人類情緒與認知歷程的潛力，並從非歐氏空間的觀點建立認知產物或心理屬性的流形視覺化詮釋，為提升 AI 的可解釋性提供新的見解。本研究不僅推進 AI 技術在心理學領域的應用，也為 AI 的資訊處理提供新的心理學理論理解。程式碼放置於此：https://github.com/NKUShaw/Psychoinformatics。

##### **Multi-stage Attack Detection and Prediction Using Graph Neural Networks: An IoT Feasibility Study**
2404.18328v1 by Hamdi Friji,Ioannis Mavromatis,Adrian Sanchez-Mompo,Pietro Carnelli,Alexis Olivereau,Aftab Khan

With the ever-increasing reliance on digital networks for various aspects of
modern life, ensuring their security has become a critical challenge. Intrusion
Detection Systems play a crucial role in ensuring network security, actively
identifying and mitigating malicious behaviours. However, the relentless
advancement of cyber-threats has rendered traditional/classical approaches
insufficient in addressing the sophistication and complexity of attacks. This
paper proposes a novel 3-stage intrusion detection system inspired by a
simplified version of the Lockheed Martin cyber kill chain to detect advanced
multi-step attacks. The proposed approach consists of three models, each
responsible for detecting a group of attacks with common characteristics. The
detection outcome of the first two stages is used to conduct a feasibility
study on the possibility of predicting attacks in the third stage. Using the
ToN IoT dataset, we achieved an average of 94% F1-Score among different stages,
outperforming the benchmark approaches based on Random-forest model. Finally,
we comment on the feasibility of this approach to be integrated in a real-world
system and propose various possible future work.

摘要：隨著現代生活中各方面對數位網路的依賴日益增加，確保網路安全已成為一項關鍵挑戰。入侵偵測系統在確保網路安全方面發揮了至關重要的作用，主動識別和減輕惡意行為。然而，網路威脅的持續進步使得傳統/古典方法無法應對攻擊的複雜性和精密性。本文提出了一個新穎的三階段入侵偵測系統，其靈感來自洛克希德馬丁網路殺戮鏈的簡化版本，用於偵測進階的多步驟攻擊。所提出的方法包含三個模型，每個模型負責偵測具有共同特徵的一組攻擊。前兩個階段的偵測結果用於對第三階段預測攻擊的可能性進行可行性研究。使用 ToN IoT 資料集，我們在不同的階段達到了平均 94% 的 F1 分數，優於基於隨機森林模型的基準方法。最後，我們評論了這種方法整合到現實世界系統中的可行性，並提出了各種可能的未來工作。

##### **SAFE-RL: Saliency-Aware Counterfactual Explainer for Deep Reinforcement Learning Policies**
2404.18326v1 by Amir Samadi,Konstantinos Koufos,Kurt Debattista,Mehrdad Dianati

While Deep Reinforcement Learning (DRL) has emerged as a promising solution
for intricate control tasks, the lack of explainability of the learned policies
impedes its uptake in safety-critical applications, such as automated driving
systems (ADS). Counterfactual (CF) explanations have recently gained prominence
for their ability to interpret black-box Deep Learning (DL) models. CF examples
are associated with minimal changes in the input, resulting in a complementary
output by the DL model. Finding such alternations, particularly for
high-dimensional visual inputs, poses significant challenges. Besides, the
temporal dependency introduced by the reliance of the DRL agent action on a
history of past state observations further complicates the generation of CF
examples. To address these challenges, we propose using a saliency map to
identify the most influential input pixels across the sequence of past observed
states by the agent. Then, we feed this map to a deep generative model,
enabling the generation of plausible CFs with constrained modifications centred
on the salient regions. We evaluate the effectiveness of our framework in
diverse domains, including ADS, Atari Pong, Pacman and space-invaders games,
using traditional performance metrics such as validity, proximity and sparsity.
Experimental results demonstrate that this framework generates more informative
and plausible CFs than the state-of-the-art for a wide range of environments
and DRL agents. In order to foster research in this area, we have made our
datasets and codes publicly available at
https://github.com/Amir-Samadi/SAFE-RL.

摘要：儘管深度強化學習 (DRL) 已成為複雜控制任務中一個有前途的解決方案，但所學政策缺乏可解釋性，阻礙了它在安全關鍵應用中的採用，例如自動駕駛系統 (ADS)。反事實 (CF) 解釋最近因其解釋黑箱深度學習 (DL) 模型的能力而備受關注。CF 樣例與輸入中的最小變更相關聯，從而導致 DL 模型產生互補的輸出。尋找此類變更，特別是對於高維度視覺輸入，會帶來重大挑戰。此外，DRL 代理動作依賴於過去狀態觀察的歷史所帶來的時間依賴性進一步複雜化了 CF 樣例的產生。為了應對這些挑戰，我們建議使用顯著性圖來識別代理在過去觀察到的狀態序列中最具影響力的輸入像素。然後，我們將此地圖饋送到深度生成模型，從而能夠生成以顯著區域為中心的受約束修改的合理 CF。我們使用傳統的效能指標（例如有效性、接近性和稀疏性）在不同的領域（包括 ADS、Atari Pong、Pacman 和太空侵略者遊戲）中評估我們架構的有效性。實驗結果表明，對於廣泛的環境和 DRL 代理，此架構產生的 CF 比最先進的技術更具資訊性和合理性。為了促進這方面的研究，我們已在 https://github.com/Amir-Samadi/SAFE-RL 上公開我們的資料集和程式碼。

##### **Trends and Challenges of Real-time Learning in Large Language Models: A Critical Review**
2404.18311v1 by Mladjan Jovanovic,Peter Voss

Real-time learning concerns the ability of learning systems to acquire
knowledge over time, enabling their adaptation and generalization to novel
tasks. It is a critical ability for intelligent, real-world systems, especially
when data may be insufficient or difficult to obtain. This review provides a
comprehensive analysis of real-time learning in Large Language Models. It
synthesizes the state-of-the-art real-time learning paradigms, including
continual learning, meta-learning, parameter-efficient learning, and
mixture-of-experts learning. We demonstrate their utility for real-time
learning by describing specific achievements from these related topics and
their critical factors. Finally, the paper highlights current problems and
challenges for future research in the field. By consolidating the latest
relevant research developments, this review offers a comprehensive
understanding of real-time learning and its implications for designing and
developing LLM-based learning systems addressing real-world problems.

摘要：實時學習涉及學習系統在時間推移中獲取知識的能力，讓其能夠適應新任務並對其進行概括。對於智慧的現實世界系統而言，這是一項至關重要的能力，特別是在資料不足或難以取得時。本篇評論提供了大型語言模型中實時學習的全面分析。它綜合了最先進的實時學習範例，包括持續學習、元學習、參數有效學習和專家混合學習。我們透過描述這些相關主題的具體成就及其關鍵因素，展示了它們在實時學習中的效用。最後，本文重點介紹了該領域未來研究當前的問題和挑戰。透過整合最新的相關研究發展，本篇評論提供了對實時學習及其對設計和開發解決現實世界問題的 LLM 基礎學習系統的影響的全面理解。

##### **Retrieval-Oriented Knowledge for Click-Through Rate Prediction**
2404.18304v1 by Huanshuo Liu,Bo Chen,Menghui Zhu,Jianghao Lin,Jiarui Qin,Yang Yang,Hao Zhang,Ruiming Tang

Click-through rate (CTR) prediction plays an important role in personalized
recommendations. Recently, sample-level retrieval-based models (e.g., RIM) have
achieved remarkable performance by retrieving and aggregating relevant samples.
However, their inefficiency at the inference stage makes them impractical for
industrial applications. To overcome this issue, this paper proposes a
universal plug-and-play Retrieval-Oriented Knowledge (ROK) framework.
Specifically, a knowledge base, consisting of a retrieval-oriented embedding
layer and a knowledge encoder, is designed to preserve and imitate the
retrieved & aggregated representations in a decomposition-reconstruction
paradigm. Knowledge distillation and contrastive learning methods are utilized
to optimize the knowledge base, and the learned retrieval-enhanced
representations can be integrated with arbitrary CTR models in both
instance-wise and feature-wise manners. Extensive experiments on three
large-scale datasets show that ROK achieves competitive performance with the
retrieval-based CTR models while reserving superior inference efficiency and
model compatibility.

摘要：點擊率 (CTR) 預測在個人化推薦中扮演著重要的角色。最近，基於樣本層級檢索的模型（例如 RIM）透過檢索並彙總相關樣本，達到了顯著的效能。然而，它們在推論階段的低效率使得它們不切實際地運用於產業應用。為了克服這個問題，本文提出了一個通用的即插即用檢索導向知識 (ROK) 架構。具體來說，一個由檢索導向嵌入層和知識編碼器組成的知識庫被設計用於在分解重建範例中保留和模擬檢索和彙總的表示。知識蒸餾和對比學習方法被用於最佳化知識庫，而學習到的檢索增強表示可以整合到任意 CTR 模型中，無論是基於實例還是基於特徵的方式。在三個大型資料集上的廣泛實驗表明，ROK 在保留優異的推論效率和模型相容性的同時，達到了與基於檢索的 CTR 模型相媲美的效能。

##### **Using Deep Q-Learning to Dynamically Toggle between Push/Pull Actions in Computational Trust Mechanisms**
2404.18296v1 by Zoi Lygizou,Dimitris Kalles

Recent work on decentralized computational trust models for open Multi Agent
Systems has resulted in the development of CA, a biologically inspired model
which focuses on the trustee's perspective. This new model addresses a serious
unresolved problem in existing trust and reputation models, namely the
inability to handle constantly changing behaviors and agents' continuous entry
and exit from the system. In previous work, we compared CA to FIRE, a
well-known trust and reputation model, and found that CA is superior when the
trustor population changes, whereas FIRE is more resilient to the trustee
population changes. Thus, in this paper, we investigate how the trustors can
detect the presence of several dynamic factors in their environment and then
decide which trust model to employ in order to maximize utility. We frame this
problem as a machine learning problem in a partially observable environment,
where the presence of several dynamic factors is not known to the trustor and
we describe how an adaptable trustor can rely on a few measurable features so
as to assess the current state of the environment and then use Deep Q Learning
(DQN), in a single-agent Reinforcement Learning setting, to learn how to adapt
to a changing environment. We ran a series of simulation experiments to compare
the performance of the adaptable trustor with the performance of trustors using
only one model (FIRE or CA) and we show that an adaptable agent is indeed
capable of learning when to use each model and, thus, perform consistently in
dynamic environments.

摘要：<paragraph>最近關於開放式多智能體系統的去中心化計算信任模型的研究，導致了 CA 的開發，這是一個以受託人的觀點為中心的生物啟發模型。這個新模型解決了現有信任和聲譽模型中一個嚴重的未解決問題，即無法處理不斷變化的行為以及代理人持續進入和退出系統。在先前的研究中，我們將 CA 與 FIRE（一個著名的信任和聲譽模型）進行比較，發現當信任者群體發生變化時，CA 較為優越，而 FIRE 對受託人群體的變化更具韌性。因此，在本文中，我們探討了信任者如何檢測其環境中幾個動態因素的存在，然後決定採用哪個信任模型以最大化效用。我們將這個問題構建為一個在部分可觀察環境中的機器學習問題，其中信任者不知道幾個動態因素的存在，而且我們描述了一個適應性信任者如何依賴幾個可測量特徵來評估環境的當前狀態，然後在單一代理強化學習設置中使用深度 Q 學習 (DQN) 來學習如何適應不斷變化的環境。我們進行了一系列模擬實驗，以比較適應性信任者與僅使用一個模型（FIRE 或 CA）的信任者的性能，並且我們表明，一個適應性代理確實有能力學習何時使用每個模型，從而始終如一地在動態環境中執行。</paragraph>

##### **Comparing LLM prompting with Cross-lingual transfer performance on Indigenous and Low-resource Brazilian Languages**
2404.18286v1 by David Ifeoluwa Adelani,A. Seza Doğruöz,André Coneglian,Atul Kr. Ojha

Large Language Models are transforming NLP for a variety of tasks. However,
how LLMs perform NLP tasks for low-resource languages (LRLs) is less explored.
In line with the goals of the AmeicasNLP workshop, we focus on 12 LRLs from
Brazil, 2 LRLs from Africa and 2 high-resource languages (HRLs) (e.g., English
and Brazilian Portuguese). Our results indicate that the LLMs perform worse for
the part of speech (POS) labeling of LRLs in comparison to HRLs. We explain the
reasons behind this failure and provide an error analyses through examples
observed in our data set.

摘要：大型語言模型正在為各種任務轉換 NLP。然而，LLM 如何為低資源語言 (LRL) 執行 NLP 任務的探索較少。根據美洲 NLP 工作坊的目標，我們專注於來自巴西的 12 個 LRL、來自非洲的 2 個 LRL 和 2 個高資源語言 (HRL)（例如，英語和巴西葡萄牙語）。我們的結果表明，與 HRL 相比，LLM 對 LRL 的詞性標記 (POS) 標記執行較差。我們解釋了這種失敗背後的原因，並通過在我們的數據集中觀察到的範例提供錯誤分析。

##### **Bias Neutralization Framework: Measuring Fairness in Large Language Models with Bias Intelligence Quotient (BiQ)**
2404.18276v1 by Malur Narayan,John Pasmore,Elton Sampaio,Vijay Raghavan,Gabriella Waters

The burgeoning influence of Large Language Models (LLMs) in shaping public
discourse and decision-making underscores the imperative to address inherent
biases within these AI systems. In the wake of AI's expansive integration
across sectors, addressing racial bias in LLMs has never been more critical.
This paper introduces a novel framework called Comprehensive Bias
Neutralization Framework (CBNF) which embodies an innovative approach to
quantifying and mitigating biases within LLMs. Our framework combines the Large
Language Model Bias Index (LLMBI) [Oketunji, A., Anas, M., Saina, D., (2023)]
and Bias removaL with No Demographics (BLIND) [Orgad, H., Belinkov, Y. (2023)]
methodologies to create a new metric called Bias Intelligence Quotient
(BiQ)which detects, measures, and mitigates racial bias in LLMs without
reliance on demographic annotations.
  By introducing a new metric called BiQ that enhances LLMBI with additional
fairness metrics, CBNF offers a multi-dimensional metric for bias assessment,
underscoring the necessity of a nuanced approach to fairness in AI [Mehrabi et
al., 2021]. This paper presents a detailed analysis of Latimer AI (a language
model incrementally trained on black history and culture) in comparison to
ChatGPT 3.5, illustrating Latimer AI's efficacy in detecting racial, cultural,
and gender biases through targeted training and refined bias mitigation
strategies [Latimer & Bender, 2023].

摘要：<paragraph>大型語言模型 (LLM) 在形塑公共論述和決策制定上的影響力與日俱增，這突顯出處理這些 AI 系統中固有偏誤的必要性。隨著 AI 在各個產業的廣泛整合，解決 LLM 中的種族偏誤比以往任何時候都更加重要。本文介紹了一個創新的框架，稱為全面偏誤中和框架 (CBNF)，它體現了一種量化和減輕 LLM 中偏誤的創新方法。我們的框架結合了大型語言模型偏誤指標 (LLMBI) [Oketunji, A., Anas, M., Saina, D., (2023)] 和無人口統計資料偏誤移除 (BLIND) [Orgad, H., Belinkov, Y. (2023)] 方法，以建立一個新的指標，稱為偏誤智商 (BiQ)，它可以偵測、衡量和減輕 LLM 中的種族偏誤，而無需依賴人口統計註解。
透過引入一個新的指標 BiQ，它以額外的公平性指標增強 LLMBI，CBNF 提供了一個多面向的指標來評估偏誤，強調了對 AI 中公平性採取細緻方法的必要性 [Mehrabi 等人，2021]。本文詳細分析了 Latimer AI（一個針對黑人歷史和文化進行增量訓練的語言模型），並與 ChatGPT 3.5 進行比較，說明 Latimer AI 透過有針對性的訓練和精緻的偏誤緩解策略，在偵測種族、文化和性別偏誤方面的效能 [Latimer & Bender, 2023]。</paragraph>

##### **Parameter-Efficient Tuning Large Language Models for Graph Representation Learning**
2404.18271v1 by Qi Zhu,Da Zheng,Xiang Song,Shichang Zhang,Bowen Jin,Yizhou Sun,George Karypis

Text-rich graphs, which exhibit rich textual information on nodes and edges,
are prevalent across a wide range of real-world business applications. Large
Language Models (LLMs) have demonstrated remarkable abilities in understanding
text, which also introduced the potential for more expressive modeling in
text-rich graphs. Despite these capabilities, efficiently applying LLMs to
representation learning on graphs presents significant challenges. Recently,
parameter-efficient fine-tuning methods for LLMs have enabled efficient new
task generalization with minimal time and memory consumption. Inspired by this,
we introduce Graph-aware Parameter-Efficient Fine-Tuning - GPEFT, a novel
approach for efficient graph representation learning with LLMs on text-rich
graphs. Specifically, we utilize a graph neural network (GNN) to encode
structural information from neighboring nodes into a graph prompt. This prompt
is then inserted at the beginning of the text sequence. To improve the quality
of graph prompts, we pre-trained the GNN to assist the frozen LLM in predicting
the next token in the node text. Compared with existing joint GNN and LMs, our
method directly generate the node embeddings from large language models with an
affordable fine-tuning cost. We validate our approach through comprehensive
experiments conducted on 8 different text-rich graphs, observing an average
improvement of 2% in hit@1 and Mean Reciprocal Rank (MRR) in link prediction
evaluations. Our results demonstrate the efficacy and efficiency of our model,
showing that it can be smoothly integrated with various large language models,
including OPT, LLaMA and Falcon.

摘要：<paragraph>文本豐富的圖表在各個領域的實際商業應用中很常見，這些圖表在節點和邊緣上展示豐富的文本資訊。大型語言模型 (LLM) 已展現出理解文本的驚人能力，這也引入了在文本豐富的圖表中進行更具表現力的建模的可能性。儘管有這些功能，但將 LLM 有效地應用於圖表上的表示學習仍面臨重大挑戰。最近，針對 LLM 的參數有效微調方法已實現有效的新任務泛化，同時將時間和記憶體消耗降至最低。受此啟發，我們引入了圖形感知參數有效微調 (GPEFT)，這是一種在文本豐富的圖表上使用 LLM 進行高效圖表表示學習的新方法。具體來說，我們利用圖神經網路 (GNN) 將來自相鄰節點的結構資訊編碼到圖提示中。然後將此提示插入文本序列的開頭。為了提高圖提示的品質，我們預先訓練了 GNN 以協助凍結的 LLM 預測節點文本中的下一個標記。與現有的聯合 GNN 和 LM 相比，我們的方法直接從大型語言模型中生成節點嵌入，且微調成本低廉。我們透過在 8 個不同的文本豐富圖表上進行的綜合實驗驗證了我們的方法，觀察到在連結預測評估中，hit@1 和平均倒數排名 (MRR) 平均提升了 2%。我們的結果證明了我們模型的效能和效率，顯示它可以與各種大型語言模型順利整合，包括 OPT、LLaMA 和 Falcon。</paragraph>

##### **Pragmatic Formal Verification of Sequential Error Detection and Correction Codes (ECCs) used in Safety-Critical Design**
2404.18270v1 by Aman Kumar

Error Detection and Correction Codes (ECCs) are often used in digital designs
to protect data integrity. Especially in safety-critical systems such as
automotive electronics, ECCs are widely used and the verification of such
complex logic becomes more critical considering the ISO 26262 safety standards.
Exhaustive verification of ECC using formal methods has been a challenge given
the high number of data bits to protect. As an example, for an ECC of 128 data
bits with a possibility to detect up to four-bit errors, the combination of bit
errors is given by 128C1 + 128C2 + 128C3 + 128C4 = 1.1 * 10^7. This vast
analysis space often leads to bounded proof results. Moreover, the complexity
and state-space increase further if the ECC has sequential encoding and
decoding stages. To overcome such problems and sign-off the design with
confidence within reasonable proof time, we present a pragmatic formal
verification approach of complex ECC cores with several complexity reduction
techniques and know-how that were learnt during the course of verification. We
discuss using the linearity of the syndrome generator as a helper assertion,
using the abstract model as glue logic to compare the RTL with the sequential
version of the circuit, k-induction-based model checking and using mathematical
relations captured as properties to simplify the verification in order to get
an unbounded proof result within 24 hours of proof runtime.

摘要：錯誤偵測及修正碼 (ECC) 常用於數位設計中，以保護資料完整性。特別是在安全關鍵系統，例如汽車電子，ECC 被廣泛使用，且考量 ISO 26262 安全標準，此類複雜邏輯的驗證變得更加重要。使用形式化方法對 ECC 進行窮舉驗證是一項挑戰，因為需要保護的資料位元數目龐大。舉例來說，對於一個可以偵測多達四位元錯誤的 128 資料位元 ECC，位元錯誤的組合由 128C1 + 128C2 + 128C3 + 128C4 = 1.1 * 10^7 給出。這個龐大的分析空間通常會導致受限的證明結果。此外，如果 ECC 有順序編碼和解碼階段，複雜度和狀態空間會進一步增加。為了克服這些問題，並在合理的證明時間內自信地簽核設計，我們提出了一個實用的形式化驗證方法，其中包含了多項複雜度降低技術和在驗證過程中習得的訣竅。我們討論使用症候群產生器的線性作為輔助斷言，使用抽象模型作為膠水邏輯，以將 RTL 與電路順序版本進行比較，基於 k 歸納的模型檢查，以及使用數學關係作為屬性來簡化驗證，以便在 24 小時的證明執行時間內獲得無界的證明結果。

##### **Modeling Orthographic Variation Improves NLP Performance for Nigerian Pidgin**
2404.18264v1 by Pin-Jie Lin,Merel Scholman,Muhammed Saeed,Vera Demberg

Nigerian Pidgin is an English-derived contact language and is traditionally
an oral language, spoken by approximately 100 million people. No orthographic
standard has yet been adopted, and thus the few available Pidgin datasets that
exist are characterised by noise in the form of orthographic variations. This
contributes to under-performance of models in critical NLP tasks. The current
work is the first to describe various types of orthographic variations commonly
found in Nigerian Pidgin texts, and model this orthographic variation. The
variations identified in the dataset form the basis of a phonetic-theoretic
framework for word editing, which is used to generate orthographic variations
to augment training data. We test the effect of this data augmentation on two
critical NLP tasks: machine translation and sentiment analysis. The proposed
variation generation framework augments the training data with new orthographic
variants which are relevant for the test set but did not occur in the training
set originally. Our results demonstrate the positive effect of augmenting the
training data with a combination of real texts from other corpora as well as
synthesized orthographic variation, resulting in performance improvements of
2.1 points in sentiment analysis and 1.4 BLEU points in translation to English.

摘要：<paragraph>奈及利亞皮欽語是一種源自英語的接觸語言，傳統上是一種口語，大約有 1 億人使用。尚未採用正字法標準，因此現有的少數皮欽語資料集的特徵是正字法變異形式的雜訊。這會導致模型在關鍵的 NLP 任務中表現不佳。目前的工作首次描述了奈及利亞皮欽語文本中常見的各種正字法變異，並對此正字法變異進行建模。資料集中識別出的變異構成了詞彙編輯的語音理論架構的基礎，用於產生正字法變異以擴充訓練資料。我們測試了這種資料擴充對兩個關鍵的 NLP 任務的影響：機器翻譯和情緒分析。所提出的變異產生架構使用新的正字法變異擴充訓練資料，這些變異與測試集相關，但最初未出現在訓練集中。我們的結果證明了使用來自其他語料庫的真實文本以及合成的正字法變異的組合來擴充訓練資料的正面效果，從而使情緒分析的性能提高了 2.1 個點，翻譯成英語的 BLEU 分數提高了 1.4 個點。</paragraph>

##### **Generating Situated Reflection Triggers about Alternative Solution Paths: A Case Study of Generative AI for Computer-Supported Collaborative Learning**
2404.18262v1 by Atharva Naik,Jessica Ruhan Yin,Anusha Kamath,Qianou Ma,Sherry Tongshuang Wu,Charles Murray,Christopher Bogart,Majd Sakr,Carolyn P. Rose

An advantage of Large Language Models (LLMs) is their contextualization
capability - providing different responses based on student inputs like
solution strategy or prior discussion, to potentially better engage students
than standard feedback. We present a design and evaluation of a
proof-of-concept LLM application to offer students dynamic and contextualized
feedback. Specifically, we augment an Online Programming Exercise bot for a
college-level Cloud Computing course with ChatGPT, which offers students
contextualized reflection triggers during a collaborative query optimization
task in database design. We demonstrate that LLMs can be used to generate
highly situated reflection triggers that incorporate details of the
collaborative discussion happening in context. We discuss in depth the
exploration of the design space of the triggers and their correspondence with
the learning objectives as well as the impact on student learning in a pilot
study with 34 students.

摘要：大型語言模型 (LLM) 的優點在於其情境化能力，可根據學生的輸入（例如解題策略或先前的討論）提供不同的回應，以比標準回饋更有效地吸引學生。我們提出了一個概念驗證 LLM 應用程式的設計和評估，以提供學生動態且情境化的回饋。具體來說，我們擴充了大學雲端運算課程的線上程式練習機器人，加入了 ChatGPT，讓學生在資料庫設計的協作查詢最佳化任務中獲得情境化的反思觸發。我們證明了 LLM 可用於產生高度情境化的反思觸發，其中包含在情境中發生的協作討論的細節。我們深入探討了觸發設計空間的探索及其與學習目標的對應關係，以及在有 34 名學生的試點研究中對學生學習的影響。

##### **Mapping 'when'-clauses in Latin American and Caribbean languages: an experiment in subtoken-based typology**
2404.18257v1 by Nilo Pedrazzini

Languages can encode temporal subordination lexically, via subordinating
conjunctions, and morphologically, by marking the relation on the predicate.
Systematic cross-linguistic variation among the former can be studied using
well-established token-based typological approaches to token-aligned parallel
corpora. Variation among different morphological means is instead much harder
to tackle and therefore more poorly understood, despite being predominant in
several language groups. This paper explores variation in the expression of
generic temporal subordination ('when'-clauses) among the languages of Latin
America and the Caribbean, where morphological marking is particularly common.
It presents probabilistic semantic maps computed on the basis of the languages
of the region, thus avoiding bias towards the many world's languages that
exclusively use lexified connectors, incorporating associations between
character $n$-grams and English $when$. The approach allows capturing
morphological clause-linkage devices in addition to lexified connectors, paving
the way for larger-scale, strategy-agnostic analyses of typological variation
in temporal subordination.

摘要：語言可以透過從屬連接詞在字彙上編碼時間從屬關係，並透過在謂語上標示關係在形態上編碼時間從屬關係。透過使用已建立的基於標記的類型學方法來對齊標記對齊平行語料庫，可以研究前者的系統性跨語言變異。儘管在幾個語言群中佔主導地位，但不同形態手段之間的變異卻難以應對，因此了解較少。本文探討拉丁美洲和加勒比海語言中一般時間從屬關係（「when」子句）表達的變異，在這些語言中形態標記特別常見。它呈現基於該地區語言計算的機率語義圖，從而避免偏向於僅使用詞彙化連接詞的許多世界語言，並結合字元 $n$-gram 和英文 $when$ 之間的關聯。這種方法除了詞彙化連接詞之外，還能擷取形態句法連結裝置，為時間從屬關係中不依賴策略的大規模類型學變異分析鋪平道路。

##### **PatentGPT: A Large Language Model for Intellectual Property**
2404.18255v1 by Zilong Bai,Ruiji Zhang,Linqing Chen,Qijun Cai,Yuan Zhong,Cong Wang Yan Fang,Jie Fang,Jing Sun,Weikuan Wang,Lizhi Zhou,Haoran Hua Tian Qiu,Chaochao Wang,Cheng Sun,Jianping Lu,Yixin Wang,Yubin Xia Meng Hu,Haowen Liu,Peng Xu,Licong Xu,Fu Bian,Xiaolong Gu,Lisha Zhang Weilei Wang,Changyang Tu

In recent years, large language models have attracted significant attention
due to their exceptional performance across a multitude of natural language
process tasks, and have been widely applied in various fields. However, the
application of large language models in the Intellectual Property (IP) space is
challenging due to the strong need for specialized knowledge, privacy
protection, processing of extremely long text in this field. In this technical
report, we present for the first time a low-cost, standardized procedure for
training IP-oriented LLMs, meeting the unique requirements of the IP domain.
Using this standard process, we have trained the PatentGPT series models based
on open-source pretrained models. By evaluating them on the open-source
IP-oriented benchmark MOZIP, our domain-specific LLMs outperforms GPT-4,
indicating the effectiveness of the proposed training procedure and the
expertise of the PatentGPT models in the IP demain. What is impressive is that
our model significantly outperformed GPT-4 on the 2019 China Patent Agent
Qualification Examination by achieving a score of 65, reaching the level of
human experts. Additionally, the PatentGPT model, which utilizes the SMoE
architecture, achieves performance comparable to that of GPT-4 in the IP domain
and demonstrates a better cost-performance ratio on long-text tasks,
potentially serving as an alternative to GPT-4 within the IP domain.

摘要：近年來，大型語言模型因其在眾多自然語言處理任務中表現出色而備受關注，並已廣泛應用於各個領域。然而，由於在知識產權 (IP) 領域中對專業知識、隱私保護、處理極長篇幅文本有很強的需求，因此大型語言模型在知識產權領域的應用面臨挑戰。在技術報告中，我們首次提出了一種低成本、標準化的程序，用於訓練以知識產權為導向的大型語言模型，以滿足知識產權領域的獨特需求。使用此標準程序，我們根據開源預訓練模型訓練了 PatentGPT 系列模型。通過在開源以知識產權為導向的基準 MOZIP 上對它們進行評估，我們的特定於領域的大型語言模型優於 GPT-4，表明所提出的訓練程序的有效性以及 PatentGPT 模型在知識產權領域的專業知識。令人印象深刻的是，我們的模型在 2019 年中國專利代理人資格考試中以 65 分的成績顯著優於 GPT-4，達到了人類專家的水平。此外，採用 SMoE 架構的 PatentGPT 模型在知識產權領域實現了與 GPT-4 相當的性能，並在長文本任務中展示了更好的成本效益比，有可能在知識產權領域內作為 GPT-4 的替代方案。

##### **LEGENT: Open Platform for Embodied Agents**
2404.18243v1 by Zhili Cheng,Zhitong Wang,Jinyi Hu,Shengding Hu,An Liu,Yuge Tu,Pengkai Li,Lei Shi,Zhiyuan Liu,Maosong Sun

Despite advancements in Large Language Models (LLMs) and Large Multimodal
Models (LMMs), their integration into language-grounded, human-like embodied
agents remains incomplete, hindering complex real-life task performance in
physical environments. Existing integrations often feature limited open
sourcing, challenging collective progress in this field. We introduce LEGENT,
an open, scalable platform for developing embodied agents using LLMs and LMMs.
LEGENT offers a dual approach: a rich, interactive 3D environment with
communicable and actionable agents, paired with a user-friendly interface, and
a sophisticated data generation pipeline utilizing advanced algorithms to
exploit supervision from simulated worlds at scale. In our experiments, an
embryonic vision-language-action model trained on LEGENT-generated data
surpasses GPT-4V in embodied tasks, showcasing promising generalization
capabilities.

摘要：儘管大型語言模型 (LLM) 和大型多模態模型 (LMM) 有所進展，但它們與以語言為基礎、類似人類的具身代理整合仍不完備，阻礙了在物理環境中執行複雜的現實生活任務。現有的整合通常具有開放原始碼的限制，對此領域的集體進展構成挑戰。我們引入了 LEGENT，一個開放、可擴充的平台，用於使用 LLM 和 LMM 開發具身代理。LEGENT 提供了雙重方法：一個豐富、互動的 3D 環境，其中包含可溝通和可操作的代理，並配備一個使用者友善的介面，以及一個精密的資料產生管道，利用先進的演算法從模擬世界中大規模利用監督。在我們的實驗中，一個在 LEGENT 生成的資料上訓練的胚胎視覺語言動作模型超越了 GPT-4V 在具身任務中的表現，展示了有希望的泛化能力。

##### **SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning**
2404.18239v1 by Jinghan Jia,Yihua Zhang,Yimeng Zhang,Jiancheng Liu,Bharat Runwal,James Diffenderfer,Bhavya Kailkhura,Sijia Liu

Large Language Models (LLMs) have highlighted the necessity of effective
unlearning mechanisms to comply with data regulations and ethical AI practices.
LLM unlearning aims at removing undesired data influences and associated model
capabilities without compromising utility out of the scope of unlearning. While
interest in studying LLM unlearning is growing,the impact of the optimizer
choice for LLM unlearning remains under-explored. In this work, we shed light
on the significance of optimizer selection in LLM unlearning for the first
time, establishing a clear connection between {second-order optimization} and
influence unlearning (a classical approach using influence functions to update
the model for data influence removal). This insight propels us to develop a
second-order unlearning framework, termed SOUL, built upon the second-order
clipped stochastic optimization (Sophia)-based LLM training method. SOUL
extends the static, one-shot model update using influence unlearning to a
dynamic, iterative unlearning process. Our extensive experiments show that SOUL
consistently outperforms conventional first-order methods across various
unlearning tasks, models, and metrics, suggesting the promise of second-order
optimization in providing a scalable and easily implementable solution for LLM
unlearning.

摘要：大型語言模型 (LLM) 凸顯了有效取消學習機制以遵守資料法規和道德 AI 實務的必要性。
LLM 取消學習旨在移除不必要的資料影響和相關模型能力，而不會損害取消學習範圍外的效用。
雖然對研究 LLM 取消學習的興趣與日俱增，但最佳化器選擇對 LLM 取消學習的影響仍未獲得充分探討。
在這項工作中，我們首次闡明了最佳化器選擇在 LLM 取消學習中的重要性，在 {二階最佳化} 和影響取消學習之間建立了明確的關聯（一種使用影響函數來更新模型以移除資料影響的經典方法）。
這種見解驅使我們開發一個二階取消學習架構，稱為 SOUL，它建立在二階裁剪隨機最佳化 (Sophia) 為基礎的 LLM 訓練方法上。
SOUL 將使用影響取消學習的靜態、一次性模型更新延伸到動態、反覆的取消學習流程。
我們的廣泛實驗表明，SOUL 在各種取消學習任務、模型和指標中始終優於傳統的一階方法，這表明二階最佳化有望為 LLM 取消學習提供可擴充且易於實作的解決方案。

##### **From Persona to Personalization: A Survey on Role-Playing Language Agents**
2404.18231v1 by Jiangjie Chen,Xintao Wang,Rui Xu,Siyu Yuan,Yikai Zhang,Wei Shi,Jian Xie,Shuang Li,Ruihan Yang,Tinghui Zhu,Aili Chen,Nianqi Li,Lida Chen,Caiyu Hu,Siye Wu,Scott Ren,Ziquan Fu,Yanghua Xiao

Recent advancements in large language models (LLMs) have significantly
boosted the rise of Role-Playing Language Agents (RPLAs), i.e., specialized AI
systems designed to simulate assigned personas. By harnessing multiple advanced
abilities of LLMs, including in-context learning, instruction following, and
social intelligence, RPLAs achieve a remarkable sense of human likeness and
vivid role-playing performance. RPLAs can mimic a wide range of personas,
ranging from historical figures and fictional characters to real-life
individuals. Consequently, they have catalyzed numerous AI applications, such
as emotional companions, interactive video games, personalized assistants and
copilots, and digital clones. In this paper, we conduct a comprehensive survey
of this field, illustrating the evolution and recent progress in RPLAs
integrating with cutting-edge LLM technologies. We categorize personas into
three types: 1) Demographic Persona, which leverages statistical stereotypes;
2) Character Persona, focused on well-established figures; and 3)
Individualized Persona, customized through ongoing user interactions for
personalized services. We begin by presenting a comprehensive overview of
current methodologies for RPLAs, followed by the details for each persona type,
covering corresponding data sourcing, agent construction, and evaluation.
Afterward, we discuss the fundamental risks, existing limitations, and future
prospects of RPLAs. Additionally, we provide a brief review of RPLAs in AI
applications, which reflects practical user demands that shape and drive RPLA
research. Through this work, we aim to establish a clear taxonomy of RPLA
research and applications, and facilitate future research in this critical and
ever-evolving field, and pave the way for a future where humans and RPLAs
coexist in harmony.

摘要：<paragraph>大型語言模型 (LLM) 的最新進展顯著提升了角色扮演語言代理 (RPLA) 的崛起，也就是專門設計用來模擬指定角色的 AI 系統。透過運用 LLM 的多種進階能力，包括情境學習、指令遵循和社交智慧，RPLA 達到了顯著的人類相似度和生動的角色扮演表現。RPLA 能夠模仿廣泛的角色，從歷史人物和虛構角色到現實生活中的個人。因此，催化了許多 AI 應用程式，例如情緒伴侶、互動式電玩遊戲、個人化助理和副駕駛，以及數位分身。在本文中，我們對這個領域進行全面的調查，說明 RPLA 與尖端 LLM 技術整合的演進和最新進展。我們將角色分為三種類型：1) 人口統計角色，利用統計刻板印象；2) 角色角色，專注於著名的角色；3) 個人化角色，透過持續的使用者互動進行客製化，以提供個人化服務。我們首先提出 RPLA 目前方法的全面概述，接著說明每種類型的角色，涵蓋對應的資料來源、代理建構和評估。之後，我們討論 RPLA 的基本風險、現有限制和未來前景。此外，我們簡要回顧 AI 應用程式中的 RPLA，這反映了形塑和推動 RPLA 研究的實際使用者需求。透過這項工作，我們旨在建立 RPLA 研究和應用程式的明確分類法，並促進這個關鍵且不斷演進的領域的未來研究，並為人類與 RPLA 和諧共存的未來鋪路。</paragraph>

##### **TextGram: Towards a better domain-adaptive pretraining**
2404.18228v1 by Sharayu Hiwarkhedkar,Saloni Mittal,Vidula Magdum,Omkar Dhekane,Raviraj Joshi,Geetanjali Kale,Arnav Ladkat

For green AI, it is crucial to measure and reduce the carbon footprint
emitted during the training of large language models. In NLP, performing
pre-training on Transformer models requires significant computational
resources. This pre-training involves using a large amount of text data to gain
prior knowledge for performing downstream tasks. Thus, it is important that we
select the correct data in the form of domain-specific data from this vast
corpus to achieve optimum results aligned with our domain-specific tasks. While
training on large unsupervised data is expensive, it can be optimized by
performing a data selection step before pretraining. Selecting important data
reduces the space overhead and the substantial amount of time required to
pre-train the model while maintaining constant accuracy. We investigate the
existing selection strategies and propose our own domain-adaptive data
selection method - TextGram - that effectively selects essential data from
large corpora. We compare and evaluate the results of finetuned models for text
classification task with and without data selection. We show that the proposed
strategy works better compared to other selection methods.

摘要：對於綠色 AI 而言，衡量和減少大型語言模型訓練期間所排放的碳足跡至關重要。在 NLP 中，在 Transformer 模型上執行預訓練需要大量的運算資源。此預訓練涉及使用大量的文字資料，以獲得執行下游任務的先備知識。因此，重要的是我們從這個龐大的語料庫中選擇正確的資料，以特定領域的資料形式，以達成與我們特定領域任務相符的最佳結果。雖然針對大量非監督資料進行訓練很昂貴，但可以在預訓練之前執行資料選擇步驟進行最佳化。選擇重要的資料可減少空間開銷和預訓練模型所需的大量時間，同時維持恆定的準確度。我們調查現有的選擇策略，並提出我們自己的領域適應資料選擇方法 - TextGram - 可有效從大型語料庫中選擇必要的資料。我們比較並評估微調模型在有和沒有資料選擇的文字分類任務中的結果。我們證明所提出的策略與其他選擇方法相比，表現得更好。

##### **L3Cube-MahaNews: News-based Short Text and Long Document Classification Datasets in Marathi**
2404.18216v1 by Saloni Mittal,Vidula Magdum,Omkar Dhekane,Sharayu Hiwarkhedkar,Raviraj Joshi

The availability of text or topic classification datasets in the low-resource
Marathi language is limited, typically consisting of fewer than 4 target
labels, with some achieving nearly perfect accuracy. In this work, we introduce
L3Cube-MahaNews, a Marathi text classification corpus that focuses on News
headlines and articles. This corpus stands out as the largest supervised
Marathi Corpus, containing over 1.05L records classified into a diverse range
of 12 categories. To accommodate different document lengths, MahaNews comprises
three supervised datasets specifically designed for short text, long documents,
and medium paragraphs. The consistent labeling across these datasets
facilitates document length-based analysis. We provide detailed data statistics
and baseline results on these datasets using state-of-the-art pre-trained BERT
models. We conduct a comparative analysis between monolingual and multilingual
BERT models, including MahaBERT, IndicBERT, and MuRIL. The monolingual MahaBERT
model outperforms all others on every dataset. These resources also serve as
Marathi topic classification datasets or models and are publicly available at
https://github.com/l3cube-pune/MarathiNLP .

摘要：低資源馬拉地語語言中可用於文字或主題分類的資料集有限，通常包含少於 4 個目標標籤，有些標籤的準確度接近完美。在此工作中，我們引入了 L3Cube-MahaNews，這是一個馬拉地語文字分類語料庫，專注於新聞標題和文章。此語料庫是最大的監督式馬拉地語語料庫，包含超過 1.05L 條記錄，分類為 12 個類別。為了適應不同的文件長度，MahaNews 包含三個監督式資料集，專門針對短文字、長文件和中等長度的段落設計。這些資料集中一致的標籤便於基於文件長度的分析。我們使用最先進的預訓練 BERT 模型提供這些資料集的詳細資料統計和基準結果。我們對單語和多語 BERT 模型（包括 MahaBERT、IndicBERT 和 MuRIL）進行了比較分析。單語 MahaBERT 模型在每個資料集上的表現都優於其他模型。這些資源還可用作馬拉地語主題分類資料集或模型，並在 https://github.com/l3cube-pune/MarathiNLP 公開提供。

##### **Contrastive Learning Method for Sequential Recommendation based on Multi-Intention Disentanglement**
2404.18214v1 by Zeyu Hu,Yuzhi Xiao,Tao Huang,Xuanrong Huo

Sequential recommendation is one of the important branches of recommender
system, aiming to achieve personalized recommended items for the future through
the analysis and prediction of users' ordered historical interactive behaviors.
However, along with the growth of the user volume and the increasingly rich
behavioral information, how to understand and disentangle the user's
interactive multi-intention effectively also poses challenges to behavior
prediction and sequential recommendation. In light of these challenges, we
propose a Contrastive Learning sequential recommendation method based on
Multi-Intention Disentanglement (MIDCL). In our work, intentions are recognized
as dynamic and diverse, and user behaviors are often driven by current
multi-intentions, which means that the model needs to not only mine the most
relevant implicit intention for each user, but also impair the influence from
irrelevant intentions. Therefore, we choose Variational Auto-Encoder (VAE) to
realize the disentanglement of users' multi-intentions, and propose two types
of contrastive learning paradigms for finding the most relevant user's
interactive intention, and maximizing the mutual information of positive sample
pairs, respectively. Experimental results show that MIDCL not only has
significant superiority over most existing baseline methods, but also brings a
more interpretable case to the research about intention-based prediction and
recommendation.

摘要：序列推薦是推薦系統的重要分支之一，旨在通過分析和預測用戶的歷史交互行為，為未來實現個性化的推薦項目。然而，隨著用戶量的增長和行為信息的日益豐富，如何理解和有效解開用戶的交互多意圖也對行為預測和序列推薦提出了挑戰。針對這些挑戰，我們提出了一種基於多意圖解糾纏（MIDCL）的對比學習序列推薦方法。在我們的研究中，意圖被認為是動態且多樣的，用戶行為通常由當前的多意圖驅動，這意味著模型不僅需要挖掘每個用戶最相關的隱含意圖，還要削弱無關意圖的影響。因此，我們選擇變分自動編碼器（VAE）來實現用戶多意圖的解糾纏，並提出了兩種對比學習範例，分別用於發現最相關的用戶交互意圖，並最大化正樣本對的互信息。實驗結果表明，MIDCL 不僅對大多數現有基線方法具有顯著的優越性，而且為基於意圖的預測和推薦的研究帶來了更具可解釋性的案例。

##### **S$^2$Mamba: A Spatial-spectral State Space Model for Hyperspectral Image Classification**
2404.18213v1 by Guanchun Wang,Xiangrong Zhang,Zelin Peng,Tianyang Zhang,Xiuping Jia,Licheng Jiao

Land cover analysis using hyperspectral images (HSI) remains an open problem
due to their low spatial resolution and complex spectral information. Recent
studies are primarily dedicated to designing Transformer-based architectures
for spatial-spectral long-range dependencies modeling, which is computationally
expensive with quadratic complexity. Selective structured state space model
(Mamba), which is efficient for modeling long-range dependencies with linear
complexity, has recently shown promising progress. However, its potential in
hyperspectral image processing that requires handling numerous spectral bands
has not yet been explored. In this paper, we innovatively propose S$^2$Mamba, a
spatial-spectral state space model for hyperspectral image classification, to
excavate spatial-spectral contextual features, resulting in more efficient and
accurate land cover analysis. In S$^2$Mamba, two selective structured state
space models through different dimensions are designed for feature extraction,
one for spatial, and the other for spectral, along with a spatial-spectral
mixture gate for optimal fusion. More specifically, S$^2$Mamba first captures
spatial contextual relations by interacting each pixel with its adjacent
through a Patch Cross Scanning module and then explores semantic information
from continuous spectral bands through a Bi-directional Spectral Scanning
module. Considering the distinct expertise of the two attributes in homogenous
and complicated texture scenes, we realize the Spatial-spectral Mixture Gate by
a group of learnable matrices, allowing for the adaptive incorporation of
representations learned across different dimensions. Extensive experiments
conducted on HSI classification benchmarks demonstrate the superiority and
prospect of S$^2$Mamba. The code will be available at:
https://github.com/PURE-melo/S2Mamba.

摘要：使用高光谱图像 (HSI) 的土地覆盖分析仍然是一个悬而未决的问题，因为它们的空间分辨率低且光谱信息复杂。最近的研究主要致力于设计基于 Transformer 的架构，用于建模空间光谱远程依赖性，这在计算上很昂贵，具有二次复杂度。选择性结构状态空间模型 (Mamba) 对于使用线性复杂度建模远程依赖性很有效，最近显示出了有希望的进展。然而，它在需要处理大量光谱波段的高光谱图像处理中的潜力尚未得到探索。在本文中，我们创新性地提出了 S$^2$Mamba，一种用于高光谱图像分类的空间光谱状态空间模型，以挖掘空间光谱上下文特征，从而实现更高效、更准确的土地覆盖分析。在 S$^2$Mamba 中，通过不同的维度设计了两个选择性结构状态空间模型用于特征提取，一个用于空间，另一个用于光谱，以及一个用于最佳融合的空间光谱混合门。更具体地说，S$^2$Mamba 首先通过 Patch Cross Scanning 模块使每个像素与其相邻像素交互来捕获空间上下文关系，然后通过双向光谱扫描模块探索连续光谱波段的语义信息。考虑到两种属性在均匀和复杂纹理场景中的独特专业知识，我们通过一组可学习矩阵实现了空间光谱混合门，从而允许自适应地合并跨不同维度学习的表示。在 HSI 分类基准上进行的广泛实验证明了 S$^2$Mamba 的优越性和前景。代码将在以下位置提供：
https://github.com/PURE-melo/S2Mamba。

##### **Paint by Inpaint: Learning to Add Image Objects by Removing Them First**
2404.18212v1 by Navve Wasserman,Noam Rotstein,Roy Ganz,Ron Kimmel

Image editing has advanced significantly with the introduction of
text-conditioned diffusion models. Despite this progress, seamlessly adding
objects to images based on textual instructions without requiring user-provided
input masks remains a challenge. We address this by leveraging the insight that
removing objects (Inpaint) is significantly simpler than its inverse process of
adding them (Paint), attributed to the utilization of segmentation mask
datasets alongside inpainting models that inpaint within these masks.
Capitalizing on this realization, by implementing an automated and extensive
pipeline, we curate a filtered large-scale image dataset containing pairs of
images and their corresponding object-removed versions. Using these pairs, we
train a diffusion model to inverse the inpainting process, effectively adding
objects into images. Unlike other editing datasets, ours features natural
target images instead of synthetic ones; moreover, it maintains consistency
between source and target by construction. Additionally, we utilize a large
Vision-Language Model to provide detailed descriptions of the removed objects
and a Large Language Model to convert these descriptions into diverse,
natural-language instructions. We show that the trained model surpasses
existing ones both qualitatively and quantitatively, and release the
large-scale dataset alongside the trained models for the community.

摘要：隨著文字條件擴散模型的引入，影像編輯已大幅進展。儘管有這些進展，根據文字說明無縫地將物件加入影像中，而不需要使用者提供的輸入遮罩仍然是一項挑戰。我們透過利用移除物件（修復）明顯比其反向過程（繪製）簡單的見解來解決這個問題，這歸因於利用分割遮罩資料集以及在這些遮罩內修復的修復模型。透過實作自動化且廣泛的管線來利用這個發現，我們策劃一個經過篩選的大型影像資料集，其中包含成對的影像及其對應的移除物件版本。使用這些成對的資料，我們訓練一個擴散模型來反轉修復過程，有效地將物件加入影像中。與其他編輯資料集不同，我們的資料集採用自然目標影像，而非合成影像；此外，它透過建構來維持來源和目標之間的一致性。此外，我們利用一個大型視覺語言模型來提供移除物件的詳細描述，並利用一個大型語言模型將這些描述轉換為多樣化的自然語言說明。我們展示訓練好的模型在質量和數量上都超越現有的模型，並釋出大型資料集以及訓練好的模型供社群使用。

##### **LMM-PCQA: Assisting Point Cloud Quality Assessment with LMM**
2404.18203v1 by Zicheng Zhang,Haoning Wu,Yingjie Zhou,Chunyi Li,Wei Sun,Chaofeng Chen,Xiongkuo Min,Xiaohong Liu,Weisi Lin,Guangtao Zhai

Although large multi-modality models (LMMs) have seen extensive exploration
and application in various quality assessment studies, their integration into
Point Cloud Quality Assessment (PCQA) remains unexplored. Given LMMs'
exceptional performance and robustness in low-level vision and quality
assessment tasks, this study aims to investigate the feasibility of imparting
PCQA knowledge to LMMs through text supervision. To achieve this, we transform
quality labels into textual descriptions during the fine-tuning phase, enabling
LMMs to derive quality rating logits from 2D projections of point clouds. To
compensate for the loss of perception in the 3D domain, structural features are
extracted as well. These quality logits and structural features are then
combined and regressed into quality scores. Our experimental results affirm the
effectiveness of our approach, showcasing a novel integration of LMMs into PCQA
that enhances model understanding and assessment accuracy. We hope our
contributions can inspire subsequent investigations into the fusion of LMMs
with PCQA, fostering advancements in 3D visual quality analysis and beyond.

摘要：儘管大型多模態模型 (LMM) 已在各種品質評估研究中廣泛探索和應用，但它們整合到點雲品質評估 (PCQA) 中仍未探索。鑑於 LMM 在低階視覺和品質評估任務中表現出色的效能和穩健性，本研究旨在探討透過文字監督將 PCQA 知識傳授給 LMM 的可行性。為此，我們在微調階段將品質標籤轉換為文字描述，使 LMM 能夠從點雲的 2D 投影中推導出品質評分邏輯。為了彌補 3D 領域中感知的損失，也提取了結構特徵。然後將這些品質邏輯和結構特徵結合並回歸到品質分數中。我們的實驗結果肯定了我們方法的有效性，展示了 LMM 與 PCQA 的創新整合，增強了模型理解和評估準確性。我們希望我們的貢獻能激勵後續對 LMM 與 PCQA 融合的研究，促進 3D 視覺品質分析及其他領域的進步。

##### **WorldGPT: Empowering LLM as Multimodal World Model**
2404.18202v1 by Zhiqi Ge,Hongzhe Huang,Mingze Zhou,Juncheng Li,Guoming Wang,Siliang Tang,Yueting Zhuang

World models are progressively being employed across diverse fields,
extending from basic environment simulation to complex scenario construction.
However, existing models are mainly trained on domain-specific states and
actions, and confined to single-modality state representations. In this paper,
We introduce WorldGPT, a generalist world model built upon Multimodal Large
Language Model (MLLM). WorldGPT acquires an understanding of world dynamics
through analyzing millions of videos across various domains. To further enhance
WorldGPT's capability in specialized scenarios and long-term tasks, we have
integrated it with a novel cognitive architecture that combines memory
offloading, knowledge retrieval, and context reflection. As for evaluation, we
build WorldNet, a multimodal state transition prediction benchmark encompassing
varied real-life scenarios. Conducting evaluations on WorldNet directly
demonstrates WorldGPT's capability to accurately model state transition
patterns, affirming its effectiveness in understanding and predicting the
dynamics of complex scenarios. We further explore WorldGPT's emerging potential
in serving as a world simulator, helping multimodal agents generalize to
unfamiliar domains through efficiently synthesising multimodal instruction
instances which are proved to be as reliable as authentic data for fine-tuning
purposes. The project is available on
\url{https://github.com/DCDmllm/WorldGPT}.

摘要：世界模型正逐步應用於各個領域，
從基本的環境模擬到複雜的場景建構。
然而，現有的模型主要訓練於特定領域的狀態和
動作，並侷限於單一模態狀態表示。在本文中，
我們介紹 WorldGPT，一個建立在多模態大型
語言模型 (MLLM) 上的泛用世界模型。WorldGPT 通過
分析跨越各種領域的數百萬個影片來獲取對世界動態的理解。為了進一步增強
WorldGPT 在特定場景和長期任務中的能力，我們
已將其與一種新穎的認知架構整合在一起，該架構結合了記憶
卸載、知識檢索和情境反射。至於評估，我們
建立了 WorldNet，一個多模態狀態轉換預測基準，包含
各種現實生活場景。在 WorldNet 上進行評估直接
展示了 WorldGPT 精確建模狀態轉換
模式的能力，肯定了其在理解和預測
複雜場景的動態方面的有效性。我們進一步探索了 WorldGPT 作為世界模擬器的潛力，幫助多模態代理概化到
不熟悉的領域，通過有效地綜合多模態指令
實例，這些實例被證明與真實數據一樣可靠，可用於微調
目的。該專案可在
\url{https://github.com/DCDmllm/WorldGPT} 上取得。

##### **Exploring the Robustness of In-Context Learning with Noisy Labels**
2404.18191v1 by Chen Cheng,Xinzhi Yu,Haodong Wen,Jinsong Sun,Guanzhang Yue,Yihao Zhang,Zeming Wei

Recently, the mysterious In-Context Learning (ICL) ability exhibited by
Transformer architectures, especially in large language models (LLMs), has
sparked significant research interest. However, the resilience of Transformers'
in-context learning capabilities in the presence of noisy samples, prevalent in
both training corpora and prompt demonstrations, remains underexplored. In this
paper, inspired by prior research that studies ICL ability using simple
function classes, we take a closer look at this problem by investigating the
robustness of Transformers against noisy labels. Specifically, we first conduct
a thorough evaluation and analysis of the robustness of Transformers against
noisy labels during in-context learning and show that they exhibit notable
resilience against diverse types of noise in demonstration labels. Furthermore,
we delve deeper into this problem by exploring whether introducing noise into
the training set, akin to a form of data augmentation, enhances such robustness
during inference, and find that such noise can indeed improve the robustness of
ICL. Overall, our fruitful analysis and findings provide a comprehensive
understanding of the resilience of Transformer models against label noises
during ICL and provide valuable insights into the research on Transformers in
natural language processing. Our code is available at
https://github.com/InezYu0928/in-context-learning.

摘要：最近，Transformer 架構，特別是在大型語言模型 (LLM) 中展現的神秘語境學習 (ICL) 能力已經引起顯著的研究興趣。然而，Transformer 的語境學習能力在存在於訓練語料庫和提示演示中的大量雜訊樣本的情況下的復原力仍然未被充分探討。在本文中，受到先前研究的啟發，這些研究使用簡單函數類別來研究 ICL 能力，我們透過探討 Transformer 對雜訊標籤的穩健性來更仔細地探討這個問題。具體來說，我們首先對 Transformer 在語境學習期間對雜訊標籤的穩健性進行徹底的評估和分析，並顯示出它們對示範標籤中不同類型的雜訊表現出顯著的復原力。此外，我們通過探討將雜訊引入訓練集（類似於一種資料擴充）是否會增強這種復原力，深入探討這個問題，並發現這種雜訊確實可以改善 ICL 的穩健性。總體而言，我們富有成果的分析和發現提供了 Transformer 模型在 ICL 期間對標籤雜訊的復原力的全面理解，並為自然語言處理中 Transformer 的研究提供了寶貴的見解。我們的程式碼可在 https://github.com/InezYu0928/in-context-learning 取得。

##### **Ranked List Truncation for Large Language Model-based Re-Ranking**
2404.18185v1 by Chuan Meng,Negar Arabzadeh,Arian Askari,Mohammad Aliannejadi,Maarten de Rijke

We study ranked list truncation (RLT) from a novel "retrieve-then-re-rank"
perspective, where we optimize re-ranking by truncating the retrieved list
(i.e., trim re-ranking candidates). RLT is crucial for re-ranking as it can
improve re-ranking efficiency by sending variable-length candidate lists to a
re-ranker on a per-query basis. It also has the potential to improve re-ranking
effectiveness. Despite its importance, there is limited research into applying
RLT methods to this new perspective. To address this research gap, we reproduce
existing RLT methods in the context of re-ranking, especially newly emerged
large language model (LLM)-based re-ranking. In particular, we examine to what
extent established findings on RLT for retrieval are generalizable to the
"retrieve-then-re-rank" setup from three perspectives: (i) assessing RLT
methods in the context of LLM-based re-ranking with lexical first-stage
retrieval, (ii) investigating the impact of different types of first-stage
retrievers on RLT methods, and (iii) investigating the impact of different
types of re-rankers on RLT methods. We perform experiments on the TREC 2019 and
2020 deep learning tracks, investigating 8 RLT methods for pipelines involving
3 retrievers and 2 re-rankers. We reach new insights into RLT methods in the
context of re-ranking.

摘要：<paragraph>我們從創新的「先擷取再重新排序」觀點研究排名清單截斷 (RLT)，我們透過截斷擷取清單（即修剪重新排序候選項）來最佳化重新排序。RLT 對重新排序至關重要，因為它可以透過將長度可變的候選清單依據每次查詢傳送給重新排序器，來提升重新排序效率。它也有可能提升重新排序效果。儘管它很重要，但應用 RLT 方法到這個新觀點的研究有限。為了解決這個研究差距，我們在重新排序的脈絡中重現現有的 RLT 方法，特別是新興的大型語言模型 (LLM) 為基礎的重新排序。特別是，我們探討 RLT 的既有研究結果在多大程度上可以推廣到「先擷取再重新排序」的設定，從三個觀點來看：(i) 評估 RLT 方法在基於 LLM 的重新排序脈絡中，搭配詞彙第一階段擷取，(ii) 調查不同類型第一階段擷取器對 RLT 方法的影響，以及 (iii) 調查不同類型重新排序器對 RLT 方法的影響。我們在 TREC 2019 和 2020 深度學習軌道上執行實驗，調查 8 種 RLT 方法，以涉及 3 個擷取器和 2 個重新排序器的管道。我們在重新排序的脈絡中獲得 RLT 方法的新見解。</paragraph>

##### **EkoHate: Abusive Language and Hate Speech Detection for Code-switched Political Discussions on Nigerian Twitter**
2404.18180v1 by Comfort Eseohen Ilevbare,Jesujoba O. Alabi,David Ifeoluwa Adelani,Firdous Damilola Bakare,Oluwatoyin Bunmi Abiola,Oluwaseyi Adesina Adeyemo

Nigerians have a notable online presence and actively discuss political and
topical matters. This was particularly evident throughout the 2023 general
election, where Twitter was used for campaigning, fact-checking and
verification, and even positive and negative discourse. However, little or none
has been done in the detection of abusive language and hate speech in Nigeria.
In this paper, we curated code-switched Twitter data directed at three
musketeers of the governorship election on the most populous and economically
vibrant state in Nigeria; Lagos state, with the view to detect offensive speech
in political discussions. We developed EkoHate -- an abusive language and hate
speech dataset for political discussions between the three candidates and their
followers using a binary (normal vs offensive) and fine-grained four-label
annotation scheme. We analysed our dataset and provided an empirical evaluation
of state-of-the-art methods across both supervised and cross-lingual transfer
learning settings. In the supervised setting, our evaluation results in both
binary and four-label annotation schemes show that we can achieve 95.1 and 70.3
F1 points respectively. Furthermore, we show that our dataset adequately
transfers very well to three publicly available offensive datasets (OLID,
HateUS2020, and FountaHate), generalizing to political discussions in other
regions like the US.

摘要：奈及利亞網路上有顯著的存在，並積極討論政治和時事議題。這在 2023 年的普選中特別明顯，推特用於競選、事實查核和驗證，甚至正面和負面的討論。然而，在奈及利亞偵測辱罵性語言和仇恨言論方面，幾乎沒有或根本沒有作為。在本文中，我們整理了針對奈及利亞人口最多、經濟最活躍的拉各斯州州長選舉的三位候選人的代碼轉換推特資料，目的是偵測政治討論中的攻擊性言論。我們開發了 EkoHate，一個針對三位候選人及其追隨者之間的政治討論的辱罵性語言和仇恨言論資料集，使用二元（正常與攻擊性）和細緻的四標籤註解方案。我們分析了我們的資料集，並對監督式和跨語言轉移學習設定中的最先進方法提供了經驗評估。在監督式設定中，我們的評估結果在二元和四標籤註解方案中顯示，我們分別可以達到 95.1 和 70.3 的 F1 點數。此外，我們表明我們的資料集充分轉移到三個公開可用的攻擊性資料集（OLID、HateUS2020 和 FountaHate），推廣到美國等其他地區的政治討論。

