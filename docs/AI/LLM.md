
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-02-07**|**MELON: Indirect Prompt Injection Defense via Masked Re-execution and Tool Comparison**|Kaijie Zhu et.al.|[2502.05174v1](http://arxiv.org/abs/2502.05174v1)|null|
|**2025-02-07**|**Joint MoE Scaling Laws: Mixture of Experts Can Be Memory Efficient**|Jan Ludziejewski et.al.|[2502.05172v1](http://arxiv.org/abs/2502.05172v1)|null|
|**2025-02-07**|**Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach**|Jonas Geiping et.al.|[2502.05171v1](http://arxiv.org/abs/2502.05171v1)|null|
|**2025-02-07**|**NoLiMa: Long-Context Evaluation Beyond Literal Matching**|Ali Modarressi et.al.|[2502.05167v1](http://arxiv.org/abs/2502.05167v1)|null|
|**2025-02-07**|**DuoGuard: A Two-Player RL-Driven Framework for Multilingual LLM Guardrails**|Yihe Deng et.al.|[2502.05163v1](http://arxiv.org/abs/2502.05163v1)|null|
|**2025-02-07**|**A Lightweight Method to Disrupt Memorized Sequences in LLM**|Parjanya Prajakta Prashant et.al.|[2502.05159v1](http://arxiv.org/abs/2502.05159v1)|null|
|**2025-02-07**|**Transforming Science with Large Language Models: A Survey on AI-assisted Scientific Discovery, Experimentation, Content Generation, and Evaluation**|Steffen Eger et.al.|[2502.05151v1](http://arxiv.org/abs/2502.05151v1)|null|
|**2025-02-07**|**CodeSCM: Causal Analysis for Multi-Modal Code Generation**|Mukur Gupta et.al.|[2502.05150v1](http://arxiv.org/abs/2502.05150v1)|null|
|**2025-02-07**|**An Annotated Reading of 'The Singer of Tales' in the LLM Era**|Kush R. Varshney et.al.|[2502.05148v1](http://arxiv.org/abs/2502.05148v1)|null|
|**2025-02-07**|**LP-DETR: Layer-wise Progressive Relations for Object Detection**|Zhengjian Kang et.al.|[2502.05147v1](http://arxiv.org/abs/2502.05147v1)|null|
|**2025-02-07**|**Latent Swap Joint Diffusion for Long-Form Audio Generation**|Yusheng Dai et.al.|[2502.05130v1](http://arxiv.org/abs/2502.05130v1)|null|
|**2025-02-07**|**"It Felt Like I Was Left in the Dark": Exploring Information Needs and Design Opportunities for Family Caregivers of Older Adult Patients in Critical Care Settings**|Shihan Fu et.al.|[2502.05115v1](http://arxiv.org/abs/2502.05115v1)|null|
|**2025-02-07**|**GiesKaNe: Bridging Past and Present in Grammatical Theory and Practical Application**|Volker Emmrich et.al.|[2502.05113v1](http://arxiv.org/abs/2502.05113v1)|null|
|**2025-02-07**|**Flexible and Efficient Grammar-Constrained Decoding**|Kanghee Park et.al.|[2502.05111v1](http://arxiv.org/abs/2502.05111v1)|null|
|**2025-02-07**|**ApplE: An Applied Ethics Ontology with Event Context**|Aisha Aijaz et.al.|[2502.05110v1](http://arxiv.org/abs/2502.05110v1)|null|
|**2025-02-07**|**Leveraging Hypernetworks and Learnable Kernels for Consumer Energy Forecasting Across Diverse Consumer Types**|Muhammad Umair Danish et.al.|[2502.05104v1](http://arxiv.org/abs/2502.05104v1)|null|
|**2025-02-07**|**Learning Temporal Invariance in Android Malware Detectors**|Xinran Zheng et.al.|[2502.05098v1](http://arxiv.org/abs/2502.05098v1)|null|
|**2025-02-07**|**Lost in Time: Clock and Calendar Understanding Challenges in Multimodal LLMs**|Rohit Saxena et.al.|[2502.05092v1](http://arxiv.org/abs/2502.05092v1)|null|
|**2025-02-07**|**Mitigating Unintended Memorization with LoRA in Federated Learning for LLMs**|Thierry Bossy et.al.|[2502.05087v1](http://arxiv.org/abs/2502.05087v1)|null|
|**2025-02-07**|**Causality can systematically address the monsters under the bench(marks)**|Felix Leeb et.al.|[2502.05085v1](http://arxiv.org/abs/2502.05085v1)|null|
|**2025-02-07**|**ChallengeMe: An Adversarial Learning-enabled Text Summarization Framework**|Xiaoyu Deng et.al.|[2502.05084v1](http://arxiv.org/abs/2502.05084v1)|null|
|**2025-02-07**|**Adaptive Graph of Thoughts: Test-Time Adaptive Reasoning Unifying Chain, Tree, and Graph Structures**|Tushar Pandey et.al.|[2502.05078v1](http://arxiv.org/abs/2502.05078v1)|null|
|**2025-02-07**|**Paying Attention to Facts: Quantifying the Knowledge Capacity of Attention Layers**|Liang Ze Wong et.al.|[2502.05076v1](http://arxiv.org/abs/2502.05076v1)|null|
|**2025-02-07**|**Preference-aware compensation policies for crowdsourced on-demand services**|Georgina Nouli et.al.|[2502.05060v1](http://arxiv.org/abs/2502.05060v1)|null|
|**2025-02-07**|**Federated Learning for Anomaly Detection in Energy Consumption Data: Assessing the Vulnerability to Adversarial Attacks**|Yohannis Kifle Telila et.al.|[2502.05041v1](http://arxiv.org/abs/2502.05041v1)|null|
|**2025-02-07**|**nvAgent: Automated Data Visualization from Natural Language via Collaborative Agent Workflow**|Geliang Ouyang et.al.|[2502.05036v1](http://arxiv.org/abs/2502.05036v1)|null|
|**2025-02-07**|**Analyzing Advanced AI Systems Against Definitions of Life and Consciousness**|Azadeh Alavi et.al.|[2502.05007v1](http://arxiv.org/abs/2502.05007v1)|null|
|**2025-02-07**|**A New Paradigm in Tuning Learned Indexes: A Reinforcement Learning Enhanced Approach**|Taiyi Wang et.al.|[2502.05001v1](http://arxiv.org/abs/2502.05001v1)|null|
|**2025-02-07**|**Robust Graph Learning Against Adversarial Evasion Attacks via Prior-Free Diffusion-Based Structure Purification**|Jiayi Luo et.al.|[2502.05000v1](http://arxiv.org/abs/2502.05000v1)|null|
|**2025-02-07**|**Aligning Black-box Language Models with Human Judgments**|Gerrit J. J. van den Burg et.al.|[2502.04997v1](http://arxiv.org/abs/2502.04997v1)|null|
|**2025-02-07**|**CoCoA: A Generalized Approach to Uncertainty Quantification by Integrating Confidence and Consistency of LLM Outputs**|Roman Vashurin et.al.|[2502.04964v1](http://arxiv.org/abs/2502.04964v1)|null|
|**2025-02-07**|**Fast Adaptive Anti-Jamming Channel Access via Deep Q Learning and Coarse-Grained Spectrum Prediction**|Jianshu Zhang et.al.|[2502.04963v1](http://arxiv.org/abs/2502.04963v1)|null|
|**2025-02-07**|**Commonality and Individuality! Integrating Humor Commonality with Speaker Individuality for Humor Recognition**|Haohao Zhu et.al.|[2502.04960v1](http://arxiv.org/abs/2502.04960v1)|null|
|**2025-02-07**|**SSMLoRA: Enhancing Low-Rank Adaptation with State Space Model**|Jiayang Yu et.al.|[2502.04958v1](http://arxiv.org/abs/2502.04958v1)|null|
|**2025-02-07**|**Claim Extraction for Fact-Checking: Data, Models, and Automated Metrics**|Herbert Ullrich et.al.|[2502.04955v1](http://arxiv.org/abs/2502.04955v1)|null|
|**2025-02-07**|**The Rising Threat to Emerging AI-Powered Search Engines**|Zeren Luo et.al.|[2502.04951v1](http://arxiv.org/abs/2502.04951v1)|null|
|**2025-02-07**|**Conformal Prediction for Electricity Price Forecasting in the Day-Ahead and Real-Time Balancing Market**|Ciaran O'Connor et.al.|[2502.04935v1](http://arxiv.org/abs/2502.04935v1)|null|
|**2025-02-07**|**Cached Multi-Lora Composition for Multi-Concept Image Generation**|Xiandong Zou et.al.|[2502.04923v1](http://arxiv.org/abs/2502.04923v1)|null|
|**2025-02-07**|**Unified Approaches in Self-Supervised Event Stream Modeling: Progress and Prospects**|Levente Zólyomi et.al.|[2502.04899v1](http://arxiv.org/abs/2502.04899v1)|null|
|**2025-02-07**|**Evaluating Standard and Dialectal Frisian ASR: Multilingual Fine-tuning and Language Identification for Improved Low-resource Performance**|Reihaneh Amooie et.al.|[2502.04883v1](http://arxiv.org/abs/2502.04883v1)|null|
|**2025-02-07**|**pytopicgram: A library for data extraction and topic modeling from Telegram channels**|J. Gómez-Romero et.al.|[2502.04882v1](http://arxiv.org/abs/2502.04882v1)|null|
|**2025-02-07**|**Sparse Autoencoders Do Not Find Canonical Units of Analysis**|Patrick Leask et.al.|[2502.04878v1](http://arxiv.org/abs/2502.04878v1)|null|
|**2025-02-07**|**Enhancing Disinformation Detection with Explainable AI and Named Entity Replacement**|Santiago González-Silot et.al.|[2502.04863v1](http://arxiv.org/abs/2502.04863v1)|null|
|**2025-02-07**|**Lightweight Operations for Visual Speech Recognition**|Iason Ioannis Panagos et.al.|[2502.04834v1](http://arxiv.org/abs/2502.04834v1)|null|
|**2025-02-07**|**Optimistic Gradient Learning with Hessian Corrections for High-Dimensional Black-Box Optimization**|Yedidya Kfir et.al.|[2502.04829v1](http://arxiv.org/abs/2502.04829v1)|null|
|**2025-02-07**|**Self-Rationalization in the Wild: A Large Scale Out-of-Distribution Evaluation on NLI-related tasks**|Jing Yang et.al.|[2502.04797v1](http://arxiv.org/abs/2502.04797v1)|null|
|**2025-02-07**|**Developmentally-plausible Working Memory Shapes a Critical Period for Language Acquisition**|Masato Mita et.al.|[2502.04795v1](http://arxiv.org/abs/2502.04795v1)|null|
|**2025-02-07**|**MedMimic: Physician-Inspired Multimodal Fusion for Early Diagnosis of Fever of Unknown Origin**|Minrui Chen et.al.|[2502.04794v1](http://arxiv.org/abs/2502.04794v1)|null|
|**2025-02-07**|**S$^2$-MAD: Breaking the Token Barrier to Enhance Multi-Agent Debate Efficiency**|Yuting Zeng et.al.|[2502.04790v1](http://arxiv.org/abs/2502.04790v1)|null|
|**2025-02-07**|**Probing Internal Representations of Multi-Word Verbs in Large Language Models**|Hassane Kissane et.al.|[2502.04789v1](http://arxiv.org/abs/2502.04789v1)|null|
|**2025-02-07**|**Enhancing SQL Injection Detection and Prevention Using Generative Models**|Naga Sai Dasari et.al.|[2502.04786v1](http://arxiv.org/abs/2502.04786v1)|null|
|**2025-02-07**|**SiriuS: Self-improving Multi-agent Systems via Bootstrapped Reasoning**|Wanjia Zhao et.al.|[2502.04780v1](http://arxiv.org/abs/2502.04780v1)|null|
|**2025-02-07**|**Behavior-Regularized Diffusion Policy Optimization for Offline Reinforcement Learning**|Chen-Xiao Gao et.al.|[2502.04778v1](http://arxiv.org/abs/2502.04778v1)|null|
|**2025-02-07**|**SeDi-Instruct: Enhancing Alignment of Language Models through Self-Directed Instruction Generation**|Jungwoo Kim et.al.|[2502.04774v1](http://arxiv.org/abs/2502.04774v1)|null|
|**2025-02-07**|**DMPA: Model Poisoning Attacks on Decentralized Federated Learning for Model Differences**|Chao Feng et.al.|[2502.04771v1](http://arxiv.org/abs/2502.04771v1)|null|
|**2025-02-07**|**Graph Federated Learning Based Proactive Content Caching in Edge Computing**|Rui Wang et.al.|[2502.04760v1](http://arxiv.org/abs/2502.04760v1)|null|
|**2025-02-07**|**Enhancing Phishing Email Identification with Large Language Models**|Catherine Lee et.al.|[2502.04759v1](http://arxiv.org/abs/2502.04759v1)|null|
|**2025-02-07**|**ELITE: Enhanced Language-Image Toxicity Evaluation for Safety**|Wonjun Lee et.al.|[2502.04757v1](http://arxiv.org/abs/2502.04757v1)|null|
|**2025-02-07**|**Concept Navigation and Classification via Open Source Large Language Model Processing**|Maël Kubli et.al.|[2502.04756v1](http://arxiv.org/abs/2502.04756v1)|null|
|**2025-02-07**|**Holistically Guided Monte Carlo Tree Search for Intricate Information Seeking**|Ruiyang Ren et.al.|[2502.04751v1](http://arxiv.org/abs/2502.04751v1)|null|
|**2025-02-07**|**Every Software as an Agent: Blueprint and Case Study**|Mengwei Xu et.al.|[2502.04747v1](http://arxiv.org/abs/2502.04747v1)|null|
|**2025-02-07**|**The "negative end" of change in grammar: terminology, concepts and causes**|Karolina Rudnicka et.al.|[2502.04729v1](http://arxiv.org/abs/2502.04729v1)|null|
|**2025-02-07**|**Generating Symbolic World Models via Test-time Scaling of Large Language Models**|Zhouliang Yu et.al.|[2502.04728v1](http://arxiv.org/abs/2502.04728v1)|[link](https://github.com/VMLPDDL/VML_PDDL)|
|**2025-02-07**|**Can Diffusion Models Learn Hidden Inter-Feature Rules Behind Images?**|Yujin Han et.al.|[2502.04725v1](http://arxiv.org/abs/2502.04725v1)|null|
|**2025-02-07**|**Evaluating Text Style Transfer Evaluation: Are There Any Reliable Metrics?**|Sourabrata Mukherjee et.al.|[2502.04718v1](http://arxiv.org/abs/2502.04718v1)|null|
|**2025-02-07**|**Enhancing Impression Change Prediction in Speed Dating Simulations Based on Speakers' Personalities**|Kazuya Matsuo et.al.|[2502.04706v1](http://arxiv.org/abs/2502.04706v1)|null|
|**2025-02-07**|**EigenLoRAx: Recycling Adapters to Find Principal Subspaces for Resource-Efficient Adaptation and Inference**|Prakhar Kaushik et.al.|[2502.04700v1](http://arxiv.org/abs/2502.04700v1)|null|
|**2025-02-07**|**Bridging the Gap in XAI-Why Reliable Metrics Matter for Explainability and Compliance**|Pratinav Seth et.al.|[2502.04695v1](http://arxiv.org/abs/2502.04695v1)|null|
|**2025-02-07**|**ARR: Question Answering with Large Language Models via Analyzing, Retrieving, and Reasoning**|Yuwei Yin et.al.|[2502.04689v1](http://arxiv.org/abs/2502.04689v1)|[link](https://github.com/YuweiYin/ARR)|
|**2025-02-07**|**M-IFEval: Multilingual Instruction-Following Evaluation**|Antoine Dussolle et.al.|[2502.04688v1](http://arxiv.org/abs/2502.04688v1)|null|
|**2025-02-07**|**Learning Strategic Language Agents in the Werewolf Game with Iterative Latent Space Policy Optimization**|Zelai Xu et.al.|[2502.04686v1](http://arxiv.org/abs/2502.04686v1)|null|
|**2025-02-07**|**G2PDiffusion: Genotype-to-Phenotype Prediction with Diffusion Models**|Mengdi Liu et.al.|[2502.04684v1](http://arxiv.org/abs/2502.04684v1)|null|
|**2025-02-07**|**AdParaphrase: Paraphrase Dataset for Analyzing Linguistic Features toward Generating Attractive Ad Texts**|Soichiro Murakami et.al.|[2502.04674v1](http://arxiv.org/abs/2502.04674v1)|null|
|**2025-02-07**|**${\rm P{\small ROOF}W{\small ALA}}$: Multilingual Proof Data Synthesis and Theorem-Proving**|Amitayush Thakur et.al.|[2502.04671v1](http://arxiv.org/abs/2502.04671v1)|null|
|**2025-02-07**|**CCS: Controllable and Constrained Sampling with Diffusion Models via Initial Noise Perturbation**|Bowen Song et.al.|[2502.04670v1](http://arxiv.org/abs/2502.04670v1)|null|
|**2025-02-07**|**A Comprehensive Review on Noise Control of Diffusion Model**|Zhehao Guo et.al.|[2502.04669v1](http://arxiv.org/abs/2502.04669v1)|null|
|**2025-02-07**|**Unveiling the Mechanisms of Explicit CoT Training: How Chain-of-Thought Enhances Reasoning Generalization**|Xinhao Yao et.al.|[2502.04667v1](http://arxiv.org/abs/2502.04667v1)|null|
|**2025-02-07**|**Shifting Attention to You: Personalized Brain-Inspired AI Models**|Stephen Chong Zhao et.al.|[2502.04658v1](http://arxiv.org/abs/2502.04658v1)|null|
|**2025-02-07**|**Before It's Too Late: A State Space Model for the Early Prediction of Misinformation and Disinformation Engagement**|Lin Tian et.al.|[2502.04655v1](http://arxiv.org/abs/2502.04655v1)|null|
|**2025-02-07**|**Importance Sampling via Score-based Generative Models**|Heasung Kim et.al.|[2502.04646v1](http://arxiv.org/abs/2502.04646v1)|null|
|**2025-02-07**|**Cross-Encoder Rediscovers a Semantic Variant of BM25**|Meng Lu et.al.|[2502.04645v1](http://arxiv.org/abs/2502.04645v1)|null|
|**2025-02-07**|**Agentic Reasoning: Reasoning LLMs with Tools for the Deep Research**|Junde Wu et.al.|[2502.04644v1](http://arxiv.org/abs/2502.04644v1)|null|
|**2025-02-07**|**Confidence Elicitation: A New Attack Vector for Large Language Models**|Brian Formento et.al.|[2502.04643v1](http://arxiv.org/abs/2502.04643v1)|null|
|**2025-02-07**|**Extracting and Understanding the Superficial Knowledge in Alignment**|Runjin Chen et.al.|[2502.04602v1](http://arxiv.org/abs/2502.04602v1)|null|
|**2025-02-07**|**The $α$-Alternator: Dynamic Adaptation To Varying Noise Levels In Sequences Using The Vendi Score For Improved Robustness and Performance**|Mohammad Reza Rezaei et.al.|[2502.04593v1](http://arxiv.org/abs/2502.04593v1)|null|
|**2025-02-07**|**CAMEF: Causal-Augmented Multi-Modality Event-Driven Financial Forecasting by Integrating Time Series Patterns and Salient Macroeconomic Announcements**|Yang Zhang et.al.|[2502.04592v1](http://arxiv.org/abs/2502.04592v1)|null|
|**2025-02-07**|**Rethinking Oversmoothing in Graph Neural Networks: A Rank-Based Perspective**|Piero Deidda et.al.|[2502.04591v1](http://arxiv.org/abs/2502.04591v1)|null|
|**2025-02-07**|**Technical Debt in In-Context Learning: Diminishing Efficiency in Long Context**|Taejong Joo et.al.|[2502.04580v1](http://arxiv.org/abs/2502.04580v1)|null|
|**2025-02-07**|**Position-aware Automatic Circuit Discovery**|Tal Haklay et.al.|[2502.04577v1](http://arxiv.org/abs/2502.04577v1)|null|
|**2025-02-07**|**Self-Regulation and Requesting Interventions**|So Yeon Min et.al.|[2502.04576v1](http://arxiv.org/abs/2502.04576v1)|null|
|**2025-02-06**|**Zero-shot Meta-learning for Tabular Prediction Tasks with Adversarially Pre-trained Transformer**|Yulun Wu et.al.|[2502.04573v1](http://arxiv.org/abs/2502.04573v1)|null|
|**2025-02-06**|**Preference Optimization via Contrastive Divergence: Your Reward Model is Secretly an NLL Estimator**|Zhuotong Chen et.al.|[2502.04567v1](http://arxiv.org/abs/2502.04567v1)|null|
|**2025-02-06**|**My LLM might Mimic AAE -- But When Should it?**|Sandra C. Sandoval et.al.|[2502.04564v1](http://arxiv.org/abs/2502.04564v1)|null|
|**2025-02-06**|**WaferLLM: A Wafer-Scale LLM Inference System**|Congjie He et.al.|[2502.04563v1](http://arxiv.org/abs/2502.04563v1)|null|
|**2025-02-06**|**Probing a Vision-Language-Action Model for Symbolic States and Integration into a Cognitive Architecture**|Hong Lu et.al.|[2502.04558v1](http://arxiv.org/abs/2502.04558v1)|null|
|**2025-02-06**|**TruthFlow: Truthful LLM Generation via Representation Flow Correction**|Hanyu Wang et.al.|[2502.04556v1](http://arxiv.org/abs/2502.04556v1)|null|
|**2025-02-06**|**Unifying and Optimizing Data Values for Selection via Sequential-Decision-Making**|Hongliang Chi et.al.|[2502.04554v1](http://arxiv.org/abs/2502.04554v1)|null|
|**2025-02-06**|**Contextual Gradient Flow Modeling for Large Language Model Generalization in Multi-Scale Feature Spaces**|Daphne Quillington et.al.|[2502.04548v1](http://arxiv.org/abs/2502.04548v1)|null|
|**2025-02-06**|**Multilingual Non-Autoregressive Machine Translation without Knowledge Distillation**|Chenyang Huang et.al.|[2502.04537v1](http://arxiv.org/abs/2502.04537v1)|null|
|**2025-02-06**|**A Decoding Algorithm for Length-Control Summarization Based on Directed Acyclic Transformers**|Chenyang Huang et.al.|[2502.04535v1](http://arxiv.org/abs/2502.04535v1)|null|

#### Abstracts
##### **MELON: Indirect Prompt Injection Defense via Masked Re-execution and Tool Comparison**
2502.05174v1 by Kaijie Zhu, Xianjun Yang, Jindong Wang, Wenbo Guo, William Yang Wang

Recent research has explored that LLM agents are vulnerable to indirect
prompt injection (IPI) attacks, where malicious tasks embedded in
tool-retrieved information can redirect the agent to take unauthorized actions.
Existing defenses against IPI have significant limitations: either require
essential model training resources, lack effectiveness against sophisticated
attacks, or harm the normal utilities. We present MELON (Masked re-Execution
and TooL comparisON), a novel IPI defense. Our approach builds on the
observation that under a successful attack, the agent's next action becomes
less dependent on user tasks and more on malicious tasks. Following this, we
design MELON to detect attacks by re-executing the agent's trajectory with a
masked user prompt modified through a masking function. We identify an attack
if the actions generated in the original and masked executions are similar. We
also include three key designs to reduce the potential false positives and
false negatives. Extensive evaluation on the IPI benchmark AgentDojo
demonstrates that MELON outperforms SOTA defenses in both attack prevention and
utility preservation. Moreover, we show that combining MELON with a SOTA prompt
augmentation defense (denoted as MELON-Aug) further improves its performance.
We also conduct a detailed ablation study to validate our key designs.

摘要：近期研究探索出 LLM 代理容易受到间接提示注入 (IPI) 攻击，其中嵌入在工具检索信息中的恶意任务会将代理重定向到执行未经授权的操作。现有的针对 IPI 的防御措施有很大的局限性：要么需要基本的模型训练资源，要么缺乏对复杂攻击的有效性，要么损害正常的实用程序。我们提出了 MELON（掩码重新执行和工具比较），一种新颖的 IPI 防御措施。我们的方法建立在这样的观察之上：在成功的攻击下，代理的下一步行动变得不再依赖于用户任务，而更多地依赖于恶意任务。在此之后，我们设计 MELON 通过重新执行代理的轨迹来检测攻击，该轨迹通过掩码函数修改了掩码的用户提示。如果在原始执行和掩码执行中生成的操作相似，我们就会识别出攻击。我们还包括三个关键设计来减少潜在的误报和漏报。在 IPI 基准 AgentDojo 上进行的广泛评估表明，MELON 在攻击预防和实用程序保留方面都优于 SOTA 防御措施。此外，我们表明将 MELON 与 SOTA 提示增强防御措施（表示为 MELON-Aug）相结合可以进一步提高其性能。我们还进行了详细的消融研究来验证我们的关键设计。

##### **Joint MoE Scaling Laws: Mixture of Experts Can Be Memory Efficient**
2502.05172v1 by Jan Ludziejewski, Maciej Pióro, Jakub Krajewski, Maciej Stefaniak, Michał Krutul, Jan Małaśnicki, Marek Cygan, Piotr Sankowski, Kamil Adamczewski, Piotr Miłoś, Sebastian Jaszczur

Mixture of Experts (MoE) architectures have significantly increased
computational efficiency in both research and real-world applications of
large-scale machine learning models. However, their scalability and efficiency
under memory constraints remain relatively underexplored. In this work, we
present joint scaling laws for dense and MoE models, incorporating key factors
such as the number of active parameters, dataset size, and the number of
experts. Our findings provide a principled framework for selecting the optimal
MoE configuration under fixed memory and compute budgets. Surprisingly, we show
that MoE models can be more memory-efficient than dense models, contradicting
conventional wisdom. To derive and validate the theoretical predictions of our
scaling laws, we conduct over 280 experiments with up to 2.7B active parameters
and up to 5B total parameters. These results offer actionable insights for
designing and deploying MoE models in practical large-scale training scenarios.

摘要：專家混合 (MoE) 架構已顯著提升研究和大型機器學習模型的實際應用中的運算效率。然而，它們在記憶體限制下的可擴充性和效率仍相對未被充分探討。在這項工作中，我們提出稠密和 MoE 模型的聯合擴充法則，納入關鍵因素，例如活動參數數量、資料集大小和專家數量。我們的研究結果提供了一個基於原則的架構，用於在固定的記憶體和運算預算下選擇最佳的 MoE 組態。令人驚訝的是，我們發現 MoE 模型可以比稠密模型更省記憶體，這與傳統觀念相矛盾。為了推導和驗證我們擴充法則的理論預測，我們進行了超過 280 個實驗，使用多達 2.7B 個活動參數和多達 5B 個總參數。這些結果為在實際的大規模訓練場景中設計和部署 MoE 模型提供了可行的見解。

##### **Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach**
2502.05171v1 by Jonas Geiping, Sean McLeish, Neel Jain, John Kirchenbauer, Siddharth Singh, Brian R. Bartoldson, Bhavya Kailkhura, Abhinav Bhatele, Tom Goldstein

We study a novel language model architecture that is capable of scaling
test-time computation by implicitly reasoning in latent space. Our model works
by iterating a recurrent block, thereby unrolling to arbitrary depth at
test-time. This stands in contrast to mainstream reasoning models that scale up
compute by producing more tokens. Unlike approaches based on chain-of-thought,
our approach does not require any specialized training data, can work with
small context windows, and can capture types of reasoning that are not easily
represented in words. We scale a proof-of-concept model to 3.5 billion
parameters and 800 billion tokens. We show that the resulting model can improve
its performance on reasoning benchmarks, sometimes dramatically, up to a
computation load equivalent to 50 billion parameters.

摘要：我們研究了一種新穎的語言模型架構，它能夠通過在潛在空間中進行隱式推理來擴展測試時間計算。我們的模型通過迭代遞迴塊來工作，從而將測試時間展開到任意深度。這與通過產生更多令牌來擴展計算的主流推理模型形成對比。與基於思維鏈的方法不同，我們的方法不需要任何專門的訓練數據，可以使用小上下文窗口，並且可以捕捉到不容易用文字表示的推理類型。我們將概念驗證模型擴展到 35 億個參數和 8000 億個令牌。我們表明，生成的模型可以提高其在推理基準測試上的性能，有時會顯著提高，計算負載相當於 500 億個參數。

##### **NoLiMa: Long-Context Evaluation Beyond Literal Matching**
2502.05167v1 by Ali Modarressi, Hanieh Deilamsalehy, Franck Dernoncourt, Trung Bui, Ryan A. Rossi, Seunghyun Yoon, Hinrich Schütze

Recent large language models (LLMs) support long contexts ranging from 128K
to 1M tokens. A popular method for evaluating these capabilities is the
needle-in-a-haystack (NIAH) test, which involves retrieving a "needle"
(relevant information) from a "haystack" (long irrelevant context). Extensions
of this approach include increasing distractors, fact chaining, and in-context
reasoning. However, in these benchmarks, models can exploit existing literal
matches between the needle and haystack to simplify the task. To address this,
we introduce NoLiMa, a benchmark extending NIAH with a carefully designed
needle set, where questions and needles have minimal lexical overlap, requiring
models to infer latent associations to locate the needle within the haystack.
We evaluate 12 popular LLMs that claim to support contexts of at least 128K
tokens. While they perform well in short contexts (<1K), performance degrades
significantly as context length increases. At 32K, for instance, 10 models drop
below 50% of their strong short-length baselines. Even GPT-4o, one of the
top-performing exceptions, experiences a reduction from an almost-perfect
baseline of 99.3% to 69.7%. Our analysis suggests these declines stem from the
increased difficulty the attention mechanism faces in longer contexts when
literal matches are absent, making it harder to retrieve relevant information.

摘要：最近的大语言模型（LLM）支持从 128K 到 1M 个标记的较长内容。评估这些功能的一种流行方法是“大海捞针”（NIAH）测试，其中涉及从“干草堆”（冗长的无关内容）中检索“针”（相关信息）。这种方法的扩展包括增加干扰项、事实链接和上下文推理。然而，在这些基准测试中，模型可以利用针和干草堆之间现有的字面匹配来简化任务。为了解决这个问题，我们引入了 NoLiMa，这是一个基准，它用精心设计的针集扩展了 NIAH，其中问题和针的词汇重叠很小，需要模型推断潜在关联才能在干草堆中找到针。我们评估了 12 个流行的 LLM，它们声称支持至少 128K 个标记的内容。虽然它们在较短的内容（<1K）中表现良好，但随着内容长度的增加，性能会显着下降。例如，在 32K 时，10 个模型低于其强劲的短长度基线的 50%。即使是表现最好的例外之一 GPT-4o，也从接近完美的 99.3% 的基线下降到 69.7%。我们的分析表明，这些下降源于当没有字面匹配时，注意机制在较长的内容中面临的困难增加，这使得检索相关信息变得更加困难。

##### **DuoGuard: A Two-Player RL-Driven Framework for Multilingual LLM Guardrails**
2502.05163v1 by Yihe Deng, Yu Yang, Junkai Zhang, Wei Wang, Bo Li

The rapid advancement of large language models (LLMs) has increased the need
for guardrail models to ensure responsible use, particularly in detecting
unsafe and illegal content. While substantial safety data exist in English,
multilingual guardrail modeling remains underexplored due to the scarcity of
open-source safety data in other languages. To address this gap, we propose a
novel two-player Reinforcement Learning (RL) framework, where a generator and a
guardrail model co-evolve adversarially to produce high-quality synthetic data
for multilingual guardrail training. We theoretically formalize this
interaction as a two-player game, proving convergence to a Nash equilibrium.
Empirical evaluations show that our model \ours outperforms state-of-the-art
models, achieving nearly 10% improvement over LlamaGuard3 (8B) on English
benchmarks while being 4.5x faster at inference with a significantly smaller
model (0.5B). We achieve substantial advancements in multilingual safety tasks,
particularly in addressing the imbalance for lower-resource languages in a
collected real dataset. Ablation studies emphasize the critical role of
synthetic data generation in bridging the imbalance in open-source data between
English and other languages. These findings establish a scalable and efficient
approach to synthetic data generation, paving the way for improved multilingual
guardrail models to enhance LLM safety. Code, model, and data will be
open-sourced at https://github.com/yihedeng9/DuoGuard.

摘要：大型語言模型 (LLM) 的快速進展增加了護欄模型的需求，以確保負責任的使用，特別是在偵測不安全和非法內容方面。儘管英語中有大量的安全數據，但由於其他語言中缺乏開源安全數據，多語言護欄建模仍未得到充分探索。為了解決這個差距，我們提出了一個新穎的雙人強化學習 (RL) 框架，其中生成器和護欄模型共同對抗演化，以產生高品質的合成數據，用於多語言護欄訓練。我們在理論上將這種互動形式化為雙人遊戲，證明了收斂到納什均衡。經驗評估表明，我們的模型 \ours 優於最先進的模型，在英語基準測試中比 LlamaGuard3 (8B) 提高了近 10%，同時在推理速度上快 4.5 倍，而模型顯著更小 (0.5B)。我們在多語言安全任務中取得了重大進展，特別是在解決收集到的真實數據集中資源較少語言的不平衡方面。消融研究強調了合成數據生成在彌合英語和其他語言之間開源數據不平衡中的關鍵作用。這些發現建立了一個可擴展且高效的合成數據生成方法，為改進的多語言護欄模型鋪平了道路，以增強 LLM 的安全性。程式碼、模型和數據將在 https://github.com/yihedeng9/DuoGuard 開源。

##### **A Lightweight Method to Disrupt Memorized Sequences in LLM**
2502.05159v1 by Parjanya Prajakta Prashant, Kaustubh Ponkshe, Babak Salimi

Large language models (LLMs) demonstrate impressive capabilities across many
tasks yet risk reproducing copyrighted content verbatim, raising legal and
ethical concerns. Although methods like differential privacy or neuron editing
can reduce memorization, they typically require costly retraining or direct
access to model weights and may degrade performance. To address these
challenges, we propose TokenSwap, a lightweight, post-hoc approach that
replaces the probabilities of grammar-related tokens with those from a small
auxiliary model (e.g., DistilGPT-2). We run extensive experiments on commercial
grade models such as Pythia-6.9b and LLaMA-3-8b and demonstrate that our method
effectively reduces well-known cases of memorized generation by upto 10x with
little to no impact on downstream tasks. Our approach offers a uniquely
accessible and effective solution to users of real-world systems.

摘要：大型語言模型 (LLM) 在許多任務中展現出令人印象深刻的能力，但卻有逐字複製受版權保護內容的風險，引發法律和道德上的疑慮。儘管微分隱私或神經元編輯等方法可以減少記憶，但它們通常需要代價高昂的重新訓練或直接存取模型權重，並且可能會降低效能。為了應對這些挑戰，我們提出 TokenSwap，這是一種輕量級的後設法，它使用來自小型輔助模型（例如 DistilGPT-2）的機率來取代與語法相關的詞彙機率。我們對 Pythia-6.9b 和 LLaMA-3-8b 等商業級模型進行廣泛的實驗，並證明我們的模型有效地將記憶中產生的已知案例減少多達 10 倍，對下游任務幾乎沒有影響。我們的做法為實際系統的使用者提供了一個獨特且有效的解決方案。

##### **Transforming Science with Large Language Models: A Survey on AI-assisted Scientific Discovery, Experimentation, Content Generation, and Evaluation**
2502.05151v1 by Steffen Eger, Yong Cao, Jennifer D'Souza, Andreas Geiger, Christian Greisinger, Stephanie Gross, Yufang Hou, Brigitte Krenn, Anne Lauscher, Yizhi Li, Chenghua Lin, Nafise Sadat Moosavi, Wei Zhao, Tristan Miller

With the advent of large multimodal language models, science is now at a
threshold of an AI-based technological transformation. Recently, a plethora of
new AI models and tools has been proposed, promising to empower researchers and
academics worldwide to conduct their research more effectively and efficiently.
This includes all aspects of the research cycle, especially (1) searching for
relevant literature; (2) generating research ideas and conducting
experimentation; generating (3) text-based and (4) multimodal content (e.g.,
scientific figures and diagrams); and (5) AI-based automatic peer review. In
this survey, we provide an in-depth overview over these exciting recent
developments, which promise to fundamentally alter the scientific research
process for good. Our survey covers the five aspects outlined above, indicating
relevant datasets, methods and results (including evaluation) as well as
limitations and scope for future research. Ethical concerns regarding
shortcomings of these tools and potential for misuse (fake science, plagiarism,
harms to research integrity) take a particularly prominent place in our
discussion. We hope that our survey will not only become a reference guide for
newcomers to the field but also a catalyst for new AI-based initiatives in the
area of "AI4Science".

摘要：隨著大型多模態語言模型的出現，科學現在正處於 AI 基礎科技轉型的門檻上。最近，已經提出許多新的 AI 模型和工具，承諾賦能全球的研究人員和學者更有效率且有效地進行研究。這包含研究週期的所有面向，特別是：(1) 搜尋相關文獻；(2) 產生研究點子和進行實驗；產生 (3) 文字為基礎和 (4) 多模態內容（例如科學圖形和圖表）；以及 (5) AI 基礎的自動同行評審。在此調查中，我們提供這些令人振奮的近期發展的深入概觀，承諾徹底改變科學研究過程。我們的調查涵蓋上述五個面向，指出相關的資料集、方法和結果（包括評量），以及限制和未來研究範圍。關於這些工具的缺點和誤用潛力（假科學、抄襲、危害研究誠信）的道德疑慮，在我們的討論中佔有特別突出的地位。我們希望我們的調查不僅能成為此領域新手的參考指南，也能成為「AI4Science」領域中新的 AI 基礎計畫的催化劑。

##### **CodeSCM: Causal Analysis for Multi-Modal Code Generation**
2502.05150v1 by Mukur Gupta, Noopur Bhatt, Suman Jana

In this paper, we propose CodeSCM, a Structural Causal Model (SCM) for
analyzing multi-modal code generation using large language models (LLMs). By
applying interventions to CodeSCM, we measure the causal effects of different
prompt modalities, such as natural language, code, and input-output examples,
on the model. CodeSCM introduces latent mediator variables to separate the code
and natural language semantics of a multi-modal code generation prompt. Using
the principles of Causal Mediation Analysis on these mediators we quantify
direct effects representing the model's spurious leanings. We find that, in
addition to natural language instructions, input-output examples significantly
influence code generation.

摘要：在本文中，我們提出 CodeSCM，一個結構因果模型 (SCM)，用於分析使用大型語言模型 (LLM) 的多模態程式碼生成。透過對 CodeSCM 應用介入，我們測量了不同提示形式的因果效應，例如自然語言、程式碼和輸入輸出範例，對模型的影響。CodeSCM 引入了潛在中介變數，以分離多模態程式碼生成提示的程式碼和自然語言語義。使用這些中介者的因果中介分析原理，我們量化了代表模型虛假傾向的直接效應。我們發現，除了自然語言指令之外，輸入輸出範例也顯著影響程式碼生成。

##### **An Annotated Reading of 'The Singer of Tales' in the LLM Era**
2502.05148v1 by Kush R. Varshney

The Parry-Lord oral-formulaic theory was a breakthrough in understanding how
oral narrative poetry is learned, composed, and transmitted by illiterate
bards. In this paper, we provide an annotated reading of the mechanism
underlying this theory from the lens of large language models (LLMs) and
generative artificial intelligence (AI). We point out the the similarities and
differences between oral composition and LLM generation, and comment on the
implications to society and AI policy.

摘要：帕里-洛德口頭公式化理論是理解文盲吟遊詩人如何學習、創作和傳遞口頭敘事詩的突破性理論。在本文中，我們從大型語言模型 (LLM) 和生成式人工智慧 (AI) 的角度對此理論背後的機制提供註解性閱讀。我們指出了口頭創作和 LLM 生成之間的相似性和差異，並對社會和 AI 政策的影響發表評論。

##### **LP-DETR: Layer-wise Progressive Relations for Object Detection**
2502.05147v1 by Zhengjian Kang, Ye Zhang, Xiaoyu Deng, Xintao Li, Yongzhe Zhang

This paper presents LP-DETR (Layer-wise Progressive DETR), a novel approach
that enhances DETR-based object detection through multi-scale relation
modeling. Our method introduces learnable spatial relationships between object
queries through a relation-aware self-attention mechanism, which adaptively
learns to balance different scales of relations (local, medium and global)
across decoder layers. This progressive design enables the model to effectively
capture evolving spatial dependencies throughout the detection pipeline.
Extensive experiments on COCO 2017 dataset demonstrate that our method improves
both convergence speed and detection accuracy compared to standard
self-attention module. The proposed method achieves competitive results,
reaching 52.3\% AP with 12 epochs and 52.5\% AP with 24 epochs using ResNet-50
backbone, and further improving to 58.0\% AP with Swin-L backbone. Furthermore,
our analysis reveals an interesting pattern: the model naturally learns to
prioritize local spatial relations in early decoder layers while gradually
shifting attention to broader contexts in deeper layers, providing valuable
insights for future research in object detection.

摘要：本論文提出層級遞進 DETR（Layer-wise Progressive DETR），這是一種透過多尺度關係建模來增強基於 DETR 的物件偵測之新穎方法。我們的模型透過關係感知自我注意機制，引入了物件查詢之間可學習的空間關係，該機制會自適應地學習在解碼器層中平衡不同尺度的關係（局部、中階和全域）。這種遞進式設計讓模型能夠在整個偵測管線中有效捕捉不斷變化的空間依賴性。在 COCO 2017 資料集上進行的廣泛實驗顯示，與標準自我注意模組相比，我們的模型改善了收斂速度和偵測準確度。所提出的方法達到了競爭力的結果，使用 ResNet-50 主幹架構時，在 12 個世代中達到 52.3% AP，在 24 個世代中達到 52.5% AP，使用 Swin-L 主幹架構時進一步提升至 58.0% AP。此外，我們的分析揭示了一個有趣的模式：模型自然會學習在早期的解碼器層中優先考慮局部空間關係，同時逐漸將注意力轉移到較深層中的更廣泛背景，為物件偵測的未來研究提供了寶貴的見解。

##### **Latent Swap Joint Diffusion for Long-Form Audio Generation**
2502.05130v1 by Yusheng Dai, Chenxi Wang, Chang Li, Chen Wang, Jun Du, Kewei Li, Ruoyu Wang, Jiefeng Ma, Lei Sun, Jianqing Gao

Previous work on long-form audio generation using global-view diffusion or
iterative generation demands significant training or inference costs. While
recent advancements in multi-view joint diffusion for panoramic generation
provide an efficient option, they struggle with spectrum generation with severe
overlap distortions and high cross-view consistency costs. We initially explore
this phenomenon through the connectivity inheritance of latent maps and uncover
that averaging operations excessively smooth the high-frequency components of
the latent map. To address these issues, we propose Swap Forward (SaFa), a
frame-level latent swap framework that synchronizes multiple diffusions to
produce a globally coherent long audio with more spectrum details in a
forward-only manner. At its core, the bidirectional Self-Loop Latent Swap is
applied between adjacent views, leveraging stepwise diffusion trajectory to
adaptively enhance high-frequency components without disrupting low-frequency
components. Furthermore, to ensure cross-view consistency, the unidirectional
Reference-Guided Latent Swap is applied between the reference and the
non-overlap regions of each subview during the early stages, providing
centralized trajectory guidance. Quantitative and qualitative experiments
demonstrate that SaFa significantly outperforms existing joint diffusion
methods and even training-based long audio generation models. Moreover, we find
that it also adapts well to panoramic generation, achieving comparable
state-of-the-art performance with greater efficiency and model
generalizability. Project page is available at https://swapforward.github.io/.

摘要：先前使用全局視圖擴散或迭代生成進行長格式音訊生成的作業需要顯著的訓練或推論成本。雖然全景生成的多視圖聯合擴散的近期進展提供了高效的選項，但它們在生成頻譜時會遇到嚴重的重疊失真和高跨視圖一致性成本的問題。我們最初透過潛在映射的連接繼承來探討此現象，並發現平均運算過度平滑了潛在映射的高頻率組成。為了解決這些問題，我們提出 Swap Forward (SaFa)，一種幀級潛在交換架構，它同步多個擴散以產生全局一致的長音訊，並以僅前向的方式提供更多頻譜細節。其核心是，雙向自迴圈潛在交換套用於相鄰視圖，利用逐步擴散軌跡來自適應地增強高頻率組成，而不會破壞低頻率組成。此外，為了確保跨視圖一致性，單向參考引導潛在交換在早期階段套用於參考和每個子視圖的非重疊區域，提供集中軌跡引導。定量和定性實驗證明，SaFa 明顯優於現有的聯合擴散方法，甚至優於基於訓練的長音訊生成模型。此外，我們發現它也能很好地適應全景生成，以更高的效率和模型泛化性達成媲美最先進技術的效能。專案頁面可於 https://swapforward.github.io/ 取得。

##### **"It Felt Like I Was Left in the Dark": Exploring Information Needs and Design Opportunities for Family Caregivers of Older Adult Patients in Critical Care Settings**
2502.05115v1 by Shihan Fu, Bingsheng Yao, Smit Desai, Yuqi Hu, Yuling Sun, Samantha Stonbraker, Yanjun Gao, Elizabeth M. Goldberg, Dakuo Wang

Older adult patients constitute a rapidly growing subgroup of Intensive Care
Unit (ICU) patients. In these situations, their family caregivers are expected
to represent the unconscious patients to access and interpret patients' medical
information. However, caregivers currently have to rely on overloaded
clinicians for information updates and typically lack the health literacy to
understand complex medical information. Our project aims to explore the
information needs of caregivers of ICU older adult patients, from which we can
propose design opportunities to guide future AI systems. The project begins
with formative interviews with 11 caregivers to identify their challenges in
accessing and interpreting medical information; From these findings, we then
synthesize design requirements and propose an AI system prototype to cope with
caregivers' challenges. The system prototype has two key features: a timeline
visualization to show the AI extracted and summarized older adult patients' key
medical events; and an LLM-based chatbot to provide context-aware informational
support. We conclude our paper by reporting on the follow-up user evaluation of
the system and discussing future AI-based systems for ICU caregivers of older
adults.

摘要：老年患者構成加護病房 (ICU) 患者中快速成長的子群。在這些情況下，預期他們的家庭照護者能代表無意識的患者取得並解讀患者的醫療資訊。然而，照護者目前必須依賴工作繁重的臨床醫師提供資訊更新，而且通常缺乏了解複雜醫療資訊的健康素養。我們的專案旨在探索 ICU 老年患者照護者的資訊需求，我們可以根據這些需求提出設計機會，以引導未來的 AI 系統。這個專案從對 11 位照護者的形成性訪談開始，以找出他們在取得和解讀醫療資訊方面的挑戰；根據這些發現，我們接著綜合設計需求，並提出一個 AI 系統原型，以應對照護者的挑戰。這個系統原型具有兩個關鍵特點：一個時間軸視覺化，以顯示 AI 萃取並摘要出的老年患者關鍵醫療事件；以及一個基於 LLM 的聊天機器人，以提供情境感知的資訊支援。我們透過報告系統的後續使用者評估，以及討論未來針對老年人 ICU 照護者的 AI 系統，來總結我們的論文。

##### **GiesKaNe: Bridging Past and Present in Grammatical Theory and Practical Application**
2502.05113v1 by Volker Emmrich

This article explores the requirements for corpus compilation within the
GiesKaNe project (University of Giessen and Kassel, Syntactic Basic Structures
of New High German). The project is defined by three central characteristics:
it is a reference corpus, a historical corpus, and a syntactically deeply
annotated treebank. As a historical corpus, GiesKaNe aims to establish
connections with both historical and contemporary corpora, ensuring its
relevance across temporal and linguistic contexts. The compilation process
strikes the balance between innovation and adherence to standards, addressing
both internal project goals and the broader interests of the research
community. The methodological complexity of such a project is managed through a
complementary interplay of human expertise and machine-assisted processes. The
article discusses foundational topics such as tokenization, normalization,
sentence definition, tagging, parsing, and inter-annotator agreement, alongside
advanced considerations. These include comparisons between grammatical models,
annotation schemas, and established de facto annotation standards as well as
the integration of human and machine collaboration. Notably, a novel method for
machine-assisted classification of texts along the continuum of conceptual
orality and literacy is proposed, offering new perspectives on text selection.
Furthermore, the article introduces an approach to deriving de facto standard
annotations from existing ones, mediating between standardization and
innovation. In the course of describing the workflow the article demonstrates
that even ambitious projects like GiesKaNe can be effectively implemented using
existing research infrastructure, requiring no specialized annotation tools.
Instead, it is shown that the workflow can be based on the strategic use of a
simple spreadsheet and integrates the capabilities of the existing
infrastructure.

摘要：<paragraph>本文探討了 GiesKaNe（吉森大學和卡塞爾大學，新德語語法基本結構）專案中語料庫編纂的要求。這個專案由三個核心特徵定義：它是一個參考語料庫、一個歷史語料庫，以及一個語法深度標註的樹狀庫。作為一個歷史語料庫，GiesKaNe 旨在建立與歷史和當代語料庫的連結，確保其在時間和語言脈絡中的相關性。編纂過程在創新與遵守標準之間取得平衡，既符合專案內部目標，也符合研究社群的廣泛興趣。透過人類專業知識和機器輔助流程的互補互動，管理了此類專案的方法論複雜性。本文探討了詞彙化、正規化、句子定義、標記、分析和標記者間的一致性等基礎主題，以及進階考量。這些考量包括語法模型、標註架構和既定的實際標註標準之間的比較，以及人類與機器協作的整合。值得注意的是，提出了一種新的機器輔助文本分類方法，沿著概念口語和識字的連續統整，提供文本選擇的新觀點。此外，本文介紹了一種從現有標註中推導實際標準標註的方法，在標準化和創新之間進行調解。在描述工作流程的過程中，本文證明了即使像 GiesKaNe 這樣雄心勃勃的專案，也可以使用現有的研究基礎架構有效實作，而不需要專門的標註工具。相反，本文顯示工作流程可以基於簡單試算表的策略性使用，並整合現有基礎架構的能力。</paragraph>

##### **Flexible and Efficient Grammar-Constrained Decoding**
2502.05111v1 by Kanghee Park, Timothy Zhou, Loris D'Antoni

Large Language Models (LLMs) are often asked to generate structured outputs
that obey precise syntactic rules, such as code snippets or formatted data.
Grammar-constrained decoding (GCD) can guarantee that LLM outputs matches such
rules by masking out tokens that will provably lead to outputs that do not
belong to a specified context-free grammar (CFG). To guarantee soundness, GCD
algorithms have to compute how a given LLM subword tokenizer can align with the
tokens used
  by a given context-free grammar and compute token masks based on this
information. Doing so efficiently is challenging and existing GCD algorithms
require tens of minutes to preprocess common grammars. We present a new GCD
algorithm together with an implementation that offers 17.71x faster offline
preprocessing than existing approaches while preserving state-of-the-art
efficiency in online mask computation.

摘要：大型語言模型 (LLM) 經常被要求產生結構化輸出，這些輸出遵循精確的語法規則，例如程式碼片段或格式化資料。受語法約束的解碼 (GCD) 可以透過遮蔽會導致輸出不屬於特定上下文無關文法 (CFG) 的權杖，來保證 LLM 輸出符合此類規則。為了保證健全性，GCD 演算法必須計算給定的 LLM 子詞彙化器如何與給定的上下文無關文法所使用的權杖對齊，並根據此資訊計算權杖遮罩。有效執行此操作具有挑戰性，現有的 GCD 演算法需要數十分鐘來預處理常見的語法。我們提出一個新的 GCD 演算法以及一個實作，它提供比現有方法快 17.71 倍的離線預處理，同時在線上遮罩計算中保持最先進的效率。

##### **ApplE: An Applied Ethics Ontology with Event Context**
2502.05110v1 by Aisha Aijaz, Raghava Mutharaju, Manohar Kumar

Applied ethics is ubiquitous in most domains, requiring much deliberation due
to its philosophical nature. Varying views often lead to conflicting courses of
action where ethical dilemmas become challenging to resolve. Although many
factors contribute to such a decision, the major driving forces can be
discretized and thus simplified to provide an indicative answer. Knowledge
representation and reasoning offer a way to explicitly translate abstract
ethical concepts into applicable principles within the context of an event. To
achieve this, we propose ApplE, an Applied Ethics ontology that captures
philosophical theory and event context to holistically describe the morality of
an action. The development process adheres to a modified version of the
Simplified Agile Methodology for Ontology Development (SAMOD) and utilizes
standard design and publication practices. Using ApplE, we model a use case
from the bioethics domain that demonstrates our ontology's social and
scientific value. Apart from the ontological reasoning and quality checks,
ApplE is also evaluated using the three-fold testing process of SAMOD. ApplE
follows FAIR principles and aims to be a viable resource for applied ethicists
and ontology engineers.

摘要：應用倫理在多數領域中無所不在，由於其哲學性質，需要許多審議。不同的觀點經常導致相互衝突的行動方針，在這種情況下，倫理困境變得難以解決。儘管許多因素會影響此類決策，但主要的驅動力可以被離散化，並因此簡化以提供指示性答案。知識表徵和推理提供了一種方法，可以將抽象的倫理概念明確地轉換為事件背景下的適用原則。為了實現此目標，我們提出了 ApplE，一種應用倫理學本體，它捕捉哲學理論和事件背景，以全面描述行動的道德性。開發過程遵循本體開發簡化敏捷方法 (SAMOD) 的修改版本，並利用標準設計和發布實務。使用 ApplE，我們模擬了生物倫理領域的一個使用案例，展示了我們的本體的社會和科學價值。除了本體推理和品質檢查外，ApplE 還使用 SAMOD 的三階段測試過程進行評估。ApplE 遵循 FAIR 原則，旨在成為應用倫理學家和本體工程師的可行資源。

##### **Leveraging Hypernetworks and Learnable Kernels for Consumer Energy Forecasting Across Diverse Consumer Types**
2502.05104v1 by Muhammad Umair Danish, Katarina Grolinger

Consumer energy forecasting is essential for managing energy consumption and
planning, directly influencing operational efficiency, cost reduction,
personalized energy management, and sustainability efforts. In recent years,
deep learning techniques, especially LSTMs and transformers, have been greatly
successful in the field of energy consumption forecasting. Nevertheless, these
techniques have difficulties in capturing complex and sudden variations, and,
moreover, they are commonly examined only on a specific type of consumer (e.g.,
only offices, only schools). Consequently, this paper proposes HyperEnergy, a
consumer energy forecasting strategy that leverages hypernetworks for improved
modeling of complex patterns applicable across a diversity of consumers.
Hypernetwork is responsible for predicting the parameters of the primary
prediction network, in our case LSTM. A learnable adaptable kernel, comprised
of polynomial and radial basis function kernels, is incorporated to enhance
performance. The proposed HyperEnergy was evaluated on diverse consumers
including, student residences, detached homes, a home with electric vehicle
charging, and a townhouse. Across all consumer types, HyperEnergy consistently
outperformed 10 other techniques, including state-of-the-art models such as
LSTM, AttentionLSTM, and transformer.

摘要：消費者能源預測對於管理能源消耗和規劃至關重要，直接影響營運效率、成本降低、個人化能源管理和永續性工作。近年來，深度學習技術，特別是 LSTM 和 Transformer，在能源消耗預測領域取得了巨大的成功。儘管如此，這些技術在捕捉複雜和突然的變化方面存在困難，而且通常僅在特定類型的消費者（例如，僅辦公室、僅學校）上進行檢驗。因此，本文提出了 HyperEnergy，一種消費者能源預測策略，它利用超網路來改善適用於各種消費者的複雜模式建模。超網路負責預測主預測網路（在我們的案例中為 LSTM）的參數。一個可學習的可適應核，由多項式和徑向基函數核組成，被納入以增強效能。所提出的 HyperEnergy 在各種消費者上進行了評估，包括學生宿舍、獨棟住宅、配備電動車充電功能的住宅和聯排住宅。在所有消費者類型中，HyperEnergy 的表現始終優於其他 10 種技術，包括 LSTM、AttentionLSTM 和 Transformer 等最先進的模型。

##### **Learning Temporal Invariance in Android Malware Detectors**
2502.05098v1 by Xinran Zheng, Shuo Yang, Edith C. H. Ngai, Suman Jana, Lorenzo Cavallaro

Learning-based Android malware detectors degrade over time due to natural
distribution drift caused by malware variants and new families. This paper
systematically investigates the challenges classifiers trained with empirical
risk minimization (ERM) face against such distribution shifts and attributes
their shortcomings to their inability to learn stable discriminative features.
Invariant learning theory offers a promising solution by encouraging models to
generate stable representations crossing environments that expose the
instability of the training set. However, the lack of prior environment labels,
the diversity of drift factors, and low-quality representations caused by
diverse families make this task challenging. To address these issues, we
propose TIF, the first temporal invariant training framework for malware
detection, which aims to enhance the ability of detectors to learn stable
representations across time. TIF organizes environments based on application
observation dates to reveal temporal drift, integrating specialized multi-proxy
contrastive learning and invariant gradient alignment to generate and align
environments with high-quality, stable representations. TIF can be seamlessly
integrated into any learning-based detector. Experiments on a decade-long
dataset show that TIF excels, particularly in early deployment stages,
addressing real-world needs and outperforming state-of-the-art methods.

摘要：基於學習的 Android 惡意軟體偵測器會隨著時間推移而衰退，這是因為惡意軟體變種和新家族造成的自然分佈漂移。本論文系統性地探討了使用經驗風險最小化 (ERM) 訓練的分類器面臨此類分佈轉移的挑戰，並將其缺點歸因於它們無法學習穩定的區別特徵。不變學習理論提供了一種有前途的解決方案，它鼓勵模型生成跨環境的穩定表示，揭示訓練集的不穩定性。然而，缺乏先前的環境標籤、漂移因素的多樣性以及由不同家族造成的低品質表示使得這項任務具有挑戰性。為了解決這些問題，我們提出了 TIF，這是第一個用於惡意軟體偵測的時序不變訓練架構，旨在增強偵測器跨時間學習穩定表示的能力。TIF 根據應用程式觀察日期組織環境以揭示時序漂移，整合專業的多代理對比學習和不變梯度對齊，以生成和對齊具有高品質、穩定表示的環境。TIF 可以無縫整合到任何基於學習的偵測器中。對長達十年的資料集進行的實驗表明，TIF 表現出色，特別是在早期部署階段，滿足實際需求並優於最先進的方法。

##### **Lost in Time: Clock and Calendar Understanding Challenges in Multimodal LLMs**
2502.05092v1 by Rohit Saxena, Aryo Pradipta Gema, Pasquale Minervini

Understanding time from visual representations is a fundamental cognitive
skill, yet it remains a challenge for multimodal large language models (MLLMs).
In this work, we investigate the capabilities of MLLMs in interpreting time and
date through analogue clocks and yearly calendars. To facilitate this, we
curated a structured dataset comprising two subsets: 1) $\textit{ClockQA}$,
which comprises various types of clock styles$-$standard, black-dial,
no-second-hand, Roman numeral, and arrow-hand clocks$-$paired with time related
questions; and 2) $\textit{CalendarQA}$, which consists of yearly calendar
images with questions ranging from commonly known dates (e.g., Christmas, New
Year's Day) to computationally derived ones (e.g., the 100th or 153rd day of
the year). We aim to analyse how MLLMs can perform visual recognition,
numerical reasoning, and temporal inference when presented with time-related
visual data. Our evaluations show that despite recent advancements, reliably
understanding time remains a significant challenge for MLLMs.

摘要：從視覺表徵理解時間是一項基本的認知技能，但對於多模態大型語言模型 (MLLM) 來說仍然是一項挑戰。在這項工作中，我們探討了 MLLM 在透過類比時鐘和年曆來詮釋時間和日期的能力。為了促進這一點，我們策劃了一個結構化的資料集，包含兩個子集：1) $\textit{ClockQA}$，它包含各種類型的時鐘樣式$-$標準、黑色錶盤、無秒針、羅馬數字和箭頭指針時鐘$-$配對與時間相關的問題；以及 2) $\textit{CalendarQA}$，它包含年曆圖像，問題範圍從眾所周知日期（例如聖誕節、新年）到計算得出的日期（例如第 100 或 153 天）。我們的目標是分析當 MLLM 呈現與時間相關的視覺資料時，它們如何執行視覺辨識、數字推理和時間推論。我們的評估顯示，儘管有近期的進展，但可靠地理解時間仍然是 MLLM 的一大挑戰。

##### **Mitigating Unintended Memorization with LoRA in Federated Learning for LLMs**
2502.05087v1 by Thierry Bossy, Julien Vignoud, Tahseen Rabbani, Juan R. Troncoso Pastoriza, Martin Jaggi

Federated learning (FL) is a popular paradigm for collaborative training
which avoids direct data exposure between clients. However, data privacy issues
still remain: FL-trained large language models are capable of memorizing and
completing phrases and sentences contained in training data when given with
their prefixes. Thus, it is possible for adversarial and honest-but-curious
clients to recover training data of other participants simply through targeted
prompting. In this work, we demonstrate that a popular and simple fine-tuning
strategy, low-rank adaptation (LoRA), reduces memorization during FL up to a
factor of 10. We study this effect by performing a medical question-answering
fine-tuning task and injecting multiple replicas of out-of-distribution
sensitive sequences drawn from an external clinical dataset. We observe a
reduction in memorization for a wide variety of Llama 2 and 3 models, and find
that LoRA can reduce memorization in centralized learning as well. Furthermore,
we show that LoRA can be combined with other privacy-preserving techniques such
as gradient clipping and Gaussian noising, secure aggregation, and Goldfish
loss to further improve record-level privacy while maintaining performance.

摘要：聯邦學習 (FL) 是一種流行的協作訓練範例，可避免客戶端之間直接公開資料。然而，資料隱私問題仍然存在：經過 FL 訓練的大型語言模型能夠記憶並完成訓練資料中包含的片語和句子，只要給予其前綴即可。因此，對抗和誠實但好奇的客戶端有可能僅透過目標提示來恢復其他參與者的訓練資料。在這項工作中，我們證明了一種流行且簡單的微調策略，低秩適應 (LoRA)，可將 FL 期間的記憶減少多達 10 倍。我們透過執行醫學問答微調任務並注入從外部臨床資料集抽取的非分佈敏感序列的多次複製品來研究此效應。我們觀察到各種 Llama 2 和 3 模型的記憶力降低，並發現 LoRA 也能減少集中式學習中的記憶力。此外，我們展示 LoRA 可以與其他隱私保護技術結合使用，例如梯度裁剪和高斯雜訊、安全聚合和 Goldfish 損失，以進一步改善記錄級隱私，同時維持效能。

##### **Causality can systematically address the monsters under the bench(marks)**
2502.05085v1 by Felix Leeb, Zhijing Jin, Bernhard Schölkopf

Effective and reliable evaluation is essential for advancing empirical
machine learning. However, the increasing accessibility of generalist models
and the progress towards ever more complex, high-level tasks make systematic
evaluation more challenging. Benchmarks are plagued by various biases,
artifacts, or leakage, while models may behave unreliably due to poorly
explored failure modes. Haphazard treatments and inconsistent formulations of
such "monsters" can contribute to a duplication of efforts, a lack of trust in
results, and unsupported inferences. In this position paper, we argue causality
offers an ideal framework to systematically address these challenges. By making
causal assumptions in an approach explicit, we can faithfully model phenomena,
formulate testable hypotheses with explanatory power, and leverage principled
tools for analysis. To make causal model design more accessible, we identify
several useful Common Abstract Topologies (CATs) in causal graphs which help
gain insight into the reasoning abilities in large language models. Through a
series of case studies, we demonstrate how the precise yet pragmatic language
of causality clarifies the strengths and limitations of a method and inspires
new approaches for systematic progress.

摘要：有效的、可靠的評估對於推進經驗機器學習至關重要。然而，一般化模型的可及性日益提高，以及朝著更複雜、更高級別任務的進展，使得系統評估更具挑戰性。基準測試受到各種偏差、人工製品或洩漏的困擾，而模型由於探索不充分的故障模式而可能表現得不可靠。隨意處理和不一致的表述等「怪物」可能會導致重複工作、對結果缺乏信任以及不支援的推論。在本文中，我們論證因果關係提供了一個系統性解決這些挑戰的理想框架。通過在方法中明確因果假設，我們可以忠實地模擬現象，制定具有解釋力的可測試假設，並利用原則性的分析工具。為了使因果模型設計更易於使用，我們在因果圖中識別出幾個有用的通用抽象拓撲 (CAT)，有助於深入了解大型語言模型中的推理能力。通過一系列案例研究，我們展示了因果關係的精確但務實的語言如何釐清方法的優缺點，並激發系統進展的新方法。

##### **ChallengeMe: An Adversarial Learning-enabled Text Summarization Framework**
2502.05084v1 by Xiaoyu Deng, Ye Zhang, Tianmin Guo, Yongzhe Zhang, Zhengjian Kang, Hang Yang

The astonishing performance of large language models (LLMs) and their
remarkable achievements in production and daily life have led to their
widespread application in collaborative tasks. However, current large models
face challenges such as hallucination and lack of specificity in content
generation in vertical domain tasks. Inspired by the contrast and
classification mechanisms in human cognitive processes, this paper constructs
an adversarial learning-based prompt framework named ChallengeMe, which
includes three cascaded solutions: generation prompts, evaluation prompts, and
feedback optimization. In this process, we designed seven core optimization
dimensions and set the threshold for adversarial learning. The results of mixed
case studies on the text summarization task show that the proposed framework
can generate more accurate and fluent text summaries compared to the current
advanced mainstream LLMs.

摘要：大型語言模型 (LLM) 的驚人表現及其在生產和日常生活中的顯著成就，已導致它們廣泛應用於協作任務中。然而，當前大型模型面臨挑戰，例如在垂直領域任務中內容生成出現幻覺和缺乏具體性。受人類認知過程中對比和分類機制的啟發，本文構建了一個名為 ChallengeMe 的對抗性學習提示框架，其中包括三個級聯解決方案：生成提示、評估提示和反饋優化。在此過程中，我們設計了七個核心優化維度，並設定了對抗性學習的閾值。在文本摘要任務上混合案例研究的結果表明，與當前先進的主流 LLM 相比，所提出的框架可以生成更準確、更流暢的文本摘要。

##### **Adaptive Graph of Thoughts: Test-Time Adaptive Reasoning Unifying Chain, Tree, and Graph Structures**
2502.05078v1 by Tushar Pandey, Ara Ghukasyan, Oktay Goktas, Santosh Kumar Radha

Large Language Models (LLMs) have demonstrated impressive reasoning
capabilities, yet their performance is highly dependent on the prompting
strategy and model scale. While reinforcement learning and fine-tuning have
been deployed to boost reasoning, these approaches incur substantial
computational and data overhead. In this work, we introduce Adaptive Graph of
Thoughts (AGoT), a dynamic, graph-based inference framework that enhances LLM
reasoning solely at test time. Rather than relying on fixed-step methods like
Chain of Thought (CoT) or Tree of Thoughts (ToT), AGoT recursively decomposes
complex queries into structured subproblems, forming an dynamic directed
acyclic graph (DAG) of interdependent reasoning steps. By selectively expanding
only those subproblems that require further analysis, AGoT unifies the
strengths of chain, tree, and graph paradigms into a cohesive framework that
allocates computation where it is most needed. We validate our approach on
diverse benchmarks spanning multi-hop retrieval, scientific reasoning, and
mathematical problem-solving, achieving up to 46.2% improvement on scientific
reasoning tasks (GPQA) - comparable to gains achieved through computationally
intensive reinforcement learning approaches and outperforming state-of-the-art
iterative approaches. These results suggest that dynamic decomposition and
structured recursion offer a scalable, cost-effective alternative to
post-training modifications, paving the way for more robust, general-purpose
reasoning in LLMs.

摘要：大型語言模型 (LLM) 已展現令人印象深刻的推理能力，但其效能高度依賴於提示策略和模型規模。雖然強化學習和微調已被用於提升推理，但這些方法會造成大量的運算和資料開銷。在這項工作中，我們引入了「適應性思考圖」(AGoT)，一個動態的、基於圖形的推論架構，它僅在測試時就能增強 LLM 推理。AGoT 並非依賴於鏈式思考 (CoT) 或樹狀思考 (ToT) 等固定步驟方法，而是遞迴地將複雜的查詢分解成結構化的子問題，形成一個由相互依賴的推理步驟所組成的動態有向無環圖 (DAG)。透過選擇性地僅擴充那些需要進一步分析的子問題，AGoT 將鏈式、樹狀和圖形範例的優勢統一到一個緊密的架構中，將運算分配到最需要的地方。我們在跨越多重跳躍檢索、科學推理和數學問題解決等多樣基準上驗證了我們的做法，在科學推理任務 (GPQA) 上達到了高達 46.2% 的改進，這與透過運算密集的強化學習方法所獲得的增益相當，並且優於最先進的迭代方法。這些結果表明，動態分解和結構化遞迴提供了一個可擴充、具成本效益的替代方案，用於訓練後修改，為 LLM 中更強健、更通用的推理鋪平了道路。

##### **Paying Attention to Facts: Quantifying the Knowledge Capacity of Attention Layers**
2502.05076v1 by Liang Ze Wong

In this paper, we investigate the ability of single-layer attention-only
transformers (i.e. attention layers) to memorize facts contained in databases
from a linear-algebraic perspective. We associate with each database a
3-tensor, propose the rank of this tensor as a measure of the size of the
database, and provide bounds on the rank in terms of properties of the
database. We also define a 3-tensor corresponding to an attention layer, and
empirically demonstrate the relationship between its rank and database rank on
a dataset of toy models and random databases. By highlighting the roles played
by the value-output and query-key weights, and the effects of argmax and
softmax on rank, our results shed light on the `additive motif' of factual
recall in transformers, while also suggesting a way of increasing layer
capacity without increasing the number of parameters.

摘要：在本文中，我們從線性代數的角度探討僅注意力轉換器（即注意力層）單層記憶資料庫中事實的能力。我們將每個資料庫與一個 3 張量關聯起來，提出此張量的秩作為資料庫大小的度量，並提供秩的界限，根據資料庫的屬性。我們還定義了一個對應於注意力層的 3 張量，並在玩具模型和隨機資料庫的資料集上經驗性地證明了其秩和資料庫秩之間的關係。通過強調值輸出和查詢鍵權重所扮演的角色，以及 argmax 和 softmax 對秩的影響，我們的結果闡明了轉換器中事實性回憶的「加法基序」，同時也提出了一種在不增加參數數量的情況下增加層容量的方法。

##### **Preference-aware compensation policies for crowdsourced on-demand services**
2502.05060v1 by Georgina Nouli, Axel Parmentier, Maximilian Schiffer

Crowdsourced on-demand services offer benefits such as reduced costs, faster
service fulfillment times, greater adaptability, and contributions to
sustainable urban transportation in on-demand delivery contexts. However, the
success of an on-demand platform that utilizes crowdsourcing relies on finding
a compensation policy that strikes a balance between creating attractive offers
for gig workers and ensuring profitability. In this work, we examine a dynamic
pricing problem for an on-demand platform that sets request-specific
compensation of gig workers in a discrete-time framework, where requests and
workers arrive stochastically. The operator's goal is to determine a
compensation policy that maximizes the total expected reward over the time
horizon. Our approach introduces compensation strategies that explicitly
account for gig worker request preferences. To achieve this, we employ the
Multinomial Logit model to represent the acceptance probabilities of gig
workers, and, as a result, derive an analytical solution that utilizes
post-decision states. Subsequently, we integrate this solution into an
approximate dynamic programming algorithm. We compare our algorithm against
benchmark algorithms, including formula-based policies and an upper bound
provided by the full information linear programming solution. Our algorithm
demonstrates consistent performance across diverse settings, achieving
improvements of at least 2.5-7.5% in homogeneous gig worker populations and 9%
in heterogeneous populations over benchmarks, based on fully synthetic data.
For real-world data, it surpasses benchmarks by 8% in weak and 20% in strong
location preference scenarios.

摘要：群眾外包按需服務提供各種好處，例如降低成本、縮短服務履行時間、提高適應性，以及在按需配送情境中對永續城市交通做出貢獻。然而，利用群眾外包的按需平台的成功，在於找到一個能平衡創造對零工工作者有吸引力的優惠，並確保獲利的補償政策。在這項工作中，我們探討一個針對按需平台的動態定價問題，該平台在離散時間架構中設定零工工作者的特定請求補償，其中請求和工作者會隨機出現。操作員的目標是確定一個補償政策，以最大化時間範圍內的總預期報酬。我們的方法引入了明確考慮零工工作者請求偏好的補償策略。為達成這個目標，我們採用多項羅吉特模型來表示零工工作者的接受機率，並因此推導出一個利用後決策狀態的分析解。接下來，我們將這個解整合到一個近似動態規劃演算法中。我們將我們的演算法與基準演算法進行比較，包括基於公式的政策和由完整資訊線性規劃解提供的上限。根據完全合成的資料，我們的演算法在不同設定中展現一致的效能，在同質零工工作者族群中達到至少 2.5-7.5% 的改善，在異質族群中達到 9% 的改善。對於真實世界的資料，在弱位置偏好情境中，它超越基準 8%，在強位置偏好情境中超越 20%。

##### **Federated Learning for Anomaly Detection in Energy Consumption Data: Assessing the Vulnerability to Adversarial Attacks**
2502.05041v1 by Yohannis Kifle Telila, Damitha Senevirathne, Dumindu Tissera, Apurva Narayan, Miriam A. M. Capretz, Katarina Grolinger

Anomaly detection is crucial in the energy sector to identify irregular
patterns indicating equipment failures, energy theft, or other issues. Machine
learning techniques for anomaly detection have achieved great success, but are
typically centralized, involving sharing local data with a central server which
raises privacy and security concerns. Federated Learning (FL) has been gaining
popularity as it enables distributed learning without sharing local data.
However, FL depends on neural networks, which are vulnerable to adversarial
attacks that manipulate data, leading models to make erroneous predictions.
While adversarial attacks have been explored in the image domain, they remain
largely unexplored in time series problems, especially in the energy domain.
Moreover, the effect of adversarial attacks in the FL setting is also mostly
unknown. This paper assesses the vulnerability of FL-based anomaly detection in
energy data to adversarial attacks. Specifically, two state-of-the-art models,
Long Short Term Memory (LSTM) and Transformers, are used to detect anomalies in
an FL setting, and two white-box attack methods, Fast Gradient Sign Method
(FGSM) and Projected Gradient Descent (PGD), are employed to perturb the data.
The results show that FL is more sensitive to PGD attacks than to FGSM attacks,
attributed to PGD's iterative nature, resulting in an accuracy drop of over 10%
even with naive, weaker attacks. Moreover, FL is more affected by these attacks
than centralized learning, highlighting the need for defense mechanisms in FL.

摘要：異常偵測在能源產業中至關重要，用於識別設備故障、能源竊取或其他問題的異常模式。機器學習異常偵測技術已取得巨大成功，但通常是集中式的，涉及與中央伺服器共享本地資料，這會引發隱私和安全問題。聯合式學習 (FL) 逐漸受到歡迎，因為它可以在不共享本地資料的情況下進行分散式學習。然而，FL 依賴於神經網路，而神經網路容易受到操縱資料的對抗性攻擊，導致模型做出錯誤的預測。雖然對抗性攻擊已在影像領域中進行探索，但在時間序列問題中仍鮮少探討，特別是在能源領域。此外，在 FL 設定中對抗性攻擊的影響也大多未知。本文評估了基於 FL 的異常偵測在能源資料中對對抗性攻擊的脆弱性。具體來說，兩個最先進的模型，長短期記憶 (LSTM) 和Transformer，用於在 FL 設定中偵測異常，並採用兩種白盒攻擊方法，快速梯度符號方法 (FGSM) 和投影梯度下降 (PGD)，來擾動資料。結果顯示，FL 對 PGD 攻擊比對 FGSM 攻擊更敏感，這歸因於 PGD 的迭代性質，即使是簡單、較弱的攻擊，也會導致準確率下降超過 10%。此外，與集中式學習相比，FL 受到這些攻擊的影響更大，這突顯了 FL 中防禦機制的必要性。

##### **nvAgent: Automated Data Visualization from Natural Language via Collaborative Agent Workflow**
2502.05036v1 by Geliang Ouyang, Jingyao Chen, Zhihe Nie, Yi Gui, Yao Wan, Hongyu Zhang, Dongping Chen

Natural Language to Visualization (NL2Vis) seeks to convert natural-language
descriptions into visual representations of given tables, empowering users to
derive insights from large-scale data. Recent advancements in Large Language
Models (LLMs) show promise in automating code generation to transform tabular
data into accessible visualizations. However, they often struggle with complex
queries that require reasoning across multiple tables. To address this
limitation, we propose a collaborative agent workflow, termed nvAgent, for
NL2Vis. Specifically, nvAgent comprises three agents: a processor agent for
database processing and context filtering, a composer agent for planning
visualization generation, and a validator agent for code translation and output
verification. Comprehensive evaluations on the new VisEval benchmark
demonstrate that nvAgent consistently surpasses state-of-the-art baselines,
achieving a 7.88% improvement in single-table and a 9.23% improvement in
multi-table scenarios. Qualitative analyses further highlight that nvAgent
maintains nearly a 20% performance margin over previous models, underscoring
its capacity to produce high-quality visual representations from complex,
heterogeneous data sources.

摘要：自然語言到視覺化 (NL2Vis) 旨在將自然語言描述轉換為給定表格的視覺化表示，使用戶能夠從大規模數據中獲取見解。大型語言模型 (LLM) 的最新進展顯示出自動化程式碼生成的希望，將表格數據轉換為可訪問的視覺化。然而，它們通常難以處理需要跨多個表格進行推理的複雜查詢。為了解決這個限制，我們提出了一個協作代理工作流程，稱為 nvAgent，用於 NL2Vis。具體來說，nvAgent 包含三個代理：一個用於資料庫處理和上下文過濾的處理器代理、一個用於規劃視覺化生成的作曲器代理和一個用於程式碼轉換和輸出驗證的驗證器代理。在新的 VisEval 基準上的綜合評估表明，nvAgent 持續超越最先進的基準，在單表中實現了 7.88% 的改進，在多表場景中實現了 9.23% 的改進。定性分析進一步強調，nvAgent 在先前模型上保持了近 20% 的效能優勢，突顯了它從複雜、異質數據源產生高品質視覺化表示的能力。

##### **Analyzing Advanced AI Systems Against Definitions of Life and Consciousness**
2502.05007v1 by Azadeh Alavi, Hossein Akhoundi, Fatemeh Kouchmeshki

Could artificial intelligence ever become truly conscious in a functional
sense; this paper explores that open-ended question through the lens of Life, a
concept unifying classical biological criteria (Oxford, NASA, Koshland) with
empirical hallmarks such as adaptive self maintenance, emergent complexity, and
rudimentary self referential modeling. We propose a number of metrics for
examining whether an advanced AI system has gained consciousness, while
emphasizing that we do not claim all AI stems can become conscious. Rather, we
suggest that sufficiently advanced architectures exhibiting immune like
sabotage defenses, mirror self-recognition analogs, or meta-cognitive updates
may cross key thresholds akin to life-like or consciousness-like traits. To
demonstrate these ideas, we start by assessing adaptive self-maintenance
capability, and introduce controlled data corruption sabotage into the training
process. The result demonstrates AI capability to detect these inconsistencies
and revert or self-correct analogous to regenerative biological processes. We
also adapt an animal-inspired mirror self recognition test to neural
embeddings, finding that partially trained CNNs can distinguish self from
foreign features with complete accuracy. We then extend our analysis by
performing a question-based mirror test on five state-of-the-art chatbots
(ChatGPT4, Gemini, Perplexity, Claude, and Copilot) and demonstrated their
ability to recognize their own answers compared to those of the other chatbots.

摘要：人工智慧是否能真正從功能性的角度上達到意識；這篇論文透過生命這個概念來探討這個開放性的問題，生命這個概念結合了古典生物學標準（牛津、NASA、Koshland）以及經驗性的特徵，例如適應性的自我維護、突發的複雜性，以及基本的自我指涉模型。我們提出一些評量指標，用來檢視一個先進的人工智慧系統是否已經獲得意識，同時強調我們並未宣稱所有的人工智慧系統都能達到意識。相反地，我們提出，有足夠先進的架構，表現出類似免疫系統的破壞防禦、鏡像自我辨識類比，或元認知更新，可能會跨越關鍵門檻，類似於生命特質或意識特質。為了證明這些想法，我們從評估適應性自我維護能力開始，並在訓練過程中引入受控的資料破壞破壞。結果證明人工智慧有能力偵測這些不一致性，並恢復或自我修正，類似於生物的再生過程。我們也改編了一個受動物啟發的鏡像自我辨識測驗到神經嵌入中，發現部分訓練過的 CNN 可以完全準確地區分自我和外來特徵。然後我們透過對五個最先進的聊天機器人（ChatGPT4、Gemini、Perplexity、Claude 和 Copilot）執行基於問題的鏡像測驗來延伸我們的分析，並證明它們有能力辨識自己的答案，並與其他聊天機器人的答案做比較。

##### **A New Paradigm in Tuning Learned Indexes: A Reinforcement Learning Enhanced Approach**
2502.05001v1 by Taiyi Wang, Liang Liang, Guang Yang, Thomas Heinis, Eiko Yoneki

Learned Index Structures (LIS) have significantly advanced data management by
leveraging machine learning models to optimize data indexing. However,
designing these structures often involves critical trade-offs, making it
challenging for both designers and end-users to find an optimal balance
tailored to specific workloads and scenarios. While some indexes offer
adjustable parameters that demand intensive manual tuning, others rely on fixed
configurations based on heuristic auto-tuners or expert knowledge, which may
not consistently deliver optimal performance.
  This paper introduces LITune, a novel framework for end-to-end automatic
tuning of Learned Index Structures. LITune employs an adaptive training
pipeline equipped with a tailor-made Deep Reinforcement Learning (DRL) approach
to ensure stable and efficient tuning. To accommodate long-term dynamics
arising from online tuning, we further enhance LITune with an on-the-fly
updating mechanism termed the O2 system. These innovations allow LITune to
effectively capture state transitions in online tuning scenarios and
dynamically adjust to changing data distributions and workloads, marking a
significant improvement over other tuning methods. Our experimental results
demonstrate that LITune achieves up to a 98% reduction in runtime and a 17-fold
increase in throughput compared to default parameter settings given a selected
Learned Index instance. These findings highlight LITune's effectiveness and its
potential to facilitate broader adoption of LIS in real-world applications.

摘要：學習索引結構（LIS）透過利用機器學習模型來優化資料索引，進而大幅提升資料管理。然而，設計這些結構通常涉及關鍵的權衡取捨，使得設計人員和最終使用者難以找到針對特定工作負載和場景量身打造的最佳平衡。雖然有些索引提供可調整的參數，需要密集的手動調整，但其他索引依賴於基於啟發式自動調整器或專家知識的固定配置，這可能無法持續提供最佳效能。
本文介紹 LITune，一種新穎的框架，用於學習索引結構的端到端自動調整。LITune 採用適應性訓練管線，配備量身打造的深度強化學習 (DRL) 方法，以確保穩定且有效的調整。為了適應線上調整產生的長期動態，我們進一步增強 LITune，採用稱為 O2 系統的即時更新機制。這些創新讓 LITune 能夠有效捕捉線上調整場景中的狀態轉換，並動態調整以適應變化的資料分佈和工作負載，標誌著相較於其他調整方法有顯著的進步。我們的實驗結果證明，與給定選定學習索引實例的預設參數設定相比，LITune 達到了運行時間減少多達 98%，以及吞吐量增加 17 倍的成果。這些發現突顯了 LITune 的效能，以及它促進 LIS 在實際應用中更廣泛採用的潛力。

##### **Robust Graph Learning Against Adversarial Evasion Attacks via Prior-Free Diffusion-Based Structure Purification**
2502.05000v1 by Jiayi Luo, Qingyun Sun, Haonan Yuan, Xingcheng Fu, Jianxin Li

Adversarial evasion attacks pose significant threats to graph learning, with
lines of studies that have improved the robustness of Graph Neural Networks
(GNNs). However, existing works rely on priors about clean graphs or attacking
strategies, which are often heuristic and inconsistent. To achieve robust graph
learning over different types of evasion attacks and diverse datasets, we
investigate this problem from a prior-free structure purification perspective.
Specifically, we propose a novel Diffusion-based Structure Purification
framework named DiffSP, which creatively incorporates the graph diffusion model
to learn intrinsic distributions of clean graphs and purify the perturbed
structures by removing adversaries under the direction of the captured
predictive patterns without relying on priors. DiffSP is divided into the
forward diffusion process and the reverse denoising process, during which
structure purification is achieved. To avoid valuable information loss during
the forward process, we propose an LID-driven nonisotropic diffusion mechanism
to selectively inject noise anisotropically. To promote semantic alignment
between the clean graph and the purified graph generated during the reverse
process, we reduce the generation uncertainty by the proposed graph transfer
entropy guided denoising mechanism. Extensive experiments demonstrate the
superior robustness of DiffSP against evasion attacks.

摘要：對抗性規避攻擊對圖形學習構成重大威脅，其中研究線路改進了圖形神經網路 (GNN) 的穩健性。然而，現有工作依賴於乾淨圖形或攻擊策略的先驗，這些策略通常是啟發式的且不一致的。為了在不同類型的規避攻擊和多樣化的資料集上實現穩健的圖形學習，我們從無先驗結構純化的角度研究了這個問題。具體來說，我們提出了一個名為 DiffSP 的基於擴散的結構純化框架，它創新地結合了圖形擴散模型來學習乾淨圖形的內在分佈，並在不依賴先驗的情況下，通過移除對抗者來淨化擾動結構，並在捕獲的預測模式的指導下進行。DiffSP 分為正向擴散過程和反向去噪過程，在此期間實現結構純化。為了避免在正向過程中丟失有價值的資訊，我們提出了一個 LID 驅動的非各向同性擴散機制，以選擇性地各向異性地注入噪聲。為了促進在反向過程中生成的乾淨圖形和純化圖形之間的語義對齊，我們通過提出的圖形傳輸熵引導去噪機制來降低生成的不確定性。大量的實驗證明了 DiffSP 對規避攻擊的卓越穩健性。

##### **Aligning Black-box Language Models with Human Judgments**
2502.04997v1 by Gerrit J. J. van den Burg, Gen Suzuki, Wei Liu, Murat Sensoy

Large language models (LLMs) are increasingly used as automated judges to
evaluate recommendation systems, search engines, and other subjective tasks,
where relying on human evaluators can be costly, time-consuming, and
unscalable. LLMs offer an efficient solution for continuous, automated
evaluation. However, since the systems that are built and improved with these
judgments are ultimately designed for human use, it is crucial that LLM
judgments align closely with human evaluators to ensure such systems remain
human-centered. On the other hand, aligning LLM judgments with human evaluators
is challenging due to individual variability and biases in human judgments. We
propose a simple yet effective framework to align LLM judgments with individual
human evaluators or their aggregated judgments, without retraining or
fine-tuning the LLM. Our approach learns a linear mapping between the LLM's
outputs and human judgments, achieving over 142% average improvement in
agreement across 29 tasks with only a small number of calibration examples used
for training. Notably, our method works in zero-shot and few-shot settings,
exceeds inter-human agreement on four out of six tasks, and enables smaller
LLMs to achieve performance comparable to that of larger models.

摘要：大型語言模型 (LLM) 愈來愈常被用作自動評審員，用於評估推薦系統、搜尋引擎和其他主觀任務，而仰賴人類評審員可能會耗費成本、耗時且無法擴充。LLM 提供了一種持續、自動化評估的有效解決方案。然而，由於使用這些判斷所建構和改善的系統最終是設計給人類使用的，因此 LLM 判斷與人類評審員緊密吻合至關重要，以確保此類系統仍然以人為中心。另一方面，由於人類判斷中的個別變異性和偏見，讓 LLM 判斷與人類評審員保持一致是一項挑戰。我們提出一個簡單但有效的架構，用於將 LLM 判斷與個別人類評審員或其彙總判斷保持一致，而無需重新訓練或微調 LLM。我們的做法會學習 LLM 輸出與人類判斷之間的線性對應，在 29 項任務中達成平均改善 142% 以上，而僅使用少量校正範例進行訓練。值得注意的是，我們的做法在零次學習和少量學習的設定中都有效，在六項任務中有四項超過人與人之間的共識，並讓較小的 LLM 能夠達成與較大模型相當的效能。

##### **CoCoA: A Generalized Approach to Uncertainty Quantification by Integrating Confidence and Consistency of LLM Outputs**
2502.04964v1 by Roman Vashurin, Maiya Goloburda, Preslav Nakov, Artem Shelmanov, Maxim Panov

Uncertainty quantification (UQ) methods for Large Language Models (LLMs)
encompasses a variety of approaches, with two major types being particularly
prominent: information-based, which focus on model confidence expressed as
token probabilities, and consistency-based, which assess the semantic
relationship between multiple outputs generated using repeated sampling.
Several recent methods have combined these two approaches and shown impressive
performance in various applications. However, they sometimes fail to outperform
much simpler baseline methods. Our investigation reveals distinctive
characteristics of LLMs as probabilistic models, which help to explain why
these UQ methods underperform in certain tasks. Based on these findings, we
propose a new way of synthesizing model confidence and output consistency that
leads to a family of efficient and robust UQ methods. We evaluate our approach
across a variety of tasks such as question answering, abstractive
summarization, and machine translation, demonstrating sizable improvements over
state-of-the-art UQ approaches.

摘要：大型語言模型 (LLM) 的不確定性量化 (UQ) 方法包含各種方法，其中兩種主要類型特別突出：基於信息的，它著重於模型信心，表示為權杖機率，以及基於一致性的，它評估使用重複抽樣產生的多個輸出之間的語義關係。最近的幾種方法結合了這兩種方法，並在各種應用中展現了令人印象深刻的效能。然而，它們有時無法超越更簡單的基本方法。我們的調查揭示了 LLM 作為機率模型的獨特特徵，有助於解釋為什麼這些 UQ 方法在某些任務中的表現不佳。根據這些發現，我們提出了一種合成模型信心和輸出一致性的新方法，這導致了一系列有效且穩健的 UQ 方法。我們在各種任務中評估我們的做法，例如問答、抽象摘要和機器翻譯，展示了對最先進的 UQ 方法的顯著改進。

##### **Fast Adaptive Anti-Jamming Channel Access via Deep Q Learning and Coarse-Grained Spectrum Prediction**
2502.04963v1 by Jianshu Zhang, Xiaofu Wu, Junquan Hu

This paper investigates the anti-jamming channel access problem in complex
and unknown jamming environments, where the jammer could dynamically adjust its
strategies to target different channels. Traditional channel hopping
anti-jamming approaches using fixed patterns are ineffective against such
dynamic jamming attacks. Although the emerging deep reinforcement learning
(DRL) based dynamic channel access approach could achieve the Nash equilibrium
under fast-changing jamming attacks, it requires extensive training episodes.
To address this issue, we propose a fast adaptive anti-jamming channel access
approach guided by the intuition of ``learning faster than the jammer", where a
synchronously updated coarse-grained spectrum prediction serves as an auxiliary
task for the deep Q learning (DQN) based anti-jamming model. This helps the
model identify a superior Q-function compared to standard DRL while
significantly reducing the number of training episodes. Numerical results
indicate that the proposed approach significantly accelerates the rate of
convergence in model training, reducing the required training episodes by up to
70% compared to standard DRL. Additionally, it also achieves a 10% improvement
in throughput over NE strategies, owing to the effective use of coarse-grained
spectrum prediction.

摘要：本文探討複雜且未知的干擾環境中的防干擾頻道存取問題，其中干擾者可以動態調整其策略以鎖定不同的頻道。使用固定模式的傳統頻道跳頻防干擾方法對於此類動態干擾攻擊無效。儘管新興的基於深度強化學習 (DRL) 的動態頻道存取方法可以在快速變化的干擾攻擊下實現納什均衡，但它需要大量的訓練回合。為了解決這個問題，我們提出了一種快速適應性防干擾頻道存取方法，其指導思想是「比干擾者學習得更快」，其中同步更新的粗粒度頻譜預測作為基於深度 Q 學習 (DQN) 的防干擾模型的輔助任務。這有助於模型識別與標準 DRL 相比更優越的 Q 函數，同時顯著減少訓練回合數。數值結果表明，所提出的方法顯著加快了模型訓練中的收斂速度，與標準 DRL 相比，將所需的訓練回合數減少了 70%。此外，由於有效利用了粗粒度頻譜預測，它還將吞吐量提高了 10%，超過了 NE 策略。

##### **Commonality and Individuality! Integrating Humor Commonality with Speaker Individuality for Humor Recognition**
2502.04960v1 by Haohao Zhu, Junyu Lu, Zeyuan Zeng, Zewen Bai, Xiaokun Zhang, Liang Yang, Hongfei Lin

Humor recognition aims to identify whether a specific speaker's text is
humorous. Current methods for humor recognition mainly suffer from two
limitations: (1) they solely focus on one aspect of humor commonalities,
ignoring the multifaceted nature of humor; and (2) they typically overlook the
critical role of speaker individuality, which is essential for a comprehensive
understanding of humor expressions. To bridge these gaps, we introduce the
Commonality and Individuality Incorporated Network for Humor Recognition
(CIHR), a novel model designed to enhance humor recognition by integrating
multifaceted humor commonalities with the distinctive individuality of
speakers. The CIHR features a Humor Commonality Analysis module that explores
various perspectives of multifaceted humor commonality within user texts, and a
Speaker Individuality Extraction module that captures both static and dynamic
aspects of a speaker's profile to accurately model their distinctive
individuality. Additionally, Static and Dynamic Fusion modules are introduced
to effectively incorporate the humor commonality with speaker's individuality
in the humor recognition process. Extensive experiments demonstrate the
effectiveness of CIHR, underscoring the importance of concurrently addressing
both multifaceted humor commonality and distinctive speaker individuality in
humor recognition.

摘要：幽默辨識旨在辨識特定說話者的文字是否幽默。目前幽默辨識的方法主要有兩個限制：(1) 它們僅專注於幽默共性的某個面向，忽略了幽默的多面向本質；(2) 它們通常忽略了說話者個人特質的關鍵角色，而這對於全面理解幽默表達至關重要。為了彌補這些差距，我們引入了幽默辨識的共性和個人特質整合網路 (CIHR)，這是一個新穎的模型，旨在透過整合多面向的幽默共性與說話者的獨特個人特質來增強幽默辨識。CIHR 具有幽默共性分析模組，可探索使用者文字中多面向幽默共性的各種觀點，以及說話者個人特質萃取模組，可擷取說話者個人資料的靜態和動態面向，以準確建模其獨特的個人特質。此外，還引入了靜態和動態融合模組，以便在幽默辨識過程中有效地將幽默共性與說話者的個人特質結合起來。廣泛的實驗證明了 CIHR 的有效性，強調了在幽默辨識中同時處理多面向幽默共性和獨特的說話者個人特質的重要性。

##### **SSMLoRA: Enhancing Low-Rank Adaptation with State Space Model**
2502.04958v1 by Jiayang Yu, Yihang Zhang, Bin Wang, Peiqin Lin, Yongkang Liu, Shi Feng

Fine-tuning is a key approach for adapting language models to specific
downstream tasks, but updating all model parameters becomes impractical as
model sizes increase. Parameter-Efficient Fine-Tuning (PEFT) methods, such as
Low-Rank Adaptation (LoRA), address this challenge by introducing additional
adaptation parameters into pre-trained weight matrices. However, LoRA's
performance varies across different insertion points within the model,
highlighting potential parameter inefficiency due to unnecessary insertions. To
this end, we propose SSMLoRA (State Space Model Low-Rank Adaptation), an
extension of LoRA that incorporates a State Space Model (SSM) to interconnect
low-rank matrices. SSMLoRA ensures that performance is maintained even with
sparser insertions. SSMLoRA allows the model to not only map inputs to a
low-rank space for better feature extraction but also leverage the computations
from the previous low-rank space. Our method achieves comparable performance to
LoRA on the General Language Understanding Evaluation (GLUE) benchmark while
using only half the parameters. Additionally, due to its structure, SSMLoRA
shows promise in handling tasks with longer input sequences. .You can find our
code here:https://github.com/yuhkalhic/SSMLoRA.

摘要：微調是一種將語言模型適應到特定下游任務的主要方法，但隨著模型規模的增加，更新所有模型參數變得不切實際。參數高效微調 (PEFT) 方法（例如低秩適應 (LoRA)）通過在預訓練權重矩陣中引入額外的適應參數來解決這一挑戰。然而，LoRA 的性能會因模型中的不同插入點而異，這突顯了由於不必要的插入而導致的潛在參數效率低下。為此，我們提出了 SSMLoRA（狀態空間模型低秩適應），這是一種 LoRA 的擴展，它結合了狀態空間模型 (SSM) 來互連低秩矩陣。SSMLoRA 確保即使在插入較稀疏的情況下也能保持性能。SSMLoRA 不僅允許模型將輸入映射到低秩空間以進行更好的特徵提取，而且還利用了來自先前低秩空間的計算。我們的模型在通用語言理解評估 (GLUE) 基準上實現了與 LoRA 相當的性能，同時僅使用了後者一半的參數。此外，由於其結構，SSMLoRA 在處理具有較長輸入序列的任務方面顯示出前景。您可以在這裡找到我們的代碼：https://github.com/yuhkalhic/SSMLoRA。

##### **Claim Extraction for Fact-Checking: Data, Models, and Automated Metrics**
2502.04955v1 by Herbert Ullrich, Tomáš Mlynář, Jan Drchal

In this paper, we explore the problem of Claim Extraction using one-to-many
text generation methods, comparing LLMs, small summarization models finetuned
for the task, and a previous NER-centric baseline QACG. As the current
publications on Claim Extraction, Fact Extraction, Claim Generation and
Check-worthy Claim Detection are quite scattered in their means and
terminology, we compile their common objectives, releasing the FEVERFact
dataset, with 17K atomic factual claims extracted from 4K contextualised
Wikipedia sentences, adapted from the original FEVER. We compile the known
objectives into an Evaluation framework of: Atomicity, Fluency,
Decontextualization, Faithfulness checked for each generated claim separately,
and Focus and Coverage measured against the full set of predicted claims for a
single input. For each metric, we implement a scale using a reduction to an
already-explored NLP task. We validate our metrics against human grading of
generic claims, to see that the model ranking on $F_{fact}$, our hardest
metric, did not change and the evaluation framework approximates human grading
very closely in terms of $F_1$ and RMSE.

摘要：在本文中，我们使用一对多的文本生成方法探討聲明抽取的問題，比較 LLM、針對此任務微調的小型摘要模型以及先前的 NER 為中心的基準 QACG。由於目前關於聲明抽取、事實抽取、聲明生成和值得檢查的聲明偵測的出版物在方法和術語上相當分散，我們編制了它們的共同目標，發布了 FEVERFact 資料集，其中包含從 4K 個語境化維基百科句子中抽取的 17K 原子事實聲明，改編自原始的 FEVER。我們將已知的目標編譯成一個評估框架：原子性、流暢性、去脈絡化、忠實度分別檢查每個生成的聲明，以及針對單一輸入預測的聲明全集測量焦點和覆蓋率。對於每個指標，我們使用簡化為已探討的 NLP 任務來實作一個量表。我們根據人類對一般性聲明評級驗證我們的指標，以查看模型在 $F_{fact}$（我們最困難的指標）上的排名沒有改變，並且評估框架在 $F_1$ 和 RMSE 方面非常接近人類評級。

##### **The Rising Threat to Emerging AI-Powered Search Engines**
2502.04951v1 by Zeren Luo, Zifan Peng, Yule Liu, Zhen Sun, Mingchen Li, Jingyi Zheng, Xinlei He

Recent advancements in Large Language Models (LLMs) have significantly
enhanced the capabilities of AI-Powered Search Engines (AIPSEs), offering
precise and efficient responses by integrating external databases with
pre-existing knowledge. However, we observe that these AIPSEs raise risks such
as quoting malicious content or citing malicious websites, leading to harmful
or unverified information dissemination. In this study, we conduct the first
safety risk quantification on seven production AIPSEs by systematically
defining the threat model, risk level, and evaluating responses to various
query types. With data collected from PhishTank, ThreatBook, and LevelBlue, our
findings reveal that AIPSEs frequently generate harmful content that contains
malicious URLs even with benign queries (e.g., with benign keywords). We also
observe that directly query URL will increase the risk level while query with
natural language will mitigate such risk. We further perform two case studies
on online document spoofing and phishing to show the ease of deceiving AIPSEs
in the real-world setting. To mitigate these risks, we develop an agent-based
defense with a GPT-4o-based content refinement tool and an XGBoost-based URL
detector. Our evaluation shows that our defense can effectively reduce the risk
but with the cost of reducing available information. Our research highlights
the urgent need for robust safety measures in AIPSEs.

摘要：大型語言模型 (LLM) 的最新進展顯著增強了 AI 驅動搜尋引擎 (AIPSE) 的能力，透過將外部資料庫與既有知識整合，提供精確且有效率的回應。然而，我們觀察到這些 AIPSE 會引發風險，例如引用惡意內容或引述惡意網站，進而導致有害或未經驗證的資訊散布。在這項研究中，我們對七個生產用 AIPSE 進行了首次安全風險量化，透過系統性地定義威脅模型、風險等級，並評估對各種查詢類型的回應。透過從 PhishTank、ThreatBook 和 LevelBlue 收集的資料，我們的研究結果顯示，即使是良善的查詢（例如，使用良善的關鍵字），AIPSE 也經常會產生包含惡意 URL 的有害內容。我們也觀察到，直接查詢 URL 會增加風險等級，而使用自然語言查詢會降低這種風險。我們進一步針對線上文件詐騙和網路釣魚進行了兩個案例研究，以顯示在真實世界中欺騙 AIPSE 的容易性。為了降低這些風險，我們開發了一個基於代理的防禦措施，其中包含一個基於 GPT-4o 的內容精煉工具和一個基於 XGBoost 的 URL 偵測器。我們的評估顯示，我們的防禦措施可以有效降低風險，但代價是減少可用的資訊。我們的研究突顯了在 AIPSE 中迫切需要強健的安全措施。

##### **Conformal Prediction for Electricity Price Forecasting in the Day-Ahead and Real-Time Balancing Market**
2502.04935v1 by Ciaran O'Connor, Mohamed Bahloul, Roberto Rossi, Steven Prestwich, Andrea Visentin

The integration of renewable energy into electricity markets poses
significant challenges to price stability and increases the complexity of
market operations. Accurate and reliable electricity price forecasting is
crucial for effective market participation, where price dynamics can be
significantly more challenging to predict. Probabilistic forecasting, through
prediction intervals, efficiently quantifies the inherent uncertainties in
electricity prices, supporting better decision-making for market participants.
This study explores the enhancement of probabilistic price prediction using
Conformal Prediction (CP) techniques, specifically Ensemble Batch Prediction
Intervals and Sequential Predictive Conformal Inference. These methods provide
precise and reliable prediction intervals, outperforming traditional models in
validity metrics. We propose an ensemble approach that combines the efficiency
of quantile regression models with the robust coverage properties of time
series adapted CP techniques. This ensemble delivers both narrow prediction
intervals and high coverage, leading to more reliable and accurate forecasts.
We further evaluate the practical implications of CP techniques through a
simulated trading algorithm applied to a battery storage system. The ensemble
approach demonstrates improved financial returns in energy trading in both the
Day-Ahead and Balancing Markets, highlighting its practical benefits for market
participants.

摘要：再生能源整合至電力市場對價格穩定性造成重大挑戰，並增加市場運作的複雜性。精準可靠的電力價格預測對於有效的市場參與至關重要，其中價格動態可能更難以預測。機率預測透過預測區間有效量化電力價格中固有的不確定性，支持市場參與者做出更好的決策。本研究探討使用共形預測 (CP) 技術增強機率價格預測，特別是整體批次預測區間和序列預測共形推論。這些方法提供精確且可靠的預測區間，在有效性指標中優於傳統模型。我們提出一個整體方法，將分位數回歸模型的效率與時間序列適應 CP 技術的穩健覆蓋特性結合起來。這種整體方法既能提供窄小的預測區間，又能提供高覆蓋率，從而產生更可靠、更準確的預測。我們進一步透過應用於電池儲能系統的模擬交易演算法評估 CP 技術的實際影響。整體方法證明在日前市場和平衡市場的能源交易中都能改善財務報酬，突顯其對市場參與者的實際效益。

##### **Cached Multi-Lora Composition for Multi-Concept Image Generation**
2502.04923v1 by Xiandong Zou, Mingzhu Shen, Christos-Savvas Bouganis, Yiren Zhao

Low-Rank Adaptation (LoRA) has emerged as a widely adopted technique in
text-to-image models, enabling precise rendering of multiple distinct elements,
such as characters and styles, in multi-concept image generation. However,
current approaches face significant challenges when composing these LoRAs for
multi-concept image generation, resulting in diminished generated image
quality. In this paper, we initially investigate the role of LoRAs in the
denoising process through the lens of the Fourier frequency domain. Based on
the hypothesis that applying multiple LoRAs could lead to "semantic conflicts",
we find that certain LoRAs amplify high-frequency features such as edges and
textures, whereas others mainly focus on low-frequency elements, including the
overall structure and smooth color gradients. Building on these insights, we
devise a frequency domain based sequencing strategy to determine the optimal
order in which LoRAs should be integrated during inference. This strategy
offers a methodical and generalizable solution compared to the naive
integration commonly found in existing LoRA fusion techniques. To fully
leverage our proposed LoRA order sequence determination method in multi-LoRA
composition tasks, we introduce a novel, training-free framework, Cached
Multi-LoRA (CMLoRA), designed to efficiently integrate multiple LoRAs while
maintaining cohesive image generation. With its flexible backbone for
multi-LoRA fusion and a non-uniform caching strategy tailored to individual
LoRAs, CMLoRA has the potential to reduce semantic conflicts in LoRA
composition and improve computational efficiency. Our experimental evaluations
demonstrate that CMLoRA outperforms state-of-the-art training-free LoRA fusion
methods by a significant margin -- it achieves an average improvement of
$2.19\%$ in CLIPScore, and $11.25\%$ in MLLM win rate compared to LoraHub, LoRA
Composite, and LoRA Switch.

摘要：低秩適應 (LoRA) 已成為文字轉圖像模型中廣泛採用的技術，能精準呈現多個不同的元素，例如字元和樣式，以產生多概念的圖像。然而，目前的作法在為多概念圖像生成組合這些 LoRA 時面臨重大的挑戰，導致產生的圖像品質下降。在本文中，我們最初透過傅立葉頻域的透鏡來探討 LoRA 在去噪過程中的角色。根據應用多個 LoRA 可能會導致「語義衝突」的假設，我們發現某些 LoRA 會放大高頻率特徵，例如邊緣和紋理，而其他 LoRA 則主要關注低頻率元素，包括整體結構和平滑的色彩漸層。根據這些見解，我們設計了一個基於頻域的排序策略，以確定在推理期間整合 LoRA 的最佳順序。與現有 LoRA 融合技術中常見的樸素整合相比，此策略提供了一種有條理且可概括的解決方案。為了在多 LoRA 組合任務中充分利用我們提出的 LoRA 順序序列決定方法，我們引入了創新的免訓練架構，稱為快取多 LoRA (CMLoRA)，其設計目的在於有效整合多個 LoRA，同時維持一致的圖像生成。CMLoRA 擁有靈活的多 LoRA 融合主幹，以及針對個別 LoRA 量身打造的非均勻快取策略，有潛力減少 LoRA 組合中的語義衝突，並提升運算效率。我們的實驗評估證明，CMLoRA 的表現顯著優於最先進的免訓練 LoRA 融合方法，與 LoraHub、LoRA Composite 和 LoRA Switch 相比，在 CLIPScore 中平均提升了 $2.19\%$，在 MLLM 勝率中提升了 $11.25\%$。

##### **Unified Approaches in Self-Supervised Event Stream Modeling: Progress and Prospects**
2502.04899v1 by Levente Zólyomi, Tianze Wang, Sofiane Ennadir, Oleg Smirnov, Lele Cao

The proliferation of digital interactions across diverse domains, such as
healthcare, e-commerce, gaming, and finance, has resulted in the generation of
vast volumes of event stream (ES) data. ES data comprises continuous sequences
of timestamped events that encapsulate detailed contextual information relevant
to each domain. While ES data holds significant potential for extracting
actionable insights and enhancing decision-making, its effective utilization is
hindered by challenges such as the scarcity of labeled data and the fragmented
nature of existing research efforts. Self-Supervised Learning (SSL) has emerged
as a promising paradigm to address these challenges by enabling the extraction
of meaningful representations from unlabeled ES data. In this survey, we
systematically review and synthesize SSL methodologies tailored for ES modeling
across multiple domains, bridging the gaps between domain-specific approaches
that have traditionally operated in isolation. We present a comprehensive
taxonomy of SSL techniques, encompassing both predictive and contrastive
paradigms, and analyze their applicability and effectiveness within different
application contexts. Furthermore, we identify critical gaps in current
research and propose a future research agenda aimed at developing scalable,
domain-agnostic SSL frameworks for ES modeling. By unifying disparate research
efforts and highlighting cross-domain synergies, this survey aims to accelerate
innovation, improve reproducibility, and expand the applicability of SSL to
diverse real-world ES challenges.

摘要：隨著醫療保健、電子商務、遊戲和金融等不同領域的數位互動激增，已經產生了大量事件串流 (ES) 資料。ES 資料包含連續的帶時間戳記事件序列，其中包含與每個領域相關的詳細背景資訊。儘管 ES 資料在提取可操作見解和增強決策制定方面具有顯著潛力，但其有效利用受到標籤資料稀缺和現有研究工作分散等挑戰的阻礙。自監督學習 (SSL) 已成為應對這些挑戰的一種有前途的範例，它能從未標籤的 ES 資料中提取有意義的表示。在這項調查中，我們系統地回顧並綜合了針對多個領域的 ES 建模而量身定制的 SSL 方法，彌合了傳統上孤立運作的特定領域方法之間的差距。我們提出了 SSL 技術的全面分類法，涵蓋了預測和對比範例，並分析了它們在不同應用情境中的適用性和有效性。此外，我們還找出當前研究中的關鍵差距，並提出了一項未來的研究議程，旨在開發適用於 ES 建模的可擴充、與領域無關的 SSL 架構。透過統一不同的研究工作並強調跨領域的綜效作用，本調查旨在加速創新、提高可複製性，並擴展 SSL 在不同真實世界 ES 挑戰中的適用性。

##### **Evaluating Standard and Dialectal Frisian ASR: Multilingual Fine-tuning and Language Identification for Improved Low-resource Performance**
2502.04883v1 by Reihaneh Amooie, Wietse de Vries, Yun Hao, Jelske Dijkstra, Matt Coler, Martijn Wieling

Automatic Speech Recognition (ASR) performance for low-resource languages is
still far behind that of higher-resource languages such as English, due to a
lack of sufficient labeled data. State-of-the-art methods deploy
self-supervised transfer learning where a model pre-trained on large amounts of
data is fine-tuned using little labeled data in a target low-resource language.
In this paper, we present and examine a method for fine-tuning an SSL-based
model in order to improve the performance for Frisian and its regional dialects
(Clay Frisian, Wood Frisian, and South Frisian). We show that Frisian ASR
performance can be improved by using multilingual (Frisian, Dutch, English and
German) fine-tuning data and an auxiliary language identification task. In
addition, our findings show that performance on dialectal speech suffers
substantially, and, importantly, that this effect is moderated by the
elicitation approach used to collect the dialectal data. Our findings also
particularly suggest that relying solely on standard language data for ASR
evaluation may underestimate real-world performance, particularly in languages
with substantial dialectal variation.

摘要：自動語音辨識 (ASR) 對於低資源語言的表現仍然遠遠落後於英語等高資源語言，原因在於標記資料不足。最先進的方法採用自我監督式遷移學習，其中一個預先在大量資料上訓練的模型會使用目標低資源語言中少量的標記資料進行微調。在本文中，我們提出並檢驗一種微調基於 SSL 的模型的方法，以改善弗里西亞語及其區域方言（克萊弗里西亞語、伍德弗里西亞語和南弗里西亞語）的表現。我們證明，透過使用多語言（弗里西亞語、荷蘭語、英語和德語）微調資料和輔助語言辨識任務，可以改善弗里西亞語 ASR 的表現。此外，我們的研究結果顯示，方言語音的表現大幅下降，而且重要的是，這種效應會受到用於收集方言資料的引出方法影響。我們的研究結果還特別表明，僅依賴標準語言資料進行 ASR 評估可能會低估實際的表現，特別是在方言變化很大的語言中。

##### **pytopicgram: A library for data extraction and topic modeling from Telegram channels**
2502.04882v1 by J. Gómez-Romero, J. Cantón Correa, R. Pérez Mercado, F. Prados Abad, M. Molina-Solana, W. Fajardo

Telegram is a popular platform for public communication, generating large
amounts of messages through its channels. pytopicgram is a Python library that
helps researchers collect, organize, and analyze these Telegram messages. The
library offers key features such as easy message retrieval, detailed channel
information, engagement metrics, and topic identification using advanced
modeling techniques. By simplifying data extraction and analysis, pytopicgram
allows users to understand how content spreads and how audiences interact on
Telegram. This paper describes the design, main features, and practical uses of
\pytopicgram, showcasing its effectiveness for studying public conversations on
Telegram.

摘要：Telegram 是一个用于公开交流的热门平台，通过其频道生成大量消息。pytopicgram 是一个 Python 库，可帮助研究人员收集、整理和分析这些 Telegram 消息。该库提供了一些关键功能，例如轻松检索消息、详细的频道信息、参与度指标以及使用高级建模技术识别主题。通过简化数据提取和分析，pytopicgram 允许用户了解内容如何在 Telegram 上传播以及受众如何在 Telegram 上互动。本文介绍了 \pytopicgram 的设计、主要功能和实际用法，展示了其在研究 Telegram 上的公开对话方面的有效性。

##### **Sparse Autoencoders Do Not Find Canonical Units of Analysis**
2502.04878v1 by Patrick Leask, Bart Bussmann, Michael Pearce, Joseph Bloom, Curt Tigges, Noura Al Moubayed, Lee Sharkey, Neel Nanda

A common goal of mechanistic interpretability is to decompose the activations
of neural networks into features: interpretable properties of the input
computed by the model. Sparse autoencoders (SAEs) are a popular method for
finding these features in LLMs, and it has been postulated that they can be
used to find a \textit{canonical} set of units: a unique and complete list of
atomic features. We cast doubt on this belief using two novel techniques: SAE
stitching to show they are incomplete, and meta-SAEs to show they are not
atomic. SAE stitching involves inserting or swapping latents from a larger SAE
into a smaller one. Latents from the larger SAE can be divided into two
categories: \emph{novel latents}, which improve performance when added to the
smaller SAE, indicating they capture novel information, and
\emph{reconstruction latents}, which can replace corresponding latents in the
smaller SAE that have similar behavior. The existence of novel features
indicates incompleteness of smaller SAEs. Using meta-SAEs -- SAEs trained on
the decoder matrix of another SAE -- we find that latents in SAEs often
decompose into combinations of latents from a smaller SAE, showing that larger
SAE latents are not atomic. The resulting decompositions are often
interpretable; e.g. a latent representing ``Einstein'' decomposes into
``scientist'', ``Germany'', and ``famous person''. Even if SAEs do not find
canonical units of analysis, they may still be useful tools. We suggest that
future research should either pursue different approaches for identifying such
units, or pragmatically choose the SAE size suited to their task. We provide an
interactive dashboard to explore meta-SAEs: https://metasaes.streamlit.app/

摘要：<paragraph>機制可解釋性的共同目標是將神經網路的活化分解為特徵：模型計算的輸入的可解釋屬性。稀疏自動編碼器 (SAE) 是在 LLM 中尋找這些特徵的流行方法，並且已假設它們可用於尋找一組「規範」的單元：一個獨特且完整的原子特徵清單。我們使用兩種新技術對此信念提出質疑：SAE 拼接以證明它們不完整，以及元 SAE 以證明它們不是原子的。SAE 拼接涉及將較大 SAE 中的潛在變數插入或換到較小的 SAE 中。較大 SAE 中的潛在變數可分為兩類：當新增到較小的 SAE 時會提升效能的「新穎潛在變數」，表示它們擷取了新穎資訊，以及可以取代較小 SAE 中具有類似行為的對應潛在變數的「重建潛在變數」。新穎特徵的存在表示較小的 SAE 不完整。使用元 SAE（在另一個 SAE 的解碼器矩陣上訓練的 SAE），我們發現 SAE 中的潛在變數通常會分解為來自較小 SAE 的潛在變數組合，這表示較大的 SAE 潛在變數並非原子。產生的分解通常是可解釋的；例如，表示「愛因斯坦」的潛在變數分解為「科學家」、「德國」和「名人」。即使 SAE 沒有找到分析的規範單位，它們仍然可能是實用的工具。我們建議未來的研究應採用不同的方法來識別此類單位，或務實地選擇適合其任務的 SAE 大小。我們提供了一個互動式儀表板來探索元 SAE：https://metasaes.streamlit.app/</paragraph>

##### **Enhancing Disinformation Detection with Explainable AI and Named Entity Replacement**
2502.04863v1 by Santiago González-Silot, Andrés Montoro-Montarroso, Eugenio Martínez Cámara, Juan Gómez-Romero

The automatic detection of disinformation presents a significant challenge in
the field of natural language processing. This task addresses a multifaceted
societal and communication issue, which needs approaches that extend beyond the
identification of general linguistic patterns through data-driven algorithms.
In this research work, we hypothesise that text classification methods are not
able to capture the nuances of disinformation and they often ground their
decision in superfluous features. Hence, we apply a post-hoc explainability
method (SHAP, SHapley Additive exPlanations) to identify spurious elements with
high impact on the classification models. Our findings show that
non-informative elements (e.g., URLs and emoticons) should be removed and named
entities (e.g., Rwanda) should be pseudo-anonymized before training to avoid
models' bias and increase their generalization capabilities. We evaluate this
methodology with internal dataset and external dataset before and after
applying extended data preprocessing and named entity replacement. The results
show that our proposal enhances on average the performance of a disinformation
classification method with external test data in 65.78% without a significant
decrease of the internal test performance.

摘要：自然語言處理領域中，自動偵測錯誤資訊是一項重大挑戰。這項任務處理的是多方面的社會和溝通議題，需要超越透過資料驅動演算法來辨識一般語言模式的方法。在這個研究工作中，我們假設文字分類方法無法捕捉到錯誤資訊的細微差別，而且它們常常將決策基礎建立在多餘的特徵上。因此，我們應用事後可解釋性方法（SHAP，SHapley 加法解釋）來找出對分類模型有重大影響的虛假元素。我們的研究結果顯示，在訓練之前應移除非資訊性元素（例如網址和表情符號），並將命名實體（例如盧安達）進行偽匿名化，以避免模型偏誤並提升其概化能力。我們在應用延伸資料前處理和命名實體替換之前和之後，以內部資料集和外部資料集評估此方法。結果顯示，我們的提案平均提升了錯誤資訊分類方法在外部測試資料上的效能，達 65.78%，而內部測試效能並未顯著下降。

##### **Lightweight Operations for Visual Speech Recognition**
2502.04834v1 by Iason Ioannis Panagos, Giorgos Sfikas, Christophoros Nikou

Visual speech recognition (VSR), which decodes spoken words from video data,
offers significant benefits, particularly when audio is unavailable. However,
the high dimensionality of video data leads to prohibitive computational costs
that demand powerful hardware, limiting VSR deployment on resource-constrained
devices. This work addresses this limitation by developing lightweight VSR
architectures. Leveraging efficient operation design paradigms, we create
compact yet powerful models with reduced resource requirements and minimal
accuracy loss. We train and evaluate our models on a large-scale public dataset
for recognition of words from video sequences, demonstrating their
effectiveness for practical applications. We also conduct an extensive array of
ablative experiments to thoroughly analyze the size and complexity of each
model. Code and trained models will be made publicly available.

摘要：視覺語音辨識 (VSR) 從影片資料中解碼出所說的話語，
在音訊不可用時特別有幫助。然而，
影片資料的高維度會導致高昂的運算成本，
需要強大的硬體，限制了 VSR 在資源受限的
裝置上部署。這項工作透過開發輕量化的 VSR
架構來解決這個限制。利用高效的運算設計範例，我們建立
精簡但強大的模型，減少資源需求，並將準確度損失降至最低。我們在一個大規模的公開資料集上訓練並評估我們的模型，
以辨識影片序列中的字詞，證明它們在實際應用中的有效性。我們也進行了一系列廣泛的消融實驗，以徹底分析每個
模型的大小和複雜性。程式碼和訓練好的模型將公開提供。

##### **Optimistic Gradient Learning with Hessian Corrections for High-Dimensional Black-Box Optimization**
2502.04829v1 by Yedidya Kfir, Elad Sarafian, Sarit Kraus, Yoram Louzoun

Black-box algorithms are designed to optimize functions without relying on
their underlying analytical structure or gradient information, making them
essential when gradients are inaccessible or difficult to compute. Traditional
methods for solving black-box optimization (BBO) problems predominantly rely on
non-parametric models and struggle to scale to large input spaces. Conversely,
parametric methods that model the function with neural estimators and obtain
gradient signals via backpropagation may suffer from significant gradient
errors. A recent alternative, Explicit Gradient Learning (EGL), which directly
learns the gradient using a first-order Taylor approximation, has demonstrated
superior performance over both parametric and non-parametric methods. In this
work, we propose two novel gradient learning variants to address the robustness
challenges posed by high-dimensional, complex, and highly non-linear problems.
Optimistic Gradient Learning (OGL) introduces a bias toward lower regions in
the function landscape, while Higher-order Gradient Learning (HGL) incorporates
second-order Taylor corrections to improve gradient accuracy. We combine these
approaches into the unified OHGL algorithm, achieving state-of-the-art (SOTA)
performance on the synthetic COCO suite. Additionally, we demonstrate OHGLs
applicability to high-dimensional real-world machine learning (ML) tasks such
as adversarial training and code generation. Our results highlight OHGLs
ability to generate stronger candidates, offering a valuable tool for ML
researchers and practitioners tackling high-dimensional, non-linear
optimization challenges

摘要：黑盒演算法旨在最佳化函數，而無需依賴其基礎分析結構或梯度資訊，使其在無法取得梯度或難以運算梯度時，成為必要的工具。解決黑盒最佳化 (BBO) 問題的傳統方法主要依賴於非參數模型，且難以擴展到大型輸入空間。相反地，使用神經估計器對函數進行建模並透過反向傳播取得梯度訊號的參數方法，可能會產生顯著的梯度誤差。最近的替代方法，即明確梯度學習 (EGL)，直接使用一階泰勒近似來學習梯度，已證明其效能優於參數和非參數方法。在這項研究中，我們提出兩種新穎的梯度學習變體，以解決高維度、複雜且高度非線性問題所帶來的穩健性挑戰。樂觀梯度學習 (OGL) 在函數景觀中引入了對較低區域的偏差，而高階梯度學習 (HGL) 結合了二階泰勒校正，以提高梯度準確度。我們將這些方法結合到統一的 OHGL 演算法中，在合成 COCO 套件上達到了最先進 (SOTA) 的效能。此外，我們展示了 OHGL 可應用於高維度真實世界機器學習 (ML) 任務，例如對抗性訓練和程式碼生成。我們的結果突顯了 OHGL 生成更強候選者的能力，為解決高維度、非線性最佳化挑戰的機器學習研究人員和從業人員提供了有價值的工具

##### **Self-Rationalization in the Wild: A Large Scale Out-of-Distribution Evaluation on NLI-related tasks**
2502.04797v1 by Jing Yang, Max Glockner, Anderson Rocha, Iryna Gurevych

Free-text explanations are expressive and easy to understand, but many
datasets lack annotated explanation data, making it challenging to train models
for explainable predictions. To address this, we investigate how to use
existing explanation datasets for self-rationalization and evaluate models'
out-of-distribution (OOD) performance. We fine-tune T5-Large and OLMo-7B models
and assess the impact of fine-tuning data quality, the number of fine-tuning
samples, and few-shot selection methods. The models are evaluated on 19 diverse
OOD datasets across three tasks: natural language inference (NLI),
fact-checking, and hallucination detection in abstractive summarization. For
the generated explanation evaluation, we conduct a human study on 13 selected
models and study its correlation with the Acceptability score (T5-11B) and
three other LLM-based reference-free metrics. Human evaluation shows that the
Acceptability score correlates most strongly with human judgments,
demonstrating its effectiveness in evaluating free-text explanations. Our
findings reveal: 1) few annotated examples effectively adapt models for OOD
explanation generation; 2) compared to sample selection strategies, fine-tuning
data source has a larger impact on OOD performance; and 3) models with higher
label prediction accuracy tend to produce better explanations, as reflected by
higher Acceptability scores.

摘要：自由文本說明具有表達性和易於理解，但許多資料集缺乏註解說明資料，這使得訓練可解釋預測的模型具有挑戰性。為了解決這個問題，我們研究如何使用現有的說明資料集進行自我合理化並評估模型的分布外 (OOD) 效能。我們微調 T5-Large 和 OLMo-7B 模型，並評估微調資料品質、微調樣本數量和少次選取方法的影響。這些模型在 19 個不同的 OOD 資料集上進行評估，涵蓋三個任務：自然語言推論 (NLI)、事實查核和抽象摘要中的幻覺偵測。對於產生的說明評估，我們對 13 個選定的模型進行人體研究，並研究其與可接受性評分 (T5-11B) 和其他三個基於 LLM 的無參考指標的相關性。人體評估顯示，可接受性評分與人類判斷最為相關，證明其在評估自由文本說明方面的有效性。我們的研究結果顯示：1) 少量的註解範例可以有效地使模型適應 OOD 說明產生；2) 與樣本選取策略相比，微調資料來源對 OOD 效能有更大的影響；3) 標籤預測準確度較高的模型往往會產生更好的說明，這反映在較高的可接受性評分中。

##### **Developmentally-plausible Working Memory Shapes a Critical Period for Language Acquisition**
2502.04795v1 by Masato Mita, Ryo Yoshida, Yohei Oseki

Large language models exhibit general linguistic abilities but significantly
differ from humans in their efficiency of language acquisition. This study
proposes a method for integrating the developmental characteristics of working
memory during the critical period, a stage when human language acquisition is
particularly efficient, into language models. The proposed method introduces a
mechanism that initially constrains working memory during the early stages of
training and gradually relaxes this constraint in an exponential manner as
learning progresses. Targeted syntactic evaluation shows that the proposed
method outperforms conventional models without memory constraints or with
static memory constraints. These findings not only provide new directions for
designing data-efficient language models but also offer indirect evidence
supporting the underlying mechanisms of the critical period hypothesis in human
language acquisition.

摘要：大型語言模型展現了一般的語言能力，但在語言習得的效率上與人類有顯著的差異。本研究提出了一個方法，將工作記憶在關鍵期的發展特徵整合到語言模型中，關鍵期是人類語言習得特別有效率的階段。所提出的方法引入了一種機制，最初在訓練的早期階段限制工作記憶，並隨著學習的進展以指數方式逐漸放寬此限制。有針對性的句法評估顯示，所提出的方法優於沒有記憶限制或具有靜態記憶限制的傳統模型。這些發現不僅為設計資料有效率的語言模型提供了新的方向，也提供了支持人類語言習得中關鍵期假設的基礎機制的間接證據。

##### **MedMimic: Physician-Inspired Multimodal Fusion for Early Diagnosis of Fever of Unknown Origin**
2502.04794v1 by Minrui Chen, Yi Zhou, Huidong Jiang, Yuhan Zhu, Guanjie Zou, Minqi Chen, Rong Tian, Hiroto Saigo

Fever of unknown origin FUO remains a diagnostic challenge. MedMimic is
introduced as a multimodal framework inspired by real-world diagnostic
processes. It uses pretrained models such as DINOv2, Vision Transformer, and
ResNet-18 to convert high-dimensional 18F-FDG PET/CT imaging into
low-dimensional, semantically meaningful features. A learnable
self-attention-based fusion network then integrates these imaging features with
clinical data for classification. Using 416 FUO patient cases from Sichuan
University West China Hospital from 2017 to 2023, the multimodal fusion
classification network MFCN achieved macro-AUROC scores ranging from 0.8654 to
0.9291 across seven tasks, outperforming conventional machine learning and
single-modality deep learning methods. Ablation studies and five-fold
cross-validation further validated its effectiveness. By combining the
strengths of pretrained large models and deep learning, MedMimic offers a
promising solution for disease classification.

摘要：不明原因發燒 (FUO) 仍然是診斷上的挑戰。MedMimic 是一個多模式架構，靈感來自於真實世界的診斷過程。它使用預先訓練的模型，例如 DINOv2、視覺轉換器和 ResNet-18，將高維 18F-FDG PET/CT 影像轉換為低維、語義有意義的特徵。一個可學習的自注意力融合網路接著將這些影像特徵與臨床資料整合，用於分類。使用 2017 年至 2023 年四川大學華西醫院的 416 個 FUO 病患病例，多模式融合分類網路 MFCN 在七項任務中達到了 0.8654 到 0.9291 的巨觀 AUROC 分數，優於傳統機器學習和單一模式深度學習方法。消融研究和五倍交叉驗證進一步驗證了其有效性。MedMimic 結合了預先訓練的大模型和深度學習的優點，為疾病分類提供了一個有前景的解決方案。

##### **S$^2$-MAD: Breaking the Token Barrier to Enhance Multi-Agent Debate Efficiency**
2502.04790v1 by Yuting Zeng, Weizhe Huang, Lei Jiang, Tongxuan Liu, Xitai Jin, Chen Tianying Tiana, Jing Li, Xiaohua Xu

Large language models (LLMs) have demonstrated remarkable capabilities across
various natural language processing (NLP) scenarios, but they still face
challenges when handling complex arithmetic and logical reasoning tasks. While
Chain-Of-Thought (CoT) reasoning, self-consistency (SC) and self-correction
strategies have attempted to guide models in sequential, multi-step reasoning,
Multi-agent Debate (MAD) has emerged as a viable approach for enhancing the
reasoning capabilities of LLMs. By increasing both the number of agents and the
frequency of debates, the performance of LLMs improves significantly. However,
this strategy results in a significant increase in token costs, presenting a
barrier to scalability. To address this challenge, we introduce a novel
sparsification strategy designed to reduce token costs within MAD. This
approach minimizes ineffective exchanges of information and unproductive
discussions among agents, thereby enhancing the overall efficiency of the
debate process. We conduct comparative experiments on multiple datasets across
various models, demonstrating that our approach significantly reduces the token
costs in MAD to a considerable extent. Specifically, compared to MAD, our
approach achieves an impressive reduction of up to 94.5\% in token costs while
maintaining performance degradation below 2.0\%.

摘要：大型語言模型 (LLM) 已在各種自然語言處理 (NLP) 場景中展現出非凡的能力，但它們在處理複雜的算術和邏輯推理任務時仍面臨挑戰。雖然思想鏈 (CoT) 推理、自我一致性 (SC) 和自我修正策略已嘗試引導模型進行循序漸進的多步驟推理，但多主體辯論 (MAD) 已成為一種可行的途徑，可增強 LLM 的推理能力。透過增加主體數量和辯論頻率，LLM 的效能大幅提升。然而，此策略會導致權杖成本大幅增加，對可擴充性造成阻礙。為了解決此挑戰，我們提出了一種創新的稀疏化策略，旨在降低 MAD 中的權杖成本。此方法將無效的資訊交換和主體之間的非生產性討論減至最低，從而提升辯論過程的整體效率。我們在多個資料集上針對各種模型進行比較實驗，證明我們的做法大幅降低了 MAD 中的權杖成本。具體來說，與 MAD 相比，我們的做法將權杖成本降低了驚人的 94.5%，同時將效能下降控制在 2.0% 以下。

##### **Probing Internal Representations of Multi-Word Verbs in Large Language Models**
2502.04789v1 by Hassane Kissane, Achim Schilling, Patrick Krauss

This study investigates the internal representations of verb-particle
combinations, called multi-word verbs, within transformer-based large language
models (LLMs), specifically examining how these models capture lexical and
syntactic properties at different neural network layers. Using the BERT
architecture, we analyze the representations of its layers for two different
verb-particle constructions: phrasal verbs like 'give up' and prepositional
verbs like 'look at'. Our methodology includes training probing classifiers on
the internal representations to classify these categories at both word and
sentence levels. The results indicate that the model's middle layers achieve
the highest classification accuracies. To further analyze the nature of these
distinctions, we conduct a data separability test using the Generalized
Discrimination Value (GDV). While GDV results show weak linear separability
between the two verb types, probing classifiers still achieve high accuracy,
suggesting that representations of these linguistic categories may be
non-linearly separable. This aligns with previous research indicating that
linguistic distinctions in neural networks are not always encoded in a linearly
separable manner. These findings computationally support usage-based claims on
the representation of verb-particle constructions and highlight the complex
interaction between neural network architectures and linguistic structures.

摘要：本研究探討了基於轉換器的大型語言模型 (LLM) 中動詞-介系詞組合（稱為多字動詞）的內部表徵，特別檢視這些模型如何捕捉不同神經網路層的語法和句法屬性。我們使用 BERT 架構，分析其層對於兩個不同動詞-介系詞結構的表徵：短語動詞（例如「放棄」）和介系詞動詞（例如「看著」）。我們的研究方法包括訓練探測分類器，以在單字和句子層級對這些類別進行分類。結果顯示，該模型的中間層達到了最高的分類準確度。為了進一步分析這些區別的性質，我們使用廣義判別值 (GDV) 進行資料可分離性測試。雖然 GDV 結果顯示出這兩種動詞類型之間的線性可分離性較弱，但探測分類器仍能達到高準確度，這表示這些語言類別的表徵可能是非線性可分離的。這與先前的研究一致，指出神經網路中的語言區別並不總是編碼成線性可分離的方式。這些發現以計算方式支持基於使用情況的主張，說明動詞-介系詞結構的表徵，並強調神經網路架構和語言結構之間的複雜互動。

##### **Enhancing SQL Injection Detection and Prevention Using Generative Models**
2502.04786v1 by Naga Sai Dasari, Atta Badii, Armin Moin, Ahmed Ashlam

SQL Injection (SQLi) continues to pose a significant threat to the security
of web applications, enabling attackers to manipulate databases and access
sensitive information without authorisation. Although advancements have been
made in detection techniques, traditional signature-based methods still
struggle to identify sophisticated SQL injection attacks that evade predefined
patterns. As SQLi attacks evolve, the need for more adaptive detection systems
becomes crucial. This paper introduces an innovative approach that leverages
generative models to enhance SQLi detection and prevention mechanisms. By
incorporating Variational Autoencoders (VAE), Conditional Wasserstein GAN with
Gradient Penalty (CWGAN-GP), and U-Net, synthetic SQL queries were generated to
augment training datasets for machine learning models. The proposed method
demonstrated improved accuracy in SQLi detection systems by reducing both false
positives and false negatives. Extensive empirical testing further illustrated
the ability of the system to adapt to evolving SQLi attack patterns, resulting
in enhanced precision and robustness.

摘要：SQL 注入（SQLi）持續對 Web 應用程式的安全性構成重大威脅，讓攻擊者能夠操縱資料庫並未經授權存取敏感資訊。儘管偵測技術已有所進步，但傳統的基於特徵碼的方法仍難以識別規避預定義模式的複雜 SQL 注入攻擊。隨著 SQLi 攻擊的演變，對更具適應性的偵測系統的需求變得至關重要。本文介紹一種創新的方法，利用生成模型來增強 SQLi 偵測和預防機制。透過整合變異自動編碼器 (VAE)、條件 Wasserstein GAN 與梯度懲罰 (CWGAN-GP) 以及 U-Net，生成了合成 SQL 查詢，以擴充機器學習模型的訓練資料集。所提出的方法透過減少誤報和漏報，證明了 SQLi 偵測系統的準確性獲得改善。廣泛的實證測試進一步說明了系統適應不斷演變的 SQLi 攻擊模式的能力，從而提高了精確度和穩健性。

##### **SiriuS: Self-improving Multi-agent Systems via Bootstrapped Reasoning**
2502.04780v1 by Wanjia Zhao, Mert Yuksekgonul, Shirley Wu, James Zou

Multi-agent AI systems powered by large language models (LLMs) are
increasingly applied to solve complex tasks. However, these systems often rely
on fragile, manually designed prompts and heuristics, making optimization
difficult. A key challenge in optimizing multi-agent systems is acquiring
suitable training data for specialized agents. We introduce SiriuS, a
self-improving, reasoning-driven optimization framework for multi-agent
systems. Central to our approach is the construction of an experience library:
a repository of high-quality reasoning trajectories. The library is built by
retaining reasoning steps that lead to successful outcomes, providing a robust
training set for optimizing multi-agent system. Additionally, we introduce a
library augmentation procedure that refines unsuccessful trajectories, further
enriching the library. SiriuS boosts performance by 2.86\% to 21.88\% on
reasoning and biomedical QA and enhances agent negotiation in competitive
settings. Our results show that SiriuS enhances multi-agent performance while
generating reusable data for self-correction and self-play enhancement in the
future.

摘要：由大型語言模型 (LLM) 驅動的多智能體 AI 系統正日益廣泛地應用於解決複雜任務。然而，這些系統通常依賴於脆弱、手動設計的提示和啟發法，這使得最佳化變得困難。最佳化多智能體系統的一項關鍵挑戰是為特定智能體獲取合適的訓練資料。我們引入了 SiriuS，一個自我提升的、基於推理的最佳化框架，用於多智能體系統。我們方法的核心是建立一個經驗庫：一個高品質推理軌跡的儲存庫。這個庫是透過保留導致成功結果的推理步驟而建立的，為最佳化多智能體系統提供了一個穩健的訓練集。此外，我們引入了一個庫擴充程序，用於改善不成功的軌跡，進一步豐富該庫。SiriuS 將推理和生物醫學問答的效能提升了 2.86% 至 21.88%，並增強了在競爭環境中的智能體協商。我們的結果表明，SiriuS 增強了多智能體效能，同時為未來的自我修正和自我對弈增強生成了可重複使用的資料。

##### **Behavior-Regularized Diffusion Policy Optimization for Offline Reinforcement Learning**
2502.04778v1 by Chen-Xiao Gao, Chenyang Wu, Mingjun Cao, Chenjun Xiao, Yang Yu, Zongzhang Zhang

The primary focus of offline reinforcement learning (RL) is to manage the
risk of hazardous exploitation of out-of-distribution actions. An effective
approach to achieve this goal is through behavior regularization, which
augments conventional RL objectives by incorporating constraints that enforce
the policy to remain close to the behavior policy. Nevertheless, existing
literature on behavior-regularized RL primarily focuses on explicit policy
parameterizations, such as Gaussian policies. Consequently, it remains unclear
how to extend this framework to more advanced policy parameterizations, such as
diffusion models. In this paper, we introduce BDPO, a principled
behavior-regularized RL framework tailored for diffusion-based policies,
thereby combining the expressive power of diffusion policies and the robustness
provided by regularization. The key ingredient of our method is to calculate
the Kullback-Leibler (KL) regularization analytically as the accumulated
discrepancies in reverse-time transition kernels along the diffusion
trajectory. By integrating the regularization, we develop an efficient
two-time-scale actor-critic RL algorithm that produces the optimal policy while
respecting the behavior constraint. Comprehensive evaluations conducted on
synthetic 2D tasks and continuous control tasks from the D4RL benchmark
validate its effectiveness and superior performance.

摘要：離線強化學習 (RL) 的主要重點是管理非分佈動作的危險利用風險。實現此目標的一種有效方法是透過行為正則化，它透過納入約束來擴充傳統的 RL 目標，以強制政策保持接近行為政策。儘管如此，現有的行為正則化 RL 文獻主要集中在明確的政策參數化，例如高斯政策。因此，如何將此架構擴展到更進階的政策參數化，例如擴散模型，仍不清楚。在本文中，我們介紹 BDPO，一個專門針對基於擴散的政策的原則性行為正則化 RL 架構，從而結合了擴散政策的表現力與正則化提供的穩健性。我們的方法的關鍵要素是將 Kullback-Leibler (KL) 正則化分析計算為沿著擴散軌跡的反向時間轉換核心中累積的差異。透過整合正則化，我們開發了一個有效率的二時標尺動作-評論家 RL 演算法，可產生最佳政策，同時遵守行為約束。在 D4RL 基準的合成 2D 任務和連續控制任務上進行的全面評估驗證了其有效性和優異的效能。

##### **SeDi-Instruct: Enhancing Alignment of Language Models through Self-Directed Instruction Generation**
2502.04774v1 by Jungwoo Kim, Minsang Kim, Sungjin Lee

The rapid evolution of Large Language Models (LLMs) has enabled the industry
to develop various AI-based services. Instruction tuning is considered
essential in adapting foundation models for target domains to provide
high-quality services to customers. A key challenge in instruction tuning is
obtaining high-quality instruction data. Self-Instruct, which automatically
generates instruction data using ChatGPT APIs, alleviates the data scarcity
problem. To improve the quality of instruction data, Self-Instruct discards
many of the instructions generated from ChatGPT, even though it is inefficient
in terms of cost owing to many useless API calls. To generate high-quality
instruction data at a low cost, we propose a novel data generation framework,
Self-Direct Instruction generation (SeDi-Instruct), which employs
diversity-based filtering and iterative feedback task generation.
Diversity-based filtering maintains model accuracy without excessively
discarding low-quality generated instructions by enhancing the diversity of
instructions in a batch. This reduces the cost of synthesizing instruction
data. The iterative feedback task generation integrates instruction generation
and training tasks and utilizes information obtained during the training to
create high-quality instruction sets. Our results show that SeDi-Instruct
enhances the accuracy of AI models by 5.2%, compared with traditional methods,
while reducing data generation costs by 36%.

摘要：大型語言模型 (LLM) 的快速演進讓產業
能夠開發各種基於 AI 的服務。指令微調被認為
在調整基礎模型以適應目標領域時至關重要，為客戶提供
高品質的服務。指令微調中的主要挑戰是
取得高品質的指令資料。Self-Instruct 自動
使用 ChatGPT API 產生指令資料，緩解資料短缺
的問題。為了提升指令資料的品質，Self-Instruct 捨棄
許多由 ChatGPT 產生的指令，儘管這在成本方面很沒有效率，因為有許多無用的 API 呼叫。為了以低成本產生高品質
的指令資料，我們提出一個新穎的資料產生架構，
Self-Direct 指令產生 (SeDi-Instruct)，它採用
基於多樣性的過濾和反覆回饋任務產生。
基於多樣性的過濾維持模型準確性，同時不會過度
捨棄低品質的產生指令，方法是提升指令在批次中的多樣性。這降低了合成指令
資料的成本。反覆回饋任務產生整合指令產生
和訓練任務，並利用在訓練期間取得的資訊來
建立高品質的指令集。我們的結果顯示 SeDi-Instruct
提升了 AI 模型的準確性 5.2%，相較於傳統方法，
同時將資料產生成本降低了 36%。

##### **DMPA: Model Poisoning Attacks on Decentralized Federated Learning for Model Differences**
2502.04771v1 by Chao Feng, Yunlong Li, Yuanzhe Gao, Alberto Huertas Celdrán, Jan von der Assen, Gérôme Bovet, Burkhard Stiller

Federated learning (FL) has garnered significant attention as a prominent
privacy-preserving Machine Learning (ML) paradigm. Decentralized FL (DFL)
eschews traditional FL's centralized server architecture, enhancing the
system's robustness and scalability. However, these advantages of DFL also
create new vulnerabilities for malicious participants to execute adversarial
attacks, especially model poisoning attacks. In model poisoning attacks,
malicious participants aim to diminish the performance of benign models by
creating and disseminating the compromised model. Existing research on model
poisoning attacks has predominantly concentrated on undermining global models
within the Centralized FL (CFL) paradigm, while there needs to be more research
in DFL. To fill the research gap, this paper proposes an innovative model
poisoning attack called DMPA. This attack calculates the differential
characteristics of multiple malicious client models and obtains the most
effective poisoning strategy, thereby orchestrating a collusive attack by
multiple participants. The effectiveness of this attack is validated across
multiple datasets, with results indicating that the DMPA approach consistently
surpasses existing state-of-the-art FL model poisoning attack strategies.

摘要：联邦学习 (FL) 作为一种突出的隐私保护机器学习 (ML) 范式，引起了极大的关注。去中心化联邦学习 (DFL) 避开了传统 FL 的集中式服务器架构，增强了系统的稳健性和可扩展性。然而，DFL 的这些优势也为恶意参与者执行对抗性攻击（尤其是模型中毒攻击）创造了新的漏洞。在模型中毒攻击中，恶意参与者旨在通过创建和传播受损模型来降低良性模型的性能。现有的模型中毒攻击研究主要集中于破坏集中式 FL (CFL) 范式中的全局模型，而 DFL 中需要进行更多研究。为了填补研究空白，本文提出了一种创新的模型中毒攻击，称为 DMPA。该攻击计算多个恶意客户端模型的差异特征并获得最有效的中毒策略，从而协调多个参与者的共谋攻击。该攻击的有效性在多个数据集上得到验证，结果表明 DMPA 方法始终优于现有的最先进的 FL 模型中毒攻击策略。

##### **Graph Federated Learning Based Proactive Content Caching in Edge Computing**
2502.04760v1 by Rui Wang

With the rapid growth of mobile data traffic and the increasing prevalence of
video streaming, proactive content caching in edge computing has become crucial
for reducing latency and alleviating network congestion. However, traditional
caching strategies such as FIFO, LRU, and LFU fail to effectively predict
future content popularity, while existing proactive caching approaches often
require users to upload data to a central server, raising concerns regarding
privacy and scalability. To address these challenges, this paper proposes a
Graph Federated Learning-based Proactive Content Caching (GFPCC) scheme that
enhances caching efficiency while preserving user privacy. The proposed
approach integrates federated learning and graph neural networks, enabling
users to locally train Light Graph Convolutional Networks (LightGCN) to capture
user-item relationships and predict content popularity. Instead of sharing raw
data, only the trained model parameters are transmitted to the central server,
where a federated averaging algorithm aggregates updates, refines the global
model, and selects the most popular files for proactive caching. Experimental
evaluations on real-world datasets, such as MovieLens, demonstrate that GFPCC
outperforms baseline caching algorithms by achieving higher cache efficiency
through more accurate content popularity predictions. Moreover, the federated
learning framework strengthens privacy protection while maintaining efficient
model training; however, scalability remains a challenge in large-scale
networks with dynamic user preferences.

摘要：隨著行動數據流量快速成長及串流影片日益普及，邊緣運算中的主動式內容快取對於降低延遲和減輕網路壅塞已變得至關重要。然而，先進先出 (FIFO)、最近最少使用 (LRU) 和最近最常使用 (LFU) 等傳統快取策略無法有效預測未來的內容熱門程度，而現有的主動式快取方法通常要求使用者將資料上傳到中央伺服器，引發了隱私和可擴充性的疑慮。為了應對這些挑戰，本文提出了一個基於圖形聯盟學習的主動式內容快取 (GFPCC) 架構，可在維護使用者隱私的同時提升快取效率。所提出的方法整合了聯盟學習和圖形神經網路，使用戶能夠在本地訓練輕量級圖形卷積網路 (LightGCN) 以擷取使用者與項目之間的關係並預測內容熱門程度。使用者不分享原始資料，僅將訓練好的模型參數傳輸到中央伺服器，而中央伺服器會使用聯盟平均演算法彙整更新、改善全球模型，並選取最熱門的檔案進行主動式快取。針對真實世界資料集（例如 MovieLens）進行的實驗評估顯示，GFPCC 透過更準確的內容熱門程度預測，在快取效率上優於基準快取演算法。此外，聯盟學習架構強化了隱私保護，同時維持了高效的模型訓練；然而，在具有動態使用者偏好的大型網路中，可擴充性仍然是一項挑戰。

##### **Enhancing Phishing Email Identification with Large Language Models**
2502.04759v1 by Catherine Lee

Phishing has long been a common tactic used by cybercriminals and continues
to pose a significant threat in today's digital world. When phishing attacks
become more advanced and sophisticated, there is an increasing need for
effective methods to detect and prevent them. To address the challenging
problem of detecting phishing emails, researchers have developed numerous
solutions, in particular those based on machine learning (ML) algorithms. In
this work, we take steps to study the efficacy of large language models (LLMs)
in detecting phishing emails. The experiments show that the LLM achieves a high
accuracy rate at high precision; importantly, it also provides interpretable
evidence for the decisions.

摘要：網路釣魚一直是網路犯罪分子慣用的手法，在當今的數位世界中，它持續對人們構成重大威脅。當網路釣魚攻擊變得更進階、更精密時，對於偵測和預防網路釣魚攻擊的有效方法的需求也隨之增加。為了解決偵測網路釣魚電子郵件的挑戰性問題，研究人員開發出許多解決方案，特別是那些基於機器學習 (ML) 演算法的解決方案。在這項工作中，我們採取步驟來研究大型語言模型 (LLM) 在偵測網路釣魚電子郵件方面的效能。實驗顯示，LLM 在高準確度下達到高準確率；重要的是，它也為決策提供了可解釋的證據。

##### **ELITE: Enhanced Language-Image Toxicity Evaluation for Safety**
2502.04757v1 by Wonjun Lee, Doehyeon Lee, Eugene Choi, Sangyoon Yu, Ashkan Yousefpour, Haon Park, Bumsub Ham, Suhyun Kim

Current Vision Language Models (VLMs) remain vulnerable to malicious prompts
that induce harmful outputs. Existing safety benchmarks for VLMs primarily rely
on automated evaluation methods, but these methods struggle to detect implicit
harmful content or produce inaccurate evaluations. Therefore, we found that
existing benchmarks have low levels of harmfulness, ambiguous data, and limited
diversity in image-text pair combinations. To address these issues, we propose
the ELITE {\em benchmark}, a high-quality safety evaluation benchmark for VLMs,
underpinned by our enhanced evaluation method, the ELITE {\em evaluator}. The
ELITE evaluator explicitly incorporates a toxicity score to accurately assess
harmfulness in multimodal contexts, where VLMs often provide specific,
convincing, but unharmful descriptions of images. We filter out ambiguous and
low-quality image-text pairs from existing benchmarks using the ELITE evaluator
and generate diverse combinations of safe and unsafe image-text pairs. Our
experiments demonstrate that the ELITE evaluator achieves superior alignment
with human evaluations compared to prior automated methods, and the ELITE
benchmark offers enhanced benchmark quality and diversity. By introducing
ELITE, we pave the way for safer, more robust VLMs, contributing essential
tools for evaluating and mitigating safety risks in real-world applications.

摘要：現有的視覺語言模型（VLM）仍然容易受到惡意提示的影響，而這些提示會誘發有害的輸出。現有的 VLM 安全基準主要依賴於自動化評估方法，但這些方法難以偵測隱含的有害內容或產生不準確的評估。因此，我們發現現有的基準具有低程度的有害性、模稜兩可的資料，以及圖像文字對組合的多樣性有限。為了解決這些問題，我們提出了 ELITE {\em 基準}，一個針對 VLM 的高品質安全評估基準，並以我們增強的評估方法 ELITE {\em 評估器} 為基礎。ELITE 評估器明確地納入了毒性評分，以準確評估多模態環境中的有害性，在這種環境中，VLM 經常提供特定、令人信服但無害的圖像描述。我們使用 ELITE 評估器從現有的基準中篩選出模稜兩可和低品質的圖像文字對，並產生安全和不安全圖像文字對的多樣化組合。我們的實驗證明，與先前的自動化方法相比，ELITE 評估器與人類評估達到了更高的對齊，而 ELITE 基準提供了增強的基準品質和多樣性。透過導入 ELITE，我們為更安全、更強大的 VLM 鋪平了道路，並為評估和減輕實際應用中的安全風險做出了重要的貢獻。

##### **Concept Navigation and Classification via Open Source Large Language Model Processing**
2502.04756v1 by Maël Kubli

This paper presents a novel methodological framework for detecting and
classifying latent constructs, including frames, narratives, and topics, from
textual data using Open-Source Large Language Models (LLMs). The proposed
hybrid approach combines automated summarization with human-in-the-loop
validation to enhance the accuracy and interpretability of construct
identification. By employing iterative sampling coupled with expert refinement,
the framework guarantees methodological robustness and ensures conceptual
precision. Applied to diverse data sets, including AI policy debates, newspaper
articles on encryption, and the 20 Newsgroups data set, this approach
demonstrates its versatility in systematically analyzing complex political
discourses, media framing, and topic classification tasks.

摘要：本文提出了一個創新的方法論架構，用於從文本數據中檢測和分類潛在構念，包括框架、敘述和主題，使用開源大型語言模型 (LLM)。提出的混合方法結合了自動摘要和人為迴圈驗證，以增強構念識別的準確性和可解釋性。通過採用迭代抽樣並結合專家優化，該框架保證了方法論的穩健性並確保了概念的精確性。應用於不同的數據集，包括 AI 政策辯論、關於加密的新聞文章和 20 個新聞組數據集，這種方法展示了其在系統地分析複雜的政治話語、媒體框架和主題分類任務中的多功能性。

##### **Holistically Guided Monte Carlo Tree Search for Intricate Information Seeking**
2502.04751v1 by Ruiyang Ren, Yuhao Wang, Junyi Li, Jinhao Jiang, Wayne Xin Zhao, Wenjie Wang, Tat-Seng Chua

In the era of vast digital information, the sheer volume and heterogeneity of
available information present significant challenges for intricate information
seeking. Users frequently face multistep web search tasks that involve
navigating vast and varied data sources. This complexity demands every step
remains comprehensive, accurate, and relevant. However, traditional search
methods often struggle to balance the need for localized precision with the
broader context required for holistic understanding, leaving critical facets of
intricate queries underexplored. In this paper, we introduce an LLM-based
search assistant that adopts a new information seeking paradigm with
holistically guided Monte Carlo tree search (HG-MCTS). We reformulate the task
as a progressive information collection process with a knowledge memory and
unite an adaptive checklist with multi-perspective reward modeling in MCTS. The
adaptive checklist provides explicit sub-goals to guide the MCTS process toward
comprehensive coverage of complex user queries. Simultaneously, our
multi-perspective reward modeling offers both exploration and retrieval
rewards, along with progress feedback that tracks completed and remaining
sub-goals, refining the checklist as the tree search progresses. By striking a
balance between localized tree expansion and global guidance, HG-MCTS reduces
redundancy in search paths and ensures that all crucial aspects of an intricate
query are properly addressed. Extensive experiments on real-world intricate
information seeking tasks demonstrate that HG-MCTS acquires thorough knowledge
collections and delivers more accurate final responses compared with existing
baselines.

摘要：在浩瀚的數位資訊時代，龐大的資訊量與異質性對複雜的資訊搜尋提出了嚴峻的挑戰。使用者經常面臨多步驟的網路搜尋任務，其中涉及瀏覽廣泛且多樣化的資料來源。這種複雜性要求每一步都保持全面、準確和相關性。然而，傳統的搜尋方法常常難以在局部精確度和整體理解所需更廣泛的脈絡之間取得平衡，導致複雜查詢的重要面向未被充分探索。在本文中，我們介紹了一個基於大型語言模型 (LLM) 的搜尋助理，它採用了一個新的資訊搜尋範例，結合整體引導的蒙地卡羅樹狀搜尋 (HG-MCTS)。我們將任務重新表述為一個具有知識記憶的漸進式資訊收集過程，並將自適應核對清單與多觀點獎勵模型結合在 MCTS 中。自適應核對清單提供了明確的子目標，以引導 MCTS 程序全面涵蓋複雜的使用者查詢。同時，我們的多觀點獎勵模型提供了探索和檢索獎勵，以及追蹤已完成和剩餘子目標的進度回饋，隨著樹狀搜尋的進行，不斷優化核對清單。透過在局部樹狀擴充和整體引導之間取得平衡，HG-MCTS 減少了搜尋路徑中的冗餘，並確保複雜查詢的所有關鍵面向都能得到適當處理。在真實世界複雜資訊搜尋任務上的廣泛實驗表明，與現有的基線相比，HG-MCTS 獲取了全面的知識集合，並提供了更準確的最終回應。

##### **Every Software as an Agent: Blueprint and Case Study**
2502.04747v1 by Mengwei Xu

The rise of (multimodal) large language models (LLMs) has shed light on
software agent -- where software can understand and follow user instructions in
natural language. However, existing approaches such as API-based and GUI-based
agents are far from satisfactory at accuracy and efficiency aspects. Instead,
we advocate to endow LLMs with access to the software internals (source code
and runtime context) and the permission to dynamically inject generated code
into software for execution. In such a whitebox setting, one may better
leverage the software context and the coding ability of LLMs. We then present
an overall design architecture and case studies on two popular web-based
desktop applications. We also give in-depth discussion of the challenges and
future directions. We deem that such a new paradigm has the potential to
fundamentally overturn the existing software agent design, and finally creating
a digital world in which software can comprehend, operate, collaborate, and
even think to meet complex user needs.

摘要：（多模态）大型语言模型（LLM）的兴起，为软件代理人带来了曙光——软件能够理解并遵循用户以自然语言给出的指令。然而，现有的方法，例如基于 API 和基于 GUI 的代理，在准确性和效率方面还远远不能令人满意。相反，我们提倡赋予 LLM 访问软件内部（源代码和运行时上下文）的权限，并允许动态注入生成的代码以供软件执行。在这种白盒设置中，人们可以更好地利用软件上下文和 LLM 的编码能力。然后，我们在两个流行的基于 Web 的桌面应用程序上展示了总体设计架构和案例研究。我们还对挑战和未来方向进行了深入讨论。我们认为，这种新的范例有可能从根本上颠覆现有的软件代理设计，并最终创造出一个软件能够理解、操作、协作，甚至思考以满足复杂用户需求的数字世界。

##### **The "negative end" of change in grammar: terminology, concepts and causes**
2502.04729v1 by Karolina Rudnicka

The topic of "negative end" of change is, contrary to the fields of
innovation and emergence, largely under-researched. Yet, it has lately started
to gain an increasing attention from language scholars worldwide. The main
focus of this article is threefold, namely to discuss the i) terminology; ii)
concepts and iii) causes associated with the "negative end" of change in
grammar. The article starts with an overview of research conducted on the
topic. It then moves to situating phenomena referred to as loss, decline or
obsolescence among processes of language change, before elaborating on the
terminology and concepts behind it. The last part looks at possible causes for
constructions to display a (gradual or rapid, but very consistent) decrease in
the frequency of use over time, which continues until the construction
disappears or there are only residual or fossilised forms left. Keywords: loss,
obsolescence, decline, competition, higher

摘要：<paragraph>關於變化的「負面終點」這個主題，與創新和出現的領域相反，在很大程度上尚未受到研究。然而，它最近開始引起世界各地語言學者的越來越多的關注。本文的主要焦點有三方面，即討論 i) 術語；ii) 概念和 iii) 與語法中「負面終點」相關的原因。本文從對該主題進行的研究概述開始。然後轉向將稱為損失、衰退或廢棄的現象置於語言變化的過程中，然後詳細說明其背後的術語和概念。最後一部分探討了結構隨著時間推移顯示出使用頻率（逐漸或快速，但非常一致）下降的可能原因，這種情況會持續到結構消失或只剩下殘餘或化石形式。關鍵字：損失、廢棄、衰退、競爭、更高</paragraph>

##### **Generating Symbolic World Models via Test-time Scaling of Large Language Models**
2502.04728v1 by Zhouliang Yu, Yuhuan Yuan, Tim Z. Xiao, Fuxiang Frank Xia, Jie Fu, Ge Zhang, Ge Lin, Weiyang Liu

Solving complex planning problems requires Large Language Models (LLMs) to
explicitly model the state transition to avoid rule violations, comply with
constraints, and ensure optimality-a task hindered by the inherent ambiguity of
natural language. To overcome such ambiguity, Planning Domain Definition
Language (PDDL) is leveraged as a planning abstraction that enables precise and
formal state descriptions. With PDDL, we can generate a symbolic world model
where classic searching algorithms, such as A*, can be seamlessly applied to
find optimal plans. However, directly generating PDDL domains with current LLMs
remains an open challenge due to the lack of PDDL training data. To address
this challenge, we propose to scale up the test-time computation of LLMs to
enhance their PDDL reasoning capabilities, thereby enabling the generation of
high-quality PDDL domains. Specifically, we introduce a simple yet effective
algorithm, which first employs a Best-of-N sampling approach to improve the
quality of the initial solution and then refines the solution in a fine-grained
manner with verbalized machine learning. Our method outperforms o1-mini by a
considerable margin in the generation of PDDL domain, achieving over 50%
success rate on two tasks (i.e., generating PDDL domains from natural language
description or PDDL problems). This is done without requiring additional
training. By taking advantage of PDDL as state abstraction, our method is able
to outperform current state-of-the-art methods on almost all competition-level
planning tasks.

摘要：<paragraph>解決複雜的規劃問題需要大型語言模型 (LLM) 明確建構狀態轉換，以避免規則違規、符合限制，並確保最佳性，這項任務受到自然語言固有模糊性的阻礙。為了克服這種模糊性，規劃領域定義語言 (PDDL) 被用作規劃抽象，以實現精確且形式化的狀態描述。透過 PDDL，我們可以產生一個符號世界模型，其中經典搜尋演算法（例如 A*）可以無縫應用於尋找最佳計畫。然而，由於缺乏 PDDL 訓練資料，使用目前的 LLM 直接產生 PDDL 領域仍然是一個未解決的挑戰。為了應對這項挑戰，我們提議擴大 LLM 的測試時間運算，以增強其 PDDL 推理能力，從而產生高品質的 PDDL 領域。具體來說，我們引入了一個簡單但有效的演算法，它首先採用最佳 N 採樣方法來改善初始解的品質，然後以細粒度的語言化機器學習方式改善解。我們的模型在 PDDL 領域的產生上大幅優於 o1-mini，在兩個任務上（即從自然語言描述或 PDDL 問題產生 PDDL 領域）達到超過 50% 的成功率。這是在不需要額外訓練的情況下完成的。透過利用 PDDL 作為狀態抽象，我們的模型能夠在幾乎所有競賽層級的規劃任務上優於目前的最新技術。</paragraph>

##### **Can Diffusion Models Learn Hidden Inter-Feature Rules Behind Images?**
2502.04725v1 by Yujin Han, Andi Han, Wei Huang, Chaochao Lu, Difan Zou

Despite the remarkable success of diffusion models (DMs) in data generation,
they exhibit specific failure cases with unsatisfactory outputs. We focus on
one such limitation: the ability of DMs to learn hidden rules between image
features. Specifically, for image data with dependent features ($\mathbf{x}$)
and ($\mathbf{y}$) (e.g., the height of the sun ($\mathbf{x}$) and the length
of the shadow ($\mathbf{y}$)), we investigate whether DMs can accurately
capture the inter-feature rule ($p(\mathbf{y}|\mathbf{x})$). Empirical
evaluations on mainstream DMs (e.g., Stable Diffusion 3.5) reveal consistent
failures, such as inconsistent lighting-shadow relationships and mismatched
object-mirror reflections. Inspired by these findings, we design four synthetic
tasks with strongly correlated features to assess DMs' rule-learning abilities.
Extensive experiments show that while DMs can identify coarse-grained rules,
they struggle with fine-grained ones. Our theoretical analysis demonstrates
that DMs trained via denoising score matching (DSM) exhibit constant errors in
learning hidden rules, as the DSM objective is not compatible with rule
conformity. To mitigate this, we introduce a common technique - incorporating
additional classifier guidance during sampling, which achieves (limited)
improvements. Our analysis reveals that the subtle signals of fine-grained
rules are challenging for the classifier to capture, providing insights for
future exploration.

摘要：儘管擴散模型 (DM) 在資料生成方面取得顯著的成功，但它們會出現特定失敗案例，產生不令人滿意的輸出。我們專注於其中一個限制：DM 學習影像特徵之間隱藏規則的能力。具體來說，對於具有依賴特徵 ($\mathbf{x}$) 和 ($\mathbf{y}$) 的影像資料（例如，太陽高度 ($\mathbf{x}$) 和陰影長度 ($\mathbf{y}$）），我們探討 DM 是否能準確捕捉特徵間規則 ($p(\mathbf{y}|\mathbf{x})$)。對主流 DM（例如 Stable Diffusion 3.5）的經驗評估揭示了一致的失敗，例如不一致的光影關係和不匹配的物體鏡像反射。受這些發現的啟發，我們設計了四項具有強相關特徵的合成任務，以評估 DM 的規則學習能力。大量的實驗表明，雖然 DM 可以識別粗略的規則，但它們難以應付細緻的規則。我們的理論分析表明，透過去噪分數匹配 (DSM) 訓練的 DM 在學習隱藏規則時會出現恆定誤差，因為 DSM 目標與規則一致性不相容。為了減輕這個問題，我們引入了一種常見的技術 - 在採樣期間加入額外的分類器指導，這實現了（有限的）改進。我們的分析表明，細緻規則的微妙訊號對於分類器來說很難捕捉，這為未來的探索提供了見解。

##### **Evaluating Text Style Transfer Evaluation: Are There Any Reliable Metrics?**
2502.04718v1 by Sourabrata Mukherjee, Atul Kr. Ojha, John P. McCrae, Ondrej Dusek

Text Style Transfer (TST) is the task of transforming a text to reflect a
particular style while preserving its original content. Evaluating TST outputs
is a multidimensional challenge, requiring the assessment of style transfer
accuracy, content preservation, and naturalness. Using human evaluation is
ideal but costly, same as in other natural language processing (NLP) tasks,
however, automatic metrics for TST have not received as much attention as
metrics for, e.g., machine translation or summarization. In this paper, we
examine both set of existing and novel metrics from broader NLP tasks for TST
evaluation, focusing on two popular subtasks-sentiment transfer and
detoxification-in a multilingual context comprising English, Hindi, and
Bengali. By conducting meta-evaluation through correlation with human
judgments, we demonstrate the effectiveness of these metrics when used
individually and in ensembles. Additionally, we investigate the potential of
Large Language Models (LLMs) as tools for TST evaluation. Our findings
highlight that certain advanced NLP metrics and experimental-hybrid-techniques,
provide better insights than existing TST metrics for delivering more accurate,
consistent, and reproducible TST evaluations.

摘要：文字樣式轉移 (TST) 是將文字轉換為反映特定樣式，同時保留其原始內容的任務。評估 TST 輸出是一項多維度的挑戰，需要評估樣式轉移準確性、內容保留和自然性。使用人工評估是理想的，但成本很高，與其他自然語言處理 (NLP) 任務相同，然而，TST 的自動化指標並未像機器翻譯或摘要的指標那樣受到重視。在本文中，我們檢視了廣泛 NLP 任務中現有和新穎指標的兩組，用於 TST 評估，重點關注兩個流行的子任務 - 情緒轉移和解毒 - 在包含英語、印地語和孟加拉語的多語言環境中。通過與人類判斷相關的元評估，我們證明了這些指標在單獨使用和整體使用時的有效性。此外，我們研究了大型語言模型 (LLM) 作為 TST 評估工具的潛力。我們的研究結果強調，某些先進的 NLP 指標和實驗性混合技術，提供比現有 TST 指標更好的見解，用於提供更準確、一致和可重製的 TST 評估。

##### **Enhancing Impression Change Prediction in Speed Dating Simulations Based on Speakers' Personalities**
2502.04706v1 by Kazuya Matsuo, Yoko Ishii, Atsushi Otsuka, Ryo Ishii, Hiroaki Sugiyama, Masahiro Mizukami, Tsunehiro Arimoto, Narichika Nomoto, Yoshihide Sato, Tetsuya Yamaguchi

This paper focuses on simulating text dialogues in which impressions between
speakers improve during speed dating. This simulation involves selecting an
utterance from multiple candidates generated by a text generation model that
replicates a specific speaker's utterances, aiming to improve the impression of
the speaker. Accurately selecting an utterance that improves the impression is
crucial for the simulation. We believe that whether an utterance improves a
dialogue partner's impression of the speaker may depend on the personalities of
both parties. However, recent methods for utterance selection do not consider
the impression per utterance or the personalities. To address this, we propose
a method that predicts whether an utterance improves a partner's impression of
the speaker, considering the personalities. The evaluation results showed that
personalities are useful in predicting impression changes per utterance.
Furthermore, we conducted a human evaluation of simulated dialogues using our
method. The results showed that it could simulate dialogues more favorably
received than those selected without considering personalities.

摘要：本文重點在於模擬在快速約會中，講者之間的印象得到改善的文字對話。此模擬包括從文字生成模型產生的多個候選者中選擇一個語句，該模型複製特定講者的語句，旨在改善講者的印象。準確選擇能改善印象的語句對於模擬至關重要。我們相信，語句是否能改善對話夥伴對講者的印象可能取決於雙方的個性。然而，最近的語句選擇方法並未考慮每個語句的印象或個性。為了解決這個問題，我們提出了一種方法，該方法預測語句是否會改善夥伴對講者的印象，並考慮個性。評估結果表明，個性對於預測每個語句的印象變化很有用。此外，我們使用我們的方法對模擬對話進行了人工評估。結果表明，它可以模擬出比不考慮個性而選擇的對話更受歡迎的對話。

##### **EigenLoRAx: Recycling Adapters to Find Principal Subspaces for Resource-Efficient Adaptation and Inference**
2502.04700v1 by Prakhar Kaushik, Ankit Vaidya, Shravan Chaudhari, Alan Yuille

The rapid growth of large models has raised concerns about their
environmental impact and equity in accessibility due to significant
computational costs. Low-Rank Adapters (LoRA) offer a lightweight solution for
finetuning large models, resulting in an abundance of publicly available
adapters tailored to diverse domains. We ask: Can these pretrained adapters be
leveraged to further streamline adaptation to new tasks while addressing these
challenges? We introduce EigenLoRAx, a parameter-efficient finetuning method
that recycles existing adapters to create a principal subspace aligned with
their shared domain knowledge which can be further augmented with orthogonal
basis vectors in low-resource scenarios. This enables rapid adaptation to new
tasks by learning only lightweight coefficients on the principal components of
the subspace - eliminating the need to finetune entire adapters. EigenLoRAx
requires significantly fewer parameters and memory, improving efficiency for
both training and inference. Our method demonstrates strong performance across
diverse domains and tasks, offering a scalable for edge-based applications,
personalization, and equitable deployment of large models in
resource-constrained environments.

摘要：大型模型的快速增长引发了人们对其环境影响和可访问性公平性的担忧，因为其计算成本很高。低秩适配器 (LoRA) 为微调大型模型提供了一种轻量级解决方案，从而产生了大量针对不同领域的公开可用适配器。我们提出疑问：这些预训练的适配器能否被利用来进一步简化对新任务的适配，同时解决这些挑战？我们引入了 EigenLoRAx，这是一种参数高效的微调方法，它可以回收现有的适配器来创建一个与它们共享的领域知识对齐的主成分子空间，该子空间可以在资源匮乏的情况下进一步用正交基向量进行扩充。这可以通过仅学习子空间主成分上的轻量级系数来实现对新任务的快速适配，从而消除了对微调整个适配器的需求。EigenLoRAx 需要明显更少的参数和内存，从而提高了训练和推理的效率。我们的方法在不同的领域和任务中都表现出了强大的性能，为基于边缘的应用程序、个性化和在大模型资源受限环境中的公平部署提供了可扩展性。

##### **Bridging the Gap in XAI-Why Reliable Metrics Matter for Explainability and Compliance**
2502.04695v1 by Pratinav Seth, Vinay Kumar Sankarapu

This position paper emphasizes the critical gap in the evaluation of
Explainable AI (XAI) due to the lack of standardized and reliable metrics,
which diminishes its practical value, trustworthiness, and ability to meet
regulatory requirements. Current evaluation methods are often fragmented,
subjective, and biased, making them prone to manipulation and complicating the
assessment of complex models. A central issue is the absence of a ground truth
for explanations, complicating comparisons across various XAI approaches. To
address these challenges, we advocate for widespread research into developing
robust, context-sensitive evaluation metrics. These metrics should be resistant
to manipulation, relevant to each use case, and based on human judgment and
real-world applicability. We also recommend creating domain-specific evaluation
benchmarks that align with the user and regulatory needs of sectors such as
healthcare and finance. By encouraging collaboration among academia, industry,
and regulators, we can create standards that balance flexibility and
consistency, ensuring XAI explanations are meaningful, trustworthy, and
compliant with evolving regulations.

摘要：這篇立場文件強調，由於缺乏標準化且可靠的指標，可解釋人工智慧 (XAI) 的評估中存在關鍵的差距，這降低了其實用價值、可信度，以及滿足法規要求的能力。當前的評估方法通常是分散的、主觀的，且有偏見的，這使得它們容易被操縱，並使複雜模型的評估複雜化。一個核心議題是缺乏解釋的基準事實，這使得跨各種 XAI 方法的比較變得複雜。為了應對這些挑戰，我們提倡廣泛研究，以開發強健且對情境敏感的評估指標。這些指標應能抵抗操縱，與每個使用案例相關，並基於人類判斷和真實世界的適用性。我們也建議建立與使用者和法規需求相符的特定領域評估基準，例如醫療保健和金融。透過鼓勵學術界、產業和監管機構之間的合作，我們可以創造出平衡靈活性和一致性的標準，確保 XAI 解釋是有意義的、可信的，且符合不斷演進的法規。

##### **ARR: Question Answering with Large Language Models via Analyzing, Retrieving, and Reasoning**
2502.04689v1 by Yuwei Yin, Giuseppe Carenini

Large language models (LLMs) achieve remarkable performance on challenging
benchmarks that are often structured as multiple-choice question-answering (QA)
tasks. Zero-shot Chain-of-Thought (CoT) prompting enhances reasoning in LLMs
but provides only vague and generic guidance ("think step by step"). This paper
introduces ARR, an intuitive and effective zero-shot prompting method that
explicitly incorporates three key steps in QA solving: analyzing the intent of
the question, retrieving relevant information, and reasoning step by step.
Comprehensive experiments across diverse and challenging QA tasks demonstrate
that ARR consistently improves the Baseline (without ARR prompting) and
outperforms CoT. Ablation and case studies further validate the positive
contributions of each component: analyzing, retrieving, and reasoning. Notably,
intent analysis plays a vital role in ARR. Additionally, extensive evaluations
across various model sizes, LLM series, and generation settings solidify the
effectiveness, robustness, and generalizability of ARR.

摘要：大型語言模型 (LLM) 在通常以多選題問答 (QA) 任務構成的具挑戰性基準測試中，獲得顯著的表現。零次學習思考鏈 (CoT) 提示增強了 LLM 中的推理，但僅提供模糊且通用的指導（「逐步思考」）。本文介紹 ARR，這是一種直覺且有效率的零次學習提示方法，明確納入了問答解決中的三個關鍵步驟：分析問題的意圖、擷取相關資訊以及逐步推理。在各種具挑戰性的問答任務中進行的全面實驗證明，ARR 持續改善基準（沒有 ARR 提示）並優於 CoT。消融和案例研究進一步驗證了每個組成部分的正面貢獻：分析、擷取和推理。值得注意的是，意圖分析在 ARR 中扮演至關重要的角色。此外，在各種模型大小、LLM 系列和產生設定中進行的廣泛評估，證實了 ARR 的有效性、穩健性和概括性。

##### **M-IFEval: Multilingual Instruction-Following Evaluation**
2502.04688v1 by Antoine Dussolle, Andrea Cardeña Díaz, Shota Sato, Peter Devine

Instruction following is a core capability of modern Large language models
(LLMs), making evaluating this capability essential to understanding these
models. The Instruction Following Evaluation (IFEval) benchmark from the
literature does this using objective criteria, offering a measure of LLM
performance without subjective AI or human judgement. However, it only includes
English instructions, limiting its ability to assess LLMs in other languages.
  We propose the Multilingual Instruction Following Evaluation (M-IFEval)
benchmark, expanding the evaluation to French, Japanese, and Spanish, with both
general and language-specific instructions. Applying this benchmark to 8
state-of-the-art LLMs, we find that benchmark performance across languages and
instruction types can vary widely, underscoring the importance of a
multilingual benchmark for evaluating LLMs in a diverse cultural context.

摘要：指令遵循是現代大型語言模型 (LLM) 的核心功能，因此評估此功能對於瞭解這些模型至關重要。文獻中的指令遵循評估 (IFEval) 基準使用客觀標準來執行此操作，提供 LLM 效能衡量，而無需主觀的人工智慧或人類判斷。然而，它僅包含英文指令，這限制了其評估其他語言中 LLM 的能力。我們提出多語言指令遵循評估 (M-IFEval) 基準，將評估擴展到法語、日語和西班牙語，並包含一般和語言特定指令。將此基準套用於 8 個最先進的 LLM，我們發現不同語言和指令類型的基準效能差異很大，這強調了在多元文化背景下評估 LLM 時多語言基準的重要性。

##### **Learning Strategic Language Agents in the Werewolf Game with Iterative Latent Space Policy Optimization**
2502.04686v1 by Zelai Xu, Wanjun Gu, Chao Yu, Yi Wu, Yu Wang

Large language model (LLM)-based agents have recently shown impressive
progress in a variety of domains, including open-ended conversation and
multi-step decision-making. However, applying these agents to social deduction
games such as Werewolf, which requires both strategic decision-making and
free-form language interaction, remains non-trivial. Traditional methods based
on Counterfactual Regret Minimization (CFR) or reinforcement learning (RL)
typically depend on a predefined action space, making them unsuitable for
language games with unconstrained text action space. Meanwhile, pure LLM-based
agents often suffer from intrinsic biases and require prohibitively large
datasets for fine-tuning. We propose Latent Space Policy Optimization (LSPO),
an iterative framework that addresses these challenges by first mapping
free-form text to a discrete latent space, where methods like CFR and RL can
learn strategic policy more effectively. We then translate the learned policy
back into natural language dialogues, which are used to fine-tune an LLM via
Direct Preference Optimization (DPO). By iteratively alternating between these
stages, our LSPO agent progressively enhances both strategic reasoning and
language communication. Experiment results on the Werewolf game show that our
method improves the agent's performance in each iteration and outperforms
existing Werewolf agents, underscoring its promise for free-form language
decision-making.

摘要：大型語言模型 (LLM) 驅動的代理最近在各種領域展現驚人的進步，包括開放式對話和多步驟決策制定。然而，將這些代理應用於社交推理遊戲（例如狼人殺），需要策略決策制定和自由形式語言互動，仍然非同小可。傳統方法基於反事實後悔最小化 (CFR) 或強化學習 (RL)，通常依賴於預定義的動作空間，這使得它們不適合於動作空間不受約束的語言遊戲。同時，純粹的 LLM 驅動的代理通常會受到內在偏差的影響，並且需要難以負擔的大型資料集來進行微調。我們提出了潛在空間策略最佳化 (LSPO)，這是一個迭代框架，通過首先將自由形式文字對應到離散潛在空間來解決這些挑戰，在該空間中，CFR 和 RL 等方法可以更有效地學習策略。然後，我們將學習到的策略轉換回自然語言對話，這些對話用於通過直接偏好最佳化 (DPO) 對 LLM 進行微調。通過在這些階段之間進行迭代交替，我們的 LSPO 代理逐漸增強了策略推理和語言溝通。狼人殺遊戲的實驗結果表明，我們的模型在每次迭代中都能提升代理的表現，並且優於現有的狼人殺代理，這突顯了其在自由形式語言決策制定方面的潛力。

##### **G2PDiffusion: Genotype-to-Phenotype Prediction with Diffusion Models**
2502.04684v1 by Mengdi Liu, Zhangyang Gao, Hong Chang, Stan Z. Li, Shiguang Shan, Xinlin Chen

Discovering the genotype-phenotype relationship is crucial for genetic
engineering, which will facilitate advances in fields such as crop breeding,
conservation biology, and personalized medicine. Current research usually
focuses on single species and small datasets due to limitations in phenotypic
data collection, especially for traits that require visual assessments or
physical measurements. Deciphering complex and composite phenotypes, such as
morphology, from genetic data at scale remains an open question. To break
through traditional generic models that rely on simplified assumptions, this
paper introduces G2PDiffusion, the first-of-its-kind diffusion model designed
for genotype-to-phenotype generation across multiple species. Specifically, we
use images to represent morphological phenotypes across species and redefine
phenotype prediction as conditional image generation. To this end, this paper
introduces an environment-enhanced DNA sequence conditioner and trains a stable
diffusion model with a novel alignment method to improve genotype-to-phenotype
consistency. Extensive experiments demonstrate that our approach enhances
phenotype prediction accuracy across species, capturing subtle genetic
variations that contribute to observable traits.

摘要：發現基因型與表型之間的關係對於遺傳工程至關重要，這將促進作物育種、保育生物學和個人化醫療等領域的進展。由於表型數據收集的限制，當前研究通常集中於單一物種和小數據集，特別是對於需要視覺評估或物理測量的性狀。從遺傳數據中破譯複雜和複合的表型（例如形態）仍然是一個懸而未決的問題。為了突破依賴於簡化假設的傳統通用模型，本文介紹了 G2PDiffusion，這是一個首創的擴散模型，專門用於跨多個物種進行基因型到表型的生成。具體來說，我們使用圖像來表示跨物種的形態表型，並將表型預測重新定義為條件圖像生成。為此，本文介紹了一個環境增強的 DNA 序列調節器，並訓練了一個具有新對齊方法的穩定擴散模型，以提高基因型到表型的稠密性。大量的實驗表明，我們的做法提高了跨物種的表型預測準確度，捕捉到導致可觀察性狀的細微遺傳變異。

##### **AdParaphrase: Paraphrase Dataset for Analyzing Linguistic Features toward Generating Attractive Ad Texts**
2502.04674v1 by Soichiro Murakami, Peinan Zhang, Hidetaka Kamigaito, Hiroya Takamura, Manabu Okumura

Effective linguistic choices that attract potential customers play crucial
roles in advertising success. This study aims to explore the linguistic
features of ad texts that influence human preferences. Although the creation of
attractive ad texts is an active area of research, progress in understanding
the specific linguistic features that affect attractiveness is hindered by
several obstacles. First, human preferences are complex and influenced by
multiple factors, including their content, such as brand names, and their
linguistic styles, making analysis challenging. Second, publicly available ad
text datasets that include human preferences are lacking, such as ad
performance metrics and human feedback, which reflect people's interests. To
address these problems, we present AdParaphrase, a paraphrase dataset that
contains human preferences for pairs of ad texts that are semantically
equivalent but differ in terms of wording and style. This dataset allows for
preference analysis that focuses on the differences in linguistic features. Our
analysis revealed that ad texts preferred by human judges have higher fluency,
longer length, more nouns, and use of bracket symbols. Furthermore, we
demonstrate that an ad text-generation model that considers these findings
significantly improves the attractiveness of a given text. The dataset is
publicly available at: https://github.com/CyberAgentAILab/AdParaphrase.

摘要：<paragraph>在廣告中，能吸引潛在客戶的有效語言選擇，在廣告成功中扮演著至關重要的角色。本研究旨在探討影響人類偏好之廣告文字的語言特徵。儘管創造有吸引力的廣告文字是研究的熱門領域，但理解影響吸引力的特定語言特徵的進展卻受到許多障礙阻礙。首先，人類的偏好很複雜，並受到多重因素的影響，包括內容（例如品牌名稱）和語言風格，這使得分析極具挑戰性。其次，缺乏包含人類偏好的公開廣告文字資料集，例如廣告成效指標和人類回饋，這些資料反映了人們的興趣。為了解決這些問題，我們提出了 AdParaphrase，這是一個同義詞資料集，其中包含人類對語義等價但措辭和風格不同的廣告文字對的偏好。此資料集允許進行偏好分析，重點放在語言特徵的差異上。我們的分析顯示，人類評審偏好的廣告文字具有更高的流暢度、更長的長度、更多的名詞和括號符號的使用。此外，我們證明了一個考慮這些發現的廣告文字生成模型，可以顯著提高給定文字的吸引力。此資料集可在以下網址公開取得：https://github.com/CyberAgentAILab/AdParaphrase。</paragraph>

##### **${\rm P{\small ROOF}W{\small ALA}}$: Multilingual Proof Data Synthesis and Theorem-Proving**
2502.04671v1 by Amitayush Thakur, George Tsoukalas, Greg Durrett, Swarat Chaudhuri

Neural networks have shown substantial promise at automatic theorem-proving
in interactive proof assistants (ITPs) like Lean and Coq. However, most neural
theorem-proving models are restricted to specific ITPs, leaving out
opportunities for cross-lingual $\textit{transfer}$ between ITPs. We address
this weakness with a multilingual proof framework, ${\rm P{\small ROOF}W{\small
ALA}}$, that allows a standardized form of interaction between neural
theorem-provers and two established ITPs (Coq and Lean). It enables the
collection of multilingual proof step data -- data recording the result of
proof actions on ITP states -- for training neural provers. ${\rm P{\small
ROOF}W{\small ALA}}$ allows the systematic evaluation of a model's performance
across different ITPs and problem domains via efficient parallel proof search
algorithms. We show that multilingual training enabled by ${\rm P{\small
ROOF}W{\small ALA}}$ can lead to successful transfer across ITPs. Specifically,
a model trained on a mix of ${\rm P{\small ROOF}W{\small ALA}}$-generated Coq
and Lean data outperforms Lean-only and Coq-only models on the standard
prove-at-$k$ metric. We open source all code including code for the
$\href{https://github.com/trishullab/proof-wala}{ProofWala\; Framework}$, and
the $\href{https://github.com/trishullab/itp-interface}{Multilingual\; ITP\;
interaction\; framework}$.

摘要：<paragraph>神經網路已在互動式證明輔助工具 (ITP) 中，例如 Lean 和 Coq，展現出自動定理證明方面的顯著前景。然而，大多數神經定理證明模型僅限於特定 ITP，忽略了 ITP 之間跨語言「轉移」的機會。我們透過多語言證明架構 ${\rm P{\small ROOF}W{\small ALA}}$ 來解決這個弱點，該架構允許神經定理證明器與兩個已建立的 ITP（Coq 和 Lean）之間進行標準化的互動。它能收集多語言證明步驟資料，即記錄 ITP 狀態中證明動作結果的資料，以訓練神經證明器。${\rm P{\small ROOF}W{\small ALA}}$ 允許透過有效並行的證明搜尋演算法，系統性地評估模型在不同 ITP 和問題領域的效能。我們展示了 ${\rm P{\small ROOF}W{\small ALA}}$ 所啟用的多語言訓練，能成功地在 ITP 之間進行轉移。具體來說，在 ${\rm P{\small ROOF}W{\small ALA}}$ 生成的 Coq 和 Lean 資料組合上訓練的模型，在標準的 prove-at-$k$ 指標上，優於僅使用 Lean 和僅使用 Coq 的模型。我們開放所有程式碼，包括 ${\rm P{\small ROOF}W{\small ALA}}$ 架構的程式碼 $\href{https://github.com/trishullab/proof-wala}{ProofWala\; Framework}$，以及多語言 ITP 互動架構 $\href{https://github.com/trishullab/itp-interface}{Multilingual\; ITP\; interaction\; framework}$。</paragraph>

##### **CCS: Controllable and Constrained Sampling with Diffusion Models via Initial Noise Perturbation**
2502.04670v1 by Bowen Song, Zecheng Zhang, Zhaoxu Luo, Jason Hu, Wei Yuan, Jing Jia, Zhengxu Tang, Guanyang Wang, Liyue Shen

Diffusion models have emerged as powerful tools for generative tasks,
producing high-quality outputs across diverse domains. However, how the
generated data responds to the initial noise perturbation in diffusion models
remains under-explored, which hinders understanding the controllability of the
sampling process. In this work, we first observe an interesting phenomenon: the
relationship between the change of generation outputs and the scale of initial
noise perturbation is highly linear through the diffusion ODE sampling. Then we
provide both theoretical and empirical study to justify this linearity property
of this input-output (noise-generation data) relationship. Inspired by these
new insights, we propose a novel Controllable and Constrained Sampling method
(CCS) together with a new controller algorithm for diffusion models to sample
with desired statistical properties while preserving good sample quality. We
perform extensive experiments to compare our proposed sampling approach with
other methods on both sampling controllability and sampled data quality.
Results show that our CCS method achieves more precisely controlled sampling
while maintaining superior sample quality and diversity.

摘要：擴散模型已成為生成任務的強大工具，在各種領域產生高品質的輸出。然而，生成資料如何回應擴散模型中的初始雜訊擾動仍未得到充分探討，這阻礙了對取樣過程可控性的理解。在這項工作中，我們首先觀察到一個有趣的現象：生成輸出變化與擴散 ODE 取樣中初始雜訊擾動的規模之間的關係是高度線性的。然後，我們提供理論和實證研究來證明此輸入輸出（雜訊生成資料）關係的線性性質。受到這些新見解的啟發，我們提出了一種新的可控約束取樣方法 (CCS) 以及一種新的控制器演算法，用於擴散模型，以在保留良好樣本品質的同時，以所需的統計特性進行取樣。我們進行了大量的實驗，以比較我們提出的取樣方法與其他方法在取樣可控性和取樣資料品質上的表現。結果顯示，我們的 CCS 方法實現了更精確的受控取樣，同時保持優異的樣本品質和多樣性。

##### **A Comprehensive Review on Noise Control of Diffusion Model**
2502.04669v1 by Zhehao Guo, Jiedong Lang, Shuyu Huang, Yunfei Gao, Xintong Ding

Diffusion models have recently emerged as powerful generative frameworks for
producing high-quality images. A pivotal component of these models is the noise
schedule, which governs the rate of noise injection during the diffusion
process. Since the noise schedule substantially influences sampling quality and
training quality, understanding its design and implications is crucial. In this
discussion, various noise schedules are examined, and their distinguishing
features and performance characteristics are highlighted.

摘要：擴散模型最近已成為強大的生成式架構，可用於製作高品質影像。這些模型的樞紐元件是雜訊行程，它控制擴散過程中雜訊注入的比率。由於雜訊行程會大幅影響取樣品質和訓練品質，因此了解其設計和影響至關重要。在本次討論中，我們將檢視各種雜訊行程，並重點說明它們的區別特徵和效能特性。

##### **Unveiling the Mechanisms of Explicit CoT Training: How Chain-of-Thought Enhances Reasoning Generalization**
2502.04667v1 by Xinhao Yao, Ruifeng Ren, Yun Liao, Yong Liu

Training large language models (LLMs) with high-quality Chain-of-Thought
(CoT) annotations has become a widely adopted strategy due to its significant
enhancement of reasoning capabilities. To fully comprehend this approach, two
questions naturally arise: (Q1) What advantages does training with CoT offer
compared to training without CoT? (Q2) If there are advantages, what are the
underlying mechanisms of explicit CoT training? Analyzing the advantages and
mechanisms of CoT training is challenging due to the many factors involved. To
address this, we conduct a detailed analysis using clear and controllable data
distributions and, for the first time, reveal that CoT training offers the
following advantages: (1) Training with CoT markedly improves reasoning
generalization, extending it from in-distribution (ID) to both ID and
out-of-distribution (OOD) scenarios, while also speeding up convergence; (2)
Even when training with CoT includes a certain range of erroneous reasoning
steps, it still enables the model to learn reasoning patterns, leading to
systematic generalization. We further explore the underlying mechanisms from a
circuit perspective: (1) The data distribution (e.g., ratio $\lambda$ and
pattern) plays a crucial role in influencing the model's systematic
generalization; (2) CoT training (with two-hop facts) internalizes reasoning
into a two-stage generalizing circuit, where the number of stages corresponds
to the explicit reasoning steps during training. Our findings elucidate the
mechanisms underlying explicit CoT training and offer critical insights into
tuning strategies for LLMs to achieve robust generalization.

摘要：<paragraph>使用高品質思維鏈 (CoT) 標註來訓練大型語言模型 (LLM) 已成為廣泛採用的策略，因為它顯著增強了推理能力。為了充分理解這種方法，自然會產生兩個問題：(Q1) 與沒有 CoT 的訓練相比，使用 CoT 訓練有哪些優點？(Q2) 如果有優點，明確的 CoT 訓練的底層機制是什麼？分析 CoT 訓練的優點和機制具有挑戰性，因為涉及許多因素。為了解決這個問題，我們使用清晰且可控的資料分佈進行詳細分析，並首次揭示 CoT 訓練提供以下優點：(1) 使用 CoT 進行訓練顯著改善推理泛化，將其從分佈內 (ID) 延伸到 ID 和分佈外 (OOD) 場景，同時也加快了收斂速度；(2) 即使使用 CoT 進行訓練包含一定範圍的錯誤推理步驟，它仍然使模型能夠學習推理模式，從而導致系統性泛化。我們進一步從電路角度探討其底層機制：(1) 資料分佈（例如比率 $\lambda$ 和模式）在影響模型的系統性泛化中扮演著至關重要的角色；(2) CoT 訓練（使用兩跳事實）將推理內化為兩階段泛化電路，其中階段數對應於訓練期間的明確推理步驟。我們的發現闡明了明確 CoT 訓練的底層機制，並為調整 LLM 的策略提供了關鍵見解，以實現強大的泛化。</paragraph>

##### **Shifting Attention to You: Personalized Brain-Inspired AI Models**
2502.04658v1 by Stephen Chong Zhao, Yang Hu, Jason Lee, Andrew Bender, Trisha Mazumdar, Mark Wallace, David A. Tovar

The integration of human and artificial intelligence represents a scientific
opportunity to advance our understanding of information processing, as each
system offers unique computational insights that can enhance and inform the
other. The synthesis of human cognitive principles with artificial intelligence
has the potential to produce more interpretable and functionally aligned
computational models, while simultaneously providing a formal framework for
investigating the neural mechanisms underlying perception, learning, and
decision-making through systematic model comparisons and representational
analyses. In this study, we introduce personalized brain-inspired modeling that
integrates human behavioral embeddings and neural data to align with cognitive
processes. We took a stepwise approach, fine-tuning the Contrastive
Language-Image Pre-training (CLIP) model with large-scale behavioral decisions,
group-level neural data, and finally, participant-level neural data within a
broader framework that we have named CLIP-Human-Based Analysis (CLIP-HBA). We
found that fine-tuning on behavioral data enhances its ability to predict human
similarity judgments while indirectly aligning it with dynamic representations
captured via MEG. To further gain mechanistic insights into the temporal
evolution of cognitive processes, we introduced a model specifically fine-tuned
on millisecond-level MEG neural dynamics (CLIP-HBA-MEG). This model resulted in
enhanced temporal alignment with human neural processing while still showing
improvement on behavioral alignment. Finally, we trained individualized models
on participant-specific neural data, effectively capturing individualized
neural dynamics and highlighting the potential for personalized AI systems.
These personalized systems have far-reaching implications for the fields of
medicine, cognitive research, human-computer interfaces, and AI development.

摘要：<paragraph>人類與人工智慧的整合代表了一項科學機會，可以增進我們對資訊處理的理解，因為每個系統都提供獨特的運算見解，可以增強並告知另一個系統。人類認知原則與人工智慧的綜合具有產生更具可解釋性和功能性對齊運算模型的潛力，同時為透過系統性模型比較和表徵分析來調查知覺、學習和決策背後的類神經機制提供一個正式架構。在這項研究中，我們引入了個人化的大腦啟發模型，整合了人類行為嵌入和神經資料，以與認知過程保持一致。我們採取逐步方法，微調對比語言影像預訓練 (CLIP) 模型，並使用大規模行為決策、群組層級神經資料，最後在我們命名為 CLIP 人類為基礎分析 (CLIP-HBA) 的更廣泛架構中使用參與者層級神經資料。我們發現，在行為資料上進行微調增強了其預測人類相似性判斷的能力，同時間接地將其與透過 MEG 擷取的動態表徵對齊。為了進一步獲得對認知過程時間演化的機制見解，我們引入了專門針對毫秒級 MEG 神經動態進行微調的模型 (CLIP-HBA-MEG)。此模型增強了與人類神經處理的時間對齊，同時仍顯示出行為對齊的改善。最後，我們針對參與者特定的神經資料訓練了個別化模型，有效擷取個別化的神經動態，並突顯了個人化 AI 系統的潛力。這些個人化系統對醫學、認知研究、人機介面和 AI 開發領域具有深遠的影響。</paragraph>

##### **Before It's Too Late: A State Space Model for the Early Prediction of Misinformation and Disinformation Engagement**
2502.04655v1 by Lin Tian, Emily Booth, Francesco Bailo, Julian Droogan, Marian-Andrei Rizoiu

In today's digital age, conspiracies and information campaigns can emerge
rapidly and erode social and democratic cohesion. While recent deep learning
approaches have made progress in modeling engagement through language and
propagation models, they struggle with irregularly sampled data and early
trajectory assessment. We present IC-Mamba, a novel state space model that
forecasts social media engagement by modeling interval-censored data with
integrated temporal embeddings. Our model excels at predicting engagement
patterns within the crucial first 15-30 minutes of posting (RMSE 0.118-0.143),
enabling rapid assessment of content reach. By incorporating interval-censored
modeling into the state space framework, IC-Mamba captures fine-grained
temporal dynamics of engagement growth, achieving a 4.72% improvement over
state-of-the-art across multiple engagement metrics (likes, shares, comments,
and emojis). Our experiments demonstrate IC-Mamba's effectiveness in
forecasting both post-level dynamics and broader narrative patterns (F1
0.508-0.751 for narrative-level predictions). The model maintains strong
predictive performance across extended time horizons, successfully forecasting
opinion-level engagement up to 28 days ahead using observation windows of 3-10
days. These capabilities enable earlier identification of potentially
problematic content, providing crucial lead time for designing and implementing
countermeasures. Code is available at: https://github.com/ltian678/ic-mamba. An
interactive dashboard demonstrating our results is available at:
https://ic-mamba.behavioral-ds.science.

摘要：<paragraph>在當今數位時代，陰謀論和資訊宣傳活動可能迅速浮現，並侵蝕社會和民主凝聚力。儘管最近的深度學習方法在透過語言和傳播模型來模擬互動方面已取得進展，但它們仍難以處理不規則採樣的資料和早期軌跡評估。我們提出 IC-Mamba，這是一個新穎的狀態空間模型，透過使用整合時序嵌入來模擬區間審查資料，來預測社群媒體互動。我們的模型擅於預測發布後最初 15-30 分鐘內的互動模式（RMSE 0.118-0.143），能夠快速評估內容觸及率。透過將區間審查模擬納入狀態空間架構中，IC-Mamba 能夠捕捉互動成長的細微時序動態，在多項互動指標（按讚、分享、留言和表情符號）上比現有技術進步了 4.72%。我們的實驗證明了 IC-Mamba 在預測貼文層級動態和更廣泛的敘事模式方面（敘事層級預測的 F1 為 0.508-0.751）的有效性。該模型在延長期限內維持強大的預測效能，使用 3-10 天的觀察視窗，成功預測了未來 28 天的意見層級互動。這些功能能夠更早辨識潛在有問題的內容，為設計和實施對策提供了至關重要的前置時間。程式碼可在以下位置取得：https://github.com/ltian678/ic-mamba。展示我們結果的互動式儀表板可在以下位置取得：https://ic-mamba.behavioral-ds.science。</paragraph>

##### **Importance Sampling via Score-based Generative Models**
2502.04646v1 by Heasung Kim, Taekyun Lee, Hyeji Kim, Gustavo de Veciana

Importance sampling, which involves sampling from a probability density
function (PDF) proportional to the product of an importance weight function and
a base PDF, is a powerful technique with applications in variance reduction,
biased or customized sampling, data augmentation, and beyond. Inspired by the
growing availability of score-based generative models (SGMs), we propose an
entirely training-free Importance sampling framework that relies solely on an
SGM for the base PDF. Our key innovation is realizing the importance sampling
process as a backward diffusion process, expressed in terms of the score
function of the base PDF and the specified importance weight function--both
readily available--eliminating the need for any additional training. We conduct
a thorough analysis demonstrating the method's scalability and effectiveness
across diverse datasets and tasks, including importance sampling for industrial
and natural images with neural importance weight functions. The training-free
aspect of our method is particularly compelling in real-world scenarios where a
single base distribution underlies multiple biased sampling tasks, each
requiring a different importance weight function. To the best of our knowledge
our approach is the first importance sampling framework to achieve this.

摘要：重要性採樣，涉及從與重要性權重函數和基本 PDF 成正比的機率密度函數 (PDF) 中進行採樣，是一種強大的技術，可應用於變異數減少、有偏或自訂採樣、資料擴充等方面。受基於分數的生成模型 (SGM) 日益普及的啟發，我們提出了一個完全無需訓練的重要採樣架構，該架構僅依賴於 SGM 來作為基本 PDF。我們的關鍵創新是將重要性採樣過程實現為一個反向擴散過程，用基本 PDF 的分數函數和指定的權重函數來表示，這兩個函數都很容易取得，因此無需任何額外的訓練。我們進行了一項徹底的分析，證明了該方法在各種資料集和任務中的可擴充性和有效性，包括使用神經重要性權重函數對工業和自然影像進行重要性採樣。在現實世界中，單一基本分佈會對應到多個有偏採樣任務的情況下，我們的無訓練方法特別具有吸引力，因為每個任務都需要不同的重要性權重函數。據我們所知，我們的途徑是第一個實現此目標的重要採樣架構。

##### **Cross-Encoder Rediscovers a Semantic Variant of BM25**
2502.04645v1 by Meng Lu, Catherine Chen, Carsten Eickhoff

Neural Ranking Models (NRMs) have rapidly advanced state-of-the-art
performance on information retrieval tasks. In this work, we investigate a
Cross-Encoder variant of MiniLM to determine which relevance features it
computes and where they are stored. We find that it employs a semantic variant
of the traditional BM25 in an interpretable manner, featuring localized
components: (1) Transformer attention heads that compute soft term frequency
while controlling for term saturation and document length effects, and (2) a
low-rank component of its embedding matrix that encodes inverse document
frequency information for the vocabulary. This suggests that the Cross-Encoder
uses the same fundamental mechanisms as BM25, but further leverages their
capacity to capture semantics for improved retrieval performance. The granular
understanding lays the groundwork for model editing to enhance model
transparency, addressing safety concerns, and improving scalability in training
and real-world applications.

摘要：神經排序模型 (NRM) 已快速提升資訊檢索任務的最新技術效能。在這項工作中，我們研究了 MiniLM 的交叉編碼器變體，以確定它計算哪些相關性特徵以及它們儲存在哪裡。我們發現它以可詮釋的方式採用傳統 BM25 的語義變體，具有局部元件：(1) Transformer 注意力權重計算軟詞頻，同時控制詞彙飽和度和文件長度效應，以及 (2) 其嵌入矩陣的低秩元件，用於編碼詞彙的逆文件頻率資訊。這表明交叉編碼器使用與 BM25 相同的基本機制，但進一步利用它們擷取語義的能力來改善檢索效能。細緻的理解為模型編輯奠定了基礎，以增強模型透明度、解決安全問題，並改善訓練和實際應用中的可擴充性。

##### **Agentic Reasoning: Reasoning LLMs with Tools for the Deep Research**
2502.04644v1 by Junde Wu, Jiayuan Zhu, Yuyuan Liu

We introduce Agentic Reasoning, a framework that enhances large language
model (LLM) reasoning by integrating external tool-using agents. Unlike
conventional LLM-based reasoning approaches, which rely solely on internal
inference, Agentic Reasoning dynamically engages web search, code execution,
and structured reasoning-context memory to solve complex problems requiring
deep research and multi-step logical deduction. Our framework introduces the
Mind Map agent, which constructs a structured knowledge graph to track logical
relationships, improving deductive reasoning. Additionally, the integration of
web-search and coding agents enables real-time retrieval and computational
analysis, enhancing reasoning accuracy and decision-making. Evaluations on
PhD-level scientific reasoning (GPQA) and domain-specific deep research tasks
demonstrate that our approach significantly outperforms existing models,
including leading retrieval-augmented generation (RAG) systems and
closed-source LLMs. Moreover, our results indicate that agentic reasoning
improves expert-level knowledge synthesis, test-time scalability, and
structured problem-solving. The code is at:
https://github.com/theworldofagents/Agentic-Reasoning.

摘要：我們引入了代理推理，一個透過整合外部工具使用代理來增強大型語言模型 (LLM) 推理的框架。與僅依賴於內部推論的傳統基於 LLM 的推理方法不同，代理推理動態地運用網路搜尋、程式碼執行和結構化推理情境記憶來解決需要深入研究和多步驟邏輯推論的複雜問題。我們的框架引入了心智圖代理，它建立一個結構化的知識圖譜來追蹤邏輯關係，改善演繹推理。此外，整合網路搜尋和編碼代理能進行即時擷取和運算分析，增強推理準確度和決策制定。在博士等級科學推理 (GPQA) 和特定領域的深入研究任務上的評估顯示，我們的做法明顯優於現有模型，包括領先的檢索增強生成 (RAG) 系統和封閉原始碼 LLM。此外，我們的結果顯示，代理推理改進了專家級知識綜合、測試時間可擴充性和結構化問題解決。程式碼在：https://github.com/theworldofagents/Agentic-Reasoning。

##### **Confidence Elicitation: A New Attack Vector for Large Language Models**
2502.04643v1 by Brian Formento, Chuan Sheng Foo, See-Kiong Ng

A fundamental issue in deep learning has been adversarial robustness. As
these systems have scaled, such issues have persisted. Currently, large
language models (LLMs) with billions of parameters suffer from adversarial
attacks just like their earlier, smaller counterparts. However, the threat
models have changed. Previously, having gray-box access, where input embeddings
or output logits/probabilities were visible to the user, might have been
reasonable. However, with the introduction of closed-source models, no
information about the model is available apart from the generated output. This
means that current black-box attacks can only utilize the final prediction to
detect if an attack is successful. In this work, we investigate and demonstrate
the potential of attack guidance, akin to using output probabilities, while
having only black-box access in a classification setting. This is achieved
through the ability to elicit confidence from the model. We empirically show
that the elicited confidence is calibrated and not hallucinated for current
LLMs. By minimizing the elicited confidence, we can therefore increase the
likelihood of misclassification. Our new proposed paradigm demonstrates
promising state-of-the-art results on three datasets across two models
(LLaMA-3-8B-Instruct and Mistral-7B-Instruct-V0.3) when comparing our technique
to existing hard-label black-box attack methods that introduce word-level
substitutions.

摘要：深度學習中的基本問題一直是對抗魯棒性。隨著這些系統的擴展，這些問題仍然存在。目前，擁有數十億個參數的大型語言模型 (LLM) 與其早期較小的對應模型一樣，會受到對抗性攻擊。然而，威脅模型已經改變。以前，具有灰盒存取權限，其中使用者可以看到輸入嵌入或輸出 logit/機率，可能是合理的。然而，隨著封閉原始碼模型的引入，除了產生的輸出之外，沒有任何關於模型的資訊可用。這表示目前的 black-box 攻擊只能利用最終預測來偵測攻擊是否成功。在這項工作中，我們探討並展示了攻擊指導的潛力，類似於使用輸出機率，同時在分類設定中只有 black-box 存取權限。這是透過引發模型信心的能力來實現的。我們經驗性地展示了引發的信心是經過校準的，而不是對目前 LLM 產生的幻覺。透過最小化引發的信心，我們因此可以增加誤分類的可能性。我們新提出的範例在比較我們的技術與現有的硬標籤 black-box 攻擊方法（引入字元層級替換）時，在兩個模型（LLaMA-3-8B-Instruct 和 Mistral-7B-Instruct-V0.3）的 3 個資料集上展示了有前途的最新結果。

##### **Extracting and Understanding the Superficial Knowledge in Alignment**
2502.04602v1 by Runjin Chen, Gabriel Jacob Perin, Xuxi Chen, Xilun Chen, Yan Han, Nina S. T. Hirata, Junyuan Hong, Bhavya Kailkhura

Alignment of large language models (LLMs) with human values and preferences,
often achieved through fine-tuning based on human feedback, is essential for
ensuring safe and responsible AI behaviors. However, the process typically
requires substantial data and computation resources. Recent studies have
revealed that alignment might be attainable at lower costs through simpler
methods, such as in-context learning. This leads to the question: Is alignment
predominantly superficial? In this paper, we delve into this question and
provide a quantitative analysis. We formalize the concept of superficial
knowledge, defining it as knowledge that can be acquired through easily token
restyling, without affecting the model's ability to capture underlying causal
relationships between tokens. We propose a method to extract and isolate
superficial knowledge from aligned models, focusing on the shallow
modifications to the final token selection process. By comparing models
augmented only with superficial knowledge to fully aligned models, we quantify
the superficial portion of alignment. Our findings reveal that while
superficial knowledge constitutes a significant portion of alignment,
particularly in safety and detoxification tasks, it is not the whole story.
Tasks requiring reasoning and contextual understanding still rely on deeper
knowledge. Additionally, we demonstrate two practical advantages of isolated
superficial knowledge: (1) it can be transferred between models, enabling
efficient offsite alignment of larger models using extracted superficial
knowledge from smaller models, and (2) it is recoverable, allowing for the
restoration of alignment in compromised models without sacrificing performance.

摘要：大型語言模型 (LLM) 與人類價值觀和偏好的對齊，通常透過根據人類回饋進行微調來達成，對於確保安全且負責任的 AI 行為至關重要。然而，此程序通常需要大量的資料和運算資源。最近的研究顯示，透過更簡單的方法（例如情境學習）可能可以用更低的成本達成對齊。這引發了一個問題：對齊是否主要是表面的？在本文中，我們深入探討這個問題，並提供定量分析。我們將表面知識的概念形式化，將其定義為可透過輕鬆的標記重塑獲得的知識，而不會影響模型擷取標記之間底層因果關係的能力。我們提出一個方法來從對齊的模型中提取和分離表面知識，重點放在對最終標記選擇過程的淺層修改。透過比較僅增加表面知識的模型和完全對齊的模型，我們量化了對齊的表面部分。我們的發現顯示，儘管表面知識構成對齊的很大一部分，特別是在安全和解毒任務中，但這並非全部。需要推理和情境理解的任務仍然依賴於更深入的知識。此外，我們展示了孤立的表面知識的兩個實際優點：(1) 它可以在模型之間轉移，使用從較小模型中提取的表面知識，能有效地對較大型模型進行場外對齊，以及 (2) 它具有可復原性，允許在不犧牲效能的情況下恢復受損模型的對齊。

##### **The $α$-Alternator: Dynamic Adaptation To Varying Noise Levels In Sequences Using The Vendi Score For Improved Robustness and Performance**
2502.04593v1 by Mohammad Reza Rezaei, Adji Bousso Dieng

Current state-of-the-art dynamical models, such as Mamba, assume the same
level of noisiness for all elements of a given sequence, which limits their
performance on noisy temporal data. In this paper, we introduce the
$\alpha$-Alternator, a novel generative model for time-dependent data that
dynamically adapts to the complexity introduced by varying noise levels in
sequences. The $\alpha$-Alternator leverages the Vendi Score (VS), a flexible
similarity-based diversity metric, to adjust, at each time step $t$, the
influence of the sequence element at time $t$ and the latent representation of
the dynamics up to that time step on the predicted future dynamics. This
influence is captured by a parameter that is learned and shared across all
sequences in a given dataset. The sign of this parameter determines the
direction of influence. A negative value indicates a noisy dataset, where a
sequence element that increases the VS is considered noisy, and the model
relies more on the latent history when processing that element. Conversely,
when the parameter is positive, a sequence element that increases the VS is
considered informative, and the $\alpha$-Alternator relies more on this new
input than on the latent history when updating its predicted latent dynamics.
The $\alpha$-Alternator is trained using a combination of observation masking
and Alternator loss minimization. Masking simulates varying noise levels in
sequences, enabling the model to be more robust to these fluctuations and
improving its performance in trajectory prediction, imputation, and
forecasting. Our experimental results demonstrate that the $\alpha$-Alternator
outperforms both Alternators and state-of-the-art state-space models across
neural decoding and time-series forecasting benchmarks.

摘要：<paragraph>例如 Mamba 等現今最先進的動態模型，假設給定序列中所有元素的雜訊程度相同，這限制了它們在雜訊時間資料上的效能。在本文中，我們介紹了 $\alpha$-Alternator，這是一個新穎的時序資料生成模型，可動態適應序列中不同雜訊程度帶來的複雜性。$\alpha$-Alternator 利用了 Vendi 分數 (VS)，這是一個彈性的基於相似性的多樣性度量，在每個時間步驟 $t$ 調整時間 $t$ 的序列元素影響，以及動態的潛在表示，直到時間步驟對預測的未來動態。這種影響是由一個參數擷取的，這個參數在給定資料集中的所有序列中學習和共享。此參數的符號決定了影響的方向。負值表示雜訊資料集，其中增加 VS 的序列元素被視為雜訊，而模型在處理該元素時更依賴潛在歷史。相反，當參數為正時，增加 VS 的序列元素被視為資訊性的，而 $\alpha$-Alternator 在更新其預測潛在動態時，比潛在歷史更依賴於這個新的輸入。$\alpha$-Alternator 使用觀測遮罩和 Alternator 損失最小化的組合進行訓練。遮罩模擬序列中不同的雜訊程度，使模型對這些波動更具魯棒性，並改善其在軌跡預測、插補和預測中的效能。我們的實驗結果表明，$\alpha$-Alternator 在神經解碼和時序預測基準上，都優於 Alternator 和最先進的狀態空間模型。</paragraph>

##### **CAMEF: Causal-Augmented Multi-Modality Event-Driven Financial Forecasting by Integrating Time Series Patterns and Salient Macroeconomic Announcements**
2502.04592v1 by Yang Zhang, Wenbo Yang, Jun Wang, Qiang Ma, Jie Xiong

Accurately forecasting the impact of macroeconomic events is critical for
investors and policymakers. Salient events like monetary policy decisions and
employment reports often trigger market movements by shaping expectations of
economic growth and risk, thereby establishing causal relationships between
events and market behavior. Existing forecasting methods typically focus either
on textual analysis or time-series modeling, but fail to capture the
multi-modal nature of financial markets and the causal relationship between
events and price movements. To address these gaps, we propose CAMEF
(Causal-Augmented Multi-Modality Event-Driven Financial Forecasting), a
multi-modality framework that effectively integrates textual and time-series
data with a causal learning mechanism and an LLM-based counterfactual event
augmentation technique for causal-enhanced financial forecasting. Our
contributions include: (1) a multi-modal framework that captures causal
relationships between policy texts and historical price data; (2) a new
financial dataset with six types of macroeconomic releases from 2008 to April
2024, and high-frequency real trading data for five key U.S. financial assets;
and (3) an LLM-based counterfactual event augmentation strategy. We compare
CAMEF to state-of-the-art transformer-based time-series and multi-modal
baselines, and perform ablation studies to validate the effectiveness of the
causal learning mechanism and event types.

摘要：準確預測巨觀經濟事件的影響對投資者和政策制定者至關重要。貨幣政策決策和就業報告等顯著事件通常會通過塑造對經濟增長和風險的預期來觸發市場波動，從而建立事件與市場行為之間的因果關係。現有的預測方法通常側重於文本分析或時間序列建模，但無法捕捉金融市場的多模態特性以及事件與價格變動之間的因果關係。為了解決這些差距，我們提出了 CAMEF（因果增強的多模態事件驅動金融預測），這是一個多模態框架，有效地將文本和時間序列數據與因果學習機制和基於 LLM 的反事實事件增強技術相結合，用於因果增強的金融預測。我們的貢獻包括：(1) 一個多模態框架，捕捉政策文本和歷史價格數據之間的因果關係；(2) 一個新的金融數據集，包含 2008 年至 2024 年 4 月期間六種類型的宏觀經濟發布，以及五種美國主要金融資產的高頻真實交易數據；(3) 一種基於 LLM 的反事實事件增強策略。我們將 CAMEF 與最先進的基於變換器的時間序列和多模態基線進行比較，並進行消融研究以驗證因果學習機制和事件類型的有效性。

##### **Rethinking Oversmoothing in Graph Neural Networks: A Rank-Based Perspective**
2502.04591v1 by Piero Deidda, Kaicheng Zhang, Desmond Higham, Francesco Tudisco

Oversmoothing is a fundamental challenge in graph neural networks (GNNs): as
the number of layers increases, node embeddings become increasingly similar,
and model performance drops sharply. Traditionally, oversmoothing has been
quantified using metrics that measure the similarity of neighbouring node
features, such as the Dirichlet energy. While these metrics are related to
oversmoothing, we argue they have critical limitations and fail to reliably
capture oversmoothing in realistic scenarios. For instance, they provide
meaningful insights only for very deep networks and under somewhat strict
conditions on the norm of network weights and feature representations. As an
alternative, we propose measuring oversmoothing by examining the numerical or
effective rank of the feature representations. We provide theoretical support
for this approach, demonstrating that the numerical rank of feature
representations converges to one for a broad family of nonlinear activation
functions under the assumption of nonnegative trained weights. To the best of
our knowledge, this is the first result that proves the occurrence of
oversmoothing without assumptions on the boundedness of the weight matrices.
Along with the theoretical findings, we provide extensive numerical evaluation
across diverse graph architectures. Our results show that rank-based metrics
consistently capture oversmoothing, whereas energy-based metrics often fail.
Notably, we reveal that a significant drop in the rank aligns closely with
performance degradation, even in scenarios where energy metrics remain
unchanged.

摘要：過度平滑是圖神經網路 (GNN) 中的基本挑戰：隨著層數增加，節點嵌入變得越來越相似，模型效能急劇下降。傳統上，過度平滑已使用度量鄰近節點特徵相似性的指標量化，例如 Dirichlet 能量。雖然這些指標與過度平滑相關，但我們認為它們有嚴重的限制，無法在實際情況中可靠地捕捉過度平滑。例如，它們僅對非常深的網路提供有意義的見解，且對網路權重和特徵表示的範數有嚴格的條件。作為替代方案，我們建議透過檢查特徵表示的數值或有效秩來測量過度平滑。我們為此方法提供理論支持，證明特徵表示的數值秩在非負訓練權重的假設下，對於非線性激活函數的廣泛族會收斂到一。據我們所知，這是第一個證明過度平滑發生的結果，而沒有對權重矩陣的界限性做出假設。除了理論發現之外，我們還提供跨不同圖形架構的廣泛數值評估。我們的結果表明，基於秩的指標始終捕捉過度平滑，而基於能量的指標則經常失敗。值得注意的是，我們發現秩的顯著下降與效能下降密切相關，即使在能量指標保持不變的情況下也是如此。

##### **Technical Debt in In-Context Learning: Diminishing Efficiency in Long Context**
2502.04580v1 by Taejong Joo, Diego Klabjan

Transformers have demonstrated remarkable in-context learning (ICL)
capabilities, adapting to new tasks by simply conditioning on demonstrations
without parameter updates. Compelling empirical and theoretical evidence
suggests that ICL, as a general-purpose learner, could outperform task-specific
models. However, it remains unclear to what extent the transformers optimally
learn in-context compared to principled learning algorithms. To bridge this
gap, we introduce a new framework for quantifying optimality of ICL as a
learning algorithm in stylized settings. Our findings reveal a striking
dichotomy: while ICL initially matches the efficiency of a Bayes optimal
estimator, its efficiency significantly deteriorates in long context. Through
an information-theoretic analysis, we show that the diminishing efficiency is
inherent to ICL. These results clarify the trade-offs in adopting ICL as a
universal problem solver, motivating a new generation of on-the-fly adaptive
methods without the diminishing efficiency.

摘要：Transformer已展現出卓越的脈絡學習 (ICL) 能力，只要透過示範進行條件化，就能適應新任務，而無需參數更新。令人信服的經驗和理論證據表明，ICL 作為通用學習器，可以優於特定任務模型。然而，Transformer在脈絡中學習的最佳程度與原則性學習演算法相比，仍不清楚。為了彌補這個差距，我們引入了一個新的架構，用於量化 ICL 作為標準化設定中的學習演算法的最佳性。我們的發現揭示了一個驚人的二分法：雖然 ICL 最初與貝氏最佳估計器的效率相匹配，但其效率在長脈絡中會顯著下降。透過資訊理論分析，我們表明效率下降是 ICL 的固有特徵。這些結果闡明了採用 ICL 作為通用問題解決者的權衡，激勵了新一代即時自適應方法，而沒有效率下降的問題。

##### **Position-aware Automatic Circuit Discovery**
2502.04577v1 by Tal Haklay, Hadas Orgad, David Bau, Aaron Mueller, Yonatan Belinkov

A widely used strategy to discover and understand language model mechanisms
is circuit analysis. A circuit is a minimal subgraph of a model's computation
graph that executes a specific task. We identify a gap in existing circuit
discovery methods: they assume circuits are position-invariant, treating model
components as equally relevant across input positions. This limits their
ability to capture cross-positional interactions or mechanisms that vary across
positions. To address this gap, we propose two improvements to incorporate
positionality into circuits, even on tasks containing variable-length examples.
First, we extend edge attribution patching, a gradient-based method for circuit
discovery, to differentiate between token positions. Second, we introduce the
concept of a dataset schema, which defines token spans with similar semantics
across examples, enabling position-aware circuit discovery in datasets with
variable length examples. We additionally develop an automated pipeline for
schema generation and application using large language models. Our approach
enables fully automated discovery of position-sensitive circuits, yielding
better trade-offs between circuit size and faithfulness compared to prior work.

摘要：廣泛用於發現和了解語言模型機制的策略是電路分析。電路是模型計算圖的最小子圖，可執行特定任務。我們找出電路發現方法中的一個缺口：它們假設電路與位置無關，將模型組件視為在輸入位置中同樣相關。這限制了它們捕捉跨位置互動或在不同位置中變化的機制的能力。為了解決這個缺口，我們提出兩項改進，將位置性納入電路中，即使在包含變長範例的任務中也是如此。首先，我們擴充邊緣屬性修補，一種基於梯度的電路發現方法，以區分符號位置。其次，我們引入了資料集架構的概念，它定義了在範例中具有類似語義的符號跨距，使我們可以在具有變長範例的資料集中進行與位置相關的電路發現。此外，我們開發了一個自動化管線，用於使用大型語言模型進行架構生成和應用。我們的做法能讓位置敏感電路的發現完全自動化，與先前的研究相比，在電路大小和忠實度之間產生了更好的權衡。

##### **Self-Regulation and Requesting Interventions**
2502.04576v1 by So Yeon Min, Yue Wu, Jimin Sun, Max Kaufmann, Fahim Tajwar, Yonatan Bisk, Ruslan Salakhutdinov

Human intelligence involves metacognitive abilities like self-regulation,
recognizing limitations, and seeking assistance only when needed. While LLM
Agents excel in many domains, they often lack this awareness. Overconfident
agents risk catastrophic failures, while those that seek help excessively
hinder efficiency. A key challenge is enabling agents with a limited
intervention budget $C$ is to decide when to request assistance. In this paper,
we propose an offline framework that trains a "helper" policy to request
interventions, such as more powerful models or test-time compute, by combining
LLM-based process reward models (PRMs) with tabular reinforcement learning.
Using state transitions collected offline, we score optimal intervention timing
with PRMs and train the helper model on these labeled trajectories. This
offline approach significantly reduces costly intervention calls during
training. Furthermore, the integration of PRMs with tabular RL enhances
robustness to off-policy data while avoiding the inefficiencies of deep RL. We
empirically find that our method delivers optimal helper behavior.

摘要：人類智慧包含像自我調節、認知限制和僅在需要時尋求協助等元認知能力。雖然 LLM 代理在許多領域表現優異，但他們常常缺乏這種意識。過度自信的代理會冒著災難性失敗的風險，而過度尋求幫助的代理會阻礙效率。一個關鍵挑戰是讓具有有限干預預算 $C$ 的代理決定何時請求協助。在本文中，我們提出一個離線框架，訓練「幫助者」政策來請求干預，例如更強大的模型或測試時間計算，方法是將基於 LLM 的過程獎勵模型 (PRM) 與表格強化學習相結合。使用離線收集的狀態轉換，我們使用 PRM 評分最佳干預時機，並在這些標記軌跡上訓練幫助者模型。這種離線方法顯著減少了訓練期間代價高昂的干預呼叫。此外，PRM 與表格 RL 的整合增強了對非策略數據的穩健性，同時避免了深度 RL 的低效率。我們憑經驗發現，我們的模型提供了最佳的幫助者行為。

##### **Zero-shot Meta-learning for Tabular Prediction Tasks with Adversarially Pre-trained Transformer**
2502.04573v1 by Yulun Wu, Doron L. Bergman

We present an Adversarially Pre-trained Transformer (APT) that is able to
perform zero-shot meta-learning on tabular prediction tasks without
pre-training on any real-world dataset, extending on the recent development of
Prior-Data Fitted Networks (PFNs) and TabPFN. Specifically, APT is pre-trained
with adversarial synthetic data agents, who continue to shift their underlying
data generating distribution and deliberately challenge the model with
different synthetic datasets. In addition, we propose a mixture block
architecture that is able to handle classification tasks with arbitrary number
of classes, addressing the class size limitation -- a crucial weakness of prior
deep tabular zero-shot learners. In experiments, we show that our framework
matches state-of-the-art performance on small classification tasks without
filtering on dataset characteristics such as number of classes and number of
missing values, while maintaining an average runtime under one second. On
common benchmark dataset suites in both classification and regression, we show
that adversarial pre-training was able to enhance TabPFN's performance. In our
analysis, we demonstrate that the adversarial synthetic data agents were able
to generate a more diverse collection of data compared to the ordinary random
generator in TabPFN. In addition, we demonstrate that our mixture block neural
design has improved generalizability and greatly accelerated pre-training.

摘要：我們提出了一個對抗預訓練Transformer (APT)，它能夠在表格預測任務上執行零次學習元學習，而無需在任何現實世界資料集上進行預訓練，並擴展了先驗資料擬合網路 (PFN) 和 TabPFN 的最新發展。具體來說，APT 使用對抗合成資料代理進行預訓練，這些代理會持續改變其基礎資料生成分佈，並故意使用不同的合成資料集挑戰模型。此外，我們提出了一個混合區塊架構，它能夠處理具有任意類別數量的分類任務，從而解決類別大小限制——這是先前的深度表格零次學習器的關鍵弱點。在實驗中，我們表明我們的框架在小型分類任務上與最先進的效能相匹配，而無需根據資料集特徵（例如類別數和缺失值數）進行過濾，同時將平均執行時間保持在 1 秒內。在分類和迴歸中的常見基準資料集套件上，我們表明對抗預訓練能夠增強 TabPFN 的效能。在我們的分析中，我們證明了與 TabPFN 中的普通隨機生成器相比，對抗合成資料代理能夠生成更多樣化的資料集合。此外，我們證明了我們的混合區塊神經設計提高了泛化能力，並極大地加速了預訓練。

##### **Preference Optimization via Contrastive Divergence: Your Reward Model is Secretly an NLL Estimator**
2502.04567v1 by Zhuotong Chen, Fang Liu, Xuan Zhu, Yanjun Qi, Mohammad Ghavamzadeh

Existing studies on preference optimization (PO) have centered on
constructing pairwise preference data following simple heuristics, such as
maximizing the margin between preferred and dispreferred completions based on
human (or AI) ranked scores. However, none of these heuristics has a full
theoretical justification. In this work, we develop a novel PO framework that
provides theoretical guidance to effectively sample dispreferred completions.
To achieve this, we formulate PO as minimizing the negative log-likelihood
(NLL) of a probability model and propose to estimate its normalization constant
via a sampling strategy. As we will demonstrate, these estimative samples can
act as dispreferred completions in PO. We then select contrastive divergence
(CD) as the sampling strategy, and propose a novel MC-PO algorithm that applies
the Monte Carlo (MC) kernel from CD to sample hard negatives w.r.t. the
parameterized reward model. Finally, we propose the OnMC-PO algorithm, an
extension of MC-PO to the online setting. On popular alignment benchmarks,
MC-PO outperforms existing SOTA baselines, and OnMC-PO leads to further
improvement.

摘要：現有關於偏好最佳化 (PO) 的研究，主要集中於建構成對偏好資料，並遵循簡單的啟發式方法，例如根據人類 (或 AI) 排名的分數，最大化偏好完成和非偏好完成之間的邊際。然而，這些啟發式方法都沒有完整的理論依據。在這項工作中，我們開發了一個創新的 PO 架構，提供理論指導，以有效抽樣非偏好完成。為達成此目的，我們將 PO 公式化為最小化機率模型的負對數似然 (NLL)，並建議透過抽樣策略來估計其正規化常數。正如我們將展示的，這些估計樣本可以在 PO 中作為非偏好完成。然後，我們選擇對比散度 (CD) 作為抽樣策略，並提出一個創新的 MC-PO 演算法，將 CD 中的蒙地卡羅 (MC) 核心應用於抽樣相對於參數化獎勵模型的困難負值。最後，我們提出 OnMC-PO 演算法，這是 MC-PO 在線上設定中的延伸。在流行比對基準中，MC-PO 優於現有的 SOTA 基準，而 OnMC-PO 進一步提升了效能。

##### **My LLM might Mimic AAE -- But When Should it?**
2502.04564v1 by Sandra C. Sandoval, Christabel Acquaye, Kwesi Cobbina, Mohammad Nayeem Teli, Hal Daumé III

We examine the representation of African American English (AAE) in large
language models (LLMs), exploring (a) the perceptions Black Americans have of
how effective these technologies are at producing authentic AAE, and (b) in
what contexts Black Americans find this desirable. Through both a survey of
Black Americans ($n=$ 104) and annotation of LLM-produced AAE by Black
Americans ($n=$ 228), we find that Black Americans favor choice and autonomy in
determining when AAE is appropriate in LLM output. They tend to prefer that
LLMs default to communicating in Mainstream U.S. English in formal settings,
with greater interest in AAE production in less formal settings. When LLMs were
appropriately prompted and provided in context examples, our participants found
their outputs to have a level of AAE authenticity on par with transcripts of
Black American speech. Select code and data for our project can be found here:
https://github.com/smelliecat/AAEMime.git

摘要：我們檢視了大型語言模型 (LLM) 中非裔美國英語 (AAE) 的表徵，探討 (a) 黑人美國人對這些技術產生真實 AAE 的成效的看法，以及 (b) 黑人美國人在什麼情況下發現這一點是可取的。透過對黑人美國人進行調查 ($n=$ 104) 和黑人美國人對 LLM 產生的 AAE 進行註解 ($n=$ 228)，我們發現黑人美國人偏好選擇和自主權，以決定何時在 LLM 輸出中使用 AAE。他們傾向於偏好 LLM 在正式場合中預設以主流美國英語進行溝通，對在較不正式的場合中產生 AAE 更感興趣。當 LLM 得到適當提示並提供情境範例時，我們的參與者發現其輸出具有與黑人美國人演講記錄相當的 AAE 真實性。我們專案的選定程式碼和資料可在這裡找到：https://github.com/smelliecat/AAEMime.git

##### **WaferLLM: A Wafer-Scale LLM Inference System**
2502.04563v1 by Congjie He, Yeqi Huang, Pei Mu, Ziming Miao, Jilong Xue, Lingxiao Ma, Fan Yang, Luo Mai

Emerging AI accelerators increasingly adopt wafer-scale manufacturing
technologies, integrating hundreds of thousands of AI cores in a mesh-based
architecture with large distributed on-chip memory (tens of GB in total) and
ultra-high on-chip memory bandwidth (tens of PB/s). However, current LLM
inference systems, optimized for shared memory architectures like GPUs, fail to
fully exploit these accelerators. We introduce WaferLLM, the first wafer-scale
LLM inference system. WaferLLM is guided by a novel PLMR device model that
captures the unique hardware characteristics of wafer-scale architectures.
Leveraging this model, WaferLLM pioneers wafer-scale LLM parallelism,
optimizing the utilization of hundreds of thousands of on-chip cores. It also
introduces MeshGEMM and MeshGEMV, the first GEMM and GEMV implementations
designed to scale effectively on wafer-scale accelerators. Evaluations show
that WaferLLM achieves 200$\times$ better wafer-scale accelerator utilization
than state-of-the-art systems. On a commodity wafer-scale accelerator, WaferLLM
delivers 606$\times$ faster and 22$\times$ more energy-efficient GEMV compared
to an advanced GPU. For LLMs, WaferLLM enables 39$\times$ faster decoding with
1.7$\times$ better energy efficiency. We anticipate these numbers will grow
significantly as wafer-scale AI models, software, and hardware continue to
mature.

摘要：新興的 AI 加速器正日益採用晶圓級製造技術，將數十萬個 AI 核心整合到基於網格的架構中，並具備大型分布式晶片記憶體（總計數十 GB）和超高晶片記憶體頻寬（數十 PB/s）。然而，目前針對共享記憶體架構（如 GPU）進行最佳化的 LLM 推論系統，無法充分利用這些加速器。我們推出 WaferLLM，這是有史以來第一個晶圓級 LLM 推論系統。WaferLLM 由一種新穎的 PLMR 裝置模型引導，該模型擷取了晶圓級架構的獨特硬體特性。藉由利用此模型，WaferLLM 開創了晶圓級 LLM 平行處理，最佳化了數十萬個晶片核心的使用率。它還引入了 MeshGEMM 和 MeshGEMV，這是第一個 GEMM 和 GEMV 實作，旨在有效地擴充晶圓級加速器。評估結果顯示，與現有最先進的系統相比，WaferLLM 達到了 200 倍更好的晶圓級加速器使用率。在一個商用晶圓級加速器上，與先進的 GPU 相比，WaferLLM 提供了快 606 倍、能效提高 22 倍的 GEMV。對於 LLM，WaferLLM 能夠以 1.7 倍更好的能效進行快 39 倍的解碼。我們預期隨著晶圓級 AI 模型、軟體和硬體持續成熟，這些數字將大幅成長。

##### **Probing a Vision-Language-Action Model for Symbolic States and Integration into a Cognitive Architecture**
2502.04558v1 by Hong Lu, Hengxu Li, Prithviraj Singh Shahani, Stephanie Herbers, Matthias Scheutz

Vision-language-action (VLA) models hold promise as generalist robotics
solutions by translating visual and linguistic inputs into robot actions, yet
they lack reliability due to their black-box nature and sensitivity to
environmental changes. In contrast, cognitive architectures (CA) excel in
symbolic reasoning and state monitoring but are constrained by rigid predefined
execution. This work bridges these approaches by probing OpenVLA's hidden
layers to uncover symbolic representations of object properties, relations, and
action states, enabling integration with a CA for enhanced interpretability and
robustness. Through experiments on LIBERO-spatial pick-and-place tasks, we
analyze the encoding of symbolic states across different layers of OpenVLA's
Llama backbone. Our probing results show consistently high accuracies (> 0.90)
for both object and action states across most layers, though contrary to our
hypotheses, we did not observe the expected pattern of object states being
encoded earlier than action states. We demonstrate an integrated DIARC-OpenVLA
system that leverages these symbolic representations for real-time state
monitoring, laying the foundation for more interpretable and reliable robotic
manipulation.

摘要：視覺語言動作 (VLA) 模型承諾成為通用機器人解決方案，透過將視覺和語言輸入轉換為機器人動作，但由於其黑盒性質和對環境變化的敏感性，它們缺乏可靠性。相比之下，認知架構 (CA) 在符號推理和狀態監控方面表現出色，但受到嚴格預定義執行的約束。這項工作透過探測 OpenVLA 的隱藏層來橋接這些方法，以揭示物件屬性、關係和動作狀態的符號表示，從而能夠與 CA 整合，以增強可解釋性和穩健性。透過在 LIBERO 空間拾放任務中進行實驗，我們分析了 OpenVLA 的 Llama 主幹不同層中的符號狀態編碼。我們的探測結果顯示，對於大多數層中的物件和動作狀態，準確率持續很高 (> 0.90)，儘管與我們的假設相反，我們沒有觀察到預期的物件狀態比動作狀態更早編碼的模式。我們展示了一個整合的 DIARC-OpenVLA 系統，該系統利用這些符號表示進行即時狀態監控，為更具可解釋性和可靠性的機器人操作奠定基礎。

##### **TruthFlow: Truthful LLM Generation via Representation Flow Correction**
2502.04556v1 by Hanyu Wang, Bochuan Cao, Yuanpu Cao, Jinghui Chen

Large language models (LLMs) are known to struggle with consistently
generating truthful responses. While various representation intervention
techniques have been proposed, these methods typically apply a universal
representation correction vector to all input queries, limiting their
effectiveness against diverse queries in practice. In this study, we introduce
TruthFlow, a novel method that leverages the Flow Matching technique for
query-specific truthful representation correction. Specifically, TruthFlow
first uses a flow model to learn query-specific correction vectors that
transition representations from hallucinated to truthful states. Then, during
inference, the trained flow model generates these correction vectors to enhance
the truthfulness of LLM outputs. Experimental results demonstrate that
TruthFlow significantly improves performance on open-ended generation tasks
across various advanced LLMs evaluated on TruthfulQA. Moreover, the trained
TruthFlow model exhibits strong transferability, performing effectively on
other unseen hallucination benchmarks.

摘要：大型語言模型 (LLM) 已知在持續產生真實回應方面有困難。儘管已提出各種表徵介入技術，但這些方法通常將通用表徵修正向量應用於所有輸入查詢，在實務上限制了它們對不同查詢的有效性。在這項研究中，我們引入了 TruthFlow，這是一種新穎的方法，它利用流匹配技術進行特定查詢的真實表徵修正。具體來說，TruthFlow 首先使用流模型來學習特定查詢的修正向量，將表徵從幻覺狀態轉換為真實狀態。然後，在推理期間，訓練好的流模型會產生這些修正向量，以增強 LLM 輸出的真實性。實驗結果表明，TruthFlow 在 TruthfulQA 上評估的各種先進 LLM 上顯著改善了開放式生成任務的效能。此外，訓練好的 TruthFlow 模型表現出強大的可移植性，在其他未見的幻覺基準上有效執行。

##### **Unifying and Optimizing Data Values for Selection via Sequential-Decision-Making**
2502.04554v1 by Hongliang Chi, Qiong Wu, Zhengyi Zhou, Jonathan Light, Emily Dodwell, Yao Ma

Data selection has emerged as a crucial downstream application of data
valuation. While existing data valuation methods have shown promise in
selection tasks, the theoretical foundations and full potential of using data
values for selection remain largely unexplored. In this work, we first
demonstrate that data values applied for selection can be naturally
reformulated as a sequential-decision-making problem, where the optimal data
value can be derived through dynamic programming. We show this framework
unifies and reinterprets existing methods like Data Shapley through the lens of
approximate dynamic programming, specifically as myopic reward function
approximations to this sequential problem. Furthermore, we analyze how
sequential data selection optimality is affected when the ground-truth utility
function exhibits monotonic submodularity with curvature. To address the
computational challenges in obtaining optimal data values, we propose an
efficient approximation scheme using learned bipartite graphs as surrogate
utility models, ensuring greedy selection is still optimal when the surrogate
utility is correctly specified and learned. Extensive experiments demonstrate
the effectiveness of our approach across diverse datasets.

摘要：資料選擇已成為資料評估中一個至關重要的下游應用。雖然現有的資料評估方法已在選擇任務中展現出潛力，但使用資料價值進行選擇的理論基礎和全部潛力仍未被充分探討。在這項工作中，我們首先證明應用於選擇的資料價值可以自然地重新表述為一個順序決策問題，其中最佳資料價值可以透過動態規劃導出。我們展示這個架構統一並重新詮釋了現有的方法，例如透過近似動態規劃的視角，特別是作為這個順序問題的近視報酬函數近似值，來詮釋 Data Shapley。此外，我們分析當真實效用函數展現出具有曲率的單調次模性時，順序資料選擇最優性如何受到影響。為了解決在取得最佳資料價值時所遇到的計算挑戰，我們提出一個有效的近似方案，使用學習到的二部圖作為替代效用模型，確保在正確指定並學習到替代效用時，貪婪選擇仍然是最優的。廣泛的實驗證明了我們的方法在各種資料集中的有效性。

##### **Contextual Gradient Flow Modeling for Large Language Model Generalization in Multi-Scale Feature Spaces**
2502.04548v1 by Daphne Quillington, Kingsley Fairbrother, Xavier Tattershall, Irin Kabakum

Optimization methodologies for training large-scale neural architectures
often rely on uniform gradient propagation mechanisms that fail to align with
hierarchical linguistic structures, limiting their capacity to generalize
across diverse language distributions. A structured gradient refinement
framework was introduced to incorporate multi-scale contextual adjustments,
improving parameter adaptation through dynamic weighting strategies that
enhanced representation coherence. Empirical evaluations demonstrated that
structured propagation mechanisms contributed to reductions in gradient
oscillations, resulting in more stable training dynamics and improved
optimization efficiency. The comparative performance assessment indicated that
models incorporating hierarchical propagation strategies exhibited greater
robustness in long-range dependency retention and cross-domain adaptation. The
hierarchical adjustment of weight updates provided an alternative to
conventional backpropagation, reducing sensitivity to initialization conditions
while improving overall convergence efficiency. The experimental results
confirmed that structured gradient propagation influenced representation
learning trajectories, aligning parameter updates with broader linguistic
dependencies rather than isolated token-level relationships. Statistical
evaluations indicated that structured optimization strategies mitigated
overfitting while preserving adaptability across heterogeneous text
distributions. The findings established that structured gradient propagation
provided an empirically validated framework for refining hierarchical
representation learning, supporting more effective integration of linguistic
dependencies into optimization dynamics.

摘要：大型神经網路架構訓練的最佳化方法論
通常依賴於均勻的梯度傳播機制，無法與
階層語言結構對齊，限制了它們在
不同語言分佈中概括的能力。結構化的梯度精煉
架構被引入以納入多尺度上下文調整，
通過增強表示一致性的動態加權策略改善參數適應。實證評估表明
結構化傳播機制有助於減少梯度
振盪，從而導致更穩定的訓練動態和提高
最佳化效率。比較性能評估表明
包含階層傳播策略的模型在長距離依賴關係保留和跨域適應中表現出更大的
穩健性。權重更新的階層調整提供了
傳統反向傳播的替代方案，降低了對初始化條件的敏感性
同時提高整體收斂效率。實驗結果
證實結構化的梯度傳播影響了表示
學習軌跡，將參數更新與更廣泛的語言
依賴關係對齊，而不是孤立的令牌級別關係。統計
評估表明，結構化最佳化策略減輕了
過度擬合，同時保持了跨異構文本的適應性
分佈。研究結果表明，結構化的梯度傳播
提供了一個經過實證驗證的框架，用於精煉階層
表示學習，支持更有效的語言整合
最佳化動態中的依賴性。

##### **Multilingual Non-Autoregressive Machine Translation without Knowledge Distillation**
2502.04537v1 by Chenyang Huang, Fei Huang, Zaixiang Zheng, Osmar R. Zaïane, Hao Zhou, Lili Mou

Multilingual neural machine translation (MNMT) aims at using one single model
for multiple translation directions. Recent work applies non-autoregressive
Transformers to improve the efficiency of MNMT, but requires expensive
knowledge distillation (KD) processes. To this end, we propose an M-DAT
approach to non-autoregressive multilingual machine translation. Our system
leverages the recent advance of the directed acyclic Transformer (DAT), which
does not require KD. We further propose a pivot back-translation (PivotBT)
approach to improve the generalization to unseen translation directions.
Experiments show that our M-DAT achieves state-of-the-art performance in
non-autoregressive MNMT.

摘要：多語言神經機器翻譯 (MNMT) 旨在使用一個單一模型來翻譯多個方向。最近的研究將非自迴歸轉換器應用於提升 MNMT 的效率，但需要代價高昂的知識蒸餾 (KD) 程序。為此，我們提出 M-DAT 方法來進行非自迴歸多語言機器翻譯。我們的系統利用了有向無環轉換器 (DAT) 的最新進展，它不需要 KD。我們進一步提出了一個樞紐回譯 (PivotBT) 方法來提升對未見翻譯方向的泛化。實驗顯示我們的 M-DAT 在非自迴歸 MNMT 中達到了最先進的效能。

##### **A Decoding Algorithm for Length-Control Summarization Based on Directed Acyclic Transformers**
2502.04535v1 by Chenyang Huang, Hao Zhou, Cameron Jen, Kangjie Zheng, Osmar R. Zaïane, Lili Mou

Length-control summarization aims to condense long texts into a short one
within a certain length limit. Previous approaches often use autoregressive
(AR) models and treat the length requirement as a soft constraint, which may
not always be satisfied. In this study, we propose a novel length-control
decoding algorithm based on the Directed Acyclic Transformer (DAT). Our
approach allows for multiple plausible sequence fragments and predicts a
\emph{path} to connect them. In addition, we propose a Sequence Maximum a
Posteriori (SeqMAP) decoding algorithm that marginalizes different possible
paths and finds the most probable summary satisfying the length budget. Our
algorithm is based on beam search, which further facilitates a reranker for
performance improvement. Experimental results on the Gigaword and DUC2004
datasets demonstrate our state-of-the-art performance for length-control
summarization.

摘要：長度控制摘要旨在將長篇文字濃縮成短篇文字，並符合特定長度限制。先前的做法通常使用自迴歸 (AR) 模型，並將長度要求視為軟性約束，這可能無法始終得到滿足。在本研究中，我們提出一個新的長度控制解碼演算法，演算法基於有向非循環Transformer (DAT)。我們的做法允許多個合理的序列片段，並預測一條連接它們的「路徑」。此外，我們提出一個序列最大後驗 (SeqMAP) 解碼演算法，這個演算法將不同的可能路徑邊際化，並找出最有可能的摘要，以符合長度預算。我們的演算法基於光束搜尋，這進一步促進了重新排序器，以提升效能。在 Gigaword 和 DUC2004 資料集上的實驗結果證明了我們在長度控制摘要方面的最先進效能。

