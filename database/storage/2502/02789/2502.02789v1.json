{"2502.02789": {"publish_time": "2025-02-05", "title": "Speculative Prefill: Turbocharging TTFT with Lightweight and Training-Free Token Importance Estimation", "paper_summary": "Improving time-to-first-token (TTFT) is an essentially important objective in\nmodern large language model (LLM) inference engines. Because optimizing TTFT\ndirectly results in higher maximal QPS and meets the requirements of many\ncritical applications. However, boosting TTFT is notoriously challenging since\nit is purely compute-bounded and the performance bottleneck shifts from the\nself-attention to the MLP part. We present SpecPrefill, a training free\nframework that accelerates the inference TTFT for both long and medium context\nqueries based on the following insight: LLMs are generalized enough to still\npreserve the quality given only a carefully chosen subset of prompt tokens. At\nits core, SpecPrefill leverages a lightweight model to speculate locally\nimportant tokens based on the context. These tokens, along with the necessary\npositional information, are then sent to the main model for processing. We\nevaluate SpecPrefill with a diverse set of tasks, followed by a comprehensive\nbenchmarking of performance improvement both in a real end-to-end setting and\nablation studies. SpecPrefill manages to serve Llama-3.1-405B-Instruct-FP8 with\nup to $7\\times$ maximal end-to-end QPS on real downstream tasks and\n$7.66\\times$ TTFT improvement during benchmarking.", "paper_summary_zh": "\u6539\u5584\u9996\u6b21\u6807\u8bb0\u65f6\u95f4 (TTFT) \u662f\u73b0\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u63a8\u7406\u5f15\u64ce\u4e2d\u81f3\u5173\u91cd\u8981\u7684\u76ee\u6807\u3002\u56e0\u4e3a\u4f18\u5316 TTFT \u76f4\u63a5\u5bfc\u81f4\u66f4\u9ad8\u7684\u6700\u5927 QPS\uff0c\u5e76\u6ee1\u8db3\u8bb8\u591a\u5173\u952e\u5e94\u7528\u7a0b\u5e8f\u7684\u8981\u6c42\u3002\u7136\u800c\uff0c\u63d0\u5347 TTFT \u4f17\u6240\u5468\u77e5\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u5b83\u7eaf\u7cb9\u53d7\u8ba1\u7b97\u9650\u5236\uff0c\u5e76\u4e14\u6027\u80fd\u74f6\u9888\u4ece\u81ea\u6ce8\u610f\u529b\u8f6c\u79fb\u5230 MLP \u90e8\u5206\u3002\u6211\u4eec\u63d0\u51fa\u4e86 SpecPrefill\uff0c\u8fd9\u662f\u4e00\u4e2a\u8bad\u7ec3\u514d\u8d39\u7684\u6846\u67b6\uff0c\u5b83\u57fa\u4e8e\u4ee5\u4e0b\u89c1\u89e3\u52a0\u901f\u4e86\u957f\u4e0a\u4e0b\u6587\u548c\u4e2d\u7b49\u4e0a\u4e0b\u6587\u67e5\u8be2\u7684\u63a8\u7406 TTFT\uff1aLLM \u8db3\u591f\u901a\u7528\uff0c\u5373\u4f7f\u53ea\u7ed9\u5b9a\u7cbe\u5fc3\u9009\u62e9\u7684\u63d0\u793a\u6807\u8bb0\u5b50\u96c6\uff0c\u4e5f\u80fd\u4fdd\u6301\u8d28\u91cf\u3002\u4ece\u672c\u8d28\u4e0a\u8bb2\uff0cSpecPrefill \u5229\u7528\u8f7b\u91cf\u7ea7\u6a21\u578b\u6839\u636e\u4e0a\u4e0b\u6587\u63a8\u6d4b\u5c40\u90e8\u91cd\u8981\u6807\u8bb0\u3002\u7136\u540e\u5c06\u8fd9\u4e9b\u6807\u8bb0\u8fde\u540c\u5fc5\u8981\u7684\u4f4d\u7f6e\u4fe1\u606f\u4e00\u8d77\u53d1\u9001\u5230\u4e3b\u6a21\u578b\u8fdb\u884c\u5904\u7406\u3002\u6211\u4eec\u4f7f\u7528\u5404\u79cd\u4efb\u52a1\u8bc4\u4f30 SpecPrefill\uff0c\u7136\u540e\u5728\u771f\u5b9e\u7aef\u5230\u7aef\u8bbe\u7f6e\u548c\u6d88\u878d\u7814\u7a76\u4e2d\u5bf9\u6027\u80fd\u6539\u8fdb\u8fdb\u884c\u4e86\u5168\u9762\u57fa\u51c6\u6d4b\u8bd5\u3002SpecPrefill \u80fd\u591f\u4e3a Llama-3.1-405B-Instruct-FP8 \u63d0\u4f9b\u9ad8\u8fbe 7 \u500d\u7684\u6700\u5927\u7aef\u5230\u7aef QPS\uff0c\u7528\u4e8e\u5b9e\u9645\u4e0b\u6e38\u4efb\u52a1\uff0c\u5e76\u5728\u57fa\u51c6\u6d4b\u8bd5\u671f\u95f4\u5c06 TTFT \u63d0\u9ad8 7.66 \u500d\u3002", "author": "Jingyu Liu et.al.", "authors": "Jingyu Liu, Beidi Chen, Ce Zhang", "id": "2502.02789v1", "paper_url": "http://arxiv.org/abs/2502.02789v1", "repo": "null"}}