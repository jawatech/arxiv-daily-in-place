{"2405.13902": {"publish_time": "2024-05-22", "title": "LOGIN: A Large Language Model Consulted Graph Neural Network Training Framework", "paper_summary": "Recent prevailing works on graph machine learning typically follow a similar\nmethodology that involves designing advanced variants of graph neural networks\n(GNNs) to maintain the superior performance of GNNs on different graphs. In\nthis paper, we aim to streamline the GNN design process and leverage the\nadvantages of Large Language Models (LLMs) to improve the performance of GNNs\non downstream tasks. We formulate a new paradigm, coined \"LLMs-as-Consultants,\"\nwhich integrates LLMs with GNNs in an interactive manner. A framework named\nLOGIN (LLM Consulted GNN training) is instantiated, empowering the interactive\nutilization of LLMs within the GNN training process. First, we attentively\ncraft concise prompts for spotted nodes, carrying comprehensive semantic and\ntopological information, and serving as input to LLMs. Second, we refine GNNs\nby devising a complementary coping mechanism that utilizes the responses from\nLLMs, depending on their correctness. We empirically evaluate the effectiveness\nof LOGIN on node classification tasks across both homophilic and heterophilic\ngraphs. The results illustrate that even basic GNN architectures, when employed\nwithin the proposed LLMs-as-Consultants paradigm, can achieve comparable\nperformance to advanced GNNs with intricate designs. Our codes are available at\nhttps://github.com/QiaoYRan/LOGIN.", "paper_summary_zh": "\u8fd1\u671f\u7684\u4e3b\u6d41\u56fe\u673a\u5668\u5b66\u4e60\u7814\u7a76\u901a\u5e38\u9075\u5faa\u7c7b\u4f3c\u7684\u65b9\u6cd5\uff0c\u5373\u8bbe\u8ba1\u56fe\u795e\u7ecf\u7f51\u7edc (GNN) \u7684\u9ad8\u7ea7\u53d8\u4f53\uff0c\u4ee5\u7ef4\u6301 GNN \u5728\u4e0d\u540c\u56fe\u4e0a\u7684\u4f18\u5f02\u6027\u80fd\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u65e8\u5728\u7b80\u5316 GNN \u8bbe\u8ba1\u6d41\u7a0b\uff0c\u5e76\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u7684\u4f18\u52bf\u6765\u63d0\u5347 GNN \u5728\u4e0b\u6e38\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002\u6211\u4eec\u5236\u5b9a\u4e86\u4e00\u4e2a\u65b0\u7684\u8303\u4f8b\uff0c\u79f0\u4e3a\u201cLLM \u4f5c\u4e3a\u987e\u95ee\u201d\uff0c\u5b83\u4ee5\u4ea4\u4e92\u65b9\u5f0f\u5c06 LLM \u4e0e GNN \u96c6\u6210\u5728\u4e00\u8d77\u3002\u5b9e\u4f8b\u5316\u4e86\u4e00\u4e2a\u540d\u4e3a LOGIN\uff08LLM \u54a8\u8be2\u7684 GNN \u8bad\u7ec3\uff09\u7684\u6846\u67b6\uff0c\u8d4b\u80fd\u4e86 LLM \u5728 GNN \u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u4ea4\u4e92\u5f0f\u5229\u7528\u3002\u9996\u5148\uff0c\u6211\u4eec\u4e13\u6ce8\u4e8e\u4e3a\u53d1\u73b0\u7684\u8282\u70b9\u7cbe\u5fc3\u8bbe\u8ba1\u7b80\u6d01\u7684\u63d0\u793a\uff0c\u627f\u8f7d\u5168\u9762\u7684\u8bed\u4e49\u548c\u62d3\u6251\u4fe1\u606f\uff0c\u5e76\u4f5c\u4e3a LLM \u7684\u8f93\u5165\u3002\u5176\u6b21\uff0c\u6211\u4eec\u901a\u8fc7\u8bbe\u8ba1\u4e00\u79cd\u5229\u7528 LLM \u54cd\u5e94\u7684\u8865\u5145\u5e94\u5bf9\u673a\u5236\u6765\u4f18\u5316 GNN\uff0c\u8fd9\u53d6\u51b3\u4e8e\u5b83\u4eec\u7684\u6b63\u786e\u6027\u3002\u6211\u4eec\u5bf9 LOGIN \u5728\u540c\u8d28\u548c\u5f02\u8d28\u56fe\u4e0a\u7684\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u7684\u6709\u6548\u6027\u8fdb\u884c\u4e86\u5b9e\u8bc1\u8bc4\u4f30\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5373\u4f7f\u662f\u57fa\u672c\u7684 GNN \u67b6\u6784\uff0c\u5728\u6240\u63d0\u51fa\u7684 LLM \u4f5c\u4e3a\u987e\u95ee\u8303\u4f8b\u4e2d\u4f7f\u7528\u65f6\uff0c\u4e5f\u53ef\u4ee5\u5b9e\u73b0\u4e0e\u5177\u6709\u590d\u6742\u8bbe\u8ba1\u7684\u5148\u8fdb GNN \u76f8\u5ab2\u7f8e\u7684\u6027\u80fd\u3002\u6211\u4eec\u7684\u4ee3\u7801\u53ef\u5728 https://github.com/QiaoYRan/LOGIN \u83b7\u53d6\u3002", "author": "Yiran Qiao et.al.", "authors": "Yiran Qiao, Xiang Ao, Yang Liu, Jiarong Xu, Xiaoqian Sun, Qing He", "id": "2405.13902v1", "paper_url": "http://arxiv.org/abs/2405.13902v1", "repo": "null"}}