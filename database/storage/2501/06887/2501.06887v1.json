{"2501.06887": {"publish_time": "2025-01-12", "title": "MedGrad E-CLIP: Enhancing Trust and Transparency in AI-Driven Skin Lesion Diagnosis", "paper_summary": "As deep learning models gain attraction in medical data, ensuring transparent\nand trustworthy decision-making is essential. In skin cancer diagnosis, while\nadvancements in lesion detection and classification have improved accuracy, the\nblack-box nature of these methods poses challenges in understanding their\ndecision processes, leading to trust issues among physicians. This study\nleverages the CLIP (Contrastive Language-Image Pretraining) model, trained on\ndifferent skin lesion datasets, to capture meaningful relationships between\nvisual features and diagnostic criteria terms. To further enhance transparency,\nwe propose a method called MedGrad E-CLIP, which builds on gradient-based\nE-CLIP by incorporating a weighted entropy mechanism designed for complex\nmedical imaging like skin lesions. This approach highlights critical image\nregions linked to specific diagnostic descriptions. The developed integrated\npipeline not only classifies skin lesions by matching corresponding\ndescriptions but also adds an essential layer of explainability developed\nespecially for medical data. By visually explaining how different features in\nan image relates to diagnostic criteria, this approach demonstrates the\npotential of advanced vision-language models in medical image analysis,\nultimately improving transparency, robustness, and trust in AI-driven\ndiagnostic systems.", "paper_summary_zh": "\u968f\u7740\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u533b\u5b66\u6570\u636e\u4e2d\u83b7\u5f97\u5173\u6ce8\uff0c\u786e\u4fdd\u900f\u660e\u4e14\u503c\u5f97\u4fe1\u8d56\u7684\u51b3\u7b56\u81f3\u5173\u91cd\u8981\u3002\u5728\u76ae\u80a4\u764c\u8bca\u65ad\u4e2d\uff0c\u867d\u7136\u75c5\u7076\u68c0\u6d4b\u548c\u5206\u7c7b\u7684\u8fdb\u6b65\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u7684\u9ed1\u76d2\u6027\u8d28\u5bf9\u7406\u89e3\u5176\u51b3\u7b56\u8fc7\u7a0b\u6784\u6210\u4e86\u6311\u6218\uff0c\u5bfc\u81f4\u533b\u751f\u4e4b\u95f4\u7684\u4fe1\u4efb\u95ee\u9898\u3002\u672c\u7814\u7a76\u5229\u7528\u5728\u4e0d\u540c\u76ae\u80a4\u75c5\u53d8\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684 CLIP\uff08\u5bf9\u6bd4\u8bed\u8a00\u56fe\u50cf\u9884\u8bad\u7ec3\uff09\u6a21\u578b\uff0c\u4ee5\u6355\u6349\u89c6\u89c9\u7279\u5f81\u548c\u8bca\u65ad\u6807\u51c6\u672f\u8bed\u4e4b\u95f4\u7684\u6709\u610f\u4e49\u5173\u7cfb\u3002\u4e3a\u4e86\u8fdb\u4e00\u6b65\u63d0\u9ad8\u900f\u660e\u5ea6\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a MedGrad E-CLIP \u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u4e13\u4e3a\u76ae\u80a4\u75c5\u53d8\u7b49\u590d\u6742\u533b\u5b66\u5f71\u50cf\u8bbe\u8ba1\u7684\u52a0\u6743\u71b5\u673a\u5236\uff0c\u5efa\u7acb\u5728\u57fa\u4e8e\u68af\u5ea6\u7684 E-CLIP \u4e4b\u4e0a\u3002\u6b64\u65b9\u6cd5\u7a81\u51fa\u4e86\u4e0e\u7279\u5b9a\u8bca\u65ad\u63cf\u8ff0\u76f8\u5173\u8054\u7684\u5173\u952e\u56fe\u50cf\u533a\u57df\u3002\u5f00\u53d1\u7684\u96c6\u6210\u7ba1\u9053\u4e0d\u4ec5\u901a\u8fc7\u5339\u914d\u76f8\u5e94\u7684\u63cf\u8ff0\u5bf9\u76ae\u80a4\u75c5\u53d8\u8fdb\u884c\u5206\u7c7b\uff0c\u8fd8\u6dfb\u52a0\u4e86\u4e00\u5c42\u4e13\u95e8\u4e3a\u533b\u5b66\u6570\u636e\u5f00\u53d1\u7684\u57fa\u672c\u53ef\u89e3\u91ca\u6027\u3002\u901a\u8fc7\u76f4\u89c2\u5730\u89e3\u91ca\u56fe\u50cf\u4e2d\u4e0d\u540c\u7279\u5f81\u4e0e\u8bca\u65ad\u6807\u51c6\u7684\u5173\u7cfb\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5c55\u793a\u4e86\u9ad8\u7ea7\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u56fe\u50cf\u5206\u6790\u4e2d\u7684\u6f5c\u529b\uff0c\u6700\u7ec8\u63d0\u9ad8\u4e86\u900f\u660e\u5ea6\u3001\u7a33\u5065\u6027\u548c\u5bf9\u4eba\u5de5\u667a\u80fd\u9a71\u52a8\u7684\u8bca\u65ad\u7cfb\u7edf\u7684\u4fe1\u4efb\u3002", "author": "Sadia Kamal et.al.", "authors": "Sadia Kamal, Tim Oates", "id": "2501.06887v1", "paper_url": "http://arxiv.org/abs/2501.06887v1", "repo": "null"}}