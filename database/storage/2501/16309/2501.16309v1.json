{"2501.16309": {"publish_time": "2025-01-27", "title": "Evaluating The Performance of Using Large Language Models to Automate Summarization of CT Simulation Orders in Radiation Oncology", "paper_summary": "Purpose: This study aims to use a large language model (LLM) to automate the\ngeneration of summaries from the CT simulation orders and evaluate its\nperformance.\n  Materials and Methods: A total of 607 CT simulation orders for patients were\ncollected from the Aria database at our institution. A locally hosted Llama 3.1\n405B model, accessed via the Application Programming Interface (API) service,\nwas used to extract keywords from the CT simulation orders and generate\nsummaries. The downloaded CT simulation orders were categorized into seven\ngroups based on treatment modalities and disease sites. For each group, a\ncustomized instruction prompt was developed collaboratively with therapists to\nguide the Llama 3.1 405B model in generating summaries. The ground truth for\nthe corresponding summaries was manually derived by carefully reviewing each CT\nsimulation order and subsequently verified by therapists. The accuracy of the\nLLM-generated summaries was evaluated by therapists using the verified ground\ntruth as a reference.\n  Results: About 98% of the LLM-generated summaries aligned with the manually\ngenerated ground truth in terms of accuracy. Our evaluations showed an improved\nconsistency in format and enhanced readability of the LLM-generated summaries\ncompared to the corresponding therapists-generated summaries. This automated\napproach demonstrated a consistent performance across all groups, regardless of\nmodality or disease site.\n  Conclusions: This study demonstrated the high precision and consistency of\nthe Llama 3.1 405B model in extracting keywords and summarizing CT simulation\norders, suggesting that LLMs have great potential to help with this task,\nreduce the workload of therapists and improve workflow efficiency.", "paper_summary_zh": "\u76ee\u7684\uff1a\u672c\u7814\u7a76\u65e8\u5728\u4f7f\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u81ea\u52d5\u5316\u5f9e CT \u6a21\u64ec\u8a02\u55ae\u4e2d\u751f\u6210\u6458\u8981\uff0c\u4e26\u8a55\u4f30\u5176\u6548\u80fd\u3002\n\u6750\u6599\u548c\u65b9\u6cd5\uff1a\u5f9e\u6211\u5011\u6a5f\u69cb\u7684 Aria \u8cc7\u6599\u5eab\u4e2d\u6536\u96c6\u4e86 607 \u4efd\u60a3\u8005\u7684 CT \u6a21\u64ec\u8a02\u55ae\u3002\u900f\u904e\u61c9\u7528\u7a0b\u5f0f\u4ecb\u9762 (API) \u670d\u52d9\u5b58\u53d6\u7684\u672c\u5730\u8a17\u7ba1 Llama 3.1 405B \u6a21\u578b\uff0c\u7528\u65bc\u5f9e CT \u6a21\u64ec\u8a02\u55ae\u4e2d\u8403\u53d6\u95dc\u9375\u5b57\u4e26\u7522\u751f\u6458\u8981\u3002\u4e0b\u8f09\u7684 CT \u6a21\u64ec\u8a02\u55ae\u6839\u64da\u6cbb\u7642\u65b9\u5f0f\u548c\u75be\u75c5\u90e8\u4f4d\u5206\u70ba\u4e03\u7d44\u3002\u5c0d\u65bc\u6bcf\u7d44\uff0c\u8207\u6cbb\u7642\u5e2b\u5408\u4f5c\u5236\u5b9a\u81ea\u8a02\u8aaa\u660e\u63d0\u793a\uff0c\u4ee5\u5f15\u5c0e Llama 3.1 405B \u6a21\u578b\u7522\u751f\u6458\u8981\u3002\u5c0d\u61c9\u6458\u8981\u7684\u57fa\u672c\u4e8b\u5be6\u662f\u900f\u904e\u4ed4\u7d30\u6aa2\u95b1\u6bcf\u4efd CT \u6a21\u64ec\u8a02\u55ae\u624b\u52d5\u884d\u751f\uff0c\u96a8\u5f8c\u7531\u6cbb\u7642\u5e2b\u9a57\u8b49\u3002\u6cbb\u7642\u5e2b\u4f7f\u7528\u9a57\u8b49\u7684\u57fa\u672c\u4e8b\u5be6\u4f5c\u70ba\u53c3\u8003\uff0c\u8a55\u4f30 LLM \u751f\u6210\u7684\u6458\u8981\u7684\u6e96\u78ba\u6027\u3002\n\u7d50\u679c\uff1a\u7d04 98% \u7684 LLM \u751f\u6210\u7684\u6458\u8981\u5728\u6e96\u78ba\u6027\u65b9\u9762\u8207\u624b\u52d5\u751f\u6210\u7684\u5be6\u969b\u60c5\u6cc1\u4e00\u81f4\u3002\u6211\u5011\u7684\u8a55\u4f30\u986f\u793a\uff0c\u8207\u5c0d\u61c9\u7684\u6cbb\u7642\u5e2b\u751f\u6210\u7684\u6458\u8981\u76f8\u6bd4\uff0cLLM \u751f\u6210\u7684\u6458\u8981\u5728\u683c\u5f0f\u4e0a\u5177\u6709\u4e00\u81f4\u6027\uff0c\u4e14\u53ef\u8b80\u6027\u4e5f\u5f97\u5230\u6539\u5584\u3002\u9019\u7a2e\u81ea\u52d5\u5316\u65b9\u6cd5\u5728\u6240\u6709\u7d44\u5225\u4e2d\u8868\u73fe\u4e00\u81f4\uff0c\u7121\u8ad6\u6cbb\u7642\u65b9\u5f0f\u6216\u75be\u75c5\u90e8\u4f4d\u70ba\u4f55\u3002\n\u7d50\u8ad6\uff1a\u672c\u7814\u7a76\u8b49\u660e Llama 3.1 405B \u6a21\u578b\u5728\u8403\u53d6\u95dc\u9375\u5b57\u548c\u6458\u8981 CT \u6a21\u64ec\u8a02\u55ae\u65b9\u9762\u5177\u6709\u9ad8\u5ea6\u7684\u7cbe\u78ba\u5ea6\u548c\u4e00\u81f4\u6027\uff0c\u9019\u8868\u793a LLM \u5728\u5354\u52a9\u9019\u9805\u4efb\u52d9\u3001\u6e1b\u5c11\u6cbb\u7642\u5e2b\u7684\u5de5\u4f5c\u91cf\u548c\u6539\u5584\u5de5\u4f5c\u6d41\u7a0b\u6548\u7387\u65b9\u9762\u5177\u6709\u5f88\u5927\u7684\u6f5b\u529b\u3002", "author": "Meiyun Cao et.al.", "authors": "Meiyun Cao, Shaw Hu, Jason Sharp, Edward Clouser, Jason Holmes, Linda L. Lam, Xiaoning Ding, Diego Santos Toesca, Wendy S. Lindholm, Samir H. Patel, Sujay A. Vora, Peilong Wang, Wei Liu", "id": "2501.16309v1", "paper_url": "http://arxiv.org/abs/2501.16309v1", "repo": "null"}}