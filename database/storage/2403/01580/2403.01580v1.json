{"2403.01580": {"publish_time": "2024-03-03", "title": "Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures", "paper_summary": "In the current machine translation (MT) landscape, the Transformer\narchitecture stands out as the gold standard, especially for high-resource\nlanguage pairs. This research delves into its efficacy for low-resource\nlanguage pairs including both the English$\\leftrightarrow$Irish and\nEnglish$\\leftrightarrow$Marathi language pairs. Notably, the study identifies\nthe optimal hyperparameters and subword model type to significantly improve the\ntranslation quality of Transformer models for low-resource language pairs.\n  The scarcity of parallel datasets for low-resource languages can hinder MT\ndevelopment. To address this, gaHealth was developed, the first bilingual\ncorpus of health data for the Irish language. Focusing on the health domain,\nmodels developed using this in-domain dataset exhibited very significant\nimprovements in BLEU score when compared with models from the LoResMT2021\nShared Task. A subsequent human evaluation using the multidimensional quality\nmetrics error taxonomy showcased the superior performance of the Transformer\nsystem in reducing both accuracy and fluency errors compared to an RNN-based\ncounterpart.\n  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source\napplications streamlined for the development, fine-tuning, and deployment of\nneural machine translation models. These tools considerably simplify the setup\nand evaluation process, making MT more accessible to both developers and\ntranslators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes\neco-friendly natural language processing research by highlighting the\nenvironmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM\ndemonstrated advancements in translation performance for two low-resource\nlanguage pairs: English$\\leftrightarrow$Irish and\nEnglish$\\leftrightarrow$Marathi, compared to baselines from the LoResMT2021\nShared Task.", "paper_summary_zh": "", "author": "S\u00e9amus Lankford et.al.", "authors": "S\u00e9amus Lankford", "id": "2403.01580v1", "paper_url": "http://arxiv.org/abs/2403.01580v1", "repo": "null"}}