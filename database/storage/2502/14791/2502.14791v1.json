{"2502.14791": {"publish_time": "2025-02-20", "title": "Rapid Word Learning Through Meta In-Context Learning", "paper_summary": "Humans can quickly learn a new word from a few illustrative examples, and\nthen systematically and flexibly use it in novel contexts. Yet the abilities of\ncurrent language models for few-shot word learning, and methods for improving\nthese abilities, are underexplored. In this study, we introduce a novel method,\nMeta-training for IN-context learNing Of Words (Minnow). This method trains\nlanguage models to generate new examples of a word's usage given a few\nin-context examples, using a special placeholder token to represent the new\nword. This training is repeated on many new words to develop a general\nword-learning ability. We find that training models from scratch with Minnow on\nhuman-scale child-directed language enables strong few-shot word learning,\ncomparable to a large language model (LLM) pre-trained on orders of magnitude\nmore data. Furthermore, through discriminative and generative evaluations, we\ndemonstrate that finetuning pre-trained LLMs with Minnow improves their ability\nto discriminate between new words, identify syntactic categories of new words,\nand generate reasonable new usages and definitions for new words, based on one\nor a few in-context examples. These findings highlight the data efficiency of\nMinnow and its potential to improve language model performance in word learning\ntasks.", "paper_summary_zh": "\u4eba\u985e\u53ef\u4ee5\u5f9e\u5e7e\u500b\u8aaa\u660e\u6027\u7684\u7bc4\u4f8b\u4e2d\u5feb\u901f\u5b78\u7fd2\u4e00\u500b\u65b0\u5b57\u8a5e\uff0c\u7136\u5f8c\u7cfb\u7d71\u6027\u4e14\u9748\u6d3b\u5730\u5c07\u5176\u7528\u65bc\u65b0\u7684\u8108\u7d61\u4e2d\u3002\u7136\u800c\uff0c\u76ee\u524d\u8a9e\u8a00\u6a21\u578b\u5728\u5c11\u91cf\u5b57\u8a5e\u5b78\u7fd2\u4e2d\u7684\u80fd\u529b\uff0c\u4ee5\u53ca\u6539\u5584\u9019\u4e9b\u80fd\u529b\u7684\u65b9\u6cd5\uff0c\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u8a0e\u3002\u5728\u9019\u9805\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u7a2e\u65b0\u65b9\u6cd5\uff0c\u5373\u300c\u7528\u65bc\u5b57\u8a5e\u60c5\u5883\u5b78\u7fd2\u7684\u5143\u8a13\u7df4\u300d(Minnow)\u3002\u6b64\u65b9\u6cd5\u8a13\u7df4\u8a9e\u8a00\u6a21\u578b\u5728\u7d66\u5b9a\u5e7e\u500b\u60c5\u5883\u7bc4\u4f8b\u7684\u60c5\u6cc1\u4e0b\uff0c\u7522\u751f\u5b57\u8a5e\u7528\u6cd5\u7684\u7bc4\u4f8b\uff0c\u4e26\u4f7f\u7528\u7279\u6b8a\u4f54\u4f4d\u7b26\u6a19\u8a18\u4f86\u8868\u793a\u65b0\u7684\u5b57\u8a5e\u3002\u6b64\u8a13\u7df4\u6703\u5728\u8a31\u591a\u65b0\u5b57\u8a5e\u4e0a\u91cd\u8907\u9032\u884c\uff0c\u4ee5\u57f9\u990a\u4e00\u822c\u7684\u5b57\u8a5e\u5b78\u7fd2\u80fd\u529b\u3002\u6211\u5011\u767c\u73fe\uff0c\u5f9e\u982d\u958b\u59cb\u4f7f\u7528 Minnow \u5728\u4eba\u985e\u898f\u6a21\u7684\u5152\u7ae5\u5c0e\u5411\u8a9e\u8a00\u4e0a\u8a13\u7df4\u6a21\u578b\uff0c\u53ef\u4ee5\u5be6\u73fe\u5f37\u5927\u7684\u5c11\u91cf\u5b57\u8a5e\u5b78\u7fd2\u80fd\u529b\uff0c\u9019\u8207\u9810\u5148\u5728\u5927\u91cf\u8cc7\u6599\u4e0a\u8a13\u7df4\u7684\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u76f8\u7576\u3002\u6b64\u5916\uff0c\u900f\u904e\u5340\u8fa8\u6027\u548c\u751f\u6210\u6027\u8a55\u4f30\uff0c\u6211\u5011\u8b49\u660e\u4f7f\u7528 Minnow \u5fae\u8abf\u9810\u5148\u8a13\u7df4\u7684 LLM \u53ef\u4ee5\u63d0\u5347\u5176\u5340\u8fa8\u65b0\u5b57\u8a5e\u3001\u8b58\u5225\u65b0\u5b57\u8a5e\u7684\u53e5\u6cd5\u985e\u5225\uff0c\u4ee5\u53ca\u6839\u64da\u4e00\u500b\u6216\u5e7e\u500b\u60c5\u5883\u7bc4\u4f8b\u7522\u751f\u5408\u7406\u7684\u65b0\u7528\u6cd5\u548c\u5b9a\u7fa9\u7684\u80fd\u529b\u3002\u9019\u4e9b\u767c\u73fe\u7a81\u986f\u4e86 Minnow \u7684\u8cc7\u6599\u6548\u7387\uff0c\u4ee5\u53ca\u5b83\u5728\u5b57\u8a5e\u5b78\u7fd2\u4efb\u52d9\u4e2d\u63d0\u5347\u8a9e\u8a00\u6a21\u578b\u6548\u80fd\u7684\u6f5b\u529b\u3002", "author": "Wentao Wang et.al.", "authors": "Wentao Wang, Guangyuan Jiang, Tal Linzen, Brenden M. Lake", "id": "2502.14791v1", "paper_url": "http://arxiv.org/abs/2502.14791v1", "repo": "null"}}