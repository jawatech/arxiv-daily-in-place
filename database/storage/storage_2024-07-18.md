# arxiv-daily
 Automated deployment @ 2024-07-18 08:57:00 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-16**|**A Comprehensive Evaluation of Large Language Models on Temporal Event Forecasting**|He Chang et.al.|[2407.11638v1](http://arxiv.org/abs/2407.11638v1)|null|
|**2024-07-16**|**CIC-BART-SSA: Controllable Image Captioning with Structured Semantic Augmentation**|Kalliopi Basioti et.al.|[2407.11393v1](http://arxiv.org/abs/2407.11393v1)|[link](https://github.com/SamsungLabs/CIC-BART-SSA)|
|**2024-07-15**|**Think-on-Graph 2.0: Deep and Interpretable Large Language Model Reasoning with Knowledge Graph-guided Retrieval**|Shengjie Ma et.al.|[2407.10805v1](http://arxiv.org/abs/2407.10805v1)|null|
|**2024-07-15**|**Graphusion: Leveraging Large Language Models for Scientific Knowledge Graph Fusion and Construction in NLP Education**|Rui Yang et.al.|[2407.10794v1](http://arxiv.org/abs/2407.10794v1)|[link](https://github.com/irenezihuili/cgprompt)|
|**2024-07-15**|**GraphEval: A Knowledge-Graph Based LLM Hallucination Evaluation Framework**|Hannah Sansford et.al.|[2407.10793v1](http://arxiv.org/abs/2407.10793v1)|null|
|**2024-07-15**|**Scaling 3D Reasoning with LMMs to Large Robot Mission Environments Using Datagraphs**|W. J. Meijer et.al.|[2407.10743v1](http://arxiv.org/abs/2407.10743v1)|null|
|**2024-07-14**|**AutoGRAMS: Autonomous Graphical Agent Modeling Software**|Ben Krause et.al.|[2407.10049v1](http://arxiv.org/abs/2407.10049v1)|[link](https://github.com/autograms/autograms)|
|**2024-07-13**|**FarFetched: Entity-centric Reasoning and Claim Validation for the Greek Language based on Textually Represented Environments**|Dimitris Papadopoulos et.al.|[2407.09888v1](http://arxiv.org/abs/2407.09888v1)|null|
|**2024-07-12**|**GOFA: A Generative One-For-All Model for Joint Graph Language Modeling**|Lecheng Kong et.al.|[2407.09709v1](http://arxiv.org/abs/2407.09709v1)|[link](https://github.com/jiaruifeng/gofa)|
|**2024-07-12**|**Human-like Episodic Memory for Infinite Context LLMs**|Zafeirios Fountas et.al.|[2407.09450v1](http://arxiv.org/abs/2407.09450v1)|null|
|**2024-07-12**|**The $Î¼\mathcal{G}$ Language for Programming Graph Neural Networks**|Matteo Belenchia et.al.|[2407.09441v1](http://arxiv.org/abs/2407.09441v1)|null|
|**2024-07-12**|**Towards More Trustworthy and Interpretable LLMs for Code through Syntax-Grounded Explanations**|David N. Palacio et.al.|[2407.08983v1](http://arxiv.org/abs/2407.08983v1)|null|
|**2024-07-12**|**Domain-Hierarchy Adaptation via Chain of Iterative Reasoning for Few-shot Hierarchical Text Classification**|Ke Ji et.al.|[2407.08959v1](http://arxiv.org/abs/2407.08959v1)|null|
|**2024-07-11**|**Cloud Atlas: Efficient Fault Localization for Cloud Systems using Language Models and Causal Insight**|Zhiqiang Xie et.al.|[2407.08694v1](http://arxiv.org/abs/2407.08694v1)|null|
|**2024-07-11**|**Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents**|Haoyi Xiong et.al.|[2407.08516v2](http://arxiv.org/abs/2407.08516v2)|null|
|**2024-07-10**|**A Comprehensive Survey on the Security of Smart Grid: Challenges, Mitigations, and Future Research Opportunities**|Arastoo Zibaeirad et.al.|[2407.07966v1](http://arxiv.org/abs/2407.07966v1)|null|
|**2024-07-10**|**Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs**|Hao-Tien Lewis Chiang et.al.|[2407.07775v2](http://arxiv.org/abs/2407.07775v2)|null|
|**2024-07-10**|**Teaching Transformers Causal Reasoning through Axiomatic Training**|Aniket Vashishtha et.al.|[2407.07612v1](http://arxiv.org/abs/2407.07612v1)|null|
|**2024-07-10**|**GLBench: A Comprehensive Benchmark for Graph with Large Language Models**|Yuhan Li et.al.|[2407.07457v2](http://arxiv.org/abs/2407.07457v2)|[link](https://github.com/nineabyss/glbench)|
|**2024-07-09**|**Decoding Climate Disagreement: A Graph Neural Network-Based Approach to Understanding Social Media Dynamics**|Ruiran Su et.al.|[2407.07038v1](http://arxiv.org/abs/2407.07038v1)|null|
|**2024-07-09**|**Graph-Based Captioning: Enhancing Visual Descriptions by Interconnecting Region Captions**|Yu-Guan Hsieh et.al.|[2407.06723v1](http://arxiv.org/abs/2407.06723v1)|null|
|**2024-07-09**|**Combining Knowledge Graphs and Large Language Models**|Amanda Kau et.al.|[2407.06564v1](http://arxiv.org/abs/2407.06564v1)|null|
|**2024-07-08**|**MST5 -- Multilingual Question Answering over Knowledge Graphs**|Nikit Srivastava et.al.|[2407.06041v1](http://arxiv.org/abs/2407.06041v1)|[link](https://github.com/dice-group/MST5)|
|**2024-07-08**|**Enhancing Vision-Language Models with Scene Graphs for Traffic Accident Understanding**|Aaron Lohner et.al.|[2407.05910v1](http://arxiv.org/abs/2407.05910v1)|null|
|**2024-07-08**|**Affordances-Oriented Planning using Foundation Models for Continuous Vision-Language Navigation**|Jiaqi Chen et.al.|[2407.05890v1](http://arxiv.org/abs/2407.05890v1)|null|
|**2024-07-08**|**KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions**|Yanxu Zhu et.al.|[2407.05868v1](http://arxiv.org/abs/2407.05868v1)|[link](https://github.com/yanxuzhu/kg-fpq)|
|**2024-07-07**|**Language Models Encode Collaborative Signals in Recommendation**|Leheng Sheng et.al.|[2407.05441v1](http://arxiv.org/abs/2407.05441v1)|[link](https://github.com/lehengthu/alpharec)|
|**2024-07-07**|**LTLBench: Towards Benchmarks for Evaluating Temporal Logic Reasoning in Large Language Models**|Weizhi Tang et.al.|[2407.05434v1](http://arxiv.org/abs/2407.05434v1)|[link](https://github.com/rutatang/ltlbench)|
|**2024-07-05**|**Leveraging Graph Structures to Detect Hallucinations in Large Language Models**|Noa Nonkes et.al.|[2407.04485v1](http://arxiv.org/abs/2407.04485v1)|[link](https://github.com/noanonkes/Hallucination-Detection-in-LLMs)|
|**2024-07-05**|**AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents**|Petr Anokhin et.al.|[2407.04363v1](http://arxiv.org/abs/2407.04363v1)|[link](https://github.com/airi-institute/arigraph)|
|**2024-07-04**|**Semantic Graphs for Syntactic Simplification: A Revisit from the Age of LLM**|Peiran Yao et.al.|[2407.04067v1](http://arxiv.org/abs/2407.04067v1)|[link](https://github.com/U-Alberta/AMRS3)|
|**2024-07-04**|**Functional Faithfulness in the Wild: Circuit Discovery with Differentiable Computation Graph Pruning**|Lei Yu et.al.|[2407.03779v1](http://arxiv.org/abs/2407.03779v1)|null|
|**2024-07-03**|**BACON: Supercharge Your VLM with Bag-of-Concept Graph to Mitigate Hallucinations**|Zhantao Yang et.al.|[2407.03314v1](http://arxiv.org/abs/2407.03314v1)|null|
|**2024-07-03**|**GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models**|Zike Yuan et.al.|[2407.02936v1](http://arxiv.org/abs/2407.02936v1)|[link](https://github.com/zikeyuan/gracore)|
|**2024-07-03**|**Croppable Knowledge Graph Embedding**|Yushan Zhu et.al.|[2407.02779v1](http://arxiv.org/abs/2407.02779v1)|null|
|**2024-07-02**|**Reasoning in Large Language Models: A Geometric Perspective**|Romain Cosentino et.al.|[2407.02678v1](http://arxiv.org/abs/2407.02678v1)|null|
|**2024-07-02**|**Ensuring Responsible Sourcing of Large Language Model Training Data Through Knowledge Graph Comparison**|Devam Mondal et.al.|[2407.02659v1](http://arxiv.org/abs/2407.02659v1)|null|
|**2024-07-02**|**Multi-Peptide: Multimodality Leveraged Language-Graph Learning of Peptide Properties**|Srivathsan Badrinarayanan et.al.|[2407.03380v1](http://arxiv.org/abs/2407.03380v1)|[link](https://github.com/srivathsanb14/multipeptide)|
|**2024-07-02**|**Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification**|Pritish Sahu et.al.|[2407.02352v1](http://arxiv.org/abs/2407.02352v1)|null|
|**2024-07-02**|**Is Your Large Language Model Knowledgeable or a Choices-Only Cheater?**|Nishant Balepur et.al.|[2407.01992v1](http://arxiv.org/abs/2407.01992v1)|null|
|**2024-07-01**|**CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents**|Tianqi Xu et.al.|[2407.01511v1](http://arxiv.org/abs/2407.01511v1)|[link](https://github.com/camel-ai/crab)|
|**2024-07-01**|**Dynamic Few-Shot Learning for Knowledge Graph Question Answering**|Jacopo D'Abramo et.al.|[2407.01409v1](http://arxiv.org/abs/2407.01409v1)|null|
|**2024-07-01**|**Adapting Multilingual LLMs to Low-Resource Languages with Knowledge Graphs via Adapters**|Daniil Gurgurov et.al.|[2407.01406v1](http://arxiv.org/abs/2407.01406v1)|[link](https://github.com/d-gurgurov/Injecting-Commonsense-Knowledge-into-LLMs)|
|**2024-07-01**|**SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model**|Lingyue Fu et.al.|[2407.01245v1](http://arxiv.org/abs/2407.01245v1)|null|
|**2024-07-01**|**Revisiting Random Walks for Learning on Graphs**|Jinwoo Kim et.al.|[2407.01214v1](http://arxiv.org/abs/2407.01214v1)|[link](https://github.com/jw9730/random-walk)|
|**2024-07-01**|**LLM Uncertainty Quantification through Directional Entailment Graph and Claim Level Response Augmentation**|Longchao Da et.al.|[2407.00994v2](http://arxiv.org/abs/2407.00994v2)|null|
|**2024-06-30**|**Actionable Cyber Threat Intelligence using Knowledge Graphs and Large Language Models**|Romy Fieblinger et.al.|[2407.02528v1](http://arxiv.org/abs/2407.02528v1)|null|
|**2024-06-30**|**Chain-of-Knowledge: Integrating Knowledge Reasoning into Large Language Models by Learning from Knowledge Graphs**|Yifei Zhang et.al.|[2407.00653v1](http://arxiv.org/abs/2407.00653v1)|null|
|**2024-06-29**|**BioKGBench: A Knowledge Graph Checking Benchmark of AI Agent for Biomedical Science**|Xinna Lin et.al.|[2407.00466v1](http://arxiv.org/abs/2407.00466v1)|[link](https://github.com/westlake-autolab/biokgbench.github.io)|
|**2024-06-29**|**GraphArena: Benchmarking Large Language Models on Graph Computational Problems**|Jianheng Tang et.al.|[2407.00379v1](http://arxiv.org/abs/2407.00379v1)|[link](https://github.com/squareroot3/grapharena)|
|**2024-06-29**|**Teola: Towards End-to-End Optimization of LLM-based Applications**|Xin Tan et.al.|[2407.00326v1](http://arxiv.org/abs/2407.00326v1)|null|
|**2024-06-28**|**Into the Unknown: Generating Geospatial Descriptions for New Environments**|Tzuf Paz-Argaman et.al.|[2406.19967v1](http://arxiv.org/abs/2406.19967v1)|null|
|**2024-06-27**|**Investigating How Large Language Models Leverage Internal Knowledge to Perform Complex Reasoning**|Miyoung Ko et.al.|[2406.19502v1](http://arxiv.org/abs/2406.19502v1)|[link](https://github.com/kaistai/knowledge-reasoning)|
|**2024-06-27**|**Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment**|Hao Fei et.al.|[2406.19255v1](http://arxiv.org/abs/2406.19255v1)|null|
|**2024-06-27**|**TrustUQA: A Trustful Framework for Unified Structured Data Question Answering**|Wen Zhang et.al.|[2406.18916v1](http://arxiv.org/abs/2406.18916v1)|null|
|**2024-06-26**|**Fast Optimizer Benchmark**|Simon Blauth et.al.|[2406.18701v1](http://arxiv.org/abs/2406.18701v1)|[link](https://github.com/automl/fob)|
|**2024-06-26**|**Cascading Large Language Models for Salient Event Graph Generation**|Xingwei Tan et.al.|[2406.18449v1](http://arxiv.org/abs/2406.18449v1)|[link](https://github.com/xingwei-warwick/callmsae)|
|**2024-06-26**|**Sanskrit Knowledge-based Systems: Annotation and Computational Tools**|Hrishikesh Terdalkar et.al.|[2406.18276v1](http://arxiv.org/abs/2406.18276v1)|null|
|**2024-06-26**|**Multilingual Knowledge Graph Completion from Pretrained Language Models with Knowledge Constraints**|Ran Song et.al.|[2406.18085v1](http://arxiv.org/abs/2406.18085v1)|[link](https://github.com/Maxpa1n/gcplm-kgc)|
|**2024-06-26**|**AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning**|Yifan Yang et.al.|[2406.18060v1](http://arxiv.org/abs/2406.18060v1)|[link](https://github.com/yifanycc/adazeta)|
|**2024-06-25**|**DARG: Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph**|Zhehao Zhang et.al.|[2406.17271v1](http://arxiv.org/abs/2406.17271v1)|[link](https://github.com/salt-nlp/darg)|
|**2024-06-25**|**CogMG: Collaborative Augmentation Between Large Language Model and Knowledge Graph**|Tong Zhou et.al.|[2406.17231v1](http://arxiv.org/abs/2406.17231v1)|[link](https://github.com/tongzhou21/CogMG)|
|**2024-06-24**|**Link Prediction with Untrained Message Passing Layers**|Lisi Qarkaxhija et.al.|[2406.16687v1](http://arxiv.org/abs/2406.16687v1)|null|
|**2024-06-24**|**CLEAR: Can Language Models Really Understand Causal Graphs?**|Sirui Chen et.al.|[2406.16605v1](http://arxiv.org/abs/2406.16605v1)|[link](https://github.com/opencausalab/clear)|
|**2024-06-24**|**KEHRL: Learning Knowledge-Enhanced Language Representations with Hierarchical Reinforcement Learning**|Dongyang Li et.al.|[2406.16374v1](http://arxiv.org/abs/2406.16374v1)|[link](https://github.com/MatNLP/KEHRL)|
|**2024-06-24**|**Prompt-Consistency Image Generation (PCIG): A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models**|Yichen Sun et.al.|[2406.16333v1](http://arxiv.org/abs/2406.16333v1)|null|
|**2024-06-24**|**Graph-Augmented LLMs for Personalized Health Insights: A Case Study in Sleep Analysis**|Ajan Subramanian et.al.|[2406.16252v2](http://arxiv.org/abs/2406.16252v2)|null|
|**2024-06-23**|**GraphEval2000: Benchmarking and Improving Large Language Models on Graph Datasets**|Qiming Wu et.al.|[2406.16176v1](http://arxiv.org/abs/2406.16176v1)|null|
|**2024-06-23**|**Can LLM Graph Reasoning Generalize beyond Pattern Memorization?**|Yizhuo Zhang et.al.|[2406.15992v1](http://arxiv.org/abs/2406.15992v1)|null|
|**2024-06-22**|**LLM-Powered Explanations: Unraveling Recommendations Through Subgraph Reasoning**|Guangsi Shi et.al.|[2406.15859v2](http://arxiv.org/abs/2406.15859v2)|null|
|**2024-06-22**|**Large Language Models for Link Stealing Attacks Against Graph Neural Networks**|Faqian Guan et.al.|[2406.16963v1](http://arxiv.org/abs/2406.16963v1)|null|
|**2024-06-21**|**Inferring Pluggable Types with Machine Learning**|Kazi Amanul Islam Siddiqui et.al.|[2406.15676v1](http://arxiv.org/abs/2406.15676v1)|null|
|**2024-06-21**|**NLP-KG: A System for Exploratory Search of Scientific Literature in Natural Language Processing**|Tim Schopf et.al.|[2406.15294v2](http://arxiv.org/abs/2406.15294v2)|[link](https://github.com/nlp-knowledge-graph/nlp-kg-webapp)|
|**2024-06-21**|**Unsupervised Extraction of Dialogue Policies from Conversations**|Makesh Narsimhan Sreedhar et.al.|[2406.15214v1](http://arxiv.org/abs/2406.15214v1)|null|
|**2024-06-21**|**Uni-Mol2: Exploring Molecular Pretraining Model at Scale**|Xiaohong Ji et.al.|[2406.14969v2](http://arxiv.org/abs/2406.14969v2)|null|
|**2024-06-20**|**Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks**|Sefika Efeoglu et.al.|[2406.14745v2](http://arxiv.org/abs/2406.14745v2)|null|
|**2024-06-20**|**Do LLMs Have Distinct and Consistent Personality? TRAIT: Personality Testset designed for LLMs with Psychometrics**|Seungbeen Lee et.al.|[2406.14703v1](http://arxiv.org/abs/2406.14703v1)|null|
|**2024-06-20**|**TAGLAS: An atlas of text-attributed graph datasets in the era of large graph and language models**|Jiarui Feng et.al.|[2406.14683v1](http://arxiv.org/abs/2406.14683v1)|[link](https://github.com/jiaruifeng/taglas)|
|**2024-06-20**|**HYPERmotion: Learning Hybrid Behavior Planning for Autonomous Loco-manipulation**|Jin Wang et.al.|[2406.14655v1](http://arxiv.org/abs/2406.14655v1)|null|
|**2024-06-20**|**GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models**|Shilong Li et.al.|[2406.14550v1](http://arxiv.org/abs/2406.14550v1)|null|
|**2024-06-20**|**medIKAL: Integrating Knowledge Graphs as Assistants of LLMs for Enhanced Clinical Diagnosis on EMRs**|Mingyi Jia et.al.|[2406.14326v1](http://arxiv.org/abs/2406.14326v1)|null|
|**2024-06-20**|**Learning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs**|Junjie Wang et.al.|[2406.14282v1](http://arxiv.org/abs/2406.14282v1)|[link](https://github.com/zjukg/lpkg)|
|**2024-06-20**|**ReaLHF: Optimized RLHF Training for Large Language Models through Parameter Reallocation**|Zhiyu Mei et.al.|[2406.14088v1](http://arxiv.org/abs/2406.14088v1)|[link](https://github.com/openpsi-project/realhf)|
|**2024-06-20**|**HIGHT: Hierarchical Graph Tokenization for Graph-Language Alignment**|Yongqiang Chen et.al.|[2406.14021v1](http://arxiv.org/abs/2406.14021v1)|null|
|**2024-06-19**|**A Pure Transformer Pretraining Framework on Text-attributed Graphs**|Yu Song et.al.|[2406.13873v1](http://arxiv.org/abs/2406.13873v1)|[link](https://github.com/songyyyy/gspt)|
|**2024-06-19**|**Knowledge Graph-Enhanced Large Language Models via Path Selection**|Haochen Liu et.al.|[2406.13862v1](http://arxiv.org/abs/2406.13862v1)|[link](https://github.com/haochenliu2000/kelp)|
|**2024-06-19**|**Few-shot Knowledge Graph Relational Reasoning via Subgraph Adaptation**|Haochen Liu et.al.|[2406.15507v1](http://arxiv.org/abs/2406.15507v1)|[link](https://github.com/HaochenLiu2000/SAFER)|
|**2024-06-19**|**Dr.E Bridges Graphs with Large Language Models through Words**|Zipeng Liu et.al.|[2406.15504v1](http://arxiv.org/abs/2406.15504v1)|null|
|**2024-06-19**|**Enhancing Distractor Generation for Multiple-Choice Questions with Retrieval Augmented Pretraining and Knowledge Graph Integration**|Han-Cheng Yu et.al.|[2406.13578v1](http://arxiv.org/abs/2406.13578v1)|null|
|**2024-06-19**|**LangTopo: Aligning Language Descriptions of Graphs with Tokenized Topological Modeling**|Zhong Guan et.al.|[2406.13250v1](http://arxiv.org/abs/2406.13250v1)|null|
|**2024-06-19**|**Enhancing Collaborative Semantics of Language Model-Driven Recommendations via Graph-Aware Learning**|Zhong Guan et.al.|[2406.13235v1](http://arxiv.org/abs/2406.13235v1)|null|
|**2024-06-19**|**Bridging Law and Data: Augmenting Reasoning via a Semi-Structured Dataset with IRAC methodology**|Xiaoxi Kang et.al.|[2406.13217v1](http://arxiv.org/abs/2406.13217v1)|null|
|**2024-06-19**|**PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes**|He Cao et.al.|[2406.13193v1](http://arxiv.org/abs/2406.13193v1)|[link](https://github.com/idea-xl/presto)|
|**2024-06-19**|**QRMeM: Unleash the Length Limitation through Question then Reflection Memory Mechanism**|Bo Wang et.al.|[2406.13167v1](http://arxiv.org/abs/2406.13167v1)|null|
|**2024-06-18**|**Bridging Local Details and Global Context in Text-Attributed Graphs**|Yaoke Wang et.al.|[2406.12608v1](http://arxiv.org/abs/2406.12608v1)|null|
|**2024-06-18**|**MolecularGPT: Open Large Language Model (LLM) for Few-Shot Molecular Property Prediction**|Yuyan Liu et.al.|[2406.12950v1](http://arxiv.org/abs/2406.12950v1)|[link](https://github.com/nyushcs/moleculargpt)|
|**2024-06-18**|**LightPAL: Lightweight Passage Retrieval for Open Domain Multi-Document Summarization**|Masafumi Enomoto et.al.|[2406.12494v1](http://arxiv.org/abs/2406.12494v1)|null|
|**2024-06-18**|**Interpretable Catastrophic Forgetting of Large Language Model Fine-tuning via Instruction Vector**|Gangwei Jiang et.al.|[2406.12227v2](http://arxiv.org/abs/2406.12227v2)|null|
|**2024-06-17**|**DTGB: A Comprehensive Benchmark for Dynamic Text-Attributed Graphs**|Jiasheng Zhang et.al.|[2406.12072v2](http://arxiv.org/abs/2406.12072v2)|[link](https://github.com/zjs123/DTGB)|
|**2024-06-17**|**UniGLM: Training One Unified Language Model for Text-Attributed Graphs**|Yi Fang et.al.|[2406.12052v1](http://arxiv.org/abs/2406.12052v1)|[link](https://github.com/nyushcs/uniglm)|

#### Abstracts
##### **A Comprehensive Evaluation of Large Language Models on Temporal Event Forecasting**
2407.11638v1 by He Chang, Chenchen Ye, Zhulin Tao, Jie Wu, Zhengmao Yang, Yunshan Ma, Xianglin Huang, Tat-Seng Chua

Recently, Large Language Models (LLMs) have demonstrated great potential in
various data mining tasks, such as knowledge question answering, mathematical
reasoning, and commonsense reasoning. However, the reasoning capability of LLMs
on temporal event forecasting has been under-explored. To systematically
investigate their abilities in temporal event forecasting, we conduct a
comprehensive evaluation of LLM-based methods for temporal event forecasting.
Due to the lack of a high-quality dataset that involves both graph and textual
data, we first construct a benchmark dataset, named MidEast-TE-mini. Based on
this dataset, we design a series of baseline methods, characterized by various
input formats and retrieval augmented generation(RAG) modules. From extensive
experiments, we find that directly integrating raw texts into the input of LLMs
does not enhance zero-shot extrapolation performance. In contrast,
incorporating raw texts in specific complex events and fine-tuning LLMs
significantly improves performance. Moreover, enhanced with retrieval modules,
LLM can effectively capture temporal relational patterns hidden in historical
events. Meanwhile, issues such as popularity bias and the long-tail problem
still persist in LLMs, particularly in the RAG-based method. These findings not
only deepen our understanding of LLM-based event forecasting methods but also
highlight several promising research directions.We consider that this
comprehensive evaluation, along with the identified research opportunities,
will significantly contribute to future research on temporal event forecasting
through LLMs.

æè¦ï¼è¿æï¼å¤§åè¯­è¨æ¨¡å (LLM) å¨åç§èµææ¢åä»»å¡ä¸­å±ç°åºæå¤§çæ½åï¼ä¾å¦ç¥è¯é®ç­ãæ°å­¦æ¨çåå¸¸è¯æ¨çãç¶èï¼LLM å¨æ¶é´äºä»¶é¢æµæ¹é¢çæ¨çè½åå°æªè¢«ååæ¢ç´¢ãä¸ºäºç³»ç»æ§å°è°æ¥å¶å¨æ¶é´äºä»¶é¢æµæ¹é¢çè½åï¼æä»¬å¯¹åºäº LLM çæ¶é´äºä»¶é¢æµæ¹æ³è¿è¡äºå¨é¢çè¯ä¼°ãç±äºç¼ºä¹åæ¶åå«å¾è¡¨åææ¬èµæçé«åè´¨æ°æ®éï¼æä»¬é¦åæå»ºäºä¸ä¸ªåä¸º MidEast-TE-mini çåºåæ°æ®éãåºäºæ­¤æ°æ®éï¼æä»¬è®¾è®¡äºä¸ç³»ååºçº¿æ¹æ³ï¼å¶ç¹ç¹æ¯åç§è¾å¥æ ¼å¼åæ£ç´¢å¢å¼ºçæ (RAG) æ¨¡åãä»å¹¿æ³çå®éªä¸­ï¼æä»¬åç°ç´æ¥å°åå§ææ¬æ´åå° LLM çè¾å¥ä¸­å¹¶ä¸ä¼å¢å¼ºé¶æ¬¡å­¦ä¹ å¤æ¨æ§è½ãç¸æ¯ä¹ä¸ï¼å¨ç¹å®å¤æäºä»¶ä¸­çº³å¥åå§ææ¬å¹¶å¾®è° LLM ä¼æ¾èæé«æ§è½ãæ­¤å¤ï¼éè¿æ£ç´¢æ¨¡åçå¢å¼ºï¼LLM å¯ä»¥ææå°ææéèå¨åå²äºä»¶ä¸­çæ¶é´å³ç³»æ¨¡å¼ãåæ¶ï¼è¯¸å¦æµè¡åº¦åå·®åé¿å°¾é®é¢ç­é®é¢ä»ç¶å­å¨äº LLM ä¸­ï¼å°¤å¶æ¯å¨åºäº RAG çæ¹æ³ä¸­ãè¿äºåç°ä¸ä»å æ·±äºæä»¬å¯¹åºäº LLM çäºä»¶é¢æµæ¹æ³ççè§£ï¼è¿çªåºäºå ä¸ªæåæ¯çç ç©¶æ¹åãæä»¬è®¤ä¸ºï¼è¿é¡¹å¨é¢çè¯ä¼°ï¼è¿åå·²ç¡®å®çç ç©¶æºä¼ï¼å°æå¤§å°ä¿è¿éè¿ LLM è¿è¡æ¶é´äºä»¶é¢æµçæªæ¥ç ç©¶ã

##### **CIC-BART-SSA: Controllable Image Captioning with Structured Semantic Augmentation**
2407.11393v1 by Kalliopi Basioti, Mohamed A. Abdelsalam, Federico Fancellu, Vladimir Pavlovic, Afsaneh Fazly

Controllable Image Captioning (CIC) aims at generating natural language
descriptions for an image, conditioned on information provided by end users,
e.g., regions, entities or events of interest. However, available
image--language datasets mainly contain captions that describe the entirety of
an image, making them ineffective for training CIC models that can potentially
attend to any subset of regions or relationships. To tackle this challenge, we
propose a novel, fully automatic method to sample additional focused and
visually grounded captions using a unified structured semantic representation
built on top of the existing set of captions associated with an image. We
leverage Abstract Meaning Representation (AMR), a cross-lingual graph-based
semantic formalism, to encode all possible spatio-semantic relations between
entities, beyond the typical spatial-relations-only focus of current methods.
We use this Structured Semantic Augmentation (SSA) framework to augment
existing image--caption datasets with the grounded controlled captions,
increasing their spatial and semantic diversity and focal coverage. We then
develop a new model, CIC-BART-SSA, specifically tailored for the CIC task, that
sources its control signals from SSA-diversified datasets. We empirically show
that, compared to SOTA CIC models, CIC-BART-SSA generates captions that are
superior in diversity and text quality, are competitive in controllability,
and, importantly, minimize the gap between broad and highly focused controlled
captioning performance by efficiently generalizing to the challenging highly
focused scenarios. Code is available at
https://github.com/SamsungLabs/CIC-BART-SSA.

æè¦ï¼å¯æ§å¾åå­å¹ï¼CICï¼æ¨å¨ä¸ºå¾åçæèªç¶è¯­è¨æè¿°ï¼æ¡ä»¶æ¯æ ¹æ®æç»ç¨æ·æä¾çä¿¡æ¯ï¼ä¾å¦æå´è¶£çåºåãå®ä½æäºä»¶ãç¶èï¼å¯ç¨çå¾åè¯­è¨æ°æ®éä¸»è¦åå«æè¿°å¾åæ´ä½çå­å¹ï¼è¿ä½¿å¾å®ä»¬æ æ³ææè®­ç» CIC æ¨¡åï¼è CIC æ¨¡åæå¯è½å³æ³¨ä»»ä½åºåæå³ç³»å­éãä¸ºäºåºå¯¹è¿ä¸ææï¼æä»¬æåºäºä¸ç§æ°é¢çãå¨èªå¨çæ¹æ³æ¥ä½¿ç¨åºäºç°æä¸å¾åå³èçå­å¹éæå»ºçç»ä¸ç»æåè¯­ä¹è¡¨ç¤ºæ¥éæ ·éå çãéä¸­çåè§è§æ¥å°çå­å¹ãæä»¬å©ç¨è·¨è¯­è¨å¾å½¢å¼è¯­ä¹å½¢å¼ä¸»ä¹ââæ½è±¡æä¹è¡¨ç¤ºï¼AMRï¼æ¥å¯¹å®ä½ä¹é´çææå¯è½çæ¶ç©ºè¯­ä¹å³ç³»è¿è¡ç¼ç ï¼èä¸ä»ä»æ¯å½åæ¹æ³éå¸¸åªå³æ³¨çç©ºé´å³ç³»ãæä»¬ä½¿ç¨è¿ç§ç»æåè¯­ä¹å¢å¼ºï¼SSAï¼æ¡æ¶æ¥ä½¿ç¨æ¥å°æ§å¶å­å¹å¢å¼ºç°æçå¾åå­å¹æ°æ®éï¼ä»èå¢å å¶ç©ºé´åè¯­ä¹å¤æ ·æ§ä»¥åç¦ç¹è¦çèå´ãç¶åï¼æä»¬å¼åäºä¸ä¸ªæ°æ¨¡å CIC-BART-SSAï¼è¯¥æ¨¡åä¸é¨éå¯¹ CIC ä»»å¡å®å¶ï¼å®ä» SSA å¤ååæ°æ®éè·åå¶æ§å¶ä¿¡å·ãæä»¬éè¿å®éªè¯æï¼ä¸ SOTA CIC æ¨¡åç¸æ¯ï¼CIC-BART-SSA çæçå­å¹å¨å¤æ ·æ§åææ¬è´¨éæ¹é¢æ´èä¸ç­¹ï¼å¨å¯æ§æ§æ¹é¢å·æç«äºåï¼èä¸éè¦çæ¯ï¼å®æå¤§ç¨åº¦å°ç¼©å°äºå¹¿æ³åé«åº¦éä¸­çåæ§å­å¹æ§è½ä¹é´çå·®è·ï¼ä»èææå°æ¨å¹¿å°æå·æææ§çé«åº¦éä¸­çåºæ¯ãä»£ç å¯å¨ https://github.com/SamsungLabs/CIC-BART-SSA è·å¾ã

##### **Think-on-Graph 2.0: Deep and Interpretable Large Language Model Reasoning with Knowledge Graph-guided Retrieval**
2407.10805v1 by Shengjie Ma, Chengjin Xu, Xuhui Jiang, Muzhi Li, Huaren Qu, Jian Guo

Retrieval-augmented generation (RAG) has significantly advanced large
language models (LLMs) by enabling dynamic information retrieval to mitigate
knowledge gaps and hallucinations in generated content. However, these systems
often falter with complex reasoning and consistency across diverse queries. In
this work, we present Think-on-Graph 2.0, an enhanced RAG framework that aligns
questions with the knowledge graph and uses it as a navigational tool, which
deepens and refines the RAG paradigm for information collection and
integration. The KG-guided navigation fosters deep and long-range associations
to uphold logical consistency and optimize the scope of retrieval for precision
and interoperability. In conjunction, factual consistency can be better ensured
through semantic similarity guided by precise directives. ToG${2.0}$ not only
improves the accuracy and reliability of LLMs' responses but also demonstrates
the potential of hybrid structured knowledge systems to significantly advance
LLM reasoning, aligning it closer to human-like performance. We conducted
extensive experiments on four public datasets to demonstrate the advantages of
our method compared to the baseline.

æè¦ï¼æª¢ç´¢å¢å¼·çæï¼RAGï¼ééåç¨åæè³è¨æª¢ç´¢ä¾æ¸è¼çæå§å®¹ä¸­çç¥è­å·®è·åå¹»è¦ºï¼å¤§å¹æåå¤§åèªè¨æ¨¡åï¼LLMï¼ãç¶èï¼éäºç³»çµ±å¨è¤éæ¨çåè·¨ä¸åæ¥è©¢çä¸è´æ§æ¹é¢å¸¸å¸¸è¡¨ç¾ä¸ä½³ãå¨éé å·¥ä½ä¸­ï¼æåæåºäº Think-on-Graph 2.0ï¼ä¸åå¢å¼·ç RAG æ¡æ¶ï¼å®å°åé¡èç¥è­åè­å°é½ï¼ä¸¦å°å¶ç¨ä½å°èªå·¥å·ï¼éå æ·±ä¸¦æ¹é²äº RAG å¸ç¯ï¼ç¨æ¼è³è¨æ¶éåæ´åãåç¥è­åè­å¼å°çå°èªä¿é²äºæ·±å±¤ä¸é·ç¨çéè¯ï¼ä»¥ç¶­æéè¼¯ä¸è´æ§ä¸¦æä½³åæª¢ç´¢ç¯åï¼ä»¥æé«ç²¾ç¢ºåº¦åäºæä½æ§ãåæï¼äºå¯¦ä¸è´æ§å¯ä»¥ééç±ç²¾ç¢ºæç¤ºå¼å°çèªæç¸ä¼¼æ§ç²å¾æ´å¥½çç¢ºä¿ãToG${2.0}$ ä¸åæåäº LLM åæçæºç¢ºæ§åå¯é æ§ï¼ä¹å±ç¤ºäºæ··åçµæ§åç¥è­ç³»çµ±çæ½åï¼å¯ä»¥å¤§å¹æå LLM æ¨çï¼ä½¿å¶æ´æ¥è¿äººé¡è¬çè¡¨ç¾ãæåå¨ååå¬éè³æéä¸é²è¡äºå»£æ³çå¯¦é©ï¼ä»¥å±ç¤ºæåçæ¹æ³ç¸è¼æ¼åºç·çåªå¢ã

##### **Graphusion: Leveraging Large Language Models for Scientific Knowledge Graph Fusion and Construction in NLP Education**
2407.10794v1 by Rui Yang, Boming Yang, Sixun Ouyang, Tianwei She, Aosong Feng, Yuang Jiang, Freddy Lecue, Jinghui Lu, Irene Li

Knowledge graphs (KGs) are crucial in the field of artificial intelligence
and are widely applied in downstream tasks, such as enhancing Question
Answering (QA) systems. The construction of KGs typically requires significant
effort from domain experts. Recently, Large Language Models (LLMs) have been
used for knowledge graph construction (KGC), however, most existing approaches
focus on a local perspective, extracting knowledge triplets from individual
sentences or documents. In this work, we introduce Graphusion, a zero-shot KGC
framework from free text. The core fusion module provides a global view of
triplets, incorporating entity merging, conflict resolution, and novel triplet
discovery. We showcase how Graphusion could be applied to the natural language
processing (NLP) domain and validate it in the educational scenario.
Specifically, we introduce TutorQA, a new expert-verified benchmark for graph
reasoning and QA, comprising six tasks and a total of 1,200 QA pairs. Our
evaluation demonstrates that Graphusion surpasses supervised baselines by up to
10% in accuracy on link prediction. Additionally, it achieves average scores of
2.92 and 2.37 out of 3 in human evaluations for concept entity extraction and
relation recognition, respectively.

æè¦ï¼<paragraph>ç¥è­åè­ (KG) å¨äººå·¥æºæ§é åè³ééè¦ï¼ä¸¦å»£æ³æç¨æ¼ä¸æ¸¸ä»»åï¼ä¾å¦å¢å¼·åç­ (QA) ç³»çµ±ãç¥è­åè­çå»ºæ§éå¸¸éè¦é åå°å®¶çå¤§éå·¥ä½ãæè¿ï¼å¤§åèªè¨æ¨¡å (LLM) å·²è¢«ç¨æ¼ç¥è­åè­å»ºæ§ (KGC)ï¼ç¶èï¼ç¾ææ¹æ³å¤§å¤éæ³¨å±é¨è§é»ï¼å¾åå¥å¥å­ææä»¶ä¸­æåç¥è­ä¸åçµãå¨éé å·¥ä½ä¸­ï¼æåä»ç´¹äº Graphusionï¼ä¸åå¾èªç±ææ¬ä¸­é²è¡é¶æ¬¡å­¸ç¿ç KGC æ¡æ¶ãæ ¸å¿èåæ¨¡çµæä¾ä¸åçµçå¨å±è§é»ï¼åå«å¯¦é«åä½µãè¡çªè§£æ±ºåæ°ä¸åçµç¼ç¾ãæåå±ç¤ºäºå¦ä½å° Graphusion æç¨æ¼èªç¶èªè¨èç (NLP) é åï¼ä¸¦å¨æè²å ´æ¯ä¸­é©è­å®ãå·é«ä¾èªªï¼æåä»ç´¹äº TutorQAï¼ä¸åæ°çç±å°å®¶é©è­çåè­æ¨çååç­åºæºï¼åå«å­é ä»»ååç¸½è¨ 1,200 ååç­å°ãæåçè©ä¼°è¡¨æï¼Graphusion å¨é£çµé æ¸¬çæºç¢ºåº¦ä¸æ¯ç£ç£å¼åºæºé«åº 10%ãæ­¤å¤ï¼å¨æ¦å¿µå¯¦é«æååéä¿è­å¥çäººé¡è©ä¼°ä¸­ï¼å®åå¥ç²å¾äº 3 åä¸­ç 2.92 åå 2.37 åã</paragraph>

##### **GraphEval: A Knowledge-Graph Based LLM Hallucination Evaluation Framework**
2407.10793v1 by Hannah Sansford, Nicholas Richardson, Hermina Petric Maretic, Juba Nait Saada

Methods to evaluate Large Language Model (LLM) responses and detect
inconsistencies, also known as hallucinations, with respect to the provided
knowledge, are becoming increasingly important for LLM applications. Current
metrics fall short in their ability to provide explainable decisions,
systematically check all pieces of information in the response, and are often
too computationally expensive to be used in practice. We present GraphEval: a
hallucination evaluation framework based on representing information in
Knowledge Graph (KG) structures. Our method identifies the specific triples in
the KG that are prone to hallucinations and hence provides more insight into
where in the response a hallucination has occurred, if at all, than previous
methods. Furthermore, using our approach in conjunction with state-of-the-art
natural language inference (NLI) models leads to an improvement in balanced
accuracy on various hallucination benchmarks, compared to using the raw NLI
models. Lastly, we explore the use of GraphEval for hallucination correction by
leveraging the structure of the KG, a method we name GraphCorrect, and
demonstrate that the majority of hallucinations can indeed be rectified.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) åæè©ä¼°æ¹æ³åä¸ä¸è´æ§åµæ¸¬ï¼åç¨±çºå¹»è¦ºï¼ï¼ç¸å°æ¼ææä¾çç¥è­ï¼å°æ¼ LLM æç¨æ­£è®å¾è¶ä¾è¶éè¦ãç®åçææ¨ç¡æ³æä¾å¯è§£éçæ±ºç­ãç³»çµ±æ§å°æª¢æ¥åæä¸­çææè³è¨ï¼èä¸å¨å¯¦åä¸ä½¿ç¨æï¼éå¸¸éæ¼èè²»éç®è³æºãæåæåº GraphEvalï¼ä¸ååºæ¼ç¥è­å (KG) çµæ§ä¾è¡¨ç¤ºè³è¨çå¹»è¦ºè©ä¼°æ¶æ§ãæåçæè¡è­å¥åºå®¹æåºç¾å¹»è¦ºç KG ä¸­ç¹å®ä¸åçµï¼å æ­¤æ¯ä»¥å¾çæ¹æ³æ´æ·±å¥å°äºè§£åæä¸­å¹»è¦ºç¼çå¨åªè£¡ï¼å¦ææçè©±ï¼ãæ­¤å¤ï¼å°æåçæ¹æ³èæåé²çèªç¶èªè¨æ¨è« (NLI) æ¨¡åçµåä½¿ç¨ï¼èä½¿ç¨åå§ NLI æ¨¡åç¸æ¯ï¼å¯ä»¥å¨åç¨®å¹»è¦ºåºæºä¸æé«å¹³è¡¡æºç¢ºåº¦ãæå¾ï¼æåæ¢ç´¢ä½¿ç¨ GraphEval ä¾é²è¡å¹»è¦ºä¿®æ­£ï¼æ¹æ³æ¯å©ç¨ KG ççµæ§ï¼æåå°æ­¤æ¹æ³å½åçº GraphCorrectï¼ä¸¦è­æå¤§å¤æ¸å¹»è¦ºç¢ºå¯¦å¯ä»¥å¾å°ç³¾æ­£ã

##### **Scaling 3D Reasoning with LMMs to Large Robot Mission Environments Using Datagraphs**
2407.10743v1 by W. J. Meijer, A. C. Kemmeren, E. H. J. Riemens, J. E. Fransman, M. van Bekkum, G. J. Burghouts, J. D. van Mil

This paper addresses the challenge of scaling Large Multimodal Models (LMMs)
to expansive 3D environments. Solving this open problem is especially relevant
for robot deployment in many first-responder scenarios, such as
search-and-rescue missions that cover vast spaces. The use of LMMs in these
settings is currently hampered by the strict context windows that limit the
LMM's input size. We therefore introduce a novel approach that utilizes a
datagraph structure, which allows the LMM to iteratively query smaller sections
of a large environment. Using the datagraph in conjunction with graph traversal
algorithms, we can prioritize the most relevant locations to the query, thereby
improving the scalability of 3D scene language tasks. We illustrate the
datagraph using 3D scenes, but these can be easily substituted by other dense
modalities that represent the environment, such as pointclouds or Gaussian
splats. We demonstrate the potential to use the datagraph for two 3D scene
language task use cases, in a search-and-rescue mission example.

æè¦ï¼æ¬æè¨è«äºå°å¤§åå¤æ¨¡ææ¨¡å (LMM) æ´å±å°å»£é 3D ç°å¢çææ°ãè§£æ±ºéåéæ¾æ§åé¡å°æ¼æ©å¨äººå¨è¨±å¤ç¬¬ä¸åæäººå¡å ´æ¯ä¸­çé¨ç½²ç¹å¥ç¸éï¼ä¾å¦æ¶µèå»£éç©ºéçææä»»åãéäºè¨­å®ä¸­ä½¿ç¨ LMM ç®ååå°å´æ ¼çä¸ä¸æè¦çªéå¶ï¼ééå¶äº LMM çè¼¸å¥å¤§å°ãå æ­¤ï¼æåå¼å¥äºä¸ç¨®æ°ç©çæ¹æ³ï¼è©²æ¹æ³å©ç¨è³æåçµæ§ï¼åè¨± LMM è¿­ä»£æ¥è©¢å¤§åç°å¢çè¼å°é¨åãééå°è³æåèåå½¢éæ­·æ¼ç®æ³çµåä½¿ç¨ï¼æåå¯ä»¥åªåèæ®èæ¥è©¢æç¸éçä½ç½®ï¼å¾èæé« 3D å ´æ¯èªè¨ä»»åçå¯æ´åæ§ãæåä½¿ç¨ 3D å ´æ¯èªªæè³æåï¼ä½éäºå ´æ¯å¯ä»¥è¼é¬å°ç±å¶ä»è¡¨ç¤ºç°å¢çå¯éæ¨¡å¼åä»£ï¼ä¾å¦é»é²æé«æ¯é»ãæåå±ç¤ºäºå¨ææä»»åç¯ä¾ä¸­ä½¿ç¨è³æåé²è¡å©å 3D å ´æ¯èªè¨ä»»åç¨ä¾çæ½åã

##### **AutoGRAMS: Autonomous Graphical Agent Modeling Software**
2407.10049v1 by Ben Krause, Lucia Chen, Emmanuel Kahembwe

We introduce the AutoGRAMS framework for programming multi-step interactions
with language models. AutoGRAMS represents AI agents as a graph, where each
node can execute either a language modeling instruction or traditional code.
Likewise, transitions in the graph can be governed by either language modeling
decisions or traditional branch logic. AutoGRAMS supports using variables as
memory and allows nodes to call other AutoGRAMS graphs as functions. We show
how AutoGRAMS can be used to design highly sophisticated agents, including
self-referential agents that can modify their own graph. AutoGRAMS's
graph-centric approach aids interpretability, controllability, and safety
during the design, development, and deployment of AI agents. We provide our
framework as open source at https://github.com/autograms/autograms .

æè¦ï¼æåä»ç´¹ AutoGRAMS æ¡æ¶ï¼ç¨æ¼ç·¨å¯«èèªè¨æ¨¡åçå¤æ­¥é©äºåãAutoGRAMS å° AI ä»£çè¡¨ç¤ºçºä¸ååå½¢ï¼å¶ä¸­æ¯åç¯é»å¯ä»¥å·è¡èªè¨å»ºæ¨¡æä»¤æå³çµ±ä»£ç¢¼ãåæ¨£å°ï¼åå½¢ä¸­çè½æå¯ä»¥ç±èªè¨å»ºæ¨¡æ±ºç­æå³çµ±åæ¯éè¼¯æ§å¶ãAutoGRAMS æ¯æ´ä½¿ç¨è®æ¸ä½çºè¨æ¶é«ï¼ä¸¦åè¨±ç¯é»å¼å«å¶ä» AutoGRAMS åå½¢ä½çºå½å¼ãæåå±ç¤ºå¦ä½ä½¿ç¨ AutoGRAMS è¨­è¨é«åº¦è¤éçä»£çï¼åæ¬å¯ä»¥ä¿®æ¹èªèº«åå½¢çèªåç§ä»£çãAutoGRAMS ä»¥åå½¢çºä¸­å¿çæ¹æ³æå©æ¼å¨ AI ä»£ççè¨­è¨ãéç¼åé¨ç½²éç¨ä¸­æé«å¯è§£éæ§ãå¯æ§æ§åå®å¨æ§ãæåå¨ https://github.com/autograms/autograms æä¾æåçæ¡æ¶ä½çºéæºã

##### **FarFetched: Entity-centric Reasoning and Claim Validation for the Greek Language based on Textually Represented Environments**
2407.09888v1 by Dimitris Papadopoulos, Katerina Metropoulou, Nikolaos Matsatsinis, Nikolaos Papadakis

Our collective attention span is shortened by the flood of online
information. With \textit{FarFetched}, we address the need for automated claim
validation based on the aggregated evidence derived from multiple online news
sources. We introduce an entity-centric reasoning framework in which latent
connections between events, actions, or statements are revealed via entity
mentions and represented in a graph database. Using entity linking and semantic
similarity, we offer a way for collecting and combining information from
diverse sources in order to generate evidence relevant to the user's claim.
Then, we leverage textual entailment recognition to quantitatively determine
whether this assertion is credible, based on the created evidence. Our approach
tries to fill the gap in automated claim validation for less-resourced
languages and is showcased on the Greek language, complemented by the training
of relevant semantic textual similarity (STS) and natural language inference
(NLI) models that are evaluated on translated versions of common benchmarks.

æè¦ï¼ç¶²è·¯è³è¨çæ´ªæµç¸®ç­äºæåçéé«æ³¨æåæéãéé \textit{FarFetched}ï¼æåè§£æ±ºäºæ ¹æå¾å¤åç·ä¸æ°èä¾æºå½ç¸½çè­æé²è¡èªååè²æé©è­çéæ±ãæåå¼å¥äºä¸åä»¥å¯¦é«çºä¸­å¿çæ¨çæ¡æ¶ï¼å¶ä¸­äºä»¶ãåä½æé³è¿°ä¹éçæ½å¨éè¯ééå¯¦é«æåè¢«æ­é²ï¼ä¸¦å¨åå½¢è³æåº«ä¸­è¡¨ç¤ºãä½¿ç¨å¯¦é«é£çµåèªç¾©ç¸ä¼¼æ§ï¼æåæä¾ä¸ç¨®æ¹å¼ä¾æ¶éåçµåä¾èªä¸åä¾æºçè³è¨ï¼ä»¥ç¢çèä½¿ç¨èè²æç¸éçè­æãç¶å¾ï¼æåå©ç¨ææ¬èæ¶µè­å¥ä¾æ ¹æå»ºç«çè­æéåç¢ºå®æ­¤æ·è¨æ¯å¦å¯ä¿¡ãæåçåæ³è©¦åå¡«è£è³æºè¼å°çèªè¨çèªååè²æé©è­æ¹é¢çç©ºç½ï¼ä¸¦å¨å¸èèªä¸­å±ç¤ºï¼è¼ä»¥å°ç¸éèªç¾©ææ¬ç¸ä¼¼æ§ (STS) åèªç¶èªè¨æ¨è« (NLI) æ¨¡åçè¨ç·´ï¼éäºæ¨¡åå¨å¸¸è¦åºæºçç¿»è­¯çæ¬ä¸é²è¡è©ä¼°ã

##### **GOFA: A Generative One-For-All Model for Joint Graph Language Modeling**
2407.09709v1 by Lecheng Kong, Jiarui Feng, Hao Liu, Chengsong Huang, Jiaxin Huang, Yixin Chen, Muhan Zhang

Foundation models, such as Large Language Models (LLMs) or Large Vision
Models (LVMs), have emerged as one of the most powerful tools in the respective
fields. However, unlike text and image data, graph data do not have a
definitive structure, posing great challenges to developing a Graph Foundation
Model (GFM). For example, current attempts at designing general graph models
either transform graph data into a language format for LLM-based prediction or
still train a GNN model with LLM as an assistant. The former can handle
unlimited tasks, while the latter captures graph structure much better -- yet,
no existing work can achieve both simultaneously. In this paper, we identify
three key desirable properties of a GFM: self-supervised pretraining, fluidity
in tasks, and graph awareness. To account for these properties, we extend the
conventional language modeling to the graph domain and propose a novel
generative graph language model GOFA to solve the problem. The model
interleaves randomly initialized GNN layers into a frozen pre-trained LLM so
that the semantic and structural modeling abilities are organically combined.
GOFA is pre-trained on newly proposed graph-level next-word prediction,
question-answering, and structural tasks to obtain the above GFM properties.
The pre-trained model is further fine-tuned on downstream tasks to obtain
task-solving ability. The fine-tuned model is evaluated on various downstream
tasks, demonstrating a strong ability to solve structural and contextual
problems in zero-shot scenarios. The code is available at
https://github.com/JiaruiFeng/GOFA.

æè¦ï¼åºç¤æ¨¡åï¼ä¾å¦å¤§åèªè¨æ¨¡å (LLM) æå¤§åè¦è¦ºæ¨¡å (LVM)ï¼å·²æçºåèªé åä¸­ææåçå·¥å·ä¹ä¸ãç¶èï¼èææ¬åå½±åè³æä¸åï¼åå½¢è³ææ²ææç¢ºççµæ§ï¼å°éç¼åå½¢åºç¤æ¨¡å (GFM) æ§ææ¥µå¤§çææ°ãä¾å¦ï¼ç®åè¨­è¨éç¨åå½¢æ¨¡åçåè©¦ï¼ä¸æ¯å°åå½¢è³æè½æçºèªè¨æ ¼å¼ä»¥ä¾åºæ¼ LLM çé æ¸¬ï¼å°±æ¯è¨ç·´ GNN æ¨¡åï¼ä¸¦ä»¥ LLM ä½çºè¼å©ãåèå¯ä»¥èçç¡éçä»»åï¼èå¾èå¯ä»¥æ´å¥½å°æ·ååå½¢çµæ§ï¼ä½ç¾æçå·¥ä½ç¡æ³åæéæéå©èãå¨æ¬æä¸­ï¼æåæ¾åº GFM çä¸åééµçæ³ç¹æ§ï¼èªæç£ç£é è¨ç·´ãä»»åæµæ¢åº¦ååå½¢æç¥ãçºäºèééäºç¹æ§ï¼æåå°å³çµ±çèªè¨å»ºæ¨¡æ´åå°åå½¢é åï¼ä¸¦æåºä¸åæ°ç©ççæå¼åå½¢èªè¨æ¨¡å GOFA ä¾è§£æ±ºåé¡ãæ­¤æ¨¡åå°é¨æ©åå§åç GNN å±¤äº¤é¯æå¥åçµçé è¨ç·´ LLM ä¸­ï¼ä»¥ä¾¿èªæåçµæ§å»ºæ¨¡è½åææ©çµåãGOFA æ¡ç¨æ°æåºçåå½¢å±¤ç´ä¸ä¸åå­é æ¸¬ãåç­åçµæ§ä»»åé²è¡é è¨ç·´ï¼ä»¥åå¾ä¸è¿° GFM ç¹æ§ãé è¨ç·´æ¨¡åé²ä¸æ­¥å¨ä¸æ¸¸ä»»åä¸é²è¡å¾®èª¿ï¼ä»¥åå¾è§£æ±ºä»»åçè½åãå¾®èª¿æ¨¡åå¨åç¨®ä¸æ¸¸ä»»åä¸é²è¡è©ä¼°ï¼è­æäºå¨é¶æ¬¡å­¸ç¿å ´æ¯ä¸­è§£æ±ºçµæ§åä¸ä¸æåé¡çå¼·å¤§è½åãç¨å¼ç¢¼å¯å¨ https://github.com/JiaruiFeng/GOFA åå¾ã

##### **Human-like Episodic Memory for Infinite Context LLMs**
2407.09450v1 by Zafeirios Fountas, Martin A Benfeghoul, Adnan Oomerjee, Fenia Christopoulou, Gerasimos Lampouras, Haitham Bou-Ammar, Jun Wang

Large language models (LLMs) have shown remarkable capabilities, but still
struggle with processing extensive contexts, limiting their ability to maintain
coherence and accuracy over long sequences. In contrast, the human brain excels
at organising and retrieving episodic experiences across vast temporal scales,
spanning a lifetime. In this work, we introduce EM-LLM, a novel approach that
integrates key aspects of human episodic memory and event cognition into LLMs,
enabling them to effectively handle practically infinite context lengths while
maintaining computational efficiency. EM-LLM organises sequences of tokens into
coherent episodic events using a combination of Bayesian surprise and
graph-theoretic boundary refinement in an on-line fashion. When needed, these
events are retrieved through a two-stage memory process, combining
similarity-based and temporally contiguous retrieval for efficient and
human-like access to relevant information. Experiments on the LongBench dataset
demonstrate EM-LLM's superior performance, outperforming the state-of-the-art
InfLLM model with an overall relative improvement of 4.3% across various tasks,
including a 33% improvement on the PassageRetrieval task. Furthermore, our
analysis reveals strong correlations between EM-LLM's event segmentation and
human-perceived events, suggesting a bridge between this artificial system and
its biological counterpart. This work not only advances LLM capabilities in
processing extended contexts but also provides a computational framework for
exploring human memory mechanisms, opening new avenues for interdisciplinary
research in AI and cognitive science.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾åºéå¡çè½åï¼ä½ä»é£ä»¥èçå»£æ³çèçµ¡ï¼ééå¶äºå®åå¨é·åºåä¸­ç¶­æé£è²«æ§åæºç¢ºæ§çè½åãç¸è¼ä¹ä¸ï¼äººè¦æé·å¨å»£å¤§çæéå°ºåº¦ä¸çµç¹åæåæç¯é«é©ï¼è·¨è¶ä¸çãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äº EM-LLMï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼å®å°äººé¡æç¯è¨æ¶åäºä»¶èªç¥çééµé¢åæ´åå° LLM ä¸­ï¼è®å®åè½å¤ ææå°èçå¯¦éä¸ç¡éçèçµ¡é·åº¦ï¼åæç¶­æéç®æçãEM-LLM ä½¿ç¨è²æ°é©åååè«éçç²¾çççµåï¼ä»¥ç·ä¸æ¹å¼å°åºåæ¨è¨çµç¹æé£è²«çæç¯äºä»¶ãå¨éè¦æï¼éäºäºä»¶æééå©éæ®µçè¨æ¶éç¨ä¾æåï¼çµååºæ¼ç¸ä¼¼æ§åæéé£çºæ§çæåï¼ä»¥ææä¸é¡ä¼¼äººé¡çæ¹å¼å­åç¸éè³è¨ãå¨ LongBench è³æéä¸çå¯¦é©è­æäº EM-LLM çåè¶æè½ï¼å¨åç¨®ä»»åä¸­åªæ¼æåé²ç InfLLM æ¨¡åï¼å¨ PassageRetrieval ä»»åä¸­æ¹é²äº 33%ãæ­¤å¤ï¼æåçåææ­ç¤ºäº EM-LLM çäºä»¶åå²èäººé¡æç¥äºä»¶ä¹éçå¼·ç¸éæ§ï¼é¡¯ç¤ºäºéåäººå·¥ç³»çµ±èå¶çç©å°æç©ä¹éçæ©æ¨ãéé å·¥ä½ä¸åæåäº LLM å¨èçå»¶ä¼¸èçµ¡æ¹é¢çè½åï¼ä¹æä¾äºä¸åéç®æ¶æ§ä¾æ¢ç´¢äººé¡è¨æ¶æ©å¶ï¼çº AI åèªç¥ç§å­¸çè·¨é åç ç©¶éåäºæ°çéå¾ã

##### **The $Î¼\mathcal{G}$ Language for Programming Graph Neural Networks**
2407.09441v1 by Matteo Belenchia, Flavio Corradini, Michela Quadrini, Michele Loreti

Graph neural networks form a class of deep learning architectures
specifically designed to work with graph-structured data. As such, they share
the inherent limitations and problems of deep learning, especially regarding
the issues of explainability and trustworthiness. We propose $\mu\mathcal{G}$,
an original domain-specific language for the specification of graph neural
networks that aims to overcome these issues. The language's syntax is
introduced, and its meaning is rigorously defined by a denotational semantics.
An equivalent characterization in the form of an operational semantics is also
provided and, together with a type system, is used to prove the type soundness
of $\mu\mathcal{G}$. We show how $\mu\mathcal{G}$ programs can be represented
in a more user-friendly graphical visualization, and provide examples of its
generality by showing how it can be used to define some of the most popular
graph neural network models, or to develop any custom graph processing
application.

æè¦ï¼åå½¢ç¥ç¶ç¶²è·¯å½¢æä¸é¡æ·±åº¦å­¸ç¿æ¶æ§ï¼ç¹å¥è¨­è¨ç¨æ¼èçåå½¢çµæ§åçè³æãå æ­¤ï¼å®åå·ææ·±åº¦å­¸ç¿åºæçéå¶ååé¡ï¼ç¹å¥æ¯å¨å¯è§£éæ§åå¯ä¿¡è³´æ§åé¡ä¸ãæåæåº $\mu\mathcal{G}$ï¼ä¸ç¨®ç¨æ¼æå®åå½¢ç¥ç¶ç¶²è·¯çååµé åç¹å®èªè¨ï¼æ¨å¨åæéäºåé¡ãå¼å¥äºèªè¨çèªæ³ï¼ä¸¦ééæç¤ºèªç¾©å´æ ¼å®ç¾©å¶å«ç¾©ãéæä¾äºéç®èªç¾©å½¢å¼çç­æç¹å¾µæè¿°ï¼ä¸¦èé¡åç³»çµ±ä¸èµ·ç¨æ¼è­æ $\mu\mathcal{G}$ çé¡åå¥å¨æ§ãæåå±ç¤ºäºå¦ä½å° $\mu\mathcal{G}$ ç¨å¼è¡¨ç¤ºçºæ´ååçåå½¢è¦è¦ºåï¼ä¸¦ééå±ç¤ºå¦ä½ä½¿ç¨å®å®ç¾©ä¸äºææµè¡çåå½¢ç¥ç¶ç¶²è·¯æ¨¡åæéç¼ä»»ä½èªè¨åå½¢èçæç¨ç¨å¼ï¼ä¾æä¾å¶éç¨æ§çç¯ä¾ã

##### **Towards More Trustworthy and Interpretable LLMs for Code through Syntax-Grounded Explanations**
2407.08983v1 by David N. Palacio, Daniel Rodriguez-Cardenas, Alejandro Velasco, Dipin Khati, Kevin Moran, Denys Poshyvanyk

Trustworthiness and interpretability are inextricably linked concepts for
LLMs. The more interpretable an LLM is, the more trustworthy it becomes.
However, current techniques for interpreting LLMs when applied to code-related
tasks largely focus on accuracy measurements, measures of how models react to
change, or individual task performance instead of the fine-grained explanations
needed at prediction time for greater interpretability, and hence trust. To
improve upon this status quo, this paper introduces ASTrust, an
interpretability method for LLMs of code that generates explanations grounded
in the relationship between model confidence and syntactic structures of
programming languages. ASTrust explains generated code in the context of syntax
categories based on Abstract Syntax Trees and aids practitioners in
understanding model predictions at both local (individual code snippets) and
global (larger datasets of code) levels. By distributing and assigning model
confidence scores to well-known syntactic structures that exist within ASTs,
our approach moves beyond prior techniques that perform token-level confidence
mapping by offering a view of model confidence that directly aligns with
programming language concepts with which developers are familiar. To put
ASTrust into practice, we developed an automated visualization that illustrates
the aggregated model confidence scores superimposed on sequence, heat-map, and
graph-based visuals of syntactic structures from ASTs. We examine both the
practical benefit that ASTrust can provide through a data science study on 12
popular LLMs on a curated set of GitHub repos and the usefulness of ASTrust
through a human study.

æè¦ï¼å¯ä¿¡åº¦åå¯è§£éæ§æ¯ LLM ä¸­å¯ä¸å¯åçæ¦å¿µãLLM çå¯è§£éæ§è¶é«ï¼å®çå¯ä¿¡åº¦å°±è¶é«ãç¶èï¼ç¶æç¨æ¼èç¨å¼ç¢¼ç¸éçä»»åæï¼ç®åè§£é LLM çæè¡ä¸»è¦éä¸­å¨æºç¢ºæ§æ¸¬éãæ¨¡åå°è®åçåææ¸¬éæåå¥ä»»åè¡¨ç¾ï¼èä¸æ¯å¨é æ¸¬æéæéçç´°ç²åº¦è§£éï¼å¾èæé«å¯è§£éæ§åå æ­¤æé«ä¿¡ä»»åº¦ãçºäºæ¹åéç¨®ç¾çï¼æ¬æä»ç´¹äº ASTrustï¼éæ¯ä¸ç¨®ç¨æ¼ç¨å¼ç¢¼ LLM çå¯è§£éæ§æ¹æ³ï¼å®ææ ¹ææ¨¡åä¿¡å¿èç¨å¼èªè¨çèªæ³çµæ§ä¹éçéä¿ç¢çè§£éãASTrust å¨åºæ¼æ½è±¡èªæ³æ¨¹çèªæ³é¡å¥çä¸ä¸æä¸­è§£éç¢ççç¨å¼ç¢¼ï¼ä¸¦å¹«å©å¯¦åäººå¡å¨å±é¨ï¼åå¥ç¨å¼ç¢¼çæ®µï¼åå¨åï¼è¼å¤§çç¨å¼ç¢¼è³æéï¼å±¤ç´äºè§£æ¨¡åé æ¸¬ãééå°æ¨¡åä¿¡å¿åæ¸åéåæå®çµ¦ AST ä¸­å­å¨çç¾æå¨ç¥çèªæ³çµæ§ï¼æåçåæ³è¶è¶äºååçæè¡ï¼éäºæè¡ééæä¾èéç¼äººå¡çæçç¨å¼èªè¨æ¦å¿µç´æ¥å°é½çæ¨¡åä¿¡å¿è¦åä¾å·è¡ä»¤çç´å¥çä¿¡å¿å°æãçºäºå¯¦è¸ ASTrustï¼æåéç¼äºä¸åèªååè¦è¦ºåå·¥å·ï¼å®èªªæäºçå å¨ AST èªæ³çµæ§çåºåãç±åååºæ¼åå½¢çè¦è¦ºææä¸çèåæ¨¡åä¿¡å¿åæ¸ãæåæª¢æ¥äº ASTrust å¯ä»¥ééå° 12 åæµè¡ç LLM å¨ä¸çµç²¾é¸ç GitHub å²å­åº«ä¸é²è¡è³æç§å­¸ç ç©¶æä¾çå¯¦éå¥½èï¼ä»¥åééäººé«ç ç©¶æä¾ç ASTrust çæç¨æ§ã

##### **Domain-Hierarchy Adaptation via Chain of Iterative Reasoning for Few-shot Hierarchical Text Classification**
2407.08959v1 by Ke Ji, Peng Wang, Wenjun Ke, Guozheng Li, Jiajun Liu, Jingsheng Gao, Ziyu Shang

Recently, various pre-trained language models (PLMs) have been proposed to
prove their impressive performances on a wide range of few-shot tasks. However,
limited by the unstructured prior knowledge in PLMs, it is difficult to
maintain consistent performance on complex structured scenarios, such as
hierarchical text classification (HTC), especially when the downstream data is
extremely scarce. The main challenge is how to transfer the unstructured
semantic space in PLMs to the downstream domain hierarchy. Unlike previous work
on HTC which directly performs multi-label classification or uses graph neural
network (GNN) to inject label hierarchy, in this work, we study the HTC problem
under a few-shot setting to adapt knowledge in PLMs from an unstructured manner
to the downstream hierarchy. Technically, we design a simple yet effective
method named Hierarchical Iterative Conditional Random Field (HierICRF) to
search the most domain-challenging directions and exquisitely crafts
domain-hierarchy adaptation as a hierarchical iterative language modeling
problem, and then it encourages the model to make hierarchical consistency
self-correction during the inference, thereby achieving knowledge transfer with
hierarchical consistency preservation. We perform HierICRF on various
architectures, and extensive experiments on two popular HTC datasets
demonstrate that prompt with HierICRF significantly boosts the few-shot HTC
performance with an average Micro-F1 by 28.80% to 1.50% and Macro-F1 by 36.29%
to 1.5% over the previous state-of-the-art (SOTA) baselines under few-shot
settings, while remaining SOTA hierarchical consistency performance.

æè¦ï¼<paragraph>æè¿ï¼å·²ç»æåºäºå¤ç§é¢è®­ç»è¯­è¨æ¨¡å (PLM)ï¼ä»¥è¯æå®ä»¬å¨å¹¿æ³çå°éæ ·æ¬ä»»å¡ä¸å·æä»¤äººå°è±¡æ·±å»çæ§è½ãç¶èï¼ç±äº PLM ä¸­éç»æåçåéªç¥è¯åå°éå¶ï¼å æ­¤é¾ä»¥å¨å¤æç»æååºæ¯ï¼ä¾å¦å±æ¬¡ææ¬åç±» (HTC)ï¼ä¸­ä¿æä¸è´çæ§è½ï¼å°¤å¶æ¯å¨ä¸æ¸¸æ°æ®æå¶ç¨å°çæåµä¸ãä¸»è¦çæææ¯å¦ä½å° PLM ä¸­éç»æåçè¯­ä¹ç©ºé´è½¬ç§»å°ä¸æ¸¸åå±æ¬¡ç»æãä¸ä»¥åç´æ¥æ§è¡å¤æ ç­¾åç±»æä½¿ç¨å¾ç¥ç»ç½ç» (GNN) æ³¨å¥æ ç­¾å±æ¬¡ç»æç HTC å·¥ä½ä¸åï¼å¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å¨å°éæ ·æ¬è®¾ç½®ä¸ç ç©¶ HTC é®é¢ï¼ä»¥å° PLM ä¸­çç¥è¯ä»éç»æåæ¹å¼éåºå°ä¸æ¸¸å±æ¬¡ç»æãä»ææ¯ä¸è®²ï¼æä»¬è®¾è®¡äºä¸ç§ç®åèææçæ¹æ³ï¼ç§°ä¸ºå±æ¬¡è¿­ä»£æ¡ä»¶éæºåº (HierICRF)ï¼ä»¥æç´¢æå·é¢åæææ§çæ¹åï¼å¹¶ç²¾ç»å°å°é¢åå±æ¬¡ç»æéåºä½ä¸ºåå±è¿­ä»£è¯­è¨å»ºæ¨¡é®é¢ï¼ç¶åå®é¼å±æ¨¡åå¨æ¨çæé´è¿è¡å±æ¬¡ä¸è´æ§èªææ ¡æ­£ï¼ä»èå®ç°å·æå±æ¬¡ä¸è´æ§ä¿ççç¥è¯è½¬ç§»ãæä»¬å¨åç§æ¶æä¸æ§è¡ HierICRFï¼å¨ä¸¤ä¸ªæµè¡ç HTC æ°æ®éä¸çå¤§éå®éªè¡¨æï¼ä½¿ç¨ HierICRF çæç¤ºæ¾çæé«äºå°éæ ·æ¬ HTC æ§è½ï¼å¹³å Micro-F1 ä» 28.80% æé«å° 1.50%ï¼Macro-F1 ä» 36.29% æé«å° 1.5% å¨å°éæ ·æ¬è®¾ç½®ä¸è¶è¿äºä»¥åæåè¿ (SOTA) åºåï¼åæ¶ä¿æ SOTA å±æ¬¡ä¸è´æ§æ§è½ã</paragraph>

##### **Cloud Atlas: Efficient Fault Localization for Cloud Systems using Language Models and Causal Insight**
2407.08694v1 by Zhiqiang Xie, Yujia Zheng, Lizi Ottens, Kun Zhang, Christos Kozyrakis, Jonathan Mace

Runtime failure and performance degradation is commonplace in modern cloud
systems. For cloud providers, automatically determining the root cause of
incidents is paramount to ensuring high reliability and availability as prompt
fault localization can enable faster diagnosis and triage for timely
resolution. A compelling solution explored in recent work is causal reasoning
using causal graphs to capture relationships between varied cloud system
performance metrics. To be effective, however, systems developers must
correctly define the causal graph of their system, which is a time-consuming,
brittle, and challenging task that increases in difficulty for large and
dynamic systems and requires domain expertise. Alternatively, automated
data-driven approaches have limited efficacy for cloud systems due to the
inherent rarity of incidents. In this work, we present Atlas, a novel approach
to automatically synthesizing causal graphs for cloud systems. Atlas leverages
large language models (LLMs) to generate causal graphs using system
documentation, telemetry, and deployment feedback. Atlas is complementary to
data-driven causal discovery techniques, and we further enhance Atlas with a
data-driven validation step. We evaluate Atlas across a range of fault
localization scenarios and demonstrate that Atlas is capable of generating
causal graphs in a scalable and generalizable manner, with performance that far
surpasses that of data-driven algorithms and is commensurate to the
ground-truth baseline.

æè¦ï¼å¨ç¾ä»£é²ç«¯ç³»çµ±ä¸­ï¼å·è¡æææéåæè½éä½æ¯å¸ç©ºè¦æ£çäºãå°æ¼é²ç«¯ä¾æåèè¨ï¼èªåæ¾åºäºä»¶çæ ¹æ¬åå å°æ¼ç¢ºä¿é«å¯é æ§åå¯ç¨æ§è³ééè¦ï¼å çºåæçæéå®ä½å¯ä»¥è®è¨ºæ·ååé¡æ´å¿«éï¼ä»¥å©æ¼åæè§£æ±ºåé¡ãæè¿çå·¥ä½ä¸­æ¢è¨äºä¸åå¼äººæ³¨ç®çè§£æ±ºæ¹æ¡ï¼å³ä½¿ç¨å æåä¾æ·ååç¨®é²ç«¯ç³»çµ±æè½ææ¨ä¹ééä¿çå ææ¨çãç¶èï¼ç³»çµ±éç¼äººå¡å¿é æ­£ç¢ºå®ç¾©å¶ç³»çµ±çå æåæè½ç¼æ®æç¨ï¼èéé ä»»åèæãèå¼±ä¸å·æææ°æ§ï¼å°æ¼å¤§åä¸åæçç³»çµ±èè¨é£åº¦æ´é«ï¼èä¸éè¦é åå°å®¶ç¥è­ãæèï¼ç±æ¼äºä»¶çåºæç¨å°æ§ï¼èªååè³æé©åæ¹æ³å°æ¼é²ç«¯ç³»çµ±çæåæéãå¨éé å·¥ä½ä¸­ï¼æåæåº Atlasï¼ä¸ç¨®èªååæé²ç«¯ç³»çµ±å æåçæ°æ¹æ³ãAtlas å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä½¿ç¨ç³»çµ±æä»¶ãéæ¸¬åé¨ç½²åé¥ä¾ç¢çå æåãAtlas æ¯è³æé©åå æç¼ç¾æè¡çè£åï¼æåé²ä¸æ­¥ä½¿ç¨è³æé©åé©è­æ­¥é©ä¾å¢å¼· Atlasãæåå¨åç¨®æéå®ä½æå¢ä¸­è©ä¼° Atlasï¼ä¸¦è­æ Atlas è½å¤ ä»¥å¯æ´åä¸å¯æ¦åçæ¹å¼ç¢çå æåï¼å¶æè½é é è¶éè³æé©åæ¼ç®æ³ï¼ä¸¦ä¸èçå¯¦åºç·ç¸ç¶ã

##### **Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents**
2407.08516v2 by Haoyi Xiong, Zhiyuan Wang, Xuhong Li, Jiang Bian, Zeke Xie, Shahid Mumtaz, Laura E. Barnes

This article explores the convergence of connectionist and symbolic
artificial intelligence (AI), from historical debates to contemporary
advancements. Traditionally considered distinct paradigms, connectionist AI
focuses on neural networks, while symbolic AI emphasizes symbolic
representation and logic. Recent advancements in large language models (LLMs),
exemplified by ChatGPT and GPT-4, highlight the potential of connectionist
architectures in handling human language as a form of symbols. The study argues
that LLM-empowered Autonomous Agents (LAAs) embody this paradigm convergence.
By utilizing LLMs for text-based knowledge modeling and representation, LAAs
integrate neuro-symbolic AI principles, showcasing enhanced reasoning and
decision-making capabilities. Comparing LAAs with Knowledge Graphs within the
neuro-symbolic AI theme highlights the unique strengths of LAAs in mimicking
human-like reasoning processes, scaling effectively with large datasets, and
leveraging in-context samples without explicit re-training. The research
underscores promising avenues in neuro-vector-symbolic integration,
instructional encoding, and implicit reasoning, aimed at further enhancing LAA
capabilities. By exploring the progression of neuro-symbolic AI and proposing
future research trajectories, this work advances the understanding and
development of AI technologies.

æè¦ï¼æ¬ææ¢è¨äºé£ç·ä¸»ç¾©èç¬¦èäººå·¥æºæ§ï¼AIï¼çèåï¼å¾æ­·å²è¾¯è«å°ç¶ä»£é²å±ãé£ç·ä¸»ç¾© AI å³çµ±ä¸è¢«è¦çºä¸åçç¯å¼ï¼å°æ³¨æ¼ç¥ç¶ç¶²è·¯ï¼èç¬¦è AI åå¼·èª¿ç¬¦èè¡¨å¾µèéè¼¯ãå¤§åèªè¨æ¨¡åï¼LLMï¼çææ°é²å±ï¼ä¾å¦ ChatGPT å GPT-4ï¼çªé¡¯äºé£ç·ä¸»ç¾©æ¶æ§å¨å°äººé¡èªè¨è¦çºç¬¦èå½¢å¼èçæ¹é¢çæ½åãç ç©¶èªçºï¼ç± LLM è³¦è½çèªä¸»ä»£çï¼LAAï¼é«ç¾äºéç¨®ç¯å¼èåãééå©ç¨ LLM é²è¡åºæ¼æå­çç¥è­å»ºæ¨¡åè¡¨å¾µï¼LAA æ´åäºç¥ç¶ç¬¦è AI ååï¼å±ç¤ºäºå¢å¼·çæ¨çåæ±ºç­è½åãå¨ç¥ç¶ç¬¦è AI ä¸»é¡ä¸­æ¯è¼ LAA èç¥è­åè­ï¼çªåºäº LAA å¨æ¨¡æ¬é¡äººæ¨çéç¨ãæææ´åå¤§åè³æéä»¥åå©ç¨æå¢ç¯ä¾èç¡éæç¢ºéæ°è¨ç·´æ¹é¢çç¨ç¹åªå¢ãç ç©¶å¼·èª¿äºç¥ç¶åéç¬¦èæ´åãæä»¤ç·¨ç¢¼åé±å¼æ¨çä¸­åæ¯çå¥½çéå¾ï¼æ¨å¨é²ä¸æ­¥å¢å¼· LAA è½åãééæ¢ç´¢ç¥ç¶ç¬¦è AI çé²å±ä¸¦æåºæªä¾çç ç©¶è»è·¡ï¼éé å·¥ä½æ¨åäº AI æè¡ççè§£åç¼å±ã

##### **A Comprehensive Survey on the Security of Smart Grid: Challenges, Mitigations, and Future Research Opportunities**
2407.07966v1 by Arastoo Zibaeirad, Farnoosh Koleini, Shengping Bi, Tao Hou, Tao Wang

In this study, we conduct a comprehensive review of smart grid security,
exploring system architectures, attack methodologies, defense strategies, and
future research opportunities. We provide an in-depth analysis of various
attack vectors, focusing on new attack surfaces introduced by advanced
components in smart grids. The review particularly includes an extensive
analysis of coordinated attacks that incorporate multiple attack strategies and
exploit vulnerabilities across various smart grid components to increase their
adverse impact, demonstrating the complexity and potential severity of these
threats. Following this, we examine innovative detection and mitigation
strategies, including game theory, graph theory, blockchain, and machine
learning, discussing their advancements in counteracting evolving threats and
associated research challenges. In particular, our review covers a thorough
examination of widely used machine learning-based mitigation strategies,
analyzing their applications and research challenges spanning across
supervised, unsupervised, semi-supervised, ensemble, and reinforcement
learning. Further, we outline future research directions and explore new
techniques and concerns. We first discuss the research opportunities for
existing and emerging strategies, and then explore the potential role of new
techniques, such as large language models (LLMs), and the emerging threat of
adversarial machine learning in the future of smart grid security.

æè¦ï¼å¨éé ç ç©¶ä¸­ï¼æåå°æºæ§é»ç¶²å®å¨æ§é²è¡å¨é¢æª¢è¦ï¼æ¢è¨ç³»çµ±æ¶æ§ãæ»ææ¹æ³ãé²ç¦¦ç­ç¥åæªä¾çç ç©¶æ©æãæåæ·±å¥åæåç¨®æ»æåªä»ï¼å°æ³¨æ¼æºæ§é»ç¶²ä¸­åé²çµä»¶æå¼å¥çæ°æ»æé¢ãæ¬æª¢è¦ç¹å¥åå«å°åèª¿æ»æçå»£æ³åæï¼å¶ä¸­åå«å¤ç¨®æ»æç­ç¥ä¸¦å©ç¨åç¨®æºæ§é»ç¶²çµä»¶ä¸­çæ¼æ´ä¾å¢å å¶è² é¢å½±é¿ï¼å±ç¤ºéäºå¨èçè¤éæ§åæ½å¨å´éæ§ãå¨æ­¤ä¹å¾ï¼æåæ¢è¨åµæ°çåµæ¸¬åç·©è§£ç­ç¥ï¼åæ¬åå¼è«ãåè«ãåå¡éåæ©å¨å­¸ç¿ï¼è¨è«å®åå¨å°æä¸æ·æ¼è®çå¨èåç¸éç ç©¶ææ°æ¹é¢çé²å±ãç¹å¥æ¯ï¼æåçæª¢è¦æ¶µèå°å»£æ³ä½¿ç¨çåºæ¼æ©å¨å­¸ç¿çç·©è§£ç­ç¥çå¾¹åºæª¢é©ï¼åæå®åå¨ç£ç£å¼ãéç£ç£å¼ãåç£ç£å¼ãæ´é«å¼åå¼·åå­¸ç¿ä¸­çæç¨åç ç©¶ææ°ãæ­¤å¤ï¼æåæ¦è¿°æªä¾çç ç©¶æ¹åä¸¦æ¢è¨æ°æè¡ååé¡ãæåé¦åè¨è«ç¾æåæ°èç­ç¥çç ç©¶æ©æï¼ç¶å¾æ¢è¨æ°æè¡çæ½å¨ä½ç¨ï¼ä¾å¦å¤§åèªè¨æ¨¡å (LLM)ï¼ä»¥åå°æå¼æ©å¨å­¸ç¿å¨æºæ§é»ç¶²å®å¨æªä¾çå¨èã

##### **Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs**
2407.07775v2 by Hao-Tien Lewis Chiang, Zhuo Xu, Zipeng Fu, Mithun George Jacob, Tingnan Zhang, Tsang-Wei Edward Lee, Wenhao Yu, Connor Schenck, David Rendleman, Dhruv Shah, Fei Xia, Jasmine Hsu, Jonathan Hoech, Pete Florence, Sean Kirmani, Sumeet Singh, Vikas Sindhwani, Carolina Parada, Chelsea Finn, Peng Xu, Sergey Levine, Jie Tan

An elusive goal in navigation research is to build an intelligent agent that
can understand multimodal instructions including natural language and image,
and perform useful navigation. To achieve this, we study a widely useful
category of navigation tasks we call Multimodal Instruction Navigation with
demonstration Tours (MINT), in which the environment prior is provided through
a previously recorded demonstration video. Recent advances in Vision Language
Models (VLMs) have shown a promising path in achieving this goal as it
demonstrates capabilities in perceiving and reasoning about multimodal inputs.
However, VLMs are typically trained to predict textual output and it is an open
research question about how to best utilize them in navigation. To solve MINT,
we present Mobility VLA, a hierarchical Vision-Language-Action (VLA) navigation
policy that combines the environment understanding and common sense reasoning
power of long-context VLMs and a robust low-level navigation policy based on
topological graphs. The high-level policy consists of a long-context VLM that
takes the demonstration tour video and the multimodal user instruction as input
to find the goal frame in the tour video. Next, a low-level policy uses the
goal frame and an offline constructed topological graph to generate robot
actions at every timestep. We evaluated Mobility VLA in a 836m^2 real world
environment and show that Mobility VLA has a high end-to-end success rates on
previously unsolved multimodal instructions such as "Where should I return
this?" while holding a plastic bin. A video demonstrating Mobility VLA can be
found here: https://youtu.be/-Tof__Q8_5s

æè¦ï¼<paragraph>å°èªç ç©¶ä¸­ä¸åé£ä»¥ææ¸çç®æ¨ï¼æ¯å»ºç«ä¸åæºè½ä»£çï¼å®å¯ä»¥çè§£åæ¬èªç¶èªè¨åå½±åçå¤æ¨¡ææä»¤ï¼ä¸¦å·è¡æç¨çå°èªãçºäºéææ­¤ç®æ¨ï¼æåç ç©¶äºä¸é¡å»£æ³æç¨çå°èªä»»åï¼æåç¨±ä¹çºç¤ºç¯å°è¦½çå¤æ¨¡ææä»¤å°èª (MINT)ï¼å¶ä¸­ç°å¢åé©æ¯ééååéè£½çç¤ºç¯å½±çæä¾çãè¦è¦ºèªè¨æ¨¡å (VLM) çè¿æé²å±ï¼å±ç¤ºäºä¸æ¢å¯¦ç¾æ­¤ç®æ¨çæåæ¯è·¯å¾ï¼å çºå®å±ç¤ºäºæç¥åæ¨çå¤æ¨¡æè¼¸å¥çè½åãç¶èï¼VLM éå¸¸è¨ç·´ç¨æ¼é æ¸¬æå­è¼¸åºï¼èå¦ä½æä½³å©ç¨å®åé²è¡å°èªï¼åæ¯ä¸åéæ¾çç ç©¶åé¡ãçºäºè§£æ±º MINTï¼æåæåºäº Mobility VLAï¼éæ¯ä¸ç¨®åå±¤çè¦è¦º-èªè¨-åä½ (VLA) å°èªæ¿ç­ï¼å®çµåäºé·èªå¢ VLM çç°å¢çè§£åå¸¸è­æ¨çè½åï¼ä»¥ååºæ¼ææ²åçå¼·å¥ä½éå°èªæ¿ç­ãé«éæ¿ç­åå«ä¸åé·èªå¢ VLMï¼å®æ¡ç¨ç¤ºç¯å°è¦½å½±çåå¤æ¨¡æä½¿ç¨èæä»¤ä½çºè¼¸å¥ï¼ä»¥å¨å°è¦½å½±çä¸­æ¾å°ç®æ¨å¹ãæ¥ä¸ä¾ï¼ä½éæ¿ç­ä½¿ç¨ç®æ¨å¹åé¢ç·å»ºæ§çææ²åï¼å¨æ¯åæéæ­¥ç¢çæ©å¨äººåä½ãæåå¨ 836 å¹³æ¹å¬å°ºççå¯¦ä¸çç°å¢ä¸­è©ä¼°äº Mobility VLAï¼ä¸¦å±ç¤ºäº Mobility VLA å¨ååæªè§£æ±ºçå¤æ¨¡ææä»¤ï¼ä¾å¦ãææè©²æéåå¡è ç®±æ­¸éå°åªè£¡ï¼ãï¼ä¸å·æå¾é«çç«¯å°ç«¯æåçï¼åææ¿èä¸åå¡è ç®±ãå±ç¤º Mobility VLA çå½±çå¯ä»¥å¨éè£¡æ¾å°ï¼https://youtu.be/-Tof__Q8_5s</paragraph>

##### **Teaching Transformers Causal Reasoning through Axiomatic Training**
2407.07612v1 by Aniket Vashishtha, Abhinav Kumar, Abbavaram Gowtham Reddy, Vineeth N Balasubramanian, Amit Sharma

For text-based AI systems to interact in the real world, causal reasoning is
an essential skill. Since interventional data is costly to generate, we study
to what extent an agent can learn causal reasoning from passive data.
Specifically, we consider an axiomatic training setup where an agent learns
from multiple demonstrations of a causal axiom (or rule), rather than
incorporating the axiom as an inductive bias or inferring it from data values.
A key question is whether the agent would learn to generalize from the axiom
demonstrations to new scenarios. For example, if a transformer model is trained
on demonstrations of the causal transitivity axiom over small graphs, would it
generalize to applying the transitivity axiom over large graphs? Our results,
based on a novel axiomatic training scheme, indicate that such generalization
is possible. We consider the task of inferring whether a variable causes
another variable, given a causal graph structure. We find that a 67 million
parameter transformer model, when trained on linear causal chains (along with
some noisy variations) can generalize well to new kinds of graphs, including
longer causal chains, causal chains with reversed order, and graphs with
branching; even when it is not explicitly trained for such settings. Our model
performs at par (or even better) than many larger language models such as
GPT-4, Gemini Pro, and Phi-3. Overall, our axiomatic training framework
provides a new paradigm of learning causal reasoning from passive data that can
be used to learn arbitrary axioms, as long as sufficient demonstrations can be
generated.

æè¦ï¼<paragraph>å°æ¼åºæ¼æå­çäººå·¥æºæ§ç³»çµ±èçå¯¦ä¸çäºåä¾èªªï¼å ææ¨çæ¯ä¸é å¿è¦çæè½ãç±æ¼ä»å¥è³æçç¢çææ¬å¾é«ï¼æåç ç©¶ä¸ä½ä»£çäººå¾è¢«åè³æä¸­å­¸ç¿å ææ¨ççç¨åº¦ãå·é«ä¾èªªï¼æåèæ®ä¸åå¬çè¨ç·´è¨­ç½®ï¼å¶ä¸­ä¸ä½ä»£çäººå¾å æå¬çï¼æè¦åï¼çå¤åç¤ºç¯ä¸­å­¸ç¿ï¼èä¸æ¯å°å¬çä½çºæ­¸ç´åèª¤æå¾è³æå¼ä¸­æ¨æ·åºä¾ãä¸åééµåé¡æ¯ä»£çäººæ¯å¦æå­¸æå¾å¬çç¤ºç¯æ¨å»£å°æ°çå ´æ¯ãä¾å¦ï¼å¦æä¸åTransformeræ¨¡åå¨å°åè¡¨ä¸å æå³éæ§å¬ççç¤ºç¯ä¸­æ¥åè¨ç·´ï¼å®æ¯å¦ææ¨å»£å°å¨å¤§åè¡¨ä¸æç¨å³éæ§å¬çï¼æåççµæåºæ¼ä¸åæ°ç©çå¬çè¨ç·´æ¹æ¡ï¼è¡¨æéæ¨£çæ¦æ¬æ¯å¯è½çãæåèæ®æ¨è«ä¸åè®æ¸æ¯å¦å°è´å¦ä¸åè®æ¸çä»»åï¼çµ¦å®ä¸åå æåçµæ§ãæåç¼ç¾ä¸å 6700 è¬ååæ¸çTransformeræ¨¡åï¼å¨ç·æ§å æéï¼ä»¥åä¸äºéè¨è®åï¼ä¸è¨ç·´æï¼å¯ä»¥å¾å¥½å°æ¦æ¬å°æ°é¡åçåå½¢ï¼åæ¬æ´é·çå æéãé åºç¸åçå æéåå·æåæ¯çåå½¢ï¼å³ä½¿å®æ²æéå°æ­¤é¡è¨­ç½®é²è¡æç¢ºè¨ç·´ãæåçæ¨¡åè¡¨ç¾èè¨±å¤è¼å¤§çèªè¨æ¨¡åï¼ä¾å¦ GPT-4ãGemini Pro å Phi-3ï¼ç¸ç¶ï¼çè³æ´å¥½ï¼ãç¸½é«èè¨ï¼æåçå¬çè¨ç·´æ¡æ¶æä¾äºä¸åå¾è¢«åè³æä¸­å­¸ç¿å ææ¨ççæ°ç¯ä¾ï¼åªè¦å¯ä»¥ç¢çè¶³å¤ çç¤ºç¯ï¼å°±å¯ä»¥ç¨æ¼å­¸ç¿ä»»æå¬çã</paragraph>

##### **GLBench: A Comprehensive Benchmark for Graph with Large Language Models**
2407.07457v2 by Yuhan Li, Peisong Wang, Xiao Zhu, Aochuan Chen, Haiyun Jiang, Deng Cai, Victor Wai Kin Chan, Jia Li

The emergence of large language models (LLMs) has revolutionized the way we
interact with graphs, leading to a new paradigm called GraphLLM. Despite the
rapid development of GraphLLM methods in recent years, the progress and
understanding of this field remain unclear due to the lack of a benchmark with
consistent experimental protocols. To bridge this gap, we introduce GLBench,
the first comprehensive benchmark for evaluating GraphLLM methods in both
supervised and zero-shot scenarios. GLBench provides a fair and thorough
evaluation of different categories of GraphLLM methods, along with traditional
baselines such as graph neural networks. Through extensive experiments on a
collection of real-world datasets with consistent data processing and splitting
strategies, we have uncovered several key findings. Firstly, GraphLLM methods
outperform traditional baselines in supervised settings, with LLM-as-enhancers
showing the most robust performance. However, using LLMs as predictors is less
effective and often leads to uncontrollable output issues. We also notice that
no clear scaling laws exist for current GraphLLM methods. In addition, both
structures and semantics are crucial for effective zero-shot transfer, and our
proposed simple baseline can even outperform several models tailored for
zero-shot scenarios. The data and code of the benchmark can be found at
https://github.com/NineAbyss/GLBench.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çåºç¾å¾¹åºæ¹è®äºæåèåè¡¨äºåçæ¹å¼ï¼é²èç¢çä¸ç¨®ç¨±çº GraphLLM çæ°å¸ç¯ãåç®¡è¿å¹´ä¾ GraphLLM æ¹æ³å¿«éç¼å±ï¼ä½ç±æ¼ç¼ºä¹å·æä¸è´å¯¦é©åå®çåºæºï¼å æ­¤è©²é åçé²å±åçè§£ä»ä¸æç¢ºãçºäºå½è£éåå·®è·ï¼æåå¼å¥äº GLBenchï¼éæ¯ç¬¬ä¸åç¨æ¼è©ä¼° GraphLLM æ¹æ³å¨ç£ç£å¼åé¶æ¬¡å­¸ç¿å ´æ¯ä¸­çç¶ååºæºãGLBench æä¾å°ä¸åé¡å¥ç GraphLLM æ¹æ³é²è¡å¬å¹³ä¸å¾¹åºçè©ä¼°ï¼ä»¥åå³çµ±åºæºï¼ä¾å¦åç¥ç¶ç¶²è·¯ãééå°ä¸çµçå¯¦ä¸çè³æéé²è¡å»£æ³å¯¦é©ï¼ä¸¦æ¡ç¨ä¸è´çè³æèçååå²ç­ç¥ï¼æåç¼ç¾äºå¹¾åééµç¼ç¾ãé¦åï¼GraphLLM æ¹æ³å¨ç£ç£å¼è¨­å®ä¸­åªæ¼å³çµ±åºæºï¼å¶ä¸­ LLM ä½çºå¢å¼·å¨é¡¯ç¤ºåºæç©©å¥çæè½ãç¶èï¼ä½¿ç¨ LLM ä½çºé æ¸¬å¨è¼ä¸ææï¼èä¸ç¶å¸¸å°è´ç¡æ³æ§å¶çè¼¸åºåé¡ãæåéæ³¨æå°ï¼å°æ¼ç®åç GraphLLM æ¹æ³ä¸¦ä¸å­å¨æç¢ºçç¸®æ¾å®å¾ãæ­¤å¤ï¼çµæ§åèªç¾©å°æ¼ææçé¶æ¬¡å­¸ç¿å³è¼¸è³ééè¦ï¼èæåæåºçç°¡å®åºæºçè³å¯ä»¥åªæ¼éå°é¶æ¬¡å­¸ç¿å ´æ¯éèº«æé çå¹¾åæ¨¡åãåºæºçè³æåç¨å¼ç¢¼å¯ä»¥å¨ https://github.com/NineAbyss/GLBench ä¸­æ¾å°ã

##### **Decoding Climate Disagreement: A Graph Neural Network-Based Approach to Understanding Social Media Dynamics**
2407.07038v1 by Ruiran Su, Janet B. Pierrehumbert

This work introduces the ClimateSent-GAT Model, an innovative method that
integrates Graph Attention Networks (GATs) with techniques from natural
language processing to accurately identify and predict disagreements within
Reddit comment-reply pairs. Our model classifies disagreements into three
categories: agree, disagree, and neutral. Leveraging the inherent graph
structure of Reddit comment-reply pairs, the model significantly outperforms
existing benchmarks by capturing complex interaction patterns and sentiment
dynamics. This research advances graph-based NLP methodologies and provides
actionable insights for policymakers and educators in climate science
communication.

æè¦ï¼æ¬ç ç©¶ä»ç´¹ ClimateSent-GAT æ¨¡åï¼éæ¯ä¸ç¨®åµæ°çæ¹æ³ï¼å®å°åæ³¨æåç¶²è·¯ (GAT) èèªç¶èªè¨èçæè¡æ´åï¼ä»¥æºç¢ºè­å¥ä¸¦é æ¸¬ Reddit çè¨åè¦å°ä¸­çåæ­§ãæåçæ¨¡åå°åæ­§åçºä¸é¡ï¼åæãä¸åæåä¸­ç«ãééå©ç¨ Reddit çè¨åè¦å°çå§å¨åå½¢çµæ§ï¼æ­¤æ¨¡åè½å¤§å¹è¶è¶ç¾æåºæºï¼ææè¤éçäºåæ¨¡å¼åæç·åæãéé ç ç©¶æ¨åäºåºæ¼åå½¢ç NLP æ¹æ³ï¼ä¸¦çºæ°£åç§å­¸æºéä¸­çæ¿ç­å¶å®èåæè²å·¥ä½èæä¾å¯è¡çè¦è§£ã

##### **Graph-Based Captioning: Enhancing Visual Descriptions by Interconnecting Region Captions**
2407.06723v1 by Yu-Guan Hsieh, Cheng-Yu Hsieh, Shih-Ying Yeh, Louis BÃ©thune, Hadi Pour Ansari, Pavan Kumar Anasosalu Vasu, Chun-Liang Li, Ranjay Krishna, Oncel Tuzel, Marco Cuturi

Humans describe complex scenes with compositionality, using simple text
descriptions enriched with links and relationships. While vision-language
research has aimed to develop models with compositional understanding
capabilities, this is not reflected yet in existing datasets which, for the
most part, still use plain text to describe images. In this work, we propose a
new annotation strategy, graph-based captioning (GBC) that describes an image
using a labelled graph structure, with nodes of various types. The nodes in GBC
are created using, in a first stage, object detection and dense captioning
tools nested recursively to uncover and describe entity nodes, further linked
together in a second stage by highlighting, using new types of nodes,
compositions and relations among entities. Since all GBC nodes hold plain text
descriptions, GBC retains the flexibility found in natural language, but can
also encode hierarchical information in its edges. We demonstrate that GBC can
be produced automatically, using off-the-shelf multimodal LLMs and
open-vocabulary detection models, by building a new dataset, GBC10M, gathering
GBC annotations for about 10M images of the CC12M dataset. We use GBC10M to
showcase the wealth of node captions uncovered by GBC, as measured with CLIP
training. We show that using GBC nodes' annotations -- notably those stored in
composition and relation nodes -- results in significant performance boost on
downstream models when compared to other dataset formats. To further explore
the opportunities provided by GBC, we also propose a new attention mechanism
that can leverage the entire GBC graph, with encouraging experimental results
that show the extra benefits of incorporating the graph structure. Our datasets
are released at \url{https://huggingface.co/graph-based-captions}.

æè¦ï¼<paragraph>äººé¡ä½¿ç¨ç°¡å®çæå­æè¿°ï¼è±å¯çé£çµåéä¿ï¼ä¾æè¿°è¤éçå ´æ¯ãéç¶è¦è¦ºèªè¨çç ç©¶æ¨å¨éç¼å·æçµåçè§£è½åçæ¨¡åï¼ä½ç¾æçæ¸æéå°æªåæ éä¸é»ï¼éäºæ¸æéå¨å¾å¤§ç¨åº¦ä¸ä»ä½¿ç¨ç´ææ¬ä¾æè¿°ååãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°çè¨»éç­ç¥ï¼åºæ¼åè¡¨çæ¨é¡ (GBC)ï¼å®ä½¿ç¨æ¨ç±¤åè¡¨çµæ§ä¾æè¿°ååï¼å¶ä¸­åå«åç¨®é¡åçç¯é»ãGBC ä¸­çç¯é»æ¯ä½¿ç¨ç©é«æª¢æ¸¬åå¯éæ¨é¡å·¥å·å¨ç¬¬ä¸éæ®µåµå»ºçï¼ä»¥éè¿´åµå¥çæ¹å¼ç¼ç¾åæè¿°å¯¦é«ç¯é»ï¼ä¸¦å¨ç¬¬äºéæ®µä½¿ç¨æ°é¡åçç¯é»çªåºé¡¯ç¤ºï¼å¾èå°å®åé²ä¸æ­¥é£çµå¨ä¸èµ·ï¼å¯¦é«ä¹éççµååéä¿ãç±æ¼ææ GBC ç¯é»é½åå«ç´ææ¬æè¿°ï¼å æ­¤ GBC ä¿çäºèªç¶èªè¨ä¸­çéæ´»æ§ï¼ä½ä¹å¯ä»¥å¨å¶éç·£ç·¨ç¢¼åå±¤ä¿¡æ¯ãæåè­æäº GBC å¯ä»¥ä½¿ç¨ç¾æçå¤æ¨¡æ LLM åéæ¾è©å½æª¢æ¸¬æ¨¡åèªåçæï¼ééæ§å»ºä¸åæ°çæ¸æé GBC10Mï¼æ¶éäºå¤§ç´ 10M CC12M æ¸æéååç GBC è¨»éãæåä½¿ç¨ GBC10M ä¾å±ç¤º GBC ç¼ç¾çè±å¯ç¯é»æ¨é¡ï¼ä¸¦ä½¿ç¨ CLIP è¨ç·´é²è¡æ¸¬éãæåè¡¨æï¼èå¶ä»æ¸æéæ ¼å¼ç¸æ¯ï¼ä½¿ç¨ GBC ç¯é»çè¨»éââç¹å¥æ¯å­å²å¨çµååéä¿ç¯é»ä¸­çè¨»éââæé¡¯èæåä¸æ¸¸æ¨¡åçæ§è½ãçºäºé²ä¸æ­¥æ¢ç´¢ GBC æä¾çæ©æï¼æåéæåºäºä¸ç¨®æ°çæ³¨ææ©å¶ï¼å®å¯ä»¥å©ç¨æ´å GBC åè¡¨ï¼ä¸¦ééé¼åµæ§çå¯¦é©çµæå±ç¤ºäºçµååè¡¨çµæ§çé¡å¤å¥½èãæåçæ¸æéç¼å¸å¨ \url{https://huggingface.co/graph-based-captions}ã</paragraph>

##### **Combining Knowledge Graphs and Large Language Models**
2407.06564v1 by Amanda Kau, Xuzeng He, Aishwarya Nambissan, Aland Astudillo, Hui Yin, Amir Aryani

In recent years, Natural Language Processing (NLP) has played a significant
role in various Artificial Intelligence (AI) applications such as chatbots,
text generation, and language translation. The emergence of large language
models (LLMs) has greatly improved the performance of these applications,
showing astonishing results in language understanding and generation. However,
they still show some disadvantages, such as hallucinations and lack of
domain-specific knowledge, that affect their performance in real-world tasks.
These issues can be effectively mitigated by incorporating knowledge graphs
(KGs), which organise information in structured formats that capture
relationships between entities in a versatile and interpretable fashion.
Likewise, the construction and validation of KGs present challenges that LLMs
can help resolve. The complementary relationship between LLMs and KGs has led
to a trend that combines these technologies to achieve trustworthy results.
This work collected 28 papers outlining methods for KG-powered LLMs, LLM-based
KGs, and LLM-KG hybrid approaches. We systematically analysed and compared
these approaches to provide a comprehensive overview highlighting key trends,
innovative techniques, and common challenges. This synthesis will benefit
researchers new to the field and those seeking to deepen their understanding of
how KGs and LLMs can be effectively combined to enhance AI applications
capabilities.

æè¦ï¼è¿å¹´æ¥ï¼èªç¶è¯­è¨å¤ç (NLP) å¨åç§äººå·¥æºè½ (AI) åºç¨ä¸­åæ¥äºéè¦ä½ç¨ï¼ä¾å¦èå¤©æºå¨äººãææ¬çæåè¯­è¨ç¿»è¯ãå¤§è¯­è¨æ¨¡å (LLM) çåºç°æå¤§å°æé«äºè¿äºåºç¨ç¨åºçæ§è½ï¼å¨è¯­è¨çè§£åçææ¹é¢æ¾ç¤ºåºæäººçç»æãç¶èï¼å®ä»¬ä»ç¶è¡¨ç°åºä¸äºç¼ºç¹ï¼ä¾å¦å¹»è§åç¼ºä¹ç¹å®é¢åçç¥è¯ï¼è¿äºç¼ºç¹ä¼å½±åå®ä»¬å¨ç°å®ä¸çä¸­çä»»å¡ä¸­çè¡¨ç°ãéè¿çº³å¥ç¥è¯å¾è°± (KG) å¯ä»¥ææå°åè½»è¿äºé®é¢ï¼ç¥è¯å¾è°±ä»¥ç»æåæ ¼å¼ç»ç»ä¿¡æ¯ï¼ä»¥å¤åè½ä¸å¯è§£éçæ¹å¼æè·å®ä½ä¹é´çå³ç³»ãåæ ·ï¼KG çæå»ºåéªè¯æåºäº LLM å¯ä»¥å¸®å©è§£å³çææãLLM å KG ä¹é´çäºè¡¥å³ç³»å¯¼è´äºä¸ç§å°è¿äºææ¯ç¸ç»åä»¥å®ç°å¯ä¿¡ç»æçè¶å¿ãè¿é¡¹å·¥ä½æ¶éäº 28 ç¯æ¦è¿°äº KG é©±å¨ç LLMãåºäº LLM ç KG å LLM-KG æ··åæ¹æ³çæ¹æ³çè®ºæãæä»¬ç³»ç»å°åæåæ¯è¾äºè¿äºæ¹æ³ï¼ä»¥æä¾ä¸ä¸ªå¨é¢çæ¦è¿°ï¼éç¹ä»ç»å³é®è¶å¿ãåæ°ææ¯åå±åææãè¿ç§ç»¼åå°ä½¿è¯¥é¢åçæ°ç ç©¶äººååé£äºå¯»æ±å æ·±å¯¹å¦ä½ææå°å° KG å LLM ç¸ç»åä»¥å¢å¼º AI åºç¨è½åççè§£çäººåçã

##### **MST5 -- Multilingual Question Answering over Knowledge Graphs**
2407.06041v1 by Nikit Srivastava, Mengshi Ma, Daniel Vollmers, Hamada Zahera, Diego Moussallem, Axel-Cyrille Ngonga Ngomo

Knowledge Graph Question Answering (KGQA) simplifies querying vast amounts of
knowledge stored in a graph-based model using natural language. However, the
research has largely concentrated on English, putting non-English speakers at a
disadvantage. Meanwhile, existing multilingual KGQA systems face challenges in
achieving performance comparable to English systems, highlighting the
difficulty of generating SPARQL queries from diverse languages. In this
research, we propose a simplified approach to enhance multilingual KGQA systems
by incorporating linguistic context and entity information directly into the
processing pipeline of a language model. Unlike existing methods that rely on
separate encoders for integrating auxiliary information, our strategy leverages
a single, pretrained multilingual transformer-based language model to manage
both the primary input and the auxiliary data. Our methodology significantly
improves the language model's ability to accurately convert a natural language
query into a relevant SPARQL query. It demonstrates promising results on the
most recent QALD datasets, namely QALD-9-Plus and QALD-10. Furthermore, we
introduce and evaluate our approach on Chinese and Japanese, thereby expanding
the language diversity of the existing datasets.

æè¦ï¼ç¥è­åè¡¨åç­ (KGQA) ç°¡åäºä½¿ç¨èªç¶èªè¨æ¥è©¢å²å­å¨åå½¢åæ¨¡åä¸­çå¤§éç¥è­ãç¶èï¼ç ç©¶ä¸»è¦éä¸­å¨è±æä¸ï¼éå°éè±èªä½¿ç¨èä¾èªªæ¯ä¸å©çãåæï¼ç¾æçå¤èªè¨ KGQA ç³»çµ±å¨éæèè±æç³»çµ±ç¸åª²ç¾çæè½æ¹é¢é¢è¨ææ°ï¼çªé¡¯äºå¾ä¸åèªè¨ç¢ç SPARQL æ¥è©¢çå°é£æ§ãå¨éé ç ç©¶ä¸­ï¼æåæåºäºä¸ç¨®ç°¡åçæ¹æ³ï¼ééå°èªè¨å­¸èæ¯åå¯¦é«è³è¨ç´æ¥ç´å¥èªè¨æ¨¡åçèçç®¡éï¼ä¾å¢å¼·å¤èªè¨ KGQA ç³»çµ±ãèä¾è³´æ¼å®ç¨ç·¨ç¢¼å¨ä¾æ´åè¼å©è³è¨çç¾ææ¹æ³ä¸åï¼æåçç­ç¥å©ç¨å®ä¸çãé è¨ç·´çå¤èªè¨è½æå¨èªè¨æ¨¡åä¾ç®¡çä¸»è¦è¼¸å¥åè¼å©è³æãæåçæè¡é¡¯èæåäºèªè¨æ¨¡åæºç¢ºå°å°èªç¶èªè¨æ¥è©¢è½æçºç¸é SPARQL æ¥è©¢çè½åãå®å¨ææ°ç QALD è³æéï¼å³ QALD-9-Plus å QALD-10 ä¸å±ç¤ºäºæå¸æççµæãæ­¤å¤ï¼æåå¨ä¸­æåæ¥æä¸­å¼å¥ä¸¦è©ä¼°äºæåçåæ³ï¼å¾èæ´å±äºç¾æè³æéçèªè¨å¤æ¨£æ§ã

##### **Enhancing Vision-Language Models with Scene Graphs for Traffic Accident Understanding**
2407.05910v1 by Aaron Lohner, Francesco Compagno, Jonathan Francis, Alessandro Oltramari

Recognizing a traffic accident is an essential part of any autonomous driving
or road monitoring system. An accident can appear in a wide variety of forms,
and understanding what type of accident is taking place may be useful to
prevent it from reoccurring. The task of being able to classify a traffic scene
as a specific type of accident is the focus of this work. We approach the
problem by likening a traffic scene to a graph, where objects such as cars can
be represented as nodes, and relative distances and directions between them as
edges. This representation of an accident can be referred to as a scene graph,
and is used as input for an accident classifier. Better results can be obtained
with a classifier that fuses the scene graph input with representations from
vision and language. This work introduces a multi-stage, multimodal pipeline to
pre-process videos of traffic accidents, encode them as scene graphs, and align
this representation with vision and language modalities for accident
classification. When trained on 4 classes, our method achieves a balanced
accuracy score of 57.77% on an (unbalanced) subset of the popular Detection of
Traffic Anomaly (DoTA) benchmark, representing an increase of close to 5
percentage points from the case where scene graph information is not taken into
account.

æè¦ï¼è¾¨è­äº¤éäºææ¯ä»»ä½èªåé§é§æéè·¯ç£æ§ç³»çµ±çå¿è¦é¨åãäºæå¯è½ä»¥åç¨®å½¢å¼åºç¾ï¼äºè§£äºæé¡åå¯è½æå©æ¼é²æ­¢åæ¬¡ç¼çãå°äº¤éäºæå ´æ¯åé¡çºç¹å®äºæé¡åçä»»åæ¯éé å·¥ä½çéé»ãæåå°äº¤éäºæå ´æ¯æ¯å»çºåå½¢ä¾è§£æ±ºåé¡ï¼å¶ä¸­æ±½è»ç­ç©é«å¯ä»¥è¡¨ç¤ºçºç¯é»ï¼èå®åä¹éçç¸å°è·é¢åæ¹ååè¡¨ç¤ºçºéç·£ãéç¨®äºæè¡¨ç¤ºå¯ä»¥ç¨±çºå ´æ¯åï¼ä¸¦ç¨ä½äºæåé¡å¨çè¼¸å¥ãä½¿ç¨å°å ´æ¯åè¼¸å¥èè¦è¦ºåèªè¨è¡¨ç¤ºèåçåé¡å¨å¯ä»¥ç²å¾æ´å¥½ççµæãéé å·¥ä½å¼å¥äºä¸åå¤éæ®µãå¤æ¨¡æç®¡éï¼ç¨æ¼é èçäº¤éäºæå½±çãå°å¶ç·¨ç¢¼çºå ´æ¯åï¼ä»¥åå°æ­¤è¡¨ç¤ºèè¦è¦ºåèªè¨æ¨¡å¼å°é½ä»¥é²è¡äºæåé¡ãç¶å¨ 4 åé¡å¥ä¸é²è¡è¨ç·´æï¼æåçæ¨¡åå¨ç±éäº¤éç°å¸¸æª¢æ¸¬ (DoTA) åºæºçï¼ä¸å¹³è¡¡ï¼å­éä¸å¯¦ç¾äº 57.77% çå¹³è¡¡æºç¢ºçï¼æ¯ä¸èæ®å ´æ¯åè³è¨çææ³æé«äºæ¥è¿ 5 åç¾åé»ã

##### **Affordances-Oriented Planning using Foundation Models for Continuous Vision-Language Navigation**
2407.05890v1 by Jiaqi Chen, Bingqian Lin, Xinmin Liu, Xiaodan Liang, Kwan-Yee K. Wong

LLM-based agents have demonstrated impressive zero-shot performance in the
vision-language navigation (VLN) task. However, these zero-shot methods focus
only on solving high-level task planning by selecting nodes in predefined
navigation graphs for movements, overlooking low-level control in realistic
navigation scenarios. To bridge this gap, we propose AO-Planner, a novel
affordances-oriented planning framework for continuous VLN task. Our AO-Planner
integrates various foundation models to achieve affordances-oriented motion
planning and action decision-making, both performed in a zero-shot manner.
Specifically, we employ a visual affordances prompting (VAP) approach, where
visible ground is segmented utilizing SAM to provide navigational affordances,
based on which the LLM selects potential next waypoints and generates low-level
path planning towards selected waypoints. We further introduce a high-level
agent, PathAgent, to identify the most probable pixel-based path and convert it
into 3D coordinates to fulfill low-level motion. Experimental results on the
challenging R2R-CE benchmark demonstrate that AO-Planner achieves
state-of-the-art zero-shot performance (5.5% improvement in SPL). Our method
establishes an effective connection between LLM and 3D world to circumvent the
difficulty of directly predicting world coordinates, presenting novel prospects
for employing foundation models in low-level motion control.

æè¦ï¼åºæ¼ LLM çä»£çå·²å¨è¦è¦ºèªè¨å°èª (VLN) ä»»åä¸­å±ç¤ºåºä»¤äººå°è±¡æ·±å»çé¶æ¬¡å­¸ç¿æè½ãç¶èï¼éäºé¶æ¬¡å­¸ç¿æ¹æ³åå°æ³¨æ¼ééé¸æé å®ç¾©å°èªåå½¢ä¸­çç¯é»ä¾è§£æ±ºé«éä»»åè¦åï¼å¿½ç¥äºå¯¦éå°èªå ´æ¯ä¸­çä½éæ§å¶ãçºäºå½åæ­¤å·®è·ï¼æåæåº AO-Plannerï¼ä¸åç¨æ¼é£çº VLN ä»»åçæ°åä»¥å¯è² ææ§çºå°åçè¦åæ¶æ§ãæåç AO-Planner æ´ååç¨®åºç¤æ¨¡åï¼ä»¥å¯¦ç¾ä»¥å¯è² ææ§çºå°åçåä½è¦åååä½æ±ºç­ï¼å©èé½ä»¥é¶æ¬¡å­¸ç¿çæ¹å¼å·è¡ãå·é«ä¾èªªï¼æåæ¡ç¨è¦è¦ºå¯è² ææ§æç¤º (VAP) æ¹æ³ï¼å¶ä¸­å©ç¨ SAM å°å¯è¦å°é¢é²è¡åå²ï¼ä»¥æä¾å°èªå¯è² ææ§ï¼LLM æ ¹æéäºå¯è² ææ§é¸ææ½å¨çä¸ä¸åèªé»ï¼ä¸¦éå°æé¸èªé»ç¢çä½éè·¯å¾è¦åãæåé²ä¸æ­¥å¼å¥ä¸åé«éä»£ç PathAgentï¼ä»¥è­å¥æå¯è½çåºæ¼åç´ çè·¯å¾ï¼ä¸¦å°å¶è½æçº 3D åº§æ¨ï¼ä»¥å¯¦ç¾ä½éåä½ãå¨å·æææ°æ§ç R2R-CE åºæºæ¸¬è©¦ä¸çå¯¦é©çµæè¡¨æï¼AO-Planner éå°äºæåé²çé¶æ¬¡å­¸ç¿æè½ï¼SPL æå 5.5%ï¼ãæåçæ¨¡åå¨ LLM å 3D ä¸çä¹éå»ºç«äºä¸åææçé£çµï¼ä»¥è¦é¿ç´æ¥é æ¸¬ä¸çåº§æ¨çé£é¡ï¼çºå¨ä½éåä½æ§å¶ä¸­æ¡ç¨åºç¤æ¨¡åæä¾äºæ°çåæ¯ã

##### **KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions**
2407.05868v1 by Yanxu Zhu, Jinlin Xiao, Yuhang Wang, Jitao Sang

Recent studies have demonstrated that large language models (LLMs) are
susceptible to being misled by false premise questions (FPQs), leading to
errors in factual knowledge, know as factuality hallucination. Existing
benchmarks that assess this vulnerability primarily rely on manual
construction, resulting in limited scale and lack of scalability. In this work,
we introduce an automated, scalable pipeline to create FPQs based on knowledge
graphs (KGs). The first step is modifying true triplets extracted from KGs to
create false premises. Subsequently, utilizing the state-of-the-art
capabilities of GPTs, we generate semantically rich FPQs. Based on the proposed
method, we present a comprehensive benchmark, the Knowledge Graph-based False
Premise Questions (KG-FPQ), which contains approximately 178k FPQs across three
knowledge domains, at six levels of confusability, and in two task formats.
Using KG-FPQ, we conduct extensive evaluations on several representative LLMs
and provide valuable insights. The KG-FPQ dataset and code are available
at~https://github.com/yanxuzhu/KG-FPQ.

æè¦ï¼æè¿çç ç©¶è¡¨æï¼å¤§åè¯­è¨æ¨¡å (LLM) å®¹æè¢«éè¯¯åæé®é¢ (FPQ) è¯¯å¯¼ï¼ä»èå¯¼è´äºå®ç¥è¯éè¯¯ï¼å³äºå®å¹»è§ãç¨äºè¯ä¼°æ­¤æ¼æ´çç°æåºåä¸»è¦ä¾èµäºæå¨æå»ºï¼å¯¼è´è§æ¨¡æéä¸ç¼ºä¹å¯æ©å±æ§ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å¼å¥äºä¸ä¸ªåºäºç¥è¯å¾è°± (KG) åå»º FPQ çèªå¨åå¯æ©å±ç®¡éãç¬¬ä¸æ­¥æ¯ä¿®æ¹ä» KG ä¸­æåççä¸åç»ä»¥åå»ºéè¯¯åæãéåï¼å©ç¨ GPT çæåè¿åè½ï¼æä»¬çæäºè¯­ä¹ä¸°å¯ç FPQãåºäºææåºçæ¹æ³ï¼æä»¬æåºäºä¸ä¸ªç»¼ååºåï¼å³åºäºç¥è¯å¾è°±çéè¯¯åæé®é¢ (KG-FPQ)ï¼å®åå«å¤§çº¦ 178k ä¸ª FPQï¼æ¶µçä¸ä¸ªç¥è¯åï¼å­ä¸ªæ··æ·çº§å«åä¸¤ç§ä»»å¡æ ¼å¼ãä½¿ç¨ KG-FPQï¼æä»¬å¯¹å ä¸ªæä»£è¡¨æ§ç LLM è¿è¡äºå¹¿æ³çè¯ä¼°ï¼å¹¶æä¾äºæä»·å¼çè§è§£ãKG-FPQ æ°æ®éåä»£ç å¯å¨~https://github.com/yanxuzhu/KG-FPQ è·å¾ã

##### **Language Models Encode Collaborative Signals in Recommendation**
2407.05441v1 by Leheng Sheng, An Zhang, Yi Zhang, Yuxin Chen, Xiang Wang, Tat-Seng Chua

Recent studies empirically indicate that language models (LMs) encode rich
world knowledge beyond mere semantics, attracting significant attention across
various fields. However, in the recommendation domain, it remains uncertain
whether LMs implicitly encode user preference information. Contrary to the
prevailing understanding that LMs and traditional recommender models learn two
distinct representation spaces due to a huge gap in language and behavior
modeling objectives, this work rethinks such understanding and explores
extracting a recommendation space directly from the language representation
space. Surprisingly, our findings demonstrate that item representations, when
linearly mapped from advanced LM representations, yield superior recommendation
performance. This outcome suggests the homomorphism between the language
representation space and an effective recommendation space, implying that
collaborative signals may indeed be encoded within advanced LMs. Motivated by
these findings, we propose a simple yet effective collaborative filtering (CF)
model named AlphaRec, which utilizes language representations of item textual
metadata (e.g., titles) instead of traditional ID-based embeddings.
Specifically, AlphaRec is comprised of three main components: a multilayer
perceptron (MLP), graph convolution, and contrastive learning (CL) loss
function, making it extremely easy to implement and train. Our empirical
results show that AlphaRec outperforms leading ID-based CF models on multiple
datasets, marking the first instance of such a recommender with text embeddings
achieving this level of performance. Moreover, AlphaRec introduces a new
language-representation-based CF paradigm with several desirable advantages:
being easy to implement, lightweight, rapid convergence, superior zero-shot
recommendation abilities in new domains, and being aware of user intention.

æè¦ï¼<paragraph>æè¿çç ç©¶å¯¦è­è¡¨æï¼èªè¨æ¨¡å (LM) ç·¨ç¢¼è±å¯çä¸çç¥è­ï¼è¶è¶äºå®ç´çèªç¾©ï¼å¸å¼äºååé åçæ¥µå¤§éæ³¨ãç¶èï¼å¨æ¨è¦é åä¸­ï¼LM æ¯å¦é±å«ç·¨ç¢¼ä½¿ç¨èåå¥½è³è¨ä»ä¸ç¢ºå®ãèæ®éèªç¥ç¸åï¼LM åå³çµ±æ¨è¦æ¨¡åç±æ¼èªè¨åè¡çºå»ºæ¨¡ç®æ¨çå·¨å¤§å·®è·èå­¸ç¿å©åä¸åçè¡¨ç¤ºç©ºéï¼éé å·¥ä½éæ°æèéç¨®çè§£ï¼ä¸¦æ¢ç´¢ç´æ¥å¾èªè¨è¡¨ç¤ºç©ºéä¸­æåæ¨è¦ç©ºéãä»¤äººé©è¨çæ¯ï¼æåçç ç©¶çµæè¡¨æï¼ç¶å¾åé²ç LM è¡¨ç¤ºä¸­ç·æ§æ å°æï¼é ç®è¡¨ç¤ºæç¢çåªç°çæ¨è¦æè½ãæ­¤çµæè¡¨æèªè¨è¡¨ç¤ºç©ºéåææçæ¨è¦ç©ºéä¹éå­å¨åææ§ï¼éæå³èåä½è¨èç¢ºå¯¦å¯è½ç·¨ç¢¼å¨åé²ç LM ä¸­ãåéäºç ç©¶çµæçåç¼ï¼æåæåºäºä¸åç°¡å®ä½ææçååéæ¿¾ (CF) æ¨¡åï¼åçº AlphaRecï¼å®å©ç¨é ç®æå­åè³æï¼ä¾å¦æ¨é¡ï¼çèªè¨è¡¨ç¤ºï¼èä¸æ¯å³çµ±åºæ¼ ID çåµå¥ãå·é«ä¾èªªï¼AlphaRec ç±ä¸åä¸»è¦çµæé¨åçµæï¼å¤å±¤æç¥å¨ (MLP)ãåå½¢å·ç©åå°æ¯å­¸ç¿ (CL) æå¤±å½æ¸ï¼ä½¿å¶æ¥µææ¼å¯¦ä½åè¨ç·´ãæåçå¯¦è­çµæè¡¨æï¼AlphaRec å¨å¤åè³æéä¸åªæ¼é åçåºæ¼ ID ç CF æ¨¡åï¼æ¨èªèéç¨®å·ææå­åµå¥çæ¨è¦ç³»çµ±é¦æ¬¡éå°æ­¤æè½æ°´æºãæ­¤å¤ï¼AlphaRec å¼å¥äºä¸åæ°çåºæ¼èªè¨è¡¨ç¤ºç CF å¸ç¯ï¼å·æå¤é çæ³çåªé»ï¼ææ¼å¯¦ä½ãè¼éç´ãå¿«éæ¶æãå¨æ°çé åä¸­å·æåªç°çé¶æ¬¡å­¸ç¿æ¨è¦è½åï¼ä¸¦ä¸å¯ä»¥äºè§£ä½¿ç¨èçæåã</paragraph>

##### **LTLBench: Towards Benchmarks for Evaluating Temporal Logic Reasoning in Large Language Models**
2407.05434v1 by Weizhi Tang, Vaishak Belle

Temporal reasoning (TR) is a critical component of artificial intelligence,
encompassing understanding and processing temporal information and
relationships between events. To discover and study the TR ability in Large
Language Models (LLMs), various datasets have been constructed in different
ways for evaluating various aspects of TR ability. Our work proposes a novel
approach to design and develop a pipeline for constructing datasets to evaluate
the TR ability of LLMs by leveraging random directed graph generation, LTL
formula, and the NuSMV model checker. Based on the pipeline, we have also
constructed a dataset as a benchmark, namely LTLBench, consisting of 2,000 TR
challenges and evaluated six LLMs with it. Furthermore, we have conducted
additional experiments to discover the impact of increasing the number of
events and formula operators on the complexity of TR problems and the
performance of LLMs. We have demonstrated that although LLMs exhibit some
promise in handling TR challenges, they still struggle with complex TR. We
expect this work can offer insights into TR ability in LLMs while also
providing a valuable tool for future TR evaluations.

æè¦ï¼æéæ¨ç (TR) æ¯äººå·¥æºæ§çä¸é ééµçµæé¨åï¼
æ¶µèäºå°æéè³è¨åäºä»¶ä¹ééä¿ççè§£åèçãçºäºç¼ç¾åç ç©¶å¤§åèªè¨æ¨¡å (LLM) ä¸­ç TR è½åï¼å·²ééåç¨®æ¹å¼å»ºæ§åç¨®è³æéï¼ç¨æ¼è©ä¼° TR è½åçååé¢åãæåçå·¥ä½æåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼ç¨æ¼è¨­è¨åéç¼ä¸åå»ºæ§è³æéçç®¡éï¼ä»¥è©ä¼° LLM ç TR è½åï¼æ¹æ³æ¯å©ç¨é¨æ©æååçæãLTL å¬å¼å NuSMV æ¨¡åæª¢æ¥å¨ãæ ¹æéåç®¡éï¼æåéå»ºæ§äºä¸åè³æéä½çºåºæºï¼å³ LTLBenchï¼å¶ä¸­åå« 2,000 å TR ææ°ï¼ä¸¦ç¨å®è©ä¼°äºå­å LLMãæ­¤å¤ï¼æåéé²è¡äºé¡å¤çå¯¦é©ï¼ä»¥ç¼ç¾å¢å äºä»¶æ¸éåå¬å¼éç®å­å° TR åé¡è¤éæ§å LLM æè½çå½±é¿ãæåå·²ç¶è­æï¼åç®¡ LLM å¨èç TR ææ°æ¹é¢è¡¨ç¾åºä¸äºå¸æï¼ä½å®åä»ç¶é£ä»¥èçè¤éç TRãæåé æéé å·¥ä½å¯ä»¥æä¾å° LLM ä¸­ TR è½åçè¦è§£ï¼åæä¹çºæªä¾ç TR è©ä¼°æä¾ä¸åæå¹å¼çå·¥å·ã

##### **Leveraging Graph Structures to Detect Hallucinations in Large Language Models**
2407.04485v1 by Noa Nonkes, Sergei Agaronian, Evangelos Kanoulas, Roxana Petcu

Large language models are extensively applied across a wide range of tasks,
such as customer support, content creation, educational tutoring, and providing
financial guidance. However, a well-known drawback is their predisposition to
generate hallucinations. This damages the trustworthiness of the information
these models provide, impacting decision-making and user confidence. We propose
a method to detect hallucinations by looking at the structure of the latent
space and finding associations within hallucinated and non-hallucinated
generations. We create a graph structure that connects generations that lie
closely in the embedding space. Moreover, we employ a Graph Attention Network
which utilizes message passing to aggregate information from neighboring nodes
and assigns varying degrees of importance to each neighbor based on their
relevance. Our findings show that 1) there exists a structure in the latent
space that differentiates between hallucinated and non-hallucinated
generations, 2) Graph Attention Networks can learn this structure and
generalize it to unseen generations, and 3) the robustness of our method is
enhanced when incorporating contrastive learning. When evaluated against
evidence-based benchmarks, our model performs similarly without access to
search-based methods.

æè¦ï¼å¤§åèªè¨æ¨¡åå»£æ³æç¨æ¼åç¨®ä»»åä¸­ï¼ä¾å¦å®¢æ¶æ¯æ´ãå§å®¹åµä½ãæè²è¼å°åæä¾è²¡åæå°ãç¶èï¼ä¸åç¾æå¨ç¥çç¼ºé»æ¯å®åå¾åæ¼ç¢çå¹»è¦ºãéæå®³äºéäºæ¨¡åææä¾è³è¨çå¯ä¿¡åº¦ï¼å½±é¿äºæ±ºç­å¶å®åä½¿ç¨èä¿¡å¿ãæåæåºäºä¸ç¨®ééè§å¯æ½å¨ç©ºéççµæ§ä¸¦æ¾åºå¹»è¦ºåéå¹»è¦ºçæä¸­çéè¯ä¾åµæ¸¬å¹»è¦ºçæ¹æ³ãæåå»ºç«äºä¸ååå½¢çµæ§ï¼é£æ¥å¨åµå¥ç©ºéä¸­ç·å¯ç¸é£ççæãæ­¤å¤ï¼æåæ¡ç¨äºä¸ååå½¢æ³¨æåç¶²è·¯ï¼å®å©ç¨è¨æ¯å³éä¾å½ç¸½ä¾èªç¸é°ç¯é»çè³è¨ï¼ä¸¦æ ¹ææ¯åç¸é°ç¯é»çç¸éæ§çºå¶æå®ä¸åç¨åº¦çéè¦æ§ãæåçç ç©¶çµæé¡¯ç¤ºï¼1) æ½å¨ç©ºéä¸­å­å¨ä¸åçµæ§ï¼å¯ä»¥ååå¹»è¦ºåéå¹»è¦ºçæï¼2) åå½¢æ³¨æåç¶²è·¯å¯ä»¥å­¸ç¿éåçµæ§ä¸¦å°å¶æ¦æ¬å°æªè¦ççæä¸­ï¼ä»¥å 3) ç¶ç´å¥å°æ¯å­¸ç¿æï¼æåæ¹æ³çç©©å¥æ§æå¾å°å¢å¼·ãç¶æ ¹æåºæ¼è­æçåºæºé²è¡è©ä¼°æï¼æåçæ¨¡åå¨ç¡æ³åå¾åºæ¼æå°çæ¹æ³çææ³ä¸ï¼è¡¨ç¾å¾é¡ä¼¼ã

##### **AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents**
2407.04363v1 by Petr Anokhin, Nikita Semenov, Artyom Sorokin, Dmitry Evseev, Mikhail Burtsev, Evgeny Burnaev

Advancements in generative AI have broadened the potential applications of
Large Language Models (LLMs) in the development of autonomous agents. Achieving
true autonomy requires accumulating and updating knowledge gained from
interactions with the environment and effectively utilizing it. Current
LLM-based approaches leverage past experiences using a full history of
observations, summarization or retrieval augmentation. However, these
unstructured memory representations do not facilitate the reasoning and
planning essential for complex decision-making. In our study, we introduce
AriGraph, a novel method wherein the agent constructs a memory graph that
integrates semantic and episodic memories while exploring the environment. This
graph structure facilitates efficient associative retrieval of interconnected
concepts, relevant to the agent's current state and goals, thus serving as an
effective environmental model that enhances the agent's exploratory and
planning capabilities. We demonstrate that our Ariadne LLM agent, equipped with
this proposed memory architecture augmented with planning and decision-making,
effectively handles complex tasks on a zero-shot basis in the TextWorld
environment. Our approach markedly outperforms established methods such as
full-history, summarization, and Retrieval-Augmented Generation in various
tasks, including the cooking challenge from the First TextWorld Problems
competition and novel tasks like house cleaning and puzzle Treasure Hunting.

æè¦ï¼çæå¼ AI çé²æ­¥æ´å±äºå¤§åèªè¨æ¨¡å (LLM) å¨èªä¸»ä»£çéç¼ä¸­çæ½å¨æç¨ãå¯¦ç¾çæ­£çèªä¸»æ§éè¦ç´¯ç©åæ´æ°å¾èç°å¢äºåä¸­ç²å¾çç¥è­ï¼ä¸¦ææå©ç¨å®ãç¶åçåºæ¼ LLM çæ¹æ³å©ç¨éå»çç¶é©ï¼ä½¿ç¨å®æ´çè§å¯ãæè¦ææª¢ç´¢æ´åãç¶èï¼éäºéçµæ§åçè¨æ¶è¡¨å¾µä¸¦ä¸è½ä¿é²è¤éæ±ºç­å¶å®ä¸­å¿ä¸å¯å°çæ¨çåè¦åãå¨æåçç ç©¶ä¸­ï¼æåä»ç´¹äº AriGraphï¼éæ¯ä¸ç¨®æ°æ¹æ³ï¼å¶ä¸­ä»£çæ§å»ºäºä¸åè¨æ¶åï¼è©²åå¨æ¢ç´¢ç°å¢ææ´åäºèªç¾©åæç¯è¨æ¶ãéç¨®åå½¢çµæ§ä¿é²äºç¸äºè¯ç¹«çæ¦å¿µçææéè¯æ§æª¢ç´¢ï¼èä»£ççç¶åçæåç®æ¨ç¸éï¼å¾èä½çºä¸åææçç°å¢æ¨¡åï¼å¢å¼·äºä»£ççæ¢ç´¢åè¦åè½åãæåå±ç¤ºäºæåç Ariadne LLM ä»£çï¼éåäºéç¨®æè­°çè¨æ¶æ¶æ§ï¼ä¸¦å¢å¼·äºè¦ååæ±ºç­å¶å®ï¼ææå°èçäº TextWorld ç°å¢ä¸­é¶æ¬¡å­¸ç¿çè¤éä»»åãæåçåæ³é¡¯èåªæ¼å·²å»ºç«çæ¹æ³ï¼ä¾å¦å®æ´æ­·å²ãæè¦åæª¢ç´¢å¢å¼·çæï¼å¨åç¨®ä»»åä¸­ï¼åæ¬ä¾èªç¬¬ä¸å TextWorld åé¡ç«¶è³½çç¹é£ªææ°åæ¿å±æ¸æ½åæ¼åå°å¯¶ç­æ°ä»»åã

##### **Semantic Graphs for Syntactic Simplification: A Revisit from the Age of LLM**
2407.04067v1 by Peiran Yao, Kostyantyn Guzhva, Denilson Barbosa

Symbolic sentence meaning representations, such as AMR (Abstract Meaning
Representation) provide expressive and structured semantic graphs that act as
intermediates that simplify downstream NLP tasks. However, the
instruction-following capability of large language models (LLMs) offers a
shortcut to effectively solve NLP tasks, questioning the utility of semantic
graphs. Meanwhile, recent work has also shown the difficulty of using meaning
representations merely as a helpful auxiliary for LLMs. We revisit the position
of semantic graphs in syntactic simplification, the task of simplifying
sentence structures while preserving their meaning, which requires semantic
understanding, and evaluate it on a new complex and natural dataset. The
AMR-based method that we propose, AMRS$^3$, demonstrates that state-of-the-art
meaning representations can lead to easy-to-implement simplification methods
with competitive performance and unique advantages in cost, interpretability,
and generalization. With AMRS$^3$ as an anchor, we discover that syntactic
simplification is a task where semantic graphs are helpful in LLM prompting. We
propose AMRCoC prompting that guides LLMs to emulate graph algorithms for
explicit symbolic reasoning on AMR graphs, and show its potential for improving
LLM on semantic-centered tasks like syntactic simplification.

æè¦ï¼ç¬¦èå¥å­æç¾©è¡¨å¾µï¼ä¾å¦ AMRï¼æ½è±¡æç¾©è¡¨å¾µï¼ï¼æä¾è¡¨éæ§åçµæ§åçèªç¾©åè¡¨ï¼ä½çºç°¡åä¸æ¸¸ NLP ä»»åçä¸­ä»ãç¶èï¼å¤§åèªè¨æ¨¡å (LLM) çæä»¤éµå¾ªè½åæä¾äºä¸åæ·å¾ä¾ææè§£æ±º NLP ä»»åï¼è³ªçèªç¾©åè¡¨çæç¨ãåæï¼æè¿çç ç©¶ä¹è¡¨æåå°æç¾©è¡¨å¾µç¨ä½ LLM çè¼å©å·¥å·çé£åº¦ãæåéæ°å¯©è¦èªç¾©åè¡¨å¨èªæ³ç°¡åä¸­çä½ç½®ï¼èªæ³ç°¡åçä»»åæ¯å¨ä¿çå¥å­çµæ§çåæç°¡åå¥å­çµæ§ï¼ééè¦èªç¾©çè§£ï¼ä¸¦å¨ä¸åæ°çè¤éä¸èªç¶çæ¸æéä¸å°å¶é²è¡è©ä¼°ãæåæåºçåºæ¼ AMR çæ¹æ³ AMRS$^3$ è­æäºæåé²çæç¾©è¡¨å¾µå¯ä»¥å°è´ææ¼å¯¦ç¾çç°¡åæ¹æ³ï¼å¨ææ¬ãå¯è§£éæ§åæ³åæ¹é¢å·æç«¶ç­åªå¢åç¨ç¹åªå¢ãä»¥ AMRS$^3$ çºé¨é»ï¼æåç¼ç¾èªæ³ç°¡åæ¯ä¸é èªç¾©åè¡¨æå©æ¼ LLM æç¤ºçä»»åãæåæåº AMRCoC æç¤ºï¼æå° LLM æ¨¡æ¬åå½¢æ¼ç®æ³ï¼å° AMR åå½¢é²è¡æç¢ºçç¬¦èæ¨çï¼ä¸¦å±ç¤ºå¶å¨æ¹é² LLM å¨ä»¥èªç¾©çºä¸­å¿çä»»åï¼å¦èªæ³ç°¡åï¼æ¹é¢çæ½åã

##### **Functional Faithfulness in the Wild: Circuit Discovery with Differentiable Computation Graph Pruning**
2407.03779v1 by Lei Yu, Jingcheng Niu, Zining Zhu, Gerald Penn

In this paper, we introduce a comprehensive reformulation of the task known
as Circuit Discovery, along with DiscoGP, a novel and effective algorithm based
on differentiable masking for discovering circuits. Circuit discovery is the
task of interpreting the computational mechanisms of language models (LMs) by
dissecting their functions and capabilities into sparse subnetworks (circuits).
We identified two major limitations in existing circuit discovery efforts: (1)
a dichotomy between weight-based and connection-edge-based approaches forces
researchers to choose between pruning connections or weights, thereby limiting
the scope of mechanistic interpretation of LMs; (2) algorithms based on
activation patching tend to identify circuits that are neither functionally
faithful nor complete. The performance of these identified circuits is
substantially reduced, often resulting in near-random performance in isolation.
Furthermore, the complement of the circuit -- i.e., the original LM with the
identified circuit removed -- still retains adequate performance, indicating
that essential components of a complete circuits are missed by existing
methods.
  DiscoGP successfully addresses the two aforementioned issues and demonstrates
state-of-the-art faithfulness, completeness, and sparsity. The effectiveness of
the algorithm and its novel structure open up new avenues of gathering new
insights into the internal workings of generative AI.

æè¦ï¼<paragraph>å¨æ¬æä¸­ï¼æåä»ç´¹äºå°ç¨±çºé»è·¯ç¼ç¾ä»»åçå¨é¢éæ°è¡¨è¿°ï¼ä»¥å DiscoGPï¼ä¸ç¨®åºæ¼å¯å¾®é®ç½©çç¼ç¾é»è·¯çæ°ç©ä¸ææçæ¼ç®æ³ãé»è·¯ç¼ç¾æ¯ééå°å¶åè½åè½åè§£åæç¨çå­ç¶²è·¯ï¼é»è·¯ï¼ä¾è©®éèªè¨æ¨¡åï¼LMï¼çéç®æ©å¶çä»»åãæåå¨ç¾æçé»è·¯ç¼ç¾å·¥ä½ä¸­ç¼ç¾äºå©åä¸»è¦çéå¶ï¼ï¼1ï¼åºæ¼æ¬éååºæ¼é£æ¥éç·£çæ¹æ³ä¹éçäºåæ³è¿«ä½¿ç ç©¶äººå¡å¨ä¿®åªé£æ¥ææ¬éä¹éé²è¡é¸æï¼å¾èéå¶äº LM æ©å¶è©®éçç¯åï¼ï¼2ï¼åºæ¼åç¨ä¿®è£çæ¼ç®æ³å¾åæ¼è­å¥å¨åè½ä¸æ¢ä¸å¿ å¯¦ä¹ä¸å®æ´çé»è·¯ãéäºå·²è­å¥é»è·¯çæè½å¤§å¹éä½ï¼éå¸¸å°è´å­¤ç«çè¿ä¹é¨æ©æè½ãæ­¤å¤ï¼é»è·¯çè£æ¸ââå³ç§»é¤å·²è­å¥é»è·¯çåå§ LMââä»ä¿çäºè¶³å¤ çæè½ï¼éè¡¨ç¤ºç¾ææ¹æ³é¯å¤±äºå®æ´é»è·¯çåºæ¬çµæé¨åã
DiscoGP æåå°è§£æ±ºäºä¸è¿°å©ååé¡ï¼ä¸¦å±ç¤ºäºæåé²çå¿ å¯¦åº¦ãå®æ´æ§åç¨çæ§ãè©²æ¼ç®æ³çæææ§åå¶æ°ç©ççµæ§çºæ·±å¥ç­è§£çæå¼ AI çå§é¨éä½éé¢äºæ°çéå¾ã</paragraph>

##### **BACON: Supercharge Your VLM with Bag-of-Concept Graph to Mitigate Hallucinations**
2407.03314v1 by Zhantao Yang, Ruili Feng, Keyu Yan, Huangji Wang, Zhicai Wang, Shangwen Zhu, Han Zhang, Jie Xiao, Pingyu Wu, Kai Zhu, Jixuan Chen, Chen-Wei Xie, Chaojie Mao, Yue Yang, Hongyang Zhang, Yu Liu, Fan Cheng

This paper presents Bag-of-Concept Graph (BACON) to gift models with limited
linguistic abilities to taste the privilege of Vision Language Models (VLMs)
and boost downstream tasks such as detection, visual question answering (VQA),
and image generation. Since the visual scenes in physical worlds are structured
with complex relations between objects, BACON breaks down annotations into
basic minimum elements and presents them in a graph structure. Element-wise
style enables easy understanding, and structural composition liberates
difficult locating. Careful prompt design births the BACON captions with the
help of public-available VLMs and segmentation methods. In this way, we gather
a dataset with 100K annotated images, which endow VLMs with remarkable
capabilities, such as accurately generating BACON, transforming prompts into
BACON format, envisioning scenarios in the style of BACONr, and dynamically
modifying elements within BACON through interactive dialogue and more. Wide
representative experiments, including detection, VQA, and image generation
tasks, tell BACON as a lifeline to achieve previous out-of-reach tasks or excel
in their current cutting-edge solutions.

æè¦ï¼æ¬ææåº Bag-of-Concept Graph (BACON)ï¼èµäºè¯­è¨è½åæéçæ¨¡ååå°è§è§è¯­è¨æ¨¡å (VLM) çç¹æï¼å¹¶æåä¸æ¸¸ä»»å¡ï¼ä¾å¦æ£æµãè§è§é®ç­ (VQA) åå¾åçæãç±äºç©çä¸çä¸­çè§è§åºæ¯æ¯ç±å¯¹è±¡ä¹é´çå¤æå³ç³»æå»ºèæçï¼å æ­¤ BACON å°æ³¨éåè§£ä¸ºåºæ¬çæå°åç´ ï¼å¹¶ä»¥å¾å½¢ç»æåç°å®ä»¬ãåºäºåç´ çé£æ ¼ä¾¿äºçè§£ï¼ç»æåç»åè§£æ¾äºå°é¾çå®ä½ãå¨å¬å±å¯ç¨ VLM ååå²æ¹æ³çå¸®å©ä¸ï¼ç²¾å¿è®¾è®¡çæç¤ºçæäº BACON æ é¢ãéè¿è¿ç§æ¹å¼ï¼æä»¬æ¶éäºä¸ä¸ªåå« 100K å¼ æ³¨éå¾åçæ°æ®éï¼è¯¥æ°æ®éèµäº VLM æ¾èçè½åï¼ä¾å¦åç¡®çæ BACONãå°æç¤ºè½¬æ¢ä¸º BACON æ ¼å¼ãä»¥ BACONr çé£æ ¼è®¾æ³åºæ¯ï¼ä»¥åéè¿äº¤äºå¼å¯¹è¯å¨æä¿®æ¹ BACON ä¸­çåç´ ç­ç­ãå¹¿æ³çä»£è¡¨æ§å®éªï¼åæ¬æ£æµãVQA åå¾åçæä»»å¡ï¼è¡¨æ BACON ä½ä¸ºä¸æ¡çå½çº¿ï¼å¯ä»¥å®ç°ä»¥åæ æ³å®ç°çä»»å¡ï¼æå¨å½åçå°ç«¯è§£å³æ¹æ¡ä¸­è¡¨ç°åºè²ã

##### **GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models**
2407.02936v1 by Zike Yuan, Ming Liu, Hui Wang, Bing Qin

Evaluating the graph comprehension and reasoning abilities of Large Language
Models (LLMs) is challenging and often incomplete. Existing benchmarks focus
primarily on pure graph understanding, lacking a comprehensive evaluation
across all graph types and detailed capability definitions. This paper presents
GraCoRe, a benchmark for systematically assessing LLMs' graph comprehension and
reasoning. GraCoRe uses a three-tier hierarchical taxonomy to categorize and
test models on pure graph and heterogeneous graphs, subdividing capabilities
into 10 distinct areas tested through 19 tasks. Our benchmark includes 11
datasets with 5,140 graphs of varying complexity. We evaluated three
closed-source and seven open-source LLMs, conducting thorough analyses from
both ability and task perspectives. Key findings reveal that semantic
enrichment enhances reasoning performance, node ordering impacts task success,
and the ability to process longer texts does not necessarily improve graph
comprehension or reasoning. GraCoRe is open-sourced at
https://github.com/ZIKEYUAN/GraCoRe

æè¦ï¼è©ä¼°å¤§åèªè¨æ¨¡å (LLM) çåå½¢çè§£åæ¨çè½åå·æææ°æ§ï¼ä¸éå¸¸ä¸å®æ´ãç¾æçåºæºä¸»è¦èéæ¼ç´ç²¹çåå½¢çè§£ï¼ç¼ºä¹å°ææåå½¢é¡ååè©³ç´°åè½å®ç¾©çå¨é¢è©ä¼°ãæ¬ææåºäº GraCoReï¼ä¸åç¨æ¼ç³»çµ±è©ä¼° LLM çåå½¢çè§£åæ¨ççåºæºãGraCoRe ä½¿ç¨ä¸å±¤éå±¤åé¡æ³å°æ¨¡åé²è¡åé¡åæ¸¬è©¦ï¼å°åè½ç´°åçº 10 åä¸åçé åï¼ä¸¦éé 19 åä»»åé²è¡æ¸¬è©¦ãæåçåºæºåå« 11 åæ¸æéï¼å¶ä¸­åå« 5,140 åä¸åè¤éåº¦çåå½¢ãæåè©ä¼°äºä¸åéæºåä¸åéæº LLMï¼å¾è½ååä»»åè§åº¦é²è¡äºå¾¹åºçåæãä¸»è¦ç¼ç¾è¡¨æèªç¾©è±å¯åå¢å¼·äºæ¨çæ§è½ï¼ç¯é»æåºå½±é¿ä»»åæåï¼èèçè¼é·ææ¬çè½åä¸¦ä¸ä¸å®è½æ¹ååå½¢çè§£ææ¨çãGraCoRe å¨ https://github.com/ZIKEYUAN/GraCoRe éæº

##### **Croppable Knowledge Graph Embedding**
2407.02779v1 by Yushan Zhu, Wen Zhang, Zhiqiang Liu, Mingyang Chen, Lei Liang, Huajun Chen

Knowledge Graph Embedding (KGE) is a common method for Knowledge Graphs (KGs)
to serve various artificial intelligence tasks. The suitable dimensions of the
embeddings depend on the storage and computing conditions of the specific
application scenarios. Once a new dimension is required, a new KGE model needs
to be trained from scratch, which greatly increases the training cost and
limits the efficiency and flexibility of KGE in serving various scenarios. In
this work, we propose a novel KGE training framework MED, through which we
could train once to get a croppable KGE model applicable to multiple scenarios
with different dimensional requirements, sub-models of the required dimensions
can be cropped out of it and used directly without any additional training. In
MED, we propose a mutual learning mechanism to improve the low-dimensional
sub-models performance and make the high-dimensional sub-models retain the
capacity that low-dimensional sub-models have, an evolutionary improvement
mechanism to promote the high-dimensional sub-models to master the knowledge
that the low-dimensional sub-models can not learn, and a dynamic loss weight to
balance the multiple losses adaptively. Experiments on 3 KGE models over 4
standard KG completion datasets, 3 real application scenarios over a real-world
large-scale KG, and the experiments of extending MED to the language model BERT
show the effectiveness, high efficiency, and flexible extensibility of MED.

æè¦ï¼ç¥è­ååµå¥ (KGE) æ¯ç¥è­å (KG) ç¨æ¼æååç¨®äººå·¥æºæ§ä»»åçå¸¸è¦æ¹æ³ãåµå¥çé©ç¶ç¶­åº¦åæ±ºæ¼ç¹å®æç¨å ´æ¯çå²å­åéç®æ¢ä»¶ãä¸æ¦éè¦æ°çç¶­åº¦ï¼å°±éè¦å¾é ­è¨ç·´æ°ç KGE æ¨¡åï¼éå¤§å¤§å¢å äºè¨ç·´ææ¬ï¼ä¸¦éå¶äº KGE å¨æååç¨®å ´æ¯ä¸­çæçåéæ´»æ§ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°ç©ç KGE è¨ç·´æ¡æ¶ MEDï¼ééå®ï¼æåå¯ä»¥è¨ç·´ä¸æ¬¡ä»¥ç²å¾é©ç¨æ¼å·æä¸åç¶­åº¦éæ±çå¤åå ´æ¯çå¯è£åª KGE æ¨¡åï¼å¯ä»¥å¾ä¸­è£åªåºæéç¶­åº¦çå­æ¨¡åä¸¦ç´æ¥ä½¿ç¨ï¼èç¡éä»»ä½é¡å¤è¨ç·´ãå¨ MED ä¸­ï¼æåæåºäºä¸ç¨®ç¸äºå­¸ç¿æ©å¶ï¼ä»¥æé«ä½ç¶­å­æ¨¡åçæè½ï¼ä¸¦ä½¿é«ç¶­å­æ¨¡åä¿çä½ç¶­å­æ¨¡åå·æçè½åï¼ä¸ç¨®é²åæ¹é²æ©å¶ï¼ä»¥ä¿é²é«ç¶­å­æ¨¡åææ¡ä½ç¶­å­æ¨¡åç¡æ³å­¸ç¿çç¥è­ï¼ä»¥åä¸ç¨®åææå¤±æ¬éï¼ä»¥èªé©æå°å¹³è¡¡å¤éæå¤±ãå¨ 4 åæ¨æº KG å®æè³æéä¸ç 3 å KGE æ¨¡åãä¸åçå¯¦ä¸çå¤§è¦æ¨¡ KG ä¸ç 3 åå¯¦éæç¨å ´æ¯ä»¥åå° MED æ´å±å°èªè¨æ¨¡å BERT çå¯¦é©ä¸­ï¼å±ç¤ºäº MED çæææ§ãé«æçåéæ´»çå¯æ´åæ§ã

##### **Reasoning in Large Language Models: A Geometric Perspective**
2407.02678v1 by Romain Cosentino, Sarath Shekkizhar

The advancement of large language models (LLMs) for real-world applications
hinges critically on enhancing their reasoning capabilities. In this work, we
explore the reasoning abilities of large language models (LLMs) through their
geometrical understanding. We establish a connection between the expressive
power of LLMs and the density of their self-attention graphs. Our analysis
demonstrates that the density of these graphs defines the intrinsic dimension
of the inputs to the MLP blocks. We demonstrate through theoretical analysis
and toy examples that a higher intrinsic dimension implies a greater expressive
capacity of the LLM. We further provide empirical evidence linking this
geometric framework to recent advancements in methods aimed at enhancing the
reasoning capabilities of LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨å¯¦éæç¨ä¸­çé²å±ï¼ééµå¨æ¼æåå¶æ¨çè½åãå¨éé å·¥ä½ä¸­ï¼æåééå¤§åèªè¨æ¨¡å (LLM) çå¹¾ä½çè§£ï¼æ¢è¨å¶æ¨çè½åãæåå»ºç«äº LLM çè¡¨éè½åèå¶èªæ³¨æååå¯åº¦ä¹éçéè¯ãæåçåæè­æï¼éäºåçå¯åº¦å®ç¾©äº MLP å¡è¼¸å¥çå§å¨ç¶­åº¦ãæåééçè«åæåç©å·ç¯ä¾è­æï¼è¼é«çå§å¨ç¶­åº¦æå³è LLM å·ææ´å¤§çè¡¨éè½åãæåé²ä¸æ­¥æä¾ç¶é©è­æï¼å°éåå¹¾ä½æ¡æ¶é£çµå°æè¿å¨æ¨å¨å¢å¼· LLM æ¨çè½åçæ¹æ³ä¸­åå¾çé²å±ã

##### **Ensuring Responsible Sourcing of Large Language Model Training Data Through Knowledge Graph Comparison**
2407.02659v1 by Devam Mondal, Carlo Lipizzi

In light of recent plagiarism allegations Brough by publishers, newspapers,
and other creators of copyrighted corpora against large language model (LLM)
developers, we propose a novel system, a variant of a plagiarism detection
system, that assesses whether a knowledge source has been used in the training
or fine-tuning of a large language model. Unlike current methods, we utilize an
approach that uses Resource Description Framework (RDF) triples to create
knowledge graphs from both a source document and a LLM continuation of that
document. These graphs are then analyzed with respect to content using cosine
similarity and with respect to structure using a normalized version of graph
edit distance that shows the degree of isomorphism. Unlike traditional systems
that focus on content matching and keyword identification between a source and
target corpus, our approach enables a broader evaluation of similarity and thus
a more accurate comparison of the similarity between a source document and LLM
continuation by focusing on relationships between ideas and their organization
with regards to others. Additionally, our approach does not require access to
LLM metrics like perplexity that may be unavailable in closed large language
modeling "black-box" systems, as well as the training corpus. A prototype of
our system will be found on a hyperlinked GitHub repository.

æè¦ï¼é´äºåºçåãæ¥çº¸åå¶ä»åçæä¿æ¤è¯­æåºçåé èæè¿å¯¹å¤§åè¯­è¨æ¨¡å (LLM) å¼åèæåºçå½çªææ§ï¼æä»¬æåºäºä¸ç§æ°é¢çç³»ç»ï¼è¯¥ç³»ç»æ¯å½çªæ£æµç³»ç»çä¸ä¸ªåä½ï¼å®è¯ä¼°ç¥è¯æºæ¯å¦å·²ç¨äºå¤§åè¯­è¨æ¨¡åçè®­ç»æå¾®è°ãä¸å½åæ¹æ³ä¸åï¼æä»¬å©ç¨ä¸ç§ä½¿ç¨èµæºæè¿°æ¡æ¶ (RDF) ä¸åç»çæ¹æ³ä»æºææ¡£åè¯¥ææ¡£ç LLM å»¶ç»­ä¸­åå»ºç¥è¯å¾è°±ãç¶åä½¿ç¨ä½å¼¦ç¸ä¼¼æ§åæè¿äºå¾è°±çåå®¹ï¼å¹¶ä½¿ç¨å¾ç¼è¾è·ç¦»çæ ååçæ¬åæç»æï¼è¯¥çæ¬æ¾ç¤ºåæåº¦ãä¸ä¸æ³¨äºæºè¯­æåºåç®æ è¯­æåºä¹é´çåå®¹å¹éåå³é®è¯è¯å«çä¼ ç»ç³»ç»ä¸åï¼æä»¬çæ¹æ³è½å¤å¯¹ç¸ä¼¼æ§è¿è¡æ´å¹¿æ³çè¯ä¼°ï¼ä»èæ´åç¡®å°æ¯è¾æºææ¡£å LLM å»¶ç»­ä¹é´çç¸ä¼¼æ§ï¼æ¹æ³æ¯å³æ³¨ææ³ä¹é´çå³ç³»ä»¥åå®ä»¬ä¸å¶ä»ææ³çå³ç³»ãæ­¤å¤ï¼æä»¬çæ¹æ³ä¸éè¦è®¿é® LLM ææ ï¼ä¾å¦å°æåº¦ï¼è¿äºææ å¨å°é­çå¤§åè¯­è¨å»ºæ¨¡âé»å£å­âç³»ç»ä»¥åè®­ç»è¯­æåºä¸­å¯è½ä¸å¯ç¨ãæä»¬ç³»ç»çååå°å¨è¶é¾æ¥ç GitHub å­å¨åºä¸­æ¾å°ã

##### **Multi-Peptide: Multimodality Leveraged Language-Graph Learning of Peptide Properties**
2407.03380v1 by Srivathsan Badrinarayanan, Chakradhar Guntuboina, Parisa Mollaei, Amir Barati Farimani

Peptides are essential in biological processes and therapeutics. In this
study, we introduce Multi-Peptide, an innovative approach that combines
transformer-based language models with Graph Neural Networks (GNNs) to predict
peptide properties. We combine PeptideBERT, a transformer model tailored for
peptide property prediction, with a GNN encoder to capture both sequence-based
and structural features. By employing Contrastive Language-Image Pre-training
(CLIP), Multi-Peptide aligns embeddings from both modalities into a shared
latent space, thereby enhancing the model's predictive accuracy. Evaluations on
hemolysis and nonfouling datasets demonstrate Multi-Peptide's robustness,
achieving state-of-the-art 86.185% accuracy in hemolysis prediction. This study
highlights the potential of multimodal learning in bioinformatics, paving the
way for accurate and reliable predictions in peptide-based research and
applications.

æè¦ï¼è½å¨çç©éç¨åæ²»çä¸­è³ééè¦ãå¨æ­¤ç ç©¶ä¸­ï¼æåä»ç´¹äºå¤è½ï¼éæ¯ä¸ç¨®åµæ°çæ¹æ³ï¼çµåäºåºæ¼è½æå¨çèªè¨æ¨¡åååç¥ç¶ç¶²çµ¡ (GNN) ä¾é æ¸¬è½çæ§è³ªãæåçµåäºå°éç¨æ¼è½æ§è³ªé æ¸¬çè½æå¨æ¨¡å PeptideBERT å GNN ç·¨ç¢¼å¨ï¼ä»¥æç²åºæ¼åºååçµæ§çç¹å¾µãééæ¡ç¨å°æ¯èªè¨ååé è¨ç·´ (CLIP)ï¼å¤è½å°ä¾èªå©ç¨®æ¨¡æçåµå¥å°é½å°ä¸åå±äº«çæ½å¨ç©ºéä¸­ï¼å¾èå¢å¼·æ¨¡åçé æ¸¬æºç¢ºåº¦ãå°æº¶è¡åææ±¡æ¸æéçè©ä¼°è­æäºå¤è½çç©©å¥æ§ï¼å¨æº¶è¡é æ¸¬ä¸­å¯¦ç¾äºæåé²ç 86.185% æºç¢ºçãæ¬ç ç©¶å¼·èª¿äºçç©ä¿¡æ¯å­¸ä¸­å¤æ¨¡æå­¸ç¿çæ½åï¼çºåºæ¼è½çç ç©¶åæç¨ä¸­çæºç¢ºä¸å¯é çé æ¸¬éªå¹³äºéè·¯ã

##### **Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification**
2407.02352v1 by Pritish Sahu, Karan Sikka, Ajay Divakaran

Large Visual Language Models (LVLMs) struggle with hallucinations in visual
instruction following task(s), limiting their trustworthiness and real-world
applicability. We propose Pelican -- a novel framework designed to detect and
mitigate hallucinations through claim verification. Pelican first decomposes
the visual claim into a chain of sub-claims based on first-order predicates.
These sub-claims consist of (predicate, question) pairs and can be
conceptualized as nodes of a computational graph. We then use
Program-of-Thought prompting to generate Python code for answering these
questions through flexible composition of external tools. Pelican improves over
prior work by introducing (1) intermediate variables for precise grounding of
object instances, and (2) shared computation for answering the sub-question to
enable adaptive corrections and inconsistency identification. We finally use
reasoning abilities of LLM to verify the correctness of the the claim by
considering the consistency and confidence of the (question, answer) pairs from
each sub-claim. Our experiments reveal a drop in hallucination rate by
$\sim$8%-32% across various baseline LVLMs and a 27% drop compared to
approaches proposed for hallucination mitigation on MMHal-Bench. Results on two
other benchmarks further corroborate our results.

æè¦ï¼å¤§åè§è§è¯­è¨æ¨¡å (LVLMs) å¨è§è§æä»¤éµå¾ªä»»å¡ä¸­ä¼äº§çå¹»è§ï¼è¿éå¶äºå®ä»¬çå¯é æ§åç°å®ä¸ççéç¨æ§ãæä»¬æåºäº Pelicanââä¸ç§æ¨å¨éè¿å£°æéªè¯æ¥æ£æµååè½»å¹»è§çæ°åæ¡æ¶ãPelican é¦åæ ¹æ®ä¸é¶è°è¯å°è§è§å£°æåè§£æä¸ä¸ªå­å£°æé¾ãè¿äºå­å£°æç± (è°è¯ãé®é¢) å¯¹ç»æï¼å¯ä»¥è¢«æ¦å¿µåä¸ºè®¡ç®å¾çèç¹ãç¶åï¼æä»¬ä½¿ç¨ææ³è®¡åæç¤ºæ¥çæ Python ä»£ç ï¼éè¿å¤é¨å·¥å·ççµæ´»ç»åæ¥åç­è¿äºé®é¢ãPelican éè¿å¼å¥ (1) ç¨äºå¯¹è±¡å®ä¾ç²¾ç¡®æ¥å°çä¸­é´åéï¼ä»¥å (2) ç¨äºåç­å­é®é¢ä»¥å®ç°èªéåºæ ¡æ­£åä¸ä¸è´æ§è¯å«çå±äº«è®¡ç®ï¼æ¹è¿äºä¹åçå·¥ä½ãæä»¬æç»ä½¿ç¨ LLM çæ¨çè½åï¼éè¿èèæ¯ä¸ªå­å£°æç (é®é¢ãç­æ¡) å¯¹çä¸è´æ§åç½®ä¿¡åº¦æ¥éªè¯å£°æçæ­£ç¡®æ§ãæä»¬çå®éªè¡¨æï¼å¨åç§åºçº¿ LVLMs ä¸­ï¼å¹»è§çä¸éäºçº¦ 8%-32%ï¼ä¸ MMHal-Bench ä¸æåºçå¹»è§ç¼è§£æ¹æ³ç¸æ¯ï¼ä¸éäº 27%ãå¨å¦å¤ä¸¤ä¸ªåºåä¸çç»æè¿ä¸æ­¥è¯å®äºæä»¬çç»æã

##### **Is Your Large Language Model Knowledgeable or a Choices-Only Cheater?**
2407.01992v1 by Nishant Balepur, Rachel Rudinger

Recent work shows that large language models (LLMs) can answer
multiple-choice questions using only the choices, but does this mean that MCQA
leaderboard rankings of LLMs are largely influenced by abilities in
choices-only settings? To answer this, we use a contrast set that probes if
LLMs over-rely on choices-only shortcuts in MCQA. While previous works build
contrast sets via expensive human annotations or model-generated data which can
be biased, we employ graph mining to extract contrast sets from existing MCQA
datasets. We use our method on UnifiedQA, a group of six commonsense reasoning
datasets with high choices-only accuracy, to build an 820-question contrast
set. After validating our contrast set, we test 12 LLMs, finding that these
models do not exhibit reliance on choice-only shortcuts when given both the
question and choices. Thus, despite the susceptibility~of MCQA to high
choices-only accuracy, we argue that LLMs are not obtaining high ranks on MCQA
leaderboards just due to their ability to exploit choices-only shortcuts.

æè¦ï¼æè¿çç ç©¶è¡¨æï¼å¤§åè¯­è¨æ¨¡å (LLM) ä»ä½¿ç¨éé¡¹å°±è½åç­å¤é¡¹éæ©é¢ï¼ä½è¿æ¯å¦è¡¨ç¤ºå¤é¡¹éæ©é®ç­ (MCQA) æè¡æ¦ä¸ç LLM ä¸»è¦åéäºä»éé¡¹è®¾ç½®ä¸­çè½åï¼ä¸ºäºåç­è¿ä¸ªé®é¢ï¼æä»¬ä½¿ç¨å¯¹æ¯éæ¥æ¢æ¥ LLM å¨ MCQA ä¸­æ¯å¦è¿åº¦ä¾èµä»éé¡¹æ·å¾ãè½ç¶ååçç ç©¶éè¿æè´µçäººå·¥æ³¨éæå¯è½å­å¨åå·®çæ¨¡åçææ°æ®æ¥æå»ºå¯¹æ¯éï¼ä½æä»¬éç¨å¾ææä»ç°æ MCQA æ°æ®éä¸­æåå¯¹æ¯éãæä»¬ä½¿ç¨æä»¬çæ¹æ³å¨ UnifiedQA ä¸ï¼è¿æ¯ä¸ä¸ªç±å­ä¸ªå·æé«ä»éé¡¹åç¡®ççå¸¸è¯æ¨çæ°æ®éç»æçç»ï¼æå»ºäºä¸ä¸ª 820 é¢çå¯¹æ¯éãå¨éªè¯æä»¬çå¯¹æ¯éåï¼æä»¬æµè¯äº 12 ä¸ª LLMï¼åç°å½åæ¶ç»åºé®é¢åéé¡¹æ¶ï¼è¿äºæ¨¡åä¸ä¼è¡¨ç°åºå¯¹ä»éé¡¹æ·å¾çä¾èµãå æ­¤ï¼å°½ç®¡ MCQA å®¹æåå°é«ä»éé¡¹åç¡®ççå½±åï¼ä½æä»¬è®¤ä¸º LLM å¨ MCQA æè¡æ¦ä¸è·å¾é«æåå¹¶éä»ä»å ä¸ºå®ä»¬å©ç¨ä»éé¡¹æ·å¾çè½åã

##### **CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents**
2407.01511v1 by Tianqi Xu, Linyao Chen, Dai-Jie Wu, Yanjun Chen, Zecheng Zhang, Xiang Yao, Zhiqiang Xie, Yongchao Chen, Shilong Liu, Bochen Qian, Philip Torr, Bernard Ghanem, Guohao Li

The development of autonomous agents increasingly relies on Multimodal
Language Models (MLMs) to perform tasks described in natural language with GUI
environments, such as websites, desktop computers, or mobile phones. Existing
benchmarks for MLM agents in interactive environments are limited by their
focus on a single environment, lack of detailed and generalized evaluation
methods, and the complexities of constructing tasks and evaluators. To overcome
these limitations, we introduce Crab, the first agent benchmark framework
designed to support cross-environment tasks, incorporating a graph-based
fine-grained evaluation method and an efficient mechanism for task and
evaluator construction. Our framework supports multiple devices and can be
easily extended to any environment with a Python interface. Leveraging Crab, we
developed a cross-platform Crab Benchmark-v0 comprising 100 tasks in computer
desktop and mobile phone environments. We evaluated four advanced MLMs using
different single and multi-agent system configurations on this benchmark. The
experimental results demonstrate that the single agent with GPT-4o achieves the
best completion ratio of 35.26%. All framework code, agent code, and task
datasets are publicly available at https://github.com/camel-ai/crab.

æè¦ï¼èªä¸»ä»£ççéç¼è¶ä¾è¶ä¾è³´å¤æ¨¡æèªè¨æ¨¡å (MLM)ï¼ä»¥å¨å·æ GUI ç°å¢ï¼ä¾å¦ç¶²ç«ãæ¡ä¸åé»è¦æææ©ï¼çèªç¶èªè¨ä¸­å·è¡ä»»åãç¾æçäºåç°å¢ä¸­ MLM ä»£ççåºæºåå°ä»¥ä¸éå¶ï¼å®åå°æ³¨æ¼å®ä¸ç°å¢ãç¼ºä¹è©³ç´°ä¸éç¨çè©ä¼°æ¹æ³ï¼ä»¥åå»ºæ§ä»»ååè©ä¼°å¨çè¤éæ§ãçºäºåæéäºéå¶ï¼æåå¼å¥äº Crabï¼éæ¯ç¬¬ä¸åä»£çåºæºæ¶æ§ï¼æ¨å¨æ¯æ´è·¨ç°å¢ä»»åï¼ä¸¦çµåäºåºæ¼åå½¢çç´°ç²åº¦è©ä¼°æ¹æ³åä»»åèè©ä¼°å¨å»ºæ§çæææ©å¶ãæåçæ¶æ§æ¯æ´å¤ç¨®è£ç½®ï¼ä¸¦ä¸å¯ä»¥è¼é¬å°æ´åå°ä»»ä½å·æ Python ä»é¢çç°å¢ãå©ç¨ Crabï¼æåéç¼äºä¸åè·¨å¹³å°ç Crab Benchmark-v0ï¼å¶ä¸­åå«é»è¦æ¡ä¸åé»è¦åææ©ç°å¢ä¸­ç 100 åä»»åãæåä½¿ç¨ä¸åçå®ä¸åå¤ä»£çç³»çµ±éç½®ï¼å¨éååºæºä¸è©ä¼°äºåç¨®åé²ç MLMãå¯¦é©çµæè¡¨æï¼å·æ GPT-4o çå®ä¸ä»£çå¯¦ç¾äº 35.26% çæä½³å®æçãæææ¶æ§ç¨å¼ç¢¼ãä»£çç¨å¼ç¢¼åä»»åè³æéé½å¬éæ¼ https://github.com/camel-ai/crabã

##### **Dynamic Few-Shot Learning for Knowledge Graph Question Answering**
2407.01409v1 by Jacopo D'Abramo, Andrea Zugarini, Paolo Torroni

Large language models present opportunities for innovative Question Answering
over Knowledge Graphs (KGQA). However, they are not inherently designed for
query generation. To bridge this gap, solutions have been proposed that rely on
fine-tuning or ad-hoc architectures, achieving good results but limited
out-of-domain distribution generalization. In this study, we introduce a novel
approach called Dynamic Few-Shot Learning (DFSL). DFSL integrates the
efficiency of in-context learning and semantic similarity and provides a
generally applicable solution for KGQA with state-of-the-art performance. We
run an extensive evaluation across multiple benchmark datasets and architecture
configurations.

æè¦ï¼å¤§åèªè¨æ¨¡åçºç¥è­åè­ï¼KGQAï¼çåµæ°åç­æä¾äºæ©æãç¶èï¼å®åä¸¦éå¤©çå°±è¨­è¨ç¨æ¼æ¥è©¢çæãçºäºå½è£éä¸å·®è·ï¼å·²æåºä¾è³´æ¼å¾®èª¿æç¹å®æ¶æ§çè§£æ±ºæ¹æ¡ï¼åå¾äºè¯å¥½ççµæï¼ä½åå¤åä½æ³åè½åæéãå¨æ¬ç ç©¶ä¸­ï¼æåå¼å¥äºä¸ç¨®ç¨±çºåæå°æ¨£æ¬å­¸ç¿ï¼DFSLï¼çæ°æ¹æ³ãDFSL éæäºèªå¢å­¸ç¿åèªç¾©ç¸ä¼¼æ§çæçï¼ä¸¦çº KGQA æä¾äºä¸åæ®éé©ç¨çè§£æ±ºæ¹æ¡ï¼å·ææåé²çæ§è½ãæåå°å¤ååºæºè³æéåæ¶æ§éç½®é²è¡äºå»£æ³çè©ä¼°ã

##### **Adapting Multilingual LLMs to Low-Resource Languages with Knowledge Graphs via Adapters**
2407.01406v1 by Daniil Gurgurov, Mareike Hartmann, Simon Ostermann

This paper explores the integration of graph knowledge from linguistic
ontologies into multilingual Large Language Models (LLMs) using adapters to
improve performance for low-resource languages (LRLs) in sentiment analysis
(SA) and named entity recognition (NER). Building upon successful
parameter-efficient fine-tuning techniques, such as K-ADAPTER and MAD-X, we
propose a similar approach for incorporating knowledge from multilingual
graphs, connecting concepts in various languages with each other through
linguistic relationships, into multilingual LLMs for LRLs. Specifically, we
focus on eight LRLs -- Maltese, Bulgarian, Indonesian, Nepali, Javanese,
Uyghur, Tibetan, and Sinhala -- and employ language-specific adapters
fine-tuned on data extracted from the language-specific section of ConceptNet,
aiming to enable knowledge transfer across the languages covered by the
knowledge graph. We compare various fine-tuning objectives, including standard
Masked Language Modeling (MLM), MLM with full-word masking, and MLM with
targeted masking, to analyse their effectiveness in learning and integrating
the extracted graph data. Through empirical evaluation on language-specific
tasks, we assess how structured graph knowledge affects the performance of
multilingual LLMs for LRLs in SA and NER, providing insights into the potential
benefits of adapting language models for low-resource scenarios.

æè¦ï¼éç¯è«ææ¢è¨äºä½¿ç¨é©éå¨å°èªè¨æ¬é«è«ä¸­çåå½¢ç¥è­æ´åå°å¤èªè¨å¤§åèªè¨æ¨¡å (LLM) ä¸­ï¼ä»¥æ¹åä½è³æºèªè¨ (LRL) å¨æç·åæ (SA) åå½åå¯¦é«è¾¨è­ (NER) ä¸­çæè½ãå»ºç«å¨æåçåæ¸ææå¾®èª¿æè¡ä¸ï¼ä¾å¦ K-ADAPTER å MAD-Xï¼æåæåºäºä¸ç¨®é¡ä¼¼çæ¹æ³ï¼ç¨æ¼å°ä¾èªå¤èªè¨åå½¢ãééèªè¨éä¿å°åç¨®èªè¨ä¸­çæ¦å¿µå½¼æ­¤é£æ¥çç¥è­æ´åå° LRL çå¤èªè¨ LLM ä¸­ãå·é«ä¾èªªï¼æåå°æ³¨æ¼å«ç¨® LRLââé¦¬ç¾ä»èªãä¿å å©äºèªãå°å°¼èªãå°¼æ³ç¾èªãçªåèªãç¶­å¾ç¾èªãèèªåå§ä¼½ç¾èªââä¸¦ä½¿ç¨éå°å¾ ConceptNet çèªè¨ç¹å®é¨åä¸­èåçè³æé²è¡å¾®èª¿çèªè¨ç¹å®é©éå¨ï¼æ¨å¨è®ç¥è­å¨ç¥è­åå½¢æ¶µèçèªè¨ä¹éè½ç§»ãæåæ¯è¼äºåç¨®å¾®èª¿ç®æ¨ï¼åæ¬æ¨æºçé®ç½©èªè¨æ¨¡å (MLM)ãå¸¶æå¨è©é®ç½©ç MLM åå¸¶æç®æ¨é®ç½©ç MLMï¼ä»¥åæå®åå¨å­¸ç¿åæ´åèåçåå½¢è³ææ¹é¢çæææ§ãééå°èªè¨ç¹å®ä»»åçç¶é©è©ä¼°ï¼æåè©ä¼°äºçµæ§åçåå½¢ç¥è­å¦ä½å½±é¿å¤èªè¨ LLM å¨ SA å NER ä¸­çæè½ï¼ä¸¦æ·±å¥äºè§£äºçºä½è³æºå ´æ¯èª¿æ´èªè¨æ¨¡åçæ½å¨å¥½èã

##### **SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model**
2407.01245v1 by Lingyue Fu, Hao Guan, Kounianhua Du, Jianghao Lin, Wei Xia, Weinan Zhang, Ruiming Tang, Yasheng Wang, Yong Yu

Knowledge Tracing (KT) aims to determine whether students will respond
correctly to the next question, which is a crucial task in intelligent tutoring
systems (ITS). In educational KT scenarios, transductive ID-based methods often
face severe data sparsity and cold start problems, where interactions between
individual students and questions are sparse, and new questions and concepts
consistently arrive in the database. In addition, existing KT models only
implicitly consider the correlation between concepts and questions, lacking
direct modeling of the more complex relationships in the heterogeneous graph of
concepts and questions. In this paper, we propose a Structure-aware Inductive
Knowledge Tracing model with large language model (dubbed SINKT), which, for
the first time, introduces large language models (LLMs) and realizes inductive
knowledge tracing. Firstly, SINKT utilizes LLMs to introduce structural
relationships between concepts and constructs a heterogeneous graph for
concepts and questions. Secondly, by encoding concepts and questions with LLMs,
SINKT incorporates semantic information to aid prediction. Finally, SINKT
predicts the student's response to the target question by interacting with the
student's knowledge state and the question representation. Experiments on four
real-world datasets demonstrate that SINKT achieves state-of-the-art
performance among 12 existing transductive KT models. Additionally, we explore
the performance of SINKT on the inductive KT task and provide insights into
various modules.

æè¦ï¼ç¥è­è¿½è¹¤ (KT) æ¨å¨å¤æ·å­¸çæ¯å¦ææ­£ç¢ºåç­ä¸ä¸ååé¡ï¼éå¨æºæ§åæå­¸ç³»çµ± (ITS) ä¸­æ¯ä¸é è³ééè¦çä»»åãå¨æè² KT å ´æ¯ä¸­ï¼åºæ¼è½å° ID çæ¹æ³éå¸¸æé¢è¨å´éçè³æç¨çæ§åå·åååé¡ï¼å¶ä¸­åå¥å­¸çèåé¡ä¹éçäºåå¾ç¨å°ï¼èä¸æ°çåé¡åæ¦å¿µææçºåºç¾å¨è³æåº«ä¸­ãæ­¤å¤ï¼ç¾æç KT æ¨¡ååé±å«å°èæ®æ¦å¿µååé¡ä¹éçéè¯æ§ï¼ç¼ºä¹å°æ¦å¿µååé¡ç°è³ªåä¸­æ´è¤ééä¿çç´æ¥å»ºæ¨¡ãå¨æ¬æä¸­ï¼æåæåºäºä¸åå·æå¤§åèªè¨æ¨¡åççµæ§æç¥æ­¸ç´ç¥è­è¿½è¹¤æ¨¡å (ç¨±çº SINKT)ï¼è©²æ¨¡åé¦æ¬¡å¼å¥äºå¤§åèªè¨æ¨¡å (LLM) ä¸¦å¯¦ç¾äºæ­¸ç´ç¥è­è¿½è¹¤ãé¦åï¼SINKT å©ç¨ LLM ä¾å¼å¥æ¦å¿µä¹éççµæ§éä¿ï¼ä¸¦çºæ¦å¿µååé¡æ§å»ºä¸åç°è³ªåãå¶æ¬¡ï¼ééä½¿ç¨ LLM ç·¨ç¢¼æ¦å¿µååé¡ï¼SINKT ç´å¥äºèªç¾©è³è¨ä»¥åå©é æ¸¬ãæå¾ï¼SINKT ééèå­¸ççç¥è­çæååé¡è¡¨ç¤ºé²è¡äºåä¾é æ¸¬å­¸çå°ç®æ¨åé¡çåæãå¨ååçå¯¦ä¸çè³æéä¸çå¯¦é©è¡¨æï¼SINKT å¨ 12 åç¾æè½å° KT æ¨¡åä¸­éå°äºæåé²çæè½ãæ­¤å¤ï¼æåæ¢è¨äº SINKT å¨æ­¸ç´ KT ä»»åä¸­çæè½ï¼ä¸¦æ·±å¥äºè§£åç¨®æ¨¡çµã

##### **Revisiting Random Walks for Learning on Graphs**
2407.01214v1 by Jinwoo Kim, Olga Zaghen, Ayhan Suleymanzade, Youngmin Ryou, Seunghoon Hong

We revisit a simple idea for machine learning on graphs, where a random walk
on a graph produces a machine-readable record, and this record is processed by
a deep neural network to directly make vertex-level or graph-level predictions.
We refer to these stochastic machines as random walk neural networks, and show
that we can design them to be isomorphism invariant while capable of universal
approximation of graph functions in probability. A useful finding is that
almost any kind of record of random walk guarantees probabilistic invariance as
long as the vertices are anonymized. This enables us to record random walks in
plain text and adopt a language model to read these text records to solve graph
tasks. We further establish a parallelism to message passing neural networks
using tools from Markov chain theory, and show that over-smoothing in message
passing is alleviated by construction in random walk neural networks, while
over-squashing manifests as probabilistic under-reaching. We show that random
walk neural networks based on pre-trained language models can solve several
hard problems on graphs, such as separating strongly regular graphs where the
3-WL test fails, counting substructures, and transductive classification on
arXiv citation network without training. Code is available at
https://github.com/jw9730/random-walk.

æè¦ï¼<paragraph>æåéæ°å¯©è¦åå½¢æ©å¨å­¸ç¿çä¸åç°¡å®æ³æ³ï¼å¶ä¸­åå½¢ä¸çé¨æ©éèµ°æç¢çæ©å¨å¯è®çè¨éï¼èéåè¨éæç±æ·±åº¦ç¥ç¶ç¶²è·¯èçï¼ä»¥ç´æ¥é²è¡é é»å±¤ç´æåå½¢å±¤ç´çé æ¸¬ãæåå°éäºé¨æ©æ©å¨ç¨±çºé¨æ©éèµ°ç¥ç¶ç¶²è·¯ï¼ä¸¦å±ç¤ºæåå¯ä»¥å°å®åè¨­è¨æåæ§ä¸è®ï¼åæå·åæ©çä¸­åå½¢å½æ¸çéç¨è¿ä¼¼è½åãä¸åæç¨çç¼ç¾æ¯ï¼åªè¦é é»æ¯å¿åçï¼å¹¾ä¹ä»»ä½é¡åçé¨æ©éèµ°è¨éé½å¯ä»¥ä¿è­æ©çä¸è®æ§ãéä½¿æåè½å¤ ä»¥ç´æå­è¨éé¨æ©éèµ°ï¼ä¸¦æ¡ç¨èªè¨æ¨¡åä¾è®åéäºæå­è¨éï¼ä»¥è§£æ±ºåå½¢ä»»åãæåé²ä¸æ­¥å»ºç«äºä¸åèè¨æ¯å³éç¥ç¶ç¶²è·¯çå¹³è¡æ§ï¼ä½¿ç¨é¦¬å¯å¤«éçè«çå·¥å·ï¼ä¸¦å±ç¤ºè¨æ¯å³éä¸­çéåº¦å¹³æ»æå é¨æ©éèµ°ç¥ç¶ç¶²è·¯ä¸­çæ§é èå¾å°ç·©è§£ï¼èéåº¦å£ç¸®åè¡¨ç¾çºæ©çæ§ä¸è¶³ãæåå±ç¤ºäºåºæ¼é åè¨ç·´èªè¨æ¨¡åçé¨æ©éèµ°ç¥ç¶ç¶²è·¯å¯ä»¥è§£æ±ºåå½¢ä¸çå¹¾åå°é£åé¡ï¼ä¾å¦åé¢ 3-WL æ¸¬è©¦å¤±æçå¼·æ­£ååå½¢ãè¨ç®å­çµæ§ï¼ä»¥åå¨ arXiv å¼æç¶²è·¯ä¸­é²è¡è½å°åé¡ï¼èç¡éè¨ç·´ãç¨å¼ç¢¼å¯å¨ https://github.com/jw9730/random-walk åå¾ã</paragraph>

##### **LLM Uncertainty Quantification through Directional Entailment Graph and Claim Level Response Augmentation**
2407.00994v2 by Longchao Da, Tiejin Chen, Lu Cheng, Hua Wei

The Large language models (LLMs) have showcased superior capabilities in
sophisticated tasks across various domains, stemming from basic question-answer
(QA), they are nowadays used as decision assistants or explainers for
unfamiliar content. However, they are not always correct due to the data
sparsity in specific domain corpus, or the model's hallucination problems.
Given this, how much should we trust the responses from LLMs? This paper
presents a novel way to evaluate the uncertainty that captures the directional
instability, by constructing a directional graph from entailment probabilities,
and we innovatively conduct Random Walk Laplacian given the asymmetric property
of a constructed directed graph, then the uncertainty is aggregated by the
derived eigenvalues from the Laplacian process. We also provide a way to
incorporate the existing work's semantics uncertainty with our proposed layer.
Besides, this paper identifies the vagueness issues in the raw response set and
proposes an augmentation approach to mitigate such a problem, we conducted
extensive empirical experiments and demonstrated the superiority of our
proposed solutions.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨ååé åçè¤éä»»åä¸­å±ç¾åºåè¶çè½åï¼å¾åºæ¬çåç­ (QA) éå§ï¼å®åç¾å¨è¢«ç¨ä½æ±ºç­å©çæä¸çæå§å®¹çèªªæèãç¶èï¼å®åä¸¦ä¸ç¸½æ¯æ­£ç¢ºçï¼å çºç¹å®é åèªæåº«ä¸­çæ¸æç¨çï¼ææ¨¡åçå¹»è¦ºåé¡ãæéæ¼æ­¤ï¼æåæè©²å¤ç¸ä¿¡ LLM çåæï¼æ¬ææåºäºä¸ç¨®æ°çæ¹æ³ä¾è©ä¼°æææ¹åä¸ç©©å®æ§çä¸ç¢ºå®æ§ï¼ééå¾èæ¶µæ¦çæ§é ä¸åæååï¼ä¸¦ä¸æååµæ°å°é²è¡é¨æ©éèµ°ææ®ææ¯ç®å­ï¼çµ¦å®ä¸åæ§é çæååçä¸å°ç¨±å±¬æ§ï¼ç¶å¾ä¸ç¢ºå®æ§ç±ææ®ææ¯éç¨ä¸­çå°åºç¹å¾µå¼èåãæåéæä¾äºä¸ç¨®å°ç¾æå·¥ä½çèªç¾©ä¸ç¢ºå®æ§èæåæåºçå±¤çµåèµ·ä¾çæ¹æ³ãæ­¤å¤ï¼æ¬æè­å¥äºåå§åæéä¸­æ¨¡ç³çåé¡ï¼ä¸¦æåºäºä¸ç¨®æ´åæ¹æ³ä¾æ¸è¼éç¨®åé¡ï¼æåé²è¡äºå»£æ³çå¯¦è­å¯¦é©ï¼ä¸¦å±ç¤ºäºæåæåºçè§£æ±ºæ¹æ¡çåªè¶æ§ã

##### **Actionable Cyber Threat Intelligence using Knowledge Graphs and Large Language Models**
2407.02528v1 by Romy Fieblinger, Md Tanvirul Alam, Nidhi Rastogi

Cyber threats are constantly evolving. Extracting actionable insights from
unstructured Cyber Threat Intelligence (CTI) data is essential to guide
cybersecurity decisions. Increasingly, organizations like Microsoft, Trend
Micro, and CrowdStrike are using generative AI to facilitate CTI extraction.
This paper addresses the challenge of automating the extraction of actionable
CTI using advancements in Large Language Models (LLMs) and Knowledge Graphs
(KGs). We explore the application of state-of-the-art open-source LLMs,
including the Llama 2 series, Mistral 7B Instruct, and Zephyr for extracting
meaningful triples from CTI texts. Our methodology evaluates techniques such as
prompt engineering, the guidance framework, and fine-tuning to optimize
information extraction and structuring. The extracted data is then utilized to
construct a KG, offering a structured and queryable representation of threat
intelligence. Experimental results demonstrate the effectiveness of our
approach in extracting relevant information, with guidance and fine-tuning
showing superior performance over prompt engineering. However, while our
methods prove effective in small-scale tests, applying LLMs to large-scale data
for KG construction and Link Prediction presents ongoing challenges.

æè¦ï¼ç¶²è·¯å¨èä¸æ·æ¼è®ãå¾éçµæ§åçç¶²è·¯å¨èæå ± (CTI) è³æä¸­èåå¯æ¡åè¡åçè¦è§£ï¼å°æ¼å¼å°ç¶²è·¯å®å¨æ±ºç­è³ééè¦ãè¶ä¾è¶å¤çµç¹ï¼ä¾å¦ Microsoftãè¶¨å¢ç§æå CrowdStrikeï¼ä½¿ç¨çæå¼ AI ä¾ä¿é² CTI èåãæ¬ææ¢è¨äºä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) åç¥è­åè­ (KG) çé²å±ï¼èªåèåå¯æ¡åè¡åç CTI çææ°ãæåæ¢è¨äºæåé²çéæº LLM çæç¨ï¼åæ¬ Llama 2 ç³»åãMistral 7B Instruct å Zephyrï¼ä»¥å¾ CTI æå­ä¸­èåææç¾©çä¸åçµãæåçåæ³è©ä¼°äºæç¤ºå·¥ç¨ãæå°æ¶æ§åå¾®èª¿ç­æè¡ï¼ä»¥æä½³åè³è¨èååçµæ§åãç¶å¾ï¼å°èåçè³æç¨æ¼å»ºæ§ KGï¼æä¾å¨èæå ±ççµæ§åä¸å¯æ¥è©¢çè¡¨ç¤ºãå¯¦é©çµæè­æäºæåæ¹æ³å¨èåç¸éè³è¨æ¹é¢çæææ§ï¼æå°åå¾®èª¿é¡¯ç¤ºåºåªæ¼æç¤ºå·¥ç¨çæè½ãç¶èï¼éç¶æåçåæ³å¨å°è¦æ¨¡æ¸¬è©¦ä¸­è­æææï¼ä½å° LLM æç¨æ¼å¤§è¦æ¨¡è³æä»¥é²è¡ KG å»ºæ§åé£çµé æ¸¬ï¼ä»å­å¨æçºçææ°ã

##### **Chain-of-Knowledge: Integrating Knowledge Reasoning into Large Language Models by Learning from Knowledge Graphs**
2407.00653v1 by Yifei Zhang, Xintao Wang, Jiaqing Liang, Sirui Xia, Lida Chen, Yanghua Xiao

Large Language Models (LLMs) have exhibited impressive proficiency in various
natural language processing (NLP) tasks, which involve increasingly complex
reasoning. Knowledge reasoning, a primary type of reasoning, aims at deriving
new knowledge from existing one.While it has been widely studied in the context
of knowledge graphs (KGs), knowledge reasoning in LLMs remains underexplored.
In this paper, we introduce Chain-of-Knowledge, a comprehensive framework for
knowledge reasoning, including methodologies for both dataset construction and
model learning. For dataset construction, we create KnowReason via rule mining
on KGs. For model learning, we observe rule overfitting induced by naive
training. Hence, we enhance CoK with a trial-and-error mechanism that simulates
the human process of internal knowledge exploration. We conduct extensive
experiments with KnowReason. Our results show the effectiveness of CoK in
refining LLMs in not only knowledge reasoning, but also general reasoning
benchmarkms.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®èªç¶èªè¨èç (NLP) ä»»åä¸­å±ç¾åºé©äººçè½åï¼éäºä»»åæ¶åè¶ä¾è¶è¤éçæ¨çãç¥è­æ¨çä½çºæ¨ççä¸»è¦é¡åï¼æ¨å¨å¾æ¢æç¥è­ä¸­æ¨å°åºæ°ç¥è­ãåç®¡ç¥è­æ¨çå·²å¨ç¥è­åè­ (KG) çèæ¯ä¸å¾å°å»£æ³ç ç©¶ï¼ä½ LLM ä¸­çç¥è­æ¨çä»èæ¼æ¢ç´¢éæ®µãå¨æ¬æä¸­ï¼æåä»ç´¹äºç¥è­æ¨ççç¶åæ¡æ¶ç¥è­éï¼å¶ä¸­åæ¬ç¨æ¼è³æéæ§å»ºåæ¨¡åå­¸ç¿çæ¹æ³ãå°æ¼è³æéæ§å»ºï¼æåééå¨ KG ä¸­é²è¡è¦åææä¾å»ºç« KnowReasonãå°æ¼æ¨¡åå­¸ç¿ï¼æåè§å¯å°ç±å¤©çè¨ç·´å¼ç¼çè¦åéåº¦æ¬åãå æ­¤ï¼æåä½¿ç¨æ¨¡æ¬äººé¡å§é¨ç¥è­æ¢ç´¢éç¨çè©¦é¯æ©å¶ä¾å¢å¼· CoKãæåå° KnowReason é²è¡äºå»£æ³çå¯¦é©ãæåççµæé¡¯ç¤º CoK å¨ç²¾ç LLM ä¸åå¨ç¥è­æ¨çæ¹é¢ï¼éåæ¬ä¸è¬æ¨çåºæºæ¹é¢é½éå¸¸ææã

##### **BioKGBench: A Knowledge Graph Checking Benchmark of AI Agent for Biomedical Science**
2407.00466v1 by Xinna Lin, Siqi Ma, Junjie Shan, Xiaojing Zhang, Shell Xu Hu, Tiannan Guo, Stan Z. Li, Kaicheng Yu

Pursuing artificial intelligence for biomedical science, a.k.a. AI Scientist,
draws increasing attention, where one common approach is to build a copilot
agent driven by Large Language Models (LLMs). However, to evaluate such
systems, people either rely on direct Question-Answering (QA) to the LLM
itself, or in a biomedical experimental manner. How to precisely benchmark
biomedical agents from an AI Scientist perspective remains largely unexplored.
To this end, we draw inspiration from one most important abilities of
scientists, understanding the literature, and introduce BioKGBench. In contrast
to traditional evaluation benchmark that only focuses on factual QA, where the
LLMs are known to have hallucination issues, we first disentangle
"Understanding Literature" into two atomic abilities, i) "Understanding" the
unstructured text from research papers by performing scientific claim
verification, and ii) Ability to interact with structured Knowledge-Graph
Question-Answering (KGQA) as a form of "Literature" grounding. We then
formulate a novel agent task, dubbed KGCheck, using KGQA and domain-based
Retrieval-Augmented Generation (RAG) to identify the factual errors of existing
large-scale knowledge graph databases. We collect over two thousand data for
two atomic tasks and 225 high-quality annotated data for the agent task.
Surprisingly, we discover that state-of-the-art agents, both daily scenarios
and biomedical ones, have either failed or inferior performance on our
benchmark. We then introduce a simple yet effective baseline, dubbed BKGAgent.
On the widely used popular knowledge graph, we discover over 90 factual errors
which provide scenarios for agents to make discoveries and demonstrate the
effectiveness of our approach. The code and data are available at
https://github.com/westlake-autolab/BioKGBench.

æè¦ï¼<paragraph>è¿½æ±çç©é«å­¸ç§å­¸çäººå·¥æºæ§ï¼åç¨± AI ç§å­¸å®¶ï¼
è¶ä¾è¶åå°éæ³¨ï¼å¶ä¸­ä¸ç¨®å¸¸è¦çæ¹æ³æ¯å»ºç«ç±å¤§åèªè¨æ¨¡å (LLM) é©åçå¯é§é§ä»£çãç¶èï¼è¦è©ä¼°æ­¤é¡
ç³»çµ±ï¼äººåè¦ä¹ä¾è³´ LLM æ¬èº«çç´æ¥åç­ (QA)ï¼è¦ä¹ä¾è³´çç©é«å­¸å¯¦é©æ¹å¼ãå¦ä½å¾ AI ç§å­¸å®¶çè§åº¦ç²¾ç¢ºè©é
çç©é«å­¸ä»£çå¨å¾å¤§ç¨åº¦ä¸ä»æªæ¢ç´¢ã
çºæ­¤ï¼æåå¾ç§å­¸å®¶æéè¦çè½åä¹ä¸ï¼å³çè§£æç»ä¸­æ±²åéæï¼ä¸¦ä»ç´¹ BioKGBenchãèåéæ³¨äºå¯¦ QA çå³çµ±è©éåºæºä¸åï¼å·²ç¥ LLM å¨äºå¯¦ QA ä¸­å­å¨å¹»è¦ºåé¡ï¼æåé¦åå°
ãçè§£æç»ãåè§£çºå©ç¨®åºæ¬è½åï¼i) ééå·è¡ç§å­¸ä¸»å¼µé©è­ä¾ãçè§£ãç ç©¶è«æä¸­çéçµæ§åæå­ï¼ä»¥å ii) ä»¥ãæç»ãçºåºç¤ï¼èçµæ§åçç¥è­åè¡¨åç­ (KGQA) äºåçè½åãç¶å¾
æåä½¿ç¨ KGQA ååºæ¼ç¶²åçæª¢ç´¢æ´åç¢ç (RAG) å¶å®äºä¸é æ°ç©çä»£çä»»åï¼ç¨±çº KGCheckï¼ä»¥è­å¥ç¾æå¤§åç¥è­åè¡¨è³æåº«çäºå¯¦é¯èª¤ãæåçº
å©ååºæ¬ä»»åæ¶éäºå©åå¤åè³æï¼ä»¥å 225 åé«åè³ªè¨»è§£è³æï¼ä»¥ä½çºä»£çä»»åãä»¤äººé©è¨çæ¯ï¼æåç¼ç¾æåé²çä»£çï¼ç¡è«æ¯æ¥å¸¸æå¢éæ¯çç©é«å­¸ï¼å¨æåç
åºæºä¸é½è¡¨ç¾ä¸ä½³æè¡¨ç¾è¼å·®ãç¶å¾ï¼æåå¼å¥äºä¸åç°¡å®ä½ææçåºæºï¼ç¨±çº BKGAgentãå¨å»£æ³ä½¿ç¨çç±éç¥è­åè¡¨ä¸ï¼æåç¼ç¾è¶é 90 åäºå¯¦é¯èª¤ï¼éäºé¯èª¤çºä»£çæä¾äºç¼ç¾æå¢ï¼ä¸¦è­æäºæåæ¹æ³çæææ§ãç¨å¼ç¢¼åè³æå¯å¨
https://github.com/westlake-autolab/BioKGBench åå¾ã</paragraph>

##### **GraphArena: Benchmarking Large Language Models on Graph Computational Problems**
2407.00379v1 by Jianheng Tang, Qifan Zhang, Yuhan Li, Jia Li

The "arms race" of Large Language Models (LLMs) demands novel, challenging,
and diverse benchmarks to faithfully examine their progresses. We introduce
GraphArena, a benchmarking tool designed to evaluate LLMs on graph
computational problems using million-scale real-world graphs from diverse
scenarios such as knowledge graphs, social networks, and molecular structures.
GraphArena offers a suite of 10 computational tasks, encompassing four
polynomial-time (e.g., Shortest Distance) and six NP-complete challenges (e.g.,
Travelling Salesman Problem). It features a rigorous evaluation framework that
classifies LLM outputs as correct, suboptimal (feasible but not optimal), or
hallucinatory (properly formatted but infeasible). Evaluation of 10 leading
LLMs, including GPT-4o and LLaMA3-70B-Instruct, reveals that even
top-performing models struggle with larger, more complex graph problems and
exhibit hallucination issues. Despite the application of strategies such as
chain-of-thought prompting, these issues remain unresolved. GraphArena
contributes a valuable supplement to the existing LLM benchmarks and is
open-sourced at https://github.com/squareRoot3/GraphArena.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çãè»åç«¶è³½ãéè¦æ°ç©ãå·ææ°æ§ä¸å¤æ¨£åçåºæºä¾å¿ å¯¦æª¢é©å¶é²åº¦ãæåæ¨åº GraphArenaï¼éæ¯ä¸ååºæºå·¥å·ï¼æ¨å¨ä½¿ç¨ä¾èªç¥è­åè­ãç¤¾äº¤ç¶²è·¯ååå­çµæ§ç­å¤æ¨£åæå¢çæ¸ç¾è¬åçå¯¦ä¸çåå½¢ï¼éå°åå½¢è¨ç®åé¡è©ä¼° LLMãGraphArena æä¾ä¸ç³»å 10 åè¨ç®ä»»åï¼åå«ååå¤é å¼æéï¼ä¾å¦ï¼æç­è·é¢ï¼åå­å NP å®å¨ææ°ï¼ä¾å¦ï¼æè¡æ¨é·å¡åé¡ï¼ãå®å·æä¸åå´è¬¹çè©ä¼°æ¶æ§ï¼å° LLM è¼¸åºåé¡çºæ­£ç¢ºãæ¬¡ä½³ï¼å¯è¡ä½éæä½³ï¼æå¹»è¦ºï¼æ ¼å¼æ­£ç¢ºä½ä¸å¯è¡ï¼ãå°åæ¬ GPT-4o å LLaMA3-70B-Instruct å¨å§ç 10 åé å LLM çè©ä¼°é¡¯ç¤ºï¼å³ä½¿æ¯æè½æä½³çæ¨¡åå¨èçæ´å¤§ãæ´è¤éçåå½¢åé¡æä»æéå°å°é£ï¼ä¸¦åºç¾å¹»è¦ºåé¡ãåç®¡æç¨äºä¸ç³»åç­ç¥ï¼ä¾å¦æèéæç¤ºï¼éäºåé¡ä»æªè§£æ±ºãGraphArena çºç¾æç LLM åºæºæä¾äºæå¹å¼çè£åï¼ä¸¦å¨ https://github.com/squareRoot3/GraphArena éæºã

##### **Teola: Towards End-to-End Optimization of LLM-based Applications**
2407.00326v1 by Xin Tan, Yimin Jiang, Yitao Yang, Hong Xu

Large language model (LLM)-based applications consist of both LLM and non-LLM
components, each contributing to the end-to-end latency. Despite great efforts
to optimize LLM inference, end-to-end workflow optimization has been
overlooked. Existing frameworks employ coarse-grained orchestration with task
modules, which confines optimizations to within each module and yields
suboptimal scheduling decisions. We propose fine-grained end-to-end
orchestration, which utilizes task primitives as the basic units and represents
each query's workflow as a primitive-level dataflow graph. This explicitly
exposes a much larger design space, enables optimizations in parallelization
and pipelining across primitives of different modules, and enhances scheduling
to improve application-level performance. We build Teola, a novel orchestration
framework for LLM-based applications that implements this scheme. Comprehensive
experiments show that Teola can achieve up to 2.09x speedup over existing
systems across various popular LLM applications.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æç¨ç¨å¼ç± LLM åé LLM åä»¶çµæï¼æ¯ååä»¶é½æå½±é¿ç«¯å°ç«¯å»¶é²ãåç®¡å·²éå°æä½³å LLM æ¨è«ååºè¨±å¤åªåï¼ä½ç«¯å°ç«¯å·¥ä½æµç¨æä½³åå»é­å°å¿½ç¥ãç¾ææ¶æ§æ¡ç¨ç²ç¥çç·¨æèä»»åæ¨¡çµï¼å°æä½³åéå¶å¨æ¯åæ¨¡çµå§ï¼ä¸¦ç¢çæ¬¡ä½³çæç¨æ±ºç­ãæåæåºç´°ç·»çç«¯å°ç«¯ç·¨æï¼å®ä½¿ç¨ä»»ååèªä½çºåºæ¬å®ä½ï¼ä¸¦å°æ¯åæ¥è©¢çå·¥ä½æµç¨è¡¨ç¤ºçºåèªå±¤ç´è³ææµåãéæç¢ºå°æ­é²äºæ´å¤§çè¨­è¨ç©ºéï¼å¨ä¸åæ¨¡çµçåèªä¹éåç¨å¹³è¡ååç®¡ç·æä½³åï¼ä¸¦å å¼·æç¨ä»¥æ¹åæç¨ç¨å¼å±¤ç´æè½ãæåå»ºæ§ Teolaï¼ä¸åå¯¦ä½æ­¤æ¶æ§ç LLM æç¨ç¨å¼åµæ°ç·¨ææ¶æ§ãå¨é¢çå¯¦é©é¡¯ç¤ºï¼Teola è½å¨åç¨®ç±é LLM æç¨ç¨å¼ä¸­ï¼æ¯ç¾æç³»çµ±å¿«ä¸ 2.09 åã

##### **Into the Unknown: Generating Geospatial Descriptions for New Environments**
2406.19967v1 by Tzuf Paz-Argaman, John Palowitch, Sayali Kulkarni, Reut Tsarfaty, Jason Baldridge

Similar to vision-and-language navigation (VLN) tasks that focus on bridging
the gap between vision and language for embodied navigation, the new Rendezvous
(RVS) task requires reasoning over allocentric spatial relationships
(independent of the observer's viewpoint) using non-sequential navigation
instructions and maps. However, performance substantially drops in new
environments with no training data. Using opensource descriptions paired with
coordinates (e.g., Wikipedia) provides training data but suffers from limited
spatially-oriented text resulting in low geolocation resolution. We propose a
large-scale augmentation method for generating high-quality synthetic data for
new environments using readily available geospatial data. Our method constructs
a grounded knowledge-graph, capturing entity relationships. Sampled entities
and relations (`shop north of school') generate navigation instructions via (i)
generating numerous templates using context-free grammar (CFG) to embed
specific entities and relations; (ii) feeding the entities and relation into a
large language model (LLM) for instruction generation. A comprehensive
evaluation on RVS, showed that our approach improves the 100-meter accuracy by
45.83% on unseen environments. Furthermore, we demonstrate that models trained
with CFG-based augmentation achieve superior performance compared with those
trained with LLM-based augmentation, both in unseen and seen environments.
These findings suggest that the potential advantages of explicitly structuring
spatial information for text-based geospatial reasoning in previously unknown,
can unlock data-scarce scenarios.

æè¦ï¼é¡ä¼¼æ¼å°æ³¨æ¼å½åå·é«å°èªä¸­è¦è¦ºèèªè¨å·®è·çè¦è¦ºèªè¨å°èª (VLN) ä»»åï¼æ°çæé¢ (RVS) ä»»åéè¦ä½¿ç¨éé åºå°èªæä»¤åå°åæ¨çç°ä¸­å¿ç©ºééä¿ï¼èè§å¯èçè§é»ç¡éï¼ãç¶èï¼å¨æ²æè¨ç·´è³æçæ°ç°å¢ä¸­ï¼æè½æå¤§å¹ä¸éãä½¿ç¨èåº§æ¨éå°çéæºèªªæï¼ä¾å¦ï¼ç¶­åºç¾ç§ï¼æä¾äºè¨ç·´è³æï¼ä½ç±æ¼ç©ºéå°åæå­æéï¼å°è´å°çä½ç½®è§£æåº¦ä½ãæåæåºäºä¸ç¨®å¤§è¦æ¨¡æ´åæ¹æ³ï¼ä½¿ç¨ç¾æçå°çç©ºéè³æçºæ°ç°å¢ç¢çé«åè³ªçåæè³æãæåçå»ºæ§æ¹æ³å»ºç«äºä¸ååºç¤ç¥è­åï¼æ·åå¯¦é«éä¿ãåæ¨£çå¯¦é«åéä¿ï¼ãååºå¨å­¸æ ¡åéãï¼ééä»¥ä¸æ¹å¼ç¢çå°èªæä»¤ï¼(i) ä½¿ç¨ç¡éä¹èªå¢çææ³ (CFG) ç¢çè¨±å¤ç¯æ¬ä¾åµå¥ç¹å®å¯¦é«åéä¿ï¼(ii) å°å¯¦é«åéä¿è¼¸å¥å¤§åèªè¨æ¨¡å (LLM) ä»¥ç¢çæä»¤ãå¨ RVS ä¸çå¨é¢è©ä¼°é¡¯ç¤ºï¼æåçåæ³å°æªè¦éç°å¢ä¸­ç 100 å¬å°ºæºç¢ºåº¦æåäº 45.83%ãæ­¤å¤ï¼æåè­æä½¿ç¨åºæ¼ CFG çæ´åæè¨ç·´çæ¨¡åï¼å¨æªè¦éåè¦éç°å¢ä¸­ï¼é½æ¯ä½¿ç¨åºæ¼ LLM çæ´åæè¨ç·´çæ¨¡åç²å¾äºæ´å¥½çæè½ãéäºç¼ç¾è¡¨æï¼å¨ä»¥åæªç¥çç°å¢ä¸­ï¼æç¢ºå»ºæ§ç¨æ¼åºæ¼æå­çå°çç©ºéæ¨ççç©ºéè³è¨çæ½å¨åªå¢ï¼å¯ä»¥è§£éè³æç¨å°çå ´æ¯ã

##### **Investigating How Large Language Models Leverage Internal Knowledge to Perform Complex Reasoning**
2406.19502v1 by Miyoung Ko, Sue Hyun Park, Joonsuk Park, Minjoon Seo

Despite significant advancements, there is a limited understanding of how
large language models (LLMs) utilize knowledge for reasoning. To address this,
we propose a method that deconstructs complex real-world questions into a
graph, representing each question as a node with parent nodes of background
knowledge needed to solve the question. We develop the DepthQA dataset,
deconstructing questions into three depths: (i) recalling conceptual knowledge,
(ii) applying procedural knowledge, and (iii) analyzing strategic knowledge.
Based on a hierarchical graph, we quantify forward discrepancy, discrepancies
in LLMs' performance on simpler sub-problems versus complex questions. We also
measure backward discrepancy, where LLMs answer complex questions but struggle
with simpler ones. Our analysis shows that smaller models have more
discrepancies than larger models. Additionally, guiding models from simpler to
complex questions through multi-turn interactions improves performance across
model sizes, highlighting the importance of structured intermediate steps in
knowledge reasoning. This work enhances our understanding of LLM reasoning and
suggests ways to improve their problem-solving abilities.

æè¦ï¼åç®¡æé¡¯èçé²å±ï¼ä½å°æ¼å¤§åèªè¨æ¨¡å (LLM) å¦ä½å©ç¨ç¥è­é²è¡æ¨çççè§£ä»ç¶æéãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸ç¨®æ¹æ³ï¼å°è¤éççå¯¦ä¸çåé¡è§£æ§æä¸ååå½¢ï¼å°æ¯ååé¡è¡¨ç¤ºçºä¸åç¯é»ï¼å¶ä¸­åå«è§£æ±ºåé¡æéçèæ¯ç¥è­çç¶ç¯é»ãæåéç¼äº DepthQA è³æéï¼å°åé¡è§£æ§æä¸åæ·±åº¦ï¼(i) åæ¶æ¦å¿µç¥è­ï¼(ii) æç¨ç¨åºç¥è­ï¼ä»¥å (iii) åæç­ç¥ç¥è­ãåºæ¼ä¸åéå±¤åå½¢ï¼æåéåäºæ­£åå·®ç°ï¼LLM å¨è¼ç°¡å®çå­åé¡åè¤éåé¡ä¸çæè½å·®ç°ãæåä¹æ¸¬éäºååå·®ç°ï¼å¶ä¸­ LLM è½åç­è¤éåé¡ï¼ä½å¨è¼ç°¡å®çåé¡ä¸å»æå°é£ãæåçåæé¡¯ç¤ºï¼è¼å°çæ¨¡åæ¯è¼å¤§çæ¨¡åææ´å¤çå·®ç°ãæ­¤å¤ï¼ééå¤ååäºåå¼å°æ¨¡åå¾è¼ç°¡å®å°è¤éçåé¡ï¼å¯ä»¥æ¹åæææ¨¡åè¦æ¨¡çæè½ï¼çªé¡¯äºçµæ§åä¸­éæ­¥é©å¨ç¥è­æ¨çä¸­çéè¦æ§ãéé å·¥ä½å¢é²äºæåå° LLM æ¨çççè§£ï¼ä¸¦æåºäºæ¹åå¶åé¡è§£æ±ºè½åçæ¹æ³ã

##### **Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment**
2406.19255v1 by Hao Fei, Shengqiong Wu, Meishan Zhang, Min Zhang, Tat-Seng Chua, Shuicheng Yan

While pre-training large-scale video-language models (VLMs) has shown
remarkable potential for various downstream video-language tasks, existing VLMs
can still suffer from certain commonly seen limitations, e.g., coarse-grained
cross-modal aligning , under-modeling of temporal dynamics, detached
video-language view. In this work, we target enhancing VLMs with a fine-grained
structural spatio-temporal alignment learning method (namely Finsta). First of
all, we represent the input texts and videos with fine-grained scene graph (SG)
structures, both of which are further unified into a holistic SG (HSG) for
bridging two modalities. Then, an SG-based framework is built, where the
textual SG (TSG) is encoded with a graph Transformer, while the video dynamic
SG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for
spatial and temporal feature propagation. A spatial-temporal Gaussian
differential graph Transformer is further devised to strengthen the sense of
the changes in objects across spatial and temporal dimensions. Next, based on
the fine-grained structural features of TSG and DSG, we perform object-centered
spatial alignment and predicate-centered temporal alignment respectively,
enhancing the video-language grounding in both the spatiality and temporality.
We design our method as a plug&play system, which can be integrated into
existing well-trained VLMs for further representation augmentation, without
training from scratch or relying on SG annotations in downstream applications.
On 6 representative VL modeling tasks over 12 datasets in both standard and
long-form video scenarios, Finsta consistently improves the existing 13
strong-performing VLMs persistently, and refreshes the current state-of-the-art
end task performance significantly in both the fine-tuning and zero-shot
settings.

æè¦ï¼<paragraph>éç¶é è¨ç·´å¤§åè¦è¨èªè¨æ¨¡å (VLM) å·²å±ç¾åºå°åç¨®ä¸æ¸¸è¦è¨èªè¨ä»»åçé¡¯èæ½åï¼ä½ç¾æç VLM ä»å¯è½åå°æäºå¸¸è¦éå¶çå½±é¿ï¼ä¾å¦ç²ç²åº¦çè·¨æ¨¡æå°é½ãå°æéåæçå»ºæ¨¡ä¸è¶³ãåé¢çè¦è¨èªè¨æª¢è¦ãå¨éé å·¥ä½ä¸­ï¼æåä»¥å·åç´°ç²åº¦çµæ§åæç©ºå°é½å­¸ç¿æ¹æ³ (å³ Finsta) çå¢å¼· VLM çºç®æ¨ãé¦åï¼æåä»¥ç´°ç²åº¦çå ´æ¯å (SG) çµæ§è¡¨ç¤ºè¼¸å¥æå­åè¦è¨ï¼å©èé²ä¸æ­¥çµ±ä¸å°ä¸åæ´é« SG (HSG) ä¸­ï¼ä»¥æ©æ¥å©åæ¨¡æãç¶å¾ï¼å»ºç«ä¸ååºæ¼ SG çæ¡æ¶ï¼å¶ä¸­æå­ SG (TSG) ä½¿ç¨åå½¢ Transformer ç·¨ç¢¼ï¼èè¦è¨åæ SG (DSG) å HSG åä½¿ç¨æ°ç©çéè¿´åå½¢ Transformer å»ºæ¨¡ï¼ä»¥é²è¡ç©ºéåæéç¹å¾µå³æ­ãé²ä¸æ­¥è¨­è¨äºä¸åæç©ºé«æ¯å·®ååå½¢ Transformerï¼ä»¥å¢å¼·ç©é«å¨æç©ºç¶­åº¦ä¸­è®åçæè¦ºãæ¥ä¸ä¾ï¼æ ¹æ TSG å DSG çç´°ç²åº¦çµæ§ç¹å¾µï¼æååå¥å·è¡ä»¥ç©ä»¶çºä¸­å¿çç©ºéå°é½åä»¥è¬è©çºä¸­å¿çæåºå°é½ï¼å¢å¼·è¦è¨èªè¨å¨ç©ºéåæéä¸çåºç¤ãæåå°æ¹æ³è¨­è¨çºä¸åå³æå³ç¨çç³»çµ±ï¼å¯ä»¥æ´åå°ç¾æçè¨ç·´è¯å¥½ç VLM ä¸­ï¼ä»¥é²ä¸æ­¥æ´åè¡¨ç¤ºï¼èç¡éå¾é ­éå§è¨ç·´æä¾è³´ä¸æ¸¸æç¨ç¨å¼ä¸­ç SG æ¨è¨»ãå¨ 12 åè³æéä¸ç 6 åä»£è¡¨æ§ VL å»ºæ¨¡ä»»åä¸­ï¼ç¡è«æ¯å¨æ¨æºè¦è¨å ´æ¯éæ¯é·æ ¼å¼è¦è¨å ´æ¯ä¸­ï¼Finsta é½æçºæ¹åç¾æç 13 åæè½å¼·å¤§ç VLMï¼ä¸¦å¨å¾®èª¿åé¶æ¬¡å­¸ç¿è¨­å®ä¸­é¡¯èæ´æ°ç®åçææ°æè¡æçµä»»åæè½ã</paragraph>

##### **TrustUQA: A Trustful Framework for Unified Structured Data Question Answering**
2406.18916v1 by Wen Zhang, Long Jin, Yushan Zhu, Jiaoyan Chen, Zhiwei Huang, Junjie Wang, Yin Hua, Lei Liang, Huajun Chen

Natural language question answering (QA) over structured data sources such as
tables and knowledge graphs (KGs) have been widely investigated, for example
with Large Language Models (LLMs). The main solutions include question to
formal query parsing and retrieval-based answer generation. However, current
methods of the former often suffer from weak generalization, failing to dealing
with multiple sources simultaneously, while the later is limited in
trustfulness. In this paper, we propose UnifiedTQA, a trustful QA framework
that can simultaneously support multiple types of structured data in a unified
way. To this end, it adopts an LLM-friendly and unified knowledge
representation method called Condition Graph (CG), and uses an LLM and
demonstration-based two-level method for CG querying. For enhancement, it is
also equipped with dynamic demonstration retrieval. We have evaluated
UnifiedTQA with 5 benchmarks covering 3 types of structured data. It
outperforms 2 existing unified structured data QA methods and in comparison
with the baselines that are specific to a data type, it achieves
state-of-the-art on 2 of them. Further more, we demonstrates potential of our
method for more general QA tasks, QA over mixed structured data and QA across
structured data.

æè¦ï¼èªç¶èªè¨åç­ (QA) ééçµæ§åè³æä¾æºï¼ä¾å¦è¡¨æ ¼åç¥è­åè­ (KGs)ï¼å·²å»£æ³ç ç©¶ï¼ä¾å¦ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM)ãä¸»è¦è§£æ±ºæ¹æ¡åæ¬åé¡è½ææå½¢å¼åæ¥è©¢è§£æååºæ¼æª¢ç´¢çç­æ¡ç¢çãç¶èï¼åèçç¾è¡æ¹æ³éå¸¸æç¢çå¼±æ³åï¼ç¡æ³åæèçå¤åä¾æºï¼èå¾èååå°å¯ä¿¡åº¦çéå¶ãå¨æ¬æä¸­ï¼æåæåº UnifiedTQAï¼ä¸åå¯ä¿¡è³´ç QA æ¡æ¶ï¼è½å¤ ä»¥çµ±ä¸çæ¹å¼åææ¯æ´å¤ç¨®é¡åççµæ§åè³æãçºæ­¤ï¼å®æ¡ç¨äºä¸ç¨® LLM ååä¸çµ±ä¸çç¥è­è¡¨ç¤ºæ¹æ³ï¼ç¨±çºæ¢ä»¶å (CG)ï¼ä¸¦ä½¿ç¨ LLM ååºæ¼ç¤ºç¯çäºéæ¹æ³é²è¡ CG æ¥è©¢ãçºäºå å¼·ï¼å®ééåäºåæç¤ºç¯æª¢ç´¢ãæåå·²ç¶ä½¿ç¨æ¶µè 3 ç¨®é¡åçµæ§åè³æç 5 ååºæºè©ä¼° UnifiedTQAãå®åªæ¼ 2 ç¨®ç¾æççµ±ä¸çµæ§åè³æ QA æ¹æ³ï¼ä¸¦ä¸èç¹å®æ¼è³æé¡åçåºç·ç¸æ¯ï¼å®å¨å¶ä¸­ 2 ååºæºä¸éå°äºæåé²çæ°´å¹³ãæ­¤å¤ï¼æåå±ç¤ºäºæåçæ¹æ³å¨æ´éç¨ç QA ä»»åãæ··åçµæ§åè³æç QA åè·¨çµæ§åè³æç QA ä¸­çæ½åã

##### **Fast Optimizer Benchmark**
2406.18701v1 by Simon Blauth, Tobias BÃ¼rger, Zacharias HÃ¤ringer, JÃ¶rg Franke, Frank Hutter

In this paper, we present the Fast Optimizer Benchmark (FOB), a tool designed
for evaluating deep learning optimizers during their development. The benchmark
supports tasks from multiple domains such as computer vision, natural language
processing, and graph learning. The focus is on convenient usage, featuring
human-readable YAML configurations, SLURM integration, and plotting utilities.
FOB can be used together with existing hyperparameter optimization (HPO) tools
as it handles training and resuming of runs. The modular design enables
integration into custom pipelines, using it simply as a collection of tasks. We
showcase an optimizer comparison as a usage example of our tool. FOB can be
found on GitHub: https://github.com/automl/FOB.

æè¦ï¼å¨æ¬æä¸­ï¼æåæåºäºå¿«éåªåå¨åºæº (FOB)ï¼éæ¯ä¸åç¨æ¼å¨éç¼éç¨ä¸­è©ä¼°æ·±åº¦å­¸ç¿åªåå¨çå·¥å·ãåºæºæ¯æä¾èªå¤åé åçä»»åï¼ä¾å¦é»è¦è¦è¦ºãèªç¶èªè¨èçååå½¢å­¸ç¿ãéé»å¨æ¼æ¹ä¾¿ä½¿ç¨ï¼å·æäººé¡å¯è®ç YAML éç½®ãSLURM æ´ååç¹ªåç¨å¼ãFOB å¯ä»¥èç¾æçè¶åæ¸åªå (HPO) å·¥å·ä¸èµ·ä½¿ç¨ï¼å çºå®å¯ä»¥èçè¨ç·´åæ¢å¾©éè¡ãæ¨¡çµåè¨­è¨è½å¤ æ´åå°èªè¨ç®¡ç·ä¸­ï¼åªéå°å¶ç¨ä½ä»»åéåå³å¯ãæåå±ç¤ºäºä¸ååªåå¨æ¯è¼ä½çºæåå·¥å·çä½¿ç¨ç¯ä¾ãFOB å¯ä»¥å¾ GitHub æ¾å°ï¼https://github.com/automl/FOBã

##### **Cascading Large Language Models for Salient Event Graph Generation**
2406.18449v1 by Xingwei Tan, Yuxiang Zhou, Gabriele Pergola, Yulan He

Generating event graphs from long documents is challenging due to the
inherent complexity of multiple tasks involved such as detecting events,
identifying their relationships, and reconciling unstructured input with
structured graphs. Recent studies typically consider all events with equal
importance, failing to distinguish salient events crucial for understanding
narratives. This paper presents CALLMSAE, a CAscading Large Language Model
framework for SAlient Event graph generation, which leverages the capabilities
of LLMs and eliminates the need for costly human annotations. We first identify
salient events by prompting LLMs to generate summaries, from which salient
events are identified. Next, we develop an iterative code refinement prompting
strategy to generate event relation graphs, removing hallucinated relations and
recovering missing edges. Fine-tuning contextualised graph generation models on
the LLM-generated graphs outperforms the models trained on CAEVO-generated
data. Experimental results on a human-annotated test set show that the proposed
method generates salient and more accurate graphs, outperforming competitive
baselines.

æè¦ï¼ç±æ¼æ¶åå¤é ä»»åçå§å¨è¤éæ§ï¼ä¾å¦åµæ¸¬äºä»¶ãè­å¥å¶éä¿ï¼ä»¥åèª¿åéçµæ§åè¼¸å¥èçµæ§ååè¡¨ï¼å æ­¤å¾é·ç¯æä»¶ç¢çäºä»¶åè¡¨æ¯ä¸é ææ°ãæè¿çç ç©¶éå¸¸å°ææäºä»¶è¦çºåç­éè¦ï¼æªè½ååå°çè§£æäºè³ééè¦çé¡¯èäºä»¶ãæ¬ææåºäº CALLMSAEï¼ä¸åç¨æ¼çæé¡¯èäºä»¶åè¡¨çå±¤çå¼å¤§åèªè¨æ¨¡åæ¡æ¶ï¼å®å©ç¨äº LLM çåè½ï¼ä¸¦æ¶é¤äºå°æè²´çäººå·¥æ¨è¨»çéæ±ãæåé¦åééæç¤º LLM ç¢çæè¦ä¾è­å¥é¡¯èäºä»¶ï¼å¾ä¸­è­å¥åºé¡¯èäºä»¶ãæ¥ä¸ä¾ï¼æåéç¼äºä¸ç¨®åè¦çç¨å¼ç¢¼ç²¾çæç¤ºç­ç¥ä¾ç¢çäºä»¶éä¿åè¡¨ï¼ç§»é¤å¹»è¦ºéä¿ä¸¦æ¢å¾©éºå¤±çéç·£ãå¨ LLM çæçåè¡¨ä¸å¾®èª¿æå¢ååè¡¨çææ¨¡åï¼å¶è¡¨ç¾åªæ¼å¨ CAEVO çæçè³æä¸è¨ç·´çæ¨¡åãå¨äººå·¥æ¨è¨»çæ¸¬è©¦éä¸çå¯¦é©çµæé¡¯ç¤ºï¼ææåºçæ¹æ³ç¢çäºé¡¯èä¸æ´æºç¢ºçåè¡¨ï¼åªæ¼ç«¶ç­æ§çåºæºã

##### **Sanskrit Knowledge-based Systems: Annotation and Computational Tools**
2406.18276v1 by Hrishikesh Terdalkar

We address the challenges and opportunities in the development of knowledge
systems for Sanskrit, with a focus on question answering. By proposing a
framework for the automated construction of knowledge graphs, introducing
annotation tools for ontology-driven and general-purpose tasks, and offering a
diverse collection of web-interfaces, tools, and software libraries, we have
made significant contributions to the field of computational Sanskrit. These
contributions not only enhance the accessibility and accuracy of Sanskrit text
analysis but also pave the way for further advancements in knowledge
representation and language processing. Ultimately, this research contributes
to the preservation, understanding, and utilization of the rich linguistic
information embodied in Sanskrit texts.

æè¦ï¼æåèæè§£æ±ºæ¢µèªç¥è­ç³»çµ±éç¼ä¸­çææ°åæ©æï¼éé»å¨æ¼åé¡è§£ç­ãééæåºä¸åç¨æ¼èªåå»ºæ§ç¥è­åè­çæ¶æ§ï¼å°å¥ç¨æ¼æ¬é«é©ååä¸è¬ç¨éä»»åçè¨»è§£å·¥å·ï¼ä¸¦æä¾å¤æ¨£åçç¶²è·¯ä»é¢ãå·¥å·åè»é«å½å¼åº«ï¼æåå°è¨ç®æ¢µèªé åååºäºéå¤§è²¢ç»ãéäºè²¢ç»ä¸åå¢å¼·äºæ¢µèªææ¬åæçå¯å­åæ§åæºç¢ºæ§ï¼ä¹çºç¥è­è¡¨å¾µåèªè¨èççé²ä¸æ­¥é²å±éªå¹³äºéè·¯ãæçµï¼éé ç ç©¶æå©æ¼ä¿å­ãçè§£åå©ç¨æ¢µèªææ¬ä¸­èå«çè±å¯èªè¨è³è¨ã

##### **Multilingual Knowledge Graph Completion from Pretrained Language Models with Knowledge Constraints**
2406.18085v1 by Ran Song, Shizhu He, Shengxiang Gao, Li Cai, Kang Liu, Zhengtao Yu, Jun Zhao

Multilingual Knowledge Graph Completion (mKGC) aim at solving queries like
(h, r, ?) in different languages by reasoning a tail entity t thus improving
multilingual knowledge graphs. Previous studies leverage multilingual
pretrained language models (PLMs) and the generative paradigm to achieve mKGC.
Although multilingual pretrained language models contain extensive knowledge of
different languages, its pretraining tasks cannot be directly aligned with the
mKGC tasks. Moreover, the majority of KGs and PLMs currently available exhibit
a pronounced English-centric bias. This makes it difficult for mKGC to achieve
good results, particularly in the context of low-resource languages. To
overcome previous problems, this paper introduces global and local knowledge
constraints for mKGC. The former is used to constrain the reasoning of answer
entities, while the latter is used to enhance the representation of query
contexts. The proposed method makes the pretrained model better adapt to the
mKGC task. Experimental results on public datasets demonstrate that our method
outperforms the previous SOTA on Hits@1 and Hits@10 by an average of 12.32% and
16.03%, which indicates that our proposed method has significant enhancement on
mKGC.

æè¦ï¼å¤èªè¨ç¥è­åè­å®æ (mKGC) æ¨å¨ééæ¨çå°¾é¨å¯¦é« t ä¾è§£æ±ºä¸åèªè¨ä¸­çæ¥è©¢ï¼ä¾å¦ (h, r, ?)ï¼é²èæ¹åå¤èªè¨ç¥è­åè­ãååçç ç©¶å©ç¨å¤èªè¨é è¨ç·´èªè¨æ¨¡å (PLM) åçæç¯ä¾ä¾éæ mKGCãåç®¡å¤èªè¨é è¨ç·´èªè¨æ¨¡ååå«ä¸åèªè¨çå»£æ³ç¥è­ï¼ä½å¶é è¨ç·´ä»»åç¡æ³ç´æ¥è mKGC ä»»åå°é½ãæ­¤å¤ï¼ç®åå¤§å¤æ¸çç¥è­åè­å PLM é½å±ç¾åºæé¡¯çè±èªä¸­å¿åèª¤ãéä½¿å¾ mKGC é£ä»¥éæè¯å¥½ççµæï¼ç¹å¥æ¯å¨ä½è³æºèªè¨çèçµ¡ä¸­ãçºäºåæååçåé¡ï¼æ¬æéå° mKGC å¼å¥äºå¨åèå±é¨ç¥è­éå¶ãåèç¨æ¼éå¶ç­æ¡å¯¦é«çæ¨çï¼èå¾èç¨æ¼å å¼·æ¥è©¢èçµ¡çè¡¨ç¤ºãææåºçæ¹æ³ä½¿å¾é è¨ç·´æ¨¡åè½æ´å¥½å°é©æ mKGC ä»»åãå¬éè³æéä¸çå¯¦é©çµæé¡¯ç¤ºï¼æåçæ¨¡åå¨ Hits@1 å Hits@10 ä¸å¹³ååªæ¼ååç SOTA 12.32% å 16.03%ï¼éè¡¨ç¤ºæåæåºçæ¹æ³é¡¯èå°å¢å¼·äº mKGCã

##### **AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning**
2406.18060v1 by Yifan Yang, Kai Zhen, Ershad Banijamal, Athanasios Mouchtaris, Zheng Zhang

Fine-tuning large language models (LLMs) has achieved remarkable performance
across various natural language processing tasks, yet it demands more and more
memory as model sizes keep growing. To address this issue, the recently
proposed Memory-efficient Zeroth-order (MeZO) methods attempt to fine-tune LLMs
using only forward passes, thereby avoiding the need for a backpropagation
graph. However, significant performance drops and a high risk of divergence
have limited their widespread adoption. In this paper, we propose the Adaptive
Zeroth-order Tensor-Train Adaption (AdaZeta) framework, specifically designed
to improve the performance and convergence of the ZO methods. To enhance
dimension-dependent ZO estimation accuracy, we introduce a fast-forward,
low-parameter tensorized adapter. To tackle the frequently observed divergence
issue in large-scale ZO fine-tuning tasks, we propose an adaptive query number
schedule that guarantees convergence. Detailed theoretical analysis and
extensive experimental results on Roberta-Large and Llama-2-7B models
substantiate the efficacy of our AdaZeta framework in terms of accuracy, memory
efficiency, and convergence speed.

æè¦ï¼å¾®è°å¤§åè¯­è¨æ¨¡å (LLM) å¨åç§èªç¶è¯­è¨å¤çä»»å¡ä¸­åå¾äºæ¾èçæ§è½ï¼ä½éçæ¨¡åè§æ¨¡çä¸æ­æ©å¤§ï¼å®å¯¹åå­çéæ±ä¹è¶æ¥è¶å¤§ãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æè¿æåºçåå­é«æé¶é¶ (MeZO) æ¹æ³è¯å¾ä»ä½¿ç¨ååä¼ éæ¥å¾®è° LLMï¼ä»èé¿åäºå¯¹ååä¼ æ­å¾çéæ±ãç¶èï¼ä¸¥éçæ§è½ä¸éååæ£çé«é£é©éå¶äºå®ä»¬çå¹¿æ³éç¨ãå¨æ¬æä¸­ï¼æä»¬æåºäºèªéåºé¶é¶å¼ éè®­ç»èªéåº (AdaZeta) æ¡æ¶ï¼ä¸é¨è®¾è®¡ç¨äºæé« ZO æ¹æ³çæ§è½åæ¶ææ§ãä¸ºäºå¢å¼ºç»´åº¦ç¸å³ç ZO ä¼°è®¡ç²¾åº¦ï¼æä»¬å¼å¥äºä¸ä¸ªå¿«éååãä½åæ°å¼ éåééå¨ãä¸ºäºè§£å³å¨å¤§è§æ¨¡ ZO å¾®è°ä»»å¡ä¸­ç»å¸¸è§å¯å°çåæ£é®é¢ï¼æä»¬æåºäºä¸ä¸ªèªéåºæ¥è¯¢æ°éè®¡åï¼ä»¥ä¿è¯æ¶ææ§ãå¯¹ Roberta-Large å Llama-2-7B æ¨¡åçè¯¦ç»çè®ºåæåå¹¿æ³çå®éªç»æè¯æäºæä»¬ç AdaZeta æ¡æ¶å¨åç¡®æ§ãåå­æçåæ¶æéåº¦æ¹é¢çæææ§ã

##### **DARG: Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph**
2406.17271v1 by Zhehao Zhang, Jiaao Chen, Diyi Yang

The current paradigm of evaluating Large Language Models (LLMs) through
static benchmarks comes with significant limitations, such as vulnerability to
data contamination and a lack of adaptability to the evolving capabilities of
LLMs. Therefore, evaluation methods that can adapt and generate evaluation data
with controlled complexity are urgently needed. In this work, we introduce
Dynamic Evaluation of LLMs via Adaptive Reasoning Graph Evolvement (DARG) to
dynamically extend current benchmarks with controlled complexity and diversity.
Specifically, we first extract the reasoning graphs of data points in current
benchmarks and then perturb the reasoning graphs to generate novel testing
data. Such newly generated test samples can have different levels of complexity
while maintaining linguistic diversity similar to the original benchmarks. We
further use a code-augmented LLM to ensure the label correctness of newly
generated data. We apply our DARG framework to diverse reasoning tasks in four
domains with 15 state-of-the-art LLMs. Experimental results show that almost
all LLMs experience a performance decrease with increased complexity and
certain LLMs exhibit significant drops. Additionally, we find that LLMs exhibit
more biases when being evaluated via the data generated by DARG with higher
complexity levels. These observations provide useful insights into how to
dynamically and adaptively evaluate LLMs. The code is available at
https://github.com/SALT-NLP/DARG.

æè¦ï¼ç®åéééæåºæºè©ä¼°å¤§åèªè¨æ¨¡å (LLM) çç¯ä¾ä¼´é¨èé¡¯èçéå¶ï¼ä¾å¦å®¹æåå°è³ææ±¡æï¼ä»¥åç¼ºä¹é©æ LLM ä¸æ·æ¼é²çè½åãå æ­¤ï¼è¿«åéè¦è½å¤ é©æä¸¦ç¢çå·æåæ§è¤éæ§çè©ä¼°è³æçè©ä¼°æ¹æ³ãå¨éé å·¥ä½ä¸­ï¼æåééèªé©ææ¨çåå½¢æ¼å (DARG) å¼å¥ LLM çåæè©ä¼°ï¼ä»¥åæå»¶ä¼¸ç®åå·æåæ§è¤éæ§åå¤æ¨£æ§çåºæºãå·é«ä¾èªªï¼æåé¦åæ·åç®ååºæºä¸­è³æé»çæ¨çåå½¢ï¼ç¶å¾æ¾åæ¨çåå½¢ä»¥ç¢çæ°çæ¸¬è©¦è³æãéäºæ°ç¢ççæ¸¬è©¦æ¨£æ¬å¯ä»¥æä¸åçè¤éæ§å±¤ç´ï¼åæç¶­æèåå§åºæºé¡ä¼¼çèªè¨å¤æ¨£æ§ãæåé²ä¸æ­¥ä½¿ç¨ç¨å¼ç¢¼å¢å¼·ç LLM ä¾ç¢ºä¿æ°ç¢çè³æçæ¨ç±¤æ­£ç¢ºæ§ãæåå° DARG æ¶æ§å¥ç¨æ¼ååé åä¸­çåç¨®æ¨çä»»åï¼ä¸¦ä½¿ç¨ 15 åæåé²ç LLMãå¯¦é©çµæé¡¯ç¤ºï¼å¹¾ä¹ææ LLM å¨è¤éæ§å¢å çææ³ä¸é½æåºç¾æè½ä¸éï¼èæäº LLM åè¡¨ç¾åºé¡¯èçä¸éãæ­¤å¤ï¼æåç¼ç¾ LLM å¨éé DARG ç¢çå·æè¼é«è¤éæ§å±¤ç´çè³æé²è¡è©ä¼°æï¼æè¡¨ç¾åºæ´å¤åå·®ãéäºè§å¯çµææä¾äºæç¨çè¦è§£ï¼èªªæå¦ä½åæä¸èªé©æå°è©ä¼° LLMãç¨å¼ç¢¼å¯å¨ https://github.com/SALT-NLP/DARG åå¾ã

##### **CogMG: Collaborative Augmentation Between Large Language Model and Knowledge Graph**
2406.17231v1 by Tong Zhou, Yubo Chen, Kang Liu, Jun Zhao

Large language models have become integral to question-answering applications
despite their propensity for generating hallucinations and factually inaccurate
content. Querying knowledge graphs to reduce hallucinations in LLM meets the
challenge of incomplete knowledge coverage in knowledge graphs. On the other
hand, updating knowledge graphs by information extraction and knowledge graph
completion faces the knowledge update misalignment issue. In this work, we
introduce a collaborative augmentation framework, CogMG, leveraging knowledge
graphs to address the limitations of LLMs in QA scenarios, explicitly targeting
the problems of incomplete knowledge coverage and knowledge update
misalignment. The LLMs identify and decompose required knowledge triples that
are not present in the KG, enriching them and aligning updates with real-world
demands. We demonstrate the efficacy of this approach through a supervised
fine-tuned LLM within an agent framework, showing significant improvements in
reducing hallucinations and enhancing factual accuracy in QA responses. Our
code and video are publicly available.

æè¦ï¼å¤§åèªè¨æ¨¡åå·²æçºåç­æç¨ç¨å¼ä¸­ä¸å¯æç¼ºçä¸é¨åï¼åç®¡å®åå¾åæ¼ç¢çå¹»è¦ºåäºå¯¦ä¸æ­£ç¢ºçå§å®¹ãæ¥è©¢ç¥è­åè¡¨ä»¥æ¸å° LLM ä¸­çå¹»è¦ºæéå°ç¥è­åè¡¨ä¸­ç¥è­è¦èä¸å®æ´çææ°ãå¦ä¸æ¹é¢ï¼ééè³è¨èååç¥è­åè¡¨å®æä¾æ´æ°ç¥è­åè¡¨æé¢è¨ç¥è­æ´æ°é¯ä½åé¡ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºåä½æ´åæ¶æ§ CogMGï¼å©ç¨ç¥è­åè¡¨ä¾è§£æ±º LLM å¨ QA å ´æ¯ä¸­çéå¶ï¼æç¢ºéå°ä¸å®æ´çç¥è­è¦èåç¥è­æ´æ°é¯ä½åé¡ãLLM è­å¥ä¸¦åè§£ KG ä¸­ä¸å­å¨çæéç¥è­ä¸åçµï¼è±å¯å®åä¸¦å°æ´æ°èç¾å¯¦ä¸ççéæ±ä¿æä¸è´ãæåééä»£çæ¶æ§ä¸­ç£ç£å¾®èª¿ç LLM å±ç¤ºäºéç¨®æ¹æ³çåæï¼é¡¯ç¤ºåºå¨æ¸å°å¹»è¦ºåå¢å¼· QA åæä¸­çäºå¯¦æºç¢ºæ§æ¹é¢æé¡¯èçæ¹é²ãæåçç¨å¼ç¢¼åå½±çå¬éæä¾ã

##### **Link Prediction with Untrained Message Passing Layers**
2406.16687v1 by Lisi Qarkaxhija, Anatol E. Wegner, Ingo Scholtes

Message passing neural networks (MPNNs) operate on graphs by exchanging
information between neigbouring nodes. MPNNs have been successfully applied to
various node-, edge-, and graph-level tasks in areas like molecular science,
computer vision, natural language processing, and combinatorial optimization.
However, most MPNNs require training on large amounts of labeled data, which
can be costly and time-consuming. In this work, we explore the use of various
untrained message passing layers in graph neural networks, i.e. variants of
popular message passing architecture where we remove all trainable parameters
that are used to transform node features in the message passing step. Focusing
on link prediction, we find that untrained message passing layers can lead to
competitive and even superior performance compared to fully trained MPNNs,
especially in the presence of high-dimensional features. We provide a
theoretical analysis of untrained message passing by relating the inner
products of features implicitly produced by untrained message passing layers to
path-based topological node similarity measures. As such, untrained message
passing architectures can be viewed as a highly efficient and interpretable
approach to link prediction.

æè¦ï¼è¨æ¯å³éç¥ç¶ç¶²è·¯ (MPNN) ééäº¤æé°è¿ç¯é»ä¹éçè³è¨ä¾èçåå½¢ãMPNN å·²æåæç¨æ¼åç¨®ç¯é»ãéç·£ååå½¢å±¤ç´çä»»åï¼ä¾å¦åå­ç§å­¸ãé»è¦è¦è¦ºãèªç¶èªè¨èçåçµåæä½³åãç¶èï¼å¤§å¤æ¸ MPNN éè¦å¤§éæ¨ç±¤è³ææè½é²è¡è¨ç·´ï¼éå¯è½æå¾æè²´ä¸èæãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨äºå¨åå½¢ç¥ç¶ç¶²è·¯ä¸­ä½¿ç¨åç¨®æªè¨ç·´çè¨æ¯å³éå±¤ï¼ä¹å°±æ¯èªªï¼æåç§»é¤äºææç¨æ¼å¨è¨æ¯å³éæ­¥é©ä¸­è½æç¯é»ç¹å¾µçå¯è¨ç·´åæ¸ï¼éæ¯ç±éè¨æ¯å³éæ¶æ§çè®é«ãå°æ³¨æ¼é£çµé æ¸¬ï¼æåç¼ç¾æªè¨ç·´çè¨æ¯å³éå±¤å¯ä»¥ç¢çå·æç«¶ç­åï¼çè³åªæ¼å®å¨è¨ç·´ç MPNN çæè½ï¼å°¤å¶æ¯å¨å­å¨é«ç¶­ç¹å¾µçææ³ä¸ãæåééå°æªè¨ç·´çè¨æ¯å³éå±¤é±å«ç¢ççç¹å¾µçå§ç©èåºæ¼è·¯å¾çææ²ç¯é»ç¸ä¼¼åº¦æ¸¬ééè¯ï¼æä¾æªè¨ç·´è¨æ¯å³éççè«åæãå æ­¤ï¼æªè¨ç·´çè¨æ¯å³éæ¶æ§å¯ä»¥è¦çºä¸ç¨®é«åº¦ææä¸å¯è§£éçé£çµé æ¸¬æ¹æ³ã

##### **CLEAR: Can Language Models Really Understand Causal Graphs?**
2406.16605v1 by Sirui Chen, Mengying Xu, Kun Wang, Xingyu Zeng, Rui Zhao, Shengjie Zhao, Chaochao Lu

Causal reasoning is a cornerstone of how humans interpret the world. To model
and reason about causality, causal graphs offer a concise yet effective
solution. Given the impressive advancements in language models, a crucial
question arises: can they really understand causal graphs? To this end, we
pioneer an investigation into language models' understanding of causal graphs.
Specifically, we develop a framework to define causal graph understanding, by
assessing language models' behaviors through four practical criteria derived
from diverse disciplines (e.g., philosophy and psychology). We then develop
CLEAR, a novel benchmark that defines three complexity levels and encompasses
20 causal graph-based tasks across these levels. Finally, based on our
framework and benchmark, we conduct extensive experiments on six leading
language models and summarize five empirical findings. Our results indicate
that while language models demonstrate a preliminary understanding of causal
graphs, significant potential for improvement remains. Our project website is
at https://github.com/OpenCausaLab/CLEAR.

æè¦ï¼å ææ¨çæ¯äººé¡è©®éä¸ççåºç³ãçºäºå°å æéä¿å»ºæ¨¡åæ¨çï¼å æåæä¾äºä¸åç°¡æ½èææçè§£æ±ºæ¹æ¡ãéæ¼èªè¨æ¨¡åçé©äººé²æ­¥ï¼ä¸åééµåé¡åºç¾äºï¼å®åççè½çè§£å æååï¼çºæ­¤ï¼æåçåå°èªè¨æ¨¡åå°å æåççè§£é²è¡äºèª¿æ¥ãå·é«ä¾èªªï¼æåéç¼äºä¸åæ¡æ¶ä¾å®ç¾©å æåçè§£ï¼ééå¾ä¸åå­¸ç§ï¼ä¾å¦å²å­¸åå¿çå­¸ï¼è¡ççååå¯¦ç¨æ¨æºä¾è©ä¼°èªè¨æ¨¡åçè¡çºãç¶å¾ï¼æåéç¼äº CLEARï¼ä¸åæ°çåºæºï¼å®å®ç¾©äºä¸åè¤éæ§ç´å¥ï¼ä¸¦æ¶µèäºéäºç´å¥ä¸­ç 20 ååºæ¼å æåçä»»åãæå¾ï¼åºæ¼æåçæ¡æ¶ååºæºï¼æåå°å­åé åçèªè¨æ¨¡åé²è¡äºå»£æ³çå¯¦é©ï¼ä¸¦ç¸½çµäºäºé å¯¦è­ç¼ç¾ãæåççµæè¡¨æï¼åç®¡èªè¨æ¨¡åå±ç¤ºäºå°å æåçåæ­¥çè§£ï¼ä½ä»æå¾å¤§çæ¹é²æ½åãæåçé ç®ç¶²ç«ä½æ¼ https://github.com/OpenCausaLab/CLEARã

##### **KEHRL: Learning Knowledge-Enhanced Language Representations with Hierarchical Reinforcement Learning**
2406.16374v1 by Dongyang Li, Taolin Zhang, Longtao Huang, Chengyu Wang, Xiaofeng He, Hui Xue

Knowledge-enhanced pre-trained language models (KEPLMs) leverage relation
triples from knowledge graphs (KGs) and integrate these external data sources
into language models via self-supervised learning. Previous works treat
knowledge enhancement as two independent operations, i.e., knowledge injection
and knowledge integration. In this paper, we propose to learn
Knowledge-Enhanced language representations with Hierarchical Reinforcement
Learning (KEHRL), which jointly addresses the problems of detecting positions
for knowledge injection and integrating external knowledge into the model in
order to avoid injecting inaccurate or irrelevant knowledge. Specifically, a
high-level reinforcement learning (RL) agent utilizes both internal and prior
knowledge to iteratively detect essential positions in texts for knowledge
injection, which filters out less meaningful entities to avoid diverting the
knowledge learning direction. Once the entity positions are selected, a
relevant triple filtration module is triggered to perform low-level RL to
dynamically refine the triples associated with polysemic entities through
binary-valued actions. Experiments validate KEHRL's effectiveness in probing
factual knowledge and enhancing the model's performance on various natural
language understanding tasks.

æè¦ï¼ç¥è­å¢å¼·é è¨ç·´èªè¨æ¨¡å (KEPLM) å©ç¨ç¥è­åè­ (KG) ä¸­çéè¯ä¸åçµï¼ä¸¦ééèªæç£ç£å¼å­¸ç¿å°éäºå¤é¨è³æä¾æºæ´åå°èªè¨æ¨¡åä¸­ãååçç ç©¶å°ç¥è­å¢å¼·è¦çºå©åç¨ç«çæä½ï¼å³ç¥è­æ³¨å¥åç¥è­æ´åãå¨æ¬æä¸­ï¼æåå»ºè­°ä½¿ç¨åå±¤å¼·åå­¸ç¿ (KEHRL) å­¸ç¿ç¥è­å¢å¼·èªè¨è¡¨å¾µï¼éå±åè§£æ±ºäºåµæ¸¬ç¥è­æ³¨å¥ä½ç½®åå°å¤é¨ç¥è­æ´åå°æ¨¡åä¸­çåé¡ï¼ä»¥é¿åæ³¨å¥ä¸æºç¢ºæä¸ç¸éçç¥è­ãå·é«ä¾èªªï¼é«éå¼·åå­¸ç¿ (RL) ä»£çä½¿ç¨å§é¨ååé©ç¥è­ï¼åè¦åµæ¸¬æå­ä¸­ç¥è­æ³¨å¥çéè¦ä½ç½®ï¼éæéæ¿¾æè¼ä¸éè¦çå¯¦é«ï¼ä»¥é¿åè½ç§»ç¥è­å­¸ç¿æ¹åãä¸æ¦é¸å®å¯¦é«ä½ç½®ï¼å°±æè§¸ç¼ç¸éçä¸åçµéæ¿¾æ¨¡çµï¼ééäºé²å¶åä½åæç²¾çèå¤ç¾©å¯¦é«ç¸éçä¸åçµãå¯¦é©é©è­äº KEHRL å¨æ¢æ¥äºå¯¦ç¥è­åå¢å¼·æ¨¡åå¨åç¨®èªç¶èªè¨çè§£ä»»åä¸çæè½ã

##### **Prompt-Consistency Image Generation (PCIG): A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models**
2406.16333v1 by Yichen Sun, Zhixuan Chu, Zhan Qin, Kui Ren

The rapid advancement of Text-to-Image(T2I) generative models has enabled the
synthesis of high-quality images guided by textual descriptions. Despite this
significant progress, these models are often susceptible in generating contents
that contradict the input text, which poses a challenge to their reliability
and practical deployment. To address this problem, we introduce a novel
diffusion-based framework to significantly enhance the alignment of generated
images with their corresponding descriptions, addressing the inconsistency
between visual output and textual input. Our framework is built upon a
comprehensive analysis of inconsistency phenomena, categorizing them based on
their manifestation in the image. Leveraging a state-of-the-art large language
module, we first extract objects and construct a knowledge graph to predict the
locations of these objects in potentially generated images. We then integrate a
state-of-the-art controllable image generation model with a visual text
generation module to generate an image that is consistent with the original
prompt, guided by the predicted object locations. Through extensive experiments
on an advanced multimodal hallucination benchmark, we demonstrate the efficacy
of our approach in accurately generating the images without the inconsistency
with the original prompt. The code can be accessed via
https://github.com/TruthAI-Lab/PCIG.

æè¦ï¼ææ¬å°å¾å (T2I) çææ¨¡åçå¿«éè¿æ­¥ä½¿å¾åæç±ææ¬æè¿°å¼å¯¼çé«è´¨éå¾åæä¸ºå¯è½ãå°½ç®¡åå¾äºè¿äºéå¤§è¿å±ï¼ä½è¿äºæ¨¡åå¨çæä¸è¾å¥ææ¬ç¸çç¾çåå®¹æ¹é¢éå¸¸å¾ææï¼è¿å¯¹å®ä»¬çå¯é æ§åå®éé¨ç½²æåºäºææãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æä»¬å¼å¥äºä¸ä¸ªæ°é¢çåºäºæ©æ£çæ¡æ¶ï¼ä»¥æ¾çå¢å¼ºçæå¾åä¸å¶ç¸åºæè¿°çä¸è´æ§ï¼è§£å³è§è§è¾åºåææ¬è¾å¥ä¹é´çä¸ä¸è´æ§ãæä»¬çæ¡æ¶å»ºç«å¨å¯¹ä¸ä¸è´ç°è±¡çå¨é¢åæä¹ä¸ï¼æ ¹æ®å®ä»¬å¨å¾åä¸­çè¡¨ç°å¯¹å®ä»¬è¿è¡åç±»ãå©ç¨æåè¿çå¤§åè¯­è¨æ¨¡åï¼æä»¬é¦åæåå¯¹è±¡å¹¶æå»ºç¥è¯å¾è°±æ¥é¢æµè¿äºå¯¹è±¡å¨æ½å¨çæçå¾åä¸­çä½ç½®ãç¶åï¼æä»¬å°æåè¿çå¯æ§å¾åçææ¨¡åä¸è§è§ææ¬çææ¨¡åéæå¨ä¸èµ·ï¼ä»¥çæä¸åå§æç¤ºä¸è´çå¾åï¼å¹¶ç±é¢æµçå¯¹è±¡ä½ç½®å¼å¯¼ãéè¿å¨é«çº§å¤æ¨¡æå¹»è§åºåä¸è¿è¡å¹¿æ³çå®éªï¼æä»¬å±ç¤ºäºæä»¬çæ¹æ³å¨åç¡®çæå¾åæ¹é¢çæææ§ï¼èä¸ä¼ä¸åå§æç¤ºä¸ä¸è´ãå¯ä»¥éè¿ https://github.com/TruthAI-Lab/PCIG è®¿é®ä»£ç ã

##### **Graph-Augmented LLMs for Personalized Health Insights: A Case Study in Sleep Analysis**
2406.16252v2 by Ajan Subramanian, Zhongqi Yang, Iman Azimi, Amir M. Rahmani

Health monitoring systems have revolutionized modern healthcare by enabling
the continuous capture of physiological and behavioral data, essential for
preventive measures and early health intervention. While integrating this data
with Large Language Models (LLMs) has shown promise in delivering interactive
health advice, traditional methods like Retrieval-Augmented Generation (RAG)
and fine-tuning often fail to fully utilize the complex, multi-dimensional, and
temporally relevant data from wearable devices. These conventional approaches
typically provide limited actionable and personalized health insights due to
their inadequate capacity to dynamically integrate and interpret diverse health
data streams. In response, this paper introduces a graph-augmented LLM
framework designed to significantly enhance the personalization and clarity of
health insights. Utilizing a hierarchical graph structure, the framework
captures inter and intra-patient relationships, enriching LLM prompts with
dynamic feature importance scores derived from a Random Forest Model. The
effectiveness of this approach is demonstrated through a sleep analysis case
study involving 20 college students during the COVID-19 lockdown, highlighting
the potential of our model to generate actionable and personalized health
insights efficiently. We leverage another LLM to evaluate the insights for
relevance, comprehensiveness, actionability, and personalization, addressing
the critical need for models that process and interpret complex health data
effectively. Our findings show that augmenting prompts with our framework
yields significant improvements in all 4 criteria. Through our framework, we
can elicit well-crafted, more thoughtful responses tailored to a specific
patient.

æè¦ï¼å¥åº·ç£æ§ç³»çµ±ééæçºæ¶éççåè¡çºè³æï¼å¾¹åºæ¹è®äºç¾ä»£é«çä¿å¥ï¼éäºè³æå°æ¼é é²æªæ½åæ©æå¥åº·å¹²é è³ééè¦ãéç¶å°éäºè³æèå¤§åèªè¨æ¨¡å (LLM) æ´åï¼å·²å±ç¾åºæä¾äºåå¼å¥åº·å»ºè­°çæ½åï¼ä½å³çµ±æ¹æ³ï¼ä¾å¦æª¢ç´¢æ´åçæ (RAG) åå¾®èª¿ï¼éå¸¸ç¡æ³ååå©ç¨ç©¿æ´å¼è£ç½®ä¸­è¤éãå¤é¢åä¸èæéç¸éçè³æãéäºå³çµ±æ¹æ³éå¸¸ææä¾æéçå¯è¡ä¸åäººåçå¥åº·è¦è§£ï¼å çºå®åç¡æ³åææ´ååè©®éä¸åçå¥åº·è³æä¸²æµãçºäºè§£æ±ºéååé¡ï¼æ¬æä»ç´¹äºä¸ååå½¢æ´å LLM æ¶æ§ï¼æ¨å¨å¤§å¹æåå¥åº·è¦è§£çåäººååæ¸æ°åº¦ãéåæ¶æ§å©ç¨éå±¤å¼åå½¢çµæ§ï¼æ·åæ£èä¹éåæ£èå§é¨çéä¿ï¼ä¸¦ä½¿ç¨å¾ Random Forest æ¨¡åè¡ççåæç¹å¾µéè¦æ§è©åï¼è±å¯ LLM æç¤ºãééä¸é ç¡ç åææ¡ä¾ç ç©¶ï¼å¨ COVID-19 å°éæééå° 20 åå¤§å­¸çé²è¡ï¼è­æäºéåæ¹æ³çæææ§ï¼çªé¡¯äºæåçæ¨¡åå¨ææç¢çå¯è¡ä¸åäººåçå¥åº·è¦è§£æ¹é¢çæ½åãæåå©ç¨å¦ä¸å LLM è©ä¼°è¦è§£çç¸éæ§ãå¨é¢æ§ãå¯è¡æ§ååäººåï¼æ»¿è¶³äºæ¨¡åææèçåè©®éè¤éå¥åº·è³æçééµéæ±ãæåçç ç©¶çµæé¡¯ç¤ºï¼ä½¿ç¨æåçæ¶æ§æ´åæç¤ºï¼å¯ä»¥å¨ææ 4 åæ¨æºä¸­å¤§å¹æ¹åãééæåçæ¶æ§ï¼æåå¯ä»¥å¼ç¼ç²¾å¿è¨­è¨ãæ´å¨å¨çåæï¼éå°ç¹å®æ£èéèº«æé ã

##### **GraphEval2000: Benchmarking and Improving Large Language Models on Graph Datasets**
2406.16176v1 by Qiming Wu, Zichen Chen, Will Corcoran, Misha Sra, Ambuj K. Singh

Large language models (LLMs) have achieved remarkable success in natural
language processing (NLP), demonstrating significant capabilities in processing
and understanding text data. However, recent studies have identified
limitations in LLMs' ability to reason about graph-structured data. To address
this gap, we introduce GraphEval2000, the first comprehensive graph dataset,
comprising 40 graph data structure problems along with 2000 test cases.
Additionally, we introduce an evaluation framework based on GraphEval2000,
designed to assess the graph reasoning abilities of LLMs through coding
challenges. Our dataset categorizes test cases into four primary and four
sub-categories, ensuring a comprehensive evaluation. We evaluate eight popular
LLMs on GraphEval2000, revealing that LLMs exhibit a better understanding of
directed graphs compared to undirected ones. While private LLMs consistently
outperform open-source models, the performance gap is narrowing. Furthermore,
to improve the usability of our evaluation framework, we propose Structured
Symbolic Decomposition (SSD), an instruction-based method designed to enhance
LLM performance on GraphEval2000. Results show that SSD improves the
performance of GPT-3.5, GPT-4, and GPT-4o on complex graph problems, with an
increase of 11.11\%, 33.37\%, and 33.37\%, respectively.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨èªç¶èªè¨èç (NLP) ä¸­åå¾äºé¡¯èçæåï¼å¨èçåçè§£ææ¬æ¸ææ¹é¢è¡¨ç¾åºé¡¯èçè½åãç¶èï¼æè¿çç ç©¶ç¼ç¾ LLM å¨æ¨çåå½¢çµæ§æ¸æçè½åæ¹é¢å­å¨å±éæ§ãçºäºè§£æ±ºéåå·®è·ï¼æåå¼å¥äº GraphEval2000ï¼ç¬¬ä¸åå¨é¢çåå½¢æ¸æéï¼åå« 40 ååå½¢æ¸æçµæ§åé¡ä»¥å 2000 åæ¸¬è©¦ç¨ä¾ãæ­¤å¤ï¼æåéå¼å¥äºåºæ¼ GraphEval2000 çè©ä¼°æ¡æ¶ï¼æ¨å¨ééç·¨ç¢¼ææ°è©ä¼° LLM çåå½¢æ¨çè½åãæåçæ¸æéå°æ¸¬è©¦ç¨ä¾åçºååä¸»è¦é¡å¥åååå­é¡å¥ï¼ç¢ºä¿é²è¡å¨é¢çè©ä¼°ãæåå¨ GraphEval2000 ä¸è©ä¼°äºå«åæµè¡ç LLMï¼çµæè¡¨æï¼èç¡ååç¸æ¯ï¼LLM å°æååççè§£æ´å¥½ãéç¶ç§æ LLM æçºåªæ¼éæºæ¨¡åï¼ä½æ§è½å·®è·æ­£å¨ç¸®å°ãæ­¤å¤ï¼çºäºæé«æåè©ä¼°æ¡æ¶çå¯ç¨æ§ï¼æåæåºäºçµæ§åç¬¦èåè§£ (SSD)ï¼ä¸ç¨®åºæ¼æä»¤çæ¹æ³ï¼æ¨å¨å¢å¼· LLM å¨ GraphEval2000 ä¸çæ§è½ãçµæè¡¨æï¼SSD åå¥æé«äº GPT-3.5ãGPT-4 å GPT-4o å¨è¤éåå½¢åé¡ä¸çæ§è½ï¼åå¥å¢å äº 11.11%ã33.37% å 33.37%ã

##### **Can LLM Graph Reasoning Generalize beyond Pattern Memorization?**
2406.15992v1 by Yizhuo Zhang, Heng Wang, Shangbin Feng, Zhaoxuan Tan, Xiaochuang Han, Tianxing He, Yulia Tsvetkov

Large language models (LLMs) demonstrate great potential for problems with
implicit graphical structures, while recent works seek to enhance the graph
reasoning capabilities of LLMs through specialized instruction tuning. The
resulting 'graph LLMs' are evaluated with in-distribution settings only, thus
it remains underexplored whether LLMs are learning generalizable graph
reasoning skills or merely memorizing patterns in the synthetic training data.
To this end, we propose the NLGift benchmark, an evaluation suite of LLM graph
reasoning generalization: whether LLMs could go beyond semantic, numeric,
structural, reasoning patterns in the synthetic training data and improve
utility on real-world graph-based tasks. Extensive experiments with two LLMs
across four graph reasoning tasks demonstrate that while generalization on
simple patterns (semantic, numeric) is somewhat satisfactory, LLMs struggle to
generalize across reasoning and real-world patterns, casting doubt on the
benefit of synthetic graph tuning for real-world tasks with underlying network
structures. We explore three strategies to improve LLM graph reasoning
generalization, and we find that while post-training alignment is most
promising for real-world tasks, empowering LLM graph reasoning to go beyond
pattern memorization remains an open research question.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å°æ¼å·æé±å¼åå½¢çµæ§çåé¡å±ç¾åºå·¨å¤§çæ½åï¼èè¿æç ç©¶åééå°æ¥­æä»¤èª¿æ´ä¾å¢å¼· LLM çåå½¢æ¨çè½åãç±æ­¤ç¢ççãåå½¢ LLMãåå¨åå¸å§è¨­å®ä¸­é²è¡è©ä¼°ï¼å æ­¤ LLM æ¯å¦å­¸ç¿å°å¯æ¦æ¬çåå½¢æ¨çæè½ï¼æååè¨æ¶åæè¨ç·´è³æä¸­çæ¨¡å¼ï¼ä»æªç²å¾ååæ¢è¨ãçºæ­¤ï¼æåæåº NLGift åºæºï¼éæ¯ä¸å LLM åå½¢æ¨çæ¦æ¬è©ä¼°å¥ä»¶ï¼LLM æ¯å¦å¯ä»¥è¶è¶åæè¨ç·´è³æä¸­çèªç¾©ãæ¸å¼ãçµæ§æ¨çæ¨¡å¼ï¼ä¸¦æåå¨çå¯¦ä¸çåºæ¼åå½¢çä»»åä¸­çæç¨ãééå©å LLM å¨åååå½¢æ¨çä»»åä¸­çå»£æ³å¯¦é©è­æï¼åç®¡å¨ç°¡å®æ¨¡å¼ï¼èªç¾©ãæ¸å¼ï¼ä¸çæ¦æ¬ä»¤äººæ»¿æï¼ä½ LLM é£ä»¥å¨æ¨çåçå¯¦ä¸çæ¨¡å¼ä¸­æ¦æ¬ï¼å°åæåå½¢èª¿æ´å°æ¼å·æåºç¤ç¶²è·¯çµæ§ççå¯¦ä¸çä»»åççèæåºè³ªçãæåæ¢è¨äºä¸ç¨®ç­ç¥ä¾æ¹å LLM åå½¢æ¨çæ¦æ¬ï¼æåç¼ç¾ï¼åç®¡è¨ç·´å¾å°é½å°çå¯¦ä¸çä»»åææå¸æï¼ä½è³¦è½ LLM åå½¢æ¨çä»¥è¶è¶æ¨¡å¼è¨æ¶ä»ç¶æ¯ä¸åéæ¾çç ç©¶åé¡ã

##### **LLM-Powered Explanations: Unraveling Recommendations Through Subgraph Reasoning**
2406.15859v2 by Guangsi Shi, Xiaofeng Deng, Linhao Luo, Lijuan Xia, Lei Bao, Bei Ye, Fei Du, Shirui Pan, Yuxiao Li

Recommender systems are pivotal in enhancing user experiences across various
web applications by analyzing the complicated relationships between users and
items. Knowledge graphs(KGs) have been widely used to enhance the performance
of recommender systems. However, KGs are known to be noisy and incomplete,
which are hard to provide reliable explanations for recommendation results. An
explainable recommender system is crucial for the product development and
subsequent decision-making. To address these challenges, we introduce a novel
recommender that synergies Large Language Models (LLMs) and KGs to enhance the
recommendation and provide interpretable results. Specifically, we first
harness the power of LLMs to augment KG reconstruction. LLMs comprehend and
decompose user reviews into new triples that are added into KG. In this way, we
can enrich KGs with explainable paths that express user preferences. To enhance
the recommendation on augmented KGs, we introduce a novel subgraph reasoning
module that effectively measures the importance of nodes and discovers
reasoning for recommendation. Finally, these reasoning paths are fed into the
LLMs to generate interpretable explanations of the recommendation results. Our
approach significantly enhances both the effectiveness and interpretability of
recommender systems, especially in cross-selling scenarios where traditional
methods falter. The effectiveness of our approach has been rigorously tested on
four open real-world datasets, with our methods demonstrating a superior
performance over contemporary state-of-the-art techniques by an average
improvement of 12%. The application of our model in a multinational engineering
and technology company cross-selling recommendation system further underscores
its practical utility and potential to redefine recommendation practices
through improved accuracy and user trust.

æè¦ï¼æ¨è¦ç³»çµ±å¨åæä½¿ç¨èèé ç®ä¹éè¤éçéä¿ï¼æååç¨®ç¶²è·¯æç¨ç¨å¼çä½¿ç¨èé«é©ä¸­æ®æ¼èééµè§è²ãç¥è­åè­ (KG) å·²è¢«å»£æ³ç¨æ¼æåæ¨è¦ç³»çµ±çæè½ãç¶èï¼KG ç¾æå¨ç¥æ¯æéè¨ä¸ä¸å®æ´çï¼éä½¿å¾é£ä»¥æä¾å¯é çæ¨è¦çµæèªªæãä¸åå¯è§£éçæ¨è¦ç³»çµ±å°æ¼ç¢åéç¼åå¾çºæ±ºç­è³ééè¦ãçºäºæå°éäºææ°ï¼æåå¼å¥äºä¸åæ°ç©çæ¨è¦ç³»çµ±ï¼å®çµåäºå¤§åèªè¨æ¨¡å (LLM) å KG ä¾å å¼·æ¨è¦ä¸¦æä¾å¯è§£éççµæãå·é«ä¾èªªï¼æåé¦åå©ç¨ LLM çåéä¾æ´å KG éå»ºãLLM çè§£ä¸¦å°ä½¿ç¨èè©è«åè§£ææ°çä¸åçµï¼ä¸¦å°å¶æ°å¢å° KG ä¸­ãéééç¨®æ¹å¼ï¼æåå¯ä»¥ç¨è¡¨éä½¿ç¨èåå¥½çå¯è§£éè·¯å¾ä¾è±å¯ KGãçºäºå¢å¼·å¨æ´å KG ä¸çæ¨è¦ï¼æåå¼å¥äºä¸åæ°ç©çå­åæ¨çæ¨¡çµï¼å®å¯ä»¥ææå°è¡¡éç¯é»çéè¦æ§ï¼ä¸¦æ¾åºæ¨è¦ççç±ãæå¾ï¼éäºæ¨çè·¯å¾è¢«è¼¸å¥å° LLM ä¸­ï¼ä»¥ç¢çæ¨è¦çµæçå¯è§£éèªªæãæåçåæ³å¤§å¹æåäºæ¨è¦ç³»çµ±çæææ§åå¯è§£éæ§ï¼ç¹å¥æ¯å¨å³çµ±æ¹æ³å¤±æçäº¤åé·å®æå¢ä¸­ãæåçåæ³çæææ§å·²å¨ååéæ¾ççå¯¦ä¸çè³æéä¸ç¶éå´æ ¼æ¸¬è©¦ï¼æåçåæ³å±ç¤ºåºæ¯ç¶ä»£æåé²æè¡æ´åè¶çæè½ï¼å¹³åæåäº 12%ãæåçæ¨¡åå¨ä¸å®¶è·¨åå·¥ç¨åæè¡å¬å¸äº¤åé·å®æ¨è¦ç³»çµ±ä¸­çæç¨é²ä¸æ­¥çªé¡¯äºå®çå¯¦ç¨æ§ï¼ä»¥åééæåæºç¢ºæ§åä½¿ç¨èä¿¡ä»»ä¾éæ°å®ç¾©æ¨è¦å¯¦åçæ½åã

##### **Large Language Models for Link Stealing Attacks Against Graph Neural Networks**
2406.16963v1 by Faqian Guan, Tianqing Zhu, Hui Sun, Wanlei Zhou, Philip S. Yu

Graph data contains rich node features and unique edge information, which
have been applied across various domains, such as citation networks or
recommendation systems. Graph Neural Networks (GNNs) are specialized for
handling such data and have shown impressive performance in many applications.
However, GNNs may contain of sensitive information and susceptible to privacy
attacks. For example, link stealing is a type of attack in which attackers
infer whether two nodes are linked or not. Previous link stealing attacks
primarily relied on posterior probabilities from the target GNN model,
neglecting the significance of node features. Additionally, variations in node
classes across different datasets lead to different dimensions of posterior
probabilities. The handling of these varying data dimensions posed a challenge
in using a single model to effectively conduct link stealing attacks on
different datasets. To address these challenges, we introduce Large Language
Models (LLMs) to perform link stealing attacks on GNNs. LLMs can effectively
integrate textual features and exhibit strong generalizability, enabling
attacks to handle diverse data dimensions across various datasets. We design
two distinct LLM prompts to effectively combine textual features and posterior
probabilities of graph nodes. Through these designed prompts, we fine-tune the
LLM to adapt to the link stealing attack task. Furthermore, we fine-tune the
LLM using multiple datasets and enable the LLM to learn features from different
datasets simultaneously. Experimental results show that our approach
significantly enhances the performance of existing link stealing attack tasks
in both white-box and black-box scenarios. Our method can execute link stealing
attacks across different datasets using only a single model, making link
stealing attacks more applicable to real-world scenarios.

æè¦ï¼åå½¢æ¸æåå«è±å¯çç¯é»ç¹å¾µåç¨ç¹çéç·£è³è¨ï¼å·²æç¨æ¼åç¨®é åï¼ä¾å¦å¼æç¶²è·¯ææ¨è¦ç³»çµ±ãåå½¢ç¥ç¶ç¶²è·¯ (GNN) å°éç¨æ¼èçæ­¤é¡æ¸æï¼ä¸¦å¨è¨±å¤æç¨ä¸­å±ç¾åºä»¤äººå°è±¡æ·±å»çæè½ãç¶èï¼GNN å¯è½åå«ææè³è¨ï¼ä¸å®¹æåå°é±ç§æ»æãä¾å¦ï¼é£çµç«åæ¯ä¸ç¨®æ»æï¼æ»æèæ¨æ·å©åç¯é»æ¯å¦é£çµãååçé£çµç«åæ»æä¸»è¦ä¾è³´æ¼ç®æ¨ GNN æ¨¡åçå¾é©æ©çï¼å¿½ç¥ç¯é»ç¹å¾µçéè¦æ§ãæ­¤å¤ï¼ä¸åè³æéä¸­çç¯é»é¡å¥è®åå°è´å¾é©æ©ççä¸åç¶­åº¦ãèçéäºä¸åçè³æç¶­åº¦å¨ä½¿ç¨å®ä¸æ¨¡åå°ä¸åè³æéå·è¡é£çµç«åæ»æææ§æä¸é ææ°ãçºäºæå°éäºææ°ï¼æåå¼å¥äºå¤§åèªè¨æ¨¡å (LLM) ä¾å° GNN å·è¡é£çµç«åæ»æãLLM å¯ä»¥æææ´åæå­ç¹å¾µä¸¦å±ç¾å¼·å¤§çæ³åè½åï¼ä½¿æ»æè½å¤ èçä¸åè³æéä¸­çä¸åè³æç¶­åº¦ãæåè¨­è¨äºå©åä¸åç LLM æç¤ºï¼ä»¥ææçµåæå­ç¹å¾µååå½¢ç¯é»çå¾é©æ©çãéééäºè¨­è¨çæç¤ºï¼æåå¾®èª¿ LLM ä»¥é©æé£çµç«åæ»æä»»åãæ­¤å¤ï¼æåä½¿ç¨å¤åè³æéå¾®èª¿ LLMï¼ä¸¦ä½¿ LLM è½å¤ åæå¾ä¸åçè³æéä¸­å­¸ç¿ç¹å¾µãå¯¦é©çµæé¡¯ç¤ºï¼æåçåæ³é¡¯èæåäºç¾æé£çµç«åæ»æä»»åå¨ç½çåé»çå ´æ¯ä¸­çæè½ãæåçæ¨¡ååä½¿ç¨å®ä¸æ¨¡åå°±è½è·¨ä¸åè³æéå·è¡é£çµç«åæ»æï¼ä½¿é£çµç«åæ»ææ´é©ç¨æ¼å¯¦éå ´æ¯ã

##### **Inferring Pluggable Types with Machine Learning**
2406.15676v1 by Kazi Amanul Islam Siddiqui, Martin Kellogg

Pluggable type systems allow programmers to extend the type system of a
programming language to enforce semantic properties defined by the programmer.
Pluggable type systems are difficult to deploy in legacy codebases because they
require programmers to write type annotations manually. This paper investigates
how to use machine learning to infer type qualifiers automatically. We propose
a novel representation, NaP-AST, that encodes minimal dataflow hints for the
effective inference of type qualifiers. We evaluate several model architectures
for inferring type qualifiers, including Graph Transformer Network, Graph
Convolutional Network and Large Language Model. We further validated these
models by applying them to 12 open-source programs from a prior evaluation of
the NullAway pluggable typechecker, lowering warnings in all but one
unannotated project. We discovered that GTN shows the best performance, with a
recall of .89 and precision of 0.6. Furthermore, we conduct a study to estimate
the number of Java classes needed for good performance of the trained model.
For our feasibility study, performance improved around 16k classes, and
deteriorated due to overfitting around 22k classes.

æè¦ï¼å¯ææç±»åç³»ç»åè®¸ç¨åºåæ©å±ç¼ç¨è¯­è¨çç±»åç³»ç»ï¼ä»¥æ§è¡ç¨åºåå®ä¹çè¯­ä¹å±æ§ãå¯ææç±»åç³»ç»é¾ä»¥é¨ç½²å¨éçä»£ç åºä¸­ï¼å ä¸ºå®ä»¬è¦æ±ç¨åºåæå¨ç¼åç±»åæ³¨éãæ¬æç ç©¶å¦ä½ä½¿ç¨æºå¨å­¦ä¹ èªå¨æ¨æ­ç±»åéå®ç¬¦ãæä»¬æåºäºä¸ç§æ°é¢çè¡¨ç¤ºå½¢å¼ NaP-ASTï¼å®å¯¹ç±»åéå®ç¬¦çæææ¨æ­ç¼ç äºæå°çæ°æ®æµæç¤ºãæä»¬è¯ä¼°äºç¨äºæ¨æ­ç±»åéå®ç¬¦çå ç§æ¨¡åæ¶æï¼åæ¬å¾è½¬æ¢å¨ç½ç»ãå¾å·ç§¯ç½ç»åå¤§è¯­è¨æ¨¡åãæä»¬éè¿å°è¿äºæ¨¡ååºç¨äº NullAway å¯ææç±»åæ£æ¥å¨çååè¯ä¼°ä¸­ç 12 ä¸ªå¼æºç¨åºï¼è¿ä¸æ­¥éªè¯äºè¿äºæ¨¡åï¼é¤äºä¸ä¸ªæªæ³¨éçé¡¹ç®å¤ï¼éä½äºææé¡¹ç®çè­¦åãæä»¬åç° GTN è¡¨ç°æä½³ï¼å¬åçä¸º 0.89ï¼ç²¾ç¡®çä¸º 0.6ãæ­¤å¤ï¼æä»¬è¿è¡äºä¸é¡¹ç ç©¶ï¼ä»¥ä¼°è®¡è®­ç»æ¨¡åè¯å¥½æ§è½æéç Java ç±»æ°éãå¯¹äºæä»¬çå¯è¡æ§ç ç©¶ï¼æ§è½æé«äºçº¦ 16k ä¸ªç±»ï¼å¹¶ä¸ç±äºå¨ 22k ä¸ªç±»å·¦å³è¿åº¦æåèæ¶åã

##### **NLP-KG: A System for Exploratory Search of Scientific Literature in Natural Language Processing**
2406.15294v2 by Tim Schopf, Florian Matthes

Scientific literature searches are often exploratory, whereby users are not
yet familiar with a particular field or concept but are interested in learning
more about it. However, existing systems for scientific literature search are
typically tailored to keyword-based lookup searches, limiting the possibilities
for exploration. We propose NLP-KG, a feature-rich system designed to support
the exploration of research literature in unfamiliar natural language
processing (NLP) fields. In addition to a semantic search, NLP-KG allows users
to easily find survey papers that provide a quick introduction to a field of
interest. Further, a Fields of Study hierarchy graph enables users to
familiarize themselves with a field and its related areas. Finally, a chat
interface allows users to ask questions about unfamiliar concepts or specific
articles in NLP and obtain answers grounded in knowledge retrieved from
scientific publications. Our system provides users with comprehensive
exploration possibilities, supporting them in investigating the relationships
between different fields, understanding unfamiliar concepts in NLP, and finding
relevant research literature. Demo, video, and code are available at:
https://github.com/NLP-Knowledge-Graph/NLP-KG-WebApp.

æè¦ï¼ç§å­¸æç»çæå°éå¸¸æ¯æ¢ç´¢æ§çï¼ä½¿ç¨èå¯è½éä¸çææåç¹å®é åææ¦å¿µï¼ä½æèè¶£é²ä¸æ­¥äºè§£å®ãç¶èï¼ç¾æçç§å­¸æç»æå°ç³»çµ±éå¸¸å°ééå°åºæ¼ééµå­çæ¥è©¢æå°ï¼éå¶äºæ¢ç´¢çå¯è½æ§ãæåæåº NLP-KGï¼éæ¯ä¸ååè½è±å¯çç³»çµ±ï¼æ¨å¨æ¯æ´å¨ä¸çæçèªç¶èªè¨èç (NLP) é åä¸­æ¢ç´¢ç ç©¶æç»ãé¤äºèªææå°ä¹å¤ï¼NLP-KG ä½¿ç¨èå¯ä»¥è¼é¬æ¾å°æä¾å°æèè¶£é åçå¿«éä»ç´¹çç¶è¿°è«æãæ­¤å¤ï¼ç ç©¶é åéå±¤åè®ä½¿ç¨èè½å¤ çæä¸åé ååå¶ç¸éé åãæå¾ï¼èå¤©ä»é¢åè¨±ä½¿ç¨èè©¢åæéä¸çæçæ¦å¿µæ NLP ä¸­ç¹å®æç« çåé¡ï¼ä¸¦ç²å¾å¾ç§å­¸åºçç©ä¸­æ·åçç¥è­çºåºç¤çç­æ¡ãæåçç³»çµ±çºä½¿ç¨èæä¾å¨é¢çæ¢ç´¢å¯è½æ§ï¼åå©ä»åèª¿æ¥ä¸åé åä¹éçéä¿ï¼çè§£ NLP ä¸­ä¸çæçæ¦å¿µï¼ä¸¦æ¾å°ç¸éçç ç©¶æç»ãç¤ºç¯ãå½±çåç¨å¼ç¢¼å¯å¨ä»¥ä¸ç¶²ååå¾ï¼
https://github.com/NLP-Knowledge-Graph/NLP-KG-WebAppã

##### **Unsupervised Extraction of Dialogue Policies from Conversations**
2406.15214v1 by Makesh Narsimhan Sreedhar, Traian Rebedea, Christopher Parisien

Dialogue policies play a crucial role in developing task-oriented dialogue
systems, yet their development and maintenance are challenging and typically
require substantial effort from experts in dialogue modeling. While in many
situations, large amounts of conversational data are available for the task at
hand, people lack an effective solution able to extract dialogue policies from
this data. In this paper, we address this gap by first illustrating how Large
Language Models (LLMs) can be instrumental in extracting dialogue policies from
datasets, through the conversion of conversations into a unified intermediate
representation consisting of canonical forms. We then propose a novel method
for generating dialogue policies utilizing a controllable and interpretable
graph-based methodology. By combining canonical forms across conversations into
a flow network, we find that running graph traversal algorithms helps in
extracting dialogue flows. These flows are a better representation of the
underlying interactions than flows extracted by prompting LLMs. Our technique
focuses on giving conversation designers greater control, offering a
productivity tool to improve the process of developing dialogue policies.

æè¦ï¼å°è©±æ¿ç­å¨éç¼ä»»åå°åå°è©±ç³»çµ±ä¸­æ®æ¼èè³ééè¦çè§è²ï¼ç¶èå®åçéç¼åç¶­è­·å·æææ°æ§ï¼ä¸éå¸¸éè¦å°è©±å»ºæ¨¡å°å®¶çå¤§éå·¥ä½ãéç¶å¨è¨±å¤ææ³ä¸ï¼å¤§éå°è©±è³æå¯ç¨æ¼æéçå·¥ä½ï¼ä½äººåç¼ºä¹ä¸ç¨®ææçè§£æ±ºæ¹æ¡ï¼ç¡æ³å¾éäºè³æä¸­æåå°è©±æ¿ç­ãå¨æ¬æä¸­ï¼æåééé¦åèªªæå¤§åèªè¨æ¨¡å (LLM) å¦ä½ééå°å°è©±è½ææç±è¦ç¯å½¢å¼çµæççµ±ä¸ä¸­éè¡¨ç¤ºï¼å¾è³æéä¸­æåå°è©±æ¿ç­ï¼ä¾èªªæå¦ä½è§£æ±ºéåå·®è·ãç¶å¾ï¼æåæåºäºä¸ç¨®å©ç¨å¯æ§ä¸å¯è§£éçåºæ¼åå½¢çæ¹æ³ä¾ç¢çå°è©±æ¿ç­çæ°æ¹æ³ãééå°å°è©±ä¸­çè¦ç¯å½¢å¼çµåææµç¶²è·¯ï¼æåç¼ç¾å·è¡åå½¢éæ­·æ¼ç®æ³æå©æ¼æåå°è©±æµãéäºæµæ¯ééæç¤º LLM æåçæµæ´è½ä»£è¡¨åºå±¤äºåãæåçæè¡å°æ³¨æ¼è®å°è©±è¨­è¨å¸«æææ´å¤§çæ§å¶æ¬ï¼æä¾ä¸ç¨®çç¢åå·¥å·ä¾æ¹åéç¼å°è©±æ¿ç­çéç¨ã

##### **Uni-Mol2: Exploring Molecular Pretraining Model at Scale**
2406.14969v2 by Xiaohong Ji, Zhen Wang, Zhifeng Gao, Hang Zheng, Linfeng Zhang, Guolin Ke, Weinan E

In recent years, pretraining models have made significant advancements in the
fields of natural language processing (NLP), computer vision (CV), and life
sciences. The significant advancements in NLP and CV are predominantly driven
by the expansion of model parameters and data size, a phenomenon now recognized
as the scaling laws. However, research exploring scaling law in molecular
pretraining models remains unexplored. In this work, we present Uni-Mol2 , an
innovative molecular pretraining model that leverages a two-track transformer
to effectively integrate features at the atomic level, graph level, and
geometry structure level. Along with this, we systematically investigate the
scaling law within molecular pretraining models, characterizing the power-law
correlations between validation loss and model size, dataset size, and
computational resources. Consequently, we successfully scale Uni-Mol2 to 1.1
billion parameters through pretraining on 800 million conformations, making it
the largest molecular pretraining model to date. Extensive experiments show
consistent improvement in the downstream tasks as the model size grows. The
Uni-Mol2 with 1.1B parameters also outperforms existing methods, achieving an
average 27% improvement on the QM9 and 14% on COMPAS-1D dataset.

æè¦ï¼è¿å¹´æ¥ï¼é¢è®­ç»æ¨¡åå¨èªç¶è¯­è¨å¤ç (NLP)ãè®¡ç®æºè§è§ (CV) åçå½ç§å­¦é¢ååå¾äºéå¤§è¿å±ãNLP å CV çéå¤§è¿æ­¥ä¸»è¦ç±æ¨¡ååæ°åæ°æ®éçæ©å±æ¨å¨ï¼è¿ä¸ç°è±¡ç°å¨è¢«è®¤ä¸ºæ¯ç¼©æ¾å®å¾ãç¶èï¼æ¢ç´¢åå­é¢è®­ç»æ¨¡åä¸­ç¼©æ¾å®å¾çç ç©¶ä»æªå¾å°æ¢ç´¢ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬æåºäº Uni-Mol2ï¼ä¸ç§åæ°çåå­é¢è®­ç»æ¨¡åï¼å®å©ç¨åè½¨è½¬æ¢å¨ææå°æ´ååå­çº§ãå¾çº§åå ä½ç»æçº§çç¹å¾ãé¤æ­¤ä¹å¤ï¼æä»¬ç³»ç»å°ç ç©¶äºåå­é¢è®­ç»æ¨¡åä¸­çç¼©æ¾å®å¾ï¼æè¿°äºéªè¯æå¤±ä¸æ¨¡åå¤§å°ãæ°æ®éå¤§å°åè®¡ç®èµæºä¹é´çå¹å¾ç¸å³æ§ãå æ­¤ï¼æä»¬æåå°å° Uni-Mol2 æ©å±å° 11 äº¿ä¸ªåæ°ï¼éè¿å¯¹ 8 äº¿ä¸ªæè±¡è¿è¡é¢è®­ç»ï¼ä½¿å¶æä¸ºè¿ä»ä¸ºæ­¢æå¤§çåå­é¢è®­ç»æ¨¡åãå¤§éçå®éªè¡¨æï¼éçæ¨¡åå¤§å°çå¢é¿ï¼ä¸æ¸¸ä»»å¡æç»­å¾å°æ¹åãå·æ 1.1B åæ°ç Uni-Mol2 ä¹ä¼äºç°ææ¹æ³ï¼å¨ QM9 ä¸å®ç°äºå¹³å 27% çæ¹è¿ï¼å¨ COMPAS-1D æ°æ®éä¸å®ç°äº 14% çæ¹è¿ã

##### **Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks**
2406.14745v2 by Sefika Efeoglu, Adrian Paschke

Information Extraction (IE) is crucial for converting unstructured data into
structured formats like Knowledge Graphs (KGs). A key task within IE is
Relation Extraction (RE), which identifies relationships between entities in
text. Various RE methods exist, including supervised, unsupervised, weakly
supervised, and rule-based approaches. Recent studies leveraging pre-trained
language models (PLMs) have shown significant success in this area. In the
current era dominated by Large Language Models (LLMs), fine-tuning these models
can overcome limitations associated with zero-shot LLM prompting-based RE
methods, especially regarding domain adaptation challenges and identifying
implicit relations between entities in sentences. These implicit relations,
which cannot be easily extracted from a sentence's dependency tree, require
logical inference for accurate identification. This work explores the
performance of fine-tuned LLMs and their integration into the Retrieval
Augmented-based (RAG) RE approach to address the challenges of identifying
implicit relations at the sentence level, particularly when LLMs act as
generators within the RAG framework. Empirical evaluations on the TACRED,
TACRED-Revisited (TACREV), Re-TACRED, and SemEVAL datasets show significant
performance improvements with fine-tuned LLMs, including Llama2-7B, Mistral-7B,
and T5 (Large). Notably, our approach achieves substantial gains on SemEVAL,
where implicit relations are common, surpassing previous results on this
dataset. Additionally, our method outperforms previous works on TACRED, TACREV,
and Re-TACRED, demonstrating exceptional performance across diverse evaluation
scenarios.

æè¦ï¼è³è¨èåï¼IEï¼å°æ¼å°éçµæ§åè³æè½ææç¥è­åè­ï¼KGï¼ç­çµæ§åæ ¼å¼è³ééè¦ãIE ä¸­çä¸é ééµä»»åæ¯éä¿èåï¼REï¼ï¼ç¨æ¼è­å¥æå­ä¸­å¯¦é«ä¹éçéä¿ãRE æ¹æ³å¤ç¨®å¤æ¨£ï¼åæ¬ç£ç£å¼ãéç£ç£å¼ãå¼±ç£ç£å¼ååºæ¼è¦åçæ¹æ³ãæè¿å©ç¨é è¨ç·´èªè¨æ¨¡åï¼PLMï¼çç ç©¶å·²å¨æ­¤é åå±ç¾é¡¯èææãå¨å¤§åèªè¨æ¨¡åï¼LLMï¼ä¸»å°çç¶åæä»£ï¼å¾®èª¿éäºæ¨¡åå¯ä»¥åæèé¶æ¬¡å­¸ç¿ LLM æç¤ºå¼ RE æ¹æ³ç¸éçéå¶ï¼ç¹å¥æ¯å¨é åé©æææ°åè­å¥å¥å­ä¸­å¯¦é«ä¹éçé±å«éä¿æ¹é¢ãéäºé±å«éä¿ç¡æ³è¼æå¾å¥å­çä¾è³´æ¨¹ä¸­èåï¼éè¦éè¼¯æ¨è«æè½æºç¢ºè­å¥ãéé å·¥ä½æ¢è¨äºå¾®èª¿å¾ç LLM çæè½ï¼ä»¥åå®åæ´åå°æª¢ç´¢å¢å¼·å¼ï¼RAGï¼RE æ¹æ³ä¸­ä»¥è§£æ±ºå¨å¥å­å±¤ç´è­å¥é±å«éä¿çææ°ï¼ç¹å¥æ¯å¨ LLM å¨ RAG æ¡æ¶ä¸­åç¶çæå¨çæå¾ãå¨ TACREDãTACRED-Revisitedï¼TACREVï¼ãRe-TACRED å SemEVAL è³æéä¸çç¶é©è©ä¼°é¡¯ç¤ºï¼å¾®èª¿å¾ç LLMï¼åæ¬ Llama2-7BãMistral-7B å T5ï¼å¤§åï¼ï¼å¤§å¹æåäºæè½ãå¼å¾æ³¨æçæ¯ï¼æåçåæ³å¨ SemEVAL ä¸åå¾äºé¡¯èçé²å±ï¼å çºé±å«éä¿å¾å¸¸è¦ï¼è¶è¶äºéåè³æéä¸çååçµæãæ­¤å¤ï¼æåçåæ³å¨ TACREDãTACREV å Re-TACRED ä¸åªæ¼ååçå·¥ä½ï¼è­æäºå¨ä¸åçè©ä¼°å ´æ¯ä¸­è¡¨ç¾åºè²çæè½ã

##### **Do LLMs Have Distinct and Consistent Personality? TRAIT: Personality Testset designed for LLMs with Psychometrics**
2406.14703v1 by Seungbeen Lee, Seungwon Lim, Seungju Han, Giyeong Oh, Hyungjoo Chae, Jiwan Chung, Minju Kim, Beong-woo Kwak, Yeonsoo Lee, Dongha Lee, Jinyoung Yeo, Youngjae Yu

The idea of personality in descriptive psychology, traditionally defined
through observable behavior, has now been extended to Large Language Models
(LLMs) to better understand their behavior. This raises a question: do LLMs
exhibit distinct and consistent personality traits, similar to humans? Existing
self-assessment personality tests, while applicable, lack the necessary
validity and reliability for precise personality measurements. To address this,
we introduce TRAIT, a new tool consisting of 8K multi-choice questions designed
to assess the personality of LLMs with validity and reliability. TRAIT is built
on the psychometrically validated human questionnaire, Big Five Inventory (BFI)
and Short Dark Triad (SD-3), enhanced with the ATOMIC10X knowledge graph for
testing personality in a variety of real scenarios. TRAIT overcomes the
reliability and validity issues when measuring personality of LLM with
self-assessment, showing the highest scores across three metrics: refusal rate,
prompt sensitivity, and option order sensitivity. It reveals notable insights
into personality of LLM: 1) LLMs exhibit distinct and consistent personality,
which is highly influenced by their training data (i.e., data used for
alignment tuning), and 2) current prompting techniques have limited
effectiveness in eliciting certain traits, such as high psychopathy or low
conscientiousness, suggesting the need for further research in this direction.

æè¦ï¼å¨å³çµ±å¿çå­¸ä¸­ï¼äººæ ¼çæ¦å¿µæ¯ééå¯è§å¯çè¡çºä¾å®ç¾©çï¼ç¾å¨å·²æ´å±å°å¤§åèªè¨æ¨¡å (LLM)ï¼ä»¥æ´äºè§£å¶è¡çºãéå¼ç¼äºä¸ååé¡ï¼LLM æ¯å¦åäººé¡ä¸æ¨£è¡¨ç¾åºç¨ç¹ä¸ä¸è´çäººæ ¼ç¹è³ªï¼ç¾æçèªæè©éäººæ ¼æ¸¬é©éç¶é©ç¨ï¼ä½ç¼ºä¹ç²¾ç¢ºäººæ ¼æ¸¬éæéçæåº¦åä¿¡åº¦ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äº TRAITï¼éæ¯ä¸åç± 8K åå¤éé¸æé¡çµæçå¨æ°å·¥å·ï¼æ¨å¨è©ä¼° LLM çäººæ ¼ï¼ä¸¦å·åæåº¦åä¿¡åº¦ãTRAIT å»ºæ§æ¼ç¶éå¿çæ¸¬éé©è­çäººé¡åå·ï¼å¤§äºäººæ ¼éè¡¨ (BFI) åç°¡ç­é»æä¸åçµ (SD-3)ï¼ä¸¦å¢å¼·äº ATOMIC10X ç¥è­åè­ï¼ä»¥ä¾¿å¨åç¨®å¯¦éå ´æ¯ä¸­æ¸¬è©¦äººæ ¼ãTRAIT åæäºä½¿ç¨èªæè©éæ¸¬é LLM äººæ ¼æçä¿¡åº¦åæåº¦åé¡ï¼å¨ä¸é ææ¨ï¼æçµçãæç¤ºææåº¦åé¸é é åºææåº¦ï¼ä¸­é¡¯ç¤ºåºæé«åãå®æ­ç¤ºäº LLM äººæ ¼çéè¦è¦è§£ï¼1) LLM è¡¨ç¾åºç¨ç¹ä¸ä¸è´çäººæ ¼ï¼éæ·±åå¶è¨ç·´è³æï¼å³ç¨æ¼å°é½èª¿æ´çè³æï¼å½±é¿ï¼ä»¥å 2) ç®åçæç¤ºæè¡å¨å¼ç¼æäºç¹è³ªï¼ä¾å¦é«ç²¾ç¥çè³ªæä½ç¡è²¬æ§ï¼æ¹é¢æææéï¼éè¡¨ç¤ºéè¦é²ä¸æ­¥ç ç©¶éåæ¹åã

##### **TAGLAS: An atlas of text-attributed graph datasets in the era of large graph and language models**
2406.14683v1 by Jiarui Feng, Hao Liu, Lecheng Kong, Yixin Chen, Muhan Zhang

In this report, we present TAGLAS, an atlas of text-attributed graph (TAG)
datasets and benchmarks. TAGs are graphs with node and edge features
represented in text, which have recently gained wide applicability in training
graph-language or graph foundation models. In TAGLAS, we collect and integrate
more than 23 TAG datasets with domains ranging from citation graphs to molecule
graphs and tasks from node classification to graph question-answering. Unlike
previous graph datasets and benchmarks, all datasets in TAGLAS have a unified
node and edge text feature format, which allows a graph model to be
simultaneously trained and evaluated on multiple datasets from various domains.
Further, we provide a standardized, efficient, and simplified way to load all
datasets and tasks. We also provide useful utils like text-to-embedding
conversion, and graph-to-text conversion, which can facilitate different
evaluation scenarios. Finally, we also provide standard and easy-to-use
evaluation utils. The project is open-sourced at
https://github.com/JiaruiFeng/TAGLAS and is still under construction. Please
expect more datasets/features in the future.

æè¦ï¼<paragraph>å¨æ¬æä¸­ï¼æä»¬æåºäº TAGLASï¼ä¸ä¸ªææ¬å±æ§å¾ (TAG)
æ°æ®éååºåçå¾éãTAG æ¯å·æä»¥ææ¬è¡¨ç¤ºçèç¹åè¾¹ç¹å¾çå¾ï¼æè¿å¨è®­ç»
å¾è¯­è¨æå¾åºç¡æ¨¡åä¸­è·å¾äºå¹¿æ³çåºç¨ãå¨ TAGLAS ä¸­ï¼æä»¬æ¶éå¹¶æ´å
äº 23 ä¸ªä»¥ä¸ç TAG æ°æ®éï¼å¶é¢åä»å¼æå¾å°åå­
å¾åä»»å¡ï¼ä»èç¹åç±»å°å¾é®ç­ãä¸
ä»¥åçå¾æ°æ®éååºåä¸åï¼TAGLAS ä¸­çæææ°æ®éé½å·æç»ä¸ç
èç¹åè¾¹ææ¬ç¹å¾æ ¼å¼ï¼è¿åè®¸å¾æ¨¡åå¨æ¥èªä¸åé¢åçå¤ä¸ªæ°æ®éä¸åæ¶è®­ç»åè¯ä¼°ã
æ­¤å¤ï¼æä»¬æä¾äºä¸ç§æ ååãé«æä¸ç®åçæ¹å¼æ¥å è½½ææ
æ°æ®éåä»»å¡ãæä»¬è¿æä¾æç¨çå®ç¨ç¨åºï¼å¦ææ¬å°åµå¥
è½¬æ¢ï¼ä»¥åå¾å°ææ¬è½¬æ¢ï¼è¿å¯ä»¥ä¿è¿ä¸åç
è¯ä¼°åºæ¯ãæåï¼æä»¬è¿æä¾æ åä¸æäºä½¿ç¨ç
è¯ä¼°å®ç¨ç¨åºãè¯¥é¡¹ç®å¨
https://github.com/JiaruiFeng/TAGLAS å¼æºï¼å¹¶ä¸ä»å¨å»ºè®¾ä¸­ãè¯·
æå¾æªæ¥ææ´å¤çæ°æ®é/åè½ã</paragraph>

##### **HYPERmotion: Learning Hybrid Behavior Planning for Autonomous Loco-manipulation**
2406.14655v1 by Jin Wang, Rui Dai, Weijie Wang, Luca Rossini, Francesco Ruscelli, Nikos Tsagarakis

Enabling robots to autonomously perform hybrid motions in diverse
environments can be beneficial for long-horizon tasks such as material
handling, household chores, and work assistance. This requires extensive
exploitation of intrinsic motion capabilities, extraction of affordances from
rich environmental information, and planning of physical interaction behaviors.
Despite recent progress has demonstrated impressive humanoid whole-body control
abilities, they struggle to achieve versatility and adaptability for new tasks.
In this work, we propose HYPERmotion, a framework that learns, selects and
plans behaviors based on tasks in different scenarios. We combine reinforcement
learning with whole-body optimization to generate motion for 38 actuated joints
and create a motion library to store the learned skills. We apply the planning
and reasoning features of the large language models (LLMs) to complex
loco-manipulation tasks, constructing a hierarchical task graph that comprises
a series of primitive behaviors to bridge lower-level execution with
higher-level planning. By leveraging the interaction of distilled spatial
geometry and 2D observation with a visual language model (VLM) to ground
knowledge into a robotic morphology selector to choose appropriate actions in
single- or dual-arm, legged or wheeled locomotion. Experiments in simulation
and real-world show that learned motions can efficiently adapt to new tasks,
demonstrating high autonomy from free-text commands in unstructured scenes.
Videos and website: hy-motion.github.io/

æè¦ï¼<paragraph>è®æ©å¨äººè½å¤ å¨ä¸åç°å¢ä¸­èªä¸»å·è¡æ··ååä½ï¼å°æ¼æææ¬éãå®¶ååå·¥ä½åå©ç­é·æä»»åå¯è½æ¯æççãééè¦å»£æ³å©ç¨å§å¨éåè½åï¼å¾è±å¯çç°å¢è³è¨ä¸­æåå¯è² ææ§ï¼ä»¥åè¦åç©çäºåè¡çºãåç®¡æè¿çé²å±å·²è­æä»¤äººå°è±¡æ·±å»çäººå½¢å¨èº«æ§å¶è½åï¼ä½å®åä»é£ä»¥å¯¦ç¾æ°ä»»åçå¤åè½æ§åé©ææ§ãå¨éé å·¥ä½ä¸­ï¼æåæåº HYPERmotionï¼ä¸ååºæ¼ä¸åå ´æ¯ä¸­çä»»åä¾å­¸ç¿ãé¸æåè¦åè¡çºçæ¡æ¶ãæåçµåå¼·åå­¸ç¿èå¨èº«æä½³åï¼çº 38 ååä½éç¯ç¢çåä½ï¼ä¸¦å»ºç«ä¸ååä½åº«ä¾å²å­å­¸ç¿å°çæè½ãæåå°å¤§åèªè¨æ¨¡å (LLM) çè¦ååæ¨çåè½æç¨æ¼è¤éçéåæç¸±ä»»åï¼æ§å»ºä¸åéå±¤å¼ä»»ååï¼å¶ä¸­åå«ä¸ç³»ååºæ¬è¡çºï¼ä»¥æ©æ¥ä½éå·è¡èé«éè¦åãééå©ç¨è¸é¤¾ç©ºéå¹¾ä½å 2D è§æ¸¬èè¦è¦ºèªè¨æ¨¡å (VLM) çäºåï¼å°ç¥è­åºç¤åçºæ©å¨äººå½¢æé¸æå¨ï¼ä»¥å¨å®èæéèãè¿é¨æè¼ªå¼éåä¸­é¸æé©ç¶çåä½ãæ¨¡æ¬åç¾å¯¦ä¸ççå¯¦é©è¡¨æï¼å­¸ç¿å°çåä½å¯ä»¥ææé©ææ°ä»»åï¼è­æäºå¨éçµæ§åå ´æ¯ä¸­å¾èªç±æå­æä»¤ä¸­ç²å¾é«åº¦èªä¸»æ§ãå½±çåç¶²ç«ï¼hy-motion.github.io/</paragraph>

##### **GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models**
2406.14550v1 by Shilong Li, Yancheng He, Hangyu Guo, Xingyuan Bu, Ge Bai, Jie Liu, Jiaheng Liu, Xingwei Qu, Yangguang Li, Wanli Ouyang, Wenbo Su, Bo Zheng

Long-context capabilities are essential for large language models (LLMs) to
tackle complex and long-input tasks. Despite numerous efforts made to optimize
LLMs for long contexts, challenges persist in robustly processing long inputs.
In this paper, we introduce GraphReader, a graph-based agent system designed to
handle long texts by structuring them into a graph and employing an agent to
explore this graph autonomously. Upon receiving a question, the agent first
undertakes a step-by-step analysis and devises a rational plan. It then invokes
a set of predefined functions to read node content and neighbors, facilitating
a coarse-to-fine exploration of the graph. Throughout the exploration, the
agent continuously records new insights and reflects on current circumstances
to optimize the process until it has gathered sufficient information to
generate an answer. Experimental results on the LV-Eval dataset reveal that
GraphReader, using a 4k context window, consistently outperforms GPT-4-128k
across context lengths from 16k to 256k by a large margin. Additionally, our
approach demonstrates superior performance on four challenging single-hop and
multi-hop benchmarks.

æè¦ï¼é·èªå¢è½åå°æ¼å¤§åèªè¨æ¨¡å (LLM) ä¾èªªè³ééè¦ï¼å¯æå°è¤éä¸è¼¸å¥é·åº¦è¼é·çä»»åãåç®¡å·²éå° LLM é²è¡è¨±å¤æä½³åå·¥ä½ä»¥æå°é·èªå¢ï¼ä½å¼·å¥å°èçé·è¼¸å¥ä»å­å¨ææ°ãå¨æ¬æä¸­ï¼æåä»ç´¹ GraphReaderï¼ä¸ååºæ¼åè¡¨çä»£çç³»çµ±ï¼æ¨å¨ééå°é·ææ¬çµæ§åæä¸ååè¡¨ï¼ä¸¦ä½¿ç¨ä»£çç¨å¼èªä¸»æ¢ç´¢æ­¤åè¡¨ï¼ä¾èçé·ææ¬ãå¨æ¶å°åé¡å¾ï¼ä»£çç¨å¼é¦åé²è¡éæ­¥åæï¼ä¸¦æ¬å®ä¸ååçè¨ç«ãç¶å¾ï¼å®æå¼å«ä¸çµé å®ç¾©çå½å¼ä¾è®åç¯é»å§å®¹åé°è¿ç¯é»ï¼ä¿é²å°åè¡¨çç²ç¥å°ç²¾ç´°æ¢ç´¢ãå¨æ´åæ¢ç´¢éç¨ä¸­ï¼ä»£çç¨å¼ææçºè¨éæ°çè¦è§£ï¼ä¸¦åæç¶åææ³ï¼ä»¥æä½³åèçç¨åºï¼ç´å°æ¶éå°è¶³å¤ çè³è¨ä¾ç¢çç­æ¡ãå¨ LV-Eval è³æéä¸çå¯¦é©çµæé¡¯ç¤ºï¼GraphReader ä½¿ç¨ 4k èªå¢è¦çªï¼å¨ 16k å° 256k çèªå¢é·åº¦ä¸­ï¼å§çµå¤§å¹åªæ¼ GPT-4-128kãæ­¤å¤ï¼æåçåæ³å¨ååå·æææ°æ§çå®è·³åå¤è·³åºæºæ¸¬è©¦ä¸­å±ç¾åºåè¶çæè½ã

##### **medIKAL: Integrating Knowledge Graphs as Assistants of LLMs for Enhanced Clinical Diagnosis on EMRs**
2406.14326v1 by Mingyi Jia, Junwen Duan, Yan Song, Jianxin Wang

Electronic Medical Records (EMRs), while integral to modern healthcare,
present challenges for clinical reasoning and diagnosis due to their complexity
and information redundancy. To address this, we proposed medIKAL (Integrating
Knowledge Graphs as Assistants of LLMs), a framework that combines Large
Language Models (LLMs) with knowledge graphs (KGs) to enhance diagnostic
capabilities. medIKAL assigns weighted importance to entities in medical
records based on their type, enabling precise localization of candidate
diseases within KGs. It innovatively employs a residual network-like approach,
allowing initial diagnosis by the LLM to be merged into KG search results.
Through a path-based reranking algorithm and a fill-in-the-blank style prompt
template, it further refined the diagnostic process. We validated medIKAL's
effectiveness through extensive experiments on a newly introduced open-sourced
Chinese EMR dataset, demonstrating its potential to improve clinical diagnosis
in real-world settings.

æè¦ï¼é»å­çæ­· (EMR) éç¶æ¯ç¾ä»£é«çä¿å¥ä¸å¯æç¼ºçä¸é¨åï¼ä½ç±æ¼å¶è¤éæ§åè³è¨åé¤ï¼å°è¨åºæ¨çåè¨ºæ·æåºäºææ°ãçºäºè§£æ±ºéååé¡ï¼æåæåºäº medIKALï¼å°ç¥è­åè­æ´åçº LLM çå©çï¼ï¼ä¸åå°å¤§åèªè¨æ¨¡å (LLM) èç¥è­åè­ (KG) çµåçæ¡æ¶ï¼ä»¥å¢å¼·è¨ºæ·è½åãmedIKAL æ ¹æé«çè¨éä¸­å¯¦é«çé¡åçºå¶åéå æ¬éè¦æ§ï¼å¾èè½å¤ ç²¾ç¢ºå®ä½ KG ä¸­çåé¸ç¾çãå®åµæ°å°æ¡ç¨äºé¡ä¼¼æ®å·®ç¶²è·¯çæ¹æ³ï¼åè¨± LLM çåæ­¥è¨ºæ·è KG æå°çµæåä½µãééåºæ¼è·¯å¾çéæ°æåºæ¼ç®æ³åå¡«ç©ºå¼æç¤ºç¯æ¬ï¼é²ä¸æ­¥åªåäºè¨ºæ·éç¨ãæåééå°æ°æ¨åºçéæºä¸­æ EMR è³æéé²è¡å»£æ³çå¯¦é©ï¼é©è­äº medIKAL çæææ§ï¼è­æäºå¶å¨ç¾å¯¦ä¸çä¸­æ¹åè¨åºè¨ºæ·çæ½åã

##### **Learning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs**
2406.14282v1 by Junjie Wang, Mingyang Chen, Binbin Hu, Dan Yang, Ziqi Liu, Yue Shen, Peng Wei, Zhiqiang Zhang, Jinjie Gu, Jun Zhou, Jeff Z. Pan, Wen Zhang, Huajun Chen

Improving the performance of large language models (LLMs) in complex
question-answering (QA) scenarios has always been a research focal point.
Recent studies have attempted to enhance LLMs' performance by combining
step-wise planning with external retrieval. While effective for advanced models
like GPT-3.5, smaller LLMs face challenges in decomposing complex questions,
necessitating supervised fine-tuning. Previous work has relied on manual
annotation and knowledge distillation from teacher LLMs, which are
time-consuming and not accurate enough. In this paper, we introduce a novel
framework for enhancing LLMs' planning capabilities by using planning data
derived from knowledge graphs (KGs). LLMs fine-tuned with this data have
improved planning capabilities, better equipping them to handle complex QA
tasks that involve retrieval. Evaluations on multiple datasets, including our
newly proposed benchmark, highlight the effectiveness of our framework and the
benefits of KG-derived planning data.

æè¦ï¼<paragraph>æ¹åå¤§åèªè¨æ¨¡å (LLM) å¨è¤éåç­ (QA) æå¢ä¸­çæè½ä¸ç´æ¯ç ç©¶éé»ãæè¿çç ç©¶åè©¦ééçµåéæ­¥è¦åèå¤é¨æ·åä¾å¢å¼· LLM çæè½ãéç¶å°æ¼ GPT-3.5 ç­é²éæ¨¡åä¾èªªå¾ææï¼ä½è¼å°ç LLM å¨åè§£è¤éåé¡ææé¢è¨ææ°ï¼å æ­¤éè¦ç£ç£å¾®èª¿ãååçç ç©¶ä»°è³´äººå·¥æ¨è¨»åæå¸« LLM çç¥è­èåï¼éèæä¸ä¸å¤ ç²¾ç¢ºãå¨æ¬æä¸­ï¼æåä»ç´¹ä¸ååµæ°çæ¶æ§ï¼ééä½¿ç¨å¾ç¥è­åè­ (KG) ä¸­è¡ççè¦åè³æä¾å¢å¼· LLM çè¦åè½åãä½¿ç¨æ­¤è³æå¾®èª¿ç LLM æ¹åäºè¦åè½åï¼è®å®åæ´è½èçæ¶åæ·åçè¤é QA ä»»åãå¨å¤åè³æéï¼åæ¬æåæ°æåºçåºæºï¼ä¸çè©ä¼°çªé¡¯äºæåæ¶æ§çæææ§ï¼ä»¥å KG è¡çè¦åè³æçå¥½èã</paragraph>

##### **ReaLHF: Optimized RLHF Training for Large Language Models through Parameter Reallocation**
2406.14088v1 by Zhiyu Mei, Wei Fu, Kaiwei Li, Guangju Wang, Huanchen Zhang, Yi Wu

Reinforcement Learning from Human Feedback (RLHF) stands as a pivotal
technique in empowering large language model (LLM) applications. Since RLHF
involves diverse computational workloads and intricate dependencies among
multiple LLMs, directly adopting parallelization techniques from supervised
training can result in sub-optimal performance. To overcome this limitation, we
propose a novel approach named parameter ReaLlocation, which dynamically
redistributes LLM parameters in the cluster and adapts parallelization
strategies during training. Building upon this idea, we introduce ReaLHF, a
pioneering system capable of automatically discovering and running efficient
execution plans for RLHF training given the desired algorithmic and hardware
configurations. ReaLHF formulates the execution plan for RLHF as an augmented
dataflow graph. Based on this formulation, ReaLHF employs a tailored search
algorithm with a lightweight cost estimator to discover an efficient execution
plan. Subsequently, the runtime engine deploys the selected plan by effectively
parallelizing computations and redistributing parameters. We evaluate ReaLHF on
the LLaMA-2 models with up to $4\times70$ billion parameters and 128 GPUs. The
experiment results showcase ReaLHF's substantial speedups of $2.0-10.6\times$
compared to baselines. Furthermore, the execution plans generated by ReaLHF
exhibit an average of $26\%$ performance improvement over heuristic approaches
based on Megatron-LM. The source code of ReaLHF is publicly available at
https://github.com/openpsi-project/ReaLHF .

æè¦ï¼å¼·åå­¸ç¿ä¾èªäººé¡åé¥ (RLHF) æ¯ä¸ç¨®ééµæè¡ï¼ç¨æ¼è³¦è½å¤§åèªè¨æ¨¡å (LLM) æç¨ç¨å¼ãç±æ¼ RLHF æ¶åå¤ç¨®éç®å·¥ä½è² è¼åå¤å LLM ä¹éçè¤éä¾è³´éä¿ï¼ç´æ¥æ¡ç¨ç£ç£å¼è¨ç·´çå¹³è¡åæè¡å¯è½æå°è´æ¬¡ä½³æè½ãçºäºåæéåéå¶ï¼æåæåºäºä¸ç¨®åçºåæ¸éæ°éç½®çæ°æ¹æ³ï¼å®æåæéæ°åéå¢éä¸­ç LLM åæ¸ï¼ä¸¦å¨è¨ç·´æéèª¿æ´å¹³è¡åç­ç¥ãå¨æ­¤æ¦å¿µçåºç¤ä¸ï¼æåå¼å¥äº ReaLHFï¼éæ¯ä¸åéåµæ§çç³»çµ±ï¼è½å¤ èªåç¼ç¾ä¸¦å·è¡ RLHF è¨ç·´çé«æå·è¡è¨ç«ï¼ä¸¦èéæéçæ¼ç®æ³åç¡¬é«çµæãReaLHF å° RLHF çå·è¡è¨ç«å¶å®çºä¸åæ´å¢è³ææµåãåºæ¼æ­¤å¶å®ï¼ReaLHF æ¡ç¨éèº«æé çæå°æ¼ç®æ³ï¼æ­éè¼éç´ææ¬ä¼°è¨å¨ï¼ä»¥ç¼ç¾é«æçå·è¡è¨ç«ãé¨å¾ï¼å·è¡æéå¼æééææå¹³è¡åéç®åéæ°åéåæ¸ï¼ä¾é¨ç½²æé¸çè¨ç«ãæåå¨ LLaMA-2 æ¨¡åä¸è©ä¼° ReaLHFï¼è©²æ¨¡åæå¤æ $4\times70$0 åååæ¸å 128 å GPUãå¯¦é©çµæé¡¯ç¤ºï¼èåºæºç¸æ¯ï¼ReaLHF çéåº¦æåäº $2.0-10.6\times$ãæ­¤å¤ï¼ReaLHF çæçå·è¡è¨ç«æ¯åºæ¼ Megatron-LM çåç¼å¼æ¹æ³ï¼å¹³åæè½æåäº $26\%$ãReaLHF çåå§ç¨å¼ç¢¼å¬éæ¼ https://github.com/openpsi-project/ReaLHFã

##### **HIGHT: Hierarchical Graph Tokenization for Graph-Language Alignment**
2406.14021v1 by Yongqiang Chen, Quanming Yao, Juzheng Zhang, James Cheng, Yatao Bian

Recently there has been a surge of interest in extending the success of large
language models (LLMs) to graph modality, such as social networks and
molecules. As LLMs are predominantly trained with 1D text data, most existing
approaches adopt a graph neural network to represent a graph as a series of
node tokens and feed these tokens to LLMs for graph-language alignment. Despite
achieving some successes, existing approaches have overlooked the hierarchical
structures that are inherent in graph data. Especially, in molecular graphs,
the high-order structural information contains rich semantics of molecular
functional groups, which encode crucial biochemical functionalities of the
molecules. We establish a simple benchmark showing that neglecting the
hierarchical information in graph tokenization will lead to subpar
graph-language alignment and severe hallucination in generated outputs. To
address this problem, we propose a novel strategy called HIerarchical GrapH
Tokenization (HIGHT). HIGHT employs a hierarchical graph tokenizer that
extracts and encodes the hierarchy of node, motif, and graph levels of
informative tokens to improve the graph perception of LLMs. HIGHT also adopts
an augmented graph-language supervised fine-tuning dataset, enriched with the
hierarchical graph information, to further enhance the graph-language
alignment. Extensive experiments on 7 molecule-centric benchmarks confirm the
effectiveness of HIGHT in reducing hallucination by 40%, as well as significant
improvements in various molecule-language downstream tasks.

æè¦ï¼<paragraph>æè¿ï¼äººä»¬å¯¹å°å¤§åè¯­è¨æ¨¡å (LLM) çæåæ©å±å°å¾æ¨¡å¼ï¼ä¾å¦ç¤¾äº¤ç½ç»ååå­ï¼äº§çäºæµåçå´è¶£ãç±äº LLM ä¸»è¦ä½¿ç¨ä¸ç»´ææ¬æ°æ®è¿è¡è®­ç»ï¼å æ­¤å¤§å¤æ°ç°ææ¹æ³éç¨å¾ç¥ç»ç½ç»å°å¾è¡¨ç¤ºä¸ºä¸ç³»åèç¹æ è®°ï¼å¹¶å°è¿äºæ è®°é¦éè³ LLM ä»¥è¿è¡å¾è¯­è¨å¯¹é½ãå°½ç®¡åå¾äºä¸äºæåï¼ä½ç°ææ¹æ³å´å¿½è§äºå¾æ°æ®ä¸­åºæçå±æ¬¡ç»æãç¹å«æ¯å¨åå­å¾ä¸­ï¼é«é¶ç»æä¿¡æ¯åå«ä¸°å¯çåå­å®è½å¢è¯­ä¹ï¼å®å¯¹åå­çå³é®çååè½è¿è¡ç¼ç ãæä»¬å»ºç«äºä¸ä¸ªç®åçåºåï¼è¡¨æå¨å¾æ è®°åä¸­å¿½ç¥å±æ¬¡ä¿¡æ¯ä¼å¯¼è´æ¬¡ä¼çå¾è¯­è¨å¯¹é½ï¼å¹¶å¨çæçè¾åºä¸­åºç°ä¸¥éçå¹»è§ãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æä»¬æåºäºä¸ç§ç§°ä¸ºåå±å¾æ è®°å (HIGHT) çæ°ç­ç¥ãHIGHT éç¨åå±å¾æ è®°å¨ï¼è¯¥æ è®°å¨æååç¼ç ä¿¡æ¯æ è®°çèç¹ãä¸»é¢åå¾çº§å«å±æ¬¡ç»æï¼ä»¥æ¹å LLM çå¾æç¥ãHIGHT è¿éç¨äºä¸ä¸ªç»è¿æ©åçå¾è¯­è¨çç£å¾®è°æ°æ®éï¼è¯¥æ°æ®éåå«åå±å¾ä¿¡æ¯ï¼ä»¥è¿ä¸æ­¥å¢å¼ºå¾è¯­è¨å¯¹é½ãå¨ 7 ä¸ªä»¥åå­ä¸ºä¸­å¿çåºåä¸çå¤§éå®éªè¯å®äº HIGHT å¨å°å¹»è§åå° 40% æ¹é¢çæææ§ï¼ä»¥åå¨åç§åå­è¯­è¨ä¸æ¸¸ä»»å¡ä¸­çæ¾èæ¹è¿ã</paragraph>

##### **A Pure Transformer Pretraining Framework on Text-attributed Graphs**
2406.13873v1 by Yu Song, Haitao Mao, Jiachen Xiao, Jingzhe Liu, Zhikai Chen, Wei Jin, Carl Yang, Jiliang Tang, Hui Liu

Pretraining plays a pivotal role in acquiring generalized knowledge from
large-scale data, achieving remarkable successes as evidenced by large models
in CV and NLP. However, progress in the graph domain remains limited due to
fundamental challenges such as feature heterogeneity and structural
heterogeneity. Recently, increasing efforts have been made to enhance node
feature quality with Large Language Models (LLMs) on text-attributed graphs
(TAGs), demonstrating superiority to traditional bag-of-words or word2vec
techniques. These high-quality node features reduce the previously critical
role of graph structure, resulting in a modest performance gap between Graph
Neural Networks (GNNs) and structure-agnostic Multi-Layer Perceptrons (MLPs).
Motivated by this, we introduce a feature-centric pretraining perspective by
treating graph structure as a prior and leveraging the rich, unified feature
space to learn refined interaction patterns that generalizes across graphs. Our
framework, Graph Sequence Pretraining with Transformer (GSPT), samples node
contexts through random walks and employs masked feature reconstruction to
capture pairwise proximity in the LLM-unified feature space using a standard
Transformer. By utilizing unified text representations rather than varying
structures, our framework achieves significantly better transferability among
graphs within the same domain. GSPT can be easily adapted to both node
classification and link prediction, demonstrating promising empirical success
on various datasets.

æè¦ï¼é è¨ç·´å¨å¾å¤§åè³æä¸­ç²åå»£æ³ç¥è­æ¹é¢ç¼æ®äºééµä½ç¨ï¼å¾ CV å NLP ä¸­çå¤§åæ¨¡åæè­æçé¡¯èæåä¸­å³å¯è¦ä¸æãç¶èï¼ç±æ¼ç¹å¾µç°è³ªæ§åçµæ§ç°è³ªæ§ç­åºæ¬ææ°ï¼åå½¢é åçé²å±ä»ç¶æéãæè¿ï¼äººåå¨ææ¬å±¬æ§å (TAG) ä¸ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾å¢å¼·ç¯é»ç¹å¾µåè³ªï¼ä¸¦å·²ååºè¶ä¾è¶å¤åªåï¼è­æå¶åªæ¼å³çµ±çè©è¢æ word2vec æè¡ãéäºé«åè³ªç¯é»ç¹å¾µéä½äºåå½¢çµæ§ååè³ééè¦çä½ç¨ï¼å°è´åå½¢ç¥ç¶ç¶²è·¯ (GNN) åèçµæ§ç¡éçå¤å±¤æç¥å¨ (MLP) ä¹éçæè½å·®è·ç¸®å°ãåå°æ­¤åç¼ï¼æåééå°åå½¢çµæ§è¦çºåé©ï¼ä¸¦å©ç¨è±å¯ççµ±ä¸ç¹å¾µç©ºéä¾å­¸ç¿å¨åå½¢ä¸­æ¦æ¬çç²¾ç·»äºåæ¨¡å¼ï¼å¼å¥äºä»¥ç¹å¾µçºä¸­å¿çé è¨ç·´è§é»ãæåçæ¶æ§åå½¢åºåé è¨ç·´è Transformer (GSPT)ï¼ééé¨æ©éèµ°åæ¨£ç¯é»èçµ¡ï¼ä¸¦æ¡ç¨é®è½ç¹å¾µéå»ºï¼ä»¥ä½¿ç¨æ¨æº Transformer å¨ LLM çµ±ä¸ç¹å¾µç©ºéä¸­æ·åæå°æ¥è¿åº¦ãééå©ç¨çµ±ä¸çæå­è¡¨å¾µï¼èéè®åççµæ§ï¼æåçæ¶æ§å¨åä¸åç¶²åä¸­çåå½¢ä¹ééå°äºé¡¯èæ´å¥½çå¯å³éæ§ãGSPT å¯ä»¥è¼é¬å°èª¿æ´å°ç¯é»åé¡åé£çµé æ¸¬ï¼å¨åç¨®è³æéä¸å±ç¾åºæå¸æçå¯¦è­æåã

##### **Knowledge Graph-Enhanced Large Language Models via Path Selection**
2406.13862v1 by Haochen Liu, Song Wang, Yaochen Zhu, Yushun Dong, Jundong Li

Large Language Models (LLMs) have shown unprecedented performance in various
real-world applications. However, they are known to generate factually
inaccurate outputs, a.k.a. the hallucination problem. In recent years,
incorporating external knowledge extracted from Knowledge Graphs (KGs) has
become a promising strategy to improve the factual accuracy of LLM-generated
outputs. Nevertheless, most existing explorations rely on LLMs themselves to
perform KG knowledge extraction, which is highly inflexible as LLMs can only
provide binary judgment on whether a certain knowledge (e.g., a knowledge path
in KG) should be used. In addition, LLMs tend to pick only knowledge with
direct semantic relationship with the input text, while potentially useful
knowledge with indirect semantics can be ignored. In this work, we propose a
principled framework KELP with three stages to handle the above problems.
Specifically, KELP is able to achieve finer granularity of flexible knowledge
extraction by generating scores for knowledge paths with input texts via latent
semantic matching. Meanwhile, knowledge paths with indirect semantic
relationships with the input text can also be considered via trained encoding
between the selected paths in KG and the input text. Experiments on real-world
datasets validate the effectiveness of KELP.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®å¯¦éæç¨ä¸­å±ç¾äºåææªæçæè½ãç¶èï¼å®åæç¢çäºå¯¦ä¸ä¸æºç¢ºçè¼¸åºï¼ä¹å°±æ¯æè¬çå¹»è¦ºåé¡ãè¿å¹´ä¾ï¼ç´å¥å¾ç¥è­åè­ (KG) ä¸­èåçå¤é¨ç¥è­å·²æçºæ¹å LLM çæçè¼¸åºäºå¯¦æºç¢ºæ§çæåéç­ç¥ãåç®¡å¦æ­¤ï¼ç¾æçæ¢ç´¢å¤§å¤ä¾è³´ LLM æ¬èº«ä¾å·è¡ KG ç¥è­èåï¼ééå¸¸ä¸éæ´»ï¼å çº LLM åªæå°ç¹å®ç¥è­ï¼ä¾å¦ï¼KG ä¸­çç¥è­è·¯å¾ï¼æ¯å¦æè©²ä½¿ç¨æä¾äºåå¤æ·ãæ­¤å¤ï¼LLM å¾ååæé¸èè¼¸å¥æå­æç´æ¥èªç¾©éä¿çç¥è­ï¼èå¯è½å°èªææéæ¥éè¯çæç¨ç¥è­å¯è½æè¢«å¿½ç¥ãå¨éé å·¥ä½ä¸­ï¼æåæåºä¸åæååç KELP æ¶æ§ï¼åå«ä¸åéæ®µä¾èçä¸è¿°åé¡ãå·é«ä¾èªªï¼KELP è½å¤ ééé±å«èªç¾©æ¯å°çºç¥è­è·¯å¾èè¼¸å¥æå­ç¢çåæ¸ï¼é²èéææ´ç´°ç·»çå½æ§ç¥è­èåãåæï¼ä¹å¯ä»¥ééå¨ KG ä¸­é¸å®çè·¯å¾èè¼¸å¥æå­ä¹éè¨ç·´ç·¨ç¢¼çæ¹å¼ï¼èéèè¼¸å¥æå­æéæ¥èªç¾©éä¿çç¥è­è·¯å¾ãå¨å¯¦éè³æéä¸çå¯¦é©é©è­äº KELP çæææ§ã

##### **Few-shot Knowledge Graph Relational Reasoning via Subgraph Adaptation**
2406.15507v1 by Haochen Liu, Song Wang, Chen Chen, Jundong Li

Few-shot Knowledge Graph (KG) Relational Reasoning aims to predict unseen
triplets (i.e., query triplets) for rare relations in KGs, given only several
triplets of these relations as references (i.e., support triplets). This task
has gained significant traction due to the widespread use of knowledge graphs
in various natural language processing applications. Previous approaches have
utilized meta-training methods and manually constructed meta-relation sets to
tackle this task. Recent efforts have focused on edge-mask-based methods, which
exploit the structure of the contextualized graphs of target triplets (i.e., a
subgraph containing relevant triplets in the KG). However, existing
edge-mask-based methods have limitations in extracting insufficient information
from KG and are highly influenced by spurious information in KG. To overcome
these challenges, we propose SAFER (Subgraph Adaptation for Few-shot Relational
Reasoning), a novel approach that effectively adapts the information in
contextualized graphs to various subgraphs generated from support and query
triplets to perform the prediction. Specifically, SAFER enables the extraction
of more comprehensive information from support triplets while minimizing the
impact of spurious information when predicting query triplets. Experimental
results on three prevalent datasets demonstrate the superiority of our proposed
framework SAFER.

æè¦ï¼å°æ ·æ¬ç¥è¯å¾è°± (KG) å³ç³»æ¨çæ¨å¨é¢æµ KG ä¸­ç½è§å³ç³»ççä¸è§ä¸åç»ï¼å³æ¥è¯¢ä¸åç»ï¼ï¼èä»ç»åºå ä¸ªä¸åç»ä½ä¸ºåèï¼å³æ¯æä¸åç»ï¼ãç±äºç¥è¯å¾è°±å¨åç§èªç¶è¯­è¨å¤çåºç¨ç¨åºä¸­çå¹¿æ³ä½¿ç¨ï¼è¿é¡¹ä»»å¡è·å¾äºæ¾èçå³æ³¨ãä»¥åçæ¹æ³å©ç¨åè®­ç»æ¹æ³åæå¨æå»ºçåå³ç³»éæ¥è§£å³æ­¤ä»»å¡ãæè¿çåªåéä¸­å¨åºäºè¾¹ç¼æ©ç çæ¹æ³ä¸ï¼è¯¥æ¹æ³å©ç¨ç®æ ä¸åç»çä¸ä¸æåå¾çç»æï¼å³åå« KG ä¸­ç¸å³ä¸åç»çå­å¾ï¼ãç¶èï¼ç°æçåºäºè¾¹ç¼æ©ç çæ¹æ³å¨ä» KG ä¸­æåä¸è¶³ä¿¡æ¯æ¹é¢å­å¨å±éæ§ï¼å¹¶ä¸å KG ä¸­èåä¿¡æ¯çæå¤§å½±åãä¸ºäºåæè¿äºææï¼æä»¬æåºäº SAFERï¼ç¨äºå°æ ·æ¬å³ç³»æ¨ççå­å¾èªéåºï¼ï¼ä¸ç§æ°é¢çæ¹æ³ï¼å®ææå°å°ä¸ä¸æåå¾ä¸­çä¿¡æ¯éåºä»æ¯æåæ¥è¯¢ä¸åç»çæçä¸åå­å¾ä»¥æ§è¡é¢æµãå·ä½æ¥è¯´ï¼SAFER è½å¤ä»æ¯æä¸åç»ä¸­æåæ´å¨é¢çä¿¡æ¯ï¼åæ¶å¨é¢æµæ¥è¯¢ä¸åç»æ¶æå¤§ç¨åº¦å°åå°èåä¿¡æ¯çå½±åãå¨ä¸ä¸ªæµè¡æ°æ®éä¸çå®éªç»æè¯æäºæä»¬æåºç SAFER æ¡æ¶çä¼è¶æ§ã

##### **Dr.E Bridges Graphs with Large Language Models through Words**
2406.15504v1 by Zipeng Liu, Likang Wu, Ming He, Zhong Guan, Hongke Zhao, Nan Feng

Significant efforts have been directed toward integrating powerful Large
Language Models (LLMs) with diverse modalities, particularly focusing on the
fusion of vision, language, and audio data. However, the graph-structured data,
inherently rich in structural and domain-specific knowledge, have not yet been
gracefully adapted to LLMs. Existing methods either describe the graph with raw
text, suffering the loss of graph structural information, or feed Graph Neural
Network (GNN) embeddings directly into LLM at the cost of losing semantic
representation. To bridge this gap, we introduce an innovative, end-to-end
modality-aligning framework, equipped with a pretrained Dual-Residual Vector
Quantized-Variational AutoEncoder (Dr.E). This framework is specifically
designed to facilitate token-level alignment with LLMs, enabling an effective
translation of the intrinsic `language' of graphs into comprehensible natural
language. Our experimental evaluations on standard GNN node classification
tasks demonstrate competitive performance against other state-of-the-art
approaches. Additionally, our framework ensures interpretability, efficiency,
and robustness, with its effectiveness further validated under both fine-tuning
and few-shot settings. This study marks the first successful endeavor to
achieve token-level alignment between GNNs and LLMs.

æè¦ï¼å¤§éçåªåå·²æå¥å°å°å¼·å¤§çå¤§åèªè¨æ¨¡å (LLM) èä¸åçæ¨¡ææ´åï¼ç¹å¥æ¯å°æ³¨æ¼è¦è¦ºãèªè¨åé³è¨è³æçèåãç¶èï¼åå½¢çµæ§åçè³ææ¬è³ªä¸å¯å«çµæ§åé åç¹å®çç¥è­ï¼ä½å°æªåªéå°é©æ LLMãç¾ææ¹æ³ä¸æ¯ç¨åå§æå­æè¿°åå½¢ï¼å°è´åå½¢çµæ§è³è¨éºå¤±ï¼å°±æ¯å°åå½¢ç¥ç¶ç¶²è·¯ (GNN) çåµå¥ç´æ¥é¥å¥ LLMï¼ä»£å¹æ¯å¤±å»èªç¾©è¡¨ç¤ºãçºäºå½è£éåå·®è·ï¼æåå¼å¥äºä¸ååµæ°çç«¯å°ç«¯æ¨¡æå°é½æ¡æ¶ï¼éåäºä¸åé åè¨ç·´çéæ®å·®åééåè®åèªç·¨ç¢¼å¨ (Dr.E)ãæ­¤æ¡æ¶ç¹å¥è¨­è¨ç¨æ¼ä¿é²è LLM çæ¨è¨å±¤ç´å°é½ï¼è®åå½¢çå§å¨ãèªè¨ãè½ææè½ææææ¼çè§£çèªç¶èªè¨ãæåå¨æ¨æº GNN ç¯é»åé¡ä»»åä¸çå¯¦é©è©ä¼°é¡¯ç¤ºï¼èå¶ä»æåé²çæ¹æ³ç¸æ¯ï¼æåçè¡¨ç¾å·æç«¶ç­åãæ­¤å¤ï¼æåçæ¡æ¶ç¢ºä¿äºè§£éæ§ãæçåç©©å¥æ§ï¼å¨å¾®èª¿åå°æ¨£æ¬è¨­å®ä¸é²ä¸æ­¥é©è­å¶æææ§ãéé ç ç©¶æ¨èªèå¨ GNN å LLM ä¹éå¯¦ç¾æ¨è¨å±¤ç´å°é½çé¦æ¬¡æååè©¦ã

##### **Enhancing Distractor Generation for Multiple-Choice Questions with Retrieval Augmented Pretraining and Knowledge Graph Integration**
2406.13578v1 by Han-Cheng Yu, Yu-An Shih, Kin-Man Law, Kai-Yu Hsieh, Yu-Chen Cheng, Hsin-Chih Ho, Zih-An Lin, Wen-Chuan Hsu, Yao-Chung Fan

In this paper, we tackle the task of distractor generation (DG) for
multiple-choice questions. Our study introduces two key designs. First, we
propose \textit{retrieval augmented pretraining}, which involves refining the
language model pretraining to align it more closely with the downstream task of
DG. Second, we explore the integration of knowledge graphs to enhance the
performance of DG. Through experiments with benchmarking datasets, we show that
our models significantly outperform the state-of-the-art results. Our
best-performing model advances the F1@3 score from 14.80 to 16.47 in MCQ
dataset and from 15.92 to 16.50 in Sciq dataset.

æè¦ï¼å¨æ¬æä¸­ï¼æä»¬èçå¤é¸é¡çå¹²æ¾å¨çæ (DG) ä»»åãæåçç ç©¶å¼å¥äºå©åééµè¨­è¨ãé¦åï¼æåæåºãæª¢ç´¢å¢å¼·é è¨ç·´ãï¼å¶ä¸­åå«åªåèªè¨æ¨¡åé è¨ç·´ï¼ä½¿å¶è DG çä¸æ¸¸ä»»åæ´ç·å¯å°å°é½ãå¶æ¬¡ï¼æåæ¢è¨ç¥è­åè¡¨çæ´åï¼ä»¥å¢å¼· DG çæè½ãééåºæºè³æéçå¯¦é©ï¼æåè­ææåçæ¨¡åæé¡¯åªæ¼æåé²ççµæãæåæè½æä½³çæ¨¡åå° MCQ è³æéä¸­ç F1@3 åæ¸å¾ 14.80 æåå° 16.47ï¼å¨ Sciq è³æéä¸­å¾ 15.92 æåå° 16.50ã

##### **LangTopo: Aligning Language Descriptions of Graphs with Tokenized Topological Modeling**
2406.13250v1 by Zhong Guan, Hongke Zhao, Likang Wu, Ming He, Jianpin Fan

Recently, large language models (LLMs) have been widely researched in the
field of graph machine learning due to their outstanding abilities in language
comprehension and learning. However, the significant gap between natural
language tasks and topological structure modeling poses a nonnegligible
challenge. Specifically, since natural language descriptions are not sufficient
for LLMs to understand and process graph-structured data, fine-tuned LLMs
perform even worse than some traditional GNN models on graph tasks, lacking
inherent modeling capabilities for graph structures. Existing research overly
emphasizes LLMs' understanding of semantic information captured by external
models, while inadequately exploring graph topological structure modeling,
thereby overlooking the genuine capabilities that LLMs lack. Consequently, in
this paper, we introduce a new framework, LangTopo, which aligns graph
structure modeling with natural language understanding at the token level.
LangTopo quantifies the graph structure modeling capabilities of GNNs and LLMs
by constructing a codebook for the graph modality and performs consistency
maximization. This process aligns the text description of LLM with the
topological modeling of GNN, allowing LLM to learn the ability of GNN to
capture graph structures, enabling LLM to handle graph-structured data
independently. We demonstrate the effectiveness of our proposed method on
multiple datasets.

æè¦ï¼<paragraph>æè¿ï¼å¤§è¯­è¨æ¨¡å (LLM) ç±äºå¶å¨è¯­è¨çè§£åå­¦ä¹ æ¹é¢çåºè²è½åèå¨å¾æºå¨å­¦ä¹ é¢ååå°å¹¿æ³ç ç©¶ãç¶èï¼èªç¶è¯­è¨ä»»å¡åææç»æå»ºæ¨¡ä¹é´çå·¨å¤§å·®è·ææäºä¸å¯å¿½è§çææãå·ä½æ¥è¯´ï¼ç±äºèªç¶è¯­è¨æè¿°ä¸è¶³ä»¥è®© LLM çè§£åå¤çå¾ç»æåæ°æ®ï¼å æ­¤ç»è¿å¾®è°ç LLM å¨å¾ä»»å¡ä¸çè¡¨ç°çè³æ¯ä¸äºä¼ ç»ç GNN æ¨¡åè¿è¦å·®ï¼ç¼ºä¹å¯¹å¾ç»æçåºæå»ºæ¨¡è½åãç°æç ç©¶è¿åå¼ºè° LLM å¯¹å¤é¨æ¨¡åæè·çè¯­ä¹ä¿¡æ¯ççè§£ï¼èå¯¹å¾ææç»æå»ºæ¨¡çæ¢ç´¢ä¸è¶³ï¼ä»èå¿½è§äº LLM æç¼ºä¹ççæ­£è½åãå æ­¤ï¼å¨æ¬æä¸­ï¼æä»¬å¼å¥äºä¸ä¸ªæ°çæ¡æ¶ LangTopoï¼å®å¨æ è®°çº§å«å°å¾ç»æå»ºæ¨¡ä¸èªç¶è¯­è¨çè§£ç¸ç»åãLangTopo éè¿ä¸ºå¾æ¨¡ææå»ºç æ¬å¹¶æ§è¡ä¸è´æ§æå¤§åæ¥éå GNN å LLM çå¾ç»æå»ºæ¨¡è½åãæ­¤è¿ç¨å° LLM çææ¬æè¿°ä¸ GNN çææå»ºæ¨¡ç¸ç»åï¼ä½¿ LLM è½å¤å­¦ä¹  GNN æè·å¾ç»æçè½åï¼ä»èä½¿ LLM è½å¤ç¬ç«å¤çå¾ç»æåæ°æ®ãæä»¬å¨å¤ä¸ªæ°æ®éä¸å±ç¤ºäºæä»¬æåºçæ¹æ³çæææ§ã</paragraph>

##### **Enhancing Collaborative Semantics of Language Model-Driven Recommendations via Graph-Aware Learning**
2406.13235v1 by Zhong Guan, Likang Wu, Hongke Zhao, Ming He, Jianpin Fan

Large Language Models (LLMs) are increasingly prominent in the recommendation
systems domain. Existing studies usually utilize in-context learning or
supervised fine-tuning on task-specific data to align LLMs into
recommendations. However, the substantial bias in semantic spaces between
language processing tasks and recommendation tasks poses a nonnegligible
challenge. Specifically, without the adequate capturing ability of
collaborative information, existing modeling paradigms struggle to capture
behavior patterns within community groups, leading to LLMs' ineffectiveness in
discerning implicit interaction semantic in recommendation scenarios. To
address this, we consider enhancing the learning capability of language
model-driven recommendation models for structured data, specifically by
utilizing interaction graphs rich in collaborative semantics. We propose a
Graph-Aware Learning for Language Model-Driven Recommendations (GAL-Rec).
GAL-Rec enhances the understanding of user-item collaborative semantics by
imitating the intent of Graph Neural Networks (GNNs) to aggregate multi-hop
information, thereby fully exploiting the substantial learning capacity of LLMs
to independently address the complex graphs in the recommendation system.
Sufficient experimental results on three real-world datasets demonstrate that
GAL-Rec significantly enhances the comprehension of collaborative semantics,
and improves recommendation performance.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼å¨æ¨è¦ç³»çµ±é åä¸­è¶ä¾è¶çªåºãç¾æç ç©¶éå¸¸å©ç¨æå¢å­¸ç¿æå¨ç¹å®ä»»åæ¸æä¸é²è¡ç£ç£å¾®èª¿ï¼ä»¥å° LLM èª¿æ´çºå»ºè­°ãç¶èï¼èªè¨èçä»»ååæ¨è¦ä»»åä¹éèªç¾©ç©ºéçå¯¦è³ªæ§åå·®æ§æäºä¸å¯å¿½è¦çææ°ãå·é«ä¾èªªï¼ç¾æçå»ºæ¨¡ç¯ä¾å¨ç¼ºä¹åä½ä¿¡æ¯çååæç²è½åçææ³ä¸ï¼é£ä»¥ææç¤¾ç¾¤ç¾¤çµå§çè¡çºæ¨¡å¼ï¼å°è´ LLM ç¡æ³å¨æ¨è¦å ´æ¯ä¸­è¾¨è­é±å«çäºåèªç¾©ãçºäºè§£æ±ºéååé¡ï¼æåèæ®å¢å¼·èªè¨æ¨¡åé©åæ¨è¦æ¨¡åå°çµæ§åæ¸æçå­¸ç¿è½åï¼ç¹å¥æ¯ééå©ç¨å¯å«åä½èªç¾©çäº¤äºåãæåæåºäºä¸ååæç¥èªè¨æ¨¡åé©åæ¨è¦å­¸ç¿ï¼GAL-Recï¼ãGAL-Rec ééæ¨¡ä»¿åç¥ç¶ç¶²è·¯ï¼GNNï¼èåå¤è·³ä¿¡æ¯çæåä¾å¢å¼·å°ä½¿ç¨èé ç®åä½èªç¾©ççè§£ï¼å¾èååå©ç¨ LLM çå¯¦è³ªæ§å­¸ç¿è½åä¾ç¨ç«èçæ¨è¦ç³»çµ±ä¸­çè¤éåãå¨ä¸åçå¯¦ä¸çæ¸æéä¸é²è¡çååå¯¦é©çµæè¡¨æï¼GAL-Rec å¤§å¤§å¢å¼·äºå°åä½èªç¾©ççè§£ï¼ä¸¦æ¹åäºæ¨è¦æ§è½ã

##### **Bridging Law and Data: Augmenting Reasoning via a Semi-Structured Dataset with IRAC methodology**
2406.13217v1 by Xiaoxi Kang, Lizhen Qu, Lay-Ki Soon, Zhuang Li, Adnan Trakic

The effectiveness of Large Language Models (LLMs) in legal reasoning is often
limited due to the unique legal terminologies and the necessity for highly
specialized knowledge. These limitations highlight the need for high-quality
data tailored for complex legal reasoning tasks. This paper introduces
LEGALSEMI, a benchmark specifically curated for legal scenario analysis.
LEGALSEMI comprises 54 legal scenarios, each rigorously annotated by legal
experts, based on the comprehensive IRAC (Issue, Rule, Application, Conclusion)
framework. In addition, LEGALSEMI is accompanied by a structured knowledge
graph (SKG). A series of experiments were conducted to assess the usefulness of
LEGALSEMI for IRAC analysis. The experimental results demonstrate the
effectiveness of incorporating the SKG for issue identification, rule
retrieval, application and conclusion generation using four different LLMs.
LEGALSEMI will be publicly available upon acceptance of this paper.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨æ³å¾æ¨çä¸­çæææ§éå¸¸åå°ç¨ç¹çæ³å¾è¡èªåé«åº¦å°æ¥­ç¥è­çå¿è¦æ§çéå¶ãéäºéå¶çªé¡¯äºéå°è¤éæ³å¾æ¨çä»»åéèº«æé çé«åè³ªè³æçéæ±ãæ¬æä»ç´¹ LEGALSEMIï¼éæ¯ä¸åå°éçºæ³å¾æå¢åæç­åçåºæºãLEGALSEMI åå« 54 åæ³å¾æå¢ï¼æ¯åæå¢é½ç¶éæ³å¾å°å®¶æ ¹æå¨é¢ç IRACï¼åé¡ãè¦åãæç¨ãçµè«ï¼æ¶æ§å´æ ¼è¨»è§£ãæ­¤å¤ï¼LEGALSEMI ééå¸¶ä¸åçµæ§åçç¥è­åè­ (SKG)ãé²è¡äºä¸ç³»åå¯¦é©ä¾è©ä¼° LEGALSEMI å° IRAC åæçæç¨æ§ãå¯¦é©çµæè­æäºå° SKG ç´å¥åé¡è­å¥ãè¦åæª¢ç´¢ãæç¨åçµè«çæä¸­çæææ§ï¼ä½¿ç¨äºåç¨®ä¸åç LLMãLEGALSEMI å°å¨æ¬æç²æ¥åå¾å¬éã

##### **PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes**
2406.13193v1 by He Cao, Yanjun Shao, Zhiyuan Liu, Zijing Liu, Xiangru Tang, Yuan Yao, Yu Li

Multimodal Large Language Models (MLLMs) have seen growing adoption across
various scientific disciplines. These advancements encourage the investigation
of molecule-text modeling within synthetic chemistry, a field dedicated to
designing and conducting chemical reactions to synthesize new compounds with
desired properties and applications. Current approaches, however, often neglect
the critical role of multiple molecule graph interaction in understanding
chemical reactions, leading to suboptimal performance in synthetic chemistry
tasks. This study introduces PRESTO(Progressive Pretraining Enhances Synthetic
Chemistry Outcomes), a new framework that bridges the molecule-text modality
gap by integrating a comprehensive benchmark of pretraining strategies and
dataset configurations. It progressively improves multimodal LLMs through
cross-modal alignment and multi-graph understanding. Our extensive experiments
demonstrate that PRESTO offers competitive results in downstream synthetic
chemistry tasks. The code can be found at https://github.com/IDEA-XL/PRESTO.

æè¦ï¼å¤æ¨¡æå¤§åè¯­è¨æ¨¡åï¼MLLMï¼å¨åä¸ªç§å­¦å­¦ç§ä¸­éæ¸è¢«éç¨ãè¿äºè¿æ­¥ä¿è¿äºåæåå­¦ä¸­åå­ææ¬å»ºæ¨¡çç ç©¶ï¼åæåå­¦è´åäºè®¾è®¡åè¿è¡åå­¦ååºä»¥åæå·ææéæ§è´¨ååºç¨çæ°ååç©ãç¶èï¼å½åçæ¹æ³éå¸¸å¿½ç¥äºå¤ä¸ªåå­å¾ç¸äºä½ç¨å¨çè§£åå­¦ååºä¸­çå³é®ä½ç¨ï¼å¯¼è´å¨åæåå­¦ä»»å¡ä¸­çæ§è½ä¸ä½³ãæ¬ç ç©¶ä»ç»äº PRESTOï¼æ¸è¿å¼é¢è®­ç»å¢å¼ºåæåå­¦ææï¼ï¼è¿æ¯ä¸ä¸ªæ°çæ¡æ¶ï¼éè¿æ´åé¢è®­ç»ç­ç¥åæ°æ®ééç½®çç»¼ååºåæ¥å¼¥åçåå­ææ¬æ¨¡æå·®è·ãå®éè¿è·¨æ¨¡æå¯¹é½åå¤å¾çè§£éæ­¥æ¹è¿å¤æ¨¡æ LLMãæä»¬çå¹¿æ³å®éªè¡¨æï¼PRESTO å¨ä¸æ¸¸åæåå­¦ä»»å¡ä¸­æä¾äºæç«äºåçç»æãä»£ç å¯å¨ https://github.com/IDEA-XL/PRESTO ä¸­æ¾å°ã

##### **QRMeM: Unleash the Length Limitation through Question then Reflection Memory Mechanism**
2406.13167v1 by Bo Wang, Heyan Huang, Yixin Cao, Jiahao Ying, Wei Tang, Chong Feng

While large language models (LLMs) have made notable advancements in natural
language processing, they continue to struggle with processing extensive text.
Memory mechanism offers a flexible solution for managing long contexts,
utilizing techniques such as compression, summarization, and structuring to
facilitate nuanced and efficient handling of large volumes of text. However,
existing techniques face challenges with static knowledge integration, leading
to insufficient adaptation to task-specific needs and missing
multi-segmentation relationships, which hinders the dynamic reorganization and
logical combination of relevant segments during the response process. To
address these issues, we introduce a novel strategy, Question then Reflection
Memory Mechanism (QRMeM), incorporating a dual-structured memory pool. This
pool synergizes static textual content with structured graph guidance,
fostering a reflective trial-and-error approach for navigating and identifying
relevant segments. Our evaluation across multiple-choice questions (MCQ) and
multi-document question answering (Multi-doc QA) benchmarks showcases QRMeM
enhanced performance compared to existing approaches.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) å¨èªç¶èªè¨èçæ¹é¢åå¾é¡¯èé²å±ï¼ä½å®åå¨èçå¤§éæå­æä»é¢è¨å°é£ãè¨æ¶æ©å¶æä¾äºä¸åéæ´»çè§£æ±ºæ¹æ¡ï¼ç¨æ¼ç®¡çé·ç¯èçµ¡ï¼å©ç¨å£ç¸®ãæè¦åçµæ§åç­æè¡ï¼ä»¥ä¿é²å°å¤§éæå­çç´°ç·»ä¸ææççèçãç¶èï¼ç¾ææè¡å¨éæç¥è­æ´åæ¹é¢é¢è¨ææ°ï¼å°è´ç¡æ³ååé©æç¹å®ä»»åçéæ±ï¼ä¸ç¼ºå°å¤éåæ®µéä¿ï¼éé»ç¤äºåæéç¨ä¸­ç¸éåæ®µçåæéçµåéè¼¯çµåãçºäºè§£æ±ºéäºåé¡ï¼æåå¼å¥äºä¸ç¨®æ°ç­ç¥ï¼å³åç­åæè¨æ¶æ©å¶ (QRMeM)ï¼ä¸¦çµåäºéçµæ§åè¨æ¶æ± ãæ­¤è¨æ¶æ± å°éæææ¬å§å®¹èçµæ§ååå½¢æå°çµåèµ·ä¾ï¼ä¿é²äºä¸ç¨®åææ§çè©¦é¯æ¹æ³ï¼ç¨æ¼å°èªåè­å¥ç¸éåæ®µãæåå¨å¤é¸é¡ (MCQ) åå¤æä»¶åç­ (Multi-doc QA) åºæºä¸çè©ä¼°é¡¯ç¤ºï¼èç¾ææ¹æ³ç¸æ¯ï¼QRMeM å¢å¼·äºæè½ã

##### **Bridging Local Details and Global Context in Text-Attributed Graphs**
2406.12608v1 by Yaoke Wang, Yun Zhu, Wenqiao Zhang, Yueting Zhuang, Yunfei Li, Siliang Tang

Representation learning on text-attributed graphs (TAGs) is vital for
real-world applications, as they combine semantic textual and contextual
structural information. Research in this field generally consist of two main
perspectives: local-level encoding and global-level aggregating, respectively
refer to textual node information unification (e.g., using Language Models) and
structure-augmented modeling (e.g., using Graph Neural Networks). Most existing
works focus on combining different information levels but overlook the
interconnections, i.e., the contextual textual information among nodes, which
provides semantic insights to bridge local and global levels. In this paper, we
propose GraphBridge, a multi-granularity integration framework that bridges
local and global perspectives by leveraging contextual textual information,
enhancing fine-grained understanding of TAGs. Besides, to tackle scalability
and efficiency challenges, we introduce a graphaware token reduction module.
Extensive experiments across various models and datasets show that our method
achieves state-of-theart performance, while our graph-aware token reduction
module significantly enhances efficiency and solves scalability issues.

æè¦ï¼ææ¬å±æ§å¾ (TAG) ä¸çè¡¨å¾å­¦ä¹ å¯¹äºå®éåºç¨è³å³éè¦ï¼å ä¸ºå®ä»¬ç»åäºè¯­ä¹ææ¬åä¸ä¸æç»æä¿¡æ¯ãè¯¥é¢åçç ç©¶ææ¶åçä¸¤ä¸ªä¸»è¦è§ç¹ï¼å±é¨ç¼ç åå¨å±èåï¼åå«æææ¬èç¹ä¿¡æ¯ç»ä¸ï¼ä¾å¦ï¼ä½¿ç¨è¯­è¨æ¨¡åï¼åç»æå¢å¼ºå»ºæ¨¡ï¼ä¾å¦ï¼ä½¿ç¨å¾ç¥ç»ç½ç»ï¼ãå¤§å¤æ°ç°æå·¥ä½ä¾§éäºç»åä¸åçä¿¡æ¯çº§å«ï¼ä½å¿½ç¥äºç¸äºèç³»ï¼å³èç¹ä¹é´çä¸ä¸æææ¬ä¿¡æ¯ï¼å®æä¾äºè¯­ä¹è§è§£ä»¥æ¡¥æ¥å±é¨åå¨å±çº§å«ãå¨æ¬æä¸­ï¼æä»¬æåºäº GraphBridgeï¼è¿æ¯ä¸ä¸ªå¤ç²åº¦éææ¡æ¶ï¼å®éè¿å©ç¨ä¸ä¸æææ¬ä¿¡æ¯æ¥æ¡¥æ¥å±é¨åå¨å±è§è§ï¼å¢å¼ºäºå¯¹ TAG çç»ç²åº¦çè§£ãæ­¤å¤ï¼ä¸ºäºè§£å³å¯æ©å±æ§åæçææï¼æä»¬å¼å¥äºä¸ä¸ªå¾æç¥ä»¤çç¼©åæ¨¡åãè·¨åç§æ¨¡ååæ°æ®éçå¹¿æ³å®éªè¡¨æï¼æä»¬çæ¹æ³å®ç°äºæåè¿çæ§è½ï¼èæä»¬çå¾æç¥ä»¤çç¼©åæ¨¡åæ¾çæé«äºæçå¹¶è§£å³äºå¯æ©å±æ§é®é¢ã

##### **MolecularGPT: Open Large Language Model (LLM) for Few-Shot Molecular Property Prediction**
2406.12950v1 by Yuyan Liu, Sirui Ding, Sheng Zhou, Wenqi Fan, Qiaoyu Tan

Molecular property prediction (MPP) is a fundamental and crucial task in drug
discovery. However, prior methods are limited by the requirement for a large
number of labeled molecules and their restricted ability to generalize for
unseen and new tasks, both of which are essential for real-world applications.
To address these challenges, we present MolecularGPT for few-shot MPP. From a
perspective on instruction tuning, we fine-tune large language models (LLMs)
based on curated molecular instructions spanning over 1000 property prediction
tasks. This enables building a versatile and specialized LLM that can be
adapted to novel MPP tasks without any fine-tuning through zero- and few-shot
in-context learning (ICL). MolecularGPT exhibits competitive in-context
reasoning capabilities across 10 downstream evaluation datasets, setting new
benchmarks for few-shot molecular prediction tasks. More importantly, with just
two-shot examples, MolecularGPT can outperform standard supervised graph neural
network methods on 4 out of 7 datasets. It also excels state-of-the-art LLM
baselines by up to 16.6% increase on classification accuracy and decrease of
199.17 on regression metrics (e.g., RMSE) under zero-shot. This study
demonstrates the potential of LLMs as effective few-shot molecular property
predictors. The code is available at https://github.com/NYUSHCS/MolecularGPT.

æè¦ï¼åå­ç¹æ§é æ¸¬ (MPP) æ¯è¥ç©ç¼ç¾ä¸­çä¸é åºæ¬ä¸è³ééè¦çä»»åãç¶èï¼ååçç ç©¶æ¹æ³åå°å¤§éæ¨è¨åå­éæ±åæ¦åå°æªè¦åæ°ä»»åçè½ååéçéå¶ï¼éå©èå°æ¼å¯¦éæç¨é½æ¯å¿ä¸å¯å°çãçºäºæå°éäºææ°ï¼æåæåºç¨æ¼å°æ¨£æ¬ MPP ç MolecularGPTãå¾æä»¤å¾®èª¿çè§åº¦ä¾çï¼æåæ ¹ææ¶µè 1000 å¤é ç¹æ§é æ¸¬ä»»åçç­ååå­æä»¤å¾®èª¿å¤§åèªè¨æ¨¡å (LLM)ãéä½¿å¾æ§å»ºä¸åå¤åè½ä¸å°æ¥­ç LLM æçºå¯è½ï¼è©² LLM å¯ä»¥ééé¶æ¨£æ¬åå°æ¨£æ¬æå¢å­¸ç¿ (ICL) é©ææ°ç MPP ä»»åï¼èç¡éä»»ä½å¾®èª¿ãMolecularGPT å¨ 10 åä¸æ¸¸è©ä¼°è³æéä¸å±ç¤ºäºå·æç«¶ç­åçæå¢æ¨çè½åï¼çºå°æ¨£æ¬åå­é æ¸¬ä»»åè¨­å®äºæ°çåºæºãæ´éè¦çæ¯ï¼åä½¿ç¨å©æ¨£æ¬ç¯ä¾ï¼MolecularGPT å°±å¯ä»¥å¨ 7 åè³æéä¸­ç 4 åè³æéä¸åªæ¼æ¨æºç£ç£åç¥ç¶ç¶²è·¯æ¹æ³ãå®éå¨é¶æ¨£æ¬ä¸ï¼ééåé¡æºç¢ºåº¦æé«äº 16.6% ååæ­¸ææ¨ï¼ä¾å¦ RMSEï¼æ¸å°äº 199.17ï¼å¾èåªæ¼æåé²ç LLM åºæºãéé ç ç©¶è­æäº LLM ä½çºææå°æ¨£æ¬åå­ç¹æ§é æ¸¬å¨çæ½åãç¨å¼ç¢¼å¯å¨ https://github.com/NYUSHCS/MolecularGPT ç²å¾ã

##### **LightPAL: Lightweight Passage Retrieval for Open Domain Multi-Document Summarization**
2406.12494v1 by Masafumi Enomoto, Kunihiro Takeoka, Kosuke Akimoto, Kiril Gashteovski, Masafumi Oyamada

Open-Domain Multi-Document Summarization (ODMDS) is crucial for addressing
diverse information needs, which aims to generate a summary as answer to user's
query, synthesizing relevant content from multiple documents in a large
collection. Existing approaches that first find relevant passages and then
generate a summary using a language model are inadequate for ODMDS. This is
because open-ended queries often require additional context for the retrieved
passages to cover the topic comprehensively, making it challenging to retrieve
all relevant passages initially. While iterative retrieval methods have been
explored for multi-hop question answering (MQA), they are impractical for ODMDS
due to high latency from repeated large language model (LLM) inference for
reasoning. To address this issue, we propose LightPAL, a lightweight passage
retrieval method for ODMDS that constructs a graph representing passage
relationships using an LLM during indexing and employs random walk instead of
iterative reasoning and retrieval at inference time. Experiments on ODMDS
benchmarks show that LightPAL outperforms baseline retrievers in summary
quality while being significantly more efficient than an iterative MQA
approach.

æè¦ï¼éæ¾é åå¤æä»¶æè¦ (ODMDS) å°æ¼è§£æ±ºä¸åçè³è¨éæ±è³ééè¦ï¼å¶ç®çæ¯æ ¹æä½¿ç¨èçæ¥è©¢ç¢çæè¦ä½çºç­æ¡ï¼ç¶åä¾èªå¤§åéåä¸­å¤åæä»¶çç¸éå§å®¹ãç¾æçæ¹æ³æ¯åæ¾å°ç¸éæ®µè½ï¼ç¶å¾ä½¿ç¨èªè¨æ¨¡åç¢çæè¦ï¼å°æ¼ ODMDS ä¾èªªæ¯ä¸å¤ çãéæ¯å çºéæ¾å¼æ¥è©¢éå¸¸éè¦é¡å¤çå§å®¹ï¼æè½è®æ·åçæ®µè½å¨é¢æ¶µèä¸»é¡ï¼éä½¿å¾ä¸éå§å°±æ·åææç¸éæ®µè½å·æææ°æ§ãéç¶å·²ç¶æ¢ç´¢äºåè¦æ·åçæ¹æ³ç¨æ¼å¤è·³åé¡è§£ç­ (MQA)ï¼ä½ç±æ¼åè¦é²è¡å¤§åèªè¨æ¨¡å (LLM) æ¨è«ä»¥é²è¡æ¨çï¼å æ­¤å®åä¸é©ç¨æ¼ ODMDSï¼å çºéæå°è´é«å»¶é²ãçºäºè§£æ±ºéååé¡ï¼æåæåºäº LightPALï¼éæ¯ä¸ç¨®éå° ODMDS çè¼éç´æ®µè½æ·åæ¹æ³ï¼å®å¨ç´¢å¼æä½¿ç¨ LLM å»ºç«è¡¨ç¤ºæ®µè½éä¿çåï¼ä¸¦å¨æ¨è«æä½¿ç¨é¨æ©éèµ°ï¼èä¸æ¯åè¦æ¨çåæ·åãå¨ ODMDS åºæºæ¸¬è©¦ä¸­çå¯¦é©é¡¯ç¤ºï¼LightPAL å¨æè¦åè³ªä¸åªæ¼åºç·æ·åå¨ï¼åææ¯åè¦ MQA æ¹æ³ææçå¾å¤ã

##### **Interpretable Catastrophic Forgetting of Large Language Model Fine-tuning via Instruction Vector**
2406.12227v2 by Gangwei Jiang, Caigao Jiang, Zhaoyi Li, Siqiao Xue, Jun Zhou, Linqi Song, Defu Lian, Ying Wei

Fine-tuning large language models (LLMs) can cause them to lose their general
capabilities. However, the intrinsic mechanisms behind such forgetting remain
unexplored. In this paper, we begin by examining this phenomenon by focusing on
knowledge understanding and instruction following, with the latter identified
as the main contributor to forgetting during fine-tuning. Consequently, we
propose the Instruction Vector (IV) framework to capture model representations
highly related to specific instruction-following capabilities, thereby making
it possible to understand model-intrinsic forgetting. Through the analysis of
IV dynamics pre and post-training, we suggest that fine-tuning mostly adds
specialized reasoning patterns instead of erasing previous skills, which may
appear as forgetting. Building on this insight, we develop IV-guided training,
which aims to preserve original computation graph, thereby mitigating
catastrophic forgetting. Empirical tests on three benchmarks confirm the
efficacy of this new approach, supporting the relationship between IVs and
forgetting. Our code will be made available soon.

æè¦ï¼å¾®è°å¤§åè¯­è¨æ¨¡å (LLM) å¯è½å¯¼è´å®ä»¬ä¸§å¤±ä¸è¬è½åãç¶èï¼è¿ç§éå¿èåçåå¨æºå¶ä»æªå¾å°æ¢ç´¢ãå¨æ¬æä¸­ï¼æä»¬é¦åéè¿å³æ³¨ç¥è¯çè§£åæä»¤éµå¾ªæ¥æ£éªè¿ç§ç°è±¡ï¼å¶ä¸­åèè¢«è®¤ä¸ºæ¯å¾®è°è¿ç¨ä¸­éå¿çä¸»è¦åå ãå æ­¤ï¼æä»¬æåºäºæä»¤åé (IV) æ¡æ¶æ¥æè·ä¸ç¹å®æä»¤éµå¾ªè½åé«åº¦ç¸å³çæ¨¡åè¡¨ç¤ºï¼ä»èå¯ä»¥çè§£æ¨¡ååå¨çéå¿ãéè¿å¯¹è®­ç»ååç IV å¨æè¿è¡åæï¼æä»¬è®¤ä¸ºå¾®è°ä¸»è¦æ·»å äºä¸é¨çæ¨çæ¨¡å¼ï¼èä¸æ¯æ¹é¤ååçæè½ï¼è¿å¯è½è¡¨ç°ä¸ºéå¿ãåºäºè¿ä¸è§è§£ï¼æä»¬å¼åäº IV æå¯¼è®­ç»ï¼å¶ç®æ æ¯ä¿çåå§è®¡ç®å¾ï¼ä»èåè½»ç¾é¾æ§éå¿ãå¨ä¸ä¸ªåºåä¸çç»éªæµè¯è¯å®äºè¿ç§æ°æ¹æ³çæææ§ï¼æ¯æäº IV åéå¿ä¹é´çå³ç³»ãæä»¬çä»£ç å°å¾å¿«æä¾ã

##### **DTGB: A Comprehensive Benchmark for Dynamic Text-Attributed Graphs**
2406.12072v2 by Jiasheng Zhang, Jialin Chen, Menglin Yang, Aosong Feng, Shuang Liang, Jie Shao, Rex Ying

Dynamic text-attributed graphs (DyTAGs) are prevalent in various real-world
scenarios, where each node and edge are associated with text descriptions, and
both the graph structure and text descriptions evolve over time. Despite their
broad applicability, there is a notable scarcity of benchmark datasets tailored
to DyTAGs, which hinders the potential advancement in many research fields. To
address this gap, we introduce Dynamic Text-attributed Graph Benchmark (DTGB),
a collection of large-scale, time-evolving graphs from diverse domains, with
nodes and edges enriched by dynamically changing text attributes and
categories. To facilitate the use of DTGB, we design standardized evaluation
procedures based on four real-world use cases: future link prediction,
destination node retrieval, edge classification, and textual relation
generation. These tasks require models to understand both dynamic graph
structures and natural language, highlighting the unique challenges posed by
DyTAGs. Moreover, we conduct extensive benchmark experiments on DTGB,
evaluating 7 popular dynamic graph learning algorithms and their variants of
adapting to text attributes with LLM embeddings, along with 6 powerful large
language models (LLMs). Our results show the limitations of existing models in
handling DyTAGs. Our analysis also demonstrates the utility of DTGB in
investigating the incorporation of structural and textual dynamics. The
proposed DTGB fosters research on DyTAGs and their broad applications. It
offers a comprehensive benchmark for evaluating and advancing models to handle
the interplay between dynamic graph structures and natural language. The
dataset and source code are available at https://github.com/zjs123/DTGB.

æè¦ï¼<paragraph>åææå­å±¬æ§åè¡¨ (DyTAGs) æ®éå­å¨æ¼åç¨®çå¯¦ä¸ççå ´æ¯ä¸­ï¼å¶ä¸­æ¯åç¯é»åéç·£é½èæå­æè¿°ç¸éè¯ï¼ä¸åè¡¨çµæ§åæå­æè¿°æé¨èæéæ¼è®ãåç®¡å¶å»£æ³çé©ç¨æ§ï¼ä½å°ééå° DyTAGs çåºæºè³æéå»ååç¨å°ï¼éé»ç¤äºè¨±å¤ç ç©¶é åçæ½å¨é²å±ãçºäºè§£æ±ºéåå·®è·ï¼æåå¼å¥äºåææå­å±¬æ§åè¡¨åºæº (DTGB)ï¼å®æ¯ä¸åä¾èªä¸åé åçå¤§åãæè®åè¡¨çéåï¼å¶ç¯é»åéç·£ç±åæè®åçæå­å±¬æ§åé¡å¥è±å¯åãçºäºä¾¿æ¼ä½¿ç¨ DTGBï¼æåæ ¹æååçå¯¦ä¸ççç¨ä¾è¨­è¨äºæ¨æºåçè©ä¼°ç¨åºï¼æªä¾é£çµé æ¸¬ãç®çå°ç¯é»æª¢ç´¢ãéç·£åé¡åæå­éä¿çæãéäºä»»åè¦æ±æ¨¡ååæçè§£åæåè¡¨çµæ§åèªç¶èªè¨ï¼çªé¡¯äº DyTAGs å¸¶ä¾çç¨ç¹ææ°ãæ­¤å¤ï¼æåå° DTGB é²è¡äºå»£æ³çåºæºå¯¦é©ï¼è©ä¼°äº 7 ç¨®æµè¡çåæåè¡¨å­¸ç¿æ¼ç®æ³åå¶ä½¿ç¨ LLM åµå¥é©ææå­å±¬æ§çè®é«ï¼ä»¥å 6 ç¨®å¼·å¤§çå¤§åèªè¨æ¨¡å (LLM)ãæåççµæé¡¯ç¤ºäºç¾ææ¨¡åå¨èç DyTAGs æ¹é¢çå±éæ§ãæåçåæä¹è­æäº DTGB å¨ç ç©¶çµæ§åæå­åæççµåæ¹é¢çæç¨ãææåºç DTGB ä¿é²äºå° DyTAGs åå¶å»£æ³æç¨çç ç©¶ãå®çºè©ä¼°åæ¨é²æ¨¡åä»¥èçåæåè¡¨çµæ§åèªç¶èªè¨ä¹éçäº¤äºä½ç¨æä¾äºä¸åå¨é¢çåºæºãè³æéååå§ç¢¼å¯å¨ https://github.com/zjs123/DTGB åå¾ã</paragraph>

##### **UniGLM: Training One Unified Language Model for Text-Attributed Graphs**
2406.12052v1 by Yi Fang, Dongzhe Fan, Sirui Ding, Ninghao Liu, Qiaoyu Tan

Representation learning on text-attributed graphs (TAGs), where nodes are
represented by textual descriptions, is crucial for textual and relational
knowledge systems and recommendation systems. Currently, state-of-the-art
embedding methods for TAGs primarily focus on fine-tuning language models
(e.g., BERT) using structure-aware training signals. While effective, these
methods are tailored for individual TAG and cannot generalize across various
graph scenarios. Given the shared textual space, leveraging multiple TAGs for
joint fine-tuning, aligning text and graph structure from different aspects,
would be more beneficial. Motivated by this, we introduce a novel Unified Graph
Language Model (UniGLM) framework, the first graph embedding model that
generalizes well to both in-domain and cross-domain TAGs. Specifically, UniGLM
is trained over multiple TAGs with different domains and scales using
self-supervised contrastive learning. UniGLM includes an adaptive positive
sample selection technique for identifying structurally similar nodes and a
lazy contrastive module that is devised to accelerate training by minimizing
repetitive encoding calculations. Extensive empirical results across 9
benchmark TAGs demonstrate UniGLM's efficacy against leading embedding
baselines in terms of generalization (various downstream tasks and backbones)
and transfer learning (in and out of domain scenarios). The code is available
at https://github.com/NYUSHCS/UniGLM.

æè¦ï¼å¨æå­å±æ§å¾ (TAG) ä¸çè¡¨å¾å­¦ä¹ ï¼å¶ä¸­èç¹ç±æå­æè¿°è¡¨ç¤ºï¼å¯¹äºæå­åå³ç³»ç¥è¯ç³»ç»ä»¥åæ¨èç³»ç»è³å³éè¦ãç®åï¼TAG çæåè¿åµå¥æ¹æ³ä¸»è¦éä¸­äºä½¿ç¨ç»ææç¥è®­ç»ä¿¡å·å¾®è°è¯­è¨æ¨¡åï¼ä¾å¦ï¼BERTï¼ãè½ç¶ææï¼ä½è¿äºæ¹æ³æ¯éå¯¹åä¸ª TAG éèº«å®å¶çï¼å¹¶ä¸æ æ³æ¦æ¬å°åç§å¾åºæ¯ãé´äºå±äº«çææ¬ç©ºé´ï¼å©ç¨å¤ä¸ª TAG è¿è¡èåå¾®è°ï¼ä»ä¸åæ¹é¢è°æ´ææ¬åå¾ç»æï¼å°æ´æçãåæ­¤å¯åï¼æä»¬å¼å¥äºä¸ç§æ°é¢çç»ä¸å¾è¯­è¨æ¨¡å (UniGLM) æ¡æ¶ï¼è¿æ¯ç¬¬ä¸ä¸ªå¨åååè·¨å TAG ä¸­é½è½å¾å¥½å°æ¦æ¬çå¾åµå¥æ¨¡åãå·ä½æ¥è¯´ï¼UniGLM ä½¿ç¨èªçç£å¯¹æ¯å­¦ä¹ å¨å·æä¸åååè§æ¨¡çå¤ä¸ª TAG ä¸è¿è¡è®­ç»ãUniGLM åæ¬ä¸ç§èªéåºæ­£æ ·æ¬éæ©ææ¯ï¼ç¨äºè¯å«ç»æç¸ä¼¼çèç¹ï¼ä»¥åä¸ä¸ªå»¶è¿å¯¹æ¯æ¨¡åï¼è¯¥æ¨¡åæ¨å¨éè¿æå°åéå¤ç¼ç è®¡ç®æ¥å éè®­ç»ãè·¨ 9 ä¸ªåºå TAG çå¹¿æ³å®è¯ç»æè¯æäº UniGLM å¨æ³åï¼åç§ä¸æ¸¸ä»»å¡åä¸»å¹²ï¼åè¿ç§»å­¦ä¹ ï¼ååååå¤åºæ¯ï¼æ¹é¢ç¸å¯¹äºé¢ååµå¥åºåçåæãä»£ç å¯å¨ https://github.com/NYUSHCS/UniGLM è·å¾ã


### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-16**|**Schema Matching with Large Language Models: an Experimental Study**|Marcel Parciak et.al.|[2407.11852v1](http://arxiv.org/abs/2407.11852v1)|[link](https://github.com/uhasselt-dsi-data-systems-lab/code-schema-matching-llms-artefacs)|
|**2024-07-16**|**GPT Assisted Annotation of Rhetorical and Linguistic Features for Interpretable Propaganda Technique Detection in News Text**|Kyle Hamilton et.al.|[2407.11827v1](http://arxiv.org/abs/2407.11827v1)|null|
|**2024-07-16**|**Characterizing and Understanding HGNN Training on GPUs**|Dengke Han et.al.|[2407.11790v1](http://arxiv.org/abs/2407.11790v1)|null|
|**2024-07-16**|**CCoE: A Compact LLM with Collaboration of Experts**|Shaomang Huang et.al.|[2407.11686v2](http://arxiv.org/abs/2407.11686v2)|null|
|**2024-07-16**|**CCVA-FL: Cross-Client Variations Adaptive Federated Learning for Medical Imaging**|Sunny Gupta et.al.|[2407.11652v1](http://arxiv.org/abs/2407.11652v1)|null|
|**2024-07-16**|**Improving Engagement and Efficacy of mHealth Micro-Interventions for Stress Coping: an In-The-Wild Study**|Chaya Ben Yehuda et.al.|[2407.11612v1](http://arxiv.org/abs/2407.11612v1)|null|
|**2024-07-16**|**DiNO-Diffusion. Scaling Medical Diffusion via Self-Supervised Pre-Training**|Guillermo Jimenez-Perez et.al.|[2407.11594v1](http://arxiv.org/abs/2407.11594v1)|null|
|**2024-07-16**|**Probing the Efficacy of Federated Parameter-Efficient Fine-Tuning of Vision Transformers for Medical Image Classification**|Naif Alkhunaizi et.al.|[2407.11573v1](http://arxiv.org/abs/2407.11573v1)|null|
|**2024-07-16**|**Fine-Tuning Medical Language Models for Enhanced Long-Contextual Understanding and Domain Expertise**|Qimin Yang et.al.|[2407.11536v1](http://arxiv.org/abs/2407.11536v1)|null|
|**2024-07-16**|**Cross-Phase Mutual Learning Framework for Pulmonary Embolism Identification on Non-Contrast CT Scans**|Bizhe Bai et.al.|[2407.11529v1](http://arxiv.org/abs/2407.11529v1)|null|
|**2024-07-16**|**Multi-Channel Masked Autoencoder and Comprehensive Evaluations for Reconstructing 12-Lead ECG from Arbitrary Single-Lead ECG**|Jiarong Chen et.al.|[2407.11481v1](http://arxiv.org/abs/2407.11481v1)|[link](https://github.com/chenjiar3/mcma)|
|**2024-07-16**|**TM-PATHVQA:90000+ Textless Multilingual Questions for Medical Visual Question Answering**|Tonmoy Rajkhowa et.al.|[2407.11383v1](http://arxiv.org/abs/2407.11383v1)|null|
|**2024-07-15**|**Leveraging Multimodal CycleGAN for the Generation of Anatomically Accurate Synthetic CT Scans from MRIs**|Leonardo Crespi et.al.|[2407.10888v1](http://arxiv.org/abs/2407.10888v1)|null|
|**2024-07-15**|**Towards Enhanced Classification of Abnormal Lung sound in Multi-breath: A Light Weight Multi-label and Multi-head Attention Classification Method**|Yi-Wei Chua et.al.|[2407.10828v1](http://arxiv.org/abs/2407.10828v1)|null|
|**2024-07-15**|**Classification of Heart Sounds Using Multi-Branch Deep Convolutional Network and LSTM-CNN**|Seyed Amir Latifi et.al.|[2407.10689v1](http://arxiv.org/abs/2407.10689v1)|null|
|**2024-07-15**|**Spatio-temporal neural distance fields for conditional generative modeling of the heart**|Kristine SÃ¸rensen et.al.|[2407.10663v1](http://arxiv.org/abs/2407.10663v1)|[link](https://github.com/kristineaajuhl/spatio_temporal_generative_cardiac_model)|
|**2024-07-15**|**TCM-FTP: Fine-Tuning Large Language Models for Herbal Prescription Prediction**|Xingzhi Zhou et.al.|[2407.10510v1](http://arxiv.org/abs/2407.10510v1)|null|
|**2024-07-15**|**A Multi-Stage Framework for 3D Individual Tooth Segmentation in Dental CBCT**|Chunshi Wang et.al.|[2407.10433v1](http://arxiv.org/abs/2407.10433v1)|null|
|**2024-07-15**|**Static and multivariate-temporal attentive fusion transformer for readmission risk prediction**|Zhe Sun et.al.|[2407.11096v1](http://arxiv.org/abs/2407.11096v1)|null|
|**2024-07-14**|**Evolved Developmental Artificial Neural Networks for Multitasking with Advanced Activity Dependence**|Yintong Zhang et.al.|[2407.10359v1](http://arxiv.org/abs/2407.10359v1)|null|
|**2024-07-14**|**Learning Unlabeled Clients Divergence via Anchor Model Aggregation for Federated Semi-supervised Learning**|Marawan Elbatel et.al.|[2407.10327v1](http://arxiv.org/abs/2407.10327v1)|null|
|**2024-07-14**|**Rapid Biomedical Research Classification: The Pandemic PACT Advanced Categorisation Engine**|Omid Rohanian et.al.|[2407.10086v1](http://arxiv.org/abs/2407.10086v1)|null|
|**2024-07-13**|**Document-level Clinical Entity and Relation Extraction via Knowledge Base-Guided Generation**|Kriti Bhattarai et.al.|[2407.10021v1](http://arxiv.org/abs/2407.10021v1)|null|
|**2024-07-13**|**Causality extraction from medical text using Large Language Models (LLMs)**|Seethalakshmi Gopalakrishnan et.al.|[2407.10020v1](http://arxiv.org/abs/2407.10020v1)|null|
|**2024-07-13**|**Pay Less On Clinical Images: Asymmetric Multi-Modal Fusion Method For Efficient Multi-Label Skin Lesion Classification**|Peng Tang et.al.|[2407.09999v1](http://arxiv.org/abs/2407.09999v1)|null|
|**2024-07-13**|**Evaluating the Impact of Different Quantum Kernels on the Classification Performance of Support Vector Machine Algorithm: A Medical Dataset Application**|Emine Akpinar et.al.|[2407.09930v1](http://arxiv.org/abs/2407.09930v1)|null|
|**2024-07-13**|**Enhancing Semantic Segmentation with Adaptive Focal Loss: A Novel Approach**|Md Rakibul Islam et.al.|[2407.09828v1](http://arxiv.org/abs/2407.09828v1)|null|
|**2024-07-12**|**Towards Personalised Patient Risk Prediction Using Temporal Hospital Data Trajectories**|Thea Barnes et.al.|[2407.09373v1](http://arxiv.org/abs/2407.09373v1)|null|
|**2024-07-12**|**Enhancing Depressive Post Detection in Bangla: A Comparative Study of TF-IDF, BERT and FastText Embeddings**|Saad Ahmed Sazan et.al.|[2407.09187v1](http://arxiv.org/abs/2407.09187v1)|null|
|**2024-07-12**|**STD-LLM: Understanding Both Spatial and Temporal Properties of Spatial-Temporal Data with LLMs**|Yiheng Huang et.al.|[2407.09096v1](http://arxiv.org/abs/2407.09096v1)|null|
|**2024-07-12**|**FD-SOS: Vision-Language Open-Set Detectors for Bone Fenestration and Dehiscence Detection from Intraoral Images**|Marawan Elbatel et.al.|[2407.09088v1](http://arxiv.org/abs/2407.09088v1)|null|
|**2024-07-12**|**Heterogeneous Subgraph Network with Prompt Learning for Interpretable Depression Detection on Social Media**|Chen Chen et.al.|[2407.09019v1](http://arxiv.org/abs/2407.09019v1)|null|
|**2024-07-12**|**Application of Artificial Intelligence in Supporting Healthcare Professionals and Caregivers in Treatment of Autistic Children**|Hossein Mohammadi Rouzbahani et.al.|[2407.08902v1](http://arxiv.org/abs/2407.08902v1)|null|
|**2024-07-11**|**SALT: Introducing a Framework for Hierarchical Segmentations in Medical Imaging using Softmax for Arbitrary Label Trees**|Sven Koitka et.al.|[2407.08878v1](http://arxiv.org/abs/2407.08878v1)|null|
|**2024-07-11**|**FedMedICL: Towards Holistic Evaluation of Distribution Shifts in Federated Medical Imaging**|Kumail Alhamoud et.al.|[2407.08822v1](http://arxiv.org/abs/2407.08822v1)|[link](https://github.com/m1k2zoo/fedmedicl)|
|**2024-07-11**|**FairDomain: Achieving Fairness in Cross-Domain Medical Image Segmentation and Classification**|Yu Tian et.al.|[2407.08813v1](http://arxiv.org/abs/2407.08813v1)|[link](https://github.com/harvard-ophthalmology-ai-lab/fairdomain)|
|**2024-07-11**|**Uncertainty Estimation of Large Language Models in Medical Question Answering**|Jiaxin Wu et.al.|[2407.08662v1](http://arxiv.org/abs/2407.08662v1)|null|
|**2024-07-11**|**Establishing Rigorous and Cost-effective Clinical Trials for Artificial Intelligence Models**|Wanling Gao et.al.|[2407.08554v1](http://arxiv.org/abs/2407.08554v1)|[link](https://github.com/benchcouncil/vc-medai)|
|**2024-07-11**|**How Deep is your Guess? A Fresh Perspective on Deep Learning for Medical Time-Series Imputation**|Linglong Qian et.al.|[2407.08442v1](http://arxiv.org/abs/2407.08442v1)|null|
|**2024-07-11**|**Specialist vision-language models for clinical ophthalmology**|Robbie Holland et.al.|[2407.08410v1](http://arxiv.org/abs/2407.08410v1)|[link](https://github.com/robbieholland/specialistvlms)|
|**2024-07-11**|**Unveiling Disparities in Maternity Care: A Topic Modelling Approach to Analysing Maternity Incident Investigation Reports**|Georgina Cosma et.al.|[2407.08328v1](http://arxiv.org/abs/2407.08328v1)|null|
|**2024-07-11**|**Predicting Heart Failure with Attention Learning Techniques Utilizing Cardiovascular Data**|Ershadul Haque et.al.|[2407.08289v1](http://arxiv.org/abs/2407.08289v1)|null|
|**2024-07-11**|**Leveraging LLMs to Predict Affective States via Smartphone Sensor Features**|Tianyi Zhang et.al.|[2407.08240v1](http://arxiv.org/abs/2407.08240v1)|null|
|**2024-07-11**|**DALL-M: Context-Aware Clinical Data Augmentation with LLMs**|Chihcheng Hsieh et.al.|[2407.08227v1](http://arxiv.org/abs/2407.08227v1)|[link](https://github.com/chihchenghsieh/dall-m)|
|**2024-07-11**|**Synthetic Electroretinogram Signal Generation Using Conditional Generative Adversarial Network for Enhancing Classification of Autism Spectrum Disorder**|Mikhail Kulyabin et.al.|[2407.08166v1](http://arxiv.org/abs/2407.08166v1)|null|
|**2024-07-11**|**Highway Networks for Improved Surface Reconstruction: The Role of Residuals and Weight Updates**|A. Noorizadegan et.al.|[2407.08134v1](http://arxiv.org/abs/2407.08134v1)|[link](https://github.com/cmmai/resnet_for_pinn)|
|**2024-07-10**|**Machine Learning for ALSFRS-R Score Prediction: Making Sense of the Sensor Data**|Ritesh Mehta et.al.|[2407.08003v1](http://arxiv.org/abs/2407.08003v1)|null|
|**2024-07-10**|**The Human Factor in AI Red Teaming: Perspectives from Social and Collaborative Computing**|Alice Qian Zhang et.al.|[2407.07786v1](http://arxiv.org/abs/2407.07786v1)|null|
|**2024-07-10**|**A Proposed S.C.O.R.E. Evaluation Framework for Large Language Models : Safety, Consensus, Objectivity, Reproducibility and Explainability**|Ting Fang Tan et.al.|[2407.07666v1](http://arxiv.org/abs/2407.07666v1)|null|
|**2024-07-10**|**Boosting Medical Image Synthesis via Registration-guided Consistency and Disentanglement Learning**|Chuanpu Li et.al.|[2407.07660v1](http://arxiv.org/abs/2407.07660v1)|null|
|**2024-07-10**|**H-FCBFormer Hierarchical Fully Convolutional Branch Transformer for Occlusal Contact Segmentation with Articulating Paper**|Ryan Banks et.al.|[2407.07604v1](http://arxiv.org/abs/2407.07604v1)|[link](https://github.com/banksylel/h-fcbformer)|
|**2024-07-10**|**FLAIR: Feeding via Long-horizon AcquIsition of Realistic dishes**|Rajat Kumar Jenamani et.al.|[2407.07561v1](http://arxiv.org/abs/2407.07561v1)|null|
|**2024-07-10**|**Arabic Automatic Story Generation with Large Language Models**|Ahmed Oumar El-Shangiti et.al.|[2407.07551v1](http://arxiv.org/abs/2407.07551v1)|[link](https://github.com/ubc-nlp/arastories)|
|**2024-07-10**|**Weakly-supervised Medical Image Segmentation with Gaze Annotations**|Yuan Zhong et.al.|[2407.07406v1](http://arxiv.org/abs/2407.07406v1)|[link](https://github.com/med-air/gazemedseg)|
|**2024-07-10**|**Interpretable Differential Diagnosis with Dual-Inference Large Language Models**|Shuang Zhou et.al.|[2407.07330v1](http://arxiv.org/abs/2407.07330v1)|null|
|**2024-07-10**|**Large Language Model-Augmented Auto-Delineation of Treatment Target Volume in Radiation Therapy**|Praveenbalaji Rajendran et.al.|[2407.07296v1](http://arxiv.org/abs/2407.07296v1)|null|
|**2024-07-10**|**Causal Discovery in Semi-Stationary Time Series**|Shanyun Gao et.al.|[2407.07291v1](http://arxiv.org/abs/2407.07291v1)|[link](https://github.com/causalml-lab/pcmci-omega)|
|**2024-07-10**|**Causal Discovery-Driven Change Point Detection in Time Series**|Shanyun Gao et.al.|[2407.07290v1](http://arxiv.org/abs/2407.07290v1)|null|
|**2024-07-09**|**Lifestyle-Informed Personalized Blood Biomarker Prediction via Novel Representation Learning**|A. Ali Heydari et.al.|[2407.07277v1](http://arxiv.org/abs/2407.07277v1)|null|
|**2024-07-09**|**ProtoSAM -- One Shot Medical Image Segmentation With Foundational Models**|Lev Ayzenberg et.al.|[2407.07042v1](http://arxiv.org/abs/2407.07042v1)|[link](https://github.com/levayz/protosam)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-09**|**Microsoft Cloud-based Digitization Workflow with Rich Metadata Acquisition for Cultural Heritage Objects**|Krzysztof Kutt et.al.|[2407.06972v1](http://arxiv.org/abs/2407.06972v1)|null|
|**2024-07-09**|**TE-SSL: Time and Event-aware Self Supervised Learning for Alzheimer's Disease Progression Analysis**|Jacob Thrasher et.al.|[2407.06852v1](http://arxiv.org/abs/2407.06852v1)|[link](https://github.com/jacob-thrasher/te-ssl)|
|**2024-07-09**|**VRDSynth: Synthesizing Programs for Multilingual Visually Rich Document Information Extraction**|Thanh-Dat Nguyen et.al.|[2407.06826v1](http://arxiv.org/abs/2407.06826v1)|null|
|**2024-07-09**|**iASiS: Towards Heterogeneous Big Data Analysis for Personalized Medicine**|Anastasia Krithara et.al.|[2407.06748v1](http://arxiv.org/abs/2407.06748v1)|null|
|**2024-07-09**|**Generative AI for Health Technology Assessment: Opportunities, Challenges, and Policy Considerations**|Rachael Fleurence et.al.|[2407.11054v1](http://arxiv.org/abs/2407.11054v1)|null|
|**2024-07-09**|**TCKIN: A Novel Integrated Network Model for Predicting Mortality Risk in Sepsis Patients**|Fanglin Dong et.al.|[2407.06560v1](http://arxiv.org/abs/2407.06560v1)|null|
|**2024-07-08**|**AI-driven multi-omics integration for multi-scale predictive modeling of causal genotype-environment-phenotype relationships**|You Wu et.al.|[2407.06405v1](http://arxiv.org/abs/2407.06405v1)|null|
|**2024-07-08**|**Multimodal Chain-of-Thought Reasoning via ChatGPT to Protect Children from Age-Inappropriate Apps**|Chuanbo Hu et.al.|[2407.06309v1](http://arxiv.org/abs/2407.06309v1)|null|
|**2024-07-08**|**Hybrid X-Linker: Automated Data Generation and Extreme Multi-label Ranking for Biomedical Entity Linking**|Pedro Ruas et.al.|[2407.06292v1](http://arxiv.org/abs/2407.06292v1)|null|
|**2024-07-08**|**Depression Detection and Analysis using Large Language Models on Textual and Audio-Visual Modalities**|Avinash Anand et.al.|[2407.06125v1](http://arxiv.org/abs/2407.06125v1)|null|
|**2024-07-08**|**Igea: a Decoder-Only Language Model for Biomedical Text Generation in Italian**|Tommaso Mario Buonocore et.al.|[2407.06011v1](http://arxiv.org/abs/2407.06011v1)|null|
|**2024-07-08**|**Generation and De-Identification of Indian Clinical Discharge Summaries using LLMs**|Sanjeet Singh et.al.|[2407.05887v1](http://arxiv.org/abs/2407.05887v1)|null|
|**2024-07-08**|**Integrating AI in College Education: Positive yet Mixed Experiences with ChatGPT**|Xinrui Song et.al.|[2407.05810v1](http://arxiv.org/abs/2407.05810v1)|null|
|**2024-07-08**|**FedMRL: Data Heterogeneity Aware Federated Multi-agent Deep Reinforcement Learning for Medical Imaging**|Pranab Sahoo et.al.|[2407.05800v1](http://arxiv.org/abs/2407.05800v1)|[link](https://github.com/pranabiitp/fedmrl)|
|**2024-07-08**|**Large Language Models for Judicial Entity Extraction: A Comparative Study**|Atin Sakkeer Hussain et.al.|[2407.05786v1](http://arxiv.org/abs/2407.05786v1)|null|
|**2024-07-08**|**Potential of Multimodal Large Language Models for Data Mining of Medical Images and Free-text Reports**|Yutong Zhang et.al.|[2407.05758v1](http://arxiv.org/abs/2407.05758v1)|null|
|**2024-07-08**|**RadiomicsFill-Mammo: Synthetic Mammogram Mass Manipulation with Radiomics Features**|Inye Na et.al.|[2407.05683v1](http://arxiv.org/abs/2407.05683v1)|[link](https://github.com/nainye/radiomicsfill)|
|**2024-07-08**|**WSI-VQA: Interpreting Whole Slide Images by Generative Visual Question Answering**|Pingyi Chen et.al.|[2407.05603v1](http://arxiv.org/abs/2407.05603v1)|[link](https://github.com/cpystan/wsi-vqa)|
|**2024-07-07**|**Accelerating MRI Uncertainty Estimation with Mask-based Bayesian Neural Network**|Zehuan Zhang et.al.|[2407.05521v1](http://arxiv.org/abs/2407.05521v1)|null|
|**2024-07-07**|**A Survey of Models for Cognitive Diagnosis: New Developments and Future Directions**|Fei Wang et.al.|[2407.05458v1](http://arxiv.org/abs/2407.05458v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v1](http://arxiv.org/abs/2407.05440v1)|null|
|**2024-07-07**|**FM-OSD: Foundation Model-Enabled One-Shot Detection of Anatomical Landmarks**|Juzheng Miao et.al.|[2407.05412v1](http://arxiv.org/abs/2407.05412v1)|[link](https://github.com/juzhengmiao/fm-osd)|
|**2024-07-06**|**BadCLM: Backdoor Attack in Clinical Language Models for Electronic Health Records**|Weimin Lyu et.al.|[2407.05213v1](http://arxiv.org/abs/2407.05213v1)|null|
|**2024-07-06**|**RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models**|Peng Xia et.al.|[2407.05131v1](http://arxiv.org/abs/2407.05131v1)|[link](https://github.com/richard-peng-xia/rule)|
|**2024-07-06**|**Linear Attention Based Deep Nonlocal Means Filtering for Multiplicative Noise Removal**|Xiao Siyao et.al.|[2407.05087v1](http://arxiv.org/abs/2407.05087v1)|null|
|**2024-07-05**|**Brain Age Estimation with a Greedy Dual-Stream Model for Limited Datasets**|Iman Kianian et.al.|[2407.04808v1](http://arxiv.org/abs/2407.04808v1)|[link](https://github.com/iman2693/gdsm)|
|**2024-07-05**|**Entity Decomposition with Filtering: A Zero-Shot Clinical Named Entity Recognition Framework**|Reza Averly et.al.|[2407.04629v1](http://arxiv.org/abs/2407.04629v1)|null|
|**2024-07-05**|**Variational and Explanatory Neural Networks for Encoding Cancer Profiles and Predicting Drug Responses**|Tianshu Feng et.al.|[2407.04486v1](http://arxiv.org/abs/2407.04486v1)|null|
|**2024-07-05**|**Multi-modal Masked Siamese Network Improves Chest X-Ray Representation Learning**|Saeed Shurrab et.al.|[2407.04449v1](http://arxiv.org/abs/2407.04449v1)|[link](https://github.com/nyuad-cai/cxr-ehr-msn)|
|**2024-07-04**|**Query-Guided Self-Supervised Summarization of Nursing Notes**|Ya Gao et.al.|[2407.04125v1](http://arxiv.org/abs/2407.04125v1)|null|
|**2024-07-04**|**MiniGPT-Med: Large Language Model as a General Interface for Radiology Diagnosis**|Asma Alkhaldi et.al.|[2407.04106v1](http://arxiv.org/abs/2407.04106v1)|[link](https://github.com/vision-cair/minigpt-med)|
|**2024-07-04**|**Mechanisms for Data Sharing in Collaborative Causal Inference (Extended Version)**|BjÃ¶rn Filter et.al.|[2407.11032v1](http://arxiv.org/abs/2407.11032v1)|null|
|**2024-07-04**|**Unsupervised Analysis of Alzheimer's Disease Signatures using 3D Deformable Autoencoders**|Mehmet Yigit Avci et.al.|[2407.03863v1](http://arxiv.org/abs/2407.03863v1)|[link](https://github.com/ci-ber/morphade)|
|**2024-07-04**|**CaseGPT: a case reasoning framework based on language models and retrieval-augmented generation**|Rui Yang et.al.|[2407.07913v1](http://arxiv.org/abs/2407.07913v1)|null|
|**2024-07-04**|**Integrating Randomness in Large Language Models: A Linear Congruential Generator Approach for Generating Clinically Relevant Content**|Andrew Bouras et.al.|[2407.03582v1](http://arxiv.org/abs/2407.03582v1)|[link](https://github.com/andrewbouras/randomnesspaper)|
|**2024-07-03**|**Accelerated Proton Resonance Frequency-based Magnetic Resonance Thermometry by Optimized Deep Learning Method**|Sijie Xu et.al.|[2407.03308v1](http://arxiv.org/abs/2407.03308v1)|[link](https://github.com/minipuding/fastmrt)|
|**2024-07-03**|**MVGT: A Multi-view Graph Transformer Based on Spatial Relations for EEG Emotion Recognition**|Yanjie Cui et.al.|[2407.03131v2](http://arxiv.org/abs/2407.03131v2)|null|
|**2024-07-03**|**Effective Heterogeneous Federated Learning via Efficient Hypernetwork-based Weight Generation**|Yujin Shin et.al.|[2407.03086v1](http://arxiv.org/abs/2407.03086v1)|null|
|**2024-07-03**|**Attention Incorporated Network for Sharing Low-rank, Image and K-space Information during MR Image Reconstruction to Achieve Single Breath-hold Cardiac Cine Imaging**|Siying Xu et.al.|[2407.03034v1](http://arxiv.org/abs/2407.03034v1)|[link](https://github.com/midas-tum/a-liknet)|

#### Abstracts
##### **Schema Matching with Large Language Models: an Experimental Study**
2407.11852v1 by Marcel Parciak, Brecht Vandevoort, Frank Neven, Liesbet M. Peeters, Stijn Vansummeren

Large Language Models (LLMs) have shown useful applications in a variety of
tasks, including data wrangling. In this paper, we investigate the use of an
off-the-shelf LLM for schema matching. Our objective is to identify semantic
correspondences between elements of two relational schemas using only names and
descriptions. Using a newly created benchmark from the health domain, we
propose different so-called task scopes. These are methods for prompting the
LLM to do schema matching, which vary in the amount of context information
contained in the prompt. Using these task scopes we compare LLM-based schema
matching against a string similarity baseline, investigating matching quality,
verification effort, decisiveness, and complementarity of the approaches. We
find that matching quality suffers from a lack of context information, but also
from providing too much context information. In general, using newer LLM
versions increases decisiveness. We identify task scopes that have acceptable
verification effort and succeed in identifying a significant number of true
semantic matches. Our study shows that LLMs have potential in bootstrapping the
schema matching process and are able to assist data engineers in speeding up
this task solely based on schema element names and descriptions without the
need for data instances.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨åç¨®ä»»åä¸­å±ç¾åºæç¨çæç¨ï¼åæ¬è³ææ´çãå¨æ¬æä¸­ï¼æåæ¢è¨ç¾æ LLM å¨æ¶æ§æ¯å°ä¸­çç¨éãæåçç®æ¨æ¯åä½¿ç¨åç¨±åæè¿°ï¼æ¾åºå©åéè¯å¼æ¶æ§çåç´ ä¹éçèªæå°æãä½¿ç¨å¾å¥åº·é åæ°å»ºç«çåºæºï¼æåæåºä¸åçæè¬ä»»åç¯åãéäºæ¹æ³æ¯ç¨æ¼æç¤º LLM é²è¡æ¶æ§æ¯å°ï¼å¶åå«å¨æç¤ºä¸­çèçµ¡è³è¨éææä¸åãä½¿ç¨éäºä»»åç¯åï¼æåå°åºæ¼ LLM çæ¶æ§æ¯å°èå­ä¸²ç¸ä¼¼æ§åºæºé²è¡æ¯è¼ï¼æ¢è¨æ¯å°åè³ªãé©è­å·¥ä½ãææ·æ§ï¼ä»¥åæ¹æ³çäºè£æ§ãæåç¼ç¾æ¯å°åè³ªæåå°èçµ¡è³è¨ä¸è¶³ä»¥åæä¾éå¤èçµ¡è³è¨çå½±é¿ãä¸è¬ä¾èªªï¼ä½¿ç¨è¼æ°ç LLM çæ¬æå¢å ææ·æ§ãæåæ¾åºå·æå¯æ¥åé©è­å·¥ä½ï¼ä¸¦æåæ¾åºå¤§éçå¯¦èªææ¯å°çä»»åç¯åãæåçç ç©¶é¡¯ç¤ºï¼LLM æå©æ¼å¼å°æ¶æ§æ¯å°æµç¨ï¼ä¸¦ä¸è½å¤ åå©è³æå·¥ç¨å¸«åæ ¹ææ¶æ§åç´ åç¨±åæè¿°å éæ­¤ä»»åï¼èä¸éè¦è³æå¯¦ä¾ã

##### **GPT Assisted Annotation of Rhetorical and Linguistic Features for Interpretable Propaganda Technique Detection in News Text**
2407.11827v1 by Kyle Hamilton, Luca Longo, Bojan Bozic

While the use of machine learning for the detection of propaganda techniques
in text has garnered considerable attention, most approaches focus on
"black-box" solutions with opaque inner workings. Interpretable approaches
provide a solution, however, they depend on careful feature engineering and
costly expert annotated data. Additionally, language features specific to
propagandistic text are generally the focus of rhetoricians or linguists, and
there is no data set labeled with such features suitable for machine learning.
This study codifies 22 rhetorical and linguistic features identified in
literature related to the language of persuasion for the purpose of annotating
an existing data set labeled with propaganda techniques. To help human experts
annotate natural language sentences with these features, RhetAnn, a web
application, was specifically designed to minimize an otherwise considerable
mental effort. Finally, a small set of annotated data was used to fine-tune
GPT-3.5, a generative large language model (LLM), to annotate the remaining
data while optimizing for financial cost and classification accuracy. This
study demonstrates how combining a small number of human annotated examples
with GPT can be an effective strategy for scaling the annotation process at a
fraction of the cost of traditional annotation relying solely on human experts.
The results are on par with the best performing model at the time of writing,
namely GPT-4, at 10x less the cost. Our contribution is a set of features,
their properties, definitions, and examples in a machine-readable format, along
with the code for RhetAnn and the GPT prompts and fine-tuning procedures for
advancing state-of-the-art interpretable propaganda technique detection.

æè¦ï¼<paragraph>åç®¡ä½¿ç¨æ©å¨å­¸ç¿ä¾åµæ¸¬å®£å³æå·§å¨ææ¬ä¸­å·²ç²å¾ç¸ç¶çéæ³¨ï¼ä½å¤§å¤æ¸æ¹æ³é½å°æ³¨æ¼å·æä¸éæå§é¨éä½çãé»çå­ãè§£æ±ºæ¹æ¡ãå¯è§£éçæ¹æ³æä¾äºè§£æ±ºæ¹æ¡ï¼ç¶èï¼å®åä¾è³´æ¼ä»ç´°çç¹å¾µå·¥ç¨åæè²´çå°å®¶è¨»éè³æãæ­¤å¤ï¼å®£å³æ§ææ¬çç¹å®èªè¨ç¹å¾µéå¸¸æ¯ä¿®è¾­å­¸å®¶æèªè¨å­¸å®¶çéæ³¨ç¦é»ï¼ä¸¦ä¸æ²ææ¨è¨ææ­¤é¡ç¹å¾µçè³æéé©åæ©å¨å­¸ç¿ãæ¬ç ç©¶å°åºç¾å¨èèªªæèªè¨ç¸éçæç»ä¸­è­å¥åºç 22 åä¿®è¾­åèªè¨ç¹å¾µç·¨çºææ³å¸ï¼ç®çæ¯çºæ¨è¨æå®£å³æå·§çç¾æè³æéãçºäºå¹«å©äººé¡å°å®¶ä½¿ç¨éäºç¹å¾µè¨»éèªç¶èªè¨å¥å­ï¼å°éè¨­è¨äºç¶²è·¯æç¨ç¨å¼ RhetAnnï¼ä»¥æå¤§ç¨åº¦å°æ¸å°åæ¬ç¸ç¶å¤§çå¿æºè² æãæå¾ï¼ä½¿ç¨ä¸å°çµè¨»éè³æå¾®èª¿äºçæå¼å¤§åèªè¨æ¨¡å (LLM) GPT-3.5ï¼ä»¥è¨»éå©é¤è³æï¼åæéå°è²¡åææ¬ååé¡æºç¢ºåº¦é²è¡æä½³åãæ¬ç ç©¶å±ç¤ºäºå°å°æ¸äººé¡è¨»éç¯ä¾è GPT çµåå¦ä½æçºä»¥å³çµ±åä¾è³´äººé¡å°å®¶çè¨»éææ¬çä¸å°é¨åä¾æ´å±è¨»éç¨åºçææç­ç¥ãå¨æ°å¯«æ¬ææï¼çµæèç¶æè¡¨ç¾æä½³çæ¨¡å GPT-4 ç¸ç¶ï¼ææ¬å»ä½äº 10 åãæåçè²¢ç»æ¯ä¸çµç¹å¾µãå®åçå±¬æ§ãå®ç¾©åç¯ä¾ï¼æ¡ç¨æ©å¨å¯è®æ ¼å¼ï¼ä»¥å RhetAnn çç¨å¼ç¢¼å GPT æç¤ºåå¾®èª¿ç¨åºï¼ç¨æ¼æ¨é²æåé²çå¯è§£éå®£å³æå·§åµæ¸¬ã</paragraph>

##### **Characterizing and Understanding HGNN Training on GPUs**
2407.11790v1 by Dengke Han, Mingyu Yan, Xiaochun Ye, Dongrui Fan, Ninghui Sun

Owing to their remarkable representation capabilities for heterogeneous graph
data, Heterogeneous Graph Neural Networks (HGNNs) have been widely adopted in
many critical real-world domains such as recommendation systems and medical
analysis. Prior to their practical application, identifying the optimal HGNN
model parameters tailored to specific tasks through extensive training is a
time-consuming and costly process. To enhance the efficiency of HGNN training,
it is essential to characterize and analyze the execution semantics and
patterns within the training process to identify performance bottlenecks. In
this study, we conduct an in-depth quantification and analysis of two
mainstream HGNN training scenarios, including single-GPU and multi-GPU
distributed training. Based on the characterization results, we disclose the
performance bottlenecks and their underlying causes in different HGNN training
scenarios and provide optimization guidelines from both software and hardware
perspectives.

æè¦ï¼ç±æ¼ç°è³ªåç¥ç¶ç¶²è·¯ (HGNN) å·æåè¶çç°è³ªåå½¢æ¸æè¡¨ç¤ºè½åï¼å æ­¤å·²å»£æ³æç¨æ¼è¨±å¤éè¦ççå¯¦ä¸çé åï¼ä¾å¦æ¨è¦ç³»çµ±åé«çåæãå¨å¯¦éæç¨ä¹åï¼ééå»£æ³çè¨ç·´ä¾è­å¥éå°ç¹å®ä»»åèª¿æ´çæä½³ HGNN æ¨¡ååæ¸æ¯ä¸åèæä¸æè²´çéç¨ãçºäºæé« HGNN è¨ç·´çæçï¼å¿é æè¿°ååæè¨ç·´éç¨ä¸­çå·è¡èªç¾©åæ¨¡å¼ï¼ä»¥è­å¥æè½ç¶é ¸ãå¨æ¬ç ç©¶ä¸­ï¼æåå°å©åä¸»æµç HGNN è¨ç·´å ´æ¯ï¼åæ¬å® GPU åå¤ GPU åæ£å¼è¨ç·´ï¼é²è¡æ·±å¥çéåååæãæ ¹ææè¿°çµæï¼æåæ­ç¤ºäºä¸å HGNN è¨ç·´å ´æ¯ä¸­çæè½ç¶é ¸åå¶æ ¹æ¬åå ï¼ä¸¦å¾è»é«åç¡¬é«çè§åº¦æä¾äºæä½³åæåã

##### **CCoE: A Compact LLM with Collaboration of Experts**
2407.11686v2 by Shaomang Huang, Jianfeng Pan, Hanzhong Zheng

In the domain of Large Language Model (LLM), LLMs demonstrate significant
capabilities in natural language understanding and generation. With the growing
needs of applying LLMs on various domains, it is a research question that how
to efficiently train and build a model that has expertise in different domains
but with a low training cost. We propose CCoE architecture, a framework of
easily coupling multiple strong domain experts together to fuse into a big LLM,
provides a collective way of utilizing the different domain expert LLMs.
Besides, training a large collaborative of multiple expert LLMs requires a high
requirements on training sources. CCoE bypasses this problem through isolating
other experts and train each expert separately. The design of CCoE assembles
multiple expert LLMs through the CoE (Collaboration of Experts) layer. Each CoE
layer could have one or more expert LLMs. Expert LLMs have different number of
layers and have been well-trained for different domain tasks. Each expert is
fine-tuned to be able to achieve the comparable results with SOTA domain LLMs.
We start from 5 experts in the domain of Code, Math, Law, text-to-SQL and
Medical. The results indicate that our CCoE framework can easily and
efficiently boost nearly 10%-20% performance on original base model in
different domains but using less resources on training, as well as inference.

æè¦ï¼å¨å¤§èªè¨æ¨¡å (LLM) é åä¸­ï¼LLM å¨èªç¶èªè¨çè§£åçææ¹é¢å±ç¾åºé¡¯èçè½åãé¨èå¨ååé åæç¨ LLM çéæ±æ¥çå¢å ï¼å¦ä½ææè¨ç·´åå»ºç«ä¸åå¨ä¸åé åä¸­å·åå°æ¥­ç¥è­ï¼ä½è¨ç·´ææ¬å»å¾ä½çæ¨¡åï¼æçºä¸åç ç©¶èª²é¡ãæåæåº CCoE æ¶æ§ï¼ä¸åå°å¤åå¼·å¤§çé åå°å®¶è¼é¬çµåå¨ä¸èµ·ä»¥èåæä¸åå¤§å LLM çæ¡æ¶ï¼æä¾ä¸ç¨®å±åå©ç¨ä¸åé åå°å®¶ LLM çæ¹å¼ãæ­¤å¤ï¼è¨ç·´å¤åå°å®¶ LLM çå¤§ååä½éè¦å°è¨ç·´ä¾æºæå¾é«çè¦æ±ãCCoE éééé¢å¶ä»å°å®¶ä¸¦åå¥è¨ç·´æ¯åå°å®¶ä¾ç¹ééååé¡ãCCoE çè¨­è¨éé CoEï¼å°å®¶åä½ï¼å±¤çµåå¤åå°å®¶ LLMãæ¯å CoE å±¤å¯ä»¥æä¸åæå¤åå°å®¶ LLMãå°å®¶ LLM å·æä¸åçå±¤æ¸ï¼ä¸¦ä¸å·²ç¶éå°ä¸åçé åä»»åé²è¡äºå¾å¥½çè¨ç·´ãæ¯åå°å®¶é½ç¶éå¾®èª¿ï¼è½å¤ éå°è SOTA é å LLM ç¸ç¶ççµæãæåå¾ç¨å¼ç¢¼ãæ¸å­¸ãæ³å¾ãæå­è½ SQL åé«å­¸é åç 5 ä½å°å®¶éå§ãçµæè¡¨æï¼æåç CCoE æ¡æ¶å¯ä»¥è¼é¬ãææå°æåä¸åé åä¸­åå§åºç¤æ¨¡åè¿ 10%-20% çæè½ï¼ä½è¨ç·´åæ¨çä½¿ç¨çè³æºæ´å°ã

##### **CCVA-FL: Cross-Client Variations Adaptive Federated Learning for Medical Imaging**
2407.11652v1 by Sunny Gupta, Amit Sethi

Federated Learning (FL) offers a privacy-preserving approach to train models
on decentralized data. Its potential in healthcare is significant, but
challenges arise due to cross-client variations in medical image data,
exacerbated by limited annotations. This paper introduces Cross-Client
Variations Adaptive Federated Learning (CCVA-FL) to address these issues.
CCVA-FL aims to minimize cross-client variations by transforming images into a
common feature space. It involves expert annotation of a subset of images from
each client, followed by the selection of a client with the least data
complexity as the target. Synthetic medical images are then generated using
Scalable Diffusion Models with Transformers (DiT) based on the target client's
annotated images. These synthetic images, capturing diversity and representing
the original data, are shared with other clients. Each client then translates
its local images into the target image space using image-to-image translation.
The translated images are subsequently used in a federated learning setting to
develop a server model. Our results demonstrate that CCVA-FL outperforms
Vanilla Federated Averaging by effectively addressing data distribution
differences across clients without compromising privacy.

æè¦ï¼èé¦å­¦ä¹  (FL) æä¾äºä¸ç§å¨åæ£å¼æ°æ®ä¸è®­ç»æ¨¡åçéç§ä¿æ¤æ¹æ³ãå®å¨å»çä¿å¥ä¸­çæ½åå¾å¤§ï¼ä½ç±äºå»çå¾åæ°æ®ä¸­å­å¨è·¨å®¢æ·ç«¯å·®å¼ï¼å æ­¤å¸¦æ¥äºææï¼èæéçæ³¨éå å§äºè¿ä¸é®é¢ãæ¬æä»ç»äºè·¨å®¢æ·ç«¯å·®å¼èªéåºèé¦å­¦ä¹  (CCVA-FL) æ¥è§£å³è¿äºé®é¢ãCCVA-FL æ¨å¨éè¿å°å¾åè½¬æ¢ä¸ºå¬å±ç¹å¾ç©ºé´æ¥æå°åè·¨å®¢æ·ç«¯å·®å¼ãå®æ¶åä»æ¯ä¸ªå®¢æ·ç«¯æ³¨éå¾åå­éçä¸å®¶æ³¨éï¼ç¶åéæ©æ°æ®å¤ææ§æä½çå®¢æ·ç«¯ä½ä¸ºç®æ ãç¶åä½¿ç¨åºäºç®æ å®¢æ·ç«¯æ³¨éå¾åçå¯æ©å±æ©æ£æ¨¡åä¸ Transformer (DiT) çæåæå»å­¦å¾åãè¿äºåæå¾åææäºå¤æ ·æ§å¹¶ä»£è¡¨äºåå§æ°æ®ï¼ä¸å¶ä»å®¢æ·ç«¯å±äº«ãç¶åï¼æ¯ä¸ªå®¢æ·ç«¯ä½¿ç¨å¾åå°å¾åç¿»è¯å°å¶æ¬å°å¾åè½¬æ¢ä¸ºç®æ å¾åç©ºé´ãç¿»è¯åçå¾åéåå¨èé¦å­¦ä¹ è®¾ç½®ä¸­ç¨äºå¼åæå¡å¨æ¨¡åãæä»¬çç»æè¡¨æï¼CCVA-FL éè¿ææè§£å³è·¨å®¢æ·ç«¯çæ°æ®åå¸å·®å¼å¨ä¸æå®³éç§çæåµä¸ä¼äºé¦èèé¦å¹³åã

##### **Improving Engagement and Efficacy of mHealth Micro-Interventions for Stress Coping: an In-The-Wild Study**
2407.11612v1 by Chaya Ben Yehuda, Ran Gilad-Bachrach, Yarin Udi

Sustaining long-term user engagement with mobile health (mHealth)
interventions while preserving their high efficacy remains an ongoing challenge
in real-world well-being applications. To address this issue, we introduce a
new algorithm, the Personalized, Context-Aware Recommender (PCAR), for
intervention selection and evaluate its performance in a field experiment. In a
four-week, in-the-wild experiment involving 29 parents of young children, we
delivered personalized stress-reducing micro-interventions through a mobile
chatbot. We assessed their impact on stress reduction using momentary stress
level ecological momentary assessments (EMAs) before and after each
intervention. Our findings demonstrate the superiority of PCAR intervention
selection in enhancing the engagement and efficacy of mHealth
micro-interventions to stress coping compared to random intervention selection
and a control group that did not receive any intervention. Furthermore, we show
that even brief, one-minute interventions can significantly reduce perceived
stress levels (p=0.001). We observe that individuals are most receptive to
one-minute interventions during transitional periods between activities, such
as transitioning from afternoon activities to bedtime routines. Our study
contributes to the literature by introducing a personalized context-aware
intervention selection algorithm that improves engagement and efficacy of
mHealth interventions, identifying key timing for stress interventions, and
offering insights into mechanisms to improve stress coping.

æè¦ï¼<paragraph>å¨ç¶­æè¡åå¥åº· (mHealth) å¹²é æªæ½çé·æä½¿ç¨èåèåº¦ï¼åæç¶­æå¶é«åæï¼å¨ç¾å¯¦ä¸ççå¥åº·æç¨ä¸­ä»æ¯ä¸åæçºçææ°ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äºä¸ç¨®æ°çæ¼ç®æ³ï¼ç¨±çºåäººåãæå¢æç¥æ¨è¦å¨ (PCAR)ï¼ç¨æ¼å¹²é é¸æï¼ä¸¦å¨å¯¦å°å¯¦é©ä¸­è©ä¼°å¶æè½ãå¨çºæåé±çéå¤å¯¦é©ä¸­ï¼æ¶å 29 ä½å¹¼åçç¶æ¯ï¼æåééè¡åèå¤©æ©å¨äººå³éåäººåçæ¸å£å¾®åå¹²é æªæ½ãæåééå¨æ¯æ¬¡å¹²é æªæ½åå¾é²è¡çç¬éå£åç­ç´çæç¬æè©ä¼° (EMA)ï¼è©ä¼°å®åå°æ¸å£çå½±é¿ãæåçç ç©¶çµæè­æäº PCAR å¹²é é¸æå¨å¢å¼· mHealth å¾®åå¹²é æªæ½å°å£åæå°çåèåº¦åæè½æ¹é¢çåªè¶æ§ï¼ç¸è¼æ¼é¨æ©å¹²é é¸æåæªæ¥åä»»ä½å¹²é æªæ½çå°ç§çµãæ­¤å¤ï¼æåè­æäºå³ä½¿ç°¡ç­çä¸åéå¹²é æªæ½ä¹è½é¡¯èéä½æç¥å£åç­ç´ (p=0.001)ãæåè§å¯å°ï¼åäººå¨æ´»åä¹éçéæ¸¡æï¼ä¾å¦å¾ä¸åæ´»åéæ¸¡å°å°±å¯¢æéï¼å°ä¸åéçå¹²é æªæ½æå·æ¥ååº¦ãæåçç ç©¶ééå¼å¥ä¸ç¨®åäººåæå¢æç¥å¹²é é¸ææ¼ç®æ³ï¼æ¹å mHealth å¹²é æªæ½çåèåº¦åæè½ï¼æ¾åºå£åå¹²é æªæ½çééµææ©ï¼ä¸¦æä¾æ¹åå£åæå°æ©å¶çè¦è§£ï¼çºæç»ååºè²¢ç»ã</paragraph>

##### **DiNO-Diffusion. Scaling Medical Diffusion via Self-Supervised Pre-Training**
2407.11594v1 by Guillermo Jimenez-Perez, Pedro Osorio, Josef Cersovsky, Javier Montalt-Tordera, Jens Hooge, Steffen Vogler, Sadegh Mohammadi

Diffusion models (DMs) have emerged as powerful foundation models for a
variety of tasks, with a large focus in synthetic image generation. However,
their requirement of large annotated datasets for training limits their
applicability in medical imaging, where datasets are typically smaller and
sparsely annotated. We introduce DiNO-Diffusion, a self-supervised method for
training latent diffusion models (LDMs) that conditions the generation process
on image embeddings extracted from DiNO. By eliminating the reliance on
annotations, our training leverages over 868k unlabelled images from public
chest X-Ray (CXR) datasets. Despite being self-supervised, DiNO-Diffusion shows
comprehensive manifold coverage, with FID scores as low as 4.7, and emerging
properties when evaluated in downstream tasks. It can be used to generate
semantically-diverse synthetic datasets even from small data pools,
demonstrating up to 20% AUC increase in classification performance when used
for data augmentation. Images were generated with different sampling strategies
over the DiNO embedding manifold and using real images as a starting point.
Results suggest, DiNO-Diffusion could facilitate the creation of large datasets
for flexible training of downstream AI models from limited amount of real data,
while also holding potential for privacy preservation. Additionally,
DiNO-Diffusion demonstrates zero-shot segmentation performance of up to 84.4%
Dice score when evaluating lung lobe segmentation. This evidences good CXR
image-anatomy alignment, akin to segmenting using textual descriptors on
vanilla DMs. Finally, DiNO-Diffusion can be easily adapted to other medical
imaging modalities or state-of-the-art diffusion models, opening the door for
large-scale, multi-domain image generation pipelines for medical imaging.

æè¦ï¼æ´æ£æ¨¡å (DM) å·²æçºåç¨®ä»»åä¸­å¼·å¤§çåºç¤æ¨¡åï¼ç¹å¥æ¯åæå½±åçæãç¶èï¼å®åå¨è¨ç·´ä¸­å°å¤§åæ¨è¨»è³æéçè¦æ±éå¶äºå®åå¨é«çå½±åä¸­çæç¨ï¼èé«çå½±åçè³æééå¸¸è¼å°ä¸æ¨è¨»ç¨çãæåå¼å¥äº DiNO-Diffusionï¼éæ¯ä¸ç¨®ç¨æ¼è¨ç·´æ¢ä»¶çæéç¨çæ½å¨æ´æ£æ¨¡å (LDM) çèªç£ç£æ¹æ³ï¼è©²éç¨åºæ¼å¾ DiNO ä¸­æåçå½±ååµå¥ãééæ¶é¤å°æ¨è¨»çä¾è³´ï¼æåçè¨ç·´å©ç¨äºä¾èªå¬å±è¸é¨ X å (CXR) è³æéçè¶é 868k å¼µæªæ¨è¨»å½±åãåç®¡æ¯èªç£ç£çï¼ä½ DiNO-Diffusion é¡¯ç¤ºåºå¨é¢çæµå½¢è¦èï¼FID åæ¸ä½è³ 4.7ï¼ä¸¦ä¸å¨è©ä¼°ä¸æ¸¸ä»»åæåºç¾äºæ°èçå±¬æ§ãå®å¯ç¨æ¼å¾å°åè³æåº«çæèªç¾©å¤æ¨£çåæè³æéï¼å¨ç¨æ¼è³ææ´åæï¼åé¡æè½æåå¹åº¦é«é 20% AUCãå½±åæ¯å¨ DiNO åµå¥æµå½¢ä¸ä½¿ç¨ä¸åçåæ¨£ç­ç¥çæçï¼ä¸¦ä½¿ç¨çå¯¦å½±åä½çºèµ·é»ãçµæé¡¯ç¤ºï¼DiNO-Diffusion å¯ä»¥ä¿é²å¾æéççå¯¦è³æä¸­éæ´»è¨ç·´ä¸æ¸¸ AI æ¨¡åçå¤§åè³æéçå»ºç«ï¼åæä¹å·æé±ç§ä¿è­·çæ½åãæ­¤å¤ï¼DiNO-Diffusion å¨è©ä¼°èºèåå²æå±ç¤ºäºé«é 84.4% ç Dice åæ¸çé¶æ¬¡å­¸ç¿åå²æè½ãéè­æäºè¯å¥½ç CXR å½±åè§£åå°é½ï¼é¡ä¼¼æ¼å¨é¦è DM ä¸ä½¿ç¨æå­æè¿°ç¬¦é²è¡åå²ãæå¾ï¼DiNO-Diffusion å¯ä»¥è¼é¬é©æå¶ä»é«çå½±åæ¹å¼ææåé²çæ´æ£æ¨¡åï¼çºé«çå½±åçå¤§è¦æ¨¡ãå¤é åå½±åçæç®¡ééåäºå¤§éã

##### **Probing the Efficacy of Federated Parameter-Efficient Fine-Tuning of Vision Transformers for Medical Image Classification**
2407.11573v1 by Naif Alkhunaizi, Faris Almalik, Rouqaiah Al-Refai, Muzammal Naseer, Karthik Nandakumar

With the advent of large pre-trained transformer models, fine-tuning these
models for various downstream tasks is a critical problem. Paucity of training
data, the existence of data silos, and stringent privacy constraints exacerbate
this fine-tuning problem in the medical imaging domain, creating a strong need
for algorithms that enable collaborative fine-tuning of pre-trained models.
Moreover, the large size of these models necessitates the use of
parameter-efficient fine-tuning (PEFT) to reduce the communication burden in
federated learning. In this work, we systematically investigate various
federated PEFT strategies for adapting a Vision Transformer (ViT) model
(pre-trained on a large natural image dataset) for medical image
classification. Apart from evaluating known PEFT techniques, we introduce new
federated variants of PEFT algorithms such as visual prompt tuning (VPT),
low-rank decomposition of visual prompts, stochastic block attention
fine-tuning, and hybrid PEFT methods like low-rank adaptation (LoRA)+VPT.
Moreover, we perform a thorough empirical analysis to identify the optimal PEFT
method for the federated setting and understand the impact of data distribution
on federated PEFT, especially for out-of-domain (OOD) and non-IID data. The key
insight of this study is that while most federated PEFT methods work well for
in-domain transfer, there is a substantial accuracy vs. efficiency trade-off
when dealing with OOD and non-IID scenarios, which is commonly the case in
medical imaging. Specifically, every order of magnitude reduction in
fine-tuned/exchanged parameters can lead to a 4% drop in accuracy. Thus, the
initial model choice is crucial for federated PEFT. It is preferable to use
medical foundation models learned from in-domain medical image data (if
available) rather than general vision models.

æè¦ï¼<paragraph>é¨èå¤§åé è¨ç·´è½æå¨æ¨¡åçåºç¾ï¼éå°åç¨®ä¸æ¸¸ä»»åå¾®èª¿éäºæ¨¡åæ¯ä¸åééµåé¡ãè¨ç·´è³æçç¨ç¼ºæ§ãè³æå­¤å³¶çå­å¨ä»¥åå´æ ¼çé±ç§éå¶æå åé«çå½±åé åä¸­çå¾®èª¿åé¡ï¼éå°è½è®é è¨ç·´æ¨¡åé²è¡åä½å¾®èª¿çæ¼ç®æ³ç¢çäºå¼·çéæ±ãæ­¤å¤ï¼éäºæ¨¡åçé¾å¤§è¦æ¨¡éè¦ä½¿ç¨åæ¸ææå¾®èª¿ (PEFT) ä¾éä½è¯åå­¸ç¿ä¸­çéè¨è² æãå¨éé å·¥ä½ä¸­ï¼æåç³»çµ±æ§å°æ¢è¨äºåç¨®è¯å PEFT ç­ç¥ï¼ä»¥èª¿æ´è¦è¦ºè½æå¨ (ViT) æ¨¡åï¼å¨å¤§åèªç¶å½±åè³æéä¸é åè¨ç·´ï¼ä»¥é²è¡é«çå½±ååé¡ãé¤äºè©ä¼°å·²ç¥ç PEFT æè¡å¤ï¼æåéå¼å¥äº PEFT æ¼ç®æ³çæ°è¯åè®é«ï¼ä¾å¦è¦è¦ºæç¤ºèª¿æ´ (VPT)ãè¦è¦ºæç¤ºçä½ç§©åè§£ãé¨æ©åå¡æ³¨æåå¾®èª¿ï¼ä»¥åä½ç§©é©æ (LoRA)+VPT ç­æ··å PEFT æ¹æ³ãæ­¤å¤ï¼æåé²è¡äºå¾¹åºçç¶é©åæï¼ä»¥æ¾åºè¯åè¨­å®çæä½³ PEFT æ¹æ³ï¼ä¸¦äºè§£è³æåä½å°è¯å PEFT çå½±é¿ï¼ç¹å¥æ¯å°æ¼é åå¤ (OOD) åéç¨ç«ååä½ (non-IID) è³æãéé ç ç©¶çä¸»è¦è¦è§£æ¯ï¼åç®¡å¤§å¤æ¸è¯å PEFT æ¹æ³é½é©ç¨æ¼é åå§è½ç§»ï¼ä½å¨èç OOD åéç¨ç«ååä½å ´æ¯æï¼ææå¤§å¹çæºç¢ºåº¦èæçæè¡·ï¼ééå¸¸æ¯é«çå½±åä¸­çææ³ãå·é«ä¾èªªï¼å¾®èª¿/äº¤æåæ¸çæ¯åæ¸éç´æ¸å°é½å¯è½å°è´æºç¢ºåº¦ä¸é 4%ãå æ­¤ï¼åå§æ¨¡åçé¸æå°æ¼è¯å PEFT è³ééè¦ãæå¥½ä½¿ç¨å¾é åå§é«å­¸å½±åè³æï¼å¦ææçè©±ï¼å­¸ç¿çé«å­¸åºç¤æ¨¡åï¼èä¸æ¯ä¸è¬è¦è¦ºæ¨¡åã</paragraph>

##### **Fine-Tuning Medical Language Models for Enhanced Long-Contextual Understanding and Domain Expertise**
2407.11536v1 by Qimin Yang, Rongsheng Wang, Jiexin Chen, Runqi Su, Tao Tan

Large Language Models (LLMs) have been widely applied in various professional
fields. By fine-tuning the models using domain specific question and answer
datasets, the professional domain knowledge and Q\&A abilities of these models
have significantly improved, for example, medical professional LLMs that use
fine-tuning of doctor-patient Q\&A data exhibit extraordinary disease
diagnostic abilities. However, we observed that despite improvements in
specific domain knowledge, the performance of medical LLM in long-context
understanding has significantly declined, especially compared to general
language models with similar parameters. The purpose of this study is to
investigate the phenomenon of reduced performance in understanding long-context
in medical LLM. We designed a series of experiments to conduct open-book
professional knowledge exams on all models to evaluate their ability to read
long-context. By adjusting the proportion and quantity of general data and
medical data in the process of fine-tuning, we can determine the best data
composition to optimize the professional model and achieve a balance between
long-context performance and specific domain knowledge.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å»£æ³æç¨æ¼åç¨®å°æ¥­é åãééä½¿ç¨ç¹å®é åçåç­è³æéå¾®èª¿æ¨¡åï¼éäºæ¨¡åçå°æ¥­é åç¥è­ååç­è½åå·²é¡¯èæåï¼ä¾å¦ï¼ä½¿ç¨é«ç-æ£èåç­è³æé²è¡å¾®èª¿çé«çå°æ¥­ LLM å±ç¾åºéå¡çç¾çè¨ºæ·è½åãç¶èï¼æåè§å¯å°ï¼åç®¡ç¹å®é åç¥è­æææåï¼ä½é«ç LLM å¨é·èªå¢çè§£æ¹é¢çè¡¨ç¾å»å¤§å¹ä¸éï¼å°¤å¶æ¯èå·æé¡ä¼¼åæ¸çä¸è¬èªè¨æ¨¡åç¸æ¯ãæ¬ç ç©¶çç®çæ¯æ¢è¨é«ç LLM å¨çè§£é·èªå¢æ¹é¢çè¡¨ç¾ä¸éç¾è±¡ãæåè¨­è¨äºä¸ç³»åå¯¦é©ï¼å°æææ¨¡åé²è¡éæ¾å¼å°æ¥­ç¥è­èè©¦ï¼ä»¥è©ä¼°å®åé±è®é·èªå¢ççè§£è½åãééèª¿æ´å¾®èª¿éç¨ä¸­ä¸è¬è³æåé«çè³æçæ¯ä¾åæ¸éï¼æåå¯ä»¥ç¢ºå®æä½³è³æçµåï¼ä»¥åªåå°æ¥­æ¨¡åï¼ä¸¦å¨é·èªå¢è¡¨ç¾åç¹å®é åç¥è­ä¹éåå¾å¹³è¡¡ã

##### **Cross-Phase Mutual Learning Framework for Pulmonary Embolism Identification on Non-Contrast CT Scans**
2407.11529v1 by Bizhe Bai, Yan-Jie Zhou, Yujian Hu, Tony C. W. Mok, Yilang Xiang, Le Lu, Hongkun Zhang, Minfeng Xu

Pulmonary embolism (PE) is a life-threatening condition where rapid and
accurate diagnosis is imperative yet difficult due to predominantly atypical
symptomatology. Computed tomography pulmonary angiography (CTPA) is
acknowledged as the gold standard imaging tool in clinics, yet it can be
contraindicated for emergency department (ED) patients and represents an
onerous procedure, thus necessitating PE identification through non-contrast CT
(NCT) scans. In this work, we explore the feasibility of applying a
deep-learning approach to NCT scans for PE identification. We propose a novel
Cross-Phase Mutual learNing framework (CPMN) that fosters knowledge transfer
from CTPA to NCT, while concurrently conducting embolism segmentation and
abnormality classification in a multi-task manner. The proposed CPMN leverages
the Inter-Feature Alignment (IFA) strategy that enhances spatial contiguity and
mutual learning between the dual-pathway network, while the Intra-Feature
Discrepancy (IFD) strategy can facilitate precise segmentation of PE against
complex backgrounds for single-pathway networks. For a comprehensive assessment
of the proposed approach, a large-scale dual-phase dataset containing 334 PE
patients and 1,105 normal subjects has been established. Experimental results
demonstrate that CPMN achieves the leading identification performance, which is
95.4\% and 99.6\% in patient-level sensitivity and specificity on NCT scans,
indicating the potential of our approach as an economical, accessible, and
precise tool for PE identification in clinical practice.

æè¦ï¼èºæ å¡ (PE) æ¯ä¸ç¨®å±åçå½çç¾çï¼å¿«éä¸æºç¢ºçè¨ºæ·è³ééè¦ï¼ä½ç±æ¼ççä¸»è¦æ¯éå¸åçï¼å æ­¤å¾é£è¨ºæ·ãé»è¦æ·å±¤èºè¡ç®¡æå½± (CTPA) è¢«å¬èªçºè¨ºæä¸­çé»éæ¨æºå½±åå·¥å·ï¼ä½å®å¯è½æå°æ¥è¨ºé¨é (ED) çæ£èç¦å¿ï¼ä¸¦ä¸ä»£è¡¨èç¹éçç¨åºï¼å æ­¤éè¦éééå°æ¯ CT (NCT) ææä¾è­å¥ PEãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨äºå°æ·±åº¦å­¸ç¿æ¹æ³æç¨æ¼ NCT ææä»¥è­å¥ PE çå¯è¡æ§ãæåæåºäºä¸åæ°ç©çè·¨ç¸ä½äºå­¸ç¿æ¡æ¶ (CPMN)ï¼å®ä¿é²äºå¾ CTPA å° NCT çç¥è­è½ç§»ï¼åæä»¥å¤ä»»åçæ¹å¼é²è¡æ å¡åå²åç°å¸¸åé¡ãææåºç CPMN æ¡ç¨äºç¹å¾µéå°é½ (IFA) ç­ç¥ï¼å®å¢å¼·äºéè·¯å¾ç¶²è·¯ä¹éçç©ºéé£çºæ§åç¸äºå­¸ç¿ï¼èç¹å¾µå§å·®ç° (IFD) ç­ç¥å¯ä»¥ä¿é²å®è·¯å¾ç¶²è·¯å°è¤éèæ¯ä¸­ç PE é²è¡ç²¾ç¢ºåå²ãçºäºå°ææåºçæ¹æ³é²è¡å¨é¢è©ä¼°ï¼å·²ç¶å»ºç«äºä¸ååå« 334 å PE æ£èå 1,105 åæ­£å¸¸åè©¦èçãå¤§è¦æ¨¡éç¸ä½æ¸æéãå¯¦é©çµæè¡¨æï¼CPMN éå°äºé åçè­å¥æè½ï¼å¨ NCT ææä¸­ï¼æ£èå±¤ç´çæææ§åç¹ç°æ§åå¥çº 95.4% å 99.6%ï¼éè¡¨ææåçåæ³æå¯è½æçºä¸ç¨®ç¶æ¿ãææ¼åå¾ä¸ç²¾ç¢ºç PE è­å¥å·¥å·ï¼å¯æç¨æ¼è¨åºå¯¦åã

##### **Multi-Channel Masked Autoencoder and Comprehensive Evaluations for Reconstructing 12-Lead ECG from Arbitrary Single-Lead ECG**
2407.11481v1 by Jiarong Chen, Wanqing Wu, Tong Liu, Shenda Hong

In the context of cardiovascular diseases (CVD) that exhibit an elevated
prevalence and mortality, the electrocardiogram (ECG) is a popular and standard
diagnostic tool for doctors, commonly utilizing a 12-lead configuration in
clinical practice. However, the 10 electrodes placed on the surface would cause
a lot of inconvenience and discomfort, while the rapidly advancing wearable
devices adopt the reduced-lead or single-lead ECG to reduce discomfort as a
solution in long-term monitoring. Since the single-lead ECG is a subset of
12-lead ECG, it provides insufficient cardiac health information and plays a
substandard role in real-world healthcare applications. Hence, it is necessary
to utilize signal generation technologies to reduce their clinical importance
gap by reconstructing 12-lead ECG from the real single-lead ECG. Specifically,
this study proposes a multi-channel masked autoencoder (MCMA) for this goal. In
the experimental results, the visualized results between the generated and real
signals can demonstrate the effectiveness of the proposed framework. At the
same time, this study introduces a comprehensive evaluation benchmark named
ECGGenEval, encompassing the signal-level, feature-level, and diagnostic-level
evaluations, providing a holistic assessment of 12-lead ECG signals and
generative model. Further, the quantitative experimental results are as
follows, the mean square errors of 0.0178 and 0.0658, correlation coefficients
of 0.7698 and 0.7237 in the signal-level evaluation, the average F1-score with
two generated 12-lead ECG is 0.8319 and 0.7824 in the diagnostic-level
evaluation, achieving the state-of-the-art performance. The open-source code is
publicly available at \url{https://github.com/CHENJIAR3/MCMA}.

æè¦ï¼<paragraph>å¨è¡¨ç¾åºé«çè¡çåæ­»äº¡ççå¿è¡ç®¡ç¾ç (CVD) çææ³ä¸ï¼å¿é»å (ECG) æ¯ä¸ç¨®é«çå¸¸ç¨çæ¨æºè¨ºæ·å·¥å·ï¼å¨è¨åºå¯¦åä¸­éå¸¸ä½¿ç¨ 12 å°ç¨çµæãç¶èï¼æ¾ç½®å¨è¡¨é¢ç 10 åé»æ¥µæé æè¨±å¤ä¸ä¾¿åä¸é©ï¼èå¿«éé²æ­¥çå¯ç©¿æ´å¼è£ç½®æ¡ç¨æ¸å°å°ç¨æå®å°ç¨ ECG ä¾éä½ä¸é©ï¼ä½çºé·æç£æ¸¬çè§£æ±ºæ¹æ¡ãç±æ¼å®å°ç¨ ECG æ¯ 12 å°ç¨ ECG çå­éï¼å®æä¾çå¥åº·è³è¨ä¸è¶³ï¼å¨çå¯¦ä¸ççé«çä¿å¥æç¨ä¸­æ®æ¼èæ¬¡æ¨æºçè§è²ãå æ­¤ï¼æå¿è¦å©ç¨è¨èç¢çæè¡ä¾ç¸®å°å¶è¨åºéè¦æ§å·®è·ï¼æ¹æ³æ¯å¾çå¯¦çå®å°ç¨ ECG éå»º 12 å°ç¨ ECGãå·é«ä¾èªªï¼æ¬ç ç©¶æåºäºä¸åå¤ééé®ç½©èªåç·¨ç¢¼å¨ (MCMA) ä¾éææ­¤ç®æ¨ãå¨å¯¦é©çµæä¸­ï¼çæçè¨èèçå¯¦è¨èä¹éçå¯è¦åçµæå¯ä»¥è­æææåºæ¶æ§çæææ§ãåæï¼æ¬ç ç©¶å¼å¥äºç¨±çº ECGGenEval çç¶åè©ä¼°åºæºï¼æ¶µèè¨èå±¤ç´ãç¹å¾µå±¤ç´åè¨ºæ·å±¤ç´è©ä¼°ï¼æä¾ 12 å°ç¨ ECG è¨èåçææ¨¡åçæ´é«è©ä¼°ãæ­¤å¤ï¼å®éçå¯¦é©çµæå¦ä¸ï¼å¨è¨èå±¤ç´è©ä¼°ä¸­ï¼åæ¹èª¤å·®çº 0.0178 å 0.0658ï¼ç¸éä¿æ¸çº 0.7698 å 0.7237ï¼å¨è¨ºæ·å±¤ç´è©ä¼°ä¸­ï¼å©åçæç 12 å°ç¨ ECG çå¹³å F1 åæ¸çº 0.8319 å 0.7824ï¼éå°äºæåé²çæè½ãéæ¾åå§ç¢¼å¯ä»¥å¨ \url{https://github.com/CHENJIAR3/MCMA} å¬éåå¾ã</paragraph>

##### **TM-PATHVQA:90000+ Textless Multilingual Questions for Medical Visual Question Answering**
2407.11383v1 by Tonmoy Rajkhowa, Amartya Roy Chowdhury, Sankalp Nagaonkar, Achyut Mani Tripathi

In healthcare and medical diagnostics, Visual Question Answering (VQA)
mayemergeasapivotal tool in scenarios where analysis of intricate medical
images becomes critical for accurate diagnoses. Current text-based VQA systems
limit their utility in scenarios where hands-free interaction and accessibility
are crucial while performing tasks. A speech-based VQA system may provide a
better means of interaction where information can be accessed while performing
tasks simultaneously. To this end, this work implements a speech-based VQA
system by introducing a Textless Multilingual Pathological VQA (TMPathVQA)
dataset, an expansion of the PathVQA dataset, containing spoken questions in
English, German & French. This dataset comprises 98,397 multilingual spoken
questions and answers based on 5,004 pathological images along with 70 hours of
audio. Finally, this work benchmarks and compares TMPathVQA systems implemented
using various combinations of acoustic and visual features.

æè¦ï¼å¨é«çä¿å¥åé«çè¨ºæ·ä¸­ï¼è¦è¦ºåç­ï¼VQAï¼å¯è½æçºééµå·¥å·ï¼å¨åæè¤éçé«çå½±åå°æ¼æºç¢ºè¨ºæ·è³ééè¦çå ´æ¯ä¸­ãç®åçåºæ¼æå­ç VQA ç³»çµ±éå¶äºå®åå¨å·è¡ä»»åæåæäºååå¯åæ§è³ééè¦çå ´æ¯ä¸­çæç¨ãåºæ¼èªé³ç VQA ç³»çµ±å¯è½æä¾æ´å¥½çäºåæ¹å¼ï¼å¯ä»¥å¨å·è¡ä»»åçåæå­åè³è¨ãçºæ­¤ï¼æ¬ç ç©¶ééå°å¥ç¡æå­å¤èªè¨çç VQAï¼TMPathVQAï¼è³æéï¼æ´åäº PathVQA è³æéï¼åå«è±èªãå¾·èªåæ³èªçå£èªªåé¡ï¼å¯¦ä½äºä¸ååºæ¼èªé³ç VQA ç³»çµ±ãæ­¤è³æéåå« 98,397 åå¤èªè¨çå£èªªåé¡åç­æ¡ï¼åºæ¼ 5,004 åççå½±åä»¥å 70 å°æçé³è¨ãæå¾ï¼æ¬ç ç©¶ä½¿ç¨åç¨®é³è¨åè¦è¦ºç¹å¾µççµåä¾å¯¦ä½ TMPathVQA ç³»çµ±ï¼ä¸¦é²è¡åºæºæ¸¬è©¦åæ¯è¼ã

##### **Leveraging Multimodal CycleGAN for the Generation of Anatomically Accurate Synthetic CT Scans from MRIs**
2407.10888v1 by Leonardo Crespi, Samuele Camnasio, Damiano Dei, Nicola Lambri, Pietro Mancosu, Marta Scorsetti, Daniele Loiacono

In many clinical settings, the use of both Computed Tomography (CT) and
Magnetic Resonance (MRI) is necessary to pursue a thorough understanding of the
patient's anatomy and to plan a suitable therapeutical strategy; this is often
the case in MRI-based radiotherapy, where CT is always necessary to prepare the
dose delivery, as it provides the essential information about the radiation
absorption properties of the tissues. Sometimes, MRI is preferred to contour
the target volumes. However, this approach is often not the most efficient, as
it is more expensive, time-consuming and, most importantly, stressful for the
patients. To overcome this issue, in this work, we analyse the capabilities of
different configurations of Deep Learning models to generate synthetic CT scans
from MRI, leveraging the power of Generative Adversarial Networks (GANs) and,
in particular, the CycleGAN architecture, capable of working in an unsupervised
manner and without paired images, which were not available. Several CycleGAN
models were trained unsupervised to generate CT scans from different MRI
modalities with and without contrast agents. To overcome the problem of not
having a ground truth, distribution-based metrics were used to assess the
model's performance quantitatively, together with a qualitative evaluation
where physicians were asked to differentiate between real and synthetic images
to understand how realistic the generated images were. The results show how,
depending on the input modalities, the models can have very different
performances; however, models with the best quantitative results, according to
the distribution-based metrics used, can generate very difficult images to
distinguish from the real ones, even for physicians, demonstrating the
approach's potential.

æè¦ï¼å¨è¨±å¤è¨åºç°å¢ä¸­ï¼éè¦ä½¿ç¨é»è¦æ·å±¤ææ (CT) åç£æ¯é å½± (MRI) ä¾å¾¹åºäºè§£æ£èçè§£åçµæ§ï¼ä¸¦è¦åé©ç¶çæ²»çç­ç¥ï¼ééå¸¸ç¼çå¨åºæ¼ MRI çæ¾å°æ²»çä¸­ï¼å¶ä¸­ CT å°æ¼æºååéå³éç¸½æ¯å¿è¦çï¼å çºå®æä¾äºæéçµç¹è¼»å°å¸æ¶ç¹æ§çåºæ¬è³è¨ãææï¼MRI åªåæ¼å¾åç®æ¨é«ç©ãç¶èï¼éç¨®æ¹æ³éå¸¸ä¸æ¯æææççï¼å çºå®æ´æè²´ãèæï¼æéè¦çæ¯æè®æ£èæå°å£åãçºäºåæéååé¡ï¼å¨éé å·¥ä½ä¸­ï¼æååæäºæ·±åº¦å­¸ç¿æ¨¡åçä¸åéç½®ï¼ä»¥å¾ MRI çæåæ CT ææçè½åï¼å©ç¨çæå°æç¶²è·¯ (GAN) çåè½ï¼ç¹å¥æ¯ CycleGAN æ¶æ§ï¼è½å¤ ä»¥ç¡ç£ç£çæ¹å¼å·¥ä½ï¼èä¸ä¸éè¦æå°çå½±åï¼èéäºå½±åä¸¦ä¸å¯ç¨ãå¹¾å CycleGAN æ¨¡åç¶éç¡ç£ç£è¨ç·´ï¼ä»¥å¾ä¸å MRI æ¨¡å¼çæ CT ææï¼ç¡è«æ¯å¦ä½¿ç¨å°æ¯åãçºäºåææ²æåºæ¬äºå¯¦çåé¡ï¼åºæ¼åä½çææ¨è¢«ç¨æ¼å®éè©ä¼°æ¨¡åçæè½ï¼ä»¥åå®æ§è©ä¼°ï¼å¶ä¸­è¦æ±é«çååçå¯¦ååæå½±åï¼ä»¥äºè§£çæçå½±åæå¤é¼çãçµæé¡¯ç¤ºï¼æ ¹æè¼¸å¥æ¨¡å¼ï¼æ¨¡åçæè½å¯è½å¤§ä¸ç¸åï¼ç¶èï¼æ ¹ææä½¿ç¨çåºæ¼åä½çææ¨ï¼å·ææä½³å®éçµæçæ¨¡åå¯ä»¥ç¢çéå¸¸é£ä»¥èçå¯¦å½±åååçå½±åï¼å³ä½¿å°æ¼é«çä¾èªªä¹æ¯å¦æ­¤ï¼éè­æäºéç¨®æ¹æ³çæ½åã

##### **Towards Enhanced Classification of Abnormal Lung sound in Multi-breath: A Light Weight Multi-label and Multi-head Attention Classification Method**
2407.10828v1 by Yi-Wei Chua, Yun-Chien Cheng

This study aims to develop an auxiliary diagnostic system for classifying
abnormal lung respiratory sounds, enhancing the accuracy of automatic abnormal
breath sound classification through an innovative multi-label learning approach
and multi-head attention mechanism. Addressing the issue of class imbalance and
lack of diversity in existing respiratory sound datasets, our study employs a
lightweight and highly accurate model, using a two-dimensional label set to
represent multiple respiratory sound characteristics. Our method achieved a
59.2% ICBHI score in the four-category task on the ICBHI2017 dataset,
demonstrating its advantages in terms of lightweight and high accuracy. This
study not only improves the accuracy of automatic diagnosis of lung respiratory
sound abnormalities but also opens new possibilities for clinical applications.

æè¦ï¼æ¬ç ç©¶æ¨å¨éç¼ä¸åè¼å©è¨ºæ·ç³»çµ±ï¼ç¨æ¼åé¡ç°å¸¸çèºé¨å¼å¸é³ï¼ééåµæ°çå¤æ¨ç±¤å­¸ç¿æ¹æ³åå¤é ­æ³¨æåæ©å¶ï¼æåèªåç°å¸¸å¼å¸é³åé¡çæºç¢ºåº¦ãéå°ç¾æå¼å¸é³è³æéä¸­é¡å¥ä¸å¹³è¡¡åç¼ºä¹å¤æ¨£æ§çåé¡ï¼æ¬ç ç©¶æ¡ç¨è¼éä¸é«ç²¾ç¢ºåº¦çæ¨¡åï¼ä½¿ç¨äºç¶­æ¨ç±¤çµä¾è¡¨ç¤ºå¤éå¼å¸é³ç¹å¾µãæåçæ¨¡åå¨ ICBHI2017 è³æéçåé¡å¥ä»»åä¸­ï¼ç²å¾äº 59.2% ç ICBHI åæ¸ï¼è­æäºå¶å¨è¼éååé«æºç¢ºåº¦æ¹é¢çåªå¢ãæ¬ç ç©¶ä¸åæåäºèºé¨å¼å¸é³ç°å¸¸èªåè¨ºæ·çæºç¢ºåº¦ï¼ä¹çºè¨åºæç¨éåäºæ°çå¯è½æ§ã

##### **Classification of Heart Sounds Using Multi-Branch Deep Convolutional Network and LSTM-CNN**
2407.10689v1 by Seyed Amir Latifi, Hassan Ghassemian, Maryam Imani

This paper presents a fast and cost-effective method for diagnosing cardiac
abnormalities with high accuracy and reliability using low-cost systems in
clinics. The primary limitation of automatic diagnosing of cardiac diseases is
the rarity of correct and acceptable labeled samples, which can be expensive to
prepare. To address this issue, two methods are proposed in this work. The
first method is a unique Multi-Branch Deep Convolutional Neural Network (MBDCN)
architecture inspired by human auditory processing, specifically designed to
optimize feature extraction by employing various sizes of convolutional filters
and audio signal power spectrum as input. In the second method, called as Long
short-term memory-Convolutional Neural (LSCN) model, Additionally, the network
architecture includes Long Short-Term Memory (LSTM) network blocks to improve
feature extraction in the time domain. The innovative approach of combining
multiple parallel branches consisting of the one-dimensional convolutional
layers along with LSTM blocks helps in achieving superior results in audio
signal processing tasks. The experimental results demonstrate superiority of
the proposed methods over the state-of-the-art techniques. The overall
classification accuracy of heart sounds with the LSCN network is more than 96%.
The efficiency of this network is significant compared to common feature
extraction methods such as Mel Frequency Cepstral Coefficients (MFCC) and
wavelet transform. Therefore, the proposed method shows promising results in
the automatic analysis of heart sounds and has potential applications in the
diagnosis and early detection of cardiovascular diseases.

æè¦ï¼æ¬ææåºäºä¸ç¨®å¿«éä¸ç¶æ¿ææçæ¹æ³ï¼ä½¿ç¨ä½ææ¬çç³»çµ±å¨è¨ºæè¨ºæ·å¿èç°å¸¸ï¼ä¸å·æé«æºç¢ºåº¦åå¯é æ§ãèªåè¨ºæ·å¿èç¾ççä¸»è¦éå¶æ¯æ­£ç¢ºä¸å¯æ¥åçæ¨ç±¤æ¨£æ¬ç¨å°ï¼èä¸æºåèµ·ä¾å¯è½å¾æè²´ãçºäºè§£æ±ºéååé¡ï¼éé å·¥ä½æåºäºå©ç¨®æ¹æ³ãç¬¬ä¸ç¨®æ¹æ³æ¯ä¸ç¨®ç¨ç¹çå¤åæ¯æ·±åº¦å·ç©ç¥ç¶ç¶²è·¯ (MBDCN) æ¶æ§ï¼éæä¾èªäººé¡è½è¦ºèçï¼ç¹å¥è¨­è¨çºééæ¡ç¨åç¨®å¤§å°çå·ç©æ¿¾æ³¢å¨åé³è¨è¨èåçè­ä½çºè¼¸å¥ï¼ä¾æä½³åç¹å¾µæåãå¨ç¬¬äºç¨®æ¹æ³ä¸­ï¼ç¨±çºé·ç­æè¨æ¶ - å·ç©ç¥ç¶ (LSCN) æ¨¡åï¼æ­¤å¤ï¼ç¶²è·¯æ¶æ§åæ¬é·ç­æè¨æ¶ (LSTM) ç¶²è·¯åå¡ï¼ä»¥æ¹åæåä¸­çç¹å¾µæåãçµåç±ä¸ç¶­å·ç©å±¤å LSTM åå¡çµæçå¤åä¸¦è¡åæ¯çåµæ°æ¹æ³ï¼æå©æ¼å¨é³è¨è¨èèçä»»åä¸­éæåªç°ççµæãå¯¦é©çµæè­æäºææåºçæ¹æ³åªæ¼æåé²çæè¡ãLSCN ç¶²è·¯å°å¿é³çæ´é«åé¡æºç¢ºåº¦è¶é 96%ãèå¸¸è¦çç¹å¾µæåæ¹æ³ï¼ä¾å¦æ¢ç¾é »çåè­ä¿æ¸ (MFCC) åå°æ³¢è½æï¼ç¸æ¯ï¼æ­¤ç¶²è·¯çæçé¡¯èãå æ­¤ï¼ææåºçæ¹æ³å¨å¿é³çèªååæä¸­é¡¯ç¤ºåºæå¸æççµæï¼ä¸¦ä¸å¨å¿è¡ç®¡ç¾ççè¨ºæ·åæ©ææª¢æ¸¬ä¸­å·ææ½å¨æç¨ã

##### **Spatio-temporal neural distance fields for conditional generative modeling of the heart**
2407.10663v1 by Kristine SÃ¸rensen, Paula Diez, Jan Margeta, Yasmin El Youssef, Michael Pham, Jonas Jalili Pedersen, Tobias KÃ¼hl, Ole de Backer, Klaus Kofoed, Oscar Camara, Rasmus Paulsen

The rhythmic pumping motion of the heart stands as a cornerstone in life, as
it circulates blood to the entire human body through a series of carefully
timed contractions of the individual chambers. Changes in the size, shape and
movement of the chambers can be important markers for cardiac disease and
modeling this in relation to clinical demography or disease is therefore of
interest. Existing methods for spatio-temporal modeling of the human heart
require shape correspondence over time or suffer from large memory
requirements, making it difficult to use for complex anatomies. We introduce a
novel conditional generative model, where the shape and movement is modeled
implicitly in the form of a spatio-temporal neural distance field and
conditioned on clinical demography. The model is based on an auto-decoder
architecture and aims to disentangle the individual variations from that
related to the clinical demography. It is tested on the left atrium (including
the left atrial appendage), where it outperforms current state-of-the-art
methods for anatomical sequence completion and generates synthetic sequences
that realistically mimics the shape and motion of the real left atrium. In
practice, this means we can infer functional measurements from a static image,
generate synthetic populations with specified demography or disease and
investigate how non-imaging clinical data effect the shape and motion of
cardiac anatomies.

æè¦ï¼å¿èæç¯å¥çè·³ååä½æ¯çå½ä¸­çåºç³ï¼å çºå®ééä¸ç³»åä»ç´°è¨æçå®ç¨å¿å®¤æ¶ç¸®ï¼å°è¡æ¶²å¾ªç°å°æ´åèº«é«ãå¿å®¤çå¤§å°ãå½¢çåéåçè®åå¯è½æ¯å¿èç¾ççéè¦æ¨è¨ï¼å æ­¤å°æ­¤é²è¡å»ºæ¨¡ä»¥éè¯è¨åºäººå£çµ±è¨æç¾çï¼å æ­¤å·ææç¾©ãç¾æçæç©ºå»ºæ¨¡æ¹æ³éè¦é¨èæéæ¨ç§»é²è¡å½¢çå°æï¼æéè¦å¤§éçè¨æ¶é«éæ±ï¼éä½¿å¾é£ä»¥ç¨æ¼è¤éçè§£åçµæ§ãæåå¼å¥äºä¸åæ°ç©çæ¢ä»¶çææ¨¡åï¼å¶ä¸­å½¢çåéåä»¥æç©ºç¥ç¶è·é¢å ´çå½¢å¼é±å«å»ºæ¨¡ï¼ä¸¦æ ¹æè¨åºäººå£çµ±è¨é²è¡æ¢ä»¶è¨­å®ãè©²æ¨¡ååºæ¼èªåç·¨ç¢¼å¨æ¶æ§ï¼æ¨å¨è§£éèè¨åºäººå£çµ±è¨ç¸éçåå¥è®ç°ãå®å¨å·¦å¿æ¿ï¼åæ¬å·¦å¿è³ï¼ä¸é²è¡æ¸¬è©¦ï¼å¨è§£ååºåå®ææ¹é¢åªæ¼ç¶åæåé²çæ¹æ³ï¼ä¸¦çæé¼çå°æ¨¡æ¬çå¯¦å·¦å¿æ¿å½¢çåéåçåæåºåãå¯¦éä¸ï¼éæå³èæåå¯ä»¥å¾éæå½±åæ¨æ·åè½æ§æ¸¬éï¼çæå·æç¹å®äººå£çµ±è¨æç¾ççåææç¾¤ï¼ä¸¦èª¿æ¥éå½±åè¨åºè³æå¦ä½å½±é¿å¿èè§£åçµæ§çå½¢çåéåã

##### **TCM-FTP: Fine-Tuning Large Language Models for Herbal Prescription Prediction**
2407.10510v1 by Xingzhi Zhou, Xin Dong, Chunhao Li, Yuning Bai, Yulong Xu, Ka Chun Cheung, Simon See, Xinpeng Song, Runshun Zhang, Xuezhong Zhou, Nevin L. Zhang

Traditional Chinese medicine (TCM) relies on specific combinations of herbs
in prescriptions to treat symptoms and signs, a practice that spans thousands
of years. Predicting TCM prescriptions presents a fascinating technical
challenge with practical implications. However, this task faces limitations due
to the scarcity of high-quality clinical datasets and the intricate
relationship between symptoms and herbs. To address these issues, we introduce
DigestDS, a new dataset containing practical medical records from experienced
experts in digestive system diseases. We also propose a method, TCM-FTP (TCM
Fine-Tuning Pre-trained), to leverage pre-trained large language models (LLMs)
through supervised fine-tuning on DigestDS. Additionally, we enhance
computational efficiency using a low-rank adaptation technique. TCM-FTP also
incorporates data augmentation by permuting herbs within prescriptions,
capitalizing on their order-agnostic properties. Impressively, TCM-FTP achieves
an F1-score of 0.8031, surpassing previous methods significantly. Furthermore,
it demonstrates remarkable accuracy in dosage prediction, achieving a
normalized mean square error of 0.0604. In contrast, LLMs without fine-tuning
perform poorly. Although LLMs have shown capabilities on a wide range of tasks,
this work illustrates the importance of fine-tuning for TCM prescription
prediction, and we have proposed an effective way to do that.

æè¦ï¼ä¸­é«ä¾è³´ç¹å®ä¸­èè¥çµåä¾æ²»çççåå¾µåï¼éé åæ³å·²ææ¸åå¹´çæ­·å²ãé æ¸¬ä¸­é«èæ¹æ¯ä¸åå¼äººå¥åçæè¡ææ°ï¼å·æå¯¦éæç¾©ãç¶èï¼ç±æ¼ç¼ºä¹é«åè³ªçè¨åºæ¸æéä»¥åççèä¸­èè¥ä¹éçè¤ééä¿ï¼éé ä»»åé¢è¨éå¶ãçºäºè§£æ±ºéäºåé¡ï¼æåå¼å¥äº DigestDSï¼ä¸ååå«æ¶åç³»çµ±ç¾çç¶é©è±å¯å°å®¶å¯¦éçæ­·çæ°æ¸æéãæåéæåºäºä¸ç¨®æ¹æ³ï¼TCM-FTPï¼ä¸­é«å¾®èª¿é è¨ç·´ï¼ï¼ééå¨ DigestDS ä¸é²è¡ç£ç£å¾®èª¿ä¾å©ç¨é è¨ç·´çå¤§èªè¨æ¨¡å (LLM)ãæ­¤å¤ï¼æåä½¿ç¨ä½ç§©é©ææè¡ä¾æé«è¨ç®æçãTCM-FTP éééç½®æèæ¹ä¸­çä¸­èè¥ä¾ç´å¥æ¸ææ´åï¼å©ç¨å®åèé åºç¡éçç¹æ§ãä»¤äººå°è±¡æ·±å»çæ¯ï¼TCM-FTP éå°äº 0.8031 ç F1 åæ¸ï¼é¡¯èè¶è¶äºä»¥åçæ¹æ³ãæ­¤å¤ï¼å®å¨åéé æ¸¬ä¸­è¡¨ç¾åºé¡¯èçæºç¢ºæ§ï¼å¯¦ç¾äº 0.0604 çæ­¸ä¸ååæ¹èª¤å·®ãç¸æ¯ä¹ä¸ï¼æªç¶å¾®èª¿ç LLM è¡¨ç¾ä¸ä½³ãåç®¡ LLM å·²å¨å»£æ³çä»»åä¸­å±ç¾åºè½åï¼ä½éé å·¥ä½èªªæäºå¾®èª¿å°æ¼ä¸­é«èæ¹é æ¸¬çéè¦æ§ï¼èä¸æåæåºäºä¸åææçæ¹æ³ä¾åå°éä¸é»ã

##### **A Multi-Stage Framework for 3D Individual Tooth Segmentation in Dental CBCT**
2407.10433v1 by Chunshi Wang, Bin Zhao, Shuxue Ding

Cone beam computed tomography (CBCT) is a common way of diagnosing dental
related diseases. Accurate segmentation of 3D tooth is of importance for the
treatment. Although deep learning based methods have achieved convincing
results in medical image processing, they need a large of annotated data for
network training, making it very time-consuming in data collection and
annotation. Besides, domain shift widely existing in the distribution of data
acquired by different devices impacts severely the model generalization. To
resolve the problem, we propose a multi-stage framework for 3D tooth
segmentation in dental CBCT, which achieves the third place in the
"Semi-supervised Teeth Segmentation" 3D (STS-3D) challenge. The experiments on
validation set compared with other semi-supervised segmentation methods further
indicate the validity of our approach.

æè¦ï¼éçåæé»è¦æ·å±¤ææ (CBCT) æ¯ä¸ç¨®å¸¸è¦ççç§ç¸éç¾çè¨ºæ·æ¹å¼ã3D çé½çç²¾ç¢ºåå²å°æ¼æ²»çè³ééè¦ãåç®¡åºæ¼æ·±åº¦å­¸ç¿çæ¹æ³å¨é«å­¸å½±åèçä¸­å·²åå¾ä»¤äººä¿¡æçææï¼ä½å®åéè¦å¤§éçè¨»è§£è³æé²è¡ç¶²è·¯è¨ç·´ï¼éä½¿å¾è³ææ¶éåè¨»è§£éå¸¸èæãæ­¤å¤ï¼å¨ä¸åè£ç½®åå¾çè³æåä½ä¸­å»£æ³å­å¨çé åè½ç§»æå´éå½±é¿æ¨¡åçæ³åè½åãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸åå¤éæ®µæ¶æ§ï¼ç¨æ¼çç§ CBCT ä¸­ç 3D çé½åå²ï¼å¨ãåç£ç£çé½åå²ã3D (STS-3D) ææ°ä¸­ç²å¾ç¬¬ä¸åãèå¶ä»åç£ç£åå²æ¹æ³ç¸æ¯ï¼å¨é©è­éä¸çå¯¦é©é²ä¸æ­¥è­æäºæåæ¹æ³çæææ§ã

##### **Static and multivariate-temporal attentive fusion transformer for readmission risk prediction**
2407.11096v1 by Zhe Sun, Runzhi Li, Jing Wang, Gang Chen, Siyu Yan, Lihong Ma

Background: Accurate short-term readmission prediction of ICU patients is
significant in improving the efficiency of resource assignment by assisting
physicians in making discharge decisions. Clinically, both individual static
static and multivariate temporal data collected from ICU monitors play critical
roles in short-term readmission prediction. Informative static and multivariate
temporal feature representation capturing and fusion present challenges for
accurate readmission prediction. Methods:We propose a novel static and
multivariate-temporal attentive fusion transformer (SMTAFormer) to predict
short-term readmission of ICU patients by fully leveraging the potential of
demographic and dynamic temporal data. In SMTAFormer, we first apply an MLP
network and a temporal transformer network to learn useful static and temporal
feature representations, respectively. Then, the well-designed static and
multivariate temporal feature fusion module is applied to fuse static and
temporal feature representations by modeling intra-correlation among
multivariate temporal features and constructing inter-correlation between
static and multivariate temporal features. Results: We construct a readmission
risk assessment (RRA) dataset based on the MIMIC-III dataset. The extensive
experiments show that SMTAFormer outperforms advanced methods, in which the
accuracy of our proposed method is up to 86.6%, and the area under the receiver
operating characteristic curve (AUC) is up to 0.717. Conclusion: Our proposed
SMTAFormer can efficiently capture and fuse static and multivariate temporal
feature representations. The results show that SMTAFormer significantly
improves the short-term readmission prediction performance of ICU patients
through comparisons to strong baselines.

æè¦ï¼<paragraph>èæ¯ï¼ç²¾æºç­æéè¿é æ¸¬éçå è­·çæ¿ï¼ICUï¼çäººå°æ¼æåè³æºåéæçè³ééè¦ï¼è½åå©é«å¸«ååºåºé¢æ±ºç­ãè¨åºä¸ï¼å¾ ICU ç£æ¸¬å¨æ¶éå°çåå¥éæè³æåå¤è®éæéè³æå¨ç­æéè¿é æ¸¬ä¸­æ®æ¼ééµè§è²ãæ·ååèåææç¾©çéæåå¤è®éæéç¹å¾µè¡¨å¾µå°æ¼ç²¾æºéè¿é æ¸¬æ§æææ°ãæ¹æ³ï¼æåæåºä¸åæ°ç©çéæåå¤è®éæéæ³¨æåèåTransformerï¼SMTAFormerï¼ï¼èç±ååå©ç¨äººå£çµ±è¨ååææéè³æçæ½åï¼ä¾é æ¸¬ ICU çäººçç­æéè¿ãå¨ SMTAFormer ä¸­ï¼æåé¦åæç¨ä¸å MLP ç¶²è·¯åä¸åæéTransformerç¶²è·¯ï¼åå¥å­¸ç¿æç¨çéæåæéç¹å¾µè¡¨å¾µãç¶å¾ï¼æç¨ç²¾å¿è¨­è¨çéæåå¤è®éæéç¹å¾µèåæ¨¡çµï¼èç±å»ºæ¨¡å¤è®éæéç¹å¾µä¹éçå§é¨ç¸éæ§ï¼ä»¥åå»ºæ§éæåå¤è®éæéç¹å¾µä¹éçç¸äºéè¯æ§ï¼ä¾èåéæåæéç¹å¾µè¡¨å¾µãçµæï¼æåæ ¹æ MIMIC-III è³æéå»ºæ§ä¸åéè¿é¢¨éªè©ä¼°ï¼RRAï¼è³æéãå»£æ³çå¯¦é©é¡¯ç¤ºï¼SMTAFormer åªæ¼é²éæ¹æ³ï¼å¶ä¸­æåæåºçæ¹æ³çæºç¢ºåº¦é«é 86.6%ï¼èåè©¦èå·¥ä½ç¹æ§æ²ç·ï¼AUCï¼ä¸çé¢ç©é«é 0.717ãçµè«ï¼æåæåºç SMTAFormer è½æææ·ååèåéæåå¤è®éæéç¹å¾µè¡¨å¾µãçµæé¡¯ç¤ºï¼SMTAFormer èç±èå¼·å¤§çåºç·æ¯è¼ï¼é¡¯èæå ICU çäººçç­æéè¿é æ¸¬æè½ã</paragraph>

##### **Evolved Developmental Artificial Neural Networks for Multitasking with Advanced Activity Dependence**
2407.10359v1 by Yintong Zhang, Jason A. Yoder

Recently, Cartesian Genetic Programming has been used to evolve developmental
programs to guide the formation of artificial neural networks (ANNs). This
approach has demonstrated success in enabling ANNs to perform multiple tasks
while avoiding catastrophic forgetting. One unique aspect of this approach is
the use of separate developmental programs evolved to regulate the development
of separate soma and dendrite units. An opportunity afforded by this approach
is the ability to incorporate Activity Dependence (AD) into the model such that
environmental feedback can help to regulate the behavior of each type of unit.
Previous work has shown a limited version of AD (influencing neural bias) to
provide marginal improvements over non-AD ANNs. In this work, we present
promising results from new extensions to AD. Specifically, we demonstrate a
more significant improvement via AD on new neural parameters including health
and position, as well as a combination of all of these along with bias. We
report on the implications of this work and suggest several promising
directions for future work.

æè¦ï¼æè¿ï¼ç¬å¡å°éä¼ è§åå·²è¢«ç¨äºè¿ååè²ç¨åºï¼ä»¥æå¯¼äººå·¥ç¥ç»ç½ç» (ANN) çå½¢æãè¿ç§æ¹æ³å·²è¯æè½å¤è®© ANN æ§è¡å¤é¡¹ä»»å¡ï¼åæ¶é¿åç¾é¾æ§éå¿ãè¿ç§æ¹æ³çä¸ä¸ªç¬ç¹æ¹é¢æ¯ä½¿ç¨åç¬çåå±ç¨åºæ¥è°èåç¬çèº¯ä½åæ çªååçåå±ãè¿ç§æ¹æ³æä¾äºä¸ä¸ªæºä¼ï¼å³è½å¤å°æ´»å¨ä¾èµæ§ (AD) çº³å¥æ¨¡åï¼ä»¥ä¾¿ç¯å¢åé¦å¯ä»¥å¸®å©è°èæ¯ç§ç±»åçååçè¡ä¸ºãä»¥åçå·¥ä½å·²ç»å±ç¤ºäº AD çä¸ä¸ªæéçæ¬ï¼å½±åç¥ç»åç½®ï¼ï¼ä»¥æä¾å¯¹é AD ANN çè¾¹éæ¹è¿ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å±ç¤ºäº AD æ°æ©å±çä»¤äººé¼èçç»æãå·ä½æ¥è¯´ï¼æä»¬éè¿ AD å¨æ°çç¥ç»åæ°ï¼åæ¬å¥åº·åä½ç½®ï¼ä»¥åææè¿äºåæ°ä¸åç½®çç»åä¸å±ç¤ºäºæ´æ¾ççæ¹è¿ãæä»¬æ¥åäºè¿é¡¹å·¥ä½çå½±åï¼å¹¶ä¸ºæªæ¥çå·¥ä½æåºäºå ä¸ªæå¸æçæ¹åã

##### **Learning Unlabeled Clients Divergence via Anchor Model Aggregation for Federated Semi-supervised Learning**
2407.10327v1 by Marawan Elbatel, Hualiang Wang, Jixiang Chen, Hao Wang, Xiaomeng Li

Federated semi-supervised learning (FedSemi) refers to scenarios where there
may be clients with fully labeled data, clients with partially labeled, and
even fully unlabeled clients while preserving data privacy. However, challenges
arise from client drift due to undefined heterogeneous class distributions and
erroneous pseudo-labels. Existing FedSemi methods typically fail to aggregate
models from unlabeled clients due to their inherent unreliability, thus
overlooking unique information from their heterogeneous data distribution,
leading to sub-optimal results. In this paper, we enable unlabeled client
aggregation through SemiAnAgg, a novel Semi-supervised Anchor-Based federated
Aggregation. SemiAnAgg learns unlabeled client contributions via an anchor
model, effectively harnessing their informative value. Our key idea is that by
feeding local client data to the same global model and the same consistently
initialized anchor model (i.e., random model), we can measure the importance of
each unlabeled client accordingly. Extensive experiments demonstrate that
SemiAnAgg achieves new state-of-the-art results on four widely used FedSemi
benchmarks, leading to substantial performance improvements: a 9% increase in
accuracy on CIFAR-100 and a 7.6% improvement in recall on the medical dataset
ISIC-18, compared with prior state-of-the-art. Code is available at:
https://github.com/xmed-lab/SemiAnAgg.

æè¦ï¼è¯é¦åç£ç£å­¸ç¿ (FedSemi) æçæ¯å¨ä¿è­·è³æé±ç§çåæï¼å¯è½å­å¨å·æå®å¨æ¨ç±¤è³æçå®¢æ¶ç«¯ãå·æé¨åæ¨ç±¤çå®¢æ¶ç«¯ï¼çè³å®å¨æ²ææ¨ç±¤çå®¢æ¶ç«¯çææ³ãç¶èï¼ç±æ¼æªå®ç¾©çç°è³ªé¡å¥åä½åé¯èª¤çå½æ¨ç±¤ï¼å®¢æ¶ç«¯æ¼ç§»å¸¶ä¾äºææ°ãç¾æç FedSemi æ¹æ³éå¸¸ç¡æ³å½ç¸½ä¾èªæªæ¨ç±¤å®¢æ¶ç«¯çæ¨¡åï¼å çºå®åæ¬è³ªä¸ä¸å¯é ï¼å æ­¤å¿½ç¥äºå¶ç°è³ªè³æåä½ä¸­çç¨ç¹è³è¨ï¼å°è´æ¬¡ä½³çµæãå¨æ¬æä¸­ï¼æåéé SemiAnAggï¼ä¸ç¨®æ°ç©çåç£ç£é¨å®å¼è¯é¦èåï¼åç¨æªæ¨ç±¤å®¢æ¶ç«¯èåãSemiAnAgg ééé¨å®æ¨¡åå­¸ç¿æªæ¨ç±¤å®¢æ¶ç«¯è²¢ç»ï¼ææå©ç¨å¶è³è¨å¹å¼ãæåçééµæ§æ³æ¯ï¼ééå°æ¬å°å®¢æ¶ç«¯è³ææä¾çµ¦ç¸åçå¨çæ¨¡ååç¸åä¸è´åå§åçé¨å®æ¨¡åï¼å³é¨æ©æ¨¡åï¼ï¼æåå¯ä»¥ç¸æå°è¡¡éæ¯åæªæ¨ç±¤å®¢æ¶ç«¯çéè¦æ§ãå»£æ³çå¯¦é©è­æ SemiAnAgg å¨ååå»£æ³ä½¿ç¨ç FedSemi åºæºä¸ç²å¾äºæ°çæåé²çµæï¼å¸¶ä¾äºé¡¯èçæè½æåï¼èååçæåé²æè¡ç¸æ¯ï¼CIFAR-100 çæºç¢ºåº¦æé«äº 9%ï¼é«çè³æé ISIC-18 çå¬åçæé«äº 7.6%ãç¨å¼ç¢¼å¯å¨ https://github.com/xmed-lab/SemiAnAgg åå¾ã

##### **Rapid Biomedical Research Classification: The Pandemic PACT Advanced Categorisation Engine**
2407.10086v1 by Omid Rohanian, Mohammadmahdi Nouriborji, Olena Seminog, Rodrigo Furst, Thomas Mendy, Shanthi Levanita, Zaharat Kadri-Alab, Nusrat Jabin, Daniela Toale, Georgina Humphreys, Emilia Antonio, Adrian Bucher, Alice Norton, David A. Clifton

This paper introduces the Pandemic PACT Advanced Categorisation Engine
(PPACE) along with its associated dataset. PPACE is a fine-tuned model
developed to automatically classify research abstracts from funded biomedical
projects according to WHO-aligned research priorities. This task is crucial for
monitoring research trends and identifying gaps in global health preparedness
and response. Our approach builds on human-annotated projects, which are
allocated one or more categories from a predefined list. A large language model
is then used to generate `rationales' explaining the reasoning behind these
annotations. This augmented data, comprising expert annotations and rationales,
is subsequently used to fine-tune a smaller, more efficient model. Developed as
part of the Pandemic PACT project, which aims to track and analyse research
funding and clinical evidence for a wide range of diseases with outbreak
potential, PPACE supports informed decision-making by research funders,
policymakers, and independent researchers. We introduce and release both the
trained model and the instruction-based dataset used for its training. Our
evaluation shows that PPACE significantly outperforms its baselines. The
release of PPACE and its associated dataset offers valuable resources for
researchers in multilabel biomedical document classification and supports
advancements in aligning biomedical research with key global health priorities.

æè¦ï¼æ¬æä»ç´¹äºç«æ PACT é²éåé¡å¼æ (PPACE) åå¶ç¸éè³æéãPPACE æ¯ä¸åç¶éå¾®èª¿çæ¨¡åï¼éç¼ç¨æ¼æ ¹æ WHO èªå¯çç ç©¶åªåé åºèªååé¡ç²å¾è³å©ççç©é«å­¸å°æ¡çç ç©¶æè¦ãéé ä»»åå°æ¼ç£æ§ç ç©¶è¶¨å¢åæ¾åºå¨çå¥åº·æºååæè®çå·®è·è³ééè¦ãæåçåæ³å»ºç«å¨äººå·¥æ¨è¨»çå°æ¡ä¸ï¼éäºå°æ¡å¾é åå®ç¾©çæ¸å®ä¸­åéä¸åæå¤åé¡å¥ãç¶å¾ä½¿ç¨å¤§åèªè¨æ¨¡åä¾ç¢çãä¾æãï¼èªªæéäºæ¨è¨»èå¾çæ¨çãéäºæ´å¢è³æåå«å°å®¶æ¨è¨»åä¾æï¼é¨å¾ç¨æ¼å¾®èª¿ä¸åè¼å°ãæ´ææççæ¨¡åãPPACE æ¯ä½çºç«æ PACT å°æ¡çä¸é¨åéç¼çï¼è©²å°æ¡æ¨å¨è¿½è¹¤ååæåç¨®å·æçç¼æ½åçç¾ççç ç©¶è³éåè¨åºè­æï¼ä¸¦æ¯æç ç©¶è³å©èãæ¿ç­å¶å®èåç¨ç«ç ç©¶äººå¡ååºææºçæ±ºç­ãæåä»ç´¹ä¸¦éåºè¨ç·´å¥½çæ¨¡ååç¨æ¼è¨ç·´çåºæ¼æä»¤çè³æéãæåçè©ä¼°é¡¯ç¤ºï¼PPACE çè¡¨ç¾é¡¯èåªæ¼å¶åºç·ãPPACE åå¶ç¸éè³æéçéåºçºå¤æ¨ç±¤çç©é«å­¸æä»¶åé¡çç ç©¶äººå¡æä¾äºå¯¶è²´çè³æºï¼ä¸¦æ¯æå°çç©é«å­¸ç ç©¶èå¨çå¥åº·ééµåªåé åºç¸ç¬¦çé²å±ã

##### **Document-level Clinical Entity and Relation Extraction via Knowledge Base-Guided Generation**
2407.10021v1 by Kriti Bhattarai, Inez Y. Oh, Zachary B. Abrams, Albert M. Lai

Generative pre-trained transformer (GPT) models have shown promise in
clinical entity and relation extraction tasks because of their precise
extraction and contextual understanding capability. In this work, we further
leverage the Unified Medical Language System (UMLS) knowledge base to
accurately identify medical concepts and improve clinical entity and relation
extraction at the document level. Our framework selects UMLS concepts relevant
to the text and combines them with prompts to guide language models in
extracting entities. Our experiments demonstrate that this initial concept
mapping and the inclusion of these mapped concepts in the prompts improves
extraction results compared to few-shot extraction tasks on generic language
models that do not leverage UMLS. Further, our results show that this approach
is more effective than the standard Retrieval Augmented Generation (RAG)
technique, where retrieved data is compared with prompt embeddings to generate
results. Overall, we find that integrating UMLS concepts with GPT models
significantly improves entity and relation identification, outperforming the
baseline and RAG models. By combining the precise concept mapping capability of
knowledge-based approaches like UMLS with the contextual understanding
capability of GPT, our method highlights the potential of these approaches in
specialized domains like healthcare.

æè¦ï¼çæå¼é¢è®­ç»è½¬æ¢å¨ (GPT) æ¨¡åå¨ä¸´åºå®ä½åå³ç³»æ½åä»»å¡ä¸­å±ç°åºæ½åï¼å ä¸ºå®ä»¬å·æç²¾ç¡®æ½ååä¸ä¸æçè§£è½åãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬è¿ä¸æ­¥å©ç¨ç»ä¸å»å­¦è¯­è¨ç³»ç» (UMLS) ç¥è¯åºæ¥åç¡®è¯å«å»å­¦æ¦å¿µï¼å¹¶å¨ææ¡£çº§å«æ¹è¿ä¸´åºå®ä½åå³ç³»æ½åãæä»¬çæ¡æ¶éæ©ä¸ææ¬ç¸å³ç UMLS æ¦å¿µï¼å¹¶å°å®ä»¬ä¸æç¤ºç¸ç»åï¼ä»¥æå¯¼è¯­è¨æ¨¡åæ½åå®ä½ãæä»¬çå®éªè¡¨æï¼ä¸ä¸å©ç¨ UMLS çéç¨è¯­è¨æ¨¡åä¸çå°éæ½åä»»å¡ç¸æ¯ï¼è¿ç§åå§æ¦å¿µæ å°åå¨æç¤ºä¸­åå«è¿äºæ å°æ¦å¿µæ¹è¿äºæ½åç»æãæ­¤å¤ï¼æä»¬çç»æè¡¨æï¼è¿ç§æ¹æ³æ¯æ åçæ£ç´¢å¢å¼ºçæ (RAG) ææ¯æ´ææï¼å¶ä¸­æ£ç´¢å°çæ°æ®ä¸æç¤ºåµå¥è¿è¡æ¯è¾ä»¥çæç»æãæ»ä½èè¨ï¼æä»¬åç°å° UMLS æ¦å¿µä¸ GPT æ¨¡åéæå¯ä»¥æ¾èæ¹åå®ä½åå³ç³»è¯å«ï¼ä¼äºåºçº¿å RAG æ¨¡åãéè¿å° UMLS ç­åºäºç¥è¯çæ¹æ³çç²¾ç¡®æ¦å¿µæ å°è½åä¸ GPT çä¸ä¸æçè§£è½åç¸ç»åï¼æä»¬çæ¹æ³çªåºäºè¿äºæ¹æ³å¨å»çä¿å¥ç­ä¸ä¸é¢åçæ½åã

##### **Causality extraction from medical text using Large Language Models (LLMs)**
2407.10020v1 by Seethalakshmi Gopalakrishnan, Luciana Garbayo, Wlodek Zadrozny

This study explores the potential of natural language models, including large
language models, to extract causal relations from medical texts, specifically
from Clinical Practice Guidelines (CPGs). The outcomes causality extraction
from Clinical Practice Guidelines for gestational diabetes are presented,
marking a first in the field. We report on a set of experiments using variants
of BERT (BioBERT, DistilBERT, and BERT) and using Large Language Models (LLMs),
namely GPT-4 and LLAMA2. Our experiments show that BioBERT performed better
than other models, including the Large Language Models, with an average
F1-score of 0.72. GPT-4 and LLAMA2 results show similar performance but less
consistency. We also release the code and an annotated a corpus of causal
statements within the Clinical Practice Guidelines for gestational diabetes.

æè¦ï¼æ¬ç ç©¶æ¢è¨èªç¶èªè¨æ¨¡åï¼åæ¬å¤§åèªè¨æ¨¡åï¼å¾é«å­¸ææ¬ä¸­èåå æéä¿çå¯è½æ§ï¼ç¹å¥æ¯å¾è¨åºå¯¦åæå (CPG) ä¸­ãç ç©¶ææçºå¦å¨ ç³å°¿ççè¨åºå¯¦åæåä¸­å æéä¿èåï¼çºè©²é åé¦ä¾ãæåå ±åäºä¸çµä½¿ç¨ BERT è®é« (BioBERTãDistilBERT å BERT) åä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) çå¯¦é©ï¼å³ GPT-4 å LLAMA2ãæåçå¯¦é©é¡¯ç¤ºï¼BioBERT çè¡¨ç¾åªæ¼å¶ä»æ¨¡åï¼åæ¬å¤§åèªè¨æ¨¡åï¼å¹³å F1 åæ¸çº 0.72ãGPT-4 å LLAMA2 ççµæé¡¯ç¤ºåºé¡ä¼¼çè¡¨ç¾ï¼ä½ä¸è´æ§è¼ä½ãæåä¹éåºäºç¨å¼ç¢¼åå¦å¨ ç³å°¿çè¨åºå¯¦åæåä¸­å æé³è¿°çæ¨è¨»èªæåº«ã

##### **Pay Less On Clinical Images: Asymmetric Multi-Modal Fusion Method For Efficient Multi-Label Skin Lesion Classification**
2407.09999v1 by Peng Tang, Tobias Lasser

Existing multi-modal approaches primarily focus on enhancing multi-label skin
lesion classification performance through advanced fusion modules, often
neglecting the associated rise in parameters. In clinical settings, both
clinical and dermoscopy images are captured for diagnosis; however, dermoscopy
images exhibit more crucial visual features for multi-label skin lesion
classification. Motivated by this observation, we introduce a novel asymmetric
multi-modal fusion method in this paper for efficient multi-label skin lesion
classification. Our fusion method incorporates two innovative schemes. Firstly,
we validate the effectiveness of our asymmetric fusion structure. It employs a
light and simple network for clinical images and a heavier, more complex one
for dermoscopy images, resulting in significant parameter savings compared to
the symmetric fusion structure using two identical networks for both
modalities. Secondly, in contrast to previous approaches using mutual attention
modules for interaction between image modalities, we propose an asymmetric
attention module. This module solely leverages clinical image information to
enhance dermoscopy image features, considering clinical images as supplementary
information in our pipeline. We conduct the extensive experiments on the
seven-point checklist dataset. Results demonstrate the generality of our
proposed method for both networks and Transformer structures, showcasing its
superiority over existing methods We will make our code publicly available.

æè¦ï¼ç¾æçå¤æ¨¡å¼æ¹æ³ä¸»è¦å°æ³¨æ¼ééåé²çèåæ¨¡çµä¾å¢å¼·å¤æ¨ç±¤ç®èçè®åé¡æè½ï¼å¾å¾å¿½ç¥äºç¸éåæ¸çå¢å ãå¨è¨åºç°å¢ä¸­ï¼è¨åºä¸åç®èé¡å½±åé½æè¢«æ·åç¨æ¼è¨ºæ·ï¼ç¶èï¼ç®èé¡å½±åå±ç¾åºæ´éè¦çè¦è¦ºç¹å¾µï¼ç¨æ¼å¤æ¨ç±¤ç®èçè®åé¡ãåæ­¤è§å¯çµæåç¼ï¼æåå¨æ¬æä¸­ä»ç´¹ä¸ç¨®æ°ç©çä¸å°ç¨±å¤æ¨¡å¼èåæ¹æ³ï¼ç¨æ¼ææçå¤æ¨ç±¤ç®èçè®åé¡ãæåçèåæ¹æ³åå«å©ååµæ°çæ¹æ¡ãé¦åï¼æåé©è­äºæåçä¸å°ç¨±èåçµæ§çæææ§ãå®æ¡ç¨ä¸åè¼éä¸ç°¡å®çç¶²è·¯ç¨æ¼è¨åºå½±åï¼ä»¥åä¸åè¼éä¸è¤éçç¶²è·¯ç¨æ¼ç®èé¡å½±åï¼èä½¿ç¨å©åç¸åçç¶²è·¯ç¨æ¼å©ç¨®æ¨¡å¼çå°ç¨±èåçµæ§ç¸æ¯ï¼éæç¯çå¤§éçåæ¸ãå¶æ¬¡ï¼èååä½¿ç¨ç¸äºæ³¨æåæ¨¡çµç¨æ¼å½±åæ¨¡å¼ä¹éäºåçæ¹æ³ç¸åï¼æåæåºäºä¸åä¸å°ç¨±æ³¨æåæ¨¡çµãéåæ¨¡çµåå©ç¨è¨åºå½±åè³è¨ä¾å¢å¼·ç®èé¡å½±åç¹å¾µï¼å°è¨åºå½±åè¦çºæåæµç¨ä¸­çè£åè³è¨ãæåå¨ä¸é»æ ¸å°æ¸å®è³æéä¸é²è¡äºå»£æ³çå¯¦é©ãçµæè­æäºæåæåºçæ¹æ³å°ç¶²è·¯å Transformer çµæ§çæ®éæ§ï¼å±ç¤ºäºå®åªæ¼ç¾ææ¹æ³çåªè¶æ§ãæåå°å¬éæåçç¨å¼ç¢¼ã

##### **Evaluating the Impact of Different Quantum Kernels on the Classification Performance of Support Vector Machine Algorithm: A Medical Dataset Application**
2407.09930v1 by Emine Akpinar, Sardar M. N. Islam, Murat Oduncuoglu

The support vector machine algorithm with a quantum kernel estimator
(QSVM-Kernel), as a leading example of a quantum machine learning technique,
has undergone significant advancements. Nevertheless, its integration with
classical data presents unique challenges. While quantum computers primarily
interact with data in quantum states, embedding classical data into quantum
states using feature mapping techniques is essential for leveraging quantum
algorithms Despite the recognized importance of feature mapping, its specific
impact on data classification outcomes remains largely unexplored. This study
addresses this gap by comprehensively assessing the effects of various feature
mapping methods on classification results, taking medical data analysis as a
case study. In this study, the QSVM-Kernel method was applied to classification
problems in two different and publicly available medical datasets, namely, the
Wisconsin Breast Cancer (original) and The Cancer Genome Atlas (TCGA) Glioma
datasets. In the QSVM-Kernel algorithm, quantum kernel matrices obtained from 9
different quantum feature maps were used. Thus, the effects of these quantum
feature maps on the classification results of the QSVM-Kernel algorithm were
examined in terms of both classifier performance and total execution time. As a
result, in the Wisconsin Breast Cancer (original) and TCGA Glioma datasets,
when Rx and Ry rotational gates were used, respectively, as feature maps in the
QSVM-Kernel algorithm, the best classification performances were achieved both
in terms of classification performance and total execution time. The
contributions of this study are that (1) it highlights the significant impact
of feature mapping techniques on medical data classification outcomes using the
QSVM-Kernel algorithm, and (2) it also guides undertaking research for improved
QSVM classification performance.

æè¦ï¼<paragraph>ä»¥éå­æ ¸ä¼°è¨å¨çºä¸»çéå­æ©å¨å­¸ç¿æè¡ï¼æ¯æ´åéæ©æ¼ç®æ³ï¼QSVM-Kernelï¼ï¼å·²ç¶æé¡¯èçé²å±ãåç®¡å¦æ­¤ï¼å®èå³çµ±è³æçæ´åï¼åç¾äºç¨ç¹çææ°ãéç¶éå­é»è¦ä¸»è¦èéå­çæä¸­çè³æäºåï¼ä½ä½¿ç¨ç¹å¾µå°ææè¡å°å³çµ±è³æåµå¥éå­çæï¼å°æ¼å©ç¨éå­æ¼ç®æ³è³ééè¦ãåç®¡ç¹å¾µå°æçéè¦æ§ç²å¾èªå¯ï¼ä½å®å°è³æåé¡çµæçå·é«å½±é¿ï¼å¨å¾å¤§ç¨åº¦ä¸ä»æªè¢«æ¢è¨ãæ¬ç ç©¶ééå¨é¢è©ä¼°åç¨®ç¹å¾µå°ææ¹æ³å°åé¡çµæçå½±é¿ï¼ä»¥é«çè³æåæçºæ¡ä¾ç ç©¶ï¼ä¾è§£æ±ºéåå·®è·ãå¨æ¬ç ç©¶ä¸­ï¼QSVM-Kernel æ¹æ³è¢«æç¨æ¼å©åä¸åä¸å¬éçé«çè³æéä¸­çåé¡åé¡ï¼å³å¨æ¯åº·è¾ä¹³çï¼åå§ï¼åççåºå çµåè­ï¼TCGAï¼ç¥ç¶è è³ªç¤è³æéãå¨ QSVM-Kernel æ¼ç®æ³ä¸­ï¼ä½¿ç¨äºå¾ 9 åä¸åçéå­ç¹å¾µå°æä¸­ç²å¾çéå­æ ¸ç©é£ãå æ­¤ï¼éäºéå­ç¹å¾µå°æå° QSVM-Kernel æ¼ç®æ³åé¡çµæçå½±é¿ï¼å¨åé¡å¨æè½åç¸½å·è¡æéæ¹é¢é½å¾å°äºæª¢é©ãçµæï¼å¨å¨æ¯åº·è¾ä¹³çï¼åå§ï¼å TCGA ç¥ç¶è è³ªç¤è³æéä¸­ï¼ç¶ Rx å Ry æè½éåå¥ç¨ä½ QSVM-Kernel æ¼ç®æ³ä¸­çç¹å¾µå°ææï¼å¨åé¡æè½åç¸½å·è¡æéæ¹é¢é½éå°äºæä½³åé¡æè½ãæ¬ç ç©¶çè²¢ç»å¨æ¼ï¼ï¼1ï¼å®å¼·èª¿äºç¹å¾µå°ææè¡å°ä½¿ç¨ QSVM-Kernel æ¼ç®æ³çé«çè³æåé¡çµæçé¡¯èå½±é¿ï¼ä¸¦ä¸ï¼2ï¼å®ä¹æå°é²è¡ç ç©¶ä»¥æ¹å QSVM åé¡æè½ã</paragraph>

##### **Enhancing Semantic Segmentation with Adaptive Focal Loss: A Novel Approach**
2407.09828v1 by Md Rakibul Islam, Riad Hassan, Abdullah Nazib, Kien Nguyen, Clinton Fookes, Md Zahidul Islam

Deep learning has achieved outstanding accuracy in medical image
segmentation, particularly for objects like organs or tumors with smooth
boundaries or large sizes. Whereas, it encounters significant difficulties with
objects that have zigzag boundaries or are small in size, leading to a notable
decrease in segmentation effectiveness. In this context, using a loss function
that incorporates smoothness and volume information into a model's predictions
offers a promising solution to these shortcomings. In this work, we introduce
an Adaptive Focal Loss (A-FL) function designed to mitigate class imbalance by
down-weighting the loss for easy examples that results in up-weighting the loss
for hard examples and giving greater emphasis to challenging examples, such as
small and irregularly shaped objects. The proposed A-FL involves dynamically
adjusting a focusing parameter based on an object's surface smoothness, size
information, and adjusting the class balancing parameter based on the ratio of
targeted area to total area in an image. We evaluated the performance of the
A-FL using ResNet50-encoded U-Net architecture on the Picai 2022 and BraTS 2018
datasets. On the Picai 2022 dataset, the A-FL achieved an Intersection over
Union (IoU) of 0.696 and a Dice Similarity Coefficient (DSC) of 0.769,
outperforming the regular Focal Loss (FL) by 5.5% and 5.4% respectively. It
also surpassed the best baseline Dice-Focal by 2.0% and 1.2%. On the BraTS 2018
dataset, A-FL achieved an IoU of 0.883 and a DSC of 0.931. The comparative
studies show that the proposed A-FL function surpasses conventional methods,
including Dice Loss, Focal Loss, and their hybrid variants, in IoU, DSC,
Sensitivity, and Specificity metrics. This work highlights A-FL's potential to
improve deep learning models for segmenting clinically significant regions in
medical images, leading to more precise and reliable diagnostic tools.

æè¦ï¼æ·±åº¦å­¸ç¿å¨é«å­¸å½±ååå²æ¹é¢åå¾äºååºçæºç¢ºæ§ï¼ç¹å¥æ¯å°æ¼å·æå¹³æ»éçæå¤§å°ºå¯¸çå¨å®æè«ç¤ç­ç©é«ãç¶èï¼å°æ¼å·ææ²æéçæå°ºå¯¸å°çç©é«ï¼å®æéå°å¾å¤§çå°é£ï¼å°è´åå²ææé¡¯èä¸éãå¨æ­¤èæ¯ä¸ï¼ä½¿ç¨å°å¹³æ»åº¦åé«ç©è³è¨ç´å¥æ¨¡åé æ¸¬çæå¤±å½æ¸çºéäºç¼ºé»æä¾äºä¸åæå¸æçè§£æ±ºæ¹æ¡ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºä¸åèªé©æç¦é»æå¤± (A-FL) å½æ¸ï¼æ¨å¨éééä½ææ¼ç¯ä¾çæå¤±ä¾æ¸è¼é¡å¥å¤±è¡¡ï¼å¾èå¢å å°é£ç¯ä¾çæå¤±ï¼ä¸¦æ´å å¼·èª¿å·æææ°æ§çç¯ä¾ï¼ä¾å¦å°ä¸å½¢çä¸è¦åçç©é«ãææåºç A-FL æ¶åæ ¹æç©é«çè¡¨é¢å¹³æ»åº¦ãå°ºå¯¸è³è¨åæèª¿æ´èç¦åæ¸ï¼ä¸¦æ ¹æååä¸­ç®æ¨ååèç¸½ååçæ¯çèª¿æ´é¡å¥å¹³è¡¡åæ¸ãæåä½¿ç¨ ResNet50 ç·¨ç¢¼ç U-Net æ¶æ§å¨ Picai 2022 å BraTS 2018 è³æéä¸è©ä¼°äº A-FL çæè½ãå¨ Picai 2022 è³æéä¸ï¼A-FL çäº¤éæ¯è¯é (IoU) çº 0.696ï¼éª°å­ç¸ä¼¼æ§ä¿æ¸ (DSC) çº 0.769ï¼åå¥åªæ¼å¸¸è¦ç¦é»æå¤± (FL) 5.5% å 5.4%ãå®éè¶è¶äºæä½³åºæº Dice-Focal 2.0% å 1.2%ãå¨ BraTS 2018 è³æéä¸ï¼A-FL ç IoU çº 0.883ï¼DSC çº 0.931ãæ¯è¼ç ç©¶è¡¨æï¼ææåºç A-FL å½æ¸å¨ IoUãDSCãæææ§åç¹ç°æ§ææ¨ä¸åªæ¼å³çµ±æ¹æ³ï¼åæ¬ Dice æå¤±ãç¦é»æå¤±åå¶æ··åè®é«ãéé å·¥ä½çªåºäº A-FL å¨åå²é«å­¸å½±åä¸­å·æè¨åºæç¾©çååä»¥æ¹åæ·±åº¦å­¸ç¿æ¨¡åçæ½åï¼å¾èç¢çæ´ç²¾ç¢ºãæ´å¯é çè¨ºæ·å·¥å·ã

##### **Towards Personalised Patient Risk Prediction Using Temporal Hospital Data Trajectories**
2407.09373v1 by Thea Barnes, Enrico Werner, Jeffrey N. Clark, Raul Santos-Rodriguez

Quantifying a patient's health status provides clinicians with insight into
patient risk, and the ability to better triage and manage resources. Early
Warning Scores (EWS) are widely deployed to measure overall health status, and
risk of adverse outcomes, in hospital patients. However, current EWS are
limited both by their lack of personalisation and use of static observations.
We propose a pipeline that groups intensive care unit patients by the
trajectories of observations data throughout their stay as a basis for the
development of personalised risk predictions. Feature importance is considered
to provide model explainability. Using the MIMIC-IV dataset, six clusters were
identified, capturing differences in disease codes, observations, lengths of
admissions and outcomes. Applying the pipeline to data from just the first four
hours of each ICU stay assigns the majority of patients to the same cluster as
when the entire stay duration is considered. In-hospital mortality prediction
models trained on individual clusters had higher F1 score performance in five
of the six clusters when compared against the unclustered patient cohort. The
pipeline could form the basis of a clinical decision support tool, working to
improve the clinical characterisation of risk groups and the early detection of
patient deterioration.

æè¦ï¼éåæ£èçå¥åº·ç¶åµå¯è®©ä¸´åºå»çæ·±å¥äºè§£æ£èé£é©ï¼å¹¶è½æ´å¥½å°å¯¹èµæºè¿è¡åç±»åç®¡çãæ©æé¢è­¦è¯å (EWS) è¢«å¹¿æ³ç¨äºè¡¡éæ´ä½å¥åº·ç¶åµåä½é¢æ£èçä¸è¯åæé£é©ãç¶èï¼å½åç EWS åéäºå¶ç¼ºä¹ä¸ªæ§ååä½¿ç¨éæè§å¯ãæä»¬æåºäºä¸ä¸ªç®¡éï¼è¯¥ç®¡éæ ¹æ®æ£èå¨æ´ä¸ªä½é¢æé´çè§å¯æ°æ®è½¨è¿¹å¯¹éççæ¤çæ¿æ£èè¿è¡åç»ï¼ä½ä¸ºå¶å®ä¸ªæ§åé£é©é¢æµçåºç¡ãç¹å¾éè¦æ§è¢«èèä¸ºæä¾æ¨¡åå¯è§£éæ§ãä½¿ç¨ MIMIC-IV æ°æ®éï¼è¯å«åºå­ä¸ªéç¾¤ï¼ææç¾çä»£ç ãè§å¯ãå¥é¢æ¶é´åç»æçå·®å¼ãå°ç®¡éåºç¨äºæ¯ä¸ª ICU ä½é¢çååä¸ªå°æ¶çæ°æ®æ¶ï¼å°å¤§å¤æ°æ£èåéå°ä¸èèæ´ä¸ªä½é¢æ¶é´æ¶ç¸åçéç¾¤ãå¨äºä¸ªéç¾¤ä¸­ï¼éå¯¹åä¸ªéç¾¤è®­ç»çé¢åæ­»äº¡çé¢æµæ¨¡åä¸æªåç»æ£èéåç¸æ¯å·ææ´é«ç F1 åæ°è¡¨ç°ãè¯¥ç®¡éå¯ä»¥å½¢æä¸´åºå³ç­æ¯æå·¥å·çåºç¡ï¼ç¨äºæ¹åé£é©ç»çä¸´åºè¡¨å¾åæ£èæ¶åçæ©ææ£æµã

##### **Enhancing Depressive Post Detection in Bangla: A Comparative Study of TF-IDF, BERT and FastText Embeddings**
2407.09187v1 by Saad Ahmed Sazan, Mahdi H. Miraz, A B M Muntasir Rahman

Due to massive adoption of social media, detection of users' depression
through social media analytics bears significant importance, particularly for
underrepresented languages, such as Bangla. This study introduces a
well-grounded approach to identify depressive social media posts in Bangla, by
employing advanced natural language processing techniques. The dataset used in
this work, annotated by domain experts, includes both depressive and
non-depressive posts, ensuring high-quality data for model training and
evaluation. To address the prevalent issue of class imbalance, we utilised
random oversampling for the minority class, thereby enhancing the model's
ability to accurately detect depressive posts. We explored various numerical
representation techniques, including Term Frequency-Inverse Document Frequency
(TF-IDF), Bidirectional Encoder Representations from Transformers (BERT)
embedding and FastText embedding, by integrating them with a deep
learning-based Convolutional Neural Network-Bidirectional Long Short-Term
Memory (CNN-BiLSTM) model. The results obtained through extensive
experimentation, indicate that the BERT approach performed better the others,
achieving a F1-score of 84%. This indicates that BERT, in combination with the
CNN-BiLSTM architecture, effectively recognises the nuances of Bangla texts
relevant to depressive contents. Comparative analysis with the existing
state-of-the-art methods demonstrates that our approach with BERT embedding
performs better than others in terms of evaluation metrics and the reliability
of dataset annotations. Our research significantly contribution to the
development of reliable tools for detecting depressive posts in the Bangla
language. By highlighting the efficacy of different embedding techniques and
deep learning models, this study paves the way for improved mental health
monitoring through social media platforms.

æè¦ï¼<paragraph>ç±æ¼ç¤¾ç¾¤åªé«çå»£æ³æ¡ç¨ï¼ééç¤¾ç¾¤åªé«åæä¾åµæ¸¬ä½¿ç¨èçæé¬±çå·æéè¦çæç¾©ï¼ç¹å¥æ¯å°æ¼å­å æèªç­ä»£è¡¨æ§ä¸è¶³çèªè¨ãæ¬ç ç©¶ä»ç´¹äºä¸ç¨®ææ ¹æçæ¹æ³ä¾è­å¥å­å æèªä¸­çæé¬±ç¤¾ç¾¤åªé«è²¼æï¼æ¹æ³æ¯æ¡ç¨åé²çèªç¶èªè¨èçæè¡ãæ¬ç ç©¶ä¸­æä½¿ç¨çè³æéç±é åå°å®¶è¨»è§£ï¼åæ¬æé¬±åéæé¬±è²¼æï¼ç¢ºä¿æ¨¡åè¨ç·´åè©ä¼°è³æçé«åè³ªãçºäºè§£æ±ºé¡å¥ä¸å¹³è¡¡çæ®éåé¡ï¼æåå°å°æ¸é¡å¥æ¡ç¨é¨æ©éåº¦åæ¨£ï¼å¾èå¢å¼·æ¨¡åæºç¢ºåµæ¸¬æé¬±è²¼æçè½åãæåæ¢è¨äºåç¨®æ¸å¼è¡¨ç¤ºæè¡ï¼åæ¬è©é »-éæä»¶é »ç (TF-IDF)ãTransformer (BERT) åµå¥çéåç·¨ç¢¼å¨è¡¨ç¤ºå FastText åµå¥ï¼ä¸¦å°å®åèåºæ¼æ·±åº¦å­¸ç¿çå·ç©ç¥ç¶ç¶²è·¯-éåé·ç­æè¨æ¶ (CNN-BiLSTM) æ¨¡åæ´åå¨ä¸èµ·ãééå»£æ³çå¯¦é©æç²å¾ççµæé¡¯ç¤ºï¼BERT æ¹æ³çè¡¨ç¾åªæ¼å¶ä»æ¹æ³ï¼éå°äº 84% ç F1 åæ¸ãéè¡¨ç¤º BERT è CNN-BiLSTM æ¶æ§ç¸çµåï¼å¯ä»¥ææè­å¥èæé¬±å§å®¹ç¸éçå­å æèªææ¬çç´°å¾®å·®å¥ãèç¾æçæåé²æ¹æ³é²è¡æ¯è¼åæï¼è­ææåæ¡ç¨ BERT åµå¥çæ¹æ³å¨è©ä¼°ææ¨åè³æéè¨»è§£çå¯é æ§æ¹é¢åªæ¼å¶ä»æ¹æ³ãæåçç ç©¶çºéç¼ç¨æ¼åµæ¸¬å­å æèªä¸­æé¬±è²¼æçå¯é å·¥å·ååºäºéå¤§è²¢ç»ãééå¼·èª¿ä¸ååµå¥æè¡åæ·±åº¦å­¸ç¿æ¨¡åçæè½ï¼æ¬ç ç©¶çºééç¤¾ç¾¤åªé«å¹³å°æ¹åå¿çå¥åº·ç£æ§éªå¹³äºéè·¯ã</paragraph>

##### **STD-LLM: Understanding Both Spatial and Temporal Properties of Spatial-Temporal Data with LLMs**
2407.09096v1 by Yiheng Huang, Xiaowei Mao, Shengnan Guo, Yubin Chen, Youfang Lin, Huaiyu Wan

Spatial-temporal forecasting and imputation are important for real-world
dynamic systems such as intelligent transportation, urban planning, and public
health. Most existing methods are tailored for individual forecasting or
imputation tasks but are not designed for both. Additionally, they are less
effective for zero-shot and few-shot learning. While large language models
(LLMs) have exhibited strong pattern recognition and reasoning abilities across
various tasks, including few-shot and zero-shot learning, their development in
understanding spatial-temporal data has been constrained by insufficient
modeling of complex correlations such as the temporal correlations, spatial
connectivity, non-pairwise and high-order spatial-temporal correlations within
data. In this paper, we propose STD-LLM for understanding both spatial and
temporal properties of \underline{S}patial-\underline{T}emporal
\underline{D}ata with \underline{LLM}s, which is capable of implementing both
spatial-temporal forecasting and imputation tasks. STD-LLM understands
spatial-temporal correlations via explicitly designed spatial and temporal
tokenizers as well as virtual nodes. Topology-aware node embeddings are
designed for LLMs to comprehend and exploit the topology structure of data.
Additionally, to capture the non-pairwise and higher-order correlations, we
design a hypergraph learning module for LLMs, which can enhance the overall
performance and improve efficiency. Extensive experiments demonstrate that
STD-LLM exhibits strong performance and generalization capabilities across the
forecasting and imputation tasks on various datasets. Moreover, STD-LLM
achieves promising results on both few-shot and zero-shot learning tasks.

æè¦ï¼æç©ºé æ¸¬åå¡«è£å°æ¼æºæ§äº¤éãé½å¸è¨ç«åå¬å±è¡çç­çå¯¦ä¸çåæç³»çµ±ä¾èªªå¾éè¦ãç¾ææ¹æ³å¤§å¤æ¯éå°åå¥é æ¸¬æå¡«è£ä»»åéèº«æé ï¼ä½ä¸¦ééå°å©èè¨­è¨ãæ­¤å¤ï¼å®åå°æ¼é¶æ¬¡å­¸ç¿åå°æ¬¡å­¸ç¿çææè¼å·®ãåç®¡å¤§åèªè¨æ¨¡å (LLM) å·²å¨åç¨®ä»»åä¸­å±ç¾å¼·å¤§çæ¨¡å¼è­å¥åæ¨çè½åï¼åæ¬å°æ¬¡å­¸ç¿åé¶æ¬¡å­¸ç¿ï¼ä½å®åå¨çè§£æç©ºè³ææ¹é¢çç¼å±åå°éå¶ï¼åå æ¯å°è¤ééè¯æ§çå»ºæ¨¡ä¸è¶³ï¼ä¾å¦è³æä¸­çæééè¯æ§ãç©ºéé£éæ§ãéæå°åé«éæç©ºéè¯æ§ãå¨æ¬æä¸­ï¼æåæåº STD-LLMï¼ç¨æ¼äºè§£æç©ºè³æçç©ºéåæéå±¬æ§ï¼ä¸¦å·åå·è¡æç©ºé æ¸¬åå¡«è£ä»»åçè½åãSTD-LLM ééæç¢ºè¨­è¨çç©ºéåæéæ¨è¨åå¨ä»¥åèæ¬ç¯é»ä¾äºè§£æç©ºéè¯æ§ãææ²æç¥ç¯é»åµå¥æ¯çº LLM è¨­è¨çï¼ç¨æ¼çè§£åå©ç¨è³æçææ²çµæ§ãæ­¤å¤ï¼çºäºææéæå°åé«ééè¯æ§ï¼æåçº LLM è¨­è¨äºä¸åè¶åå­¸ç¿æ¨¡çµï¼å¯ä»¥æåæ´é«æè½ä¸¦æ¹åæçãå¤§éçå¯¦é©è­æ STD-LLM å¨åç¨®è³æéçé æ¸¬åå¡«è£ä»»åä¸­å±ç¾åºå¼·å¤§çæè½åæ³åè½åãæ­¤å¤ï¼STD-LLM å¨å°æ¬¡å­¸ç¿åé¶æ¬¡å­¸ç¿ä»»åä¸­é½åå¾äºä»¤äººæ»¿æçææã

##### **FD-SOS: Vision-Language Open-Set Detectors for Bone Fenestration and Dehiscence Detection from Intraoral Images**
2407.09088v1 by Marawan Elbatel, Keyuan Liu, Yanqi Yang, Xiaomeng Li

Accurate detection of bone fenestration and dehiscence (FD) is crucial for
effective treatment planning in dentistry. While cone-beam computed tomography
(CBCT) is the gold standard for evaluating FD, it comes with limitations such
as radiation exposure, limited accessibility, and higher cost compared to
intraoral images. In intraoral images, dentists face challenges in the
differential diagnosis of FD. This paper presents a novel and clinically
significant application of FD detection solely from intraoral images. To
achieve this, we propose FD-SOS, a novel open-set object detector for FD
detection from intraoral images. FD-SOS has two novel components: conditional
contrastive denoising (CCDN) and teeth-specific matching assignment (TMA).
These modules enable FD-SOS to effectively leverage external dental semantics.
Experimental results showed that our method outperformed existing detection
methods and surpassed dental professionals by 35% recall under the same level
of precision. Code is available at: https://github.com/xmed-lab/FD-SOS.

æè¦ï¼éª¨éª¼ç©¿å­åéª¨ç¼ºæ (FD) çæºç¢ºåµæ¸¬å°æ¼çç§çæææ²»çè¨ç«è³ééè¦ãéå½¢æé»è¦æ·å±¤ææ (CBCT) éç¶æ¯è©ä¼° FD çé»éæ¨æºï¼ä½å®å­å¨èè«¸å¦è¼»å°æé²ãåå¾ä¸æåèå£èå§å½±åç¸æ¯ææ¬è¼é«ç­éå¶ãå¨å£èå§å½±åä¸­ï¼çé«å¸«å¨ FD çéå¥è¨ºæ·ä¸­é¢è¨ææ°ãæ¬ææåºäºä¸ååµæ°ä¸è¨åºä¸éè¦çæç¨ï¼å¯åå¾å£èå§å½±åä¸­åµæ¸¬ FDãçºéææ­¤ç®æ¨ï¼æåæåº FD-SOSï¼éæ¯ä¸ç¨®ç¨æ¼å¾å£èå§å½±åä¸­åµæ¸¬ FD çæ°åéæ¾å¼ç©ä»¶åµæ¸¬å¨ãFD-SOS æå©åæ°ç©ççµæé¨åï¼æ¢ä»¶å°æ¯å»åª (CCDN) åç¹å®æ¼çé½çå¹éæå® (TMA)ãéäºæ¨¡çµä½¿ FD-SOS è½ææå©ç¨å¤é¨çç§èªç¾©ãå¯¦é©çµæé¡¯ç¤ºï¼æåçæè¡åªæ¼ç¾æçåµæ¸¬æè¡ï¼ä¸å¨ç¸åçæºç¢ºåº¦ä¸ï¼æ¯çç§å°æ¥­äººå¡é«åº 35% çå¬åçãç¨å¼ç¢¼å¯å¨ https://github.com/xmed-lab/FD-SOS åå¾ã

##### **Heterogeneous Subgraph Network with Prompt Learning for Interpretable Depression Detection on Social Media**
2407.09019v1 by Chen Chen, Mingwei Li, Fenghuan Li, Haopeng Chen, Yuankun Lin

Massive social media data can reflect people's authentic thoughts, emotions,
communication, etc., and therefore can be analyzed for early detection of
mental health problems such as depression. Existing works about early
depression detection on social media lacked interpretability and neglected the
heterogeneity of social media data. Furthermore, they overlooked the global
interaction among users. To address these issues, we develop a novel method
that leverages a Heterogeneous Subgraph Network with Prompt Learning(HSNPL) and
contrastive learning mechanisms. Specifically, prompt learning is employed to
map users' implicit psychological symbols with excellent interpretability while
deep semantic and diverse behavioral features are incorporated by a
heterogeneous information network. Then, the heterogeneous graph network with a
dual attention mechanism is constructed to model the relationships among
heterogeneous social information at the feature level. Furthermore, the
heterogeneous subgraph network integrating subgraph attention and
self-supervised contrastive learning is developed to explore complicated
interactions among users and groups at the user level. Extensive experimental
results demonstrate that our proposed method significantly outperforms
state-of-the-art methods for depression detection on social media.

æè¦ï¼é¾å¤§çç¤¾ç¾¤åªé«è³æå¯ä»¥åæ äººåçå¯¦çæ³æ³ãæç·ãæºéç­ï¼å æ­¤å¯ä»¥åæéäºè³æï¼ä»¥æ©æåµæ¸¬æé¬±çç­å¿çå¥åº·åé¡ãç¾æéæ¼ç¤¾ç¾¤åªé«ä¸æ©ææé¬±çåµæ¸¬çç ç©¶ç¼ºä¹å¯è§£éæ§ï¼ä¸å¿½ç¥äºç¤¾ç¾¤åªé«è³æçç°è³ªæ§ãæ­¤å¤ï¼éäºç ç©¶å¿½è¦äºä½¿ç¨èä¹éçæ´é«äºåãçºäºè§£æ±ºéäºåé¡ï¼æåéç¼äºä¸ç¨®æ°ç©çæ¹æ³ï¼éç¨®æ¹æ³å©ç¨å¸¶ææç¤ºå­¸ç¿ï¼HSNPLï¼çç°è³ªå­åç¶²è·¯åå°æ¯å­¸ç¿æ©å¶ãå·é«èè¨ï¼æç¤ºå­¸ç¿è¢«ç¨æ¼ç¹ªè£½ä½¿ç¨èå·æåºè²å¯è§£éæ§çé±å«å¿çç¬¦èï¼åæééç°è³ªè³è¨ç¶²è·¯æ´åäºæ·±å±¤èªç¾©åå¤æ¨£åçè¡çºç¹å¾µãç¶å¾ï¼æ§å»ºå·æééæ³¨ææ©å¶çç°è³ªåç¶²è·¯ï¼ä»¥å¨ç¹å¾µå±¤ç´å»ºæ¨¡ç°è³ªç¤¾ç¾¤è³è¨ä¹éçéä¿ãæ­¤å¤ï¼éç¼äºæ´åå­åæ³¨æåèªæç£ç£å°æ¯å­¸ç¿çç°è³ªå­åç¶²è·¯ï¼ä»¥æ¢ç´¢ä½¿ç¨èåç¾¤çµä¹éå¨ä½¿ç¨èå±¤ç´çè¤éäºåãå¤§éçå¯¦é©çµæè¡¨æï¼æåæåºçæ¹æ³å¨ç¤¾ç¾¤åªé«ä¸çæé¬±çåµæ¸¬æ¹é¢é¡¯èåªæ¼æåé²çæ¹æ³ã

##### **Application of Artificial Intelligence in Supporting Healthcare Professionals and Caregivers in Treatment of Autistic Children**
2407.08902v1 by Hossein Mohammadi Rouzbahani, Hadis Karimipour

Autism Spectrum Disorder (ASD) represents a multifaceted neurodevelopmental
condition marked by difficulties in social interaction, communication
impediments, and repetitive behaviors. Despite progress in understanding ASD,
its diagnosis and treatment continue to pose significant challenges due to the
variability in symptomatology and the necessity for multidisciplinary care
approaches. This paper investigates the potential of Artificial Intelligence
(AI) to augment the capabilities of healthcare professionals and caregivers in
managing ASD. We have developed a sophisticated algorithm designed to analyze
facial and bodily expressions during daily activities of both autistic and
non-autistic children, leading to the development of a powerful deep
learning-based autism detection system. Our study demonstrated that AI models,
specifically the Xception and ResNet50V2 architectures, achieved high accuracy
in diagnosing Autism Spectrum Disorder (ASD). This research highlights the
transformative potential of AI in improving the diagnosis, treatment, and
comprehensive management of ASD. Our study revealed that AI models, notably the
Xception and ResNet50V2 architectures, demonstrated high accuracy in diagnosing
ASD.

æè¦ï¼èªéçè­ç³»éç¤ (ASD) æ¯ä¸ç¨®å¤é¢åçç¥ç¶ç¼å±çæ³ï¼å¶ç¹å¾µå¨æ¼ç¤¾äº¤äºåå°é£ãæºééç¤åéè¤æ§è¡çºãåç®¡å¨äºè§£ ASD æ¹é¢åå¾é²å±ï¼ä½ç±æ¼çççå¤è®æ§åå°è·¨é åç§è­·æ¹æ³çå¿è¦æ§ï¼å¶è¨ºæ·åæ²»çä»ç¶æ§æéå¤§ææ°ãæ¬ææ¢è¨äººå·¥æºæ§ (AI) å¨æ´å¢é«çä¿å¥å°æ¥­äººå¡åç§è­·èç®¡ç ASD è½åæ¹é¢çæ½åãæåéç¼äºä¸ç¨®ç²¾å¯æ¼ç®æ³ï¼æ¨å¨åæèªéçåéèªéçåç«¥å¨æ¥å¸¸æ´»åä¸­çé¢é¨åèº«é«è¡¨æï¼é²èéç¼åºåè½å¼·å¤§çæ·±åº¦å­¸ç¿èªéçåµæ¸¬ç³»çµ±ãæåçç ç©¶è¡¨æï¼AI æ¨¡åï¼ç¹å¥æ¯ Xception å ResNet50V2 æ¶æ§ï¼å¨è¨ºæ·èªéçè­ç³»éç¤ (ASD) æ¹é¢åå¾é«æºç¢ºåº¦ãéé ç ç©¶çªé¡¯äº AI å¨æ¹å ASD è¨ºæ·ãæ²»çåå¨é¢ç®¡çæ¹é¢çè®é©æ½åãæåçç ç©¶æ­ç¤ºï¼AI æ¨¡åï¼ç¹å¥æ¯ Xception å ResNet50V2 æ¶æ§ï¼å¨è¨ºæ· ASD æ¹é¢è¡¨ç¾åºé«æºç¢ºåº¦ã

##### **SALT: Introducing a Framework for Hierarchical Segmentations in Medical Imaging using Softmax for Arbitrary Label Trees**
2407.08878v1 by Sven Koitka, Giulia Baldini, Cynthia S. Schmidt, Olivia B. Pollok, Obioma Pelka, Judith Kohnke, Katarzyna Borys, Christoph M. Friedrich, Benedikt M. Schaarschmidt, Michael Forsting, Lale Umutlu, Johannes Haubold, Felix Nensa, RenÃ© Hosch

Traditional segmentation networks approach anatomical structures as
standalone elements, overlooking the intrinsic hierarchical connections among
them. This study introduces Softmax for Arbitrary Label Trees (SALT), a novel
approach designed to leverage the hierarchical relationships between labels,
improving the efficiency and interpretability of the segmentations.
  This study introduces a novel segmentation technique for CT imaging, which
leverages conditional probabilities to map the hierarchical structure of
anatomical landmarks, such as the spine's division into lumbar, thoracic, and
cervical regions and further into individual vertebrae. The model was developed
using the SAROS dataset from The Cancer Imaging Archive (TCIA), comprising 900
body region segmentations from 883 patients. The dataset was further enhanced
by generating additional segmentations with the TotalSegmentator, for a total
of 113 labels. The model was trained on 600 scans, while validation and testing
were conducted on 150 CT scans. Performance was assessed using the Dice score
across various datasets, including SAROS, CT-ORG, FLARE22, LCTSC, LUNA16, and
WORD.
  Among the evaluated datasets, SALT achieved its best results on the LUNA16
and SAROS datasets, with Dice scores of 0.93 and 0.929 respectively. The model
demonstrated reliable accuracy across other datasets, scoring 0.891 on CT-ORG
and 0.849 on FLARE22. The LCTSC dataset showed a score of 0.908 and the WORD
dataset also showed good performance with a score of 0.844.
  SALT used the hierarchical structures inherent in the human body to achieve
whole-body segmentations with an average of 35 seconds for 100 slices. This
rapid processing underscores its potential for integration into clinical
workflows, facilitating the automatic and efficient computation of full-body
segmentations with each CT scan, thus enhancing diagnostic processes and
patient care.

æè¦ï¼<paragraph>å³çµ±çåå²ç¶²è·¯å°è§£åçµæ§è¦çºç¨ç«åç´ ï¼å¿½ç¥äºå®åä¹éåºæçå±¤ç´é£æ¥ãæ¬ç ç©¶å¼å¥äºä»»ææ¨ç±¤æ¨¹ç Softmax (SALT)ï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼æ¨å¨å©ç¨æ¨ç±¤ä¹éçå±¤ç´éä¿ï¼æé«åå²çæçåå¯è§£éæ§ã
æ¬ç ç©¶å¼å¥äºä¸ç¨®æ°ç CT å½±ååå²æè¡ï¼å®å©ç¨æ¢ä»¶æ©çä¾å°è§£åæ¨èªçå±¤ç´çµæ§é²è¡å°æï¼ä¾å¦å°èæ¤åçºè°æ¤ãè¸æ¤åé ¸æ¤ååï¼ä¸¦é²ä¸æ­¥åçºåå¥æ¤éª¨ãè©²æ¨¡åæ¯ä½¿ç¨ççå½±åæªæ¡é¤¨ (TCIA) ä¸­ç SAROS è³æééç¼çï¼å¶ä¸­åå«ä¾èª 883 ä½æ£èç 900 åèº«é«åååå²ãè©²è³æéé²ä¸æ­¥éé TotalSegmentator çæäºé¡å¤çåå²ï¼ç¸½å± 113 åæ¨ç±¤ãè©²æ¨¡åå¨ 600 æ¬¡ææä¸­æ¥åäºè¨ç·´ï¼èé©è­åæ¸¬è©¦åå¨ 150 æ¬¡ CT ææä¸­é²è¡ãæè½ä½¿ç¨ Dice åæ¸å¨åç¨®è³æéä¸é²è¡è©ä¼°ï¼åæ¬ SAROSãCT-ORGãFLARE22ãLCTSCãLUNA16 å WORDã
å¨è©ä¼°çè³æéä¸­ï¼SALT å¨ LUNA16 å SAROS è³æéä¸åå¾äºæä½³çµæï¼Dice åæ¸åå¥çº 0.93 å 0.929ãè©²æ¨¡åå¨å¶ä»è³æéä¸è¡¨ç¾åºå¯é çæºç¢ºæ§ï¼å¨ CT-ORG ä¸å¾åçº 0.891ï¼å¨ FLARE22 ä¸å¾åçº 0.849ãLCTSC è³æéçå¾åçº 0.908ï¼WORD è³æéçè¡¨ç¾ä¹å¾å¥½ï¼å¾åçº 0.844ã
SALT å©ç¨äººé«åºæçå±¤ç´çµæ§ï¼ä»¥å¹³å 35 ç§çæéå° 100 ååçé²è¡å¨èº«åå²ãéç¨®å¿«éèççªé¡¯äºå®æ´åå°è¨åºå·¥ä½æµç¨ä¸­çæ½åï¼ä¿é²äºæ¯æ¬¡ CT ææçå¨èº«åå²çèªåååé«æè¨ç®ï¼å¾èå¢å¼·äºè¨ºæ·éç¨åæ£èè­·çã</paragraph>

##### **FedMedICL: Towards Holistic Evaluation of Distribution Shifts in Federated Medical Imaging**
2407.08822v1 by Kumail Alhamoud, Yasir Ghunaim, Motasem Alfarra, Thomas Hartvigsen, Philip Torr, Bernard Ghanem, Adel Bibi, Marzyeh Ghassemi

For medical imaging AI models to be clinically impactful, they must
generalize. However, this goal is hindered by (i) diverse types of distribution
shifts, such as temporal, demographic, and label shifts, and (ii) limited
diversity in datasets that are siloed within single medical institutions. While
these limitations have spurred interest in federated learning, current
evaluation benchmarks fail to evaluate different shifts simultaneously.
However, in real healthcare settings, multiple types of shifts co-exist, yet
their impact on medical imaging performance remains unstudied. In response, we
introduce FedMedICL, a unified framework and benchmark to holistically evaluate
federated medical imaging challenges, simultaneously capturing label,
demographic, and temporal distribution shifts. We comprehensively evaluate
several popular methods on six diverse medical imaging datasets (totaling 550
GPU hours). Furthermore, we use FedMedICL to simulate COVID-19 propagation
across hospitals and evaluate whether methods can adapt to pandemic changes in
disease prevalence. We find that a simple batch balancing technique surpasses
advanced methods in average performance across FedMedICL experiments. This
finding questions the applicability of results from previous, narrow benchmarks
in real-world medical settings.

æè¦ï¼çºäºè®é«å­¸å½±å AI æ¨¡åå¨è¨åºä¸ç¢çå½±é¿ï¼å®åå¿é å·åæ³åæ§ãç¶èï¼æ­¤ç®æ¨åå° (i) åä½è½ç§»çä¸åé¡åï¼ä¾å¦æéãäººå£çµ±è¨åæ¨ç±¤è½ç§»ï¼ä»¥å (ii) ä¾·éæ¼å®ä¸é«çæ©æ§å§è³æéçå¤æ¨£æ§æé»ç¤ãåç®¡éäºéå¶æ¿ç¼äºå°è¯åå­¸ç¿çèè¶£ï¼ä½ç®åçè©ä¼°åºæºç¡æ³åæè©ä¼°ä¸åçè½ç§»ãç¶èï¼å¨å¯¦éçé«çä¿å¥ç°å¢ä¸­ï¼å¤ç¨®é¡åçè½ç§»åæå­å¨ï¼ä½å®åå°é«å­¸å½±åæè½çå½±é¿ä»æªå¾å°ç ç©¶ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äº FedMedICLï¼ä¸åçµ±ä¸çæ¶æ§ååºæºï¼ä»¥å¨é¢è©ä¼°è¯åé«å­¸å½±åææ°ï¼åææææ¨ç±¤ãäººå£çµ±è¨åæéåä½è½ç§»ãæåå¨å­åä¸åçé«å­¸å½±åè³æéï¼ç¸½è¨ 550 å GPU å°æï¼ä¸å¨é¢è©ä¼°äºå¹¾ç¨®æµè¡çæ¹æ³ãæ­¤å¤ï¼æåä½¿ç¨ FedMedICL æ¨¡æ¬äº COVID-19 å¨é«é¢éçå³æ­ï¼ä¸¦è©ä¼°æ¹æ³æ¯å¦è½é©æç¾ççè¡ççæµè¡çè®åãæåç¼ç¾ï¼ä¸åç°¡å®çæ¹æ¬¡å¹³è¡¡æè¡å¨ FedMedICL å¯¦é©ä¸­è¶è¶äºåé²çæ¹æ³çå¹³åæè½ãæ­¤ç¼ç¾è³ªçäºååç¹éåºæºå¨ç¾å¯¦ä¸çé«çç°å¢ä¸­çµæçé©ç¨æ§ã

##### **FairDomain: Achieving Fairness in Cross-Domain Medical Image Segmentation and Classification**
2407.08813v1 by Yu Tian, Congcong Wen, Min Shi, Muhammad Muneeb Afzal, Hao Huang, Muhammad Osama Khan, Yan Luo, Yi Fang, Mengyu Wang

Addressing fairness in artificial intelligence (AI), particularly in medical
AI, is crucial for ensuring equitable healthcare outcomes. Recent efforts to
enhance fairness have introduced new methodologies and datasets in medical AI.
However, the fairness issue under the setting of domain transfer is almost
unexplored, while it is common that clinics rely on different imaging
technologies (e.g., different retinal imaging modalities) for patient
diagnosis. This paper presents FairDomain, a pioneering systemic study into
algorithmic fairness under domain shifts, employing state-of-the-art domain
adaptation (DA) and generalization (DG) algorithms for both medical
segmentation and classification tasks to understand how biases are transferred
between different domains. We also introduce a novel plug-and-play fair
identity attention (FIA) module that adapts to various DA and DG algorithms to
improve fairness by using self-attention to adjust feature importance based on
demographic attributes. Additionally, we curate the first fairness-focused
dataset with two paired imaging modalities for the same patient cohort on
medical segmentation and classification tasks, to rigorously assess fairness in
domain-shift scenarios. Excluding the confounding impact of demographic
distribution variation between source and target domains will allow clearer
quantification of the performance of domain transfer models. Our extensive
evaluations reveal that the proposed FIA significantly enhances both model
performance accounted for fairness across all domain shift settings (i.e., DA
and DG) with respect to different demographics, which outperforms existing
methods on both segmentation and classification. The code and data can be
accessed at https://ophai.hms.harvard.edu/datasets/harvard-fairdomain20k.

æè¦ï¼<paragraph>å¨äººå·¥æºæ§ï¼AIï¼ï¼ç¹å¥æ¯é«ç AI ä¸­è§£æ±ºå¬å¹³æ§å°æ¼ç¢ºä¿å¬å¹³çé«çä¿å¥çµæè³ééè¦ãæè¿æåå¬å¹³æ§çåªåå¼å¥äºæ°çæ¹æ³åé«ç AI ä¸­çè³æéãç¶èï¼å¨ç¶²åè½ç§»çè¨­å®ä¸å¬å¹³æ§çè­°é¡å¹¾ä¹æªç¶æ¢è¨ï¼èè¨ºæéå¸¸ä»°è³´ä¸åçå½±åæè¡ï¼ä¾å¦ï¼ä¸åçè¦ç¶²èå½±åæ¹å¼ï¼é²è¡çæ£è¨ºæ·ãæ¬ææåº FairDomainï¼ä¸é éæ¼ç¶²åè½ç§»ä¸æ¼ç®æ³å¬å¹³æ§çåé©ç³»çµ±æ§ç ç©¶ï¼ä½¿ç¨æåé²çç¶²åé©æï¼DAï¼åæ¦åï¼DGï¼æ¼ç®æ³ï¼åæéå°é«çåå²ååé¡ä»»åï¼ä»¥äºè§£åè¦å¦ä½å¨ä¸åç¶²åéè½ç§»ãæåä¹ä»ç´¹äºä¸åæ°ç©çå³æå³ç¨å¬å¹³èº«åæ³¨æåï¼FIAï¼æ¨¡çµï¼å®é©ç¨æ¼åç¨® DA å DG æ¼ç®æ³ï¼ééä½¿ç¨èªææ³¨æåæ ¹æäººå£å±¬æ§èª¿æ´ç¹å¾µéè¦æ§ä¾æåå¬å¹³æ§ãæ­¤å¤ï¼æåç­åäºç¬¬ä¸åå¬å¹³æ§çºéé»çè³æéï¼å¶ä¸­åå«éå°ç¸åçæ£ç¾¤é«çå©ç¨®éå°å½±åæ¹å¼ï¼ç¨æ¼é«çåå²ååé¡ä»»åï¼ä»¥å´è¬¹è©ä¼°ç¶²åè½ç§»æå¢ä¸­çå¬å¹³æ§ãæé¤ä¾æºç¶²ååç®æ¨ç¶²åä¹éäººå£åä½è®ç°çæ··æ·å½±é¿ï¼å°è½æ´æ¸æ¥å°éåç¶²åè½ç§»æ¨¡åçæè½ãæåå»£æ³çè©ä¼°é¡¯ç¤ºï¼ææåºç FIA å¤§å¹æåäºèéå¬å¹³æ§çæ¨¡åæè½ï¼æ¶µèææç¶²åè½ç§»è¨­å®ï¼ä¾å¦ï¼DA å DGï¼ä»¥åä¸åäººå£çµ±è¨è³æï¼å¨åå²ååé¡æ¹é¢é½åªæ¼ç¾ææ¹æ³ãç¨å¼ç¢¼åè³æå¯æ¼ https://ophai.hms.harvard.edu/datasets/harvard-fairdomain20k åå¾ã</paragraph>

##### **Uncertainty Estimation of Large Language Models in Medical Question Answering**
2407.08662v1 by Jiaxin Wu, Yizhou Yu, Hong-Yu Zhou

Large Language Models (LLMs) show promise for natural language generation in
healthcare, but risk hallucinating factually incorrect information. Deploying
LLMs for medical question answering necessitates reliable uncertainty
estimation (UE) methods to detect hallucinations. In this work, we benchmark
popular UE methods with different model sizes on medical question-answering
datasets. Our results show that current approaches generally perform poorly in
this domain, highlighting the challenge of UE for medical applications. We also
observe that larger models tend to yield better results, suggesting a
correlation between model size and the reliability of UE. To address these
challenges, we propose Two-phase Verification, a probability-free Uncertainty
Estimation approach. First, an LLM generates a step-by-step explanation
alongside its initial answer, followed by formulating verification questions to
check the factual claims in the explanation. The model then answers these
questions twice: first independently, and then referencing the explanation.
Inconsistencies between the two sets of answers measure the uncertainty in the
original response. We evaluate our approach on three biomedical
question-answering datasets using Llama 2 Chat models and compare it against
the benchmarked baseline methods. The results show that our Two-phase
Verification method achieves the best overall accuracy and stability across
various datasets and model sizes, and its performance scales as the model size
increases.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨é«çä¿å¥é åçèªç¶èªè¨çææ¹é¢é¡¯ç¤ºåºåæ¯ï¼ä½å­å¨èæ§äºå¯¦ä¸æ­£ç¢ºè³è¨çé¢¨éªãé¨ç½² LLM ä¾åç­é«çåé¡éè¦å¯é çä¸ç¢ºå®æ§ä¼°è¨ (UE) æ¹æ³ä¾åµæ¸¬èæ§ãå¨éé å·¥ä½ä¸­ï¼æåä½¿ç¨ä¸åæ¨¡åå¤§å°å°ç±é UE æ¹æ³é²è¡åºæºæ¸¬è©¦ï¼éå°é«çåé¡åç­è³æéãæåççµæé¡¯ç¤ºï¼ç®åçä½æ³å¨éæ¹é¢éå¸¸è¡¨ç¾ä¸ä½³ï¼çªé¡¯äº UE å¨é«çæç¨ä¸­çææ°ãæåéè§å¯å°ï¼è¼å¤§çæ¨¡åå¾å¾æç¢çæ´å¥½ççµæï¼éè¡¨ææ¨¡åå¤§å°è UE çå¯é æ§ä¹éå­å¨ç¸éæ§ãçºäºæå°éäºææ°ï¼æåæåºäºå©éæ®µé©è­ï¼ä¸ç¨®ç¡æ©ççä¸ç¢ºå®æ§ä¼°è¨æ¹æ³ãé¦åï¼LLM æå¨å¶åå§ç­æ¡æéç¢çéæ­¥èªªæï¼ç¶å¾å¶å®é©è­åé¡ä¾æª¢æ¥èªªæä¸­çäºå¯¦è²æãç¶å¾ï¼æ¨¡ååç­éäºåé¡å©æ¬¡ï¼ç¬¬ä¸æ¬¡ç¨ç«åç­ï¼ç¶å¾åèèªªæãå©çµç­æ¡ä¹éçä¸ä¸è´æ§è¡¡éåå§åæä¸­çä¸ç¢ºå®æ§ãæåä½¿ç¨ Llama 2 Chat æ¨¡åå¨ä¸åçç©é«å­¸åé¡åç­è³æéä¸è©ä¼°æåçä½æ³ï¼ä¸¦å°å¶èåºæºåºæºæ¹æ³é²è¡æ¯è¼ãçµæé¡¯ç¤ºï¼æåçå©éæ®µé©è­æ¹æ³å¨åç¨®è³æéåæ¨¡åå¤§å°ä¸­å¯¦ç¾äºæä½³çæ´é«æºç¢ºæ§åç©©å®æ§ï¼ä¸¦ä¸å¶æè½é¨èæ¨¡åå¤§å°çå¢å èæ´å±ã

##### **Establishing Rigorous and Cost-effective Clinical Trials for Artificial Intelligence Models**
2407.08554v1 by Wanling Gao, Yunyou Huang, Dandan Cui, Zhuoming Yu, Wenjing Liu, Xiaoshuang Liang, Jiahui Zhao, Jiyue Xie, Hao Li, Li Ma, Ning Ye, Yumiao Kang, Dingfeng Luo, Peng Pan, Wei Huang, Zhongmou Liu, Jizhong Hu, Gangyuan Zhao, Chongrong Jiang, Fan Huang, Tianyi Wei, Suqin Tang, Bingjie Xia, Zhifei Zhang, Jianfeng Zhan

A profound gap persists between artificial intelligence (AI) and clinical
practice in medicine, primarily due to the lack of rigorous and cost-effective
evaluation methodologies. State-of-the-art and state-of-the-practice AI model
evaluations are limited to laboratory studies on medical datasets or direct
clinical trials with no or solely patient-centered controls. Moreover, the
crucial role of clinicians in collaborating with AI, pivotal for determining
its impact on clinical practice, is often overlooked. For the first time, we
emphasize the critical necessity for rigorous and cost-effective evaluation
methodologies for AI models in clinical practice, featuring
patient/clinician-centered (dual-centered) AI randomized controlled trials
(DC-AI RCTs) and virtual clinician-based in-silico trials (VC-MedAI) as an
effective proxy for DC-AI RCTs. Leveraging 7500 diagnosis records from
two-phase inaugural DC-AI RCTs across 14 medical centers with 125 clinicians,
our results demonstrate the necessity of DC-AI RCTs and the effectiveness of
VC-MedAI. Notably, VC-MedAI performs comparably to human clinicians,
replicating insights and conclusions from prospective DC-AI RCTs. We envision
DC-AI RCTs and VC-MedAI as pivotal advancements, presenting innovative and
transformative evaluation methodologies for AI models in clinical practice,
offering a preclinical-like setting mirroring conventional medicine, and
reshaping development paradigms in a cost-effective and fast-iterative manner.
Chinese Clinical Trial Registration: ChiCTR2400086816.

æè¦ï¼<paragraph>äººå·¥æºæ§ï¼AIï¼èè¨åºé«çå¯¦åä¹éå­å¨èå·¨å¤§çé´»æºï¼å¶ä¸»è¦åå å¨æ¼ç¼ºä¹å´è¬¹ä¸å·ææ¬æççè©ä¼°æ¹æ³ãæåé²ä¸ç¬¦åå¯¦åç AI æ¨¡åè©ä¼°åéæ¼éå°é«å­¸è³æéé²è¡çå¯¦é©å®¤ç ç©¶ï¼æåææ£èçºä¸­å¿çå°ç§çµçç´æ¥è¨åºè©¦é©ãæ­¤å¤ï¼è¨åºé«å¸«å¨è AI åä½ä¸­ææ®æ¼çééµè§è²ï¼å°æ¼æ±ºå®å¶å°è¨åºå¯¦åçå½±é¿è³ééè¦ï¼å»ç¶å¸¸è¢«å¿½è¦ãæåé¦åº¦å¼·èª¿å¨è¨åºå¯¦åä¸­æ¡ç¨å´è¬¹ä¸å·ææ¬æçç AI æ¨¡åè©ä¼°æ¹æ³è³ééè¦ï¼å¶ç¹è²å¨æ¼ä»¥æ£èï¼è¨åºé«å¸«çºä¸­å¿çï¼éä¸­å¿ï¼AI é¨æ©å°ç§è©¦é©ï¼DC-AI RCTï¼åèæ¬è¨åºé«å¸«çºåºç¤çé»è¦æ¨¡æ¬è©¦é©ï¼VC-MedAIï¼ï¼åçº DC-AI RCT çæææ¿ä»£æ¹æ¡ãå©ç¨ä¾èª 14 åé«çä¸­å¿ã125 ä½è¨åºé«å¸«çå©éæ®µé¦æ¬¡ DC-AI RCT ä¸­ç 7500 ç­è¨ºæ·ç´éï¼æåççµæè­æäº DC-AI RCT çå¿è¦æ§è VC-MedAI çæææ§ãå¼å¾æ³¨æçæ¯ï¼VC-MedAI çè¡¨ç¾èäººé¡è¨åºé«å¸«ç¸ç¶ï¼è¤è£½äºåç»æ§ DC-AI RCT çè¦è§£åçµè«ãæåå° DC-AI RCT å VC-MedAI è¦çºééµçé²å±ï¼å®åæåºäºåµæ°ä¸å·æè®é©æ§ç AI æ¨¡åè©ä¼°æ¹æ³ï¼å¨è¨åºå¯¦åä¸­æä¾é¡ä¼¼æ¼è¨åºåè¨­å®çç°å¢ï¼åæ å³çµ±é«å­¸ï¼ä¸¦ä»¥å·ææ¬æçä¸å¿«éåè¦éç®çæ¹å¼éæ°å¡é éç¼æ¨¡å¼ãä¸­åè¨åºè©¦é©è¨»åï¼ChiCTR2400086816ã</paragraph>

##### **How Deep is your Guess? A Fresh Perspective on Deep Learning for Medical Time-Series Imputation**
2407.08442v1 by Linglong Qian, Tao Wang, Jun Wang, Hugh Logan Ellis, Robin Mitra, Richard Dobson, Zina Ibrahim

We introduce a novel classification framework for time-series imputation
using deep learning, with a particular focus on clinical data. By identifying
conceptual gaps in the literature and existing reviews, we devise a taxonomy
grounded on the inductive bias of neural imputation frameworks, resulting in a
classification of existing deep imputation strategies based on their
suitability for specific imputation scenarios and data-specific properties. Our
review further examines the existing methodologies employed to benchmark deep
imputation models, evaluating their effectiveness in capturing the missingness
scenarios found in clinical data and emphasising the importance of reconciling
mathematical abstraction with clinical insights. Our classification aims to
serve as a guide for researchers to facilitate the selection of appropriate
deep learning imputation techniques tailored to their specific clinical data.
Our novel perspective also highlights the significance of bridging the gap
between computational methodologies and medical insights to achieve clinically
sound imputation models.

æè¦ï¼æåæåºäºä¸åæ°çæéåºåæè£åé¡æ¶æ§ï¼ä½¿ç¨æ·±åº¦å­¸ç¿ï¼ç¹å¥éæ³¨è¨åºæ¸æãééæ¾åºæç»åç¾æè©è«ä¸­çæ¦å¿µå·®è·ï¼æåè¨­è¨äºä¸ååé¡æ³ï¼è©²åé¡æ³åºæ¼ç¥ç¶æè£æ¡æ¶çæ­¸ç´åèª¤ï¼å¾èå°ç¾æçæ·±åº¦æè£ç­ç¥é²è¡åé¡ï¼åºæ¼å®åå°ç¹å®æè£å ´æ¯åæ¸æç¹å®å±¬æ§çé©ç¨æ§ãæåçåé¡§é²ä¸æ­¥æª¢é©äºç¨æ¼å°æ·±åº¦æè£æ¨¡åé²è¡åºæºæ¸¬è©¦çç¾ææ¹æ³ï¼è©ä¼°äºå®åå¨ææè¨åºæ¸æä¸­ç¼ç¾çç¼ºå¤±å ´æ¯æ¹é¢çæææ§ï¼ä¸¦å¼·èª¿äºèª¿åæ¸å­¸æ½è±¡èè¨åºè¦è§£çéè¦æ§ãæåçåé¡æ¨å¨ä½çºç ç©¶äººå¡çæåï¼ä»¥ä¿é²æ ¹æå¶ç¹å®è¨åºæ¸æé¸æé©ç¶çæ·±åº¦å­¸ç¿æè£æè¡ãæåçæ°è§é»éå¼·èª¿äºå½åè¨ç®æ¹æ³åé«å­¸è¦è§£ä¹éå·®è·ä»¥å¯¦ç¾è¨åºåçæè£æ¨¡åçéè¦æ§ã

##### **Specialist vision-language models for clinical ophthalmology**
2407.08410v1 by Robbie Holland, Thomas R. P. Taylor, Christopher Holmes, Sophie Riedl, Julia Mai, Maria Patsiamanidi, Dimitra Mitsopoulou, Paul Hager, Philip MÃ¼ller, Hendrik P. N. Scholl, Hrvoje BogunoviÄ, Ursula Schmidt-Erfurth, Daniel Rueckert, Sobha Sivaprasad, Andrew J. Lotery, Martin J. Menten

Clinicians spend a significant amount of time reviewing medical images and
transcribing their findings regarding patient diagnosis, referral and treatment
in text form. Vision-language models (VLMs), which automatically interpret
images and summarize their findings as text, have enormous potential to
alleviate clinical workloads and increase patient access to high-quality
medical care. While foundational models have stirred considerable interest in
the medical community, it is unclear whether their general capabilities
translate to real-world clinical utility. In this work, we show that foundation
VLMs markedly underperform compared to practicing ophthalmologists on
specialist tasks crucial to the care of patients with age-related macular
degeneration (AMD). To address this, we initially identified the essential
capabilities required for image-based clinical decision-making, and then
developed a curriculum to selectively train VLMs in these skills. The resulting
model, RetinaVLM, can be instructed to write reports that significantly
outperform those written by leading foundation medical VLMs in disease staging
(F1 score of 0.63 vs. 0.11) and patient referral (0.67 vs. 0.39), and
approaches the diagnostic performance of junior ophthalmologists (who achieve
0.77 and 0.78 on the respective tasks). Furthermore, in a reader study
involving two senior ophthalmologists with up to 32 years of experience,
RetinaVLM's reports were found to be similarly correct (78.6% vs. 82.1%) and
complete (both 78.6%) as reports written by junior ophthalmologists with up to
10 years of experience. These results demonstrate that our curriculum-based
approach provides a blueprint for specializing generalist foundation medical
VLMs to handle real-world clinical tasks.

æè¦ï¼<paragraph>è¨åºé«çè±è²»å¤§éæéæª¢é±é«çå½±åï¼ä¸¦ä»¥æå­å½¢å¼è¨éä»åéæ¼æ£èè¨ºæ·ãè½è¨ºåæ²»ççç¼ç¾ãè¦è¦ºèªè¨æ¨¡å (VLM) æèªåè§£è®å½±åä¸¦å°å¶ç¼ç¾æè¦ææå­ï¼å·ææ¸è¼è¨åºå·¥ä½è² è¼åå¢å æ£èç²å¾åªè³ªé«çä¿å¥çæ©æçå·¨å¤§æ½åãéç¶åºç¤æ¨¡åå¨é«ççå¼èµ·äºç¸ç¶å¤§çèè¶£ï¼ä½å°ä¸æ¸æ¥å®åçä¸è¬è½åæ¯å¦è½è½åçºå¯¦éçè¨åºæç¨ãå¨éé å·¥ä½ä¸­ï¼æåè¡¨æåºç¤ VLM å¨èå¹´é½¡ç¸éæ§é»æé¨çè® (AMD) æ£èç§è­·è³ééè¦çå°éä»»åä¸ï¼è¡¨ç¾æé¡¯ä¸å¦å·æ¥­ç¼ç§é«çãçºäºè§£æ±ºéååé¡ï¼æåæåæ¾åºå½±åå¼è¨åºæ±ºç­æéçå¿è¦è½åï¼ç¶å¾å¶å®èª²ç¨ä¾é¸ææ§å°è¨ç·´ VLM éäºæè½ãæç¢ççæ¨¡å RetinaVLM å¯ä»¥è¢«æç¤ºæ°å¯«å ±åï¼å¶å¨ç¾çåæï¼F1 åæ¸çº 0.63 å° 0.11ï¼åæ£èè½è¨ºï¼0.67 å° 0.39ï¼æ¹é¢æé¡¯åªæ¼é åçåºç¤é«ç VLM ææ°å¯«çå ±åï¼ä¸¦æ¥è¿åç´ç¼ç§é«ççè¨ºæ·è¡¨ç¾ï¼å¨åé ä»»åä¸­åå¥éå° 0.77 å 0.78ï¼ãæ­¤å¤ï¼å¨æ¶åå©ä½ææé·é 32 å¹´ç¶é©çé«ç´ç¼ç§é«ççè®èç ç©¶ä¸­ï¼ç¼ç¾ RetinaVLM çå ±åæ­£ç¢ºæ§ï¼78.6% å° 82.1%ï¼åå®æ´æ§ï¼åçº 78.6%ï¼èææé·é 10 å¹´ç¶é©çåç´ç¼ç§é«çææ°å¯«çå ±åç¸ä¼¼ãéäºçµæè¡¨æï¼æååºæ¼èª²ç¨çæ¹æ³æä¾äºå°éæåºç¤é«ç VLM å°éåä»¥èçå¯¦éè¨åºä»»åçèåã</paragraph>

##### **Unveiling Disparities in Maternity Care: A Topic Modelling Approach to Analysing Maternity Incident Investigation Reports**
2407.08328v1 by Georgina Cosma, Mohit Kumar Singh, Patrick Waterson, Gyuchan Thomas Jun, Jonathan Back

This study applies Natural Language Processing techniques, including Latent
Dirichlet Allocation, to analyse anonymised maternity incident investigation
reports from the Healthcare Safety Investigation Branch. The reports underwent
preprocessing, annotation using the Safety Intelligence Research taxonomy, and
topic modelling to uncover prevalent topics and detect differences in maternity
care across ethnic groups. A combination of offline and online methods was
utilised to ensure data protection whilst enabling advanced analysis, with
offline processing for sensitive data and online processing for non-sensitive
data using the `Claude 3 Opus' language model. Interactive topic analysis and
semantic network visualisation were employed to extract and display thematic
topics and visualise semantic relationships among keywords. The analysis
revealed disparities in care among different ethnic groups, with distinct focus
areas for the Black, Asian, and White British ethnic groups. The study
demonstrates the effectiveness of topic modelling and NLP techniques in
analysing maternity incident investigation reports and highlighting disparities
in care. The findings emphasise the crucial role of advanced data analysis in
improving maternity care quality and equity.

æè¦ï¼æ¬ç ç©¶æç¨èªç¶èªè¨èçæè¡ï¼åæ¬æ½å¨çå©åé·åéï¼åæé«çä¿å¥å®å¨èª¿æ¥å±çå¿åç¢å©¦äºä»¶èª¿æ¥å ±åãéäºå ±åç¶éé èçãä½¿ç¨å®å¨æå ±ç ç©¶åé¡æ³è¨»è§£ï¼ä»¥åä¸»é¡å»ºæ¨¡ï¼ä»¥æ¾åºæ®éçä¸»é¡ä¸¦æ¾åºä¸åæç¾¤å¨ç¢åç§è­·çå·®ç°ãçµåé¢ç·åç·ä¸æ¹æ³ï¼ä»¥ç¢ºä¿è³æä¿è­·ï¼åæé²è¡é²éåæï¼ä½¿ç¨ Claude 3 Opus èªè¨æ¨¡åå°ææè³æé²è¡é¢ç·èçï¼å°éææè³æé²è¡ç·ä¸èçãæ¡ç¨äºåä¸»é¡åæåèªæç¶²è·¯è¦è¦ºåï¼ä»¥èååé¡¯ç¤ºä¸»é¡ä¸»é¡ï¼ä¸¦è¦è¦ºåééµå­ä¹éçèªæéä¿ãåæé¡¯ç¤ºä¸åæç¾¤ä¹éçç§è­·å·®ç°ï¼é»äººãäºæ´²äººåç½äººè±åäººæç¾¤çéæ³¨é åä¸åãæ¬ç ç©¶è­æäºä¸»é¡å»ºæ¨¡åèªç¶èªè¨èçæè¡å¨åæç¢å©¦äºä»¶èª¿æ¥å ±ååå¼·èª¿ç§è­·å·®ç°æ¹é¢çæææ§ãç ç©¶çµæå¼·èª¿äºé²éè³æåæå¨æåç¢åç§è­·åè³ªåå¬å¹³æ§æ¹é¢çééµè§è²ã

##### **Predicting Heart Failure with Attention Learning Techniques Utilizing Cardiovascular Data**
2407.08289v1 by Ershadul Haque, Manoranjan Paul, Faranak Tohidi

Cardiovascular diseases (CVDs) encompass a group of disorders affecting the
heart and blood vessels, including conditions such as coronary artery disease,
heart failure, stroke, and hypertension. In cardiovascular diseases, heart
failure is one of the main causes of death and also long-term suffering in
patients worldwide. Prediction is one of the risk factors that is highly
valuable for treatment and intervention to minimize heart failure. In this
work, an attention learning-based heart failure prediction approach is proposed
on EHR(electronic health record) cardiovascular data such as ejection fraction
and serum creatinine. Moreover, different optimizers with various learning rate
approaches are applied to fine-tune the proposed approach. Serum creatinine and
ejection fraction are the two most important features to predict the patient's
heart failure. The computational result shows that the RMSProp optimizer with
0.001 learning rate has a better prediction based on serum creatinine. On the
other hand, the combination of SGD optimizer with 0.01 learning rate exhibits
optimum performance based on ejection fraction features. Overall, the proposed
attention learning-based approach performs very efficiently in predicting heart
failure compared to the existing state-of-the-art such as LSTM approach.

æè¦ï¼å¿è¡ç®¡ç¾ç (CVD) åå«ä¸çµå½±é¿å¿èåè¡ç®¡çç¾çï¼åæ¬å çåèç¾çãå¿è¡°ç«­ãä¸­é¢¨åé«è¡å£ç­ç¾çãå¨å¿è¡ç®¡ç¾çä¸­ï¼å¿è¡°ç«­æ¯å¨çæ£èæ­»äº¡çä¸»è¦åå ä¹ä¸ï¼ä¹æ¯é·æçè¦çä¾æºãé æ¸¬æ¯å°æ²»çåå¹²é ä»¥æå¤§ç¨åº¦æ¸å°å¿è¡°ç«­æ¥µæå¹å¼çé¢¨éªå ç´ ä¹ä¸ãå¨éé å·¥ä½ä¸­ï¼æåºäºä¸ç¨®åºæ¼æ³¨æåå­¸ç¿çå¿è¡°ç«­é æ¸¬æ¹æ³ï¼è©²æ¹æ³åºæ¼ EHRï¼é»å­å¥åº·è¨éï¼å¿è¡ç®¡æ¸æï¼ä¾å¦å°è¡åæ¸åè¡æ¸èéãæ­¤å¤ï¼æç¨å·æåç¨®å­¸ç¿çæ¹æ³çä¸ååªåå¨å°ææåºçæ¹æ³é²è¡å¾®èª¿ãè¡æ¸èéåå°è¡åæ¸æ¯é æ¸¬æ£èå¿è¡°ç«­çå©åæéè¦çç¹å¾µãè¨ç®çµæè¡¨æï¼å­¸ç¿ççº 0.001 ç RMSProp åªåå¨åºæ¼è¡æ¸èéå·ææ´å¥½çé æ¸¬ãå¦ä¸æ¹é¢ï¼å­¸ç¿ççº 0.01 ç SGD åªåå¨èå°è¡åæ¸ç¹å¾µç¸çµåï¼è¡¨ç¾åºæä½³æ§è½ãç¸½é«èè¨ï¼è LSTM æ¹æ³ç­ç¾ææè¡ç¸æ¯ï¼ææåºçåºæ¼æ³¨æåå­¸ç¿çæ¹æ³å¨é æ¸¬å¿è¡°ç«­æ¹é¢è¡¨ç¾å¾éå¸¸ææã

##### **Leveraging LLMs to Predict Affective States via Smartphone Sensor Features**
2407.08240v1 by Tianyi Zhang, Songyan Teng, Hong Jia, Simon D'Alfonso

As mental health issues for young adults present a pressing public health
concern, daily digital mood monitoring for early detection has become an
important prospect. An active research area, digital phenotyping, involves
collecting and analysing data from personal digital devices such as smartphones
(usage and sensors) and wearables to infer behaviours and mental health. Whilst
this data is standardly analysed using statistical and machine learning
approaches, the emergence of large language models (LLMs) offers a new approach
to make sense of smartphone sensing data. Despite their effectiveness across
various domains, LLMs remain relatively unexplored in digital mental health,
particularly in integrating mobile sensor data. Our study aims to bridge this
gap by employing LLMs to predict affect outcomes based on smartphone sensing
data from university students. We demonstrate the efficacy of zero-shot and
few-shot embedding LLMs in inferring general wellbeing. Our findings reveal
that LLMs can make promising predictions of affect measures using solely
smartphone sensing data. This research sheds light on the potential of LLMs for
affective state prediction, emphasizing the intricate link between smartphone
behavioral patterns and affective states. To our knowledge, this is the first
work to leverage LLMs for affective state prediction and digital phenotyping
tasks.

æè¦ï¼é¨èå¹´è¼äººçå¿çå¥åº·åé¡æçºè¿«åçå¬å±è¡çåé¡ï¼æ¯æ¥æ¸ä½æç·ç£æ§å·²æçºæ©æåµæ¸¬çéè¦åæ¯ãæ¸ä½è¡¨ååæ¯ä¸åç©æ¥µçç ç©¶é åï¼æ¶åæ¶éååæä¾èªåäººæ¸ä½è£ç½®ï¼ä¾å¦æºæ§åææ©ï¼ä½¿ç¨åææ¸¬å¨ï¼åå¯ç©¿æ´è£ç½®ï¼çè³æï¼ä»¥æ¨è«è¡çºåå¿çå¥åº·ãéç¶éäºè³æéå¸¸ä½¿ç¨çµ±è¨åæ©å¨å­¸ç¿æ¹æ³é²è¡åæï¼ä½å¤§åèªè¨æ¨¡å (LLM) çåºç¾æä¾äºä¸ç¨®æ°çæ¹æ³ä¾çè§£æºæ§åææ©ææ¸¬è³æãåç®¡ LLM å¨åç¨®é åé½éå¸¸ææï¼ä½å¶å¨æ¸ä½å¿çå¥åº·é åä»ç¸å°æªè¢«æ¢ç´¢ï¼ç¹å¥æ¯å¨æ´åè¡åææ¸¬å¨è³ææ¹é¢ãæåçç ç©¶æ¨å¨ééä½¿ç¨ LLM ä¾æ ¹æå¤§å­¸ççæºæ§åææ©ææ¸¬è³æé æ¸¬å½±é¿çµæï¼ä»¥å½åéä¸å·®è·ãæåå±ç¤ºäºé¶æ¬¡å­¸ç¿åå°æ¬¡å­¸ç¿åµå¥å¼ LLM å¨æ¨è«ä¸è¬å¹¸ç¦ææ¹é¢çæè½ãæåçç ç©¶çµæé¡¯ç¤ºï¼LLM å¯ä»¥åä½¿ç¨æºæ§åææ©ææ¸¬è³æå°å½±é¿æ¸¬éé²è¡æå¸æçé æ¸¬ãæ¬ç ç©¶æ­ç¤ºäº LLM å¨ææçæé æ¸¬æ¹é¢çæ½åï¼å¼·èª¿äºæºæ§åææ©è¡çºæ¨¡å¼åææçæä¹éçè¤éè¯ç¹«ãææåæç¥ï¼éæ¯ç¬¬ä¸åå©ç¨ LLM é²è¡ææçæé æ¸¬åæ¸ä½è¡¨ååä»»åçç ç©¶ã

##### **DALL-M: Context-Aware Clinical Data Augmentation with LLMs**
2407.08227v1 by Chihcheng Hsieh, Catarina Moreira, Isabel Blanco Nobre, Sandra Costa Sousa, Chun Ouyang, Margot Brereton, Joaquim Jorge, Jacinto C. Nascimento

X-ray images are vital in medical diagnostics, but their effectiveness is
limited without clinical context. Radiologists often find chest X-rays
insufficient for diagnosing underlying diseases, necessitating comprehensive
clinical features and data integration. We present a novel technique to enhance
the clinical context through augmentation techniques with clinical tabular
data, thereby improving its applicability and reliability in AI medical
diagnostics. To address this, we introduce a pioneering approach to clinical
data augmentation that employs large language models (LLMs) to generate patient
contextual synthetic data. This methodology is crucial for training more robust
deep learning models in healthcare. It preserves the integrity of real patient
data while enriching the dataset with contextually relevant synthetic features,
significantly enhancing model performance. DALL-M uses a three-phase feature
generation process: (i) clinical context storage, (ii) expert query generation,
and (iii) context-aware feature augmentation. DALL-M generates new, clinically
relevant features by synthesizing chest X-ray images and reports. Applied to
799 cases using nine features from the MIMIC-IV dataset, it created an
augmented set of 91 features. This is the first work to generate contextual
values for existing and new features based on patients' X-ray reports, gender,
and age and to produce new contextual knowledge during data augmentation.
Empirical validation with machine learning models, including Decision Trees,
Random Forests, XGBoost, and TabNET, showed significant performance
improvements. Incorporating augmented features increased the F1 score by 16.5%
and Precision and Recall by approximately 25%. DALL-M addresses a critical gap
in clinical data augmentation, offering a robust framework for generating
contextually enriched datasets.

æè¦ï¼<paragraph>X åå½±åå¨å»å­¦è¯æ­ä¸­è³å³éè¦ï¼ä½å¦ææ²¡æä¸´åºèæ¯ï¼å¶æææ§ä¼åå°éå¶ãæ¾å°ç§å»çç»å¸¸åç°è¸é¨ X åå½±åä¸è¶³ä»¥è¯æ­æ½å¨ç¾çï¼å æ­¤éè¦å¨é¢çä¸´åºç¹å¾åæ°æ®æ´åãæä»¬æåºäºä¸ç§æ°ææ¯ï¼éè¿ä½¿ç¨ä¸´åºè¡¨æ ¼æ°æ®è¿è¡å¢å¼ºææ¯æ¥å¢å¼ºä¸´åºèæ¯ï¼ä»èæé«å¶å¨ AI å»å­¦è¯æ­ä¸­çéç¨æ§åå¯é æ§ãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æä»¬å¼å¥äºä¸ç§å¼åæ§çä¸´åºæ°æ®å¢å¼ºæ¹æ³ï¼è¯¥æ¹æ³éç¨å¤§åè¯­è¨æ¨¡å (LLM) æ¥çææ£èèæ¯åææ°æ®ãè¿ç§æ¹æ³å¯¹äºå¨å»çä¿å¥é¢åè®­ç»æ´å¼ºå¤§çæ·±åº¦å­¦ä¹ æ¨¡åè³å³éè¦ãå®ä¿çäºçå®æ£èæ°æ®çå®æ´æ§ï¼åæ¶ä½¿ç¨ä¸ä¸ä¸æç¸å³çåæç¹å¾ä¸°å¯äºæ°æ®éï¼ä»èæ¾èæé«äºæ¨¡åæ§è½ãDALL-M ä½¿ç¨äºä¸ä¸ªä¸é¶æ®µç¹å¾çæè¿ç¨ï¼(i) ä¸´åºèæ¯å­å¨ï¼(ii) ä¸å®¶æ¥è¯¢çæï¼(iii) ä¸ä¸ææç¥ç¹å¾å¢å¼ºãDALL-M éè¿åæè¸é¨ X åå½±ååæ¥åæ¥çææ°çãä¸ä¸´åºç¸å³çç¹å¾ãå°å¶åºç¨äº MIMIC-IV æ°æ®éä¸­ç 799 ä¸ªæ¡ä¾ï¼ä½¿ç¨ä¹ä¸ªç¹å¾ï¼å®åå»ºäºä¸ä¸ªåå« 91 ä¸ªç¹å¾çå¢å¼ºéåãè¿æ¯ç¬¬ä¸é¡¹åºäºæ£èç X åæ¥åãæ§å«åå¹´é¾ä¸ºç°æåæ°ç¹å¾çæä¸ä¸æå¼çèä½ï¼å¹¶å¨æ°æ®å¢å¼ºæé´äº§çæ°çä¸ä¸æç¥è¯ãä½¿ç¨åæ¬å³ç­æ ãéæºæ£®æãXGBoost å TabNET å¨åçæºå¨å­¦ä¹ æ¨¡åè¿è¡çç»éªéªè¯æ¾ç¤ºåºæ¾èçæ§è½æ¹è¿ãåå¹¶å¢å¼ºåè½å° F1 åæ°æé«äº 16.5%ï¼å¹¶å°ç²¾ç¡®åº¦åå¬åçæé«äºå¤§çº¦ 25%ãDALL-M è§£å³äºä¸ä¸ªä¸´åºæ°æ®å¢å¼ºä¸­çå³é®ç©ºç½ï¼æä¾äºä¸ä¸ªç¨äºçæä¸ä¸æä¸°å¯çæ°æ®éçç¨³å¥æ¡æ¶ã</paragraph>

##### **Synthetic Electroretinogram Signal Generation Using Conditional Generative Adversarial Network for Enhancing Classification of Autism Spectrum Disorder**
2407.08166v1 by Mikhail Kulyabin, Paul A. Constable, Aleksei Zhdanov, Irene O. Lee, David H. Skuse, Dorothy A. Thompson, Andreas Maier

The electroretinogram (ERG) is a clinical test that records the retina's
electrical response to light. The ERG is a promising way to study different
neurodevelopmental and neurodegenerative disorders, including autism spectrum
disorder (ASD) - a neurodevelopmental condition that impacts language,
communication, and reciprocal social interactions. However, in heterogeneous
populations, such as ASD, where the ability to collect large datasets is
limited, the application of artificial intelligence (AI) is complicated.
Synthetic ERG signals generated from real ERG recordings carry similar
information as natural ERGs and, therefore, could be used as an extension for
natural data to increase datasets so that AI applications can be fully
utilized. As proof of principle, this study presents a Generative Adversarial
Network capable of generating synthetic ERG signals of children with ASD and
typically developing control individuals. We applied a Time Series Transformer
and Visual Transformer with Continuous Wavelet Transform to enhance
classification results on the extended synthetic signals dataset. This approach
may support classification models in related psychiatric conditions where the
ERG may help classify disorders.

æè¦ï¼è¦ç¶²èé»å (ERG) æ¯ä¸ç¨®è¨åºæ¸¬è©¦ï¼ç¨æ¼è¨éè¦ç¶²èå°åçé»æ°£åæãERG æ¯ä¸ç¨®å¾æåéçç ç©¶ä¸åç¥ç¶ç¼è²åç¥ç¶éåæ§ç¾ççæ¹æ³ï¼åæ¬èªéçè­ç³»éç¤ (ASD) - ä¸ç¨®å½±é¿èªè¨ãæºéåç¤¾äº¤äºåçç¥ç¶ç¼è²çæ³ãç¶èï¼å¨ç°è³ªäººç¾¤ä¸­ï¼ä¾å¦ ASDï¼æ¶éå¤§åæ¸æéçè½åæéï¼äººå·¥æºè½ (AI) çæç¨å¾è¤éãå¾çå¯¦ ERG è¨éä¸­ç¢ççåæ ERG ä¿¡èæå¸¶èèªç¶ ERG ç¸ä¼¼çä¿¡æ¯ï¼å æ­¤å¯ç¨ä½èªç¶æ¸æçæ´å±ï¼ä»¥å¢å æ¸æéï¼ä»¥ä¾¿ AI æç¨ç¨åºå¯ä»¥å¾å°ååå©ç¨ãä½çºåçè­æï¼æ¬ç ç©¶æåºäºä¸åçæå°æç¶²è·¯ï¼è½å¤ ç¢çèªéçåç«¥åæ­£å¸¸ç¼è²å°ç§åäººçåæ ERG ä¿¡èãæåæç¨æåºè½æå¨åå·æé£çºå°æ³¢è½æçè¦è¦ºè½æå¨ä¾å¢å¼·æ´å±åæä¿¡èæ¸æéä¸çåé¡çµæãéç¨®æ¹æ³å¯ä»¥æ¯æç¸éç²¾ç¥ç¾ççåé¡æ¨¡åï¼å¨éäºç¾çä¸­ï¼ERG å¯è½æå©æ¼å°ç¾çé²è¡åé¡ã

##### **Highway Networks for Improved Surface Reconstruction: The Role of Residuals and Weight Updates**
2407.08134v1 by A. Noorizadegan, Y. C. Hon, D. L. Young, C. S. Chen

Surface reconstruction from point clouds is a fundamental challenge in
computer graphics and medical imaging. In this paper, we explore the
application of advanced neural network architectures for the accurate and
efficient reconstruction of surfaces from data points. We introduce a novel
variant of the Highway network (Hw) called Square-Highway (SqrHw) within the
context of multilayer perceptrons and investigate its performance alongside
plain neural networks and a simplified Hw in various numerical examples. These
examples include the reconstruction of simple and complex surfaces, such as
spheres, human hands, and intricate models like the Stanford Bunny. We analyze
the impact of factors such as the number of hidden layers, interior and
exterior points, and data distribution on surface reconstruction quality. Our
results show that the proposed SqrHw architecture outperforms other neural
network configurations, achieving faster convergence and higher-quality surface
reconstructions. Additionally, we demonstrate the SqrHw's ability to predict
surfaces over missing data, a valuable feature for challenging applications
like medical imaging. Furthermore, our study delves into further details,
demonstrating that the proposed method based on highway networks yields more
stable weight norms and backpropagation gradients compared to the Plain Network
architecture. This research not only advances the field of computer graphics
but also holds utility for other purposes such as function interpolation and
physics-informed neural networks, which integrate multilayer perceptrons into
their algorithms.

æè¦ï¼å¾é»é²é²è¡æ²é¢éå»ºæ¯é»è¦åå­¸åé«å­¸å½±åä¸­çä¸é åºæ¬ææ°ãå¨æ¬æä¸­ï¼æåæ¢è¨äºåé²ç¥ç¶ç¶²è·¯æ¶æ§å¨å¾è³æé»ç²¾ç¢ºä¸ææéå»ºæ²é¢ä¸­çæç¨ãæåå¨å¤å±¤æç¥å¨çæ¶æ§ä¸­ï¼å¼å¥äºé«éå¬è·¯ç¶²è·¯ï¼Hwï¼çä¸ç¨®æ°è®é«ï¼ç¨±çº Square-Highwayï¼SqrHwï¼ï¼ä¸¦å¨åç¨®æ¸å¼ç¯ä¾ä¸­æ¢è¨å¶æè½ï¼ä»¥åèä¸è¬ç¥ç¶ç¶²è·¯åç°¡åç Hw çæè½ãéäºç¯ä¾åæ¬éå»ºç°¡å®åè¤éçæ²é¢ï¼ä¾å¦çé«ãäººæåå Stanford Bunny é£æ¨£è¤éçæ¨¡åãæååæäºé±èå±¤æ¸ãå§é¨åå¤é¨é»ä»¥åè³æåä½ç­å ç´ å°æ²é¢éå»ºåè³ªçå½±é¿ãæåççµæé¡¯ç¤ºï¼ææåºç SqrHw æ¶æ§åªæ¼å¶ä»ç¥ç¶ç¶²è·¯çµæï¼è½éææ´å¿«çæ¶æéåº¦åæ´é«åè³ªçæ²é¢éå»ºãæ­¤å¤ï¼æåå±ç¤ºäº SqrHw è½å¤ é æ¸¬éºå¤±è³æä¸çæ²é¢ï¼éå°æ¼åé«å­¸å½±åé£æ¨£å·æææ°æ§çæç¨ä¾èªªï¼æ¯ä¸åæå¹å¼çåè½ãæ­¤å¤ï¼æåçç ç©¶æ·±å¥æ¢è¨äºæ´å¤ç´°ç¯ï¼è­æäºåºæ¼é«éå¬è·¯ç¶²è·¯çææåºæ¹æ³ï¼èä¸è¬ç¶²è·¯æ¶æ§ç¸æ¯ï¼ç¢çäºæ´ç©©å®çæ¬éç¯æ¸åååå³æ­æ¢¯åº¦ãéé ç ç©¶ä¸åæ¨åäºé»è¦åå­¸é åï¼ä¹å°å¶ä»ç¨éæå¹«å©ï¼ä¾å¦å½æ¸å§æåç©çè³è¨ç¥ç¶ç¶²è·¯ï¼å°å¤å±¤æç¥å¨æ´åå°å¶æ¼ç®æ³ä¸­ã

##### **Machine Learning for ALSFRS-R Score Prediction: Making Sense of the Sensor Data**
2407.08003v1 by Ritesh Mehta, Aleksandar Pramov, Shashank Verma

Amyotrophic Lateral Sclerosis (ALS) is characterized as a rapidly progressive
neurodegenerative disease that presents individuals with limited treatment
options in the realm of medical interventions and therapies. The disease
showcases a diverse range of onset patterns and progression trajectories,
emphasizing the critical importance of early detection of functional decline to
enable tailored care strategies and timely therapeutic interventions. The
present investigation, spearheaded by the iDPP@CLEF 2024 challenge, focuses on
utilizing sensor-derived data obtained through an app. This data is used to
construct various machine learning models specifically designed to forecast the
advancement of the ALS Functional Rating Scale-Revised (ALSFRS-R) score,
leveraging the dataset provided by the organizers. In our analysis, multiple
predictive models were evaluated to determine their efficacy in handling ALS
sensor data. The temporal aspect of the sensor data was compressed and
amalgamated using statistical methods, thereby augmenting the interpretability
and applicability of the gathered information for predictive modeling
objectives. The models that demonstrated optimal performance were a naive
baseline and ElasticNet regression. The naive model achieved a Mean Absolute
Error (MAE) of 0.20 and a Root Mean Square Error (RMSE) of 0.49, slightly
outperforming the ElasticNet model, which recorded an MAE of 0.22 and an RMSE
of 0.50. Our comparative analysis suggests that while the naive approach
yielded marginally better predictive accuracy, the ElasticNet model provides a
robust framework for understanding feature contributions.

æè¦ï¼èèç¸®æ§èé«å´ç´¢ç¡¬åç (ALS) çç¹å¾µçºå¿«éé²å±çç¥ç¶éåæ§ç¾çï¼å¨é«çä»å¥åæ²»çé åä¸­ï¼æ£èçæ²»çé¸ææéãæ­¤ç¾çå±ç¤ºåºå¤æ¨£åçç¼çæ¨¡å¼åé²å±è»è·¡ï¼å¼·èª¿æ©æåµæ¸¬åè½è¡°éè³ééè¦ï¼ä»¥å¶å®å®¢è£½åçç§è­·ç­ç¥ååæçæ²»çä»å¥ãæ¬ç ç©¶ç± iDPP@CLEF 2024 ææ°å¸¶é ­ï¼å°æ³¨æ¼å©ç¨ééæç¨ç¨å¼åå¾çææ¸¬å¨è¡çè³æãéäºè³æç¨æ¼å»ºæ§åç¨®æ©å¨å­¸ç¿æ¨¡åï¼ç¹å¥è¨­è¨ç¨æ¼é æ¸¬ ALS åè½è©åéè¡¨ä¿®è¨ç (ALSFRS-R) åæ¸çé²å±ï¼ä¸¦å©ç¨ä¸»è¾¦å®ä½æä¾çè³æéãå¨æåçåæä¸­ï¼è©ä¼°äºå¤ç¨®é æ¸¬æ¨¡åï¼ä»¥ç¢ºå®å®åå¨èç ALS ææ¸¬å¨è³ææ¹é¢çæè½ãææ¸¬å¨è³æçæéé¢åä½¿ç¨çµ±è¨æ¹æ³é²è¡å£ç¸®ååä½µï¼å¾èå¢å¼·æ¶éè³è¨å¨é æ¸¬å»ºæ¨¡ç®æ¨æ¹é¢çå¯è§£éæ§åé©ç¨æ§ãè¡¨ç¾æä½³çæ¨¡åæ¯æ¨¸ç´ åºæºå ElasticNet åæ­¸ãæ¨¸ç´ æ¨¡åéå°äºå¹³åçµå°èª¤å·® (MAE) çº 0.20 ååæ¹æ ¹èª¤å·® (RMSE) çº 0.49ï¼ç¥åæ¼ ElasticNet æ¨¡åï¼å¾èç MAE çº 0.22ï¼RMSE çº 0.50ãæåçæ¯è¼åæè¡¨æï¼éç¶æ¨¸ç´ æ¹æ³ç¢ççé æ¸¬æºç¢ºåº¦ç¥é«ï¼ä½ ElasticNet æ¨¡åæä¾äºä¸åç©©å¥çæ¶æ§ï¼ç¨æ¼ç­è§£ç¹å¾µè²¢ç»ã

##### **The Human Factor in AI Red Teaming: Perspectives from Social and Collaborative Computing**
2407.07786v1 by Alice Qian Zhang, Ryland Shaw, Jacy Reese Anthis, Ashlee Milton, Emily Tseng, Jina Suh, Lama Ahmad, Ram Shankar Siva Kumar, Julian Posada, Benjamin Shestakofsky, Sarah T. Roberts, Mary L. Gray

Rapid progress in general-purpose AI has sparked significant interest in "red
teaming," a practice of adversarial testing originating in military and
cybersecurity applications. AI red teaming raises many questions about the
human factor, such as how red teamers are selected, biases and blindspots in
how tests are conducted, and harmful content's psychological effects on red
teamers. A growing body of HCI and CSCW literature examines related
practices-including data labeling, content moderation, and algorithmic
auditing. However, few, if any, have investigated red teaming itself. This
workshop seeks to consider the conceptual and empirical challenges associated
with this practice, often rendered opaque by non-disclosure agreements. Future
studies may explore topics ranging from fairness to mental health and other
areas of potential harm. We aim to facilitate a community of researchers and
practitioners who can begin to meet these challenges with creativity,
innovation, and thoughtful reflection.

æè¦ï¼ä¸è¬ç¨é AI çå¿«éé²å±å¼ç¼äºå°ãç´éãçæ¿åèè¶£ï¼ç´éæ¯ä¸ç¨®æºèªè»äºåç¶²è·¯å®å¨æç¨ä¸­çå°ææ§æ¸¬è©¦å¯¦åãAI ç´éå°äººé¡å ç´ æåºäºè¨±å¤åé¡ï¼ä¾å¦ç´éæå¡å¦ä½é¸æãæ¸¬è©¦å·è¡æ¹å¼ä¸­çåè¦åç²é»ï¼ä»¥åæå®³å§å®¹å°ç´éæå¡çå¿çå½±é¿ãè¶ä¾è¶å¤çäººæ©äºåå CSCW æç»æ¢è¨äºç¸éå¯¦åï¼åæ¬è³ææ¨è¨ãå§å®¹å¯©æ ¸åæ¼ç®æ³ç¨½æ ¸ãç¶èï¼é®®å°æäººæ¢è¨ç´éæ¬èº«ãæ¬å·¥ä½åæ¨å¨æ¢è¨èæ­¤å¯¦åç¸éçæ¦å¿µåç¶é©ææ°ï¼éäºææ°éå¸¸å ä¿å¯åè­°èè®å¾æ¨¡ç³ä¸æ¸ãæªä¾çç ç©¶å¯è½ææ¢è¨å¾å¬å¹³æ§å°å¿çå¥åº·åå¶ä»æ½å¨å±å®³é åçä¸»é¡ãæåçç®æ¨æ¯ä¿é²ç ç©¶äººå¡åå¯¦åå·¥ä½èçç¤¾ç¾¤ï¼ä»åå¯ä»¥éå§éç¨åµæãåµæ°åæ·±æçæ®çåæä¾æå°éäºææ°ã

##### **A Proposed S.C.O.R.E. Evaluation Framework for Large Language Models : Safety, Consensus, Objectivity, Reproducibility and Explainability**
2407.07666v1 by Ting Fang Tan, Kabilan Elangovan, Jasmine Ong, Nigam Shah, Joseph Sung, Tien Yin Wong, Lan Xue, Nan Liu, Haibo Wang, Chang Fu Kuo, Simon Chesterman, Zee Kin Yeong, Daniel SW Ting

A comprehensive qualitative evaluation framework for large language models
(LLM) in healthcare that expands beyond traditional accuracy and quantitative
metrics needed. We propose 5 key aspects for evaluation of LLMs: Safety,
Consensus, Objectivity, Reproducibility and Explainability (S.C.O.R.E.). We
suggest that S.C.O.R.E. may form the basis for an evaluation framework for
future LLM-based models that are safe, reliable, trustworthy, and ethical for
healthcare and clinical applications.

æè¦ï¼ä¸åå¨é¢çå®æ§è©ä¼°æ¶æ§ï¼é©ç¨æ¼é«çä¿å¥é åçå¤§åèªè¨æ¨¡å (LLM)ï¼å¶ç¯åè¶è¶å³çµ±çæºç¢ºåº¦åå®éææ¨ãæåæåºç¨æ¼è©ä¼° LLM ç 5 åééµé¢åï¼å®å¨æ§ãå±è­ãå®¢è§æ§ãå¯è¤è£½æ§åå¯è§£éæ§ (S.C.O.R.E.)ãæåå»ºè­° S.C.O.R.E. å¯ä»¥ä½çºè©ä¼°æ¶æ§çåºç¤ï¼é©ç¨æ¼æªä¾çåºæ¼ LLM çæ¨¡åï¼éäºæ¨¡åå°æ¼é«çä¿å¥åè¨åºæç¨ä¾èªªæ¯å®å¨ãå¯é ãå¼å¾ä¿¡è³´ä¸åä¹éå¾·çã

##### **Boosting Medical Image Synthesis via Registration-guided Consistency and Disentanglement Learning**
2407.07660v1 by Chuanpu Li, Zeli Chen, Yiwen Zhang, Liming Zhong, Wei Yang

Medical image synthesis remains challenging due to misalignment noise during
training. Existing methods have attempted to address this challenge by
incorporating a registration-guided module. However, these methods tend to
overlook the task-specific constraints on the synthetic and registration
modules, which may cause the synthetic module to still generate spatially
aligned images with misaligned target images during training, regardless of the
registration module's function. Therefore, this paper proposes
registration-guided consistency and incorporates disentanglement learning for
medical image synthesis. The proposed registration-guided consistency
architecture fosters task-specificity within the synthetic and registration
modules by applying identical deformation fields before and after synthesis,
while enforcing output consistency through an alignment loss. Moreover, the
synthetic module is designed to possess the capability of disentangling
anatomical structures and specific styles across various modalities. An anatomy
consistency loss is introduced to further compel the synthetic module to
preserve geometrical integrity within latent spaces. Experiments conducted on
both an in-house abdominal CECT-CT dataset and a publicly available pelvic
MR-CT dataset have demonstrated the superiority of the proposed method.

æè¦ï¼ç±æ¼è¨ç·´æéçé¯ä½éè¨ï¼é«å­¸å½±ååæä»ç¶å·æææ°æ§ãç¾ææ¹æ³å·²åè©¦ééç´å¥è¨»åå°å¼æ¨¡çµä¾è§£æ±ºæ­¤ææ°ãç¶èï¼éäºæ¹æ³å¾å¾å¿½ç¥åæèè¨»åæ¨¡çµçç¹å®ä»»åç´æï¼éå¯è½æå°è´åææ¨¡çµå¨è¨ç·´æéä»ç¢çèé¯ä½ç®æ¨å½±åç©ºéå°é½çå½±åï¼èèè¨»åæ¨¡çµçåè½ç¡éãå æ­¤ï¼æ¬ææåºè¨»åå°å¼ä¸è´æ§ï¼ä¸¦çµåè§£ç³¾çºå­¸ç¿ç¨æ¼é«å­¸å½±ååæãææåºçè¨»åå°å¼ä¸è´æ§æ¶æ§ééå¨åæåå¾æç¨ç¸åçè®å½¢å ´ï¼ä¸¦ééå°é½æå¤±ä¾å¼·å¶å·è¡è¼¸åºä¸è´æ§ï¼ä¾ä¿é²åæèè¨»åæ¨¡çµä¸­çä»»åç¹ç°æ§ãæ­¤å¤ï¼åææ¨¡çµè¢«è¨­è¨çºå·åå¨åç¨®æ¨¡æä¸­è§£éè§£åçµæ§åç¹å®æ¨£å¼çè½åãå¼å¥äºè§£åä¸è´æ§æå¤±ï¼ä»¥é²ä¸æ­¥å¼·å¶åææ¨¡çµå¨æ½å¨ç©ºéä¸­ä¿çå¹¾ä½å®æ´æ§ãå¨å§é¨è¹é¨ CECT-CT è³æéåå¬éå¯ç¨çéª¨ç MR-CT è³æéä¸é²è¡çå¯¦é©å·²è­æäºææåºæ¹æ³çåªè¶æ§ã

##### **H-FCBFormer Hierarchical Fully Convolutional Branch Transformer for Occlusal Contact Segmentation with Articulating Paper**
2407.07604v1 by Ryan Banks, Bernat Rovira-Lastra, Jordi Martinez-Gomis, Akhilanand Chaurasia, Yunpeng Li

Occlusal contacts are the locations at which the occluding surfaces of the
maxilla and the mandible posterior teeth meet. Occlusal contact detection is a
vital tool for restoring the loss of masticatory function and is a mandatory
assessment in the field of dentistry, with particular importance in
prosthodontics and restorative dentistry. The most common method for occlusal
contact detection is articulating paper. However, this method can indicate
significant medically false positive and medically false negative contact
areas, leaving the identification of true occlusal indications to clinicians.
To address this, we propose a multiclass Vision Transformer and Fully
Convolutional Network ensemble semantic segmentation model with a combination
hierarchical loss function, which we name as Hierarchical Fully Convolutional
Branch Transformer (H-FCBFormer). We also propose a method of generating
medically true positive semantic segmentation masks derived from expert
annotated articulating paper masks and gold standard masks. The proposed model
outperforms other machine learning methods evaluated at detecting medically
true positive contacts and performs better than dentists in terms of accurately
identifying object-wise occlusal contact areas while taking significantly less
time to identify them. Code is available at
https://github.com/Banksylel/H-FCBFormer.

æè¦ï¼å¬åæ¥è§¸æ¯ä¸é¡åä¸é¡å¾çå¬åé¢ç¸éçä½ç½®ãå¬åæ¥è§¸åµæ¸¬æ¯æ¢å¾©åå¼åè½åªå¤±çå¿è¦å·¥å·ï¼ä¹æ¯çç§é åä¸­çä¸é å¼·å¶æ§è©ä¼°ï¼ç¹å¥æ¯å¨è´å¾©çç§åä¿®å¾©çç§ä¸­å·æéè¦æç¾©ãæå¸¸è¦çå¬åæ¥è§¸åµæ¸¬æ¹æ³æ¯ä½¿ç¨å¬åç´ãç¶èï¼æ­¤æ¹æ³å¯è½æé¡¯ç¤ºåºé¡¯èçé«å­¸åé½æ§åé«å­¸åé°æ§æ¥è§¸ååï¼è®è¨åºé«å¸«é£ä»¥æ¾åºçæ­£çå¬åè·¡è±¡ãçºäºè§£æ±ºéååé¡ï¼æåæåºä¸åå¤é¡å¥ç Vision Transformer åå¨å·ç©ç¶²è·¯éåèªæåå²æ¨¡åï¼ä¸¦çµååå±¤æå¤±å½æ¸ï¼æåå°å¶å½åçºåå±¤å¨å·ç©åæ¯è½æå¨ (H-FCBFormer)ãæåéæåºäºä¸ç¨®çæé«å­¸çé½æ§èªæåå²é®ç½©çæ¹æ³ï¼è©²æ¹æ³æºèªå°å®¶è¨»è§£çå¬åç´é®ç½©åéæ¨æºé®ç½©ãææåºçæ¨¡åå¨åµæ¸¬é«å­¸çé½æ§æ¥è§¸æ¹é¢åªæ¼å¶ä»æ©å¨å­¸ç¿æ¹æ³ï¼ä¸¦ä¸å¨æºç¢ºè­å¥ç©ä»¶å¼å¬åæ¥è§¸ååæ¹é¢åªæ¼çé«å¸«ï¼åæè­å¥æéæéå»é¡¯èæ¸å°ãç¨å¼ç¢¼å¯å¨ https://github.com/Banksylel/H-FCBFormer åå¾ã

##### **FLAIR: Feeding via Long-horizon AcquIsition of Realistic dishes**
2407.07561v1 by Rajat Kumar Jenamani, Priya Sundaresan, Maram Sakr, Tapomayukh Bhattacharjee, Dorsa Sadigh

Robot-assisted feeding has the potential to improve the quality of life for
individuals with mobility limitations who are unable to feed themselves
independently. However, there exists a large gap between the homogeneous,
curated plates existing feeding systems can handle, and truly in-the-wild
meals. Feeding realistic plates is immensely challenging due to the sheer range
of food items that a robot may encounter, each requiring specialized
manipulation strategies which must be sequenced over a long horizon to feed an
entire meal. An assistive feeding system should not only be able to sequence
different strategies efficiently in order to feed an entire meal, but also be
mindful of user preferences given the personalized nature of the task. We
address this with FLAIR, a system for long-horizon feeding which leverages the
commonsense and few-shot reasoning capabilities of foundation models, along
with a library of parameterized skills, to plan and execute user-preferred and
efficient bite sequences. In real-world evaluations across 6 realistic plates,
we find that FLAIR can effectively tap into a varied library of skills for
efficient food pickup, while adhering to the diverse preferences of 42
participants without mobility limitations as evaluated in a user study. We
demonstrate the seamless integration of FLAIR with existing bite transfer
methods [19, 28], and deploy it across 2 institutions and 3 robots,
illustrating its adaptability. Finally, we illustrate the real-world efficacy
of our system by successfully feeding a care recipient with severe mobility
limitations. Supplementary materials and videos can be found at:
https://emprise.cs.cornell.edu/flair .

æè¦ï¼æ©å¨äººè¼å©é²é£ææ½åæ¹åè¡åä¸ä¾¿ãç¡æ³èªè¡é²é£çåäººçæ´»åè³ªãç¶èï¼ç¾æçé²é£ç³»çµ±æè½èççåè³ªãç²¾é¸é¤ç¤èå¯¦éçé¤é»ä¹éå­å¨èå¾å¤§çå·®è·ãé²é£å¯¦éçé¤é»æ¥µå·ææ°æ§ï¼å çºæ©å¨äººå¯è½éå°çé£ç©ç¨®é¡ç¹å¤ï¼æ¯ç¨®é£ç©é½éè¦ç¹å®çæä½ç­ç¥ï¼èéäºç­ç¥å¿é å¨ä¸åé·æçç¯åå§é²è¡æåºï¼æè½é²é£ä¸æ´é¤ãä¸åè¼å©é²é£ç³»çµ±ä¸åæè©²è½å¤ ææå°å°ä¸åçç­ç¥é²è¡æåºï¼ä»¥ä¾¿é²é£ä¸æ´é¤ï¼éæè©²å¨ä»»åçåæ§åæ§è³ªä¸ï¼èéä½¿ç¨èçåå¥½ãæåéé FLAIR ä¾è§£æ±ºéååé¡ï¼FLAIR æ¯éå°é·æç¨é²é£çç³»çµ±ï¼å®å©ç¨åºç¤æ¨¡åçå¸¸è­åå°éæ¨çè½åï¼ä»¥åä¸ååæ¸åæè½åº«ï¼ä¾è¦ååå·è¡ä½¿ç¨èåå¥½ä¸ææçé²é£é åºãå¨ 6 åå¯¦éé¤ç¤ççå¯¦ä¸çè©ä¼°ä¸­ï¼æåç¼ç¾ FLAIR å¯ä»¥ææå°å©ç¨åç¨®æè½åº«é²è¡ææçé£ç©åç¨ï¼åæéµå® 42 ä½è¡åä¸ä¾¿åèèçä¸ååå¥½ï¼éæ¯å¨ä½¿ç¨èç ç©¶ä¸­è©ä¼°çãæåå±ç¤ºäº FLAIR èç¾æé²é£è½ç§»æ¹æ³ [19, 28] çç¡ç¸«æ´åï¼ä¸¦å¨ 2 åæ©æ§å 3 åæ©å¨äººä¸­é¨ç½²å®ï¼èªªæäºå®çé©ææ§ãæå¾ï¼æåééæåé¤µé£ä¸ä½è¡åä¸ä¾¿çåç§è­·èä¾èªªææåç³»çµ±å¨çå¯¦ä¸çä¸­çåæãè£åææåå½±çå¯ä»¥å¨éè£¡æ¾å°ï¼https://emprise.cs.cornell.edu/flairã

##### **Arabic Automatic Story Generation with Large Language Models**
2407.07551v1 by Ahmed Oumar El-Shangiti, Fakhraddin Alwajih, Muhammad Abdul-Mageed

Large language models (LLMs) have recently emerged as a powerful tool for a
wide range of language generation tasks. Nevertheless, this progress has been
slower in Arabic. In this work, we focus on the task of generating stories from
LLMs. For our training, we use stories acquired through machine translation
(MT) as well as GPT-4. For the MT data, we develop a careful pipeline that
ensures we acquire high-quality stories. For our GPT-41 data, we introduce
crafted prompts that allow us to generate data well-suited to the Arabic
context in both Modern Standard Arabic (MSA) and two Arabic dialects (Egyptian
and Moroccan). For example, we generate stories tailored to various Arab
countries on a wide host of topics. Our manual evaluation shows that our model
fine-tuned on these training datasets can generate coherent stories that adhere
to our instructions. We also conduct an extensive automatic and human
evaluation comparing our models against state-of-the-art proprietary and
open-source models. Our datasets and models will be made publicly available at
https: //github.com/UBC-NLP/arastories.

æè¦ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼æè¿å·²æçºåç¨®èªè¨çæä»»åçå¼·å¤§å·¥å·ãåç®¡å¦æ­¤ï¼éé é²å±å¨é¿æä¼¯èªä¸­è¼çºç·©æ¢ãå¨éé å·¥ä½ä¸­ï¼æåå°æ³¨æ¼å¾ LLM çææäºçä»»åãå°æ¼æåçè¨ç·´ï¼æåä½¿ç¨ééæ©å¨ç¿»è­¯ï¼MTï¼ä»¥å GPT-4 ç²å¾çæäºãå°æ¼ MT è³æï¼æåéç¼äºä¸åä»ç´°çç®¡éï¼ä»¥ç¢ºä¿æåç²å¾é«åè³ªçæäºãå°æ¼æåç GPT-41 è³æï¼æåå¼å¥äºç²¾å¿è£½ä½çæç¤ºï¼ä½¿æåè½å¤ çæéå¸¸é©åé¿æä¼¯èªç°å¢çè³æï¼åæ¬ç¾ä»£æ¨æºé¿æä¼¯èªï¼MSAï¼åå©ç¨®é¿æä¼¯èªæ¹è¨ï¼ååèªåæ©æ´å¥èªï¼ãä¾å¦ï¼æåçæéå°åç¨®é¿æä¼¯åå®¶çæäºï¼ä¸»é¡å»£æ³ãæåçè©ä¼°é¡¯ç¤ºï¼æåéå°éäºè¨ç·´è³æéé²è¡å¾®èª¿çæ¨¡åå¯ä»¥çæç¬¦åæåæç¤ºçé£è²«æäºãæåéé²è¡äºå»£æ³çèªååäººå·¥è©ä¼°ï¼å°æåçæ¨¡åèæåé²çå°æåéæ¾åå§ç¢¼æ¨¡åé²è¡æ¯è¼ãæåçè³æéåæ¨¡åå°å¨ https: //github.com/UBC-NLP/arastories å¬éã

##### **Weakly-supervised Medical Image Segmentation with Gaze Annotations**
2407.07406v1 by Yuan Zhong, Chenhui Tang, Yumeng Yang, Ruoxi Qi, Kang Zhou, Yuqi Gong, Pheng Ann Heng, Janet H. Hsiao, Qi Dou

Eye gaze that reveals human observational patterns has increasingly been
incorporated into solutions for vision tasks. Despite recent explorations on
leveraging gaze to aid deep networks, few studies exploit gaze as an efficient
annotation approach for medical image segmentation which typically entails
heavy annotating costs. In this paper, we propose to collect dense weak
supervision for medical image segmentation with a gaze annotation scheme. To
train with gaze, we propose a multi-level framework that trains multiple
networks from discriminative human attention, simulated with a set of
pseudo-masks derived by applying hierarchical thresholds on gaze heatmaps.
Furthermore, to mitigate gaze noise, a cross-level consistency is exploited to
regularize overfitting noisy labels, steering models toward clean patterns
learned by peer networks. The proposed method is validated on two public
medical datasets of polyp and prostate segmentation tasks. We contribute a
high-quality gaze dataset entitled GazeMedSeg as an extension to the popular
medical segmentation datasets. To the best of our knowledge, this is the first
gaze dataset for medical image segmentation. Our experiments demonstrate that
gaze annotation outperforms previous label-efficient annotation schemes in
terms of both performance and annotation time. Our collected gaze data and code
are available at: https://github.com/med-air/GazeMedSeg.

æè¦ï¼äººç±»è§å¯æ¨¡å¼çç¼çæ³¨è§å·²è¶æ¥è¶å¤å°èå¥è§è§ä»»å¡çè§£å³æ¹æ¡ä¸­ãå°½ç®¡æè¿æ¢ç´¢äºå©ç¨æ³¨è§æ¥è¾å©æ·±åº¦ç½ç»ï¼ä½å¾å°æç ç©¶å©ç¨æ³¨è§ä½ä¸ºå»å­¦å¾ååå²çæææ³¨éæ¹æ³ï¼è¿éå¸¸éè¦å¤§éçæ³¨éææ¬ãå¨æ¬æä¸­ï¼æä»¬æåºæ¶éå¯éçå¼±çç£ï¼ç¨äºå·æåè§æ³¨éæ¹æ¡çå»å­¦å¾ååå²ãä¸ºäºç¨æ³¨è§è¿è¡è®­ç»ï¼æä»¬æåºäºä¸ä¸ªå¤çº§æ¡æ¶ï¼è¯¥æ¡æ¶ä»åºåæ§äººç±»æ³¨æåè®­ç»å¤ä¸ªç½ç»ï¼å¹¶éè¿å¨åè§ç­å¾ä¸åºç¨åå±éå¼æ¥æ¨¡æä¸ç»ä¼ªæ©ç ãæ­¤å¤ï¼ä¸ºäºåè½»æ³¨è§åªå£°ï¼å©ç¨è·¨çº§ä¸è´æ§æ¥æ­£ååè¿åº¦æåçåªå£°æ ç­¾ï¼å°æ¨¡åå¼å¯¼è³ç±å¯¹ç­ç½ç»å­¦ä¹ çå¹²åæ¨¡å¼ãææåºçæ¹æ³å·²å¨ä¸¤ä¸ªå¬å±å»å­¦æ°æ®éçå¤æ¯èåååèºåå²ä»»å¡ä¸å¾å°éªè¯ãæä»¬è´¡ç®äºä¸ä¸ªåä¸º GazeMedSeg çé«è´¨éåè§æ°æ®éï¼ä½ä¸ºæµè¡å»å­¦åå²æ°æ®éçæ©å±ãæ®æä»¬æç¥ï¼è¿æ¯å»å­¦å¾ååå²çç¬¬ä¸ä¸ªåè§æ°æ®éãæä»¬çå®éªè¡¨æï¼å¨æ§è½åæ³¨éæ¶é´æ¹é¢ï¼åè§æ³¨éä¼äºä»¥åçæ ç­¾é«ææ³¨éæ¹æ¡ãæä»¬æ¶éçåè§æ°æ®åä»£ç å¯å¨ä»¥ä¸ä½ç½®è·å¾ï¼https://github.com/med-air/GazeMedSegã

##### **Interpretable Differential Diagnosis with Dual-Inference Large Language Models**
2407.07330v1 by Shuang Zhou, Sirui Ding, Jiashuo Wang, Mingquan Lin, Genevieve B. Melton, Rui Zhang

Methodological advancements to automate the generation of differential
diagnosis (DDx) to predict a list of potential diseases as differentials given
patients' symptom descriptions are critical to clinical reasoning and
applications such as decision support. However, providing reasoning or
interpretation for these differential diagnoses is more meaningful.
Fortunately, large language models (LLMs) possess powerful language processing
abilities and have been proven effective in various related tasks. Motivated by
this potential, we investigate the use of LLMs for interpretable DDx. First, we
develop a new DDx dataset with expert-derived interpretation on 570 public
clinical notes. Second, we propose a novel framework, named Dual-Inf, that
enables LLMs to conduct bidirectional inference for interpretation. Both human
and automated evaluation demonstrate the effectiveness of Dual-Inf in
predicting differentials and diagnosis explanations. Specifically, the
performance improvement of Dual-Inf over the baseline methods exceeds 32%
w.r.t. BERTScore in DDx interpretation. Furthermore, experiments verify that
Dual-Inf (1) makes fewer errors in interpretation, (2) has great
generalizability, (3) is promising for rare disease diagnosis and explanation.

æè¦ï¼æ¹æ³å­¸çé²å±èªååçæå·®ç°è¨ºæ· (DDx)ï¼ä»¥é æ¸¬çµ¦å®æ£èççæè¿°çæ½å¨ç¾çæ¸å®ï¼å°æ¼è¨åºæ¨çåæ±ºç­æ¯æ´ç­æç¨è³ééè¦ãç¶èï¼æä¾éäºå·®ç°è¨ºæ·çæ¨çæè§£éæ´ææç¾©ãå¹¸éçæ¯ï¼å¤§åèªè¨æ¨¡å (LLM) ææå¼·å¤§çèªè¨èçè½åï¼ä¸¦å·²è¢«è­æå¨åç¨®ç¸éä»»åä¸­ææãåæ­¤æ½åçæ¿åµï¼æåç ç©¶äº LLM å¨å¯è§£éç DDx ä¸­çæç¨ãé¦åï¼æåéç¼äºä¸åæ°ç DDx æ¸æéï¼å¶ä¸­åå«å°å®¶å° 570 åå¬å±è¨åºç­è¨çè§£éãå¶æ¬¡ï¼æåæåºäºä¸ååçº Dual-Inf çæ°æ¡æ¶ï¼å®ä½¿ LLM è½å¤ é²è¡éåæ¨çä»¥é²è¡è§£éãäººé¡åèªååè©ä¼°é½è­æäº Dual-Inf å¨é æ¸¬å·®ç°åè¨ºæ·è§£éæ¹é¢çæææ§ãå·é«ä¾èªªï¼Dual-Inf å¨ DDx è§£éä¸­è¶éåºç·æ¹æ³çæ§è½æ¹é²è¶é 32% w.r.t. BERTScoreãæ­¤å¤ï¼å¯¦é©é©è­äº Dual-Inf (1) å¨è§£éä¸­ç¢çè¼å°çé¯èª¤ï¼(2) å·æå¾å¥½çæ¦æ¬æ§ï¼(3) å°ç½è¦ç¾ççè¨ºæ·åè§£éå¾æåæ¯ã

##### **Large Language Model-Augmented Auto-Delineation of Treatment Target Volume in Radiation Therapy**
2407.07296v1 by Praveenbalaji Rajendran, Yong Yang, Thomas R. Niedermayr, Michael Gensheimer, Beth Beadle, Quynh-Thu Le, Lei Xing, Xianjin Dai

Radiation therapy (RT) is one of the most effective treatments for cancer,
and its success relies on the accurate delineation of targets. However, target
delineation is a comprehensive medical decision that currently relies purely on
manual processes by human experts. Manual delineation is time-consuming,
laborious, and subject to interobserver variations. Although the advancements
in artificial intelligence (AI) techniques have significantly enhanced the
auto-contouring of normal tissues, accurate delineation of RT target volumes
remains a challenge. In this study, we propose a visual language model-based RT
target volume auto-delineation network termed Radformer. The Radformer utilizes
a hierarichal vision transformer as the backbone and incorporates large
language models to extract text-rich features from clinical data. We introduce
a visual language attention module (VLAM) for integrating visual and linguistic
features for language-aware visual encoding (LAVE). The Radformer has been
evaluated on a dataset comprising 2985 patients with head-and-neck cancer who
underwent RT. Metrics, including the Dice similarity coefficient (DSC),
intersection over union (IOU), and 95th percentile Hausdorff distance (HD95),
were used to evaluate the performance of the model quantitatively. Our results
demonstrate that the Radformer has superior segmentation performance compared
to other state-of-the-art models, validating its potential for adoption in RT
practice.

æè¦ï¼æ¾å°æ²»ç (RT) æ¯æææçççæ²»çæ¹æ³ä¹ä¸ï¼å¶æåæè³´æ¼ç®æ¨çæºç¢ºæç¹ªãç¶èï¼ç®æ¨æç¹ªæ¯ä¸é å¨é¢çé«çæ±ºç­ï¼ç®åå®å¨ä¾è³´äººé¡å°å®¶çæåç¨åºãæåæç¹ªèæãè²»åï¼ä¸åè§å¯èéå·®ç°å½±é¿ãåç®¡äººå·¥æºæ§ (AI) æè¡çé²æ­¥å·²é¡¯èå¢å¼·æ­£å¸¸çµç¹çèªåè¼ªå»æç¹ªï¼ä½ RT ç®æ¨é«ç©çæºç¢ºæç¹ªä»æ¯ä¸é ææ°ãå¨æ¬ç ç©¶ä¸­ï¼æåæåºä¸ååºæ¼è¦è¦ºèªè¨æ¨¡åç RT ç®æ¨é«ç©èªåæç¹ªç¶²è·¯ï¼ç¨±çº RadformerãRadformer å©ç¨éå±¤å¼è¦è¦ºTransformerä½çºä¸»å¹¹ï¼ä¸¦æ´åå¤§åèªè¨æ¨¡åå¾è¨åºè³æä¸­æåè±å¯æå­ç¹å¾µãæåå¼å¥ä¸åè¦è¦ºèªè¨æ³¨æåæ¨¡çµ (VLAM)ï¼ç¨æ¼æ´åè¦è¦ºåèªè¨ç¹å¾µï¼ä»¥é²è¡èªè¨æç¥è¦è¦ºç·¨ç¢¼ (LAVE)ãRadformer å·²å¨ä¸ååå« 2985 åæ¥å RT æ²»ççé ­é ¸çæ£èçè³æéä¸é²è¡è©ä¼°ãææ¨ï¼åæ¬ Dice ç¸ä¼¼ä¿æ¸ (DSC)ãè¯éæ¯ (IOU) åç¬¬ 95 åç¾åä½æ¸ Hausdorff è·é¢ (HD95)ï¼ç¨æ¼å®éè©ä¼°æ¨¡åçæè½ãæåççµæè¡¨æï¼èå¶ä»æåé²çæ¨¡åç¸æ¯ï¼Radformer å·æåªç°çåå²æè½ï¼é©è­äºå¶å¨ RT å¯¦åä¸­æç¨çæ½åã

##### **Causal Discovery in Semi-Stationary Time Series**
2407.07291v1 by Shanyun Gao, Raghavendra Addanki, Tong Yu, Ryan A. Rossi, Murat Kocaoglu

Discovering causal relations from observational time series without making
the stationary assumption is a significant challenge. In practice, this
challenge is common in many areas, such as retail sales, transportation
systems, and medical science. Here, we consider this problem for a class of
non-stationary time series. The structural causal model (SCM) of this type of
time series, called the semi-stationary time series, exhibits that a finite
number of different causal mechanisms occur sequentially and periodically
across time. This model holds considerable practical utility because it can
represent periodicity, including common occurrences such as seasonality and
diurnal variation. We propose a constraint-based, non-parametric algorithm for
discovering causal relations in this setting. The resulting algorithm,
PCMCI$_{\Omega}$, can capture the alternating and recurring changes in the
causal mechanisms and then identify the underlying causal graph with
conditional independence (CI) tests. We show that this algorithm is sound in
identifying causal relations on discrete time series. We validate the algorithm
with extensive experiments on continuous and discrete simulated data. We also
apply our algorithm to a real-world climate dataset.

æè¦ï¼å¨ä¸ä½å¹³ç©©åè¨­çææ³ä¸å¾è§æ¸¬æéåºåä¸­ç¼ç¾å æéä¿æ¯ä¸é éå¤§ææ°ãå¨å¯¦åä¸­ï¼éåææ°å¨è¨±å¤é åä¸­å¾å¸¸è¦ï¼ä¾å¦é¶å®é·å®ãéè¼¸ç³»çµ±åé«å­¸ç§å­¸ãå¨æ­¤ï¼æåèæ®éå¹³ç©©æéåºåé¡å¥çéååé¡ãéç¨®é¡åçæéåºåççµæ§å ææ¨¡å (SCM)ï¼ç¨±çºåå¹³ç©©æéåºåï¼å±ç¤ºäºæéæ¸éçä¸åå ææ©å¶æé¨èæéé åºä¸é±ææ§å°ç¼çãéåæ¨¡åå·æç¸ç¶å¤§çå¯¦ç¨æ§ï¼å çºå®å¯ä»¥è¡¨ç¤ºé±ææ§ï¼åæ¬å­£ç¯æ§åæå¤è®åç­å¸¸è¦ç¾è±¡ãæåæåºäºä¸ååºæ¼ç´æçéåæ¸æ¼ç®æ³ï¼ç¨æ¼ç¼ç¾éåè¨­å®ä¸­çå æéä¿ãç¢ççæ¼ç®æ³ PCMCI$_{\Omega}$ å¯ä»¥ææå ææ©å¶ä¸­çäº¤æ¿åéè¤è®åï¼ç¶å¾èç±æ¢ä»¶ç¨ç« (CI) æª¢å®ä¾è­å¥åºç¤å æåãæåè­æéåæ¼ç®æ³å¨è­å¥é¢æ£æéåºåä¸çå æéä¿ææ¯åççãæåä½¿ç¨é£çºåé¢æ£æ¨¡æ¬è³æé²è¡å»£æ³çå¯¦é©ï¼ä»¥é©è­æ¼ç®æ³ãæåä¹å°æåçæ¼ç®æ³æç¨æ¼çå¯¦ä¸ççæ°£åè³æéã

##### **Causal Discovery-Driven Change Point Detection in Time Series**
2407.07290v1 by Shanyun Gao, Raghavendra Addanki, Tong Yu, Ryan A. Rossi, Murat Kocaoglu

Change point detection in time series seeks to identify times when the
probability distribution of time series changes. It is widely applied in many
areas, such as human-activity sensing and medical science. In the context of
multivariate time series, this typically involves examining the joint
distribution of high-dimensional data: If any one variable changes, the whole
time series is assumed to have changed. However, in practical applications, we
may be interested only in certain components of the time series, exploring
abrupt changes in their distributions in the presence of other time series.
Here, assuming an underlying structural causal model that governs the
time-series data generation, we address this problem by proposing a two-stage
non-parametric algorithm that first learns parts of the causal structure
through constraint-based discovery methods. The algorithm then uses conditional
relative Pearson divergence estimation to identify the change points. The
conditional relative Pearson divergence quantifies the distribution disparity
between consecutive segments in the time series, while the causal discovery
method enables a focus on the causal mechanism, facilitating access to
independent and identically distributed (IID) samples. Theoretically, the
typical assumption of samples being IID in conventional change point detection
methods can be relaxed based on the Causal Markov Condition. Through
experiments on both synthetic and real-world datasets, we validate the
correctness and utility of our approach.

æè¦ï¼æéåºåçè®ç°é»åµæ¸¬æ¨å¨æ¾åºæéåºåçæ©çåä½æ¹è®çæéãå®å»£æ³æç¨æ¼è¨±å¤é åï¼ä¾å¦äººé¡æ´»åææ¸¬èé«å­¸ç§å­¸ãå¨å¤è®éæéåºåçèæ¯ä¸­ï¼ééå¸¸æ¶åæª¢è¦é«ç¶­åº¦è³æçè¯ååä½ï¼å¦æä»»ä½ä¸åè®æ¸æ¹è®ï¼ååè¨­æ´åæéåºåå·²ç¶æ¹è®ãç¶èï¼å¨å¯¦éæç¨ä¸­ï¼æåå¯è½åªå°æéåºåçç¹å®çµæé¨åæèè¶£ï¼æ¢ç´¢å®åçåä½å¨å¶ä»æéåºåå­å¨çææ³ä¸çªç¶æ¹è®ãå¨éè£¡ï¼åè¨­ä¸ååºç¤ççµæ§å ææ¨¡åæ¯éèæéåºåè³æççæï¼æåééæåºä¸åå©éæ®µéåæ¸æ¼ç®æ³ä¾è§£æ±ºéååé¡ï¼è©²æ¼ç®æ³é¦åééåºæ¼ç´æçç¼ç¾æ¹æ³ä¾å­¸ç¿å æçµæ§çé¨åãç¶å¾ï¼è©²æ¼ç®æ³ä½¿ç¨æ¢ä»¶ç¸å° Pearson å·®ç°ä¼°è¨ä¾æ¾åºè®ç°é»ãæ¢ä»¶ç¸å° Pearson å·®ç°éåæéåºåä¸­é£çºåæ®µä¹éçåä½å·®ç°ï¼èå æç¼ç¾æ¹æ³å¯ä»¥å°æ³¨æ¼å ææ©å¶ï¼ä¿é²åå¾ç¨ç«ä¸ååå¸ (IID) çæ¨£æ¬ãçè«ä¸ï¼æ¨£æ¬çº IID çå¸ååè¨­å¨å³çµ±è®ç°é»åµæ¸¬æ¹æ³ä¸­å¯ä»¥æ ¹æå æé¦¬å¯å¤«æ¢ä»¶æ¾å¯¬ãééå¨åæåçå¯¦ä¸çè³æéä¸é²è¡å¯¦é©ï¼æåé©è­äºæåæ¹æ³çæ­£ç¢ºæ§åå¯¦ç¨æ§ã

##### **Lifestyle-Informed Personalized Blood Biomarker Prediction via Novel Representation Learning**
2407.07277v1 by A. Ali Heydari, Naghmeh Rezaei, Javier L. Prieto, Shwetak N. Patel, Ahmed A. Metwally

Blood biomarkers are an essential tool for healthcare providers to diagnose,
monitor, and treat a wide range of medical conditions. Current reference values
and recommended ranges often rely on population-level statistics, which may not
adequately account for the influence of inter-individual variability driven by
factors such as lifestyle and genetics. In this work, we introduce a novel
framework for predicting future blood biomarker values and define personalized
references through learned representations from lifestyle data (physical
activity and sleep) and blood biomarkers. Our proposed method learns a
similarity-based embedding space that captures the complex relationship between
biomarkers and lifestyle factors. Using the UK Biobank (257K participants), our
results show that our deep-learned embeddings outperform traditional and
current state-of-the-art representation learning techniques in predicting
clinical diagnosis. Using a subset of UK Biobank of 6440 participants who have
follow-up visits, we validate that the inclusion of these embeddings and
lifestyle factors directly in blood biomarker models improves the prediction of
future lab values from a single lab visit. This personalized modeling approach
provides a foundation for developing more accurate risk stratification tools
and tailoring preventative care strategies. In clinical settings, this
translates to the potential for earlier disease detection, more timely
interventions, and ultimately, a shift towards personalized healthcare.

æè¦ï¼è¡æ¶²çç©æ¨è¨æ¯é«çä¿å¥æä¾èç¨æ¼è¨ºæ·ãç£æ¸¬åæ²»çåç¨®ç¾ççéè¦å·¥å·ãç®åçåèå¼åå»ºè­°ç¯åéå¸¸ä¾è³´æ¼äººç¾¤çµ±è¨æ¸æï¼èéäºæ¸æå¯è½ç¡æ³ååèªªæç±çæ´»æ¹å¼ååºå ç­å ç´ é©åçåé«éè®ç°çå½±é¿ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºä¸åæ°çæ¡æ¶ä¾é æ¸¬æªä¾çè¡æ¶²çç©æ¨è¨å¼ï¼ä¸¦ééå¾çæ´»æ¹å¼æ¸æï¼èº«é«æ´»ååç¡ç ï¼åè¡æ¶²çç©æ¨è¨ä¸­å­¸ç¿å°çè¡¨å¾µä¾å®ç¾©åæ§ååèãæåæåºçæ¹æ³å­¸ç¿äºä¸ååºæ¼ç¸ä¼¼æ§çåµå¥ç©ºéï¼è©²ç©ºéææäºçç©æ¨è¨åçæ´»æ¹å¼å ç´ ä¹éçè¤ééä¿ãä½¿ç¨è±åçç©éè¡ï¼257K åèèï¼ï¼æåççµæè¡¨æï¼æåæ·±åº¦å­¸ç¿çåµå¥åªæ¼å³çµ±åç¶åæåé²çè¡¨å¾µå­¸ç¿æè¡ï¼å¯ä»¥é æ¸¬è¨åºè¨ºæ·ãä½¿ç¨ææå¾çºè¨ªè¦ç 6440 ååèèçè±åçç©éè¡å­éï¼æåé©è­äºå¨è¡æ¶²çç©æ¨è¨æ¨¡åä¸­ç´æ¥åå«éäºåµå¥åçæ´»æ¹å¼å ç´ å¯ä»¥æ¹åå¾å®æ¬¡å¯¦é©å®¤è¨ªåä¸­é æ¸¬æªä¾å¯¦é©å®¤å¼ãéç¨®åæ§åå»ºæ¨¡æ¹æ³çºéç¼æ´æºç¢ºçé¢¨éªåå±¤å·¥å·åå®å¶é é²ä¿å¥ç­ç¥æä¾äºåºç¤ãå¨è¨åºç°å¢ä¸­ï¼éè½åçºæ©æç¾çæª¢æ¸¬ãæ´åæçå¹²é ï¼æçµè½ååæ§åé«çä¿å¥çæ½åã

##### **ProtoSAM -- One Shot Medical Image Segmentation With Foundational Models**
2407.07042v1 by Lev Ayzenberg, Raja Giryes, Hayit Greenspan

This work introduces a new framework, ProtoSAM, for one-shot medical image
segmentation. It combines the use of prototypical networks, known for few-shot
segmentation, with SAM - a natural image foundation model. The method proposed
creates an initial coarse segmentation mask using the ALPnet prototypical
network, augmented with a DINOv2 encoder. Following the extraction of an
initial mask, prompts are extracted, such as points and bounding boxes, which
are then input into the Segment Anything Model (SAM). State-of-the-art results
are shown on several medical image datasets and demonstrate automated
segmentation capabilities using a single image example (one shot) with no need
for fine-tuning of the foundation model.

æè¦ï¼æ¬ç ç©¶æåºä¸åæ°çæ¶æ§ï¼ProtoSAMï¼ç¨æ¼ä¸æ¬¡æ§é«å­¸å½±ååå²ãå®çµåäºååç¶²è·¯çä½¿ç¨ï¼ä»¥é²è¡å°æ¬¡åå²ï¼ä»¥å SAM - ä¸åèªç¶å½±ååºç¤æ¨¡åãææåºçæ¹æ³ä½¿ç¨ ALPnet ååç¶²è·¯å»ºç«ä¸ååå§çç²ç¥åå²é®ç½©ï¼ä¸¦ä½¿ç¨ DINOv2 ç·¨ç¢¼å¨é²è¡æ´åãå¨æååå§é®ç½©å¾ï¼ææåæç¤ºï¼ä¾å¦é»åéçæ¡ï¼ç¶å¾å°å¶è¼¸å¥å° Segment Anything Model (SAM) ä¸­ãå¨å¤åé«å­¸å½±åè³æéä¸é¡¯ç¤ºäºæåé²ççµæï¼ä¸¦å±ç¤ºäºä½¿ç¨å®ä¸å½±åç¯ä¾ï¼ä¸æ¬¡æ§ï¼çèªååå²åè½ï¼ç¡éå¾®èª¿åºç¤æ¨¡åã

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

æè¦ï¼äººå·¥æºè½ (AI) æ¯æçæ±ºç­å¶å®æ¯æªä¾ 6G ç¶²è·¯ä¸­çééµåç´ ï¼å¶ä¸­å°å¼å¥åç AI çæ¦å¿µãæ­¤å¤ï¼AI å»£æ³ç¨æ¼ä¸åçééµæç¨ä¸­ï¼ä¾å¦èªåé§é§åé«çè¨ºæ·ãå¨éäºæç¨ä¸­ï¼ä½¿ç¨ AI ä½çºé»çæ¨¡åæ¯æé¢¨éªä¸å·æææ°æ§çãå æ­¤ï¼çè§£åä¿¡ä»»éäºæ¨¡åååºçæ±ºç­è³ééè¦ãè§£æ±ºæ­¤åé¡çæ¹æ³æ¯éç¼å¯è§£é AI (XAI) æ¶æ§ï¼æ¨å¨è§£éé»çæ¨¡åè¡çºèå¾çéè¼¯ï¼å¾èç¢ºä¿å¶ææä¸å®å¨çé¨ç½²ãæè¿ï¼æåæåºäºä¸åæ°çåºæ¼æ¾åç XAI-CHEST æ¡æ¶ï¼è©²æ¡æ¶é¢åç¡ç·éä¿¡ä¸­çä¿¡éä¼°è¨ãXAI-CHEST æ¡æ¶çæ ¸å¿ææ³æ¯ééå¨ç¡éè¼¸å¥ä¸å¼å¥é«åªè²ä¾è­å¥ç¸éæ¨¡åè¼¸å¥ãéä»½æç¨¿æä¾äº XAI-CHEST æ¡æ¶çè©³ç´°çè«åºç¤ãç¹å¥æ¯ï¼æåæ¨å°äº XAI-CHEST æå¤±å½æ¸ååªè²é¾å¼å¾®èª¿åªååé¡çè§£æè¡¨éå¼ãå æ­¤ï¼è¨­è¨ç XAI-CHEST æä¾äºä¸ç¨®æºè½è¼¸å¥ç¹å¾µé¸ææ¹æ³ï¼å¯ä»¥å¨åªåæç¨æ¨¡åçæ¶æ§çåæé²ä¸æ­¥æé«æ´é«æ§è½ãæ¨¡æ¬çµæè¡¨æï¼XAI-CHEST æ¡æ¶æä¾äºææçè§£éï¼å¨éä½æéçè¨ç®è¤éåº¦çåæï¼æä¾äºæ¹é²çæ¯ç¹é¯èª¤çæ§è½ï¼èéèåºæ¼å³çµ± DL çä¿¡éä¼°è¨ç¸æ¯ã

##### **Microsoft Cloud-based Digitization Workflow with Rich Metadata Acquisition for Cultural Heritage Objects**
2407.06972v1 by Krzysztof Kutt, Jakub GomuÅka, Luiz do Valle Miranda, Grzegorz J. Nalepa

In response to several cultural heritage initiatives at the Jagiellonian
University, we have developed a new digitization workflow in collaboration with
the Jagiellonian Library (JL). The solution is based on easy-to-access
technological solutions -- Microsoft 365 cloud with MS Excel files as metadata
acquisition interfaces, Office Script for validation, and MS Sharepoint for
storage -- that allows metadata acquisition by domain experts (philologists,
historians, philosophers, librarians, archivists, curators, etc.) regardless of
their experience with information systems. The ultimate goal is to create a
knowledge graph that describes the analyzed holdings, linked to general
knowledge bases, as well as to other cultural heritage collections, so careful
attention is paid to the high accuracy of metadata and proper links to external
sources. The workflow has already been evaluated in two pilots in the DiHeLib
project focused on digitizing the so-called "Berlin Collection" and in two
workshops with international guests, which allowed for its refinement and
confirmation of its correctness and usability for JL. As the proposed workflow
does not interfere with existing systems or domain guidelines regarding
digitization and basic metadata collection in a given institution (e.g., file
type, image quality, use of Dublin Core/MARC-21), but extends them in order to
enable rich metadata collection, not previously possible, we believe that it
could be of interest to all GLAMs (galleries, libraries, archives, and
museums).

æè¦ï¼<paragraph>çºåæ Jagiello å¤§å­¸çæ¸åæåéºç¢å¡è­°ï¼æåè Jagiello åæ¸é¤¨ (JL) åä½éç¼ä¸åæ°çæ¸ä½åå·¥ä½æµç¨ãæ­¤è§£æ±ºæ¹æ¡åºæ¼ææ¼å­åçæè¡è§£æ±ºæ¹æ¡ï¼åæ¬ï¼ä½çºåè³ææ·åä»é¢ç Microsoft 365 é²ç«¯è MS Excel æªæ¡ãç¨æ¼é©è­ç Office Scriptï¼ä»¥åç¨æ¼å²å­ç MS Sharepointï¼å®åè¨±é åå°å®¶ï¼èªè¨å­¸å®¶ãæ­·å²å­¸å®¶ãå²å­¸å®¶ãåæ¸é¤¨å¡ãæªæ¡ç®¡çå¡ãç­å±äººç­ï¼æ·ååè³æï¼èç¡é å·åè³è¨ç³»çµ±æ¹é¢çç¶é©ãæçµç®æ¨æ¯å»ºç«ä¸åç¥è­åè­ï¼ç¨ä»¥æè¿°æåæçé¤¨èï¼ä¸¦é£çµè³ä¸è¬ç¥è­åº«ï¼ä»¥åå¶ä»æåéºç¢é¤¨èï¼å æ­¤æåéå¸¸éè¦åè³æçé«æºç¢ºæ§ï¼ä»¥åèå¤é¨ä¾æºçé©ç¶é£çµãæ­¤å·¥ä½æµç¨å·²å¨ DiHeLib å°æ¡ä¸­å©åè©¦é»è¨ç«ä¸­é²è¡è©ä¼°ï¼è©²å°æ¡å°æ³¨æ¼æ¸ä½åæè¬çãææé¤¨èãï¼ä»¥åèåéè¨ªå®¢é²è¡çå©åå·¥ä½åï¼éè®æåå¾ä»¥æ¹åå·¥ä½æµç¨ï¼ä¸¦ç¢ºèªå¶æ­£ç¢ºæ§ï¼ä»¥åå° JL çå¯ç¨æ§ãç±æ¼ææåºçå·¥ä½æµç¨ä¸æå¹²æ¾æ¢æç³»çµ±æéæ¼æ¸ä½åååºæ¬åè³æèéçé åæåï¼ä¾å¦ï¼æªæ¡é¡åãå½±ååè³ªãä½¿ç¨ Dublin Core/MARC-21ï¼ï¼èæ¯æ´åéäºç³»çµ±ï¼ä»¥æ¯æ´ä»¥åç¡æ³é²è¡çè±å¯åè³æèéï¼å æ­¤æåç¸ä¿¡å®å¯è½æå¼èµ·ææ GLAMï¼ç«å»ãåæ¸é¤¨ãæªæ¡é¤¨ååç©é¤¨ï¼çèè¶£ã</paragraph>

##### **TE-SSL: Time and Event-aware Self Supervised Learning for Alzheimer's Disease Progression Analysis**
2407.06852v1 by Jacob Thrasher, Alina Devkota, Ahmed Tafti, Binod Bhattarai, Prashnna Gyawali

Alzheimer's Dementia (AD) represents one of the most pressing challenges in
the field of neurodegenerative disorders, with its progression analysis being
crucial for understanding disease dynamics and developing targeted
interventions. Recent advancements in deep learning and various representation
learning strategies, including self-supervised learning (SSL), have shown
significant promise in enhancing medical image analysis, providing innovative
ways to extract meaningful patterns from complex data. Notably, the computer
vision literature has demonstrated that incorporating supervisory signals into
SSL can further augment model performance by guiding the learning process with
additional relevant information. However, the application of such supervisory
signals in the context of disease progression analysis remains largely
unexplored. This gap is particularly pronounced given the inherent challenges
of incorporating both event and time-to-event information into the learning
paradigm. Addressing this, we propose a novel framework, Time and Even-aware
SSL (TE-SSL), which integrates time-to-event and event data as supervisory
signals to refine the learning process. Our comparative analysis with existing
SSL-based methods in the downstream task of survival analysis shows superior
performance across standard metrics.

æè¦ï¼é¿è²æµ·é»çå¤±æºç (AD) æ¯ç¥ç¶éåæ§ç¾çé åä¸­æè¿«åçææ°ä¹ä¸ï¼å¶é²ç¨åæå°æ¼äºè§£ç¾çåæåéç¼ç®æ¨æ§å¹²é æªæ½è³ééè¦ãæ·±åº¦å­¸ç¿ååç¨®è¡¨ç¤ºå­¸ç¿ç­ç¥ï¼åæ¬èªç£ç£å­¸ç¿ (SSL)ï¼çææ°é²å±ï¼å·²å¨å¢å¼·é«å­¸å½±ååææ¹é¢å±ç¾é¡¯èåæ¯ï¼æä¾å¾è¤éè³æä¸­æåææç¾©æ¨¡å¼çåµæ°æ¹æ³ãå¼å¾æ³¨æçæ¯ï¼é»è¦è¦è¦ºæç»å·²è­æå°ç£ç£è¨èç´å¥ SSL å¯ä»¥ééæä¾é¡å¤ç¸éè³è¨ä¾æå°å­¸ç¿éç¨ï¼é²ä¸æ­¥å¢å¼·æ¨¡åæè½ãç¶èï¼æ­¤é¡ç£ç£è¨èå¨ç¾çé²ç¨åæä¸­çæç¨ä»æªå¾å°ååæ¢è¨ãç±æ¼å°äºä»¶åäºä»¶æéè³è¨ç´å¥å­¸ç¿ç¯ä¾çåºæææ°ï¼æ­¤å·®è·ç¹å¥æé¡¯ãéå°æ­¤åé¡ï¼æåæåºä¸ååµæ°çæ¶æ§ï¼æéåäºä»¶æç¥ SSL (TE-SSL)ï¼å®æ´åäºä»¶æéåäºä»¶è³æä½çºç£ç£è¨èï¼ä»¥åªåå­¸ç¿éç¨ãæåå¨çå­åæçä¸æ¸¸ä»»åä¸­ï¼å°å¶èç¾æåºæ¼ SSL çæ¹æ³é²è¡æ¯è¼åæï¼é¡¯ç¤ºå¶å¨æ¨æºææ¨ä¸çæè½åªç°ã

##### **VRDSynth: Synthesizing Programs for Multilingual Visually Rich Document Information Extraction**
2407.06826v1 by Thanh-Dat Nguyen, Tung Do-Viet, Hung Nguyen-Duy, Tuan-Hai Luu, Hung Le, Bach Le, Patanamon, Thongtanunam

Businesses need to query visually rich documents (VRDs) like receipts,
medical records, and insurance forms to make decisions. Existing techniques for
extracting entities from VRDs struggle with new layouts or require extensive
pre-training data. We introduce VRDSynth, a program synthesis method to
automatically extract entity relations from multilingual VRDs without
pre-training data. To capture the complexity of VRD domain, we design a
domain-specific language (DSL) to capture spatial and textual relations to
describe the synthesized programs. Along with this, we also derive a new
synthesis algorithm utilizing frequent spatial relations, search space pruning,
and a combination of positive, negative, and exclusive programs to improve
coverage.
  We evaluate VRDSynth on the FUNSD and XFUND benchmarks for semantic entity
linking, consisting of 1,592 forms in 8 languages. VRDSynth outperforms
state-of-the-art pre-trained models (LayoutXLM, InfoXLMBase, and
XLMRobertaBase) in 5, 6, and 7 out of 8 languages, respectively, improving the
F1 score by 42% over LayoutXLM in English. To test the extensibility of the
model, we further improve VRDSynth with automated table recognition, creating
VRDSynth(Table), and compare it with extended versions of the pre-trained
models, InfoXLM(Large) and XLMRoberta(Large). VRDSynth(Table) outperforms these
baselines in 4 out of 8 languages and in average F1 score. VRDSynth also
significantly reduces memory footprint (1M and 380MB vs. 1.48GB and 3GB for
LayoutXLM) while maintaining similar time efficiency.

æè¦ï¼<paragraph>ä¼æ¥­éè¦æ¥è©¢è¦è¦ºè±å¯çæä»¶ (VRD)ï¼ä¾å¦æ¶æãé«çè¨éåä¿éªå®æï¼æè½ååºæ±ºç­ãç¾æçæè¡ç¨æ¼å¾ VRD ä¸­æåå¯¦é«ï¼æéå°æ°ççé¢åé¡ï¼æèéè¦å¤§éçé è¨ç·´æ¸æãæåä»ç´¹ VRDSynthï¼éæ¯ä¸ç¨®ç¨å¼åææ¹æ³ï¼å¯ä»¥å¨æ²æé è¨ç·´æ¸æçææ³ä¸èªåå¾å¤èªè¨ VRD ä¸­æåå¯¦é«éä¿ãçºäºææ VRD é åçè¤éæ§ï¼æåè¨­è¨äºä¸åç¹å®é åèªè¨ (DSL)ï¼ç¨æ¼ææç©ºéåæå­éä¿ï¼ä»¥æè¿°åæçç¨å¼ãé¤æ­¤ä¹å¤ï¼æåéæ¨å°åºä¸åæ°çåææ¼ç®æ³ï¼å©ç¨é »ç¹çç©ºééä¿ãæå°ç©ºéåªæï¼ä»¥åæ­£ãè² åæä»ç¨å¼ççµåï¼ä»¥æ¹åæ¶µèç¯åã
æåå¨ FUNSD å XFUND åºæºä¸è©ä¼° VRDSynthï¼ç¨æ¼èªç¾©å¯¦é«é£çµï¼åå« 8 ç¨®èªè¨ç 1,592 åè¡¨å®ãVRDSynth å¨ 8 ç¨®èªè¨ä¸­ç 5ã6 å 7 ç¨®èªè¨ä¸­åªæ¼æåé²çé è¨ç·´æ¨¡å (LayoutXLMãInfoXLMBase å XLMRobertaBase)ï¼åå¥å°è±æä¸­ç F1 åæ¸æé«äº 42%ï¼é«æ¼ LayoutXLMãçºäºæ¸¬è©¦æ¨¡åçå¯æ´åæ§ï¼æåé²ä¸æ­¥æ¹é² VRDSynthï¼æ¡ç¨èªååè¡¨æ ¼è­å¥ï¼å»ºç« VRDSynth(Table)ï¼ä¸¦å°å¶èé è¨ç·´æ¨¡å InfoXLM(Large) å XLMRoberta(Large) çå»¶ä¼¸çæ¬é²è¡æ¯è¼ãVRDSynth(Table) å¨ 8 ç¨®èªè¨ä¸­ç 4 ç¨®èªè¨åå¹³å F1 åæ¸ä¸­åªæ¼éäºåºæºãVRDSynth éé¡¯èæ¸å°äºè¨æ¶é«ä½¿ç¨é (1M å 380MBï¼è LayoutXLM çº 1.48GB å 3GB)ï¼åæç¶­æé¡ä¼¼çæéæçã</paragraph>

##### **iASiS: Towards Heterogeneous Big Data Analysis for Personalized Medicine**
2407.06748v1 by Anastasia Krithara, Fotis Aisopos, Vassiliki Rentoumi, Anastasios Nentidis, Konstantinos Bougatiotis, Maria-Esther Vidal, Ernestina Menasalvas, Alejandro Rodriguez-Gonzalez, Eleftherios G. Samaras, Peter Garrard, Maria Torrente, Mariano Provencio Pulla, Nikos Dimakopoulos, Rui Mauricio, Jordi Rambla De Argila, Gian Gaetano Tartaglia, George Paliouras

The vision of IASIS project is to turn the wave of big biomedical data
heading our way into actionable knowledge for decision makers. This is achieved
by integrating data from disparate sources, including genomics, electronic
health records and bibliography, and applying advanced analytics methods to
discover useful patterns. The goal is to turn large amounts of available data
into actionable information to authorities for planning public health
activities and policies. The integration and analysis of these heterogeneous
sources of information will enable the best decisions to be made, allowing for
diagnosis and treatment to be personalised to each individual. The project
offers a common representation schema for the heterogeneous data sources. The
iASiS infrastructure is able to convert clinical notes into usable data,
combine them with genomic data, related bibliography, image data and more, and
create a global knowledge base. This facilitates the use of intelligent methods
in order to discover useful patterns across different resources. Using semantic
integration of data gives the opportunity to generate information that is rich,
auditable and reliable. This information can be used to provide better care,
reduce errors and create more confidence in sharing data, thus providing more
insights and opportunities. Data resources for two different disease categories
are explored within the iASiS use cases, dementia and lung cancer.

æè¦ï¼IASIS é ç®çé¡æ¯æ¯å°ææåèä¾çé¾å¤§çç©é«å­¸æ¸ææµªæ½®è½è®çºæ±ºç­èçå¯è¡ç¥è­ãéæ¯ééæ´åä¾èªä¸åä¾æºçæ¸æï¼åæ¬åºå çµå­¸ãé»å­å¥åº·è¨éåæ¸ç®ï¼ï¼ä¸¦æç¨åé²çåææ¹æ³ä¾ç¼ç¾æç¨çæ¨¡å¼ä¾å¯¦ç¾çãç®æ¨æ¯å°å¤§éå¯ç¨æ¸æè½åçºå¯è¡çè³è¨ï¼ä¾ç¶å±è¦åå¬å±è¡çæ´»ååæ¿ç­ãæ´åååæéäºç°è³ªçè³è¨ä¾æºå°ä½¿æä½³æ±ºç­å¾ä»¥å¶å®ï¼ä¸¦åè¨±å°æ¯åäººçè¨ºæ·åæ²»çé²è¡åäººåãè©²å°æ¡çºç°è³ªæ¸æä¾æºæä¾äºä¸åå±åçè¡¨ç¤ºæ¶æ§ãiASiS åºç¤è¨­æ½è½å¤ å°è¨åºç­è¨è½æçºå¯ç¨æ¸æï¼å°å¶èåºå çµæ¸æãç¸éæ¸ç®ãå½±åæ¸æç­çµåèµ·ä¾ï¼ä¸¦å»ºç«ä¸åå¨çç¥è­åº«ãéæå©æ¼ä½¿ç¨æºæ§æ¹æ³ä¾ç¼ç¾ä¸åè³æºä¹éçæç¨æ¨¡å¼ãä½¿ç¨æ¸æçèªç¾©æ´åæä¾äºç¢çè±å¯ãå¯ç¨½æ ¸ä¸å¯é è³è¨çæ©æãéäºè³è¨å¯ç¨æ¼æä¾æ´å¥½çç§è­·ãæ¸å°é¯èª¤ï¼ä¸¦å°è³æå±äº«å»ºç«æ´å¤ä¿¡å¿ï¼å¾èæä¾æ´å¤è¦è§£åæ©æãå¨ iASiS çä½¿ç¨æ¡ä¾ä¸­ï¼æ¢è¨äºå©ç¨®ä¸åç¾çé¡å¥çæ¸æè³æºï¼å³å¤±æºçåèºçã

##### **Generative AI for Health Technology Assessment: Opportunities, Challenges, and Policy Considerations**
2407.11054v1 by Rachael Fleurence, Jiang Bian, Xiaoyan Wang, Hua Xu, Dalia Dawoud, Tala Fakhouri, Mitch Higashi, Jagpreet Chhatwal

This review introduces the transformative potential of generative Artificial
Intelligence (AI) and foundation models, including large language models
(LLMs), for health technology assessment (HTA). We explore their applications
in four critical areas, evidence synthesis, evidence generation, clinical
trials and economic modeling: (1) Evidence synthesis: Generative AI has the
potential to assist in automating literature reviews and meta-analyses by
proposing search terms, screening abstracts, and extracting data with notable
accuracy; (2) Evidence generation: These models can potentially facilitate
automating the process and analyze the increasingly available large collections
of real-world data (RWD), including unstructured clinical notes and imaging,
enhancing the speed and quality of real-world evidence (RWE) generation; (3)
Clinical trials: Generative AI can be used to optimize trial design, improve
patient matching, and manage trial data more efficiently; and (4) Economic
modeling: Generative AI can also aid in the development of health economic
models, from conceptualization to validation, thus streamlining the overall HTA
process. Despite their promise, these technologies, while rapidly improving,
are still nascent and continued careful evaluation in their applications to HTA
is required. To ensure their responsible use and implementation, both
developers and users of research incorporating these tools, should familiarize
themselves with their current limitations, including the issues related to
scientific validity, risk of bias, and consider equity and ethical
implications. We also surveyed the current policy landscape and provide
suggestions for HTA agencies on responsibly integrating generative AI into
their workflows, emphasizing the importance of human oversight and the
fast-evolving nature of these tools.

æè¦ï¼æ¬ç¯è©è«ä»ç´¹äºçæå¼äººå·¥æºæ§ (AI) ååºç¤æ¨¡åï¼åæ¬å¤§åèªè¨æ¨¡å (LLM)ï¼å¨å¥åº·æè¡è©ä¼° (HTA) ä¸­çè½åæ½åãæåæ¢è¨äºå®åå¨ååééµé åçæç¨ï¼è­æç¶åãè­æçæãè¨åºè©¦é©åç¶æ¿å»ºæ¨¡ï¼(1) è­æç¶åï¼çæå¼ AI ææ½ååå©èªååæç»åé¡§åçµ±ååæï¼æ¹æ³æ¯æåºæå°è©å½ãç¯©é¸æè¦åæåè³æï¼æºç¢ºåº¦é¡¯èï¼(2) è­æçæï¼éäºæ¨¡åææ½åä¿é²èªååæµç¨ï¼ä¸¦åææ¥çå¯å¾çå¤§éçå¯¦ä¸çè³æ (RWD) éåï¼åæ¬éçµæ§åè¨åºç­è¨åå½±åï¼æåçå¯¦ä¸çè­æ (RWE) çæçéåº¦ååè³ªï¼(3) è¨åºè©¦é©ï¼çæå¼ AI å¯ç¨æ¼æä½³åè©¦é©è¨­è¨ãæ¹åæ£èéå°ï¼ä¸¦æ´ææçå°ç®¡çè©¦é©è³æï¼(4) ç¶æ¿å»ºæ¨¡ï¼çæå¼ AI ä¹å¯ä»¥åå©éç¼å¥åº·ç¶æ¿æ¨¡åï¼å¾æ¦å¿µåå°é©è­ï¼é²èç°¡åæ´é« HTA æµç¨ãåç®¡éäºæè¡åæ¯çå¥½ï¼ä¸é²æ­¥ç¥éï¼ä½ä»èæ¼èè½éæ®µï¼éè¦æçºå°å¿è©ä¼°å®åå¨ HTA ä¸­çæç¨ãçºäºç¢ºä¿è² è²¬ä»»å°ä½¿ç¨åå¯¦æ½éäºæè¡ï¼éäºå·¥å·çç ç©¶éç¼äººå¡åä½¿ç¨èé½æè©²çæå®åç®åçéå¶ï¼åæ¬èç§å­¸æåº¦ãåå·®é¢¨éªç¸éçåé¡ï¼ä¸¦èæ®å¬å¹³æ§åå«çææ¶µãæåä¹èª¿æ¥äºç®åçæ¿ç­ç¾æ³ï¼ä¸¦éå° HTA æ©æ§æä¾å»ºè­°ï¼èªªæå¦ä½è² è²¬ä»»å°å°çæå¼ AI æ´åå°å·¥ä½æµç¨ä¸­ï¼å¼·èª¿äººå·¥ç£ç£åéäºå·¥å·å¿«éæ¼è®çæ¬è³ªã

##### **TCKIN: A Novel Integrated Network Model for Predicting Mortality Risk in Sepsis Patients**
2407.06560v1 by Fanglin Dong

Sepsis poses a major global health threat, accounting for millions of deaths
annually and significant economic costs. Accurate predictions of mortality risk
in sepsis patients facilitate the efficient allocation of medical resources,
thereby enhancing patient survival and quality of life. Through precise risk
assessments, healthcare facilities can effectively distribute intensive care
beds, medical equipment, and staff, ensuring high-risk patients receive timely
and appropriate care. Early identification and intervention significantly
decrease mortality rates and improve patient outcomes. Current methods
typically utilize only one type of data--either constant, temporal, or ICD
codes. This study introduces the Time-Constant KAN Integrated Network(TCKIN),
an innovative model that enhances the accuracy of sepsis mortality risk
predictions by integrating both temporal and constant data from electronic
health records and ICD codes. Validated against the MIMIC-III and MIMIC-IV
datasets, TCKIN surpasses existing machine learning and deep learning methods
in accuracy, sensitivity, and specificity. Notably, TCKIN achieved AUCs of
87.76% and 88.07%, demonstrating superior capability in identifying high-risk
patients. Additionally, TCKIN effectively combats the prevalent issue of data
imbalance in clinical settings, improving the detection of patients at elevated
risk of mortality and facilitating timely interventions. These results confirm
the model's effectiveness and its potential to transform patient management and
treatment optimization in clinical practice. With this advanced risk assessment
tool, healthcare providers can devise more tailored treatment plans, optimize
resource utilization, and ultimately enhance survival rates and quality of life
for sepsis patients.

æè¦ï¼<paragraph>æè¡çæ§æå¨çä¸»è¦çå¥åº·å¨èï¼æ¯å¹´é ææ¸ç¾è¬äººæ­»äº¡ï¼ä¸¦å¸¶ä¾é¾å¤§çç¶æ¿ææ¬ãæºç¢ºé æ¸¬æè¡çæ£èçæ­»äº¡é¢¨éªï¼æå©æ¼ææåéé«çè³æºï¼å¾èæåæ£èå­æ´»çåçæ´»åè³ªãééç²¾ç¢ºçé¢¨éªè©ä¼°ï¼é«çæ©æ§å¯ä»¥ææåéå è­·çæ¿çåºãé«çè¨­ååäººå¡ï¼ç¢ºä¿é«é¢¨éªæ£èè½åæç²å¾é©ç¶çç§è­·ãæ©æç¼ç¾åä»å¥å¯ä»¥é¡¯èéä½æ­»äº¡çï¼ä¸¦æ¹åæ£èé å¾ãç®åçæ¹æ³éå¸¸åä½¿ç¨ä¸ç¨®é¡åçè³æï¼ä¾å¦å¸¸æ¸ãæéæ ICD ç·¨ç¢¼ãæ¬ç ç©¶å¼å¥äºæéå¸¸æ¸ KAN æ´åç¶²è·¯ (TCKIN)ï¼éæ¯ä¸ååµæ°çæ¨¡åï¼ééæ´åé»å­å¥åº·ç´éå ICD ç·¨ç¢¼ä¸­çæéåå¸¸æ¸è³æï¼ä¾æåæè¡çæ­»äº¡é¢¨éªé æ¸¬çæºç¢ºæ§ãå¨ MIMIC-III å MIMIC-IV è³æéé©è­ä¸ï¼TCKIN å¨æºç¢ºæ§ãæææ§åç¹ç°æ§æ¹é¢é½è¶è¶äºç¾æçæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¹æ³ãå¼å¾æ³¨æçæ¯ï¼TCKIN éå°äº 87.76% å 88.07% ç AUCï¼é¡¯ç¤ºåºåªç°çè­å¥é«é¢¨éªæ£èè½åãæ­¤å¤ï¼TCKIN ææå°è§£æ±ºäºè¨åºç°å¢ä¸­æ®éå­å¨çè³æä¸å¹³è¡¡åé¡ï¼æ¹åäºå°æ­»äº¡é¢¨éªè¼é«çæ£èçæª¢æ¸¬ï¼ä¸¦ä¿é²åæä»å¥ãéäºçµæè­å¯¦äºè©²æ¨¡åçæææ§ï¼ä»¥åå¶å¨è¨åºå¯¦åä¸­è½åæ£èç®¡çååªåæ²»ççæ½åãæäºéåé²éçé¢¨éªè©ä¼°å·¥å·ï¼é«çä¿å¥æä¾èå¯ä»¥å¶å®æ´å®¢è£½åçæ²»çè¨ç«ï¼æä½³åè³æºå©ç¨ï¼ä¸¦æçµæåæè¡çæ£èçå­æ´»çåçæ´»åè³ªã</paragraph>

##### **AI-driven multi-omics integration for multi-scale predictive modeling of causal genotype-environment-phenotype relationships**
2407.06405v1 by You Wu, Lei Xie

Despite the wealth of single-cell multi-omics data, it remains challenging to
predict the consequences of novel genetic and chemical perturbations in the
human body. It requires knowledge of molecular interactions at all biological
levels, encompassing disease models and humans. Current machine learning
methods primarily establish statistical correlations between genotypes and
phenotypes but struggle to identify physiologically significant causal factors,
limiting their predictive power. Key challenges in predictive modeling include
scarcity of labeled data, generalization across different domains, and
disentangling causation from correlation. In light of recent advances in
multi-omics data integration, we propose a new artificial intelligence
(AI)-powered biology-inspired multi-scale modeling framework to tackle these
issues. This framework will integrate multi-omics data across biological
levels, organism hierarchies, and species to predict causal
genotype-environment-phenotype relationships under various conditions. AI
models inspired by biology may identify novel molecular targets, biomarkers,
pharmaceutical agents, and personalized medicines for presently unmet medical
needs.

æè¦ï¼åç®¡æè±å¯çå®ç´°èå¤çµå­¸è³æï¼ä½é æ¸¬äººé«ä¸­æ°çéºå³ååå­¸æ¾åçå¾æä»ç¶å·æææ°æ§ãééè¦äºè§£ææçç©å±¤ç´çåå­äº¤äºä½ç¨ï¼åæ¬ç¾çæ¨¡ååäººé¡ãç®åçæ©å¨å­¸ç¿æ¹æ³ä¸»è¦å»ºç«åºå ååè¡¨åä¹éççµ±è¨ç¸éæ§ï¼ä½é£ä»¥è­å¥ççä¸éè¦çå æå ç´ ï¼å¾èéå¶äºå¶é æ¸¬è½åãé æ¸¬å»ºæ¨¡ä¸­çä¸»è¦ææ°åæ¬æ¨è¨è³æçç¨ç¼ºæ§ãè·¨ä¸åé åçæ¦åï¼ä»¥åå°å æéä¿å¾ç¸éæ§ä¸­è§£éãéæ¼å¤çµå­¸è³ææ´åçææ°é²å±ï¼æåæåºäºä¸åæ°çç±äººå·¥æºæ§ (AI) é©åçãåçç©åç¼çå¤å°ºåº¦å»ºæ¨¡æ¡æ¶ä¾è§£æ±ºéäºåé¡ãæ­¤æ¡æ¶å°æ´åè·¨çç©å±¤ç´ãçç©é«å±¤ç´åç©ç¨®çå¤çµå­¸è³æï¼ä»¥é æ¸¬å¨åç¨®æ¢ä»¶ä¸çå æåºå å-ç°å¢-è¡¨åéä¿ãåçç©åç¼ç AI æ¨¡åå¯è½æè­å¥åºæ°çåå­é¶æ¨ãçç©æ¨è¨ãè¥ç©ååæ§åè¥ç©ï¼ä»¥æ»¿è¶³ç®åå°æªæ»¿è¶³çé«çéæ±ã

##### **Multimodal Chain-of-Thought Reasoning via ChatGPT to Protect Children from Age-Inappropriate Apps**
2407.06309v1 by Chuanbo Hu, Bin Liu, Minglei Yin, Yilu Zhou, Xin Li

Mobile applications (Apps) could expose children to inappropriate themes such
as sexual content, violence, and drug use. Maturity rating offers a quick and
effective method for potential users, particularly guardians, to assess the
maturity levels of apps. Determining accurate maturity ratings for mobile apps
is essential to protect children's health in today's saturated digital
marketplace. Existing approaches to maturity rating are either inaccurate
(e.g., self-reported rating by developers) or costly (e.g., manual
examination). In the literature, there are few text-mining-based approaches to
maturity rating. However, each app typically involves multiple modalities,
namely app description in the text, and screenshots in the image. In this
paper, we present a framework for determining app maturity levels that utilize
multimodal large language models (MLLMs), specifically ChatGPT-4 Vision.
Powered by Chain-of-Thought (CoT) reasoning, our framework systematically
leverages ChatGPT-4 to process multimodal app data (i.e., textual descriptions
and screenshots) and guide the MLLM model through a step-by-step reasoning
pathway from initial content analysis to final maturity rating determination.
As a result, through explicitly incorporating CoT reasoning, our framework
enables ChatGPT to understand better and apply maturity policies to facilitate
maturity rating. Experimental results indicate that the proposed method
outperforms all baseline models and other fusion strategies.

æè¦ï¼è¡åæç¨ç¨å¼ (App) å¯è½è®åç«¥æ¥è§¸å°ä¸é©ç¶çä¸»é¡ï¼ä¾å¦æ§å§å®¹ãæ´ååè¥ç©ä½¿ç¨ãæçåº¦è©åæä¾ä¸ç¨®å¿«éä¸ææçæ¹æ³ï¼è®æ½å¨ä½¿ç¨èï¼å°¤å¶æ¯ç£è­·äººï¼è©ä¼°æç¨ç¨å¼çæçåº¦ç­ç´ãå¨ç¶ä»é£½åçæ¸ä½å¸å ´ä¸­ï¼çºè¡åæç¨ç¨å¼ç¢ºå®æºç¢ºçæçåº¦è©åå°æ¼ä¿è­·åç«¥å¥åº·è³ééè¦ãç¾æçæçåº¦è©åæ¹æ³ä¸æ¯ä¸æºç¢ºï¼ä¾å¦ï¼éç¼äººå¡èªè¡å ±åçè©åï¼ï¼å°±æ¯ææ¬é«æï¼ä¾å¦ï¼äººå·¥å¯©æ¥ï¼ãå¨æç»ä¸­ï¼å¾å°æåºæ¼æå­æ¢åçæ¹æ³ä¾è©ä¼°æçåº¦ãç¶èï¼æ¯åæç¨ç¨å¼éå¸¸æ¶åå¤ç¨®æ¨¡å¼ï¼å³æå­ä¸­çæç¨ç¨å¼èªªæåå½±åä¸­çè¢å¹æªåãå¨æ¬æä¸­ï¼æåæåºä¸åæ¡æ¶ï¼ç¨æ¼ç¢ºå®æç¨ç¨å¼çæçåº¦ç­ç´ï¼è©²æ¡æ¶å©ç¨å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM)ï¼ç¹å¥æ¯ ChatGPT-4 Visionãæåçæ¡æ¶æ¡ç¨æç¶­é (CoT) æ¨ççºåºç¤ï¼ç³»çµ±æ§å°å©ç¨ ChatGPT-4 èçå¤æ¨¡ææç¨ç¨å¼è³æï¼å³æå­èªªæåè¢å¹æªåï¼ï¼ä¸¦å¼å° MLLM æ¨¡åéæ­¥é²è¡æ¨çè·¯å¾ï¼å¾åå§å§å®¹åæå°æçµæçåº¦è©åç¢ºå®ãå æ­¤ï¼ééæç¢ºç´å¥ CoT æ¨çï¼æåçæ¡æ¶ä½¿ ChatGPT è½å¤ æ´æ·±å¥å°äºè§£ä¸¦æç¨æçåº¦æ¿ç­ä¾ä¿é²æçåº¦è©åãå¯¦é©çµæè¡¨æï¼ææåºçæ¹æ³åªæ¼ææåºç·æ¨¡ååå¶ä»èåç­ç¥ã

##### **Hybrid X-Linker: Automated Data Generation and Extreme Multi-label Ranking for Biomedical Entity Linking**
2407.06292v1 by Pedro Ruas, Fernando Gallego, Francisco J. Veredas, Francisco M. Couto

State-of-the-art deep learning entity linking methods rely on extensive
human-labelled data, which is costly to acquire. Current datasets are limited
in size, leading to inadequate coverage of biomedical concepts and diminished
performance when applied to new data. In this work, we propose to automatically
generate data to create large-scale training datasets, which allows the
exploration of approaches originally developed for the task of extreme
multi-label ranking in the biomedical entity linking task. We propose the
hybrid X-Linker pipeline that includes different modules to link disease and
chemical entity mentions to concepts in the MEDIC and the CTD-Chemical
vocabularies, respectively. X-Linker was evaluated on several biomedical
datasets: BC5CDR-Disease, BioRED-Disease, NCBI-Disease, BC5CDR-Chemical,
BioRED-Chemical, and NLM-Chem, achieving top-1 accuracies of 0.8307, 0.7969,
0.8271, 0.9511, 0.9248, and 0.7895, respectively. X-Linker demonstrated
superior performance in three datasets: BC5CDR-Disease, NCBI-Disease, and
BioRED-Chemical. In contrast, SapBERT outperformed X-Linker in the remaining
three datasets. Both models rely only on the mention string for their
operations. The source code of X-Linker and its associated data are publicly
available for performing biomedical entity linking without requiring
pre-labelled entities with identifiers from specific knowledge organization
systems.

æè¦ï¼æåé²çæ·±åº¦å­¸ç¿å¯¦é«é£çµæ¹æ³ä¾è³´æ¼å¤§éç
äººå·¥æ¨ç±¤è³æï¼èéé¡è³æçåå¾ææ¬å¾é«ãç®åçè³æé
å¤§å°æéï¼å°è´çç©é«å­¸æ¦å¿µæ¶µèä¸è¶³ï¼å¨æç¨æ¼æ°è³æææè½éä½ãå¨éé å·¥ä½ä¸­ï¼æåæè­°èªå
ç¢çè³æï¼ä»¥å»ºç«å¤§è¦æ¨¡çè¨ç·´è³æéï¼éåè¨±æ¢ç´¢åæ¬æ¯çºçç©é«å­¸å¯¦é«é£çµä»»åä¸­æ¥µç«¯å¤æ¨ç±¤æåä»»åèéç¼çæ¹æ³ãæåæè­°æ··å X-Linker ç®¡ç·ï¼å¶ä¸­åå«ä¸åçæ¨¡çµï¼åå¥å°ç¾çååå­¸å¯¦é«æåé£çµå° MEDIC å CTD-Chemical å­å½ä¸­çæ¦å¿µãX-Linker å·²å¨å¤åçç©é«å­¸è³æéä¸é²è¡è©ä¼°ï¼BC5CDR-DiseaseãBioRED-DiseaseãNCBI-DiseaseãBC5CDR-ChemicalãBioRED-Chemical å NLM-Chemï¼åå¥éå° 0.8307ã0.7969ã0.8271ã0.9511ã0.9248 å 0.7895 ç top-1 æºç¢ºåº¦ãX-Linker å¨ä¸åè³æéï¼BC5CDR-DiseaseãNCBI-Disease å BioRED-Chemical ä¸­è¡¨ç¾åºåªç°çæè½ãç¸åå°ï¼SapBERT å¨å¶é¤ä¸åè³æéä¸­åªæ¼ X-Linkerãå©åæ¨¡ååä¾è³´æ¼å®åæä½çæåå­ä¸²ãX-Linker åå¶ç¸éè³æçåå§ç¨å¼ç¢¼å¬éæä¾ï¼å¯å·è¡çç©é«å­¸å¯¦é«é£çµï¼èç¡éç¹å®ç¥è­çµç¹ç³»çµ±ä¸­è­å¥ç¬¦èçé åæ¨ç±¤å¯¦é«ã

##### **Depression Detection and Analysis using Large Language Models on Textual and Audio-Visual Modalities**
2407.06125v1 by Avinash Anand, Chayan Tank, Sarthak Pol, Vinayak Katoch, Shaina Mehta, Rajiv Ratn Shah

Depression has proven to be a significant public health issue, profoundly
affecting the psychological well-being of individuals. If it remains
undiagnosed, depression can lead to severe health issues, which can manifest
physically and even lead to suicide. Generally, Diagnosing depression or any
other mental disorder involves conducting semi-structured interviews alongside
supplementary questionnaires, including variants of the Patient Health
Questionnaire (PHQ) by Clinicians and mental health professionals. This
approach places significant reliance on the experience and judgment of trained
physicians, making the diagnosis susceptible to personal biases. Given that the
underlying mechanisms causing depression are still being actively researched,
physicians often face challenges in diagnosing and treating the condition,
particularly in its early stages of clinical presentation. Recently,
significant strides have been made in Artificial neural computing to solve
problems involving text, image, and speech in various domains. Our analysis has
aimed to leverage these state-of-the-art (SOTA) models in our experiments to
achieve optimal outcomes leveraging multiple modalities. The experiments were
performed on the Extended Distress Analysis Interview Corpus Wizard of Oz
dataset (E-DAIC) corpus presented in the Audio/Visual Emotion Challenge (AVEC)
2019 Challenge. The proposed solutions demonstrate better results achieved by
Proprietary and Open-source Large Language Models (LLMs), which achieved a Root
Mean Square Error (RMSE) score of 3.98 on Textual Modality, beating the AVEC
2019 challenge baseline results and current SOTA regression analysis
architectures. Additionally, the proposed solution achieved an accuracy of
71.43% in the classification task. The paper also includes a novel audio-visual
multi-modal network that predicts PHQ-8 scores with an RMSE of 6.51.

æè¦ï¼æé¬±çå·²è¢«è­å¯¦æ¯ä¸åéå¤§çå¬å±è¡çè­°é¡ï¼æ·±å»å½±é¿åäººå¿çå¥åº·ãå¦ææé¬±çæªç¶è¨ºæ·ï¼å¯è½æå°è´å´éçå¥åº·åé¡ï¼éäºåé¡å¯è½å¨ççä¸é¡¯ç¾ï¼çè³å°è´èªæ®ºãéå¸¸ï¼è¨ºæ·æé¬±çæä»»ä½å¶ä»ç²¾ç¥ç¾çé½æ¶åé²è¡åçµæ§åè¨ªè«ï¼ä»¥åè£ååå·ï¼åæ¬è¨åºé«çåå¿çå¥åº·å°æ¥­äººå¡æä½¿ç¨çæ£èå¥åº·åå· (PHQ) è®é«ãéç¨®æ¹æ³éå¸¸ä¾è³´åéè¨ç·´çé«å¸«çç¶é©åå¤æ·ï¼ä½¿è¨ºæ·å®¹æåå°åäººåè¦çå½±é¿ãç±æ¼å°è´æé¬±ççæ½å¨æ©å¶ä»å¨ç©æ¥µç ç©¶ä¸­ï¼å æ­¤é«å¸«å¨è¨ºæ·åæ²»çéç¨®ç¾çæç¶å¸¸é¢è¨ææ°ï¼å°¤å¶æ¯å¨è¨åºè¡¨ç¾çæ©æéæ®µãæè¿ï¼äººå·¥ç¥ç¶éç®å¨è§£æ±ºæ¶åææ¬ãå½±ååèªè¨çåç¨®é ååé¡æ¹é¢åå¾äºéå¤§é²å±ãæåçåææ¨å¨å©ç¨éäºæåé² (SOTA) æ¨¡åå¨æåçå¯¦é©ä¸­ï¼ééå©ç¨å¤ç¨®æ¨¡å¼ä¾éææä½³çµæãéäºå¯¦é©æ¯å¨ Audio/Visual Emotion Challenge (AVEC) 2019 Challenge ä¸­æåºç Extended Distress Analysis Interview Corpus Wizard of Oz è³æé (E-DAIC) èªæåº«ä¸é²è¡çãææåºçè§£æ±ºæ¹æ¡è­æäºå°æåéæ¾åå§ç¢¼å¤§åèªè¨æ¨¡å (LLM) æåå¾çè¼ä½³çµæï¼éäºæ¨¡åå¨ææ¬æ¨¡å¼ä¸éå°äº 3.98 çåæ¹æ ¹èª¤å·® (RMSE) åæ¸ï¼åªæ¼ AVEC 2019 ææ°åºæºçµæåç®åç SOTA åæ­¸åææ¶æ§ãæ­¤å¤ï¼ææåºçè§£æ±ºæ¹æ¡å¨åé¡ä»»åä¸­éå°äº 71.43% çæºç¢ºçãæ¬æéåæ¬ä¸åæ°ç©çé³è¨è¦è¦ºå¤æ¨¡å¼ç¶²è·¯ï¼å¶ä½¿ç¨ 6.51 ç RMSE é æ¸¬ PHQ-8 åæ¸ã

##### **Igea: a Decoder-Only Language Model for Biomedical Text Generation in Italian**
2407.06011v1 by Tommaso Mario Buonocore, Simone Rancati, Enea Parimbelli

The development of domain-specific language models has significantly advanced
natural language processing applications in various specialized fields,
particularly in biomedicine. However, the focus has largely been on
English-language models, leaving a gap for less-resourced languages such as
Italian. This paper introduces Igea, the first decoder-only language model
designed explicitly for biomedical text generation in Italian. Built on the
Minerva model and continually pretrained on a diverse corpus of Italian medical
texts, Igea is available in three model sizes: 350 million, 1 billion, and 3
billion parameters. The models aim to balance computational efficiency and
performance, addressing the challenges of managing the peculiarities of medical
terminology in Italian. We evaluate Igea using a mix of in-domain biomedical
corpora and general-purpose benchmarks, highlighting its efficacy and retention
of general knowledge even after the domain-specific training. This paper
discusses the model's development and evaluation, providing a foundation for
future advancements in Italian biomedical NLP.

æè¦ï¼ç¹å®é åèªè¨æ¨¡åçç¼å±å·²å¤§å¹æåäºåç¨®å°æ¥­é åçèªç¶èªè¨èçæç¨ï¼ç¹å¥æ¯å¨çç©é«å­¸é åãç¶èï¼ç®åçç ç©¶éé»ä¸»è¦æ¾å¨è±èªèªè¨æ¨¡åä¸ï¼éå°ç¾©å¤§å©èªç­è³æºè¼å°çèªè¨ä¾èªªæ¯ä¸å¤§ç¼ºæ¾ãæ¬æä»ç´¹äº Igeaï¼éæ¯ç¬¬ä¸åå°éè¨­è¨ç¨æ¼ç¾©å¤§å©èªçç©é«å­¸ææ¬çæçåè§£ç¢¼å¨èªè¨æ¨¡åãIgea å»ºæ§å¨ Minerva æ¨¡åä¸ï¼ä¸¦æçºå¨å¤§éç¾©å¤§å©é«å­¸ææ¬èªæåº«ä¸é²è¡é è¨ç·´ï¼æä¾ä¸ç¨®æ¨¡åå¤§å°ï¼3.5 åã10 åå 30 åååæ¸ãéäºæ¨¡åæ¨å¨å¹³è¡¡éç®æçåæè½ï¼è§£æ±ºèçç¾©å¤§å©èªé«å­¸è¡èªç¹æ§çææ°ãæåä½¿ç¨æ··åé åçç©é«å­¸èªæåº«åéç¨åºæºå° Igea é²è¡è©ä¼°ï¼å¼·èª¿äºå¶åæåå¨ç¹å®é åè¨ç·´å¾ä»è½ä¿çä¸è¬ç¥è­ãæ¬ææ¢è¨äºæ¨¡åçéç¼åè©ä¼°ï¼çºç¾©å¤§å©èªçç©é«å­¸èªç¶èªè¨èççæªä¾é²å±å¥ å®äºåºç¤ã

##### **Generation and De-Identification of Indian Clinical Discharge Summaries using LLMs**
2407.05887v1 by Sanjeet Singh, Shreya Gupta, Niralee Gupta, Naimish Sharma, Lokesh Srivastava, Vibhu Agarwal, Ashutosh Modi

The consequences of a healthcare data breach can be devastating for the
patients, providers, and payers. The average financial impact of a data breach
in recent months has been estimated to be close to USD 10 million. This is
especially significant for healthcare organizations in India that are managing
rapid digitization while still establishing data governance procedures that
align with the letter and spirit of the law. Computer-based systems for
de-identification of personal information are vulnerable to data drift, often
rendering them ineffective in cross-institution settings. Therefore, a rigorous
assessment of existing de-identification against local health datasets is
imperative to support the safe adoption of digital health initiatives in India.
Using a small set of de-identified patient discharge summaries provided by an
Indian healthcare institution, in this paper, we report the nominal performance
of de-identification algorithms (based on language models) trained on publicly
available non-Indian datasets, pointing towards a lack of cross-institutional
generalization. Similarly, experimentation with off-the-shelf de-identification
systems reveals potential risks associated with the approach. To overcome data
scarcity, we explore generating synthetic clinical reports (using publicly
available and Indian summaries) by performing in-context learning over Large
Language Models (LLMs). Our experiments demonstrate the use of generated
reports as an effective strategy for creating high-performing de-identification
systems with good generalization capabilities.

æè¦ï¼é«çä¿å¥è³æå¤æ´©çå¾æå°æ£èãæä¾èåä»æ¬¾èä¾èªªå¯è½æ¯æ¯æ»æ§çãæè¿å¹¾åæè³æå¤æ´©çå¹³åè²¡åå½±é¿ä¼°è¨æ¥è¿ 1,000 è¬ç¾åãéå°å°åº¦çé«çä¿å¥çµç¹ä¾èªªå°¤å¶éè¦ï¼éäºçµç¹å¨ç®¡çå¿«éæ¸ä½åçåæï¼ä»å¨å»ºç«ç¬¦åæ³å¾æ¢æåç²¾ç¥çè³ææ²»çç¨åºãç¨æ¼å»è­å¥åäººè³è¨çé»è¦ç³»çµ±å®¹æåå°è³ææ¼ç§»çå½±é¿ï¼éå¸¸å°è´å®åå¨è·¨æ©æ§è¨­å®ä¸­ç¡æãå æ­¤ï¼å¿é å´æ ¼è©ä¼°ç¾æçå»è­å¥èç¶å°å¥åº·è³æéï¼æè½æ¯æ´å°åº¦å®å¨æ¡ç¨æ¸ä½å¥åº·è¨ç«ãæ¬æä½¿ç¨å°åº¦é«çä¿å¥æ©æ§æä¾çä¸å°çµå»è­å¥æ£èåºé¢æè¦ï¼å ±åäºå¨å¬éå¯ç¨çéå°åº¦è³æéä¸è¨ç·´çå»è­å¥æ¼ç®æ³ï¼åºæ¼èªè¨æ¨¡åï¼çæ¨ç¨±æè½ï¼æåºç¼ºä¹è·¨æ©æ§æ¦åãåæ¨£å°ï¼å°ç¾æçå»è­å¥ç³»çµ±é²è¡å¯¦é©æ­ç¤ºäºèè©²æ¹æ³ç¸éçæ½å¨é¢¨éªãçºäºåæè³æç¨å°çåé¡ï¼æåæ¢è¨ééå¨å¤§èªè¨æ¨¡å (LLM) ä¸å·è¡æå¢å­¸ç¿ä¾ç¢çåæè¨åºå ±åï¼ä½¿ç¨å¬éå¯ç¨çå°åº¦æè¦ï¼ãæåçå¯¦é©è­æäºä½¿ç¨ç¢ççå ±åä½çºå»ºç«å·æè¯å¥½æ¦åè½åçé«æè½å»è­å¥ç³»çµ±çææç­ç¥ã

##### **Integrating AI in College Education: Positive yet Mixed Experiences with ChatGPT**
2407.05810v1 by Xinrui Song, Jiajin Zhang, Pingkun Yan, Juergen Hahn, Uwe Kruger, Hisham Mohamed, Ge Wang

The integration of artificial intelligence (AI) chatbots into higher
education marks a shift towards a new generation of pedagogical tools,
mirroring the arrival of milestones like the internet. With the launch of
ChatGPT-4 Turbo in November 2023, we developed a ChatGPT-based teaching
application (https://chat.openai.com/g/g-1imx1py4K-chatge-medical-imaging) and
integrated it into our undergraduate medical imaging course in the Spring 2024
semester. This study investigates the use of ChatGPT throughout a semester-long
trial, providing insights into students' engagement, perception, and the
overall educational effectiveness of the technology. We systematically
collected and analyzed data concerning students' interaction with ChatGPT,
focusing on their attitudes, concerns, and usage patterns. The findings
indicate that ChatGPT offers significant advantages such as improved
information access and increased interactivity, but its adoption is accompanied
by concerns about the accuracy of the information provided and the necessity
for well-defined guidelines to optimize its use.

æè¦ï¼äººå·¥æºè½ï¼AIï¼èå¤©æ©å¨äººæ´åå°é«ç­æè²ä¸­ï¼æ¨èªèæ°ä¸ä»£æå­¸å·¥å·çè½è®ï¼åæ äºç¶²è·¯ç­éç¨ç¢çå°ä¾ãé¨è ChatGPT-4 Turbo å¨ 2023 å¹´ 11 ææ¨åºï¼æåéç¼äºä¸ååºæ¼ ChatGPT çæå­¸æç¨ç¨å¼ï¼https://chat.openai.com/g/g-1imx1py4K-chatge-medical-imagingï¼ï¼ä¸¦å¨ 2024 å¹´æ¥å­£å­¸æå°å¶æ´åå°æåçé«å­¸å½±åå­¸æ¬ç§èª²ç¨ä¸­ãæ¬ç ç©¶èª¿æ¥äºå¨ä¸åå­¸æé·çè©¦é©ä¸­ä½¿ç¨ ChatGPT çææ³ï¼æ·±å¥äºè§£å­¸ççåèåº¦ãçæ³åæè¡çæ´é«æè²ææãæåç³»çµ±å°æ¶éååæäºæéå­¸çè ChatGPT äºåçè³æï¼éé»éæ³¨ä»åçæåº¦ãçæ®åä½¿ç¨æ¨¡å¼ãç ç©¶çµæè¡¨æï¼ChatGPT æä¾äºé¡¯èçåªå¢ï¼ä¾å¦æ¹é²è³è¨çåå¾åå¢å äºåæ§ï¼ä½å¶æ¡ç¨ä¹ä¼´é¨èå°ææä¾è³è¨æºç¢ºæ§ççæ®ï¼ä»¥åæä½³åå¶ä½¿ç¨çæç¢ºæºåçå¿è¦æ§ã

##### **FedMRL: Data Heterogeneity Aware Federated Multi-agent Deep Reinforcement Learning for Medical Imaging**
2407.05800v1 by Pranab Sahoo, Ashutosh Tripathi, Sriparna Saha, Samrat Mondal

Despite recent advancements in federated learning (FL) for medical image
diagnosis, addressing data heterogeneity among clients remains a significant
challenge for practical implementation. A primary hurdle in FL arises from the
non-IID nature of data samples across clients, which typically results in a
decline in the performance of the aggregated global model. In this study, we
introduce FedMRL, a novel federated multi-agent deep reinforcement learning
framework designed to address data heterogeneity. FedMRL incorporates a novel
loss function to facilitate fairness among clients, preventing bias in the
final global model. Additionally, it employs a multi-agent reinforcement
learning (MARL) approach to calculate the proximal term $(\mu)$ for the
personalized local objective function, ensuring convergence to the global
optimum. Furthermore, FedMRL integrates an adaptive weight adjustment method
using a Self-organizing map (SOM) on the server side to counteract distribution
shifts among clients' local data distributions. We assess our approach using
two publicly available real-world medical datasets, and the results demonstrate
that FedMRL significantly outperforms state-of-the-art techniques, showing its
efficacy in addressing data heterogeneity in federated learning. The code can
be found here~{\url{https://github.com/Pranabiitp/FedMRL}}.

æè¦ï¼åç®¡å¨ç¨æ¼é«å­¸å½±åè¨ºæ·çè¯é¦å­¸ç¿ (FL) æ¹é¢æè¿æçé²å±ï¼ä½è§£æ±ºå®¢æ¶ç«¯ä¹éçè³æç°è³ªæ§ä»ç¶æ¯å¯¦éå·è¡çéå¤§ææ°ãè¯é¦å­¸ç¿çä¸»è¦éç¤ä¾èªæ¼å®¢æ¶ç«¯ä¹éè³ææ¨£æ¬çéç¨ç«ååå¸ (non-IID) ç¹æ§ï¼ééå¸¸æå°è´å½ç¸½çå¨çæ¨¡åæè½ä¸éãå¨æ¬ç ç©¶ä¸­ï¼æåå¼å¥äº FedMRLï¼ä¸åæ°ç©çè¯é¦å¤æºè½é«æ·±åº¦å¼·åå­¸ç¿æ¡æ¶ï¼æ¨å¨è§£æ±ºè³æç°è³ªæ§ãFedMRL çµåäºä¸åæ°ç©çæå¤±å½æ¸ï¼ä»¥ä¿é²å®¢æ¶ç«¯ä¹éçå¬å¹³æ§ï¼é²æ­¢æçµå¨çæ¨¡åä¸­çåå·®ãæ­¤å¤ï¼å®æ¡ç¨å¤æºè½é«å¼·åå­¸ç¿ (MARL) æ¹æ³ä¾è¨ç®åæ§åå±é¨ç®æ¨å½æ¸çè¿ç«¯é  (Î¼)ï¼ç¢ºä¿æ¶æå°å¨å±æåªå¼ãæ­¤å¤ï¼FedMRL æ´åäºä¸ç¨®èªé©ææ¬éèª¿æ´æ¹æ³ï¼å¨ä¼ºæå¨ç«¯ä½¿ç¨èªçµç¹åå°æ (SOM)ï¼ä»¥æµæ¶å®¢æ¶ç«¯æ¬å°è³æåä½ä¹éçåå¸è½ç§»ãæåä½¿ç¨å©åå¬éå¯ç¨ççå¯¦ä¸çé«å­¸è³æéè©ä¼°æåçåæ³ï¼çµæè¡¨æ FedMRL æé¡¯åªæ¼æåé²çæè¡ï¼é¡¯ç¤ºå¶å¨è§£æ±ºè¯é¦å­¸ç¿ä¸­è³æç°è³ªæ§æ¹é¢çæè½ãç¨å¼ç¢¼å¯ä»¥å¨éè£¡æ¾å°~{\url{https://github.com/Pranabiitp/FedMRL}}ã

##### **Large Language Models for Judicial Entity Extraction: A Comparative Study**
2407.05786v1 by Atin Sakkeer Hussain, Anu Thomas

Domain-specific Entity Recognition holds significant importance in legal
contexts, serving as a fundamental task that supports various applications such
as question-answering systems, text summarization, machine translation,
sentiment analysis, and information retrieval specifically within case law
documents. Recent advancements have highlighted the efficacy of Large Language
Models in natural language processing tasks, demonstrating their capability to
accurately detect and classify domain-specific facts (entities) from
specialized texts like clinical and financial documents. This research
investigates the application of Large Language Models in identifying
domain-specific entities (e.g., courts, petitioner, judge, lawyer, respondents,
FIR nos.) within case law documents, with a specific focus on their aptitude
for handling domain-specific language complexity and contextual variations. The
study evaluates the performance of state-of-the-art Large Language Model
architectures, including Large Language Model Meta AI 3, Mistral, and Gemma, in
the context of extracting judicial facts tailored to Indian judicial texts.
Mistral and Gemma emerged as the top-performing models, showcasing balanced
precision and recall crucial for accurate entity identification. These findings
confirm the value of Large Language Models in judicial documents and
demonstrate how they can facilitate and quicken scientific research by
producing precise, organised data outputs that are appropriate for in-depth
examination.

æè¦ï¼é åç¹å®å¯¦é«è¾¨è­å¨æ³å¾èçµ¡ä¸­è³ééè¦ï¼ä½çºæ¯æ´åç¨®æç¨ç¨å¼çåºç¤ä»»åï¼ä¾å¦å¨æ¡ä¾æ³æä»¶ä¸­é²è¡åç­ç³»çµ±ãæå­æè¦ãæ©å¨ç¿»è­¯ãæç·åæåè³è¨æª¢ç´¢ãæè¿çé²å±çªé¡¯äºå¤§åèªè¨æ¨¡åå¨èªç¶èªè¨èçä»»åä¸­çæè½ï¼å±ç¤ºäºå®åæºç¢ºåµæ¸¬ååé¡ä¾èªå°æ¥­ææ¬ï¼ä¾å¦è¨åºåè²¡åæä»¶ï¼çé åç¹å®äºå¯¦ï¼å¯¦é«ï¼çè½åãæ¬ç ç©¶æ¢è¨äºå¤§åèªè¨æ¨¡åå¨æ¡ä¾æ³æä»¶ä¸­è¾¨è­é åç¹å®å¯¦é«ï¼ä¾å¦æ³é¢ãè«é¡äººãæ³å®ãå¾å¸«ãç­è¾¯äººãFIR ç·¨èï¼çæç¨ï¼ç¹å¥éæ³¨å®åèçé åç¹å®èªè¨è¤éæ§åèçµ¡è®åçè½åãæ¬ç ç©¶è©ä¼°äºæåé²çå¤§åèªè¨æ¨¡åæ¶æ§ï¼åæ¬ Large Language Model Meta AI 3ãMistral å Gemmaï¼å¨æåéå°å°åº¦å¸æ³ææ¬éèº«æé çå¸æ³äºå¯¦æ¹é¢çæè½ãMistral å Gemma æçºè¡¨ç¾æä½³çæ¨¡åï¼å±ç¤ºäºæºç¢ºå¯¦é«è¾¨è­è³ééè¦çå¹³è¡¡ç²¾ç¢ºåº¦åå¬åçãéäºç¼ç¾è­å¯¦äºå¤§åèªè¨æ¨¡åå¨å¸æ³æä»¶ä¸­çå¹å¼ï¼ä¸¦å±ç¤ºäºå®åå¦ä½ééç¢çé©ç¨æ¼æ·±å¥æª¢é©çç²¾ç¢ºãæçµç¹çè³æè¼¸åºï¼ä¾ä¿é²åå éç§å­¸ç ç©¶ã

##### **Potential of Multimodal Large Language Models for Data Mining of Medical Images and Free-text Reports**
2407.05758v1 by Yutong Zhang, Yi Pan, Tianyang Zhong, Peixin Dong, Kangni Xie, Yuxiao Liu, Hanqi Jiang, Zhengliang Liu, Shijie Zhao, Tuo Zhang, Xi Jiang, Dinggang Shen, Tianming Liu, Xin Zhang

Medical images and radiology reports are crucial for diagnosing medical
conditions, highlighting the importance of quantitative analysis for clinical
decision-making. However, the diversity and cross-source heterogeneity of these
data challenge the generalizability of current data-mining methods. Multimodal
large language models (MLLMs) have recently transformed many domains,
significantly affecting the medical field. Notably, Gemini-Vision-series
(Gemini) and GPT-4-series (GPT-4) models have epitomized a paradigm shift in
Artificial General Intelligence (AGI) for computer vision, showcasing their
potential in the biomedical domain. In this study, we evaluated the performance
of the Gemini, GPT-4, and 4 popular large models for an exhaustive evaluation
across 14 medical imaging datasets, including 5 medical imaging categories
(dermatology, radiology, dentistry, ophthalmology, and endoscopy), and 3
radiology report datasets. The investigated tasks encompass disease
classification, lesion segmentation, anatomical localization, disease
diagnosis, report generation, and lesion detection. Our experimental results
demonstrated that Gemini-series models excelled in report generation and lesion
detection but faces challenges in disease classification and anatomical
localization. Conversely, GPT-series models exhibited proficiency in lesion
segmentation and anatomical localization but encountered difficulties in
disease diagnosis and lesion detection. Additionally, both the Gemini series
and GPT series contain models that have demonstrated commendable generation
efficiency. While both models hold promise in reducing physician workload,
alleviating pressure on limited healthcare resources, and fostering
collaboration between clinical practitioners and artificial intelligence
technologies, substantial enhancements and comprehensive validations remain
imperative before clinical deployment.

æè¦ï¼<paragraph>é«å­¸å½±ååæ¾å°ç§å ±åå°è¨ºæ·é«ççæ³è³ééè¦ï¼çªé¡¯äºå®éåæå¨è¨åºæ±ºç­ä¸­çéè¦æ§ãç¶èï¼éäºæ¸æçå¤æ¨£æ§åè·¨ä¾æºç°è³ªæ§ææ°äºç¶åæ¸ææææ¹æ³çæ¦æ¬æ§ãå¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) è¿ä¾å·²è½è®è¨±å¤é åï¼å°é«å­¸é åå½±é¿éå¤§ãå¼å¾æ³¨æçæ¯ï¼Gemini-Vision ç³»å (Gemini) å GPT-4 ç³»å (GPT-4) æ¨¡åå·²æçºé»è¦è¦è¦ºä¸­äººå·¥éç¨æºæ§ (AGI) çå¸ç¯è½ç§»ï¼å±ç¤ºäºå®åå¨çç©é«å­¸é åçæ½åãå¨éé ç ç©¶ä¸­ï¼æåè©ä¼°äº GeminiãGPT-4 å 4 åç±éå¤§åæ¨¡åå¨ 14 åé«çå½±åæ¸æéä¸çå»£æ³è©ä¼°è¡¨ç¾ï¼åæ¬ 5 åé«çå½±åé¡å¥ï¼ç®èç§ãæ¾å°ç§ãçç§ãç¼ç§åå§è¦é¡æª¢æ¥ï¼ï¼ä»¥å 3 åæ¾å°ç§å ±åæ¸æéãæèª¿æ¥çä»»ååæ¬ç¾çåé¡ãçç¶åå²ãè§£åå®ä½ãç¾çè¨ºæ·ãå ±åçæåçç¶æª¢æ¸¬ãæåçå¯¦é©çµæè¡¨æï¼Gemini ç³»åæ¨¡åå¨å ±åçæåçç¶æª¢æ¸¬æ¹é¢è¡¨ç¾åºè²ï¼ä½å¨ç¾çåé¡åè§£åå®ä½æ¹é¢é¢è¨ææ°ãç¸åï¼GPT ç³»åæ¨¡åå¨çç¶åå²åè§£åå®ä½æ¹é¢è¡¨ç¾åºçç·´åº¦ï¼ä½å¨ç¾çè¨ºæ·åçç¶æª¢æ¸¬æ¹é¢éå°å°é£ãæ­¤å¤ï¼Gemini ç³»åå GPT ç³»åé½åå«å·²è­æå·æå¯åçææççæ¨¡åãåç®¡éå©ç¨®æ¨¡åé½æææ¸å°é«å¸«çå·¥ä½éï¼æ¸è¼æéé«çä¿å¥è³æºçå£åï¼ä¸¦ä¿é²è¨åºå¾æ¥­äººå¡èäººå·¥æºæ§æè¡ä¹éçåä½ï¼ä½å¨è¨åºé¨ç½²ä¹åï¼å¯¦è³ªæ§çå¢å¼·åå¨é¢çé©è­ä»ç¶å¢å¨å¿è¡ã</paragraph>

##### **RadiomicsFill-Mammo: Synthetic Mammogram Mass Manipulation with Radiomics Features**
2407.05683v1 by Inye Na, Jonghun Kim, Eun Sook Ko, Hyunjin Park

Motivated by the question, "Can we generate tumors with desired attributes?''
this study leverages radiomics features to explore the feasibility of
generating synthetic tumor images. Characterized by its low-dimensional yet
biologically meaningful markers, radiomics bridges the gap between complex
medical imaging data and actionable clinical insights. We present
RadiomicsFill-Mammo, the first of the RadiomicsFill series, an innovative
technique that generates realistic mammogram mass images mirroring specific
radiomics attributes using masked images and opposite breast images, leveraging
a recent stable diffusion model. This approach also allows for the
incorporation of essential clinical variables, such as BI-RADS and breast
density, alongside radiomics features as conditions for mass generation.
Results indicate that RadiomicsFill-Mammo effectively generates diverse and
realistic tumor images based on various radiomics conditions. Results also
demonstrate a significant improvement in mass detection capabilities,
leveraging RadiomicsFill-Mammo as a strategy to generate simulated samples.
Furthermore, RadiomicsFill-Mammo not only advances medical imaging research but
also opens new avenues for enhancing treatment planning and tumor simulation.
Our code is available at https://github.com/nainye/RadiomicsFill.

æè¦ï¼<paragraph>æ¬ç ç©¶ä»¥ãæåè½çæå·ææéå±¬æ§çè«ç¤åï¼ãéååé¡çºåæ©ï¼å©ç¨æ¾å°ç¹å¾µä¾æ¢è¨çæåæè«ç¤å½±åçå¯è¡æ§ãæ¾å°ç¹å¾µä»¥å¶ä½ç¶­åº¦ä¸å·æçç©æç¾©çæ¨è¨çºç¹å¾µï¼å½è£äºè¤éé«å­¸å½±åè³æèå¯æä½è¨åºè¦è§£ä¹éçå·®è·ãæåæåº RadiomicsFill-Mammoï¼RadiomicsFill ç³»åçç¬¬ä¸åï¼éæ¯ä¸ç¨®åµæ°çæè¡ï¼å©ç¨é®ç½©å½±ååå°å´ä¹³æ¿å½±åï¼ä¸¦å©ç¨æè¿çç©©å®æ´æ£æ¨¡åï¼çæåæ ç¹å®æ¾å°ç¹å¾µå±¬æ§çé¼çä¹³æ¿æå½±è«å¡å½±åãéç¨®æ¹æ³éåè¨±å°åºæ¬è¨åºè®æ¸ï¼ä¾å¦ BI-RADS åä¹³æ¿å¯åº¦ï¼èæ¾å°ç¹å¾µä¸èµ·ä½çºçæè«å¡çæ¢ä»¶ãçµæè¡¨æï¼RadiomicsFill-Mammo è½ææå°æ ¹æåç¨®æ¾å°æ¢ä»¶çæå¤æ¨£åä¸é¼ççè«ç¤å½±åãçµæéè­æäºè«å¡æª¢æ¸¬è½åçé¡¯èæåï¼å©ç¨ RadiomicsFill-Mammo ä½çºçææ¨¡æ¬æ¨£æ¬çç­ç¥ãæ­¤å¤ï¼RadiomicsFill-Mammo ä¸åæ¨åäºé«å­¸å½±åç ç©¶ï¼éçºå¢å¼·æ²»çè¦ååè«ç¤æ¨¡æ¬éé¢äºæ°éå¾ãæåçç¨å¼ç¢¼å¯å¨ https://github.com/nainye/RadiomicsFill åå¾ã</paragraph>

##### **WSI-VQA: Interpreting Whole Slide Images by Generative Visual Question Answering**
2407.05603v1 by Pingyi Chen, Chenglu Zhu, Sunyi Zheng, Honglin Li, Lin Yang

Whole slide imaging is routinely adopted for carcinoma diagnosis and
prognosis. Abundant experience is required for pathologists to achieve accurate
and reliable diagnostic results of whole slide images (WSI). The huge size and
heterogeneous features of WSIs make the workflow of pathological reading
extremely time-consuming. In this paper, we propose a novel framework (WSI-VQA)
to interpret WSIs by generative visual question answering. WSI-VQA shows
universality by reframing various kinds of slide-level tasks in a
question-answering pattern, in which pathologists can achieve
immunohistochemical grading, survival prediction, and tumor subtyping following
human-machine interaction. Furthermore, we establish a WSI-VQA dataset which
contains 8672 slide-level question-answering pairs with 977 WSIs. Besides the
ability to deal with different slide-level tasks, our generative model which is
named Wsi2Text Transformer (W2T) outperforms existing discriminative models in
medical correctness, which reveals the potential of our model to be applied in
the clinical scenario. Additionally, we also visualize the co-attention mapping
between word embeddings and WSIs as an intuitive explanation for diagnostic
results. The dataset and related code are available at
https://github.com/cpystan/WSI-VQA.

æè¦ï¼å¨åçå½±åéå¸¸ç¨æ¼çççè¨ºæ·åé å¾ãççå­¸å®¶éè¦æè±å¯çç¶é©æè½å°å¨åçå½±å (WSI) ååºæºç¢ºä¸å¯é çè¨ºæ·çµæãWSI çå°ºå¯¸é¾å¤§ä¸ç¹å¾µç°è³ªï¼ä½¿å¾ççå­¸å¤è®çå·¥ä½æµç¨æ¥µçºèæãå¨æ¬æä¸­ï¼æåæåºäºä¸åæ°çæ¡æ¶ (WSI-VQA)ï¼ééçæå¼è¦è¦ºåç­ä¾è©®é WSIãWSI-VQA ééå¨åç­æ¨¡å¼ä¸­éæ°å®ç¾©åç¨®åçå±¤ç´ä»»åï¼å±ç¾å¶éç¨æ§ï¼ççå­¸å®¶å¯ä»¥å¨äººæ©äºåå¾ï¼å®æåç«çµç¹åå­¸åç´ãå­æ´»é æ¸¬åè«ç¤äºååé¡ãæ­¤å¤ï¼æåå»ºç«äºä¸å WSI-VQA è³æéï¼å¶ä¸­åå« 8672 ååçå±¤ç´åç­å°ï¼ä»¥å 977 å WSIãé¤äºè½å¤ èçä¸åçåçå±¤ç´ä»»åå¤ï¼æååçº Wsi2Text Transformer (W2T) ççææ¨¡åå¨é«å­¸æ­£ç¢ºæ§æ¹é¢åªæ¼ç¾æçå¤å¥æ¨¡åï¼éæ­ç¤ºäºæåçæ¨¡åå¨è¨åºå ´æ¯ä¸­æç¨çæ½åãæ­¤å¤ï¼æåéå°è©åµå¥å WSI ä¹éçå±åæ³¨ææ å°è¦è¦ºåï¼ä½çºè¨ºæ·çµæçç´è§è§£éãè³æéåç¸éç¨å¼ç¢¼å¯å¨ https://github.com/cpystan/WSI-VQA åå¾ã

##### **Accelerating MRI Uncertainty Estimation with Mask-based Bayesian Neural Network**
2407.05521v1 by Zehuan Zhang, Matej Genci, Hongxiang Fan, Andreas Wetscherek, Wayne Luk

Accurate and reliable Magnetic Resonance Imaging (MRI) analysis is
particularly important for adaptive radiotherapy, a recent medical advance
capable of improving cancer diagnosis and treatment. Recent studies have shown
that IVIM-NET, a deep neural network (DNN), can achieve high accuracy in MRI
analysis, indicating the potential of deep learning to enhance diagnostic
capabilities in healthcare. However, IVIM-NET does not provide calibrated
uncertainty information needed for reliable and trustworthy predictions in
healthcare. Moreover, the expensive computation and memory demands of IVIM-NET
reduce hardware performance, hindering widespread adoption in realistic
scenarios. To address these challenges, this paper proposes an
algorithm-hardware co-optimization flow for high-performance and reliable MRI
analysis. At the algorithm level, a transformation design flow is introduced to
convert IVIM-NET to a mask-based Bayesian Neural Network (BayesNN),
facilitating reliable and efficient uncertainty estimation. At the hardware
level, we propose an FPGA-based accelerator with several hardware
optimizations, such as mask-zero skipping and operation reordering.
Experimental results demonstrate that our co-design approach can satisfy the
uncertainty requirements of MRI analysis, while achieving 7.5 times and 32.5
times speedup on an Xilinx VU13P FPGA compared to GPU and CPU implementations
with reduced power consumption.

æè¦ï¼ç²¾æºå¯é çç£æ¯é å½± (MRI) åæå°æ¼é©ææ§æ¾å°æ²»çç¹å¥éè¦ï¼éæ¯ä¸ç¨®è¿æé«çé²å±ï¼è½å¤ æ¹åççè¨ºæ·åæ²»çãæè¿çç ç©¶é¡¯ç¤ºï¼æ·±åº¦ç¥ç¶ç¶²è·¯ (DNN) ç IVIM-NET è½å¨ MRI åæä¸­éå°é«æºç¢ºåº¦ï¼é¡¯ç¤ºæ·±åº¦å­¸ç¿ææ½åå¢å¼·é«çä¿å¥ä¸­çè¨ºæ·è½åãç¶èï¼IVIM-NET æ²ææä¾å¨é«çä¿å¥ä¸­é²è¡å¯é ä¸å¼å¾ä¿¡è³´çé æ¸¬æéçæ ¡æºä¸ç¢ºå®æ§è³è¨ãæ­¤å¤ï¼IVIM-NET æè²´çéç®åè¨æ¶é«éæ±éä½äºç¡¬é«æè½ï¼é»ç¤äºå¨å¯¦éå ´æ¯ä¸­çå»£æ³æ¡ç¨ãçºäºè§£æ±ºéäºææ°ï¼æ¬ææåºäºä¸ç¨®æ¼ç®æ³èç¡¬é«å±åæä½³åçæµç¨ï¼ä»¥é²è¡é«æ§è½ä¸å¯é ç MRI åæãå¨æ¼ç®æ³å±¤ç´ï¼å¼å¥äºè½æè¨­è¨æµç¨ï¼å° IVIM-NET è½æçºåºæ¼é®ç½©çè²æ°ç¥ç¶ç¶²è·¯ (BayesNN)ï¼ä¿é²å¯é ä¸ææçéç¢ºå®æ§ä¼°è¨ãå¨ç¡¬é«å±¤ç´ï¼æåæåºäºä¸ç¨®åºæ¼ FPGA çå éå¨ï¼å·åå¤é ç¡¬é«æä½³åï¼ä¾å¦é®ç½©é¶è·³éåéç®éæ°æåºãå¯¦é©çµæè­æï¼æåçå±åè¨­è¨æ¹æ³å¯ä»¥æ»¿è¶³ MRI åæçä¸ç¢ºå®æ§éæ±ï¼åæå¨ Xilinx VU13P FPGA ä¸å¯¦ç¾æ¯ GPU å CPU å¯¦ä½å¿«ä¸ 7.5 åå 32.5 åçéåº¦ï¼ä¸åèéä½ã

##### **A Survey of Models for Cognitive Diagnosis: New Developments and Future Directions**
2407.05458v1 by Fei Wang, Weibo Gao, Qi Liu, Jiatong Li, Guanhao Zhao, Zheng Zhang, Zhenya Huang, Mengxiao Zhu, Shijin Wang, Wei Tong, Enhong Chen

Cognitive diagnosis has been developed for decades as an effective
measurement tool to evaluate human cognitive status such as ability level and
knowledge mastery. It has been applied to a wide range of fields including
education, sport, psychological diagnosis, etc. By providing better awareness
of cognitive status, it can serve as the basis for personalized services such
as well-designed medical treatment, teaching strategy and vocational training.
This paper aims to provide a survey of current models for cognitive diagnosis,
with more attention on new developments using machine learning-based methods.
By comparing the model structures, parameter estimation algorithms, model
evaluation methods and applications, we provide a relatively comprehensive
review of the recent trends in cognitive diagnosis models. Further, we discuss
future directions that are worthy of exploration. In addition, we release two
Python libraries: EduData for easy access to some relevant public datasets we
have collected, and EduCDM that implements popular CDMs to facilitate both
applications and research purposes.

æè¦ï¼èªç¥è¨ºæ·å·²ç¼å±æ¸åå¹´ï¼ä½çºè©ä¼°äººé¡èªç¥çæï¼ä¾å¦è½åæ°´å¹³åç¥è­ææ¡ï¼çæææ¸¬éå·¥å·ãå®å·²è¢«æç¨æ¼å»£æ³çé åï¼åæ¬æè²ãé«è²ãå¿çè¨ºæ·ç­ãééæä¾å°èªç¥çæçæ´å¥½èªè­ï¼å®å¯ä»¥ä½çºåäººåæåçåºç¤ï¼ä¾å¦ç²¾å¿è¨­è¨çé«çæ²»çãæå­¸ç­ç¥åè·æ¥­è¨ç·´ãæ¬ææ¨å¨æä¾èªç¥è¨ºæ·ç¶åæ¨¡åçç¶è¿°ï¼ä¸¦æ´éæ³¨ä½¿ç¨åºæ¼æ©å¨å­¸ç¿çæ¹æ³çæ°ç¼å±ãééæ¯è¼æ¨¡åçµæ§ãåæ¸ä¼°è¨æ¼ç®æ³ãæ¨¡åè©ä¼°æ¹æ³åæç¨ï¼æåå°èªç¥è¨ºæ·æ¨¡åçææ°è¶¨å¢æä¾äºç¸å°å¨é¢çåé¡§ãæ­¤å¤ï¼æåè¨è«äºå¼å¾æ¢ç´¢çæªä¾æ¹åãæ­¤å¤ï¼æåç¼å¸äºå©å Python ç¨å¼åº«ï¼EduDataï¼ç¨æ¼è¼é¬å­åæåæ¶éçä¸äºç¸éå¬éè³æéï¼ä»¥å EduCDMï¼ç¨æ¼å¯¦ä½ç±éç CDMï¼ä»¥ä¿é²æç¨åç ç©¶ç®çã

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v1 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

æè¦ï¼<paragraph>æ¬ææåºäºç¨äºè§ç½èç¼åºå¾åç¾çåç±»çæ©å¼ æ®å·®ç½ç» (ResNet) æ¨¡åãæ©å¼ å·ç§¯æ»¤æ³¢å¨ç¨äºæ¿æ¢ ResNet æ¨¡åè¾é«å±ä¸­çæ­£å¸¸å·ç§¯æ»¤æ³¢å¨ï¼æ©å¼  ResNetï¼ï¼ä»¥æ¹åä¸ç¨äºç¾çåç±»çæ­£å¸¸ ResNet æ¨¡åç¸æ¯çæåéãæ¬ç ç©¶ä»ç»äºéç¨æ·±åº¦å­¦ä¹ çè®¡ç®æºè¾å©è¯æ­å·¥å·ï¼å¹¶éè¿å¯è§£éç AI ææ¯è¿è¡äºå¢å¼ºãè¿äºææ¯æ¨å¨ä½¿è¯¥å·¥å·çå³ç­è¿ç¨éæåï¼ä»èä½¿å»çä¸ä¸äººåè½å¤çè§£åä¿¡ä»» AI çè¯æ­å³ç­ãå®ä»¬å¨å½ä»å»çä¿å¥é¢åå°¤ä¸ºéè¦ï¼å ä¸ºå¯¹ AI åºç¨ç¨åºçéæåº¦éæ±ä¸æ­å¢é¿ï¼ä»¥ç¡®ä¿å¶å¯é æ§åéå¾·ä½¿ç¨ãæ©å¼  ResNet ç¨ä½æ­£å¸¸ ResNet çæ¿ä»£åï¼ä»¥æé«è§ç½èç¼ççåç±»åç¡®æ§å¹¶åå°æéçè®¡ç®æ¶é´ãæ¬å·¥ä½ä¸­ä½¿ç¨çæ°æ®éæ¯ Ocular Disease Intelligent Recognition (ODIR) æ°æ®éï¼è¿æ¯ä¸ä¸ªç»æåçç¼ç§æ°æ®åºï¼åå«å«ç±»æ¶µçå¤§å¤æ°å¸¸è§è§ç½èç¼çãæ¬å·¥ä½ä¸­ä½¿ç¨çè¯ä¼°ææ åæ¬ç²¾ç¡®åº¦ãå¬åçãåç¡®åº¦å F1 åæ°ãå¨è¿é¡¹å·¥ä½ä¸­ï¼å¯¹æ­£å¸¸ ResNet æ¨¡ååæ©å¼  ResNet æ¨¡åå¨äºä¸ªåä½ï¼å³ ResNet-18ãResNet-34ãResNet-50ãResNet-101 å ResNet-152ï¼ä¹é´è¿è¡äºæ¯è¾ç ç©¶ãä¸æ­£å¸¸ ResNet ç¸æ¯ï¼æ©å¼  ResNet æ¨¡åæ¾ç¤ºåºæå¸æçç»æï¼å¨ ODIR å¤ç±»ç¾çåç±»ä¸­ï¼ä¸è¿°åä¸ªåä½çå¹³å F1 åæ°åå«ä¸º 0.71ã0.70ã0.69ã0.67 å 0.70ã</paragraph>

##### **FM-OSD: Foundation Model-Enabled One-Shot Detection of Anatomical Landmarks**
2407.05412v1 by Juzheng Miao, Cheng Chen, Keli Zhang, Jie Chuai, Quanzheng Li, Pheng-Ann Heng

One-shot detection of anatomical landmarks is gaining significant attention
for its efficiency in using minimal labeled data to produce promising results.
However, the success of current methods heavily relies on the employment of
extensive unlabeled data to pre-train an effective feature extractor, which
limits their applicability in scenarios where a substantial amount of unlabeled
data is unavailable. In this paper, we propose the first foundation
model-enabled one-shot landmark detection (FM-OSD) framework for accurate
landmark detection in medical images by utilizing solely a single template
image without any additional unlabeled data. Specifically, we use the frozen
image encoder of visual foundation models as the feature extractor, and
introduce dual-branch global and local feature decoders to increase the
resolution of extracted features in a coarse to fine manner. The introduced
feature decoders are efficiently trained with a distance-aware similarity
learning loss to incorporate domain knowledge from the single template image.
Moreover, a novel bidirectional matching strategy is developed to improve both
robustness and accuracy of landmark detection in the case of scattered
similarity map obtained by foundation models. We validate our method on two
public anatomical landmark detection datasets. By using solely a single
template image, our method demonstrates significant superiority over strong
state-of-the-art one-shot landmark detection methods.

æè¦ï¼è§£åæ¨èªçä¸ç¼åµæ¸¬å å¶ä½¿ç¨æå°æ¨ç±¤è³æç¢çæåæ¯çµæçæçèç²å¾é¡¯èéæ³¨ãç¶èï¼ç®åæ¹æ³çæåæ¥µåº¦ä¾è³´éç¨å»£æ³çæªæ¨ç±¤è³æä¾é åè¨ç·´ä¸åææç¹å¾µèåå¨ï¼ééå¶äºå¶å¨å¤§éæªæ¨ç±¤è³æä¸å¯ç¨çææ³ä¸çé©ç¨æ§ãå¨æ¬æä¸­ï¼æåæåºç¬¬ä¸ååºç¤æ¨¡ååç¨çå®ç¼æ¨èªåµæ¸¬ (FM-OSD) æ¶æ§ï¼èç±ååå©ç¨å®ä¸ç¯æ¬å½±åèç¡ä»»ä½å¶ä»æªæ¨ç±¤è³æï¼å¨é«å­¸å½±åä¸­é²è¡ç²¾ç¢ºæ¨èªåµæ¸¬ãå·é«ä¾èªªï¼æåä½¿ç¨è¦è¦ºåºç¤æ¨¡åçåçµå½±åç·¨ç¢¼å¨ä½çºç¹å¾µèåå¨ï¼ä¸¦å¼å¥éåæ¯å¨å±åå±é¨ç¹å¾µè§£ç¢¼å¨ï¼ä»¥ç²å°ç´°çæ¹å¼å¢å èåç¹å¾µçåè¾¨çãå¼å¥çç¹å¾µè§£ç¢¼å¨å©ç¨è·é¢æç¥ç¸ä¼¼æ§å­¸ç¿æå¤±å½æ¸é²è¡ææè¨ç·´ï¼ä»¥ç´å¥å®ä¸ç¯æ¬å½±åçé åç¥è­ãæ­¤å¤ï¼éç¼äºä¸ç¨®æ°ç©çéåå¹éç­ç¥ï¼ä»¥æé«åºç¤æ¨¡ååå¾çæ£ä½ç¸ä¼¼æ§åå¨æ¨èªåµæ¸¬ä¸­çç©©å¥æ§åæºç¢ºæ§ãæåå¨å©åå¬éçè§£åæ¨èªåµæ¸¬è³æéé©è­æåçæ¨¡åãæåçæ¨¡ååä½¿ç¨å®ä¸ç¯æ¬å½±åï¼è­æå¶åªæ¼ç¾ææè¡ä¸­å¼·å¤§çå®ç¼æ¨èªåµæ¸¬æ¹æ³ã

##### **BadCLM: Backdoor Attack in Clinical Language Models for Electronic Health Records**
2407.05213v1 by Weimin Lyu, Zexin Bi, Fusheng Wang, Chao Chen

The advent of clinical language models integrated into electronic health
records (EHR) for clinical decision support has marked a significant
advancement, leveraging the depth of clinical notes for improved
decision-making. Despite their success, the potential vulnerabilities of these
models remain largely unexplored. This paper delves into the realm of backdoor
attacks on clinical language models, introducing an innovative attention-based
backdoor attack method, BadCLM (Bad Clinical Language Models). This technique
clandestinely embeds a backdoor within the models, causing them to produce
incorrect predictions when a pre-defined trigger is present in inputs, while
functioning accurately otherwise. We demonstrate the efficacy of BadCLM through
an in-hospital mortality prediction task with MIMIC III dataset, showcasing its
potential to compromise model integrity. Our findings illuminate a significant
security risk in clinical decision support systems and pave the way for future
endeavors in fortifying clinical language models against such vulnerabilities.

æè¦ï¼è¨åºèªè¨æ¨¡åæ´åå°é»å­å¥åº·ç´é (EHR) ä¸­ä»¥é²è¡è¨åºæ±ºç­æ¯æ´ï¼æ¨èªèä¸é éå¤§çé²å±ï¼å©ç¨è¨åºç­è¨çæ·±åº¦ä¾æ¹åæ±ºç­å¶å®ãåç®¡éäºæ¨¡ååå¾äºæåï¼ä½å®åçæ½å¨æ¼æ´å¨å¾å¤§ç¨åº¦ä¸ä»æªå¾å°æ¢ç´¢ãæ¬ææ·±å¥æ¢è¨äºéå°è¨åºèªè¨æ¨¡åçå¾éæ»æé åï¼ä»ç´¹äºä¸ç¨®åµæ°çåºæ¼æ³¨æåçå¾éæ»ææ¹æ³ BadCLMï¼ä¸è¯è¨åºèªè¨æ¨¡åï¼ãéç¨®æè¡ç§å¯å°å¨æ¨¡åä¸­åµå¥äºä¸åå¾éï¼å°è´å®åå¨è¼¸å¥ä¸­å­å¨é å®ç¾©è§¸ç¼å¨æç¢çä¸æ­£ç¢ºçé æ¸¬ï¼èå¶ä»ææ³ä¸åæºç¢ºéä½ãæåééä½¿ç¨ MIMIC III è³æéé²è¡é¢å§æ­»äº¡çé æ¸¬ä»»åä¾è­æ BadCLM çæåï¼å±ç¤ºäºå¶æå®³æ¨¡åå®æ´æ§çæ½åãæåçç¼ç¾æ­ç¤ºäºè¨åºæ±ºç­æ¯æ´ç³»çµ±ä¸­çä¸åéå¤§å®å¨é¢¨éªï¼ä¸¦çºæªä¾å å¼·è¨åºèªè¨æ¨¡åä»¥æå°æ­¤é¡æ¼æ´çåªåéªå¹³äºéè·¯ã

##### **RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models**
2407.05131v1 by Peng Xia, Kangyu Zhu, Haoran Li, Hongtu Zhu, Yun Li, Gang Li, Linjun Zhang, Huaxiu Yao

The recent emergence of Medical Large Vision Language Models (Med-LVLMs) has
enhanced medical diagnosis. However, current Med-LVLMs frequently encounter
factual issues, often generating responses that do not align with established
medical facts. Retrieval-Augmented Generation (RAG), which utilizes external
knowledge, can improve the factual accuracy of these models but introduces two
major challenges. First, limited retrieved contexts might not cover all
necessary information, while excessive retrieval can introduce irrelevant and
inaccurate references, interfering with the model's generation. Second, in
cases where the model originally responds correctly, applying RAG can lead to
an over-reliance on retrieved contexts, resulting in incorrect answers. To
address these issues, we propose RULE, which consists of two components. First,
we introduce a provably effective strategy for controlling factuality risk
through the calibrated selection of the number of retrieved contexts. Second,
based on samples where over-reliance on retrieved contexts led to errors, we
curate a preference dataset to fine-tune the model, balancing its dependence on
inherent knowledge and retrieved contexts for generation. We demonstrate the
effectiveness of RULE on three medical VQA datasets, achieving an average
improvement of 20.8% in factual accuracy. We publicly release our benchmark and
code in https://github.com/richard-peng-xia/RULE.

æè¦ï¼æè¿åºç¾çé«çå¤§åèªè¨æ¨¡å (Med-LVLMs) æåäºé«çè¨ºæ·ãç¶èï¼ç®åç Med-LVLMs ç¶å¸¸éå°äºå¯¦åé¡ï¼éå¸¸æç¢çèå·²ç¢ºç«çé«çäºå¯¦ä¸ç¬¦çåæãå©ç¨å¤é¨ç¥è­çæª¢ç´¢å¢å¼·çæ (RAG) å¯ä»¥æ¹åéäºæ¨¡åçäºå¯¦æºç¢ºæ§ï¼ä½å¼å¥äºå©åä¸»è¦ææ°ãé¦åï¼æéçæª¢ç´¢å§å®¹å¯è½ç¡æ³æ¶µèææå¿è¦çè³è¨ï¼èéåº¦çæª¢ç´¢å¯è½æå¼å¥ä¸ç¸éåä¸æºç¢ºçåèï¼å¹²æ¾æ¨¡åççæãå¶æ¬¡ï¼å¨æ¨¡ååæ¬æ­£ç¢ºåæçææ³ä¸ï¼æç¨ RAG å¯è½æéåº¦ä¾è³´æª¢ç´¢å°çå§å®¹ï¼å°è´ä¸æ­£ç¢ºçç­æ¡ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäº RULEï¼å®åå«å©åçµæé¨åãé¦åï¼æåå¼å¥äºä¸ç¨®å¯è­æææçç­ç¥ï¼ééæ ¡æºæª¢ç´¢å°çå§å®¹æ¸éä¾æ§å¶äºå¯¦é¢¨éªãå¶æ¬¡ï¼æ ¹æéåº¦ä¾è³´æª¢ç´¢å°çå§å®¹å°è´é¯èª¤çç¯ä¾ï¼æåç­åäºä¸ååå¥½è³æéä¾å¾®èª¿æ¨¡åï¼å¹³è¡¡å¶å¨çææå°å§å¨ç¥è­åæª¢ç´¢å°çå§å®¹çä¾è³´æ§ãæåå¨ä¸åé«ç VQA è³æéä¸å±ç¤ºäº RULE çæææ§ï¼å¨äºå¯¦æºç¢ºæ§æ¹é¢å¹³åæåäº 20.8%ãæåå¨ https://github.com/richard-peng-xia/RULE ä¸­å¬éç¼å¸æåçåºæºåç¨å¼ç¢¼ã

##### **Linear Attention Based Deep Nonlocal Means Filtering for Multiplicative Noise Removal**
2407.05087v1 by Xiao Siyao, Huang Libing, Zhang Shunsheng

Multiplicative noise widely exists in radar images, medical images and other
important fields' images. Compared to normal noises, multiplicative noise has a
generally stronger effect on the visual expression of images. Aiming at the
denoising problem of multiplicative noise, we linearize the nonlocal means
algorithm with deep learning and propose a linear attention mechanism based
deep nonlocal means filtering (LDNLM). Starting from the traditional nonlocal
means filtering, we employ deep channel convolution neural networks to extract
the information of the neighborhood matrix and obtain representation vectors of
every pixel. Then we replace the similarity calculation and weighted averaging
processes with the inner operations of the attention mechanism. To reduce the
computational overhead, through the formula of similarity calculation and
weighted averaging, we derive a nonlocal filter with linear complexity.
Experiments on both simulated and real multiplicative noise demonstrate that
the LDNLM is more competitive compared with the state-of-the-art methods.
Additionally, we prove that the LDNLM possesses interpretability close to
traditional NLM.

æè¦ï¼ä¹æ§éè¨å»£æ³å­å¨æ¼é·éå½±åãé«å­¸å½±åç­éè¦é åçå½±åä¸­ãç¸è¼æ¼ä¸è¬éè¨ï¼ä¹æ§éè¨å°å½±åçè¦è¦ºè¡¨ç¾å·ææ®éæ´å¼·çå½±é¿ãéå°ä¹æ§éè¨çå»éè¨åé¡ï¼æåä»¥æ·±åº¦å­¸ç¿ç·æ§åéå±é¨åå¼æ¼ç®æ³ï¼ä¸¦æåºåºæ¼ç·æ§æ³¨æåæ©å¶çæ·±åº¦éå±é¨åå¼æ¿¾æ³¢ï¼LDNLMï¼ãå¾å³çµ±éå±é¨åå¼æ¿¾æ³¢åºç¼ï¼æåæ¡ç¨æ·±åº¦ééå·ç©ç¥ç¶ç¶²è·¯æåé°åç©é£çè³è¨ï¼ä¸¦åå¾æ¯åç«ç´ çè¡¨ç¤ºåéãæ¥èï¼æåä»¥æ³¨æåæ©å¶çå§é¨éç®åä»£ç¸ä¼¼åº¦è¨ç®èå æ¬å¹³åçç¨åºãçºäºéä½éç®è² æï¼æåééç¸ä¼¼åº¦è¨ç®èå æ¬å¹³åçå¬å¼ï¼æ¨å°åºå·æç·æ§è¤éåº¦çéå±é¨æ¿¾æ³¢å¨ãå¨æ¨¡æ¬èçå¯¦ä¹æ§éè¨ä¸çå¯¦é©åè­å¯¦ï¼LDNLM èç®åæåé²çæ¹æ³ç¸æ¯æ´å·ç«¶ç­åãæ­¤å¤ï¼æåè­æ LDNLM å·åæ¥è¿å³çµ± NLM çå¯è§£éæ§ã

##### **Brain Age Estimation with a Greedy Dual-Stream Model for Limited Datasets**
2407.04808v1 by Iman Kianian, Hedieh Sajedi

Brain age estimation involves predicting the biological age of individuals
from their brain images, which offers valuable insights into the aging process
and the progression of neurodegenerative diseases. Conducting large-scale
datasets for medical image analysis is a challenging and time-consuming task.
Existing approaches mostly depend on large datasets, which are hard to come by
and expensive. These approaches also require sophisticated, resource-intensive
models with a large number of parameters, necessitating a considerable amount
of processing power. As a result, there is a vital need to develop innovative
methods that can achieve robust performance with limited datasets and efficient
use of computational resources. This paper proposes a novel slice-based
dual-stream method called GDSM (Greedy Dual-Stream Model) for brain age
estimation. This method addresses the limitations of large dataset requirements
and computational resource intensiveness. The proposed method incorporates
local and global aspects of the brain, thereby refining the focus on specific
target regions. The approach employs four backbones to predict ages based on
local and global features, complemented by a final model for age correction.
Our method demonstrates a Mean Absolute Error (MAE) of 3.25 years on the test
set of IBID, which only contains 289 subjects. To demonstrate the robustness of
our approach for any small dataset, we analyzed the proposed method with the
IXI dataset and achieved an MAE of 4.18 years on the test set of IXI. By
leveraging dual-stream and greedy strategies, this approach achieves efficiency
and robust performance, making it comparable with other state-of-the-art
methods. The code for the GDSM model is available at
https://github.com/iman2693/GDSM.

æè¦ï¼å¤§è¦å¹´é½¡ä¼°è¨æ¶åå¾å¤§è¦å½±åé æ¸¬åé«ççç©å¹´é½¡ï¼éå°èåéç¨åç¥ç¶éåæ§ç¾ççé²å±æä¾äºå¯¶è²´çè¦è§£ãå°é«å­¸å½±ååæé²è¡å¤§è¦æ¨¡çæ¸æéèçæ¯ä¸é å·æææ°æ§ä¸èæçä»»åãç¾æçæ¹æ³å¤§å¤ä¾è³´æ¼å¤§åæ¸æéï¼èéäºæ¸æéé£ä»¥ç²å¾ä¸æè²´ãéäºæ¹æ³ééè¦è¤éçãè³æºå¯éåçæ¨¡åï¼éäºæ¨¡åå·æå¤§éçåæ¸ï¼éè¦å¤§éçèçè½åãå æ­¤ï¼è¿«åéè¦éç¼åµæ°çæ¹æ³ï¼éäºæ¹æ³å¯ä»¥å¨æéçæ¸æéåé«æå©ç¨è¨ç®è³æºçææ³ä¸å¯¦ç¾ç©©å¥çæ§è½ãæ¬ææåºäºä¸ç¨®ç¨±çº GDSMï¼è²ªå©ªéæµæ¨¡åï¼çæ°ååºæ¼åççéæµæ¹æ³ï¼ç¨æ¼å¤§è¦å¹´é½¡ä¼°è¨ãéç¨®æ¹æ³è§£æ±ºäºå°å¤§åæ¸æééæ±åè¨ç®è³æºå¯éæ§çéå¶ãææåºçæ¹æ³çµåäºå¤§è¦çå±é¨åå¨å±æ¹é¢ï¼å¾èç²¾ç¢ºéæ³¨å·é«çç®æ¨ååãè©²æ¹æ³æ¡ç¨ååä¸»å¹¹æ ¹æå±é¨åå¨å±ç¹å¾µé æ¸¬å¹´é½¡ï¼ä¸¦è¼ä»¥ä¸åæçµæ¨¡åé²è¡å¹´é½¡æ ¡æ­£ãæåçæ¨¡åå¨ååå« 289 ååè©¦èç IBID æ¸¬è©¦éä¸­å±ç¤ºäº 3.25 å¹´çå¹³åçµå°èª¤å·® (MAE)ãçºäºè­ææåçæ¨¡åå°ä»»ä½å°åæ¸æéçç©©å¥æ§ï¼æåä½¿ç¨ IXI æ¸æéåæäºææåºçæ¹æ³ï¼ä¸¦å¨ IXI çæ¸¬è©¦éä¸­å¯¦ç¾äº 4.18 å¹´ç MAEãééå©ç¨éæµåè²ªå©ªç­ç¥ï¼éç¨®æ¹æ³å¯¦ç¾äºé«æåç©©å¥çæ§è½ï¼ä½¿å¶èå¶ä»æåé²çæ¹æ³ç¸ç¶ãGDSM æ¨¡åçä»£ç¢¼å¯å¨ https://github.com/iman2693/GDSM ä¸ç²å¾ã

##### **Entity Decomposition with Filtering: A Zero-Shot Clinical Named Entity Recognition Framework**
2407.04629v1 by Reza Averly, Xia Ning

Clinical named entity recognition (NER) aims to retrieve important entities
within clinical narratives. Recent works have demonstrated that large language
models (LLMs) can achieve strong performance in this task. While previous works
focus on proprietary LLMs, we investigate how open NER LLMs, trained
specifically for entity recognition, perform in clinical NER. In this paper, we
aim to improve them through a novel framework, entity decomposition with
filtering, or EDF. Our key idea is to decompose the entity recognition task
into several retrievals of sub-entity types. We also introduce a filtering
mechanism to remove incorrect entities. Our experimental results demonstrate
the efficacy of our framework across all metrics, models, datasets, and entity
types. Our analysis reveals that entity decomposition can recognize previously
missed entities with substantial improvement. We further provide a
comprehensive evaluation of our framework and an in-depth error analysis to
pave future works.

æè¦ï¼è¨åºå½åå¯¦é«è­å¥ (NER) æ¨å¨æ·åè¨åºæè¿°ä¸­çéè¦å¯¦é«ãæè¿çç ç©¶è¡¨æï¼å¤§åèªè¨æ¨¡å (LLM) å¯ä»¥å¨æ­¤ä»»åä¸­å¯¦ç¾å¼·å¤§çæè½ãéç¶ååçç ç©¶å°æ³¨æ¼å°æç LLMï¼ä½æåæ¢è¨äºå°ééå°å¯¦é«è­å¥è¨ç·´çéæ¾å¼ NER LLM å¨è¨åº NER ä¸­çè¡¨ç¾ãå¨æ¬æä¸­ï¼æåæ¨å¨ééä¸åæ°ç©çæ¶æ§ä¾æ¹åå®åï¼å³å¸¶æéæ¿¾çå¯¦é«åè§£ï¼æ EDFãæåçééµæ³æ³æ¯å°å¯¦é«è­å¥ä»»ååè§£çºå¤åå­å¯¦é«é¡åçæ·åãæåéå¼å¥äºä¸åéæ¿¾æ©å¶ä¾ç§»é¤ä¸æ­£ç¢ºçå¯¦é«ãæåçå¯¦é©çµæè­æäºæåæ¶æ§å¨ææææ¨ãæ¨¡åãè³æéåå¯¦é«é¡åä¸­çæè½ãæåçåæé¡¯ç¤ºï¼å¯¦é«åè§£å¯ä»¥è­å¥ååéºæ¼çå¯¦é«ï¼ä¸¦æé¡¯èçæ¹åãæåé²ä¸æ­¥æä¾äºæåæ¶æ§çå¨é¢è©ä¼°åæ·±å¥çé¯èª¤åæï¼çºæªä¾çç ç©¶éªè·¯ã

##### **Variational and Explanatory Neural Networks for Encoding Cancer Profiles and Predicting Drug Responses**
2407.04486v1 by Tianshu Feng, Rohan Gnanaolivu, Abolfazl Safikhani, Yuanhang Liu, Jun Jiang, Nicholas Chia, Alexander Partin, Priyanka Vasanthakumari, Yitan Zhu, Chen Wang

Human cancers present a significant public health challenge and require the
discovery of novel drugs through translational research. Transcriptomics
profiling data that describes molecular activities in tumors and cancer cell
lines are widely utilized for predicting anti-cancer drug responses. However,
existing AI models face challenges due to noise in transcriptomics data and
lack of biological interpretability. To overcome these limitations, we
introduce VETE (Variational and Explanatory Transcriptomics Encoder), a novel
neural network framework that incorporates a variational component to mitigate
noise effects and integrates traceable gene ontology into the neural network
architecture for encoding cancer transcriptomics data. Key innovations include
a local interpretability-guided method for identifying ontology paths, a
visualization tool to elucidate biological mechanisms of drug responses, and
the application of centralized large scale hyperparameter optimization. VETE
demonstrated robust accuracy in cancer cell line classification and drug
response prediction. Additionally, it provided traceable biological
explanations for both tasks and offers insights into the mechanisms underlying
its predictions. VETE bridges the gap between AI-driven predictions and
biologically meaningful insights in cancer research, which represents a
promising advancement in the field.

æè¦ï¼äººé¡ççå°å¬å±è¡çæ§æéå¤§ææ°ï¼éè¦ééè½è­¯ç ç©¶ç¼ç¾æ°è¥ç©ãæè¿°è«ç¤åçç´°èæ ªåå­æ´»åçè½éçµå­¸åæè³æå»£æ³ç¨æ¼é æ¸¬æçè¥ç©åæãç¶èï¼ç¾æç AI æ¨¡åå è½éçµå­¸è³æä¸­çéè¨åç¼ºä¹çç©å­¸å¯è§£éæ§èé¢è¨ææ°ãçºäºåæéäºéå¶ï¼æåå¼å¥äº VETEï¼è®ç°åè§£éæ§è½éçµå­¸ç·¨ç¢¼å¨ï¼ï¼éæ¯ä¸ç¨®æ°ç©çç¥ç¶ç¶²è·¯æ¶æ§ï¼å®çµåäºè®ç°çµæä»¥æ¸è¼éè¨ææï¼ä¸¦å°å¯è¿½è¹¤çåºå æ¬é«æ´åå°ç¥ç¶ç¶²è·¯æ¶æ§ä¸­ä»¥ç·¨ç¢¼ççè½éçµå­¸è³æãééµåµæ°åæ¬ä¸ç¨®å±é¨å¯è§£éæ§å¼å°æ¹æ³ï¼ç¨æ¼è­å¥æ¬é«è·¯å¾ï¼ä¸ç¨®ç¨æ¼é¡æè¥ç©åæççç©æ©å¶çè¦è¦ºåå·¥å·ï¼ä»¥åéä¸­å¼å¤§è¦æ¨¡è¶åæ¸æä½³åçæç¨ãVETE å¨çç´°èæ ªåé¡åè¥ç©åæé æ¸¬æ¹é¢è¡¨ç¾åºç©©å¥çæºç¢ºæ§ãæ­¤å¤ï¼å®çºéå©åä»»åæä¾äºå¯è¿½è¹¤ççç©å­¸è§£éï¼ä¸¦æä¾äºå°å¶é æ¸¬èå¾æ©å¶çè¦è§£ãVETE å½åäº AI é©åé æ¸¬èççç ç©¶ä¸­å·æçç©å­¸æç¾©çè¦è§£ä¹éçå·®è·ï¼éä»£è¡¨äºè©²é åçä¸é æåéçé²å±ã

##### **Multi-modal Masked Siamese Network Improves Chest X-Ray Representation Learning**
2407.04449v1 by Saeed Shurrab, Alejandro Guerra-Manzanares, Farah E. Shamout

Self-supervised learning methods for medical images primarily rely on the
imaging modality during pretraining. While such approaches deliver promising
results, they do not leverage associated patient or scan information collected
within Electronic Health Records (EHR). Here, we propose to incorporate EHR
data during self-supervised pretraining with a Masked Siamese Network (MSN) to
enhance the quality of chest X-ray representations. We investigate three types
of EHR data, including demographic, scan metadata, and inpatient stay
information. We evaluate our approach on three publicly available chest X-ray
datasets, MIMIC-CXR, CheXpert, and NIH-14, using two vision transformer (ViT)
backbones, specifically ViT-Tiny and ViT-Small. In assessing the quality of the
representations via linear evaluation, our proposed method demonstrates
significant improvement compared to vanilla MSN and state-of-the-art
self-supervised learning baselines. Our work highlights the potential of
EHR-enhanced self-supervised pre-training for medical imaging. The code is
publicly available at: https://github.com/nyuad-cai/CXR-EHR-MSN

æè¦ï¼ç¨æ¼é«å­¸å½±åçèªç£ç£å¼å­¸ç¿æ¹æ³ä¸»è¦ä¾è³´æ¼é è¨ç·´æéçå½±åæ¨¡å¼ãéç¶æ­¤é¡æ¹æ³æä¾äºæåæ¯ççµæï¼ä½å®åä¸¦æªå©ç¨é»å­å¥åº·è¨é (EHR) ä¸­æ¶éçç¸éæ£èæææè³è¨ãå¨æ­¤ï¼æåå»ºè­°å¨ä½¿ç¨èé¢é£é«ç¶²è·¯ (MSN) é²è¡èªç£ç£é è¨ç·´æéç´å¥ EHR è³æï¼ä»¥æåè¸é¨ X åçè¡¨å¾µçåè³ªãæåæ¢è¨ä¸ç¨®é¡åç EHR è³æï¼åæ¬äººå£çµ±è¨è³æãææåè³æåä½é¢æéè³è¨ãæåå¨ä¸åå¬éçè¸é¨ X åçè³æéï¼MIMIC-CXRãCheXpert å NIH-14ï¼ä¸è©ä¼°æåçåæ³ï¼ä½¿ç¨å©åè¦è¦ºè½æå¨ (ViT) ä¸»å¹¹ï¼ç¹å¥æ¯ ViT-Tiny å ViT-Smallãå¨ééç·æ§è©ä¼°ä¾è©éè¡¨å¾µçåè³ªæï¼æåæåºçæ¹æ³èå³çµ± MSN åæåé²çèªç£ç£å¼å­¸ç¿åºæºç¸æ¯ï¼è¡¨ç¾åºé¡¯èçé²æ­¥ãæåçç ç©¶éé»èªªæäº EHR å¢å¼·çèªç£ç£é è¨ç·´å¨é«å­¸å½±åæ¹é¢çæ½åãæ­¤ç¨å¼ç¢¼å¯æ¼ä»¥ä¸ç¶²åå¬éåå¾ï¼https://github.com/nyuad-cai/CXR-EHR-MSN

##### **Query-Guided Self-Supervised Summarization of Nursing Notes**
2407.04125v1 by Ya Gao, Hans Moen, Saila Koivusalo, Miika Koskinen, Pekka Marttinen

Nursing notes, an important component of Electronic Health Records (EHRs),
keep track of the progression of a patient's health status during a care
episode. Distilling the key information in nursing notes through text
summarization techniques can improve clinicians' efficiency in understanding
patients' conditions when reviewing nursing notes. However, existing
abstractive summarization methods in the clinical setting have often overlooked
nursing notes and require the creation of reference summaries for supervision
signals, which is time-consuming. In this work, we introduce QGSumm, a
query-guided self-supervised domain adaptation framework for nursing note
summarization. Using patient-related clinical queries as guidance, our approach
generates high-quality, patient-centered summaries without relying on reference
summaries for training. Through automatic and manual evaluation by an expert
clinician, we demonstrate the strengths of our approach compared to the
state-of-the-art Large Language Models (LLMs) in both zero-shot and few-shot
settings. Ultimately, our approach provides a new perspective on conditional
text summarization, tailored to the specific interests of clinical personnel.

æè¦ï¼è­·çè¨éæ¯é»å­å¥åº·ç´é (EHR) çéè¦çµæé¨åï¼
å¨ç§è­·éç¨ä¸­è¿½è¹¤çæ£çå¥åº·çæé²å±ãå©ç¨æå­æè¦æè¡æçè­·çè¨éä¸­çééµè³è¨ï¼å¯ä»¥æåè¨åºé«å¸«å¨æª¢è¦è­·çè¨éæäºè§£çæ£çæ³çæçãç¶èï¼ç¾æçè¨åºæè¦æ¹æ³å¸¸å¸¸å¿½ç¥è­·çè¨éï¼ä¸éè¦å»ºç«åèæè¦ä½çºç£ç£è¨èï¼ééå¸¸èæãå¨éé å·¥ä½ä¸­ï¼æåæåº QGSummï¼ä¸åç¨æ¼è­·çè¨éæè¦çæ¥è©¢å¼å°å¼èªæç£ç£é åé©ææ¶æ§ãæåçåæ³ä½¿ç¨èçæ£ç¸éçè¨åºæ¥è©¢ä½çºæå¼ï¼å¨è¨ç·´ä¸­ä¸ä¾è³´åèæè¦ï¼å°±è½ç¢çé«åè³ªãä»¥çæ£çºä¸­å¿çæè¦ãééå°å®¶è¨åºé«å¸«çèªååæåè©ä¼°ï¼æåå±ç¤ºäºæåçæ¹æ³èæåé²çå¤§èªè¨æ¨¡å (LLM) ç¸æ¯å¨é¶æ¬¡å­¸ç¿åå°æ¬¡å­¸ç¿è¨­å®ä¸­çåªå¢ãæçµï¼æåçåæ³çºæ¢ä»¶å¼æå­æè¦æä¾äºæ°çè§é»ï¼å°ééå°è¨åºäººå¡çç¹å®èè¶£éèº«æé ã

##### **MiniGPT-Med: Large Language Model as a General Interface for Radiology Diagnosis**
2407.04106v1 by Asma Alkhaldi, Raneem Alnajim, Layan Alabdullatef, Rawan Alyahya, Jun Chen, Deyao Zhu, Ahmed Alsinan, Mohamed Elhoseiny

Recent advancements in artificial intelligence (AI) have precipitated
significant breakthroughs in healthcare, particularly in refining diagnostic
procedures. However, previous studies have often been constrained to limited
functionalities. This study introduces MiniGPT-Med, a vision-language model
derived from large-scale language models and tailored for medical applications.
MiniGPT-Med demonstrates remarkable versatility across various imaging
modalities, including X-rays, CT scans, and MRIs, enhancing its utility. The
model is capable of performing tasks such as medical report generation, visual
question answering (VQA), and disease identification within medical imagery.
Its integrated processing of both image and textual clinical data markedly
improves diagnostic accuracy. Our empirical assessments confirm MiniGPT-Med's
superior performance in disease grounding, medical report generation, and VQA
benchmarks, representing a significant step towards reducing the gap in
assisting radiology practice. Furthermore, it achieves state-of-the-art
performance on medical report generation, higher than the previous best model
by 19\% accuracy. MiniGPT-Med promises to become a general interface for
radiology diagnoses, enhancing diagnostic efficiency across a wide range of
medical imaging applications.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) çææ°é²å±ï¼é«çä¿å¥é ååºç¾äºé¡¯èççªç ´ï¼ç¹å¥æ¯å¨æ¹åè¨ºæ·ç¨åºæ¹é¢ãç¶èï¼ååçç ç©¶éå¸¸åéæ¼æéçåè½ãéé ç ç©¶å¼å¥äº MiniGPT-Medï¼éæ¯ä¸ç¨®æºèªå¤§è¦æ¨¡èªè¨æ¨¡åä¸å°çºé«çæç¨èè¨­è¨çè¦è¦ºèªè¨æ¨¡åãMiniGPT-Med å¨åç¨®å½±åæ¨¡å¼ä¸­å±ç¾åºéå¡çå¤åè½æ§ï¼åæ¬ X åãé»è¦æ·å±¤ææå MRIï¼é²èå¢å¼·å¶æç¨ãè©²æ¨¡åè½å¤ å·è¡è«¸å¦é«çå ±åçæãè¦è¦ºåç­ (VQA) åé«çå½±åä¸­çç¾çè­å¥ç­ä»»åãå®å°å½±ååæå­è¨åºè³ææ´åèçï¼é¡¯èæé«äºè¨ºæ·æºç¢ºæ§ãæåçå¯¦è­è©ä¼°è­å¯¦äº MiniGPT-Med å¨ç¾çåºç¤ãé«çå ±åçæå VQA åºæºä¸çåªç°è¡¨ç¾ï¼éä»£è¡¨äºç¸®å°åå©æ¾å°è¨ºæ·å¯¦åå·®è·çéè¦ä¸æ­¥ãæ­¤å¤ï¼å®å¨é«çå ±åçææ¹é¢éå°äºæåé²çè¡¨ç¾ï¼æ¯ååçæä½³æ¨¡åé«åº 19% çæºç¢ºåº¦ãMiniGPT-Med æææçºæ¾å°è¨ºæ·çéç¨ä»é¢ï¼é²èæååç¨®é«çå½±åæç¨ä¸­çè¨ºæ·æçã

##### **Mechanisms for Data Sharing in Collaborative Causal Inference (Extended Version)**
2407.11032v1 by BjÃ¶rn Filter, Ralf MÃ¶ller, ÃzgÃ¼r LÃ¼tfÃ¼ ÃzÃ§ep

Collaborative causal inference (CCI) is a federated learning method for
pooling data from multiple, often self-interested, parties, to achieve a common
learning goal over causal structures, e.g. estimation and optimization of
treatment variables in a medical setting. Since obtaining data can be costly
for the participants and sharing unique data poses the risk of losing
competitive advantages, motivating the participation of all parties through
equitable rewards and incentives is necessary. This paper devises an evaluation
scheme to measure the value of each party's data contribution to the common
learning task, tailored to causal inference's statistical demands, by comparing
completed partially directed acyclic graphs (CPDAGs) inferred from
observational data contributed by the participants. The Data Valuation Scheme
thus obtained can then be used to introduce mechanisms that incentivize the
agents to contribute data. It can be leveraged to reward agents fairly,
according to the quality of their data, or to maximize all agents' data
contributions.

æè¦ï¼åä½å ææ¨è« (CCI) æ¯ä¸ç¨®è¯é¦å­¸ç¿æ¹æ³ï¼ç¨æ¼å½æ´ä¾èªå¤åéå¸¸æ¯èªå©æ¹æ¸æï¼ä»¥éæå æçµæ§çå±åå­¸ç¿ç®æ¨ï¼ä¾å¦å¨é«çç°å¢ä¸­ä¼°è¨åæä½³åæ²»çè®æ¸ãç±æ¼åå¾æ¸æå°åèèä¾èªªå¯è½æ¯æè²´çï¼èåäº«ç¨ç¹æ¸ææé æå¤±å»ç«¶ç­åªå¢çé¢¨éªï¼å æ­¤ééå¬å¹³ççåµåèªå ä¾æ¿åµæææ¹çåèæ¯å¿è¦çãæ¬æè¨­è¨äºä¸åè©ä¼°æ¹æ¡ï¼ç¨æ¼è¡¡éæ¯åæ¹æ¸æè²¢ç»å°å±åå­¸ç¿ä»»åçå¹å¼ï¼éå°å ææ¨è«ççµ±è¨éæ±é²è¡èª¿æ´ï¼æ¹æ³æ¯æ¯è¼åèèè²¢ç»çè§å¯æ¸ææ¨è«åºçå·²å®æé¨åå°åç¡ç°å (CPDAG)ãå æ­¤ï¼åå¾çæ¸æä¼°å¼æ¹æ¡å¯é²ä¸æ­¥ç¨æ¼å¼å¥æ©å¶ï¼ä»¥æ¿åµä»£çäººè²¢ç»æ¸æãå®å¯è¢«ç¨æ¼æ ¹ææ¸æåè³ªå¬å¹³çåµä»£çäººï¼ææå¤§åææä»£çäººçæ¸æè²¢ç»ã

##### **Unsupervised Analysis of Alzheimer's Disease Signatures using 3D Deformable Autoencoders**
2407.03863v1 by Mehmet Yigit Avci, Emily Chan, Veronika Zimmer, Daniel Rueckert, Benedikt Wiestler, Julia A. Schnabel, Cosmin I. Bercea

With the increasing incidence of neurodegenerative diseases such as
Alzheimer's Disease (AD), there is a need for further research that enhances
detection and monitoring of the diseases. We present MORPHADE (Morphological
Autoencoders for Alzheimer's Disease Detection), a novel unsupervised learning
approach which uses deformations to allow the analysis of 3D T1-weighted brain
images. To the best of our knowledge, this is the first use of deformations
with deep unsupervised learning to not only detect, but also localize and
assess the severity of structural changes in the brain due to AD. We obtain
markedly higher anomaly scores in clinically important areas of the brain in
subjects with AD compared to healthy controls, showcasing that our method is
able to effectively locate AD-related atrophy. We additionally observe a visual
correlation between the severity of atrophy highlighted in our anomaly maps and
medial temporal lobe atrophy scores evaluated by a clinical expert. Finally,
our method achieves an AUROC of 0.80 in detecting AD, out-performing several
supervised and unsupervised baselines. We believe our framework shows promise
as a tool towards improved understanding, monitoring and detection of AD. To
support further research and application, we have made our code publicly
available at github.com/ci-ber/MORPHADE.

æè¦ï¼é¨èç¥ç¶éè¡æ§ç¾çï¼ä¾å¦é¿è²æµ·é»çï¼çç¼ççå¢å ï¼éè¦é²ä¸æ­¥çç ç©¶ä¾å å¼·å°éäºç¾ççåµæ¸¬åç£æ§ãæåæåº MORPHADEï¼é¿è²æµ·é»çåµæ¸¬çå½¢æèªåç·¨ç¢¼å¨ï¼ï¼éæ¯ä¸ç¨®æ°ç©çç¡ç£ç£å­¸ç¿æ¹æ³ï¼å®ä½¿ç¨è®å½¢ä¾åæ 3D T1 å æ¬è¦é¨å½±åãææåæç¥ï¼éæ¯é¦æ¬¡å°è®å½¢èæ·±åº¦ç¡ç£ç£å­¸ç¿çµåä½¿ç¨ï¼ä¸åå¯ä»¥åµæ¸¬ï¼éå¯ä»¥å®ä½åè©ä¼°é¿è²æµ·é»çå°è´çè¦é¨çµæ§è®åå´éç¨åº¦ãæåå¨é¿è²æµ·é»çåè©¦èçè¦é¨è¨åºä¸éè¦ååç²å¾é¡¯èæ´é«çç°å¸¸åæ¸ï¼èå¥åº·å°ç§çµç¸æ¯ï¼é¡¯ç¤ºæåçæ¨¡åè½å¤ ææå®ä½èé¿è²æµ·é»çç¸éçèç¸®ãæ­¤å¤ï¼æåè§å¯å°ç°å¸¸åä¸­çªåºçèç¸®å´éç¨åº¦èè¨åºå°å®¶è©ä¼°çå§å´é¡³èèç¸®åæ¸ä¹éå­å¨è¦è¦ºç¸éæ§ãæå¾ï¼æåçæ¨¡åå¨åµæ¸¬é¿è²æµ·é»çæ¹é¢éå°äº 0.80 ç AUROCï¼åªæ¼å¤åç£ç£å¼åç¡ç£ç£å¼åºæºãæåç¸ä¿¡æåçæ¶æ§é¡¯ç¤ºåºæææçºæ¹åé¿è²æµ·é»ççè§£ãç£æ§ååµæ¸¬çå·¥å·ãçºäºæ¯æé²ä¸æ­¥çç ç©¶åæç¨ï¼æåå·²å¨ github.com/ci-ber/MORPHADE å¬éæåçç¨å¼ç¢¼ã

##### **CaseGPT: a case reasoning framework based on language models and retrieval-augmented generation**
2407.07913v1 by Rui Yang

This paper presents CaseGPT, an innovative approach that combines Large
Language Models (LLMs) and Retrieval-Augmented Generation (RAG) technology to
enhance case-based reasoning in the healthcare and legal sectors. The system
addresses the challenges of traditional database queries by enabling fuzzy
searches based on imprecise descriptions, thereby improving data searchability
and usability. CaseGPT not only retrieves relevant case data but also generates
insightful suggestions and recommendations based on patterns discerned from
existing case data. This functionality proves especially valuable for tasks
such as medical diagnostics, legal precedent research, and case strategy
formulation. The paper includes an in-depth discussion of the system's
methodology, its performance in both medical and legal domains, and its
potential for future applications. Our experiments demonstrate that CaseGPT
significantly outperforms traditional keyword-based and simple LLM-based
systems in terms of precision, recall, and efficiency.

æè¦ï¼æ¬æä»ç´¹ CaseGPTï¼éæ¯ä¸ç¨®åµæ°çæ¹æ³ï¼çµåå¤§åèªè¨æ¨¡å (LLM) åæª¢ç´¢å¢å¼·çæ (RAG) æè¡ï¼ä»¥å¢å¼·é«çä¿å¥åæ³å¾é åçæ¡ä¾æ¨çãæ­¤ç³»çµ±ééåºæ¼ä¸ç²¾ç¢ºæè¿°åç¨æ¨¡ç³æå°ï¼ä¾è§£æ±ºå³çµ±è³æåº«æ¥è©¢çææ°ï¼é²èæ¹åè³æçå¯æå°æ§åå¯ç¨æ§ãCaseGPT ä¸åææ·åç¸éçæ¡ä¾è³æï¼éææ ¹æå¾ç¾ææ¡ä¾è³æä¸­è¾¨è­åºçæ¨¡å¼ï¼ç¢çæè¦å°çå»ºè­°åå»ºè­°ãæ­¤åè½å°æ¼é«çè¨ºæ·ãæ³å¾åä¾ç ç©¶åæ¡ä¾ç­ç¥å¶å®ç­ä»»åç¹å¥æå¹å¼ãæ¬æåå«å°ç³»çµ±æ¹æ³è«ãå¶å¨é«çåæ³å¾é åçæè½ï¼ä»¥åå¶æªä¾æç¨æ½åçæ·±å¥æ¢è¨ãæåçå¯¦é©è­æï¼CaseGPT å¨æºç¢ºåº¦ãå¬åçåæçæ¹é¢ï¼æé¡¯åªæ¼å³çµ±çåºæ¼ééµå­ååºæ¼ç°¡å® LLM çç³»çµ±ã

##### **Integrating Randomness in Large Language Models: A Linear Congruential Generator Approach for Generating Clinically Relevant Content**
2407.03582v1 by Andrew Bouras

Generating diverse, high-quality outputs from language models is crucial for
applications in education and content creation. Achieving true randomness and
avoiding repetition remains a significant challenge. This study uses the Linear
Congruential Generator method for systematic fact selection, combined with
AI-powered content generation. We ensured unique combinations of
gastrointestinal physiology and pathology facts across multiple rounds,
integrating these facts into prompts for GPT-4o to create clinically relevant,
vignette-style outputs. Over 14 rounds, 98 unique outputs were generated,
demonstrating LCG's effectiveness in producing diverse and high-quality
content. This method addresses key issues of randomness and repetition,
enhancing the quality and efficiency of language model-generated content for
various applications.

æè¦ï¼å¨æè²åå§å®¹åµä½çæç¨ä¸­ï¼å¾èªè¨æ¨¡åç¢çå¤æ¨£åãé«åè³ªçè¼¸åºè³ééè¦ãå¯¦ç¾çæ­£çé¨æ©æ§åé¿åéè¤ä»ç¶æ¯ä¸é éå¤§çææ°ãæ¬ç ç©¶ä½¿ç¨ç·æ§åé¤ç¢çå¨æ¹æ³é²è¡ç³»çµ±æ§äºå¯¦é¸æï¼ä¸¦çµå AI é©åçå§å®¹çæãæåç¢ºä¿äºå¨å¤è¼ªä¸­èè¸ççåççäºå¯¦çç¨ç¹çµåï¼å°éäºäºå¯¦æ´åå° GPT-4o çæç¤ºä¸­ï¼ä»¥åµå»ºå·æè¨åºç¸éæ§çç­ç¯æäºé¢¨æ ¼è¼¸åºãå¨ 14 è¼ªä¸­ï¼çæäº 98 åç¨ç¹è¼¸åºï¼è­æäº LCG å¨ç¢çå¤æ¨£ååé«åè³ªå§å®¹æ¹é¢çæææ§ãæ­¤æ¹æ³è§£æ±ºäºé¨æ©æ§åéè¤æ§çééµåé¡ï¼æé«äºèªè¨æ¨¡åçæçå§å®¹å¨åç¨®æç¨ä¸­çåè³ªåæçã

##### **Accelerated Proton Resonance Frequency-based Magnetic Resonance Thermometry by Optimized Deep Learning Method**
2407.03308v1 by Sijie Xu, Shenyan Zong, Chang-Sheng Mei, Guofeng Shen, Yueran Zhao, He Wang

Proton resonance frequency (PRF) based MR thermometry is essential for
focused ultrasound (FUS) thermal ablation therapies. This work aims to enhance
temporal resolution in dynamic MR temperature map reconstruction using an
improved deep learning method. The training-optimized methods and five
classical neural networks were applied on the 2-fold and 4-fold under-sampling
k-space data to reconstruct the temperature maps. The enhanced training modules
included offline/online data augmentations, knowledge distillation, and the
amplitude-phase decoupling loss function. The heating experiments were
performed by a FUS transducer on phantom and ex vivo tissues, respectively.
These data were manually under-sampled to imitate acceleration procedures and
trained in our method to get the reconstruction model. The additional dozen or
so testing datasets were separately obtained for evaluating the real-time
performance and temperature accuracy. Acceleration factors of 1.9 and 3.7 were
found for 2 times and 4 times k-space under-sampling strategies and the
ResUNet-based deep learning reconstruction performed exceptionally well. In
2-fold acceleration scenario, the RMSE of temperature map patches provided the
values of 0.888 degree centigrade and 1.145 degree centigrade on phantom and ex
vivo testing datasets. The DICE value of temperature areas enclosed by 43
degree centigrade isotherm was 0.809, and the Bland-Altman analysis showed a
bias of -0.253 degree centigrade with the apart of plus or minus 2.16 degree
centigrade. In 4 times under-sampling case, these evaluating values decreased
by approximately 10%. This study demonstrates that deep learning-based
reconstruction can significantly enhance the accuracy and efficiency of MR
thermometry for clinical FUS thermal therapies.

æè¦ï¼åºæ¼è³ªå­å±æ¯é »ç (PRF) ç MR æº«åº¦æ¸¬éå°æ¼èç¦è¶é³æ³¢ (FUS) ç±æ¶èçæ³è³ééè¦ãéé ç ç©¶æ¨å¨ééæ¹åæ·±åº¦å­¸ç¿æ¹æ³ï¼æååæ MR æº«åº¦åéå»ºä¸­çæéè§£æåº¦ãå¨ 2 åå 4 åç k-space è³æä¸è¶³æ¡æ¨£ä¸­ï¼å°è¨ç·´æä½³åæ¹æ³åäºåå³çµ±ç¥ç¶ç¶²è·¯æç¨æ¼éå»ºæº«åº¦åãå¢å¼·çè¨ç·´æ¨¡çµåæ¬é¢ç·/ç·ä¸è³ææ´åãç¥è­èåï¼ä»¥åæ¯å¹ç¸ä½è§£è¦æå¤±å½æ¸ãå ç±å¯¦é©åå¥ç± FUS æè½å¨å¨æ¨¡æ¬äººé«åé¢é«çµç¹ä¸å·è¡ãéäºè³æç¶éæåä¸è¶³æ¡æ¨£ä»¥æ¨¡æ¬å éç¨åºï¼ä¸¦å¨æåçæ¨¡åä¸­é²è¡è¨ç·´ä»¥åå¾éå»ºæ¨¡åãé¡å¤çåå¹¾åæ¸¬è©¦è³æéåå¦å¤åå¾ï¼ç¨æ¼è©ä¼°å³ææè½åæº«åº¦æºç¢ºåº¦ãå¨ 2 åå 4 å k-space ä¸è¶³æ¡æ¨£ç­ç¥ä¸­ï¼ç¼ç¾å éå å­çº 1.9 å 3.7ï¼èåºæ¼ ResUNet çæ·±åº¦å­¸ç¿éå»ºè¡¨ç¾å¾éå¸¸å¥½ãå¨ 2 åå éæå¢ä¸­ï¼æº«åº¦ååå¡ç RMSE å¨æ¨¡æ¬äººé«åé¢é«æ¸¬è©¦è³æéä¸æä¾ 0.888 åº¦ææ°å 1.145 åº¦ææ°çå¼ãæº«åº¦ååç DICE å¼ï¼ä»¥ 43 åº¦ææ°ç­æº«ç·åè¦ï¼çº 0.809ï¼è Bland-Altman åæé¡¯ç¤ºåå·®çº -0.253 åº¦ææ°ï¼å ä¸ææ¸å» 2.16 åº¦ææ°ãå¨ 4 åä¸è¶³æ¡æ¨£æ¡ä¾ä¸­ï¼éäºè©ä¼°å¼æ¸å°äºå¤§ç´ 10%ãéé ç ç©¶è­æï¼åºæ¼æ·±åº¦å­¸ç¿çéå»ºå¯ä»¥å¤§å¹æåè¨åº FUS ç±çä¸­ MR æº«åº¦æ¸¬éçæºç¢ºåº¦åæçã

##### **MVGT: A Multi-view Graph Transformer Based on Spatial Relations for EEG Emotion Recognition**
2407.03131v2 by Yanjie Cui, Xiaohong Liu, Jing Liang, Yamin Fu

Electroencephalography (EEG), a medical imaging technique that captures scalp
electrical activity of brain structures via electrodes, has been widely used in
affective computing. The spatial domain of EEG is rich in affective
information. However, few of the existing studies have simultaneously analyzed
EEG signals from multiple perspectives of geometric and anatomical structures
in spatial domain. In this paper, we propose a multi-view Graph Transformer
(MVGT) based on spatial relations, which integrates information from the
temporal, frequency and spatial domains, including geometric and anatomical
structures, so as to enhance the expressive power of the model comprehensively.
We incorporate the spatial information of EEG channels into the model as
encoding, thereby improving its ability to perceive the spatial structure of
the channels. Meanwhile, experimental results based on publicly available
datasets demonstrate that our proposed model outperforms state-of-the-art
methods in recent years. In addition, the results also show that the MVGT could
extract information from multiple domains and capture inter-channel
relationships in EEG emotion recognition tasks effectively.

æè¦ï¼è¦é»åï¼EEGï¼æ¯ä¸ç¨®é«å­¸å½±åæè¡ï¼ééé»æ¥µæ·åé ­ç®ä¸è¦é¨çµæ§çé»æ°£æ´»åï¼å·²å»£æ³ç¨æ¼ææéç®ä¸­ãEEG çç©ºéåèèè±å¯çææè³è¨ãç¶èï¼ç¾æçç ç©¶é®®å°åæå¾ç©ºéåä¸­çå¹¾ä½çµæ§åè§£åçµæ§ç­å¤éé¢ååæ EEG è¨èãæ¬ææåºä¸ååºæ¼ç©ºééä¿çå¤è¦ååå½¢è½æå¨ï¼MVGTï¼ï¼å®æ´åäºæéãé »çåç©ºéåï¼åæ¬å¹¾ä½çµæ§åè§£åçµæ§ï¼çè³è¨ï¼ä»¥å¨é¢æåæ¨¡åçè¡¨ç¾åãæåå° EEG ééçç©ºéè³è¨ç·¨ç¢¼å¾ç´å¥æ¨¡åä¸­ï¼é²èæåå¶æç¥ééç©ºéçµæ§çè½åãåæï¼åºæ¼å¬éè³æéçå¯¦é©çµæé¡¯ç¤ºï¼æåæåºçæ¨¡ååªæ¼è¿å¹´ä¾çç¾ææè¡ãæ­¤å¤ï¼çµæä¹é¡¯ç¤º MVGT è½ææå¾å¤éåä¸­æ·åè³è¨ï¼ä¸¦å¨ EEG æç·è¾¨è­ä»»åä¸­ææå°éééçéä¿ã

##### **Effective Heterogeneous Federated Learning via Efficient Hypernetwork-based Weight Generation**
2407.03086v1 by Yujin Shin, Kichang Lee, Sungmin Lee, You Rim Choi, Hyung-Sin Kim, JeongGil Ko

While federated learning leverages distributed client resources, it faces
challenges due to heterogeneous client capabilities. This necessitates
allocating models suited to clients' resources and careful parameter
aggregation to accommodate this heterogeneity. We propose HypeMeFed, a novel
federated learning framework for supporting client heterogeneity by combining a
multi-exit network architecture with hypernetwork-based model weight
generation. This approach aligns the feature spaces of heterogeneous model
layers and resolves per-layer information disparity during weight aggregation.
To practically realize HypeMeFed, we also propose a low-rank factorization
approach to minimize computation and memory overhead associated with
hypernetworks. Our evaluations on a real-world heterogeneous device testbed
indicate that HypeMeFed enhances accuracy by 5.12% over FedAvg, reduces the
hypernetwork memory requirements by 98.22%, and accelerates its operations by
1.86 times compared to a naive hypernetwork approach. These results demonstrate
HypeMeFed's effectiveness in leveraging and engaging heterogeneous clients for
federated learning.

æè¦ï¼éç¶è¯åå­¸ç¿å©ç¨åæ£å¼ç¨æ¶ç«¯è³æºï¼ä½ç±æ¼ç¨æ¶ç«¯è½åç°è³ªï¼å æ­¤é¢è¨ææ°ãééè¦åéé©åç¨æ¶ç«¯è³æºçæ¨¡åï¼ä¸¦ä»ç´°åæ¸èåä»¥å®¹ç´éç¨®ç°è³ªæ§ãæåæåº HypeMeFedï¼ä¸ç¨®æ°çè¯åå­¸ç¿æ¡æ¶ï¼ééå°å¤åºå£ç¶²è·¯æ¶æ§èåºæ¼è¶ç¶²è·¯çæ¨¡åæ¬éçæç¸çµåä¾æ¯æ´ç¨æ¶ç«¯ç°è³ªæ§ãæ­¤æ¹æ³å°é½ç°è³ªæ¨¡åå±¤çç¹å¾µç©ºéï¼ä¸¦å¨æ¬éèåæéè§£æ±ºéå±¤è³è¨å·®ç°ãçºäºå¯¦éå¯¦ç¾ HypeMeFedï¼æåéæåºäºä¸ç¨®ä½ç§©åè§£æ¹æ³ï¼ä»¥æå¤§éåº¦å°æ¸å°èè¶ç¶²è·¯ç¸éçè¨ç®åè¨æ¶é«éé·ãæåå¨çå¯¦ä¸çç°è³ªè¨­åæ¸¬è©¦å¹³å°ä¸çè©ä¼°è¡¨æï¼è FedAvg ç¸æ¯ï¼HypeMeFed å°æºç¢ºçæé«äº 5.12%ï¼å°è¶ç¶²è·¯è¨æ¶é«éæ±æ¸å°äº 98.22%ï¼ä¸¦ä¸èå¤©ççè¶ç¶²è·¯æ¹æ³ç¸æ¯ï¼å¶éç®éåº¦æé«äº 1.86 åãéäºçµæè­æäº HypeMeFed å¨å©ç¨åå¸å¼ç°è³ªç¨æ¶ç«¯é²è¡è¯åå­¸ç¿æ¹é¢çæææ§ã

##### **Attention Incorporated Network for Sharing Low-rank, Image and K-space Information during MR Image Reconstruction to Achieve Single Breath-hold Cardiac Cine Imaging**
2407.03034v1 by Siying Xu, Kerstin Hammernik, Andreas Lingg, Jens Kuebler, Patrick Krumm, Daniel Rueckert, Sergios Gatidis, Thomas Kuestner

Cardiac Cine Magnetic Resonance Imaging (MRI) provides an accurate assessment
of heart morphology and function in clinical practice. However, MRI requires
long acquisition times, with recent deep learning-based methods showing great
promise to accelerate imaging and enhance reconstruction quality. Existing
networks exhibit some common limitations that constrain further acceleration
possibilities, including single-domain learning, reliance on a single
regularization term, and equal feature contribution. To address these
limitations, we propose to embed information from multiple domains, including
low-rank, image, and k-space, in a novel deep learning network for MRI
reconstruction, which we denote as A-LIKNet. A-LIKNet adopts a parallel-branch
structure, enabling independent learning in the k-space and image domain.
Coupled information sharing layers realize the information exchange between
domains. Furthermore, we introduce attention mechanisms into the network to
assign greater weights to more critical coils or important temporal frames.
Training and testing were conducted on an in-house dataset, including 91
cardiovascular patients and 38 healthy subjects scanned with 2D cardiac Cine
using retrospective undersampling. Additionally, we evaluated A-LIKNet on the
real-time 8x prospectively undersampled data from the OCMR dataset. The results
demonstrate that our proposed A-LIKNet outperforms existing methods and
provides high-quality reconstructions. The network can effectively reconstruct
highly retrospectively undersampled dynamic MR images up to 24x accelerations,
indicating its potential for single breath-hold imaging.

æè¦ï¼<paragraph>å¿èåæç£å±æ¯å½±å (MRI) æä¾äºå¿èå½¢æååè½å¨è¨åºå¯¦åä¸çç²¾æºè©ä¼°ãç¶èï¼MRI éè¦è¼é·çæ·åæéï¼èæè¿åºæ¼æ·±åº¦å­¸ç¿çæ¹æ³é¡¯ç¤ºåºæ¥µä½³çæ½åï¼ç¨æ¼å éå½±åä¸¦å¢å¼·éå»ºåè³ªãç¾æçç¶²è·¯å±ç¾äºä¸äºå¸¸è¦çéå¶ï¼éå¶äºé²ä¸æ­¥çå éå¯è½æ§ï¼åæ¬å®ä¸é åå­¸ç¿ãä¾è³´å®ä¸æ­£ååé ï¼ä»¥åç¸ç­çç¹å¾µè²¢ç»ãçºäºè§£æ±ºéäºéå¶ï¼æåæè­°å°ä¾èªå¤åé åçè³è¨åµå¥ä¸åç¨æ¼ MRI éå»ºçæ°ç©æ·±åº¦å­¸ç¿ç¶²è·¯ä¸­ï¼åæ¬ä½ç§©ãå½±åï¼ä»¥å k ç©ºéï¼æåå°å¶è¡¨ç¤ºçº A-LIKNetãA-LIKNet æ¡ç¨å¹³è¡åæ¯çµæ§ï¼å¨ k ç©ºéåå½±åé åä¸­å¯¦ç¾ç¨ç«å­¸ç¿ãè¦åè³è¨å±äº«å±¤å¯¦ç¾äºé åä¹éçè³è¨äº¤æãæ­¤å¤ï¼æåå°æ³¨æåæ©å¶å¼å¥ç¶²è·¯ä¸­ï¼ä»¥å°è¼å¤§çæ¬éåéçµ¦æ´éè¦çç·åæéè¦çæéå¹ãè¨ç·´åæ¸¬è©¦æ¯å¨å§é¨è³æéä¸é²è¡çï¼å¶ä¸­åæ¬ 91 ä½å¿è¡ç®¡ç¾çæ£èå 38 ä½å¥åº·åè©¦èï¼ä»åä½¿ç¨ 2D å¿èåæå½±åé²è¡ææï¼ä¸¦ä½¿ç¨åæº¯å¼æ¬ æ¡æ¨£ãæ­¤å¤ï¼æåå¨ OCMR è³æéä¸­çå³æ 8 ååç»æ§æ¬ æ¡æ¨£è³æä¸è©ä¼°äº A-LIKNetãçµæè­æï¼æåæåºç A-LIKNet åªæ¼ç¾ææ¹æ³ï¼ä¸¦æä¾äºé«åè³ªçéå»ºãè©²ç¶²è·¯å¯ä»¥ææéå»ºé«åæº¯æ§æ¬ æ¡æ¨£çåæ MR å½±åï¼å éçé«é 24 åï¼éè¡¨ç¤ºå¶å·æå®æ¬¡éæ°£å½±åçæ½åã</paragraph>


### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v1](http://arxiv.org/abs/2407.05440v1)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v1](http://arxiv.org/abs/2406.16908v1)|null|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel MirÃ³-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v1](http://arxiv.org/abs/2404.12832v1)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|SÃ©amus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|TimothÃ©e Schmude et.al.|[2401.13324v4](http://arxiv.org/abs/2401.13324v4)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|
|**2023-11-21**|**Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**|Robert Gorwa et.al.|[2311.12573v2](http://arxiv.org/abs/2311.12573v2)|null|
|**2023-11-20**|**Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**|Muta Tah Hira et.al.|[2311.11932v1](http://arxiv.org/abs/2311.11932v1)|null|
|**2023-11-18**|**Representing visual classification as a linear combination of words**|Shobhit Agarwal et.al.|[2311.10933v1](http://arxiv.org/abs/2311.10933v1)|[link](https://github.com/lotterlab/task_word_explainability)|
|**2023-11-03**|**Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**|Emma A. M. Stanley et.al.|[2311.02115v2](http://arxiv.org/abs/2311.02115v2)|[link](https://github.com/estanley16/simba)|
|**2023-10-29**|**Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**|Adam White et.al.|[2310.19174v1](http://arxiv.org/abs/2310.19174v1)|null|
|**2023-10-03**|**Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**|Hossein Shreim et.al.|[2310.01828v2](http://arxiv.org/abs/2310.01828v2)|[link](https://github.com/geoaigroup/geoai-ecrs2023)|
|**2023-09-26**|**Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**|Muhammad Aurangzeb Ahmad et.al.|[2311.01463v1](http://arxiv.org/abs/2311.01463v1)|null|
|**2023-09-20**|**When to Trust AI: Advances and Challenges for Certification of Neural Networks**|Marta Kwiatkowska et.al.|[2309.11196v1](http://arxiv.org/abs/2309.11196v1)|null|
|**2023-09-19**|**Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**|Juan M. GarcÃ­a-GÃ³mez et.al.|[2309.10424v1](http://arxiv.org/abs/2309.10424v1)|null|
|**2023-09-19**|**QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**|Thanveer Shaik et.al.|[2309.10293v3](http://arxiv.org/abs/2309.10293v3)|null|
|**2023-09-18**|**Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**|Adarsa Sivaprasad et.al.|[2309.09917v1](http://arxiv.org/abs/2309.09917v1)|null|
|**2023-08-28**|**Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**|Yanjun Gao et.al.|[2308.14321v1](http://arxiv.org/abs/2308.14321v1)|null|
|**2023-08-18**|**Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**|Yun Xin Teoh et.al.|[2308.09380v1](http://arxiv.org/abs/2308.09380v1)|null|
|**2023-08-16**|**Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**|Munib Mesinovic et.al.|[2308.08407v1](http://arxiv.org/abs/2308.08407v1)|null|
|**2023-08-11**|**FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**|Karim Lekadir et.al.|[2309.12325v3](http://arxiv.org/abs/2309.12325v3)|null|
|**2023-08-10**|**Explainable AI applications in the Medical Domain: a systematic review**|Nicoletta Prentzas et.al.|[2308.05411v1](http://arxiv.org/abs/2308.05411v1)|null|
|**2023-08-01**|**Exploring the Role of Explainability in AI-Assisted Embryo Selection**|Lucia Urcelay et.al.|[2308.02534v1](http://arxiv.org/abs/2308.02534v1)|null|
|**2023-07-26**|**A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**|Timo Speith et.al.|[2307.14246v1](http://arxiv.org/abs/2307.14246v1)|null|
|**2023-07-26**|**Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**|Barnaby Crook et.al.|[2307.14239v1](http://arxiv.org/abs/2307.14239v1)|null|
|**2023-07-26**|**Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough**|Henry Fraser et.al.|[2308.02047v1](http://arxiv.org/abs/2308.02047v1)|null|
|**2023-07-21**|**eXplainable Artificial Intelligence (XAI) in aging clock models**|Alena Kalyakulina et.al.|[2307.13704v3](http://arxiv.org/abs/2307.13704v3)|null|
|**2023-07-19**|**Interpreting and Correcting Medical Image Classification with PIP-Net**|Meike Nauta et.al.|[2307.10404v2](http://arxiv.org/abs/2307.10404v2)|[link](https://github.com/m-nauta/pipnet)|
|**2023-07-15**|**Explaining and visualizing black-box models through counterfactual paths**|Bastian Pfeifer et.al.|[2307.07764v3](http://arxiv.org/abs/2307.07764v3)|[link](https://github.com/pievos101/cpath)|
|**2023-07-05**|**Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research**|Toygar Tanyel et.al.|[2307.02131v5](http://arxiv.org/abs/2307.02131v5)|[link](https://github.com/toygarr/counterfactual-explanations-for-medical-research)|
|**2023-06-30**|**AI and Non AI Assessments for Dementia**|Mahboobeh Parsapoor et.al.|[2307.01210v1](http://arxiv.org/abs/2307.01210v1)|null|
|**2023-06-12**|**Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation**|Ruitao Xie et.al.|[2306.07306v1](http://arxiv.org/abs/2306.07306v1)|null|
|**2023-06-09**|**HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine**|Rodrigo Agerri et.al.|[2306.06029v1](http://arxiv.org/abs/2306.06029v1)|null|
|**2023-06-07**|**XInsight: Revealing Model Insights for GNNs with Flow-based Explanations**|Eli Laird et.al.|[2306.04791v1](http://arxiv.org/abs/2306.04791v1)|null|
|**2023-06-06**|**Explainable AI using expressive Boolean formulas**|Gili Rosenberg et.al.|[2306.03976v1](http://arxiv.org/abs/2306.03976v1)|null|
|**2023-06-06**|**Utterance Classification with Logical Neural Network: Explainable AI for Mental Disorder Diagnosis**|Yeldar Toleubay et.al.|[2306.03902v1](http://arxiv.org/abs/2306.03902v1)|null|
|**2023-06-02**|**XAI Renaissance: Redefining Interpretability in Medical Diagnostic Models**|Sujith K Mandala et.al.|[2306.01668v1](http://arxiv.org/abs/2306.01668v1)|null|
|**2023-05-26**|**A Novel real-time arrhythmia detection model using YOLOv8**|Guang Jun Nicholas Ang et.al.|[2305.16727v3](http://arxiv.org/abs/2305.16727v3)|null|
|**2023-05-22**|**Breast Cancer Segmentation using Attention-based Convolutional Network and Explainable AI**|Jai Vardhan et.al.|[2305.14389v2](http://arxiv.org/abs/2305.14389v2)|null|
|**2023-05-18**|**What Symptoms and How Long? An Interpretable AI Approach for Depression Detection in Social Media**|Junwei Kuang et.al.|[2305.13127v2](http://arxiv.org/abs/2305.13127v2)|null|
|**2023-05-17**|**Echoes of Biases: How Stigmatizing Language Affects AI Performance**|Yizhi Liu et.al.|[2305.10201v4](http://arxiv.org/abs/2305.10201v4)|null|
|**2023-05-05**|**Explaining the ghosts: Feminist intersectional XAI and cartography as methods to account for invisible labour**|Goda Klumbyte et.al.|[2305.03376v1](http://arxiv.org/abs/2305.03376v1)|null|
|**2023-04-25**|**Towards Explainable and Safe Conversational Agents for Mental Health: A Survey**|Surjodeep Sarkar et.al.|[2304.13191v1](http://arxiv.org/abs/2304.13191v1)|null|
|**2023-04-04**|**A Brief Review of Explainable Artificial Intelligence in Healthcare**|Zahra Sadeghi et.al.|[2304.01543v1](http://arxiv.org/abs/2304.01543v1)|null|
|**2023-03-22**|**Reveal to Revise: An Explainable AI Life Cycle for Iterative Bias Correction of Deep Models**|Frederik Pahde et.al.|[2303.12641v2](http://arxiv.org/abs/2303.12641v2)|[link](https://github.com/maxdreyer/reveal2revise)|
|**2023-03-11**|**Explainable AI for Time Series via Virtual Inspection Layers**|Johanna Vielhaben et.al.|[2303.06365v1](http://arxiv.org/abs/2303.06365v1)|null|
|**2023-03-08**|**Towards Trust of Explainable AI in Thyroid Nodule Diagnosis**|Truong Thanh Hung Nguyen et.al.|[2303.04731v1](http://arxiv.org/abs/2303.04731v1)|[link](https://github.com/hungntt/xai_thyroid)|
|**2023-03-06**|**Cybersecurity of AI medical devices: risks, legislation, and challenges**|Elisabetta Biasin et.al.|[2303.03140v1](http://arxiv.org/abs/2303.03140v1)|null|
|**2023-02-06**|**LAVA: Granular Neuron-Level Explainable AI for Alzheimer's Disease Assessment from Fundus Images**|Nooshin Yousefzadeh et.al.|[2302.03008v2](http://arxiv.org/abs/2302.03008v2)|null|
|**2023-02-02**|**Diagrammatization: Rationalizing with diagrammatic AI explanations for abductive-deductive reasoning on hypotheses**|Brian Y. Lim et.al.|[2302.01241v2](http://arxiv.org/abs/2302.01241v2)|null|
|**2023-02-02**|**LesionAid: Vision Transformers-based Skin Lesion Generation and Classification**|Ghanta Sai Krishna et.al.|[2302.01104v1](http://arxiv.org/abs/2302.01104v1)|null|
|**2023-02-01**|**SkinCon: A skin disease dataset densely annotated by domain experts for fine-grained model debugging and analysis**|Roxana Daneshjou et.al.|[2302.00785v1](http://arxiv.org/abs/2302.00785v1)|null|
|**2023-01-19**|**Decision-Focused Evaluation: Analyzing Performance of Deployed Restless Multi-Arm Bandits**|Paritosh Verma et.al.|[2301.07835v1](http://arxiv.org/abs/2301.07835v1)|null|
|**2023-01-18**|**Exemplars and Counterexemplars Explanations for Image Classifiers, Targeting Skin Lesion Labeling**|Carlo Metta et.al.|[2302.03033v1](http://arxiv.org/abs/2302.03033v1)|null|

#### Abstracts
##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

æè¦ï¼äººå·¥æºè½ (AI) æ¯æçæ±ºç­å¶å®æ¯æªä¾ 6G ç¶²è·¯ä¸­çééµåç´ ï¼å¶ä¸­å°å¼å¥åç AI çæ¦å¿µãæ­¤å¤ï¼AI å»£æ³ç¨æ¼ä¸åçééµæç¨ä¸­ï¼ä¾å¦èªåé§é§åé«çè¨ºæ·ãå¨éäºæç¨ä¸­ï¼ä½¿ç¨ AI ä½çºé»çæ¨¡åæ¯æé¢¨éªä¸å·æææ°æ§çãå æ­¤ï¼çè§£åä¿¡ä»»éäºæ¨¡åååºçæ±ºç­è³ééè¦ãè§£æ±ºæ­¤åé¡çæ¹æ³æ¯éç¼å¯è§£é AI (XAI) æ¶æ§ï¼æ¨å¨è§£éé»çæ¨¡åè¡çºèå¾çéè¼¯ï¼å¾èç¢ºä¿å¶ææä¸å®å¨çé¨ç½²ãæè¿ï¼æåæåºäºä¸åæ°çåºæ¼æ¾åç XAI-CHEST æ¡æ¶ï¼è©²æ¡æ¶é¢åç¡ç·éä¿¡ä¸­çä¿¡éä¼°è¨ãXAI-CHEST æ¡æ¶çæ ¸å¿ææ³æ¯ééå¨ç¡éè¼¸å¥ä¸å¼å¥é«åªè²ä¾è­å¥ç¸éæ¨¡åè¼¸å¥ãéä»½æç¨¿æä¾äº XAI-CHEST æ¡æ¶çè©³ç´°çè«åºç¤ãç¹å¥æ¯ï¼æåæ¨å°äº XAI-CHEST æå¤±å½æ¸ååªè²é¾å¼å¾®èª¿åªååé¡çè§£æè¡¨éå¼ãå æ­¤ï¼è¨­è¨ç XAI-CHEST æä¾äºä¸ç¨®æºè½è¼¸å¥ç¹å¾µé¸ææ¹æ³ï¼å¯ä»¥å¨åªåæç¨æ¨¡åçæ¶æ§çåæé²ä¸æ­¥æé«æ´é«æ§è½ãæ¨¡æ¬çµæè¡¨æï¼XAI-CHEST æ¡æ¶æä¾äºææçè§£éï¼å¨éä½æéçè¨ç®è¤éåº¦çåæï¼æä¾äºæ¹é²çæ¯ç¹é¯èª¤çæ§è½ï¼èéèåºæ¼å³çµ± DL çä¿¡éä¼°è¨ç¸æ¯ã

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v1 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

æè¦ï¼<paragraph>æ¬ææåºäºç¨äºè§ç½èç¼åºå¾åç¾çåç±»çæ©å¼ æ®å·®ç½ç» (ResNet) æ¨¡åãæ©å¼ å·ç§¯æ»¤æ³¢å¨ç¨äºæ¿æ¢ ResNet æ¨¡åè¾é«å±ä¸­çæ­£å¸¸å·ç§¯æ»¤æ³¢å¨ï¼æ©å¼  ResNetï¼ï¼ä»¥æ¹åä¸ç¨äºç¾çåç±»çæ­£å¸¸ ResNet æ¨¡åç¸æ¯çæåéãæ¬ç ç©¶ä»ç»äºéç¨æ·±åº¦å­¦ä¹ çè®¡ç®æºè¾å©è¯æ­å·¥å·ï¼å¹¶éè¿å¯è§£éç AI ææ¯è¿è¡äºå¢å¼ºãè¿äºææ¯æ¨å¨ä½¿è¯¥å·¥å·çå³ç­è¿ç¨éæåï¼ä»èä½¿å»çä¸ä¸äººåè½å¤çè§£åä¿¡ä»» AI çè¯æ­å³ç­ãå®ä»¬å¨å½ä»å»çä¿å¥é¢åå°¤ä¸ºéè¦ï¼å ä¸ºå¯¹ AI åºç¨ç¨åºçéæåº¦éæ±ä¸æ­å¢é¿ï¼ä»¥ç¡®ä¿å¶å¯é æ§åéå¾·ä½¿ç¨ãæ©å¼  ResNet ç¨ä½æ­£å¸¸ ResNet çæ¿ä»£åï¼ä»¥æé«è§ç½èç¼ççåç±»åç¡®æ§å¹¶åå°æéçè®¡ç®æ¶é´ãæ¬å·¥ä½ä¸­ä½¿ç¨çæ°æ®éæ¯ Ocular Disease Intelligent Recognition (ODIR) æ°æ®éï¼è¿æ¯ä¸ä¸ªç»æåçç¼ç§æ°æ®åºï¼åå«å«ç±»æ¶µçå¤§å¤æ°å¸¸è§è§ç½èç¼çãæ¬å·¥ä½ä¸­ä½¿ç¨çè¯ä¼°ææ åæ¬ç²¾ç¡®åº¦ãå¬åçãåç¡®åº¦å F1 åæ°ãå¨è¿é¡¹å·¥ä½ä¸­ï¼å¯¹æ­£å¸¸ ResNet æ¨¡ååæ©å¼  ResNet æ¨¡åå¨äºä¸ªåä½ï¼å³ ResNet-18ãResNet-34ãResNet-50ãResNet-101 å ResNet-152ï¼ä¹é´è¿è¡äºæ¯è¾ç ç©¶ãä¸æ­£å¸¸ ResNet ç¸æ¯ï¼æ©å¼  ResNet æ¨¡åæ¾ç¤ºåºæå¸æçç»æï¼å¨ ODIR å¤ç±»ç¾çåç±»ä¸­ï¼ä¸è¿°åä¸ªåä½çå¹³å F1 åæ°åå«ä¸º 0.71ã0.70ã0.69ã0.67 å 0.70ã</paragraph>

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

æè¦ï¼åºéè¶é³æ³¢ (POCUS) æ¯è¨åºé«å¸«å¨æ£èåºéé²è¡åè§£è®è¶é³æ³¢ææçå¯¦åãç¶èï¼è§£è®éäºå½±åæéçå°æ¥­ç¥è­ç¸ç¶å¯è§ï¼èä¸å¨ç·æ¥ææ³ä¸å¯è½ä¸¦éé¨æå·åãéç¨®ç¾å¯¦ææ³ä½¿å¾æ©å¨å­¸ç¿åé¡å¨ç­æ¼ç®æ³å°æ¼å å¼·äººé¡æ±ºç­è®å¾æ¥µçºæå¹å¼ãPOCUS è£ç½®æ­£ä»¥åçææ¬æ¨åºï¼å°ºå¯¸çºææ©å¤§å°ãå° POCUS è£ç½®è½è®çºæçå·¥å·çææ°å¨æ¼ï¼è§£è®è¶é³æ³¢å½±åéè¦å°éè¨ç·´åç¶é©ãä¸å¹¸çæ¯ï¼åå¾æ­£åè¨ç·´å½±åçå°é£åº¦ä»£è¡¨èå»ºç½®ææçä¸æºç¢ºçåé¡å¨çä¸å¤§éç¤ãå æ­¤ï¼æååè©¦æ¢è¨çåé¡æ¯å¦ä½æ¢ç´¢ç­ç¥ï¼ä»¥æé«ä½¿ç¨ç¨çè³æè¨ç·´çåé¡å¨çæºç¢ºåº¦ãæååè¨­ä½¿ç¨å°æ¸è³æå¯¦ä¾é²è¡è¨ç·´å¯è½ä¸è¶³ä»¥è®åé¡å¨æ¦æ¬ï¼å°è´å®åéåº¦æ¬åãæåçåæ³ä½¿ç¨å¯è§£é AI å¢å¼·æ¹æ³ï¼ä»¥åå©æ¼ç®æ³å¾è¼å°çè³æä¸­å­¸ç¿æ´å¤ï¼ä¸¦æ½å¨åå©åé¡å¨æ´å¥½å°æ¦æ¬ã

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

æè¦ï¼è¿å¹´ä¾ï¼ç¾åè¦è­äºé»å­çæé»å­é¦è¸ä½¿ç¨çå¤§å¹æ¿å¢ï¼å°è´é»å­çåé»å­çä½¿ç¨ç¸éèºæå· (EVALI) çä¾é¡¯èå¢å ï¼å¨ 2019 å¹´ EVALI çç¼æéé æä½é¢åæ­»äº¡ï¼å¸é¡¯äºçè§£é»å­çè¡çºåå¶å®æææè¸ç­ç¥çè¿«åæ§ãç±æ¼ç¤¾ç¾¤åªé«å¹³å°çæ®åï¼å¨çè¶é 47 åä½¿ç¨èä½¿ç¨å®åé²è¡é£çµãæºéãæ°èåå¨æ¨ï¼å¶ä¸­å¾å¤§ä¸é¨åèå¥åº·ç¸éï¼å æ­¤å°ç¤¾ç¾¤åªé«è³æå»ºç«çºå¬å±è¡çç ç©¶ä¸­ç¡å¹çææ©è³æè³æºãå¨æ¬ç ç©¶ä¸­ï¼æåå¾ Reddit ä¸ä¸åé»å­çå­ç¤¾ç¾¤ä¸­æåä¸åç¯ä¾è³æéï¼ä»¥åæä½¿ç¨èçæé»å­çæåãå©ç¨ OpenAI ææ°çå¤§åèªè¨æ¨¡å GPT-4 é²è¡å¥å­å±¤ç´çæé»å­çæååµæ¸¬ï¼æ¬ç ç©¶æ¯è¼äºæ­¤æ¨¡åççµæèå¤è¡äººåè¨åºå°å®¶è¨»è§£ãä½¿ç¨ä¸åçæç¤ºç­ç¥ï¼ä¾å¦é¶æ¬¡å­¸ç¿ãä¸æ¬¡å­¸ç¿ãå°æ¬¡å­¸ç¿åæèéæç¤ºï¼æåéç¼äº 8 åæç¤ºï¼è©³ç´°ç¨åº¦ä¸åï¼å GPT-4 è§£éä»»åï¼ä¸¦è©ä¼°éäºç­ç¥å½¼æ­¤ä¹éçæè½ãéäºåæ­¥ç¼ç¾å¼·èª¿äº GPT-4 å¨ç¤¾ç¾¤åªé«è³æåæä¸­çæ½åï¼ç¹å¥æ¯å¨è­å¥äººé¡åµæ¸¬å¯è½ç¡æ³å¯è¦ºçä½¿ç¨èå¾®å¦æåæ¹é¢ã

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

æè¦ï¼<paragraph>äººå·¥æºæ§ï¼AIï¼ç®åå¨å¾å¤§ç¨åº¦ä¸ä¾è³´æ¼ç¼ºä¹å¯è§£éæ§çé»çæ©å¨å­¸ç¿æ¨¡åãå¯è§£éæ§äººå·¥æºæ§ï¼XAIï¼é åè´åæ¼è§£æ±ºéåä¸»è¦åé¡ï¼éå¨éèãæ³å¾åå¥åº·ç­é«é¢¨éªé åè³ééè¦ã
æåæåºäºä¸ç¨®åºæ¼ç¯çè«å®ç¾© AI æ¨¡ååå¶å¯è§£éæ§çæ¹æ³ãçºæ­¤ï¼æåæ¡ç¨çµåæ¨¡åçæ¦å¿µï¼å®ä»¥å½¢å¼å¼¦åçå½¢å¼çå¾æ¨¡åï¼éäºå¼¦åæç²äºæ¨¡åçæ½è±¡çµæ§åå¶å·é«å¯¦ç¾ãéç¨®ç¶åè§é»åå«äºç¢ºå®æ§ãæ¦çæ§åéå­æ¨¡åãæåå°åç¨® AI æ¨¡åä½çºçµåæ¨¡åé²è¡æ¯è¼ï¼åæ¬ç·æ§ååºæ¼è¦åçæ¨¡åãï¼éè¿´ï¼ç¥ç¶ç¶²è·¯ãTransformerãVAEï¼ä»¥åå æå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåæ ¹ææ¨¡åççµåçµæ§çµ¦åºæ¨¡åè§£éçå®ç¾©ï¼å±ç¤ºå¦ä½åææ¨¡åçå¯è§£éæ§ï¼ä¸¦ä½¿ç¨å®ä¾æ¾æ¸ XAI ä¸­çå¸¸è¦ä¸»é¡ãæåç¼ç¾ï¼è®æ¨æºçãå§å¨å¯è§£éãæ¨¡åå¦æ­¤éæçåå å¨åè¡¨ä¸­è¡¨ç¾å¾æçºæ¸æ¥ãéå¼å°æåå¾åºæ´ä¸è¬ççµåå¯è§£éï¼CIï¼æ¨¡åæ¦å¿µï¼å®å¦å¤éåæ¬å æãæ¦å¿µç©ºéå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåå±ç¤ºäº CI æ¨¡åçå¯è§£éæ§åªå¢ãé¦åï¼å®åççµåçµæ§åè¨±è¨ç®å¶ä»æèè¶£çéï¼ä¸¦å¯è½ééå¹éæ¨¡åççµæ§ä¾ä¿é²å¾æ¨¡åå°è¢«å»ºæ¨¡ç¾è±¡çæ¨çãå¶æ¬¡ï¼å®ååè¨±å°å¶è¡çºé²è¡åè§£èªªæï¼éäºèªªæåºæ¼å½±é¿ç´æãåè§£æè¡åéå¯«èªªæãæå¾ï¼æåè¨è«äºéç¨®æ¹æ³çè¨±å¤æªä¾æ¹åï¼æåºäºå¦ä½å¨å¯¦è¸ä¸­å­¸ç¿éç¨®ææç¾©ççµæ§åæ¨¡åçåé¡ã</paragraph>

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

æè¦ï¼åå®å®çæ¦å¿µå¨ååé åé½ååéæ³¨ï¼å¶éè¦æç¨ä¹ä¸ä¾¿æ¯é«çä¿å¥ãåå®å®æå·¨å¤§çæ½åééæ¹è®çæ£ç§è­·ãé«å­¸æè²ï¼ä»¥åæå­¸/å­¸ç¿åç ç©¶çæ¹å¼ä¾è½åé«çä¿å¥ãæ¬ç ç©¶çç®çæ¯æä¾åå®å®åºæ¬æ¦å¿µååºç¤æè¡çä»ç´¹ãæ¬ææ¢è¨äºåå®å®å¨é«çä¿å¥èæ¯ä¸çåªç¼ºé»ï¼ä¸¦å¾æè¡å AI çè§åº¦åæå¶æ½åãç¹å¥æ¯ï¼è¨è«äºæ©å¨å­¸ç¿æ¹æ³çè§è²ï¼æåå°èªªæå¦ä½å°æ©å¨å­¸ç¿æ¼ç®æ³æç¨æ¼åå®å®ç¢ççè³æï¼ä»¥ç²å¾é«çä¿å¥æç¨æ¹é¢çæ´ä½³è¦è§£ãæ­¤å¤ï¼æåééæ¢è¨åå¡éç­æ°èæè¡ï¼ä¸¦è§£æ±ºé±ç§åé¡ï¼ä¾æ¢è¨åå®å®å¨é«çä¿å¥æ¹é¢çæªä¾é¡æ¯ãæ¬ç ç©¶çç¼ç¾æå©æ¼æ´æ·±å¥å°äºè§£åå®å®å¨é«çä¿å¥ä¸­çæç¨ï¼ä»¥åå¶å¨é«çæåæä¾æ¹é¢ç¼æ®é©å½æ§è®é©çæ½åã

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

æè¦ï¼æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®å»£æ³çæ¢æ§ç¾çï¼æ²æå·²ç¥çæçµçæ³ä¸ç¼ççå¾é«ãç ç©¶è¡¨æï¼é²è¡æ§æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®ç°è³ªæ§ç¾çï¼æé¡¯èå½±é¿èèçµæ§ååè½ï¼æçµå°è´èè¡°ç«­ãé¨èæéçæ¨ç§»ï¼æ¢æ§èèçå·²å¾å½±é¿å°æ¸äººçè´å½ç¾çè½è®çºä¸ç¨®å´éç¨åº¦ä¸åçå¸¸è¦ç¾çãæ¬ç ç©¶çç®æ¨æ¯ä½¿ç¨éæå­¸ç¿åå¯è§£éç AI é²è¡æ©æé å¾å CKD æª¢æ¸¬ï¼ä¸¦è¦è¦ºåä¸»å°ç¹å¾µãç¹å¾µåæ¸åè¡¨ç¾åºçå¼ãçºæ­¤ï¼æåºäºä¸ç¨® AI é©åçé æ¸¬åææ¹æ³ï¼ä»¥å¹«å©è¨åºé«ççºåå¥æ£èéå·çæ´»æ¹å¼ä¿®æ¹å»ºè­°ï¼ä»¥éä½éç¨®ç¾ççé²å±éåº¦ãæåçæ¸æéæ¯å¾ CKD æ£èåå¥åº·åè©¦èçèº«é«çå½é«å¾µä¸­æ¶éçï¼ä»¥æºç¢ºéç¼æåæåºç AI é©åçè§£æ±ºæ¹æ¡ãå¨éæ¹é¢ï¼æä¾äºè¡æ¶²åå°¿æ¶²æª¢æ¸¬çµæï¼ä¸¦æç¨åºæ¼éææ¨¹çæ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬æªç¼ç¾ç CKD çä¾ãæåçç ç©¶çµæç¶éèèèç§é«ççé·æè«®è©¢å¾å¾å°é©è­ãæåçå¯¦é©åè§£éçµæèåç¨®é«çä¿å¥é åä¸­ç¾æçå¯è§£é AI æç¨é²è¡äºæ¯è¼ï¼åæ¬ CKDãæ¯è¼è¡¨æï¼æåéç¼ç AI æ¨¡åï¼ç¹å¥æ¯é¨æ©æ£®ææ¨¡åï¼å·²ç¶ç¢ºå®äºæ¯ XgBoost æ´å¤ä½çºéè¦è²¢ç»èçç¹å¾µãå¯è§£éæ§ (I) è¡¡ééè¦ç¹å¾µèæ©èç¹å¾µçæ¯çï¼è¡¨ææåç XgBoost æ¨¡åå¨éåææ¨ä¸­ç²å¾äºæ´é«çåæ¸ï¼ç¹å¥æ¯ 98% çä¿çåº¦ï¼ä¸¦ä¸å¨ FII ææ¸ä¸­èªç¶é«æ¼ç«¶ç­æ¨¡åã

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

æè¦ï¼å¿çå¥åº·æ§æäºä¸é è¤éä¸æ®éçå¨çææ°ï¼å½±é¿äºæ¸ç¾è¬äººççæ´»ï¼ä¸¦ç¶å¸¸å°è´å´éçå¾æãå¨æ¬æä¸­ï¼æåé²è¡äºä¸é å¾¹åºçèª¿æ¥ï¼ä»¥æ¢ç´¢æ¸æç§å­¸ãäººå·¥æºæ§åå¿çä¿å¥çäº¤éï¼éé»éæ³¨ééç·ä¸ç¤¾äº¤åªé« (OSM) é²è¡å¿çç¾çæª¢æ¸¬çææ°ç¼å±ãå¾å¤§ä¸é¨åäººå£ç©æ¥µåè OSM å¹³å°ï¼åµé äºä¸åé¾å¤§çäººå¡è³æåº«ï¼å°å¿çå¥åº·åæå·æå·¨å¤§çæ½åãæ¬ææ¢è¨äºå³çµ±çè¨ºæ·æ¹æ³ãæåé²çè³æå AI é©åçç ç©¶ï¼ä»¥åå¿çä¿å¥ä¸­å¯è§£é AI (XAI) æ¨¡åçåºç¾ãæååé¡§äºæåé²çæ©å¨å­¸ç¿æ¹æ³ï¼ç¹å¥æ¯é£äºåºæ¼ç¾ä»£æ·±åº¦å­¸ç¿çæ¹æ³ï¼åæå¼·èª¿äºé«çä¿å¥ AI æ¨¡åä¸­å¯è§£éæ§çå¿è¦æ§ãå¯¦é©è¨­è¨é¨åæä¾äºå°æ®éåæ³çè¦è§£ï¼åæ¬å¯ç¨çè³æéåè©ä¼°æ¹æ³ãæåéæ¾åºè©²é åçä¸»è¦åé¡åææ°ï¼ä¸¦æåºäºæå¸æçæªä¾ç ç©¶æ¹åãç±æ¼å¿çå¥åº·æ±ºç­éè¦éæåº¦ãå¯è§£éæ§åéå¾·èéï¼æ¬ææå©æ¼æ¨é²å¿çä¿å¥ä¸­ééç¤¾äº¤åªé«æ¨é² XAI çæçºè¨è«ãéè£¡æåºçå¨é¢æ¦è¿°æ¨å¨å¼å°ç ç©¶äººå¡ãå¾æ¥­äººå¡åæ¿ç­å¶å®èç¼å±å¿çç¾çæª¢æ¸¬é åã

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

æè¦ï¼<paragraph>é«çç§è­·ä¸­éè¦ AI è¼å©çè¨åºè¨ºæ·ãç¾æçæ·±åº¦å­¸ç¿æ¨¡åç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸ä¸»è¦å°æ³¨æ¼å½±ååæãæè¿éç¼çåæä¸ç¢ºå®å æéä¿å (DUCG) æ¹æ³æ¯å æé©åçãå¯è§£éçï¼ä¸¦ä¸å¨ä¸åçæç¨å ´æ¯ä¸­æ¯ä¸è®çï¼æ²æè³ææ¶éãæ¨è¨ãæ¬åãé±ç§ãåè¦ãæ¦åãé«ææ¬åé«è½èçåé¡ãééè¨åºå°å®¶å DUCG æè¡äººå¡ä¹éçå¯ååä½ï¼æ§å»ºäºæ¶µè 54 åä¸»è¨´ç 46 å DUCG æ¨¡åãå¯ä»¥å¨æ²æåæµçææ³ä¸è¨ºæ·åº 1,000 å¤ç¨®ç¾çãå¨æç¨æ¼å¯¦éä¸çä¹åï¼46 å DUCG æ¨¡åå·²ç±ç¬¬ä¸æ¹é«é¢åæº¯æ§é©è­ãé©è­çè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 95%ï¼å¶ä¸­åæ¬ç½è¦ç¾çå¨å§çæ¯ç¨®ç¾ççè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 80%ãé©è­å¾ï¼46 å DUCG æ¨¡åå·²å¨ä¸­åå¯¦éæç¨ãå·²ç¶å·è¡äºè¶éä¸ç¾è¬åçå¯¦è¨ºæ·æ¡ä¾ï¼åç¼ç¾ 17 åä¸æ­£ç¢ºçè¨ºæ·ãç±æ¼ DUCG çéææ§ï¼ç¼ç¾ä¸¦ç³¾æ­£äºå°è´ä¸æ­£ç¢ºè¨ºæ·çé¯èª¤ãé »ç¹æç¨ DUCG çè¨åºé«ççè¨ºæ·è½åå¾å°äºé¡¯èæé«ãå¨ä»ç´¹äºåé¢æåºç DUCG æ¹æ³è«ä¹å¾ï¼æåºäºæ½å¨å¥åº·æª¢æ¥çæ¨è¦æ¼ç®æ³ï¼ä¸¦æåäº DUCG çééµææ³ã</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

æè¦ï¼ç²¾ç¢ºä¸åæå°åµæ¸¬ä¹³çå°æ¼æ¹åæ£èé å¾è³ééè¦ãè¨ºæ·æ¹æ³å³çµ±ä¸ä¾è³´æ¼å®ä¸æ¨¡å¼æ¹æ³ï¼ç¶èï¼é«çè³æåææ­£å¨æ´åè¶è¶å³çµ±å½±åçåç¨®è³æä¾æºãä½¿ç¨æ´åå½±ååéå½±åè³æçå¤æ¨¡å¼æè¡ï¼æ¨èªèä¹³çè¨ºæ·çè®é©æ§é²å±ãæ¬ç¯ç¶è¿°çç®çæ¯æ¢è¨å¤æ¨¡å¼æè¡çæ°èé åï¼ç¹å¥æ¯å°çµç¹ççå­¸å½±åèéå½±åè³æèåãæ­¤å¤ï¼å¯è§£éäººå·¥æºæ§ (XAI) å°ç¨æ¼é¡æè¤éæ¼ç®æ³çæ±ºç­éç¨ï¼å¼·èª¿è¨ºæ·éç¨ä¸­å¯è§£éæ§çå¿è¦æ§ãæ¬ç¶è¿°å©ç¨å¤æ¨¡å¼è³æä¸¦å¼·èª¿å¯è§£éæ§ï¼ä»¥æé«è¨ºæ·æºç¢ºæ§ãè¨åºé«å¸«çä¿¡å¿åæ£èåèåº¦ï¼æçµä¿é²ä¹³çæ´åäººåçæ²»çç­ç¥ï¼åæä¹æ¾åºå¤æ¨¡å¼åå¯è§£éæ§çç ç©¶å·®è·ï¼å¼å°æªä¾çç ç©¶ï¼ä¸¦çºè©²é åçç­ç¥æ¹åååºè²¢ç»ã

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

æè¦ï¼èªæ³¨æåæ©å¶å·²è¢«æ¡ç¨æ¼å¤åå»£æ³ä½¿ç¨çè¨æ¯å³éç¥ç¶ç¶²è·¯ (MPNN)ï¼ä¾å¦ GATï¼ï¼å®å¯ä»¥èªé©æå°æ§å¶æ²¿èåºå±¤åå½¢éç·£æµåçè³è¨éãéç¨®æ³¨æåçä½¿ç¨ä½¿å¾æ­¤é¡æ¨¡åæçºå¯è§£é AI (XAI) ç ç©¶çåºç·ï¼å çºééæ³¨æåçè©®éå·²å¨åç¨®é åï¼ä¾å¦èªç¶èªè¨èçåé»è¦è¦è¦ºï¼ä¸­æ®åãç¶èï¼ç¾æçç ç©¶éå¸¸ä½¿ç¨å¤©ççè¨ç®æ¹æ³å¾æ³¨æåä¸­æ¨å°åºæ­¸å åæ¸ï¼ä¸¦ä¸æ²æèæ®å°éç·£æ­¸å çç²¾ç¢ºä¸ä»ç´°çè¨ç®ãå¨æåçç ç©¶ä¸­ï¼æåæ¨å¨å¡«è£æ³¨æååç¨ MPNN çå»£æ³ä½¿ç¨èå®åå¨å¾å¤§ç¨åº¦ä¸æªè¢«ååæ¢ç´¢çå¯è§£éæ§ä¹éçå·®è·ï¼éåä¸»é¡å·²å¨å¶ä»é åç©æ¥µç ç©¶ãçºæ­¤ï¼ä½çºç¬¬ä¸æ¬¡åè©¦ï¼æåå° GNN ä¸­æ³¨æåæ¬éçéç·£æ­¸å åé¡å½¢å¼åãç¶å¾ï¼æåæåº GATTï¼ä¸ç¨®å»ºç«å¨è¨ç®æ¨¹ä¸çéç·£æ­¸å è¨ç®æ¹æ³ãééå¨é¢çå¯¦é©ï¼æåå±ç¤ºäºæåæåºçæ¹æ³å¨è©ä¼° GAT çæ­¸å ææå·æçææãç¸åå°ï¼æåæç¶é©é©è­äºåå°åæ³¨æåå±¤ä¸çæ³¨æåæ¬éåå¹³åå¼ä¸è¶³ä»¥è©®é GAT æ¨¡åçè¡çºãç¨å¼ç¢¼å·²å¬éæ¼ https://github.com/jordan7186/GAtt/tree/mainã

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v1 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

æè¦ï¼æ°çåææ¯å¤§è¦ç¼è²æå®¹æåºç¾ç²ççææãå¤§è¦å°æªæçæç¼ççç²çæé æä¸è¯å¾æï¼å æ­¤éè¦ææ©è¨ºæ·ãç®åæ°çåç²çæª¢æ¸¬çé»éæ¨æºä¾è³´æ¼æçºçè¦è¨è¦é»å (EEG) ç£æ§ï¼å¶ä¸­åæ¬å¨æ°çåå è­·çæ¿ (NICU) å§éè£½å¤ééè¦é»å (EEG) åé²è¡å³æè¦è¨ç£æ§ãç¶èï¼è¦è¨è¦é»åç£æ§æè¡éè¦è¨åºå°æ¥­ç¥è­ï¼èä¸éå¸¸åéæ¼æè¡åé²ä¸è³æºè±å¯çç°å¢ãå·ææ¬æççæ°æè¡å¯ä»¥å¹«å©é«ççæºç¢ºè¨ºæ·ä¸¦ç«å³æå¡æ²»çãå¨éé å·¥ä½ä¸­ï¼æåºäºä¸åæ°ç©çå¯è§£éæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥èªååæ°çåç²çæª¢æ¸¬æµç¨ï¼ä¸¦æ¸å°è¦é»åè£ç½®ï¼æ¡ç¨å·ç©ç¥ç¶ç¶²è·¯ãåæ³¨æåå±¤åå¨é£æ¥å±¤ãé¤äºè½å¤ å³æåµæ¸¬ç²çç¼ä½ä¸¦æ¸å°è£ç½®å¤ï¼æ­¤æ¨¡åéæä¾äºå³æå¯è§£éæ§çç¨ç¹åªå¢ãééè©ä¼° Zenodo è³æéç 10 åäº¤åé©è­æè½ï¼æåºçæ¨¡åå¨æ²ç·ä¸é¢ç© (AUC) åå¬åçåå¥éå° 8.31% å 42.86% ççµå°æ¹åã

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

æè¦ï¼ä¹³ç (BC) æ¯å½±é¿å¨çå¥³æ§æå¸¸è¦çæ¡æ§è«ç¤ä¹ä¸ï¼å æ­¤éè¦é²æ­¥çè¨ºæ·æ¹æ³ï¼ä»¥æ¹åè¨åºçµæãæ¬æå¨é¢æ¢è¨äºå¯è§£éäººå·¥æºæ§ (XAI) æè¡å¨ä¹³çåµæ¸¬åè¨ºæ·ä¸­çæç¨ãé¨èäººå·¥æºæ§ (AI) æè¡æçºæ»²éé«çä¿å¥é åï¼ç¹å¥æ¯å¨è«ç¤å­¸ä¸­ï¼éæä¸å¯è§£éçæ¨¡åéæ±è®å¾å¢å¨å¿è¡ï¼ä»¥å¢å¼·è¨åºæ±ºç­å¶å®åæ£èç§è­·ãæ­¤ç¯è©è«æ¢è¨äºåç¨® XAI æ¹æ³çæ´åï¼ä¾å¦ SHAPãLIMEãGrad-CAM ç­ï¼ä»¥åç¨æ¼ä¹³çåµæ¸¬ååé¡çæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åãééæ¢è¨ä¹³çè³æéçæ¨¡å¼ï¼åæ¬ä¹³æ¿æå½±ãè¶é³æ³¢åå¶å¨ AI ä¸­çèçï¼æ¬æéé»èªªæ XAI å¦ä½è½å°è´æ´æºç¢ºçè¨ºæ·ååäººåæ²»çè¨ç«ãå®ä¹æ¢è¨äºå¯¦æ½éäºæè¡çææ°ï¼ä»¥åå¶å®æ¨æºåè©éææ¨ä»¥è©ä¼° XAI å¨è¨åºç°å¢ä¸­çæææ§çéè¦æ§ãééè©³ç´°çåæåè¨è«ï¼æ¬ææ¨å¨å¼·èª¿ XAI å¨ç¸®å°è¤é AI æ¨¡åèå¯¦åé«çä¿å¥æç¨ä¹éå·®è·çæ½åï¼é²èä¿é²é«çå°æ¥­äººå¡ä¹éçä¿¡ä»»èçè§£ï¼ä¸¦æ¹åæ£èççµæã

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

æè¦ï¼èªé³æç·è¾¨è­ (SER) ç±æ¼å¶å¨å¿çå¥åº·ãæè²åäººæ©äºåç­å¤åæç¨é åèååéæ³¨ãç¶èï¼SER ç³»çµ±çæºç¢ºæ§åå°é«ç¶­ç¹å¾µéçé»ç¤ï¼éäºç¹å¾µéå¯è½åå«ä¸ç¸éååé¤çè³è¨ãçºäºåæéåææ°ï¼æ¬ç ç©¶æåºäºä¸ç¨®ç¨æ¼ SER çè¿­ä»£ç¹å¾µæåæ¹æ³ï¼è©²æ¹æ³å¼·èª¿ç¹å¾µç¸éæ§åå¯è§£éæ§ï¼ä»¥å¢å¼·æ©å¨å­¸ç¿æ¨¡åçæè½ãæåçåæ³æ¶åä»ç´°çç¹å¾µé¸æååæï¼ä»¥å»ºç«é«æç SER ç³»çµ±ãçºäºééæ¨¡åå¯è§£éæ§è§£æ±ºæåçæ ¸å¿åé¡ï¼æåæ¡ç¨äºå·æ Shapley å¼çç¹å¾µè©ä¼°è¿´åï¼ä»¥åè¦æ¹åç¹å¾µéãéåéç¨å¨æ¨¡åæè½åéæåº¦ä¹éåå¾å¹³è¡¡ï¼éä½¿å¾æåè½å¤ å¨é¢äºè§£æ¨¡åçé æ¸¬ãææåºçæ¹æ³æä¾äºå¤é åªé»ï¼åæ¬è­å¥åç§»é¤ä¸ç¸éååé¤çç¹å¾µï¼å¾èå»ºç«æ´ææçæ¨¡åãæ­¤å¤ï¼å®ä¿é²äºå¯è§£éæ§ï¼æå©æ¼çè§£æ¨¡åçé æ¸¬ä»¥åè­å¥æç·æ±ºå®çééµç¹å¾µãææåºçæ¹æ³çæææ§å·²å¨å¤å«å¤æç·èªé³é (TESS)ãæææç·èªé³è³æåº« (EMO-DB)ãè³´ç¾æ£®é³è¨è¦è¦ºæç·èªé³åæ­æ²è³æåº« (RAVDESS) åè©éé³è¨è¦è¦ºè¡¨éæç· (SAVEE) è³æéç SER åºæºä¸å¾å°é©è­ï¼å¶æè½åªæ¼ç¾ææ¹æ³ãææåæç¥ï¼éæ¯ç¬¬ä¸åå°æ¨¡åå¯è§£éæ§ç´å¥ SER æ¶æ§çç ç©¶ãæ¬æçåå§ç¢¼å¯ééæ­¤é£çµå¬éåå¾ï¼https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognitionã

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, HÃ©loÃ¯se de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

æè¦ï¼å¯è§£éæ§éå¸¸å¯¹äºäººå·¥æºè½ (AI) çå¯æ¥åå®æ½è³å³éè¦ãå¨å»çä¿å¥é¢åï¼è¿ä¸ç¹å°¤ä¸ºéè¦ï¼å ä¸ºå³ç­ç´æ¥å½±åæ£èï¼å¹¶ä¸å¯¹ AI ç³»ç»çä¿¡ä»»è³å³éè¦ãè¿ç§ä¿¡ä»»éå¸¸å»ºç«å¨ AI æä¾çè§£éåè¯ éä¹ä¸ãå°½ç®¡ AI å¯è§£éæ§åå¾äºéå¤§è¿å±ï¼ä½ä»ç¶éè¦æç¡®çæå¯¼æ¹éï¼è¯´æå¨å»çç¯å¢ä¸­ä½æ¶ä»¥åå¨å¤å¤§ç¨åº¦ä¸éè¦è§£éãæä»¬æåºäºä¸ç§æ°é¢çåç±»ç³»ç»ï¼è¯¥ç³»ç»å·æåç§ä¸åçè§£éå¿è¦æ§ç±»å«ï¼æå¯¼æéçè§£éçº§å«ï¼æ£èææ ·æ¬ï¼å±é¨ï¼çº§å«ãéåææ°æ®éï¼å¨å±ï¼çº§å«ï¼æä¸¤ä¸ªçº§å«ãæä»¬å¼å¥äºä¸ä¸ªæ°å­¦å¬å¼ï¼è¯¥å¬å¼åºåäºè¿äºç±»å«ï¼å¹¶ä¸ºç ç©¶äººåæä¾äºä¸ä¸ªå®ç¨æ¡æ¶ï¼ä»¥ç¡®å®å»ç AI åºç¨ä¸­æéçè§£éçå¿è¦æ§åæ·±åº¦ãèèäºä¸ä¸ªå³é®å ç´ ï¼è¯ä¼°åè®®çç¨³å¥æ§ãä¸å®¶è§å¯çå¯åæ§ä»¥ååºç¨ç¨åºçè¡¨ç¤ºç»´æ°ãä»è¿ä¸ªè§åº¦æ¥çï¼æä»¬è§£å³äºè¿ä¸ªé®é¢ï¼AI å»çåºç¨ä½æ¶éè¦è§£éï¼ä»¥åéè¦è§£éå°ä½ç§ç¨åº¦ï¼

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

æè¦ï¼äººå·¥æºæ§ (AI) é åæ­£å¿«éå½±é¿èå¥åº·èé«çä¿å¥ï¼ä½å°æ¼é¢è¨å»£æ³çµæ§æ§å£è¿«çäººç¾¤ä¾èªªï¼åè¦åä¸è¯è¡¨ç¾ä¾ç¶å­å¨ãååçç ç©¶å·²æ¸æ¥èªªæï¼éè¦æ´å´æ ¼å°æ³¨æè³æä»£è¡¨æ§åæ¨¡åæè½ï¼ä»¥ä¿é²å¬å¹³æ§ä¸¦æ¸å°åè¦ãç¶èï¼æåææ©æéééç¨ç¤¾ææµè¡çå­¸åå¥åº·å¬å¹³çæä½³å¯¦åï¼ä¾æ¹å AI çå¯è§£éæ§ï¼ä»¥å¹«å©æåéå°ç¼ç¾çéè¯æ§ï¼ç¼å±åè¨­ãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼å¯è§£é AI (XAI)ï¼ä¸¦æè¿°ä¸åè·¨é åå°å®¶å°çµå¯©æ¥æ¶æ§ï¼ä»¥å¾å¤éè§é»è¨è«åæ¹å¤æ§è©ä¼° AI æ¨¡åçè§£éï¼ä¸¦æ¾åºåè¦é ååæªä¾ç ç©¶çæ¹åãæåå¼·èª¿è·¨é åå°å®¶å°çµå°æ¼ç¢çæ´æºç¢ºãå¬å¹³çè©®éè³ééè¦ï¼èéäºè©®éæ¯æ ¹ææ­·å²åèçµ¡èä¾çãè·¨é åå°çµè¨è«æå©æ¼æ¸å°åè¦ãæ¾åºæ½å¨çæ··æ·å ç´ ï¼ä¸¦å¨æç»ä¸­æç¼ºå£ææ¾åºé¡å¤ç ç©¶çæ©æãåéä¾ï¼éäºè¦è§£å¯ä»¥å»ºè­° AI æ¨¡åæ¹é²çæ©æã

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

æè¦ï¼é¨èåé²ç AI/MLï¼å°å¯è§£é AI (XAI) çç ç©¶ä¸æ·å¢å ï¼ä»¥åéæ¼äººé¡å¦ä½è AI å XAI äºåä»¥é²è¡ææçäººå·¥æºæ§åä½æ±ºç­å¶å®ãç¶èï¼æåä»ç¶ç¼ºä¹å° AI ç³»çµ±å XAI æå¦ä½é¦ååç¾çµ¦æ²ææè¡èæ¯çç¨æ¶çäºè§£ãå¨æ¬æä¸­ï¼æåå±ç¤ºäºèé«çå°æ¥­äººå¡ (n=12) åä¸»ä¿®é«å­¸åå¥åº·çå­¸ç (n=4) é²è¡åçµæ§åè¨ªè«ççµæï¼ä»¥ç ç©¶å¦ä½æ¹å AI å XAI çå¥éãå°æ¼è¨ªè«ï¼æåå»ºç«å¨äººæ©äºåæºåä¹ä¸ï¼çºä¸­é¢¨åº·å¾©è©ä¼°å AI è§£éç AI ç³»çµ±åµå»ºå¥éææï¼ä¸¦å°å®åä»ç´¹çµ¦åèèãæåçç ç©¶çµæè¡¨æï¼é¤äºåç¾å³çµ±ç AI æ§è½ææ¨å¤ï¼åèèéå¸æåºåä¿¡æ¯ãAI çå¯¦éå¥½èä»¥åäº¤äºè©¦é©ï¼ä»¥æ´å¥½å°å° AI æ§è½æå¢åï¼ä¸¦å®å AI çç®æ¨åæ§è½ãæ ¹æéäºç¼ç¾ï¼æåå¼·èª¿äºæ¹é² AI å XAI ä»¥åäººæ©åä½æ±ºç­å¶å®çå¥éæ¹åã

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

æè¦ï¼æ¬æä½¿ç¨æ©å¨å­¸ç¿ (ML) åå¯è§£éäººå·¥æºæ§ (XAI) æè¡ä¾æ¢è¨çé¤çæ³èé¿è²æµ·é»ç (AD) ç¸éçæ­»äº¡çä¹éçéä¿ãæ¡ç¨ç¬¬ä¸æ¬¡å¨åå¥åº·èçé¤æª¢æ¥èª¿æ¥ (NHANES III) è³æåº«é²è¡åæãé¸æé¨æ©æ£®ææ¨¡åä½çº XAI åæçåºç¤æ¨¡åï¼ä¸¦ä½¿ç¨ Shapley Additive Explanations (SHAP) æ¹æ³ä¾è©ä¼°ç¹å¾µéè¦æ§ãçµæçªé¡¯äºéè¦ççé¤å ç´ ï¼ä¾å¦è¡æ¸ç¶­çç´  B12 åç³åè¡ç´èç½ãè©²ç ç©¶è­æäºé¨æ©æ£®æå¨é æ¸¬ AD æ­»äº¡çæ¹é¢ç¸è¼æ¼å¶ä»ç¾ççæææ§ãæ¬ç ç©¶æä¾äºçé¤å° AD çå½±é¿çè¦è§£ï¼ä¸¦æå©æ¼æ´æ·±å¥å°äºè§£ç¾ççé²å±ã

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

æè¦ï¼å¨é«å­¸å½±åä¸­ï¼ç¹å¥æ¯å¨æ©æç¾çæª¢æ¸¬åé å¾ä»»åä¸­ï¼è¾¨å¥ AI æ¨¡åé æ¸¬èå¾çåçå°æ¼è©ä¼°å¶æ±ºç­çå¯é æ§è³ééè¦ãå³çµ±çè§£éæ¹æ³å¨è­å¥é«å­¸å½±ååé¡ä¸­å¯è­å¥çæ±ºå®æ§ç¹å¾µæé¢è¨ææ°ï¼å¶ä¸­åå¥æ§ç¹å¾µå¾å¾®å¦æä¸¦ä¸æé¡¯ãçºäºå½åéä¸å·®è·ï¼æåæåºäºä¸åå¯è§£éçæ¨¡åï¼è©²æ¨¡åå·åæ±ºç­æ¨çåç¹å¾µè­å¥è½åãæåçåæ³ä¸åæª¢æ¸¬æå½±é¿åçå½±åæ¨¡å¼ï¼éæ­ç¤ºäºæ¨åæ¨¡åæçµé æ¸¬çæ±ºå®æ§ç¹å¾µãééå¯¦æ½æåçæ¨¡åï¼æåå¯ä»¥ææè­å¥åè¦è¦ºåç±æ¸æé©åæ¨¡åå©ç¨çé¡ç¹å®ç¹å¾µï¼å¾èæ·±å¥äºè§£æ·±åº¦å­¸ç¿æ¨¡åçæ±ºç­éç¨ãæåå¨è¦æ±å´æ ¼çé«å­¸é å¾ä»»åé åé©è­äºæåçæ¨¡åï¼å±ç¤ºäºå¶å¨æé« AI å¨é«çä¿å¥ä¸­çå¯é æ§åç¼ç¾é å¾çè§£åéç¾ççæ°ç¥è­æ¹é¢çåæåæ½åã

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

æè¦ï¼æ¬ç ç©¶æ¢è¨ç·ä¸å¥åº·ç¤¾ç¾¤ä¸­å°æ±è³è¨æ¯æçåé¡ãåæï¼ä»¥åæå¹«å©çè©åä¹éçéä¿ãæåå»ºç«äºä¸çµæ¨è¨çåç­éå°è³æéï¼ä¸¦éç¼äºå¤æ¨¡ææ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥å¯é å°é æ¸¬è³è¨æ¯æåé¡ååæãæåæ¡ç¨å¯è§£éç AI ä¾æ­ç¤ºè³è¨æ¯æäº¤æµä¸­èå«çæç·ï¼è­ææç·å¨æä¾è³è¨æ¯æä¸­çéè¦æ§ãéç¨®æç·æ¯æåè³è¨æ¯æä¹éçè¤éäº¤äºä½ç¨ä»¥åä¸¦æªè¢«ç ç©¶éãæ¬ç ç©¶æ¹é²äºç¤¾ææ¯æçè«ï¼ä¸¦çºä½¿ç¨èæ±ºç­è¼å©å·¥å·çéç¼å¥ å®äºåºç¤ãè¨è«äºé²ä¸æ­¥çå½±é¿ã

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

æè¦ï¼å¨ç§æé£éç¼å±çæä»£ï¼ä¸ä½æå¤çè¨ªå®¢å·²å¨å¨çæå®¤ä¸­ä½æä¸å¸­ä¹å°ï¼é£å°±æ¯äººå·¥æºæ§ãçæå¼ AIï¼ä¾å¦ ChatGPTï¼æ¿è«¾å¨æè²é åæèµ·ä¸å ´é©å½ï¼ä½å®å»æ¯ä¸æéé¢åãå®å¨åäººåå­¸ç¿æ¹é¢çæ½åï¼å»å ä½å¼ãä¸æºç¢ºä»¥åæè²å·¥ä½èé£ä»¥å°å¶ææèå¥æå­¸è¨­è¨ç­åé¡èæµé·ãæåæ­£ç«å¨éæè²åæ²¿çéç·£ï¼é¡¯ç¶æåéè¦éå¸¸å°å¿å°æ¢ç´¢éçé åãéæ¯ä¸åéå¤§çææ°ï¼å¯è½ææå®³æåæè²éç¨çå®æ´æ§åå¹å¼ãé£éº¼ï¼æåå¦ä½å°éäºææ°è½åçºæ©éï¼ç¶ä¸é©ç¶å°ä½¿ç¨æï¼AI å·¥å·å¯è½ææçºè¤è£½è²¼ä¸å¿æçå®ç¾å·¥å·ï¼ä¸¦è¿éèèæ¹å¤æ§æç¶­ãåµé ååæ·±å¥çè§£ï¼éäºé½æ¯æåå¿«éè®åçä¸çä¸­æéè¦çæè½ãæå¸«åè¦ºå¾ä»åæ²æè½åå©ç¨éé æè¡ï¼éæ´å¤§äºæè²å·¥ä½èåæ©æ§ä¹éçæ¸ä½é´»æºãè§£æ±ºéäºåé¡éè¦æ·±å¥çç ç©¶æ¹æ³ãæåå°æ¡ç¨å¯¦è­ç ç©¶ï¼åéæè¡æ¥åæ¨¡åï¼ä¾è©ä¼°æè²å·¥ä½èåå­¸çå°çæå¼ AI çæåº¦ãäºè§£ä»åççæ³ãä½¿ç¨æ¨¡å¼åéç¤æ¯åµé ææè§£æ±ºæ¹æ¡çç¬¬ä¸åééµæ­¥é©ãæ¬ç ç©¶å°ä½çºæªä¾ç ç©¶äººå¡æç¨çæµç¨æåï¼æ ¹ææ­¤èèªªæçæ­¥é©éè¡ä»åèªå·±çæ¸æ

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike GrÃ¼ne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, AndrÃ© Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

æè¦ï¼é¨èé«çä¿å¥ç³»çµ±çæ¸ä½åï¼äººå·¥æºæ§å¨é«å­¸é åä¸­è®å¾æ´å æ®åãç¹å¥æ¯æ©å¨å­¸ç¿å¨æéåºååé¡ç­è¤éä»»åä¸­å±ç¾åºæ¥µå¤§çæ½åï¼ä½éå¸¸æ¯ä»¥éæåº¦åå¯çè§£æ§çºä»£å¹ãéå°è´äººé¡ç¼ºä¹ä¿¡ä»»ï¼å¾èé»ç¤äºå¶ç©æ¥µä½¿ç¨ãå¯è§£éçäººå·¥æºæ§è©¦åééæä¾å°æ±ºç­éç¨çæ´å¯ä¾å½è£éä¸å·®è·ï¼ä½å¶ä¸åæ¹æ³çå¯¦éæç¨å°ä¸æ¸æ¥ãæ¬ææåºäºä¸ååºæ¼ä½¿ç¨èç ç©¶çè©ä¼°ï¼å¶ä¸­åå«äº Grad-CAM è§£éæ¹æ³ï¼ä¸¦å°å¶æç¨æ¼ç¥ç¶ç¶²è·¯ä»¥åé¡æéåºåæ°çåå¼å¸æ¸æä¸­çå¼å¸ãæåå±ç¤ºäºä¸åå©çç¸éèå°å¯è§£éæ§æ¹æ³çæç¥æç¨ï¼æ­ç¤ºäºå¯¦ç¾å¯¦ééæåº¦çé£åº¦ï¼ä»¥åè¨±å¤åèèå¸æç²å¾æ´æ·±å¥çè§£éã

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) èé«çè¨ºæ·æ´å
çºè¨åºæ±ºç­æä¾äºä¸åæåæ¯çéå¾ãæ¬ç ç©¶æ¦è¿°äºä¸ç¨®æ°ç©æ¹æ³çéç¼ï¼ç¨æ¼é¶æ¬¡å­¸ç¿/å°éå­¸ç¿æå¢å­¸ç¿ (ICL)ï¼æ¹æ³æ¯ä½¿ç¨å¤å±¤çµæ§åæç¤ºæ´åé«çé åç¥è­ãæåéæ¢è¨äºä½¿ç¨èè LLM ä¹éå©ç¨®æºéæ¹å¼çåæï¼æ¸å¼å°è©± (NC) æ¹å¼ï¼å®æéæ­¥èçè³æï¼ä»¥åèªç¶èªè¨å®åå (NL-ST) æ¹å¼ï¼å®æä½¿ç¨é·ç¯æäºæç¤ºã
æåçç ç©¶ç³»çµ±æ§å°è©ä¼°äºè¨ºæ·æºç¢ºæ§åé¢¨éªå å­ï¼åæ¬æ§å¥åè¦ååé°æ§çï¼ä½¿ç¨äºä¸ååå« 920 åæ£èè¨éçè³æéï¼æ¡ç¨åç¨®å°éå­¸ç¿æå¢ãçµæè¡¨æï¼å³çµ±çè¨åºæ©å¨å­¸ç¿ (ML) æ¨¡åéå¸¸å¨é¶æ¬¡å­¸ç¿åå°éå­¸ç¿è¨­å®ä¸­è¡¨ç¾åªæ¼ LLMãç¶èï¼ç¶ä½¿ç¨å°éå­¸ç¿ç¯ä¾ä»¥åææçå¯è§£é AI (XAI) æ¹æ³ä½çºé åç¥è­ä¾æºæï¼æè½å·®è·æé¡¯èç¸®å°ãæ­¤å¤ï¼é¨èæéåè¶³åç¯ä¾æ¸éå¢å ï¼å°è©±æ¹å¼ (NC) å¹¾ä¹å¯ä»¥åª²ç¾ ML æ¨¡åçæè½ãæå¼å¾æ³¨æçæ¯ï¼LLM ç¸å°æ¼ ML æ¨¡åå±ç¾åºç¸ç¶ææ´ä½³çææ¬æææºç¢ºåº¦ã
æ¬ç ç©¶è­å¯¦ï¼ééé©ç¶çé åç¥è­åéèº«æé çæºéç­ç¥ï¼LLM å¯ä»¥é¡¯èå¢å¼·è¨ºæ·ç¨åºãéäºç¼ç¾çªé¡¯äºæä½³åè¨ç·´ç¯ä¾æ¸éåæºéæ¹å¼çéè¦æ§ï¼ä»¥æé«æºç¢ºåº¦ä¸¦æ¸å° LLM æç¨ä¸­çåå·®ã

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel MirÃ³-Nicolau, Gabriel MoyÃ -Alcover, Antoni Jaume-i-CapÃ³, Manuel GonzÃ¡lez-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

æè¦ï¼é¨èå°æ·±åº¦å­¸ç¿æ¨¡åä¾è³´æ§çå¢å ï¼å ä¸å¶åºæçéæåº¦ä¸è¶³ï¼ä¿ä½¿ä¸åæ°çç ç©¶é åç¼å±ï¼ç¨±çºå¯è§£é AI (XAI) æ¹æ³ãéäºæ¹æ³æ¨å¨ééæ·±å¥äºè§£æ±ºç­èå¾çåçï¼ä¾æåæçµä½¿ç¨èå°èªååç³»çµ±çä¿¡è³´ãæ¬ææåºäºä¸ç¨®è¡¡éä½¿ç¨èå° XAI ç³»çµ±ä¿¡è³´åº¦çæ°ç©æ¹æ³ï¼åè¨±å°å¶é²è¡æ¹é²ãæåæåºçææ¨çµåäºå®¢è§è§é»ä¸çæè½ææ¨åä¿¡è³´ææ¨ãçºäºé©è­éåæ°ç©çæ¹æ³ï¼æåå¨ä¸åçå¯¦çé«çå ´æ¯ä¸­é²è¡äºä¸åæ¡ä¾ç ç©¶ï¼ä½¿ç¨ XAI ç³»çµ±å¾ X åå½±åä¸­åµæ¸¬èºçã

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

æè¦ï¼COVID-19 ç«æå°å¨çå¬å±è¡çé æå£åï¼å¿é é²è¡æºç¢ºçè¨ºæ·åå¹²é ï¼ä»¥æ§å¶ç¾çå³æ­ä¸¦éä½æ­»äº¡çãæ¬æä»ç´¹äºä¸åå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åï¼å°éè¨­è¨ç¨æ¼ééè¸é¨ X å (CXR) å½±åæ¹åå° COVID-19 é å¾ççè§£åä¿¡è³´ãééæ´åå¤§è¦æ¨¡é è¨ç·´å½±åç·¨ç¢¼å¨ãé¢¨éªç¹å® Grad-CAM åè§£ååååµæ¸¬æè¡ï¼æåçåæ³ç¢çååå¯è§£éççµæï¼ææææå¿è¦çç¾çç¹å¾µï¼åæå°æ³¨æ¼ç½è¦ä½ééµçç°å¸¸ååãæåçæ¨¡åé æ¸¬çµæééé¢¨éªååå®ä½æä¾å¢å¼·çæ¸æ°åº¦åéæåº¦ï¼è®è¨åºé«çè½å¤ å¨æ´äºè§£é å¾è¦è§£çææ³ä¸ï¼å°± COVID-19 è¨ºæ·ååºææºçæ±ºç­ãæåå¨å¤ä¸­å¿çå­è³æéä¸è©ä¼°ææåºçæ¹æ³ï¼ä¸¦éééååè³ªåè©ä¼°è­æå¶æææ§ï¼éå°åªç°ç C ææ¸ï¼0.764 å 0.727ï¼åæéç¸é AUCï¼0.799 å 0.691ï¼ãéäºçµæè¡¨æï¼æåå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åå¨é¢¨éªé æ¸¬æ¹é¢è¶è¶å³çµ±ççå­åææ¹æ³ï¼æåè¨åºæ±ºç­çè§£éæ§ï¼ä¸¦å¢å¼· AI ç³»çµ±çä¿¡è³´åº¦ã

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

æè¦ï¼<paragraph>å¨éå»å¹¾å¹´ï¼è¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS) ä¸­çäººå·¥æºæ§ (AI) å¨å©ç¨æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¶æ§æ¹é¢ç¼æ®äºééµä½ç¨ãåç®¡ AI æ¨¡åå·æä»¤äººæ»¿æçè½åï¼ä½ç¼ºä¹éæåº¦åå¯è§£éæ§ï¼ç¹å¥æ¯å¨å¯é æ§çºå¿è¦èéçé«çèæ¯ä¸ï¼éå¸¶ä¾äºéå¤§çææ°ãå¨ä¸å½±é¿é æ¸¬ç²¾æºåº¦çææ³ä¸å¯¦ç¾éæåº¦ä»ç¶æ¯ä¸é ééµææ°ãæ¬ææåºäºä¸ç¨®æ°æ¹æ³ï¼å³ Rad4XCNNï¼ä»¥å¢å¼· CNN è¡çç¹å¾µçé æ¸¬è½åï¼åæå·åæ¾å°ç¹å¾µåºæçå¯è§£éæ§ãRad4XCNN ä¸åæ¼åºæ¼é¡¯èæ§åçå³çµ±æ¹æ³ï¼å®ééæ¾å°çµå­¸å°å¯çè§£çå«ç¾©è CNN è¡çç¹å¾µéè¯èµ·ä¾ï¼çºè¶è¶è¦è¦ºååè¡¨çè§£éæ¹æ³æä¾äºæ°çè§é»ãæåä»¥ä¹³çåé¡ä»»åä½çºæ¡ä¾ç ç©¶ï¼å¨è¶é³æ³¢å½±åè³æéä¸è©ä¼° Rad4XCNNï¼åæ¬ä¸åç·ä¸è³æéåå©åç¨æ¼å§é¨åå¤é¨é©è­çå§é¨è³æéãä¸äºééµçµæå¦ä¸ï¼i) è ViT è¡çç¹å¾µåæ¾å°ç¹å¾µç¸æ¯ï¼CNN è¡çç¹å¾µä¿è­äºæ´ç©©å¥çæºç¢ºåº¦ï¼ii) å³çµ±çè¦è¦ºååè§£éæ¹æ³å­å¨ä¸äºç¼ºé·ï¼iii) Rad4XCNN æ²æç§ç²æ¨¡åæºç¢ºåº¦ä¾æåå¶å¯è§£éæ§ï¼iv) Rad4XCNN æä¾äºå¨å±è§£éè¦è§£ï¼ä½¿é«å¸«è½å¤ åææ¨¡åè¼¸åºåç¼ç¾ãæ­¤å¤ï¼æåå¼·èª¿å°å¯è§£éæ§æ´åå° AI æ¨¡åä¸­å°æ¼å¢å¼·è¨åºå¯¦åä¸­çä¿¡ä»»åæ¡ç¨è³ééè¦ï¼ä¸¦å¼·èª¿äºæåçæ¹æ³å¦ä½è½ç·©è§£èå¯è§£é AI æ¹æ³ç¸éçä¸äºçæ®ã</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) çæ®åæ´åï¼å¨æ¶å AI é©åç³»çµ±çäºæä¸­ï¼è²¬ä»»åç¾©åæ­¸å±¬ç¢çäºè¤éçææ°ãéäºç³»çµ±çäºé£æ§ãAI å¼ç¼äºæçå«çåé¡ï¼å ä¸ AI æè¡çä¸ç¢ºå®æ§åç¼ºä¹ç¸ææ³è¦ï¼ä½¿å¾å³çµ±è²¬ä»»æ­¸å±¬é¢è¨ææ°ãçºæ­¤ï¼æ¬ç ç©¶æåºäºä¸ç¨®è¨ç®åæåè¡¡ (CRE) æ¹æ³ï¼ä»¥å»ºç«ä¸åé£è²«ä¸å¨å«çä¸å¯æ¥åçè²¬ä»»æ­¸å±¬æ¶æ§ï¼é©ç¨æ¼ææå©å®³éä¿äººãè¨ç®æ¹æ³æä¾äºçµæ§åçåæï¼åæäºæ¦å¿µæ¹æ³å¨èçåæä¸å¤é¢åæå¢æçéå¶ï¼å±ç¤ºäºè©²æ¶æ§å¨è²¬ä»»æ­¸å±¬éç¨ä¸­å·åçå¯è§£éæ§ãé£è²«æ§åé©ææ§ãæåæ¢è¨äºèåè¡¡è¨ç®ä¸­ç´¢è³ ç¸éçåå§ååå±¤ç´çééµä½ç¨ãæåä»¥ AI è¼å©é«çæ±ºç­æ¯æ´ç³»çµ±çºæ¡ä¾ç ç©¶ï¼èªªæä¸åçåå§åå¦ä½å°è´ä¸åçè²¬ä»»åéãè©²æ¶æ§æä¾äºå° AI å¼ç¼äºæä¸­åè²¬å¶çå¯¶è²´è¦è§£ï¼ééæçºç£æ§ãä¿®è¨ååæï¼ä¿é²äºæ°¸çºä¸æéæ§çç³»çµ±ç¼å±ã

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

æè¦ï¼äººå·¥æºæ§ééé æ¸¬æ¨¡ååå©é«çå°æ¥­äººå¡ï¼å¤§å¹è½è®äºè¨åºæ±ºç­å¶å®ãæ¬ç ç©¶æ¢è¨äºå¨é«çä¿å¥ä¸­ä½¿ç¨äººå·¥æºæ§æç¨ç¨å¼æå¬å¹³æ§åå¯è§£éæ§çééµéæ±ï¼ä»¥ç¢ºä¿å¨ä¸åçæ£èäººå£çµ±è¨è³æä¸­ç²å¾å¬å¹³ççµæãééå°æ³¨æ¼æè¡çç¸éæ­»äº¡ççé æ¸¬æ¨¡åï¼æåæåºäºä¸ç¨®æ¹æ³ï¼è©²æ¹æ³æå­¸ç¿ä¸åæè½æä½³åçé æ¸¬æ¨¡åï¼ç¶å¾æ¡ç¨è½ç§»å­¸ç¿éç¨ä¾ç¢çä¸åå·ææ´å¥½å¬å¹³æ§çæ¨¡åãæåçæ¨¡åéå¼å¥äºä¸ç¨®æ°ç©çåºæ¼æåçç¹å¾µéè¦æ§æ¼ç®æ³ï¼æ¨å¨é¡ææ¯åç¹å¾µå¨å¢å¼·é æ¸¬å¬å¹³æ§æ¹é¢çè²¢ç»ãèç¾æçå¯è§£éæ§æ¹æ³å°æ³¨æ¼è§£éç¹å¾µå°é æ¸¬æè½çè²¢ç»ä¸åï¼æåæåºçæ¹æ³ç¨ç¹å°å½è£äºçè§£æ¯åç¹å¾µå¦ä½æå©æ¼å¬å¹³æ§çå·®è·ãéé é²å±è³ééè¦ï¼å çºæè¡ççæ­»äº¡çå¾é«ï¼ä¸å¨ä¸åä¹ä¸çé«é¢æ­»äº¡ä¸­æ®æ¼èè§è²ãæåçæ¨¡åä¸åæå©æ¼è­å¥åæ¸è¼é æ¸¬æ¨¡åä¸­çåå·®ï¼éè½ééæé«æ¨¡åé æ¸¬çéæåº¦åå¬å¹³æ§ä¾å¹é¤é«çä¿å¥å©çç¸éèä¹éçä¿¡ä»»ï¼é²èæå©æ¼æä¾æ´å¬å¹³ä¸å¼å¾ä¿¡è³´çé«çä¿å¥æåã

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

æè¦ï¼ç¾ä»ï¼æé¬±çæ¯ä¸åéè¦çè­°é¡ãæ ¹æä¸çè¡ççµç¹ (WHO) çè³æï¼å¨ 2023 å¹´ï¼è¶é 2.8 åäººæ­£å¨èæé¬±çæé¬¥ãéæ¯ä¸åé¾å¤§çæ¸å­ï¼å¦æä¸èªççå¾ï¼éäºæ¸å­å°æå¿«éå¢å ãå¤§ç´æ 48.9 åäººæ¯ç¤¾ç¾¤åªé«ä½¿ç¨èãäººåå¨ TwitterãFacebookãRedditãInstagram ç­å¹³å°ä¸è¡¨éèªå·±çæååæç·ãéäºå¹³å°åå«æå¹å¼çè³è¨ï¼å¯ç¨æ¼ç ç©¶ç®çãå·²ç¶å¨åç¨®ç¤¾ç¾¤åªé«å¹³å°ä¸é²è¡äºå¤§éçç ç©¶ãç¶èï¼éäºåªåä»å­å¨æäºéå¶ãç¹å¥æ¯ï¼ååçç ç©¶åå°æ³¨æ¼åµæ¸¬æ¨æä¸­çæé¬±çåæé¬±ççå¼·åº¦ãæ­¤å¤ï¼è³æéæ¨ç±¤ä¸­å­å¨ä¸æºç¢ºçææ³ãå¨éé ç ç©¶å·¥ä½ä¸­ï¼ä½¿ç¨åºæ¼è©å½æ¨ç±¤ç Twitter è³æåº«ä¸­çæ¨æé æ¸¬äºäºç¨®é¡åçæé¬±çï¼éæ¥µåãéåº¦ãç²¾ç¥çåãéå¸ååç¢å¾ï¼ãå¯è§£éç AI ç¨æ¼ééå¼·èª¿ä»£è¡¨æé¬±çé¡åçæ¨æé¨åä¾æä¾æ¨çãå¾ Transformersï¼BERTï¼ä¸­æåçéåç·¨ç¢¼å¨è¡¨ç¤ºç¨æ¼ç¹å¾µæååè¨ç·´ãæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¹æ³ç¨æ¼è¨ç·´æ¨¡åãBERT æ¨¡ååç¾åºææå¸æççµæï¼éå° 0.96 çæ´é«æºç¢ºåº¦ã

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v1 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

æè¦ï¼æ·±åº¦å­¸ç¿æ­£åçå°è½è®é«å­¸å½±ååæ¾å°å­¸é åï¼è½è­å¥é«å­¸å½±åä¸­çççï¼åæ¬é»è¦æ·å±¤ææ (CT) å X åææãç¶èï¼æ·±åº¦å­¸ç¿æ¨¡åçæè½ï¼ç¹å¥æ¯å¨åå²ä»»åä¸­ï¼å¸¸å¸¸åå°å»£æ³è¨»è§£è³æééæ±çéå¶ãçºäºæå°æ­¤ææ°ï¼ééå¯è§£é AI ååäºå¯¦è§£éçç¢çï¼æ¢è¨äºå¼±ç£ç£èªæåå²çè½åãæ¬ç ç©¶çç¯åæ¯éç¼ä¸ç¨®æ°ç©çåäºå¯¦å§ç¹ªæ¹æ³ (COIN)ï¼å®ééä½¿ç¨çææ¨¡åï¼å°é æ¸¬åé¡æ¨ç±¤å¾ç°å¸¸ç¿»è½çºæ­£å¸¸ãä¾å¦ï¼å¦æåé¡å¨å°è¼¸å¥é«å­¸å½±å X è¦çºç°å¸¸ï¼è¡¨ç¤ºå­å¨ççï¼çææ¨¡åæ¨å¨å§ç¹ªç°å¸¸ååï¼å¾èéè½åé¡å¨çåå§é æ¸¬æ¨ç±¤ãæ­¤æ¹æ³ä½¿æåè½å¤ ç¢ççççç²¾ç¢ºåå²ï¼èä¸ä¾è³´æ¼é åå­å¨çåå²é®ç½©ãè³ééè¦çæ¯ï¼å©ç¨å½±åå±¤ç´æ¨ç±¤ï¼éæ¯å»ºç«è©³ç´°çåå²é®ç½©å®¹æåå¾å¾å¤ãè©²æ¹æ³çæææ§ééåå²åæç®æ¨åå¾ææ²å°¼äºå¡ç¾åå¤§å­¸é«é¢åå¾ç CT å½±åä¸­çå¯¦éèèè«ç¤ä¾è­æãç ç©¶çµæè¡¨æï¼COIN é é è¶è¶äºæ¢å®çæ­¸å æ¹æ³ï¼ä¾å¦ RISEãScoreCAM å LayerCAMï¼ä»¥å Singla ç­äººæåºçå¦ä¸ç¨®åäºå¯¦è§£éæ¹æ³ãæ­¤è­æè¡¨æï¼COIN æ¯ä¸ç¨®å¾æåæ¯ç CT å½±åä¸­è«ç¤èªæåå²æ¹æ³ï¼ä¸¦å¨ä½¿æ·±åº¦å­¸ç¿æç¨å¨è¨»è§£è³æç¨ç¼ºçé«çä¿å¥ä¸­æ´ææ¼åå¾åæ´æææ¹é¢éé²äºä¸æ­¥ã

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

æè¦ï¼å¨æ¬æä¸­ï¼æåæ¢è¨æ¸ä½äººæå­¸ç§ (DH) ä½çºä¸éå­¸ç§èæ··åæºè½ (HI) ä½çºä¸åç ç©¶å¸ç¯ä¹éçååä½ç¨ãå¨ DH ç ç©¶ä¸­ï¼æ¸ä½æ¹æ³çä½¿ç¨ï¼ç¹å¥æ¯äººå·¥æºæ§çä½¿ç¨ï¼åå°ä¸ç³»åè¦æ±åéå¶ãæåèªçºéäºè¦æ±åéå¶ç²å¾ HI çè½ååç®æ¨çååæ¯æãæåçè²¢ç»åæ¬æ¾åºäºåéæ¨£ç DH è¦æ±ï¼æåç AI ç³»çµ±éè¦è½å¤  1) èï¼äººé¡ï¼å­¸èåä½ï¼2) æ¯æ´è³ææ¹è©ï¼3) æ¯æ´å·¥å·æ¹è©ï¼4) å¯è¦ºä¸¦è¿ååç¨®è§é»ï¼5) æ¯æ´é è·åè¿è·é¢é±è®ãæåå°æ··åæºè½ç CARE ååï¼åä½ãé©æãè² è²¬åå¯è§£éï¼ä½çºçè«æ¶æ§ï¼ä¸¦å°éäºååå°æå° DH è¦æ±ãå¨æ­¤å°æä¸­ï¼æåç´å¥ç¯ä¾ç ç©¶å°æ¡ãæå¾ï¼æåæ¢è¨å¦ä½å° DH çè¦è§£æç¨æ¼ HIï¼ä¸¦è¨è«çµåéå©åå­¸ç§çéæ¾ææ°ã

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

æè¦ï¼åºç¤æ¨¡å (FM) å·æå¾¹åºæ¹è®é«å­¸å½±åçå·¨å¤§æ½åãç¶èï¼å®åå¨ç¾å¯¦ä¸çè¨åºç°å¢ä¸­çé¨ç½²éè¦å»£æ³çå«çèéãæ¬ææ¨å¨å¼·èª¿è FM ç¸éçå«çåé¡ï¼ä¸¦æåºä¸åæ¡æ¶ä¾æå°å®åå¨é«å­¸ä¸­çè² è²¬ä»»éç¼åå¯¦æ½ãæåä»ç´°å¯©æ¥äºå«çåé¡ï¼ä¾å¦æ£èæ¸æé±ç§ãåå·®ç·©è§£ãæ¼ç®æ³éæåº¦ãå¯è§£éæ§ååè²¬å¶ãææåºçæ¡æ¶æ¨å¨åªåèæ®æ£èç¦å©ãæ¸è¼æ½å¨é¢¨éªï¼ä¸¦å¹é¤å° AI è¼å©é«çä¿å¥çä¿¡ä»»ã

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

æè¦ï¼ç²çèºçæ¯ä¸ç¨®æ¥çå´éçå¨çå¥åº·åé¡ï¼éè¦åé²çè¨ºæ·æ¹æ³ãæ¬ç¯è©è«æ¢è¨äºäººå·¥æºè½èæ¾å°ç¹å¾µåæå¨ç²çèºçè¨ºæ·ä¸­çæç¨ãå¨ç¬¦å PRISMA æåçææ³ä¸ï¼å°å¤åè³æåº«é²è¡äºåé¡§ï¼ç´å° 2023 å¹´ 10 æãééçµåééµå­ï¼ç¼ç¾äºä¸ç¯éæ¼ç²çèºçåç¸éä¸»é¡çè±æå­¸è¡åºçç©ãå¨ç§»é¤ 109 ç¯éè¤æç»å¾ï¼åå§æå°å±åå³ 267 ç¯è«æãå¨æ ¹æé åç¢ºå®çæ¨æºï¼æ·æ±°äº 124 ç¯æç« çæè¦åæ¨é¡å¾ï¼é¸åºäºç¸éç ç©¶ãå¨é²è¡å¨é¢åæå¾ï¼é¡å¤æé¤äºå­é ç ç©¶ãå¨ç´å¥ç 28 é ç ç©¶ä¸­ï¼çµåè¶é³æ³¢ (US) å½±åçæ¾å°ç¹å¾µåæï¼è­æäºå¶å¨è¨ºæ·ç²çèºçæ¹é¢çæææ§ãç ç©¶çµæä¸ä¸ï¼æäºç ç©¶æåºäºåªæ¼ç¾ççæ°ç­ç¥ãæç»å¼·èª¿äºäººå·¥æºè½æ¨¡åé¢è¨çåç¨®ææ°ï¼åæ¬å¯è§£éæ§åé¡ãè³æééå¶åæä½å¡ä¾è³´æ§ã28 é ç´å¥ç ç©¶çç¶åç¼ç¾æå°ï¼éè¦æ¨æºåå·¥ä½ååç»æ§å¤ä¸­å¿ç ç©¶ä¾è§£æ±ºéäºåé¡ãæ­¤å¤ï¼éç¢ºå®äºåæéäºéç¤çæ¹æ³ï¼ä¾å¦å¯è§£éäººå·¥æºè½æè¡ååäººåé«çæè¡çé²æ­¥ãæ¬ç¯è©è«éé»æ¢è¨äºäººå·¥æºè½åæ¾å°ç¹å¾µåæå¦ä½è½è®ç²çèºççè¨ºæ·åæ²»çãåç®¡å­å¨ææ°ï¼ä½æªä¾å°å¤å­¸ç§åä½ãè¨åºé©ç¨æ§é©è­åæ¼ç®æ³æ¹é²çç ç©¶ï¼ä»ææ½åæ¹åç²çèºçæ²»çä¸­çæ£èé å¾åè¨ºæ·ç²¾æºåº¦ã

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼ä¹³çççè¡çè¿éå¢å ï¼ä½¿å¶æçºå¨çä¸»è¦çæ­»äº¡åå ä¹ä¸ãå¨ææççä¸­ï¼ä¹³çè¿ä»çºæ­¢æ¯æå¸¸è¦çãæåè¨ºæ·æ­¤ç¾çéè¦å¤§éçæéåå°æ¥­ç¥è­ãç±æ¼ä¹³ççæª¢æ¸¬éç¨èæï¼å æ­¤ééå»ºç«æ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬ï¼æå©æ¼é²æ­¢å¶é²ä¸æ­¥æ´æ£ãæ©å¨å­¸ç¿åå¯è§£é AI å¨åé¡ä¸­è³ééè¦ï¼å çºå®åä¸åå¯ä»¥æä¾æºç¢ºçé æ¸¬ï¼éå¯ä»¥æ·±å¥äºè§£æ¨¡åå¦ä½ååºæ±ºç­ï¼æå©æ¼çè§£åä¿¡è³´åé¡çµæãå¨æ­¤ç ç©¶ä¸­ï¼æåè©ä¼°ä¸¦æ¯è¼äºäºç¨®ä¸åçæ©å¨å­¸ç¿æ¹æ³çåé¡æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä½¿ç¨äºä¸åä¸»è¦çè³æéï¼éå¡é«å­¸é¢é«é¢ç 500 åæ£èï¼ãäºç¨®ä¸åçç£ç£å¼æ©å¨å­¸ç¿æè¡ï¼åæ¬æ±ºç­æ¨¹ãé¨æ©æ£®æãéè¼¯è¿´æ­¸ãæ´ç´ è²æ°å XGBoostï¼å·²ç¨æ¼å¨æåçè³æéä¸åå¾æä½³çµæãæ­¤å¤ï¼æ¬ç ç©¶å° SHAP åææç¨æ¼ XGBoost æ¨¡åï¼ä»¥è§£éæ¨¡åçé æ¸¬ä¸¦äºè§£æ¯åç¹å¾µå°æ¨¡åè¼¸åºçå½±é¿ãæåæ¯è¼äºå¹¾ç¨®æ¼ç®æ³å°è³æé²è¡åé¡çæºç¢ºåº¦ï¼ä¸¦èè©²é åçå¶ä»æç»é²è¡å°æ¯ãå¨æå¾è©ä¼°å¾ï¼æ¬ç ç©¶ç¼ç¾ XGBoost éå°äºæä½³çæ¨¡åæºç¢ºåº¦ï¼çº 97%ã</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

æè¦ï¼æ·±åº¦å­¸ç¿ (DL) ç¨æ¼å¾ä¹³æ¿æå½±è¡å½±åè¨ºæ·ä¹³ççæ¨¡åéå¸¸ä»¥ãé»çå­ãæ¹å¼éä½ï¼éä½¿å¾é«çä¿å¥å°æ¥­äººå¡é£ä»¥ä¿¡ä»»åçè§£å¶æ±ºç­éç¨ãæ¬ç ç©¶æåºä¸åæ´åæ¶æ§ï¼çµåå·ç©ç¥ç¶ç¶²è·¯ (CNN) åå¯è§£éäººå·¥æºæ§ (XAI)ï¼ä»¥ä½¿ç¨ CBIS-DDSM è³æéå¢å¼·ä¹³ççè¨ºæ·ãæ¹æ³åå«ä¸åç²¾ç´°çè³æåèçç®¡ç·åé²éè³ææ´åæè¡ï¼ä»¥å°æè³æééå¶ï¼ä¸¦æ¡ç¨é åè¨ç·´çç¶²è·¯ï¼ä¾å¦ VGG-16ãInception-V3 å ResNetï¼é²è¡é·ç§»å­¸ç¿ãæåç ç©¶çéé»æ¯è©ä¼° XAI å¨è§£éæ¨¡åé æ¸¬ä¸­çæææ§ï¼éé»å©ç¨è±ªæ¯å¤å¤«æ¸¬åº¦éåè©ä¼° AI çæçè§£éåå°å®¶è¨»è§£ä¹éçä¸è´æ§ãéç¨®æ¹æ³å°æ¼ XAI å¨ä¿é² AI è¼å©è¨ºæ·ä¸­çå¯ä¿¡åº¦åå«çå¬å¹³æ§è³ééè¦ãæåç ç©¶çç¼ç¾èªªæäº CNN å XAI å¨æ¨é²ä¹³çè¨ºæ·æ¹æ³ä¸­çææåä½ï¼å¾èä¿é²äºåé² AI æè¡å¨è¨åºç°å¢ä¸­çæ´é æ¢æ´åãééå¢å¼· AI é©åæ±ºç­çå¯è§£éæ§ï¼éé å·¥ä½çº AI ç³»çµ±åé«çå¾æ¥­äººå¡ä¹éçæ¹ååä½å¥ å®äºåºç¤ï¼æçµè±å¯äºæ£èç§è­·ãæ­¤å¤ï¼æåç ç©¶çå½±é¿é é è¶åºäºç®åçæè¡ãå®é¼åµé²ä¸æ­¥ç ç©¶å¦ä½çµåå¤æ¨¡å¼è³æä¸¦æ¹å AI è§£éï¼ä»¥æ»¿è¶³è¨åºå¯¦åçéæ±ã

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

æè¦ï¼ä»¥äººä¸ºæ¬çå¯è§£é AI (HCXAI) å¡å¯¼å°ç¤¾ä¼å±é¢æ´åå° AI è§£éä¸­ãHCXAI è¯è¯­çæ ¸å¿æ¯ç¤¾ä¼éæåº¦ (ST) æ¡æ¶ï¼å¶ç®æ æ¯è®© AI ç³»ç»çç¤¾ä¼ç»ç»èæ¯å¯¹ç¨æ·æ¥è¯´æ¯å¯çè§£çãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å»ºè®®æ©å± ST æ¡æ¶ä»¥è§£å³å¤§åè¯­è¨æ¨¡å (LLM) ä¸­ç¤¾ä¼éè¯¯å½å çé£é©ï¼å°¤å¶æ¯å¨å¿çå¥åº·ç­ææé¢åãäºå®ä¸ï¼LLM è½å¤åºè²å°æ¨¡æè§è²åäººæ ¼ï¼è¿å¯è½å¯¼è´è®¾è®¡èçæå¾åç¨æ·å¯¹ç¤¾ä¼å±æ§çè®¤ç¥ä¹é´åºç°ééï¼ä»èæé£é©ä¿è¿æç»ªæçºµåå±é©è¡ä¸ºãè®¤ç¥ä¸å¬æ­£åä¸åççä¿¡ä»»ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬å»ºè®®ç¨ç¬¬äºä¸ªâW é®é¢âæ¥å¢å¼º ST æ¡æ¶ï¼ä»¥æç¡®è®¾è®¡èåç¨æ·èµäº LLM çå·ä½ç¤¾ä¼å±æ§ãæ­¤è¡¥åæ¨å¨å¼¥å LLM è½ååç¨æ·è®¤ç¥ä¹é´çå·®è·ï¼ä¿è¿åºäº LLM çææ¯å¨éå¾·ä¸è´è´£ä»»å°å¼ååä½¿ç¨ã

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

æè¦ï¼<paragraph>èæ¯ï¼æ°£è¸æ¯ä¸ç¨®å èºé¨èè¸å£ä¹éç°å¸¸éæ°£æå¼èµ·çæ¥æ§è¸èç¾çãçºäºè§£æ±ºæ·±åº¦å­¸ç¿ï¼DLï¼æ¨¡åç¶å¸¸ä¼´é¨çä¸éææ§ï¼å¯è§£éäººå·¥æºæ§ï¼XAIï¼æ¹æ³å·²è¢«å¼å¥ï¼ç¨æ¼æ¦è¿°è DL æ¨¡åååºçæ°£è¸è¨ºæ·ç¸éçååãç¶èï¼éäºè§£éæææèå¯¦éçç¶ååææåºå¥ï¼çªé¡¯åºé²ä¸æ­¥æ¹é²çå¿è¦æ§ãæ¹æ³ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼å°æ°£è¸çè¨åºç¥è­ç´å¥ XAI æ¹æ³ç¢ççæ¨¡åè§£éä¸­ï¼å¾èæåéäºè§£éçåè³ªãå©ç¨æ¾å°ç§é«å¸«å»ºç«ççç¶æç¹ªï¼æåçåæ³é¦åç¢çä¸åæ¨¡æ¿ï¼ç¨æ¼è¡¨ç¤ºæ°£è¸å¯è½ç¼ççååãç¶å¾å°æ­¤æ¨¡æ¿çå å¨æ¨¡åè§£éä¸ï¼ä»¥ç¯©é¸åºè¶åºæ¨¡æ¿éççç¡éè§£éãçºäºé©è­å¶æåï¼æåå°ä¸ç¨® XAI æ¹æ³é²è¡äºæ¯è¼åæï¼å¨å©åçå¯¦ä¸çè³æéä¸­è§£éå©å DL æ¨¡åæï¼åå¥æ¡ç¨åä¸æ¡ç¨æåçæ¨¡æ¿å¼å°ãçµæï¼ææåºçæ¹æ³å¨å»ºç«æ¼ä¸ç¨® XAI æ¹æ³ãå©å DL æ¨¡ååå©åè³æéçåäºç¨®åºæºæå¢ä¸­ï¼å§çµæ¹åäºåºæº XAI æ¹æ³ãå¨æ¯è¼æ¨¡åè§£éåçå¯¦çç¶ååæï¼ééåºæºæè½çæè½æ¹é²è¨ç®åºçå¹³åå¢éç¾åæ¯çºäº¤éæ¯ï¼IoUï¼ç 97.8% åéª°å­ç¸ä¼¼æ§ä¿æ¸ï¼DSCï¼ç 94.1%ãçµè«ï¼å¨æ°£è¸è¨ºæ·çèæ¯ä¸ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼ç¨æ¼æ¹å AI è§£éãæåé ææåçæ¨¡æ¿å¼å°å°ééæ´åè¨åºé åå°æ¥­ç¥è­ï¼çºé¡æ AI æ¨¡åå»ºç«ä¸ç¨®æ°æ¹æ³ã</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by SÃ©amus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

æè¦ï¼<paragraph>å¨ç¶åæ©å¨ç¿»è­¯ (MT) é åä¸­ï¼Transformer æ¶æ§è«ç©èåºï¼æçºé»éæ¨æºï¼ç¹å¥æ¯å°æ¼é«è³æºèªè¨å°ãæ¬ç ç©¶æ¢è¨å¶å°ä½è³æºèªè¨å°çæè½ï¼åæ¬è±èªâæç¾è­èªåè±èªâé¦¬æå°èªèªè¨å°ãå¼å¾æ³¨æçæ¯ï¼æ¬ç ç©¶è­å¥åºæä½³è¶åæ¸åå­è©æ¨¡åé¡åï¼ä»¥é¡¯èæé« Transformer æ¨¡åå°ä½è³æºèªè¨å°çç¿»è­¯åè³ªã
ä½è³æºèªè¨çå¹³è¡è³æéçç¨ç¼ºæé»ç¤ MT çç¼å±ãçºäºè§£æ±ºéååé¡ï¼éç¼äº gaHealthï¼éæ¯æç¾è­èªçç¬¬ä¸åéèªå¥åº·è³æèªæåº«ãå°æ³¨æ¼å¥åº·é åï¼ä½¿ç¨æ­¤åå§è³æééç¼çæ¨¡åå¨ BLEU å¾åæ¹é¢è¡¨ç¾åºéå¸¸é¡¯èçé²æ­¥ï¼è LoResMT2021 å±äº«ä»»åä¸­çæ¨¡åç¸æ¯ãé¨å¾ä½¿ç¨å¤ç¶­åè³ªææ¨é¯èª¤åé¡æ³é²è¡çäººå·¥è©ä¼°é¡¯ç¤ºï¼èåºæ¼ RNN çå°ææ¨¡åç¸æ¯ï¼Transformer ç³»çµ±å¨æ¸å°æºç¢ºæ§åæµæ¢æ§é¯èª¤æ¹é¢è¡¨ç¾åºåªç°çæ§è½ã
æ­¤å¤ï¼æ¬è«æä»ç´¹äº adaptNMT å adaptMLLMï¼éå©åéæºæç¨ç¨å¼ç°¡åäºç¥ç¶æ©å¨ç¿»è­¯æ¨¡åçéç¼ãå¾®èª¿åé¨ç½²ãéäºå·¥å·å¤§å¹ç°¡åäºè¨­å®åè©ä¼°æµç¨ï¼è® MT æ´å®¹æè®éç¼äººå¡åç¿»è­¯äººå¡ä½¿ç¨ãå¼å¾æ³¨æçæ¯ï¼adaptNMT ä»¥ OpenNMT çæç³»çµ±çºåºç¤ï¼ééå¼·èª¿æ¨¡åéç¼çç°å¢è¶³è·¡ä¾ä¿é²çæåå¥½çèªç¶èªè¨èçç ç©¶ãè LoResMT2021 å±äº«ä»»åä¸­çåºæºç¸æ¯ï¼adaptMLLM å° MLLM çå¾®èª¿è­æäºè±èªâæç¾è­èªåè±èªâé¦¬æå°èªéå©åä½è³æºèªè¨å°çç¿»è­¯æ§è½é²æ­¥ã</paragraph>

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

æè¦ï¼ç³å°¿çï¼DMï¼ä½¿æ£èå®¹æåºç¾è¡ç®¡ä½µç¼çã
è¦ç¶²èå½±ååè¡ç®¡åæ èº«é«çå¾®è¡ç®¡åå·¨è¡ç®¡å¥åº·çæ³ãå®åå¯ç¨æ¼è¨ºæ·ç³å°¿çä½µç¼çï¼åæ¬ç³å°¿çè¦ç¶²èçè®ï¼DRï¼ãç¥ç¶çè®ãèçååèç²¥æ¨£ç¡¬åæ§å¿è¡ç®¡ç¾çï¼ä»¥åé æ¸¬å¿è¡ç®¡äºä»¶çé¢¨éªãçºä½¿ç¨æ¸ä½åè¦ç¶²èå½±åé²è¡é«éé DR æª¢æ¸¬èéç¼çäººå·¥æºæ§ï¼AIï¼åç¨ç³»çµ±å·²å¨è¨åºæ¡ç¨ãé¤äº DR ç¯©æª¢å¤ï¼AI æ´åä¹å·æå·¨å¤§çæ½åä¾æå°èç³å°¿çæ£èæ´é«ç§è­·ç¸éçææ°ãå¨éé å·¥ä½ä¸­ï¼æåæ¨å¨å¨é¢åé¡§åºæ¼è¦ç¶²èå½±åç AI æç¨ç¸éç ç©¶çæç»ï¼éäºç ç©¶èç³å°¿ççè¨ºæ·ãé å¾åç®¡çæéãæåå°æè¿°æ´é« AI è¼å©ç³å°¿çç§è­·çç¼ç¾ï¼åæ¬ä½ä¸éæ¼ DR ç¯©æª¢ï¼ä¸¦è¨è«å¯¦æ½æ­¤é¡ç³»çµ±çéç¤ï¼åæ¬èå«çãè³æé±ç§ãå¬å¹³å­ååå¯è§£éæ§æéçåé¡ãééè©ä¼°æ£èçå¥åº·çæ³ï¼åæèéç³å°¿çä½µç¼çä»¥åæªä¾å¿è¡ç®¡ä½µç¼ççé¢¨éªé å¾ï¼AI è¼å©è¦ç¶²èå½±ååæææ½åæçºç³å°¿çæ£èç¾ä»£ååäººåé«ççä¸­å¿å·¥å·ã

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

æè¦ï¼éé ç ç©¶å¾å¤åå©å®³éä¿äººçè§åº¦æ¢è¨ä¸åçäººå·¥æºæ§ (AI) æç¨å¨æè²ä¸çå¯æ¥åæ§ï¼åæ¬å­¸çãèå¸«åå®¶é·ãæ¿èª AI å¨æè²ä¸çè½åæ½åï¼å®è§£æ±ºäºèè³æé±ç§ãAI ä»£çãéæåº¦ãå¯è§£éæ§å AI çéå¾·é¨ç½²ç¸éççæ®ãééå°ææ²æ¹æ³ï¼åèèè¢«åç¾äºåç¨®æå¢ï¼å¶ä¸­ AI çä»£çãéæåº¦ãå¯è§£éæ§åé±ç§åå°æç¸±ãå¨æ¯åæå¢å¾ï¼åèèå®æäºä¸é èª¿æ¥ï¼è©²èª¿æ¥ææäºä»åå° AI çæ´é«æç¨ãåäººæç¨ãæ­£ç¾©ãä¿¡å¿ãé¢¨éªåå¦æå¯ç¨ï¼ä½¿ç¨æ¯åæå¢ç AI çæåççæ³ãè³æèéåå«ä¾èªåä½æ©æ§åç¤¾ç¾¤åªé«æ´»åç 1198 ä½å¤å©å®³éä¿äººåèèçæçµæ¨£æ¬ï¼ä¸¦å°æ³¨æ¼å°åå AI ä½¿ç¨æ¡ä¾çåå¥åæãå°è³æçèª¿è§£åæè¡¨æï¼å° AI çæ¥ååº¦åä¿¡ä»»å¨å©å®³éä¿äººåé«ä¹éæé¡¯èå·®ç°ãæåç¼ç¾ï¼AI çä»£çãéæåº¦åå¯è§£éæ§é«ä½ç¨åº¦ä¹éçééµèª¿è§£èï¼ä»¥åä½¿ç¨ä¸åæè² AI çæåï¼åæ¬æç¥å°çæ´é«æç¨ãæ­£ç¾©åä¿¡å¿ãéé ç ç©¶å¼·èª¿ï¼æ¥å AI å¨æè²ä¸çæç¨æ¯ä¸åå¾®å¦ä¸å¤é¢åçåé¡ï¼é¤äºä¸åçå©å®³éä¿äººççæ³å¤ï¼ééè¦ä»ç´°èæ®å·é«ç AI æç¨åå¶ç¹å¾µã

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

æè¦ï¼<paragraph>åºæ¼å¯ç©¿æ´å¼å®å°ç¨å¿é»å (ECG) è£ç½®çé ç«¯çæ£ç£æ¸¬å¨æ©æåµæ¸¬å¿èç¾çæ¹é¢å·æé¡¯èçæ½åï¼ç¹å¥æ¯èç¨æ¼èªååå¿èç¾çåµæ¸¬çäººå·¥æºæ§ (AI) æ¹æ³çµåä½¿ç¨æãååå·²æç ç©¶æç¨åºæ¼æ·±åº¦å­¸ç¿ç AI æ¹æ³é²è¡å¿èç¾çåµæ¸¬ãç¶èï¼éäºæ¨¡åå°æªè¢«å»£æ³æ¥åçºè¨åºè¨ºæ·çå¯é è¼å©å·¥å·ï¼é¨ååå å¨æ¼åç¹è¨±å¤ AI æ¼ç®æ³çç¶åé»ç®±æç¥ãç¹å¥æ¯ï¼æå¿è¦æ¾åºæå©æ¼ååºæºç¢ºè¨ºæ·ç ECG è¨èééµç¹å¾µï¼å¾èå¢å¼·æ¨¡åçå¯è§£éæ§ãå¨æ¬ç ç©¶ä¸­ï¼æåéç¼äºä¸ç¨®è¦è¦ºè½æå¨æ¹æ³ï¼ä»¥æ ¹æå®å°ç¨ ECG è³ææ¾åºå¿æ¿é¡«åãæ®å·®ç¶²è·¯ (ResNet) æ¹æ³ä¹å·²éç¼åºä¾ï¼ä»¥ä¾¿èè¦è¦ºè½æå¨æ¹æ³é²è¡æ¯è¼ãéäºæ¨¡åæç¨æ¼ Chapman-Shaoxing è³æéï¼ä»¥åé¡å¿æ¿é¡«åï¼ä»¥åå¦ä¸ç¨®å¸¸è¦çå¿å¾ä¸æ´ï¼ç«æ§å¿åéç·©ï¼åæ­£å¸¸ç«æ§å¿å¾çå¿è·³ãéäºæ¨¡åè½å¤ æ¾åºæ±ºå®æçµåé¡çå¿è·³ééµååï¼ä¸¦å¼·èª¿ P æ³¢å T æ³¢ï¼ä»¥åå¿è·³æçºæéåè¨èæ¯å¹å¨ååæ­£å¸¸ç«æ§å¿å¾èå¿æ¿é¡«ååç«æ§å¿åéç·©æ¹é¢çéè¦æ§ã</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

æè¦ï¼æ¬æä»ç´¹äºä¸ç¨®ä½¿ç¨åé²å¤§åèªè¨æ¨¡å (LLM) é²è¡æé¬±çåµæ¸¬åæ²»ççæ°æ¨¡å¼ï¼çæå¼é è¨ç·´Transformer 4 (GPT-4)ãLlama 2 èå¤©æ©å¨äººå Geminiãéäº LLM ç¶éå¾®èª¿ï¼å·åå°æ¥­æç¤ºï¼å¯è¨ºæ·ãè§£éä¸¦å»ºè­°æé¬±ççæ²»çä»å¥æ¹æ³ãä¸ç¨®ç¨ç¹çå°æ¬¡æç¤ºæ¹æ³å¢å¼·äºæ¨¡åæ ¹æ DSM-5 æ¨æºåæåè§£éæé¬±çççè½åãå¨äºåéæ®µï¼éäºæ¨¡åæåèåçå¿å°è©±ç®¡çï¼å¾ PsychDB åèªç¥è¡çºçæ³ (CBT) æåç­è³æºä¸­æ±²åï¼ä¿é²èç¶æ­·éåº¦æé¬±ççäººåçæ¯ææ§äºåãæ­¤å¤ï¼éé ç ç©¶éä»ç´¹äº Illuminate è³æåº«ï¼å¶ä¸­åå«åç¨® CBT æ¨¡çµï¼æå©æ¼åæ§åæ²»çå»ºè­°ãéé ç ç©¶ä½¿ç¨ F1 åæ¸ãæºç¢ºçãå¬åçãé¤å¼¦ç¸ä¼¼åº¦åé¢åå¬åçç Gisting è©ä¼°æ¿èº« (ROUGE) ç­ææ¨ï¼å¨ä¸åçæ¸¬è©¦éä¸­è©ä¼° LLM çè¡¨ç¾ï¼è­æäºå®åçæææ§ãéç¨®ç¶åæ¹æ³çµåäºå°ç«¯ç AI èæ¢å®çå¿çæ¹æ³ï¼çºå¿çä¿å¥æä¾äºæ°çå¯è½æ§ï¼ä¸¦å±ç¤ºäº LLM å¨é©æ°æé¬±çè¨ºæ·åæ²»çç­ç¥æ¹é¢çæ½åã

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v4 by TimothÃ©e Schmude, Laura Koesten, Torsten MÃ¶ller, Sebastian Tschiatschek

Explanations of AI systems rarely address the information needs of people
affected by algorithmic decision-making (ADM). This gap between conveyed
information and information that matters to affected stakeholders can impede
understanding and adherence to regulatory frameworks such as the AI Act. To
address this gap, we present the "XAI Novice Question Bank": A catalog of
affected stakeholders' information needs in two ADM use cases (employment
prediction and health monitoring), covering the categories data, system
context, system usage, and system specifications. Information needs were
gathered in an interview study where participants received explanations in
response to their inquiries. Participants further reported their understanding
and decision confidence, showing that while confidence tended to increase after
receiving explanations, participants also met understanding challenges, such as
being unable to tell why their understanding felt incomplete. Explanations
further influenced participants' perceptions of the systems' risks and
benefits, which they confirmed or changed depending on the use case. When risks
were perceived as high, participants expressed particular interest in
explanations about intention, such as why and to what end a system was put in
place. With this work, we aim to support the inclusion of affected stakeholders
into explainability by contributing an overview of information and challenges
relevant to them when deciding on the adoption of ADM systems. We close by
summarizing our findings in a list of six key implications that inform the
design of future explanations for affected stakeholder audiences.

æè¦ï¼<paragraph>äººå·¥æºæ§ç³»çµ±çèªªæå¾å°è½æ»¿è¶³åæ¼ç®æ³æ±ºç­ (ADM) å½±é¿çäººåçè³è¨éæ±ãå³éçè³è¨èå½±é¿å©å®³éä¿äººéè¦çè³è¨ä¹éçå·®è·ï¼å¯è½æé»ç¤äºè§£åéµå®æ³è¦æ¶æ§ï¼ä¾å¦äººå·¥æºæ§æ³æ¡ãçºäºè§£æ±ºéåå·®è·ï¼æåæåºäºãXAI åå­¸èåé¡åº«ãï¼åå½±é¿å©å®³éä¿äººè³è¨éæ±çç®éï¼æ¶µèå©å ADM ä½¿ç¨æ¡ä¾ï¼å°±æ¥­é æ¸¬åå¥åº·ç£æ¸¬ï¼ï¼æ¶µèè³æãç³»çµ±èçµ¡ãç³»çµ±ä½¿ç¨åç³»çµ±è¦æ ¼é¡å¥ãè³è¨éæ±æ¯ééè¨ªè«ç ç©¶æ¶éçï¼åèèå¨è©¢åå¾æ¶å°èªªæãåèèé²ä¸æ­¥åå ±ä»åççè§£åæ±ºç­ä¿¡å¿ï¼é¡¯ç¤ºéç¶å¨æ¶å°èªªæå¾ä¿¡å¿å¾åæ¼å¢å ï¼ä½åèèä¹éå°äºçè§£ææ°ï¼ä¾å¦ç¡æ³èªªæçºä»éº¼ä»åççè§£æè¦ºä¸å®æ´ãèªªæé²ä¸æ­¥å½±é¿åèèå°ç³»çµ±é¢¨éªåå¥½èççæ³ï¼ä»åææ ¹æä½¿ç¨æ¡ä¾ç¢ºèªææ¹è®éäºçæ³ãç¶é¢¨éªè¢«èªçºå¾é«æï¼åèèè¡¨ç¤ºç¹å¥æèè¶£äºè§£æåçèªªæï¼ä¾å¦çºä»éº¼ä»¥åçºäºä»éº¼ç®çèå»ºç«ç³»çµ±ãéééé å·¥ä½ï¼æåæ¨å¨ééå¨æ±ºç­æ¡ç¨ ADM ç³»çµ±ææä¾ç¸éè³è¨åææ°çæ¦è¦½ï¼ä¾æ¯æ´å°åå½±é¿çå©å®³éä¿äººç´å¥å¯è§£éæ§ãæåæå¾ç¸½çµæåçç¼ç¾ï¼ååºå­é ééµå½±é¿ï¼éäºå½±é¿æåç¥æªä¾éå°åå½±é¿å©å®³éä¿äººåç¾èªªæçè¨­è¨ã</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet GÃ¼rkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

æè¦ï¼äººå·¥æºæ§ (AI) çå¿«éæ¼é²ï¼å°¤å¶æ¯å¨å¤§åèªè¨æ¨¡å (LLM) åçæå¼ AI çé åï¼çºååé åçæç¨éåäºæ°éå¾ï¼ä½å¶å¨åæ¥­æè²ä¸­çè§è²ä»æªè¢«ååæ¢è¨ãæ¬ç ç©¶é¦æ¬¡å¼å¥äºåºæºï¼ç¨ä»¥è©ä¼°ä¸åä¸»è¦ LLM çæè½ï¼åæ¬ OpenAI çæ¨¡å (GPT-3.5 TurboãGPT-4 å GPT-4 Turbo)ãGoogle çæ¨¡å (PaLM 2ãGemini 1.0 Pro) å Anthropic çæ¨¡å (Claude 2 å Claude 2.1)ï¼éäºæ¨¡åå°ç¨æ¼ç ç©¶çåæ¥­èª²ç¨å¥å­¸ç¨åºä¸­çééµèè©¦ GMATãæåçåæé¡¯ç¤ºï¼å¤§å¤æ¸ LLM çè¡¨ç¾é½åªæ¼äººé¡èçï¼å¶ä¸­ GPT-4 Turbo ä¸ååªæ¼å¶ä»æ¨¡åï¼æ´è¶è¶äºé å°åå­¸é¢çç ç©¶çå¹³ååæ¸ãééæ¡ä¾ç ç©¶ï¼æ¬ç ç©¶æ¢è¨äº GPT-4 Turbo å¨è§£éç­æ¡ãè©ä¼°åæãè¾¨è­é¯èª¤ãèª¿æ´èªªæåç¢çæ¿ä»£æå¢æ¹é¢çè½åãèåä¸ä»£çæ¬ç¸æ¯ï¼ææ°ç LLM çæ¬ GPT-4 TurboãClaude 2.1 å Gemini 1.0 Pro å¨æ¨çä»»åæ¹é¢æé¡¯èçé²æ­¥ï¼å¸é¡¯äºå¶å¨è§£æ±ºè¤éåé¡æ¹é¢çæ½åãåç®¡ AI å¨æè²ãè©éåè¼å°æ¹é¢çæ¿è«¾å¾æç¢ºï¼ä½ä»æææ°å­å¨ãæåçç ç©¶ä¸åé¡æäº LLM çå­¸è¡æ½åï¼ä¹å¼·èª¿äºå¨æè²ä¸­å¯©æéç¼åæç¨ AI çå¿è¦æ§ãé¨è AI æè¡çé²æ­¥ï¼å»ºç« AI äºåçæ¶æ§ååå®ãé©è­ AI çæçå§å®¹çæºç¢ºæ§ãç¢ºä¿å¨çåå°å¤åå­¸ç¿èçå­åæ¬ï¼ä»¥ååµé ä¸å AI æ¯æäººé¡å°æ¥­ç¥è­çæè²ç°å¢è³ééè¦ãæ¬ç ç©¶çºé²ä¸æ­¥æ¢ç´¢è² è²¬ä»»å°ä½¿ç¨ AI ä¾è±å¯æè²é«é©ä¸¦æ¹åèè©¦æºååè©éæ¹æ³å¥ å®äºåºç¤ã

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

æè¦ï¼é æ¸¬å è­·çæ¿ (ICU) çæ£çé¢å§æ­»äº¡çæ¯æçµè¨åºçµæçééµãAI å·²å±ç¾åºåªç°çæºç¢ºåº¦ï¼ä½å»ç¼ºä¹å¯è§£éæ§ãçºäºè§£æ±ºéååé¡ï¼æ¬ææåºäºä¸åå¯è§£éçå¤æ¨¡å¼æ­»äº¡çé æ¸¬å¨ (X-MMP)ï¼æ¡ç¨ææä¸å¯è§£éç AI æ¹å¼ï¼èç±å¤æ¨¡å¼ ICU è³æä¾é æ¸¬é¢å§æ­»äº¡çãæåå¨æ¶æ§ä¸­æ¡ç¨å¤æ¨¡å¼å­¸ç¿ï¼å¯ä»¥æ¥æ¶ä¾èªè¨åºè³æçç°è³ªè¼¸å¥ä¸¦ååºæ±ºç­ãæ­¤å¤ï¼æåå¼å¥äºä¸åå¯è§£éçæ¹æ³ï¼ä¹å°±æ¯åå±¤å³æ­è³ Transformerï¼ä½çº LRP æ¹æ³é©ç¶å°å»¶ä¼¸è³ Transformerï¼å°å¤æ¨¡å¼è¼¸å¥ç¢çè§£éï¼ä¸¦æ­é²æ­¸å æ¼é æ¸¬çé¡¯èç¹å¾µãæ­¤å¤ï¼æ¯åæ¨¡å¼å°è¨åºçµæçè²¢ç»å¯ä»¥è¦è¦ºåï¼åå©è¨åºé«å¸«äºè§£æ±ºç­èå¾ççç±ãæåæ ¹æ MIMIC-III å MIMIC-III æ³¢å½¢è³æåº«æ¯å°å­éå»ºæ§äºä¸åå¤æ¨¡å¼è³æéãå¨åºæºè³æéä¸çå¨é¢å¯¦é©è­æï¼æåæåºçæ¶æ§å¯ä»¥éæåççè©®éï¼ä¸¦å·åç«¶ç­åçé æ¸¬æºç¢ºåº¦ãç¹å¥æ¯ï¼æåçæ¶æ§å¯ä»¥è¼é¬å°è½ç§»å°å¶ä»è¨åºä»»åï¼éæå©æ¼å¨é«çä¿å¥ç ç©¶ä¸­ç¼ç¾ééµå ç´ ã

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian GeiÃler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, BjÃ¶rn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias KÃ¼ster, AndrÃ© Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

æè¦ï¼å¨éå»çåå¹´ä¸­ï¼ççå­¸ä¸­çäººå·¥æºæ§ (AI) æ¹æ³å·²å¤§å¹é²æ­¥ãç¶èï¼ç±æ¼è¨±å¤ææ°ï¼åæ¬å°ç ç©¶çµæè½åçºè¨åºè¨ºæ·ç¢åå¨æè¡åæ³è¦æ¹é¢çéç¤ï¼ä»¥åç¼ºä¹æ¨æºåä»é¢ï¼å°è´æ´åå°å¸¸è¦è¨åºå¯¦åä¸­é²å±ç·©æ¢ãéæ¾ä¸èä¾æåç¡éç EMPAIA è¨ç«æå°äºéäºææ°ãå¨æ­¤ï¼æåæä¾ EMPAIA çæå°±åç¶é©æè¨çæ¦è¿°ãEMPAIA æ´åäºççå­¸ AI çæç³»çµ±çååå©å®³éä¿äººï¼å³ççå­¸å®¶ãé»è¦ç§å­¸å®¶åç¢æ¥­ãå¨å¯ååä½ä¸ï¼æåå¶å®äºæè¡äºéæ§æ¨æºãAI æ¸¬è©¦åç¢åéç¼å»ºè­°ï¼ä»¥åå¯è§£éæ§æ¹æ³ãæåå¯¦ä½äºæ¨¡çµåä¸éæ¾åå§ç¢¼ç EMPAIA å¹³èºï¼ä¸¦æåæ´åäºä¾èª 8 åä¸åä¾æåç 14 ååºæ¼ AI çå½±ååææç¨ç¨å¼ï¼å±ç¤ºäºä¸åçæç¨ç¨å¼å¦ä½ä½¿ç¨å®ä¸çæ¨æºåä»é¢ãæååªåèæ®éæ±ï¼ä¸¦è©ä¼°äº AI å¨æ­æ´²åäºæ´²ç 14 åä¸åççå¯¦é©å®¤ä¸­çå¯¦éè¨åºæç¨ãé¤äºæè¡éç¼å¤ï¼æåéçºææå©å®³éä¿äººå»ºç«äºä¸åè«å£ï¼ä»¥åäº«æ¸ä½ççå­¸å AI çè³è¨åç¶é©ãåæ¥­ãè¨åºåå­¸è¡å©å®³éä¿äººç¾å¨å¯ä»¥æ¡ç¨ EMPAIA çå¸¸è¦éæ¾åå§ç¢¼ä»é¢ï¼éçºå¤§è¦æ¨¡æ¨æºååç°¡åæµç¨æä¾äºç¨ç¹çæ©æãéè¦é²ä¸æ­¥çåªåæè½ææä¸å»£æ³å°å»ºç«ä¾è¡å¯¦é©å®¤ä½¿ç¨ä¸­ç AI è¼å©ãçºæ­¤ï¼å·²æç«éçå©åæ EMPAIA Internationalï¼ä»¥ä½çºæ°¸çºåºç¤æ¶æ§ï¼ç¹¼çºé²è¡æ¨æºåï¼ä¸¦æ¯æ´å»£æ³å¯¦ä½åå¡å° AI è¼å©æ¸ä½ççå­¸çæªä¾ã

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

æè¦ï¼åäºå¯¦è§£é (CE) æè¡å·²å¼èµ·éæ³¨ï¼ä½çºä¸ç¨®çºè AI ç³»çµ±äºåçä½¿ç¨èæä¾è¦è§£çæ¹æ³ãéç¶å¨é«å­¸å½±ååèªåé§é§æ±½è»ç­é åå»£æ³ç ç©¶ï¼åå½¢åäºå¯¦è§£é (GCE) æ¹æ³ç¸å°è¼å°è¢«æ¢ç´¢ãGCE æç¢çä¸åé¡ä¼¼æ¼åå§åå½¢çæ°åå½¢ï¼ä¸¦æ ¹æåºç¤é æ¸¬æ¨¡åç¢çä¸åççµæãå¨éäº GCE æè¡ä¸­ï¼åç®¡å¨å¶ä»é åï¼ä¾å¦èè¡é¢¨æ ¼åèªç¶èªè¨å»ºæ¨¡ï¼ä¸­å±ç¾åºä»¤äººå°è±¡æ·±å»çæå°±ï¼ä½æ¤åºæ¼çææ©å¶çæè¡ç²å¾çéæ³¨ç¸å°æéãå°çæå¼è§£éå¨çåå¥½æºæ¼å®åå¨æ¨çæéç¢çåäºå¯¦å¯¦ä¾çè½åï¼å©ç¨è¼¸å¥åå½¢çèªä¸»ç²åæ¾åãåºæ¼ä¸è¿°çç±ï¼æåçç ç©¶å¼å¥äº RSGG-CEï¼ä¸ç¨®ç¨æ¼åäºå¯¦è§£éçæ°åç©©å¥é¨æ©åå½¢çæå¨ï¼è½å¤ å¾å­¸ç¿å°çæ½å¨ç©ºéä¸­ç¢çåäºå¯¦ç¯ä¾ï¼èæ®é¨åæåºççæåºåãæ­¤å¤ï¼æåé²è¡å®éåå®æ§åæï¼ä»¥æ¯è¼ RSGG-CE çæè½è SoA çæå¼è§£éå¨ï¼å¼·èª¿å¶å¢å¼·äºç¢çåçè§£éåé¸çè½åã

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

æè¦ï¼å¯è§£é AI çåæ©ä¹ä¸æ¯è®äººåå¨ä½¿ç¨åé¨ç½² AI æ¨¡åæååºæ´å¥½ãæ´ææºçæ±ºç­ãä½éè¦ä»ç´°è©ä¼°ä»¥è©ä¼°æ¯å¦å·²éå°æ­¤é æãç®åçè©ä¼°ä¸»è¦éä¸­å¨è§£éçæ¼ç®æ³ç¹æ§ï¼èæ¶åäººé¡åè©¦èçè©ä¼°éå¸¸æ¡ç¨ä¸»è§åé¡ä¾æ¸¬è©¦äººé¡å°è§£éæç¨æ§ççæ³ï¼èæ²æåºæ¼å®¢è§ææ¨åæ¸¬éãå¨éé å·¥ä½ä¸­ï¼æåè©ä¼°è§£éæ¯å¦å¯ä»¥å¨æ©å¨å­¸ç¿æ¨¡åéç¼çå¯¦éå ´æ¯ä¸­æ¹åäººé¡æ±ºç­å¶å®ãæåé²è¡äºä¸é æ¶åå½±åè³æçæ··åæ¹æ³ä½¿ç¨èç ç©¶ï¼ä»¥è©ä¼° SmoothGradãGradCAM åé è¨è§£éå¨å©åä»»åä¸­ç¢ççé¡¯èæ§åï¼æ¨¡åé¸æååäºå¯¦æ¨¡æ¬ãä»¤äººé©è¨çæ¯ï¼æåæ²æç¼ç¾ä»»ä½é¡¯èæ§åï¼å³ä½¿æ¯è¨­è¨çºææ¼çè§£ä¸é«åº¦æç¤ºç­æ¡çåæé è¨è§£éï¼è½è®ä½¿ç¨èå¨éäºä»»åä¸é¡¯èæ¹åçè­æãåç®¡å¦æ­¤ï¼è§£éç¢ºå¯¦æå©æ¼ä½¿ç¨èæ´æºç¢ºå°æè¿°æ¨¡åãéäºç¼ç¾æç¤ºæåè¦å°åºæ¼é¡¯èæ§çè§£éä¸­å¯è½å­å¨èª¤è§£çæç¨æ§ä¿æè¬¹æã

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

æè¦ï¼å¯è§£éæ§åå®å¨æ§å»ºç«ä¿¡ä»»ãéäºéè¦ä¸åæ¨¡åä¾å±ç¤ºä¸è´æ§åå¯é æ§ãçºäºå¯¦ç¾éäºï¼æå¿è¦ä½¿ç¨ååææ¸æåç¥è­ï¼ä¸¦ä½¿ç¨è AI æç¨ç¸éççµ±è¨åç¬¦è AI æ¹æ³ - å®ç¨ä½¿ç¨ä»»ä½ä¸ç¨®æ¹æ³é½ä¸æå¥æãå æ­¤ï¼æåä¸»å¼µä¸¦è©¦åè­æ NeuroSymbolic AI æ¹æ³æ´é©åæ¼ä½¿ AI æçºåä¿¡ä»»ç AI ç³»çµ±ãæåæåºäº CREST æ¡æ¶ï¼å±ç¤ºäºä¸è´æ§ãå¯é æ§ãä½¿ç¨èå±¤ç´çå¯è§£éæ§åå®å¨æ§æ¯å¦ä½å»ºç«å¨ NeuroSymbolic æ¹æ³ä¸çï¼è©²æ¹æ³ä½¿ç¨æ¸æåç¥è­ä¾æ¯æééµæç¨ï¼ä¾å¦å¥åº·åç¦ç¥ï¼çè¦æ±ãæ¬æéé»éæ³¨å¤§åèªè¨æ¨¡å (LLM)ï¼å çºå®æ¯ CREST æ¡æ¶ä¸­é¸æç AI ç³»çµ±ãLLM å å¶å¨èçå»£æ³çèªç¶èªè¨èç (NLP) å ´æ¯æ¹é¢çå¤åè½æ§èååç ç©¶äººå¡çéæ³¨ãä¾å¦ï¼ChatGPT å Google ç MedPaLM å·²æçºæä¾ä¸è¬åå¥åº·ç¸éæ¥è©¢ä¿¡æ¯çæ¥µæå¸æçå¹³å°ãåç®¡å¦æ­¤ï¼éäºæ¨¡åä»ç¶æ¯é»çå­ï¼åç®¡ç´å¥äºäººé¡åé¥åæä»¤å¼å°çèª¿æ´ãä¾å¦ï¼åç®¡å¶å®äºå®å¨é²è­·æªæ½ï¼ChatGPT ä»å¯è½ç¢çä¸å®å¨çåæãCREST æåºäºä¸ç¨®åççæ¹æ³ï¼å¨ NeuroSymbolic æ¡æ¶ä¸­å©ç¨ç¨åºååºæ¼åè¡¨çç¥è­ï¼ä»¥é¡æè LLM ç¸éçææ°ã

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano, Stephen Glass, Ravi P. Ramachandran, Sharad Patel, Aaron J. Masino, Ghulam Rasool

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

æè¦ï¼æ¬ç ç©¶è°æ¥äºå¨ COVID-19 ç«ææé´åä»¥åé¢æµæ­»äº¡çæ¶ï¼å·²é¨ç½²äººå·¥æºè½ (AI) æ¨¡åçæ§è½ãå¯è§£éæ§åç¨³å¥æ§ãä½ä¸ºåç±»ç ç©¶ä¸­çé¦ä¾ï¼æä»¬åç°è´å¶æ¯ç¥ç»ç½ç» (BNN) åæºè½è®­ç»ææ¯è®©æä»¬çæ¨¡åå¨æ°æ®åçéå¤§ååæ¶ä»è½ä¿ææ§è½ãæä»¬çç»æå¼ºè°äºå¼åç¨³å¥ç AI æ¨¡åçéè¦æ§ï¼å³ä½¿å¨å·ææææ§çæ¡ä»¶ä¸ï¼è¿äºæ¨¡åä¹è½å¹éæè¶è¶ä¸´åºå»ççé¢æµãæä»¬å¯¹æ¨¡åå¯è§£éæ§çæ¢ç´¢è¡¨æï¼éæºæ¨¡åä¼äº§çæ´å¤æ ·åä¸ä¸ªæ§åçè§£éï¼ä»èçªåºäºå¨ç°å®ä¸ççä¸´åºç¯å¢ä¸­æä¾è¯¦ç»ä¸ä¸ªæ§åè§è§£ç AI æ¨¡åçå¿è¦æ§ãæ­¤å¤ï¼æä»¬å¼ºè°äºéå AI æ¨¡åä¸­ä¸ç¡®å®æ§çéè¦æ§ï¼è¿ä½¿ä¸´åºå»çè½å¤æ ¹æ®å¯é çé¢æµååºæ´ææºçå³ç­ãæä»¬çç ç©¶æå¡å¨å»çä¿å¥ç AI ç ç©¶ä¸­ä¼åèèå®æ½ç§å­¦ï¼å¹¶ç¡®ä¿ AI è§£å³æ¹æ¡å¨ç°å®ä¸ççä¸´åºç¯å¢ä¸­å®ç¨ãæçä¸å¯æç»­ãéè¿è§£å³å»çä¿å¥ç¯å¢ä¸­çç¬ç¹ææåå¤ææ§ï¼ç ç©¶äººåå¯ä»¥å¼ååºæææ¹åä¸´åºå®è·µåæ£èé¢åç AI æ¨¡åã

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel, Aaron Quyn, David Jayne, Samuel D. Relton

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

æè¦ï¼èºçå è±åççæ­»äº¡äººæ¸ç 21%ï¼äºå¹´å­æ´»çå¾å¤§ç¨åº¦åæ±ºæ¼ççè¢«ç¼ç¾çéæ®µãæè¿çç ç©¶å·²è­æäººå·¥æºè½æ¹æ³å·æå¾ä¾è¡ææä¸­æºç¢ºåæ©è¨ºæ·èºççè½åãç¶èï¼æ­¤è­æå°æªè½åçºè¨åºå¯¦åï¼å¶ä¸­ä¸åéç¤æ¯ç¼ºä¹å¯è§£éçæ¨¡åãæ¬ç ç©¶æ¢è¨äºæç¨è®åèªåç·¨ç¢¼å¨ (VAE)ï¼ä¸ç¨®çæå¼äººå·¥æºè½æ¨¡åï¼æ¼èºççç¶ãå°æåºçæ¨¡åè¨ç·´æ¼å¾ LIDC-IDRI å¬å±æ¸æéä¸­æåç 3D é»è¦æ·å±¤ææçç¶ãééèé¡æ¢ç´¢äº VAE çæç 2D åççæ½å¨åéè¡¨ç¤ºï¼ä»¥è­æå¶åè³ªï¼ä¸¦ç¨æ¼èºçè¨ºæ·ç MLP åé¡å¨æ¨¡åï¼æä½³æ¨¡åéå°äº AUC 0.98 å 93.1% æºç¢ºåº¦çæåé²ææ¨ãèé¡åæé¡¯ç¤ºï¼VAE æ½å¨ç©ºéæ ¹æææç¾©çç¹å¾µçµæï¼åæ¬è«ç¤å¤§å°ãå½¢çãæ£èåæ¡æ§é¡å¥ï¼å°æ¡æ§åè¯æ§çç¶çæ¸æéåéãæåéåæ¬æ¨æºé«æ¯ VAE (GVAE) åæ´æ°ççå©åé· VAE (DirVAE) çæ¯è¼åæï¼å¾èç¨çå©åé·åä½åä»£åé©ï¼ä»¥ä¿é²å·æè§£éç¹å¾µè¡¨ç¤ºçæ´å·å¯è§£éæ§çæ½å¨ç©ºéãæå¾ï¼æåå±ç¤ºäºèè¨åºææç¾©çç¹å¾µè®åç¸æçæ½å¨ç©ºéæ©«è¶çæ½åã

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

æè¦ï¼ç¾æçåååé¡å¨è¼¸åºè§£éå·¥å·å¯åçºä¾è³´æ¼æ¨¡åå§é¨å­åæ¬éçç½çï¼ä»¥åèæ¨¡åç¡éçé»çãé¨è AI å¨é«çé åçä½¿ç¨å¢å ï¼å¯è§£éæ§å·¥å·çä½¿ç¨ä¹é¨ä¹å¢å ãç¾æé«å­¸å½±åè§£éçå·¥ä½éé»å¨æ¼ç½çå·¥å·ï¼ä¾å¦ gradcamãç¶èï¼åæå°é»çå·¥å·ææé¡¯çåªé»ï¼åæ¬è½å¤ èä»»ä½åé¡å¨ä¸èµ·ä½¿ç¨ï¼ä»¥åå»£æ³çé»çå·¥å·å¯ä¾é¸æãå¨æ¨æºå½±åä¸ï¼é»çå·¥å·èç½çä¸æ¨£ç²¾ç¢ºãå¨æ¬æä¸­ï¼æåæ¯è¼äºå¤ç¨®é»çæ¹æ³å¨è¦ç MRI è³æéä¸è gradcam çæè½ãæåè­æå¤§å¤æ¸é»çå·¥å·ä¸é©åè§£éé«å­¸å½±ååé¡ï¼ä¸¦è©³ç´°åæå¶ç¼ºé»çåå ãæåéè¡¨æä¸ç¨®é»çå·¥å·ï¼åºæ¼å æå¯è§£éæ§ç rexï¼è¡¨ç¾è \gradcam ä¸æ¨£å¥½ã

##### **Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**
2311.12573v2 by Robert Gorwa, Michael Veale

The AI development community is increasingly making use of hosting
intermediaries such as Hugging Face provide easy access to user-uploaded models
and training data. These model marketplaces lower technical deployment barriers
for hundreds of thousands of users, yet can be used in numerous potentially
harmful and illegal ways. In this article, we explain ways in which AI systems,
which can both `contain' content and be open-ended tools, present one of the
trickiest platform governance challenges seen to date. We provide case studies
of several incidents across three illustrative platforms -- Hugging Face,
GitHub and Civitai -- to examine how model marketplaces moderate models.
Building on this analysis, we outline important (and yet nevertheless limited)
practices that industry has been developing to respond to moderation demands:
licensing, access and use restrictions, automated content moderation, and open
policy development. While the policy challenge at hand is a considerable one,
we conclude with some ideas as to how platforms could better mobilize resources
to act as a careful, fair, and proportionate regulatory access point.

æè¦ï¼AI ç¼å±ç¤¾ç¾¤æ¥çå©ç¨ Hugging Face ç­è¨ç®¡ä¸­ä»ï¼æä¾ä½¿ç¨èä¸å³ä¹æ¨¡åèè¨ç·´è³æçç°¡æåå¾ç®¡éãéäºæ¨¡åå¸ééä½äºæ¸åè¬åä½¿ç¨èçæè¡é¨ç½²éæª»ï¼ä½å»å¯è½è¢«ç¨æ¼è¨±å¤æ½å¨æå®³ä¸éæ³çç¨éãå¨æ¬æä¸­ï¼æåèªªæäº AI ç³»çµ±æ¢å¯ä»¥ãåå«ãå§å®¹ï¼ä¹å¯ä»¥ä½çºéæ¾å¼å·¥å·ï¼éæåºäºè¿ä»çºæ­¢ææ£æçå¹³å°æ²»çææ°ä¹ä¸ãæåæä¾ Hugging FaceãGitHub å Civitai ç­ä¸åèªªææ§å¹³å°ä¸æ¸èµ·äºä»¶çæ¡ä¾ç ç©¶ï¼ä»¥æ¢è¨æ¨¡åå¸éå¦ä½æ§ç®¡æ¨¡åãæ ¹ææ­¤åæï¼æåæ¦è¿°äºç¢æ¥­çºåææ§ç®¡éæ±èç¼å±çéè¦ï¼ä½ä»æéï¼å¯¦åï¼ææ¬ãå­ååä½¿ç¨éå¶ãèªåå§å®¹æ§ç®¡åéæ¾å¼æ¿ç­ç¼å±ãåç®¡ç®åé¢è¨çæ¿ç­ææ°ç¸ç¶å´å³»ï¼æåä»æåºäºä¸äºæ³æ³ï¼èªªæå¹³å°å¦ä½è½æ´å¥½å°åå¡è³æºï¼ä½çºè¬¹æãå¬å¹³åé©åº¦çæ³è¦å­åé»ã

##### **Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**
2311.11932v1 by Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker

Background and objectives: By extracting this information, Machine or Deep
Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and
cancer researchers in discovering patterns and relationships from complex data
sets. Many DL-based analyses on ovarian cancer (OC) data have recently been
published. These analyses are highly diverse in various aspects of cancer
(e.g., subdomain(s) and cancer type they address) and data analysis features.
However, a comprehensive understanding of these analyses in terms of these
features and AI assurance (AIA) is currently lacking. This systematic review
aims to fill this gap by examining the existing literature and identifying
important aspects of OC data analysis using DL, explicitly focusing on the key
features and AI assurance perspectives. Methods: The PRISMA framework was used
to conduct comprehensive searches in three journal databases. Only studies
published between 2015 and 2023 in peer-reviewed journals were included in the
analysis. Results: In the review, a total of 96 DL-driven analyses were
examined. The findings reveal several important insights regarding DL-driven
ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on
detection and diagnosis, while no study addressed the prediction and prevention
of OC. - The analyses were predominantly based on samples from a non-diverse
population (75% (72/96 studies)), limited to a geographic location or country.
- Only a small proportion of studies (only 33% (32/96)) performed integrated
analyses, most of which used homogeneous data (clinical or omics). - Notably, a
mere 8.3% (8/96) of the studies validated their models using external and
diverse data sets, highlighting the need for enhanced model validation, and -
The inclusion of AIA in cancer data analysis is in a very early stage; only
2.1% (2/96) explicitly addressed AIA through explainability.

æè¦ï¼<paragraph>èæ¯åç®æ¨ï¼ééæåéäºè³è¨ï¼æ©å¨ææ·±åº¦å­¸ç¿ (ML/DL) åºæ¼èªä¸»æ¸æåæå·¥å·å¯ä»¥åå©è¨åºé«çåççç ç©¶äººå¡å¾è¤éçæ¸æéä¸­ç¼ç¾æ¨¡å¼åéä¿ãæè¿å·²ç¼è¡¨è¨±å¤åºæ¼ DL çåµå·¢ç (OC) æ¸æåæãéäºåæå¨çççååæ¹é¢ï¼ä¾å¦ï¼å®åæ¶åçå­é ååççé¡åï¼åæ¸æåæåè½æ¹é¢é«åº¦å¤æ¨£åãç¶èï¼ç®åç¼ºä¹å°éäºåæå¨éäºç¹å¾µå AI ä¿è­ (AIA) æ¹é¢çå¨é¢çè§£ãéç¯ç³»çµ±æ§åé¡§æ¨å¨ééæª¢è¦ç¾ææç»ä¸¦æç¢ºéæ³¨ééµç¹å¾µå AI ä¿è­è§é»ï¼ä¾å¡«è£éåç©ºç½ãæ¹æ³ï¼ä½¿ç¨ PRISMA æ¶æ§å¨ä¸åæåè³æåº«ä¸­é²è¡å¨é¢æå°ãåæååæ¬ 2015 å¹´è³ 2023 å¹´éç¼è¡¨æ¼åè¡è©å¯©æåçç ç©¶ãçµæï¼å¨åé¡§ä¸­ï¼ç¸½å±æª¢è¦äº 96 é ç± DL é©åçåæãç ç©¶çµææ­ç¤ºäºå¹¾åéæ¼ç± DL é©åçåµå·¢çæ¸æåæçéè¦è¦è§£ï¼- å¤§å¤æ¸ç ç©¶ 71%ï¼96 é ä¸­æ 68 é ï¼å°æ³¨æ¼æª¢æ¸¬åè¨ºæ·ï¼èæ²æç ç©¶æ¢è¨ OC çé æ¸¬åé é²ã- éäºåæä¸»è¦åºæ¼ä¾èªéå¤åæç¾¤çæ¨£æ¬ï¼75%ï¼96 é ç ç©¶ä¸­ç 72 é ï¼ï¼ï¼åéæ¼æåå°çä½ç½®æåå®¶ã- åªæå°é¨åç ç©¶ï¼å 33%ï¼96 é ç ç©¶ä¸­ç 32 é ï¼å·è¡æ´ååæï¼å¶ä¸­å¤§å¤æ¸ä½¿ç¨åè³ªæ¸æï¼è¨åºæçµå­¸ï¼ã- å¼å¾æ³¨æçæ¯ï¼åªæ 8.3%ï¼96 é ç ç©¶ä¸­ç 8 é ï¼ä½¿ç¨å¤é¨åå¤åæ¸æéé©è­äºå¶æ¨¡åï¼å¼·èª¿äºå å¼·æ¨¡åé©è­çå¿è¦æ§ï¼ä»¥å- å° AIA ç´å¥ççæ¸æåæä»èæ¼éå¸¸æ©æçéæ®µï¼åªæ 2.1%ï¼96 é ç ç©¶ä¸­ç 2 é ï¼ééå¯è§£éæ§æç¢ºæ¢è¨äº AIAã</paragraph>

##### **Representing visual classification as a linear combination of words**
2311.10933v1 by Shobhit Agarwal, Yevgeniy R. Semenov, William Lotter

Explainability is a longstanding challenge in deep learning, especially in
high-stakes domains like healthcare. Common explainability methods highlight
image regions that drive an AI model's decision. Humans, however, heavily rely
on language to convey explanations of not only "where" but "what".
Additionally, most explainability approaches focus on explaining individual AI
predictions, rather than describing the features used by an AI model in
general. The latter would be especially useful for model and dataset auditing,
and potentially even knowledge generation as AI is increasingly being used in
novel tasks. Here, we present an explainability strategy that uses a
vision-language model to identify language-based descriptors of a visual
classification task. By leveraging a pre-trained joint embedding space between
images and text, our approach estimates a new classification task as a linear
combination of words, resulting in a weight for each word that indicates its
alignment with the vision-based classifier. We assess our approach using two
medical imaging classification tasks, where we find that the resulting
descriptors largely align with clinical knowledge despite a lack of
domain-specific language training. However, our approach also identifies the
potential for 'shortcut connections' in the public datasets used. Towards a
functional measure of explainability, we perform a pilot reader study where we
find that the AI-identified words can enable non-expert humans to perform a
specialized medical task at a non-trivial level. Altogether, our results
emphasize the potential of using multimodal foundational models to deliver
intuitive, language-based explanations of visual tasks.

æè¦ï¼<paragraph>è§£éæ§æ¯æ·±åº¦å­¸ç¿ä¸­é·æçææ°ï¼ç¹å¥æ¯å¨é«çä¿å¥ç­é«é¢¨éªé åãå¸¸è¦çè§£éæ§æ¹æ³æå¼·èª¿é©å AI æ¨¡åæ±ºç­çå½±åååãç¶èï¼äººé¡å¾å¤§ç¨åº¦ä¾è³´èªè¨ä¾å³éä¸åæ¯ãå¨åªè£¡ãï¼éæãæ¯ä»éº¼ãçè§£éãæ­¤å¤ï¼å¤§å¤æ¸è§£éæ§æ¹æ³é½å°æ³¨æ¼è§£éåå¥ AI é æ¸¬ï¼èä¸æ¯æè¿° AI æ¨¡åä¸è¬ä½¿ç¨çç¹å¾µãå¾èå°æ¼æ¨¡ååè³æéç¨½æ ¸ç¹å¥æç¨ï¼çè³å¯è½å¨ AI æä¾æç¨æ¼æ°ç©ä»»åæç¢çç¥è­ãå¨æ­¤ï¼æåæåºä¸åä½¿ç¨è¦è¦ºèªè¨æ¨¡åä¾è¾¨è­è¦è¦ºåé¡ä»»åçèªè¨æè¿°ç¬¦çè§£éæ§ç­ç¥ãééå©ç¨å½±ååæå­ä¹éé åè¨ç·´çè¯ååµå¥ç©ºéï¼æåçåæ³å°æ°çåé¡ä»»åä¼°è¨çºä¸åç·æ§æå­çµåï¼å°è´æ¯åæå­é½ææ¬éï¼è¡¨ç¤ºå®èåºæ¼è¦è¦ºçåé¡å¨å°é½ãæåä½¿ç¨å©åé«å­¸å½±ååé¡ä»»åä¾è©ä¼°æåçåæ³ï¼æåç¼ç¾ç¢ççæè¿°ç¬¦å¨å¾å¤§ç¨åº¦ä¸èè¨åºç¥è­ä¸è´ï¼åç®¡ç¼ºä¹ç¹å®é åçèªè¨è¨ç·´ãç¶èï¼æåçåæ³ä¹ç¼ç¾äºæç¨å¬éè³æéä¸­çãæ·å¾é£ç·ãçå¯è½æ§ãçºäºéå°è§£éæ§çåè½æ§è¡¡éï¼æåé²è¡äºä¸é è©¦é©è®èç ç©¶ï¼ç¼ç¾ AI è­å¥çæå­è½è®éå°å®¶äººé¡å¨éå¹³å¡çå±¤ç´å·è¡å°æ¥­çé«çä»»åãç¸½ä¹ï¼æåççµæå¼·èª¿äºä½¿ç¨å¤æ¨¡å¼åºç¤æ¨¡åä¾æä¾ç´è§çãåºæ¼èªè¨çè¦è¦ºä»»åè§£éçæ½åã</paragraph>

##### **Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**
2311.02115v2 by Emma A. M. Stanley, Raissa Souza, Anthony Winder, Vedant Gulve, Kimberly Amador, Matthias Wilms, Nils D. Forkert

Artificial intelligence (AI) models trained using medical images for clinical
tasks often exhibit bias in the form of disparities in performance between
subgroups. Since not all sources of biases in real-world medical imaging data
are easily identifiable, it is challenging to comprehensively assess how those
biases are encoded in models, and how capable bias mitigation methods are at
ameliorating performance disparities. In this article, we introduce a novel
analysis framework for systematically and objectively investigating the impact
of biases in medical images on AI models. We developed and tested this
framework for conducting controlled in silico trials to assess bias in medical
imaging AI using a tool for generating synthetic magnetic resonance images with
known disease effects and sources of bias. The feasibility is showcased by
using three counterfactual bias scenarios to measure the impact of simulated
bias effects on a convolutional neural network (CNN) classifier and the
efficacy of three bias mitigation strategies. The analysis revealed that the
simulated biases resulted in expected subgroup performance disparities when the
CNN was trained on the synthetic datasets. Moreover, reweighing was identified
as the most successful bias mitigation strategy for this setup, and we
demonstrated how explainable AI methods can aid in investigating the
manifestation of bias in the model using this framework. Developing fair AI
models is a considerable challenge given that many and often unknown sources of
biases can be present in medical imaging datasets. In this work, we present a
novel methodology to objectively study the impact of biases and mitigation
strategies on deep learning pipelines, which can support the development of
clinical AI that is robust and responsible.

æè¦ï¼<paragraph>ä½¿ç¨é«çå½±åè¨ç·´çäººå·¥æºæ§ (AI) æ¨¡åï¼ç¨æ¼è¨åºä»»åæï¼å¸¸æå¨æè½ä¸å±ç¾åºæ¬¡ç¾¤é«ä¹éçå·®ç°ï¼å½¢æåè¦ãç±æ¼ä¸¦éææçå¯¦ä¸çé«çå½±åè³æä¸­çåè¦ä¾æºé½å®¹æè¾¨è­ï¼å æ­¤å¨é¢è©ä¼°éäºåè¦æ¯å¦ä½ç·¨ç¢¼å°æ¨¡åä¸­ï¼ä»¥ååè¦ç·©è§£æ¹æ³å¨æ¹åæè½å·®ç°æ¹é¢çè½åï¼æ¯ä¸é ææ°ãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸åæ°ç©çåææ¶æ§ï¼ç¨æ¼ç³»çµ±åä¸å®¢è§å°èª¿æ¥é«çå½±åä¸­çåè¦å° AI æ¨¡åçå½±é¿ãæåéç¼ä¸¦æ¸¬è©¦äºéåæ¶æ§ï¼ä»¥é²è¡åæ§çé»è¦æ¨¡æ¬è©¦é©ï¼ä½¿ç¨ä¸åå·¥å·ä¾è©ä¼°é«çå½±å AI ä¸­çåè¦ï¼è©²å·¥å·ç¨æ¼ç¢çå·æå·²ç¥ç¾çå½±é¿ååè¦ä¾æºçåæç£å±æ¯å½±åãå¯è¡æ§ééä½¿ç¨ä¸ååäºå¯¦åè¦æå¢ä¾è¡¡éæ¨¡æ¬åè¦ææå°å·ç©ç¥ç¶ç¶²è·¯ (CNN) åé¡å¨åä¸ååè¦ç·©è§£ç­ç¥çå½±é¿ï¼ä¸¦å±ç¤ºåºä¾ãåæé¡¯ç¤ºï¼ç¶ CNN å¨åæè³æéä¸åè¨æï¼æ¨¡æ¬åè¦æå°è´é æçæ¬¡ç¾¤é«æè½å·®ç°ãæ­¤å¤ï¼éæ°å æ¬è¢«èªçºæ¯æ­¤è¨­å®ä¸­ææåçåè¦ç·©è§£ç­ç¥ï¼æåå±ç¤ºäºè§£éæ§ AI æ¹æ³å¦ä½åå©ä½¿ç¨éåæ¶æ§èª¿æ¥æ¨¡åä¸­åè¦çè¡¨ç¾ãéç¼å¬å¹³ç AI æ¨¡åæ¯ä¸é éå¤§çææ°ï¼å çºé«çå½±åè³æéä¸­å¯è½å­å¨è¨±å¤ä¸ç¶å¸¸æªç¥çåè¦ä¾æºãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼ç¨æ¼å®¢è§å°ç ç©¶åè¦åç·©è§£ç­ç¥å°æ·±åº¦å­¸ç¿ç®¡ç·çå½±é¿ï¼éå¯ä»¥æ¯æ´å¥å¨ä¸è² è²¬ä»»çè¨åº AI çéç¼ã</paragraph>

##### **Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**
2310.19174v1 by Adam White, Margarita Saranti, Artur d'Avila Garcez, Thomas M. H. Hope, Cathy J. Price, Howard Bowman

Machine learning offers great potential for automated prediction of
post-stroke symptoms and their response to rehabilitation. Major challenges for
this endeavour include the very high dimensionality of neuroimaging data, the
relatively small size of the datasets available for learning, and how to
effectively combine neuroimaging and tabular data (e.g. demographic information
and clinical characteristics). This paper evaluates several solutions based on
two strategies. The first is to use 2D images that summarise MRI scans. The
second is to select key features that improve classification accuracy.
Additionally, we introduce the novel approach of training a convolutional
neural network (CNN) on images that combine regions-of-interest extracted from
MRIs, with symbolic representations of tabular data. We evaluate a series of
CNN architectures (both 2D and a 3D) that are trained on different
representations of MRI and tabular data, to predict whether a composite measure
of post-stroke spoken picture description ability is in the aphasic or
non-aphasic range. MRI and tabular data were acquired from 758 English speaking
stroke survivors who participated in the PLORAS study. The classification
accuracy for a baseline logistic regression was 0.678 for lesion size alone,
rising to 0.757 and 0.813 when initial symptom severity and recovery time were
successively added. The highest classification accuracy 0.854 was observed when
8 regions-of-interest was extracted from each MRI scan and combined with lesion
size, initial severity and recovery time in a 2D Residual Neural Network.Our
findings demonstrate how imaging and tabular data can be combined for high
post-stroke classification accuracy, even when the dataset is small in machine
learning terms. We conclude by proposing how the current models could be
improved to achieve even higher levels of accuracy using images from hospital
scanners.

æè¦ï¼æ©å¨å­¸ç¿çºèªåé æ¸¬ä¸­é¢¨å¾ççåå¶å°å¾©å¥çåææä¾äºæ¥µå¤§çæ½åãéé å·¥ä½çéå¤§ææ°åæ¬ç¥ç¶å½±åè³æçç¶­åº¦éå¸¸é«ãå¯ç¨æ¼å­¸ç¿çè³æéè¦æ¨¡ç¸å°è¼å°ï¼ä»¥åå¦ä½ææçµåç¥ç¶å½±ååè¡¨æ ¼è³æï¼ä¾å¦äººå£çµ±è¨è³è¨åè¨åºç¹å¾µï¼ãæ¬ææ ¹æå©ç¨®ç­ç¥è©ä¼°äºå¤ç¨®è§£æ±ºæ¹æ¡ãç¬¬ä¸ç¨®æ¯ä½¿ç¨ç¸½çµ MRI ææç 2D å½±åãç¬¬äºç¨®æ¯é¸ææå©æ¼æé«åé¡ç²¾ç¢ºåº¦çééµç¹å¾µãæ­¤å¤ï¼æåå¼å¥äºå¨çµåå¾ MRI ä¸­æåçæèè¶£ååèè¡¨æ ¼è³æçç¬¦èè¡¨ç¤ºçå½±åä¸è¨ç·´å·ç©ç¥ç¶ç¶²è·¯ (CNN) çæ°ç©æ¹æ³ãæåè©ä¼°äºä¸ç³»å CNN æ¶æ§ï¼2D å 3Dï¼ï¼éäºæ¶æ§å¨ MRI åè¡¨æ ¼è³æçä¸åè¡¨ç¤ºä¸é²è¡è¨ç·´ï¼ä»¥é æ¸¬ä¸­é¢¨å¾å£è¿°åçæè¿°è½åçç¶åæ¸¬éæ¯å¦å¨å¤±èªçæéå¤±èªçç¯åå§ãMRI åè¡¨æ ¼è³æä¾èª 758 ååè PLORAS ç ç©¶çè±èªä¸­é¢¨åå­èãåéå°çç¶å¤§å°çåºç·éè¼¯è¿´æ­¸åé¡æºç¢ºåº¦çº 0.678ï¼ç¶ä¾åºå å¥åå§ççå´éç¨åº¦åæ¢å¾©æéæï¼ä¸åè³ 0.757 å 0.813ãå¨å¾æ¯å MRI ææä¸­æå 8 åæèè¶£ååä¸¦å¨ 2D æ®å·®ç¥ç¶ç¶²è·¯ä¸­èçç¶å¤§å°ãåå§å´éç¨åº¦åæ¢å¾©æéçµåæï¼è§å¯å°æé«çåé¡æºç¢ºåº¦ 0.854ãæåçç ç©¶çµæå±ç¤ºäºå¦ä½å°å½±ååè¡¨æ ¼è³æçµåèµ·ä¾ä»¥ç²å¾é«æ¼ä¸­é¢¨å¾åé¡æºç¢ºåº¦ï¼å³ä½¿å¨æ©å¨å­¸ç¿è¡èªä¸­è³æéå¾å°çææ³ä¸ä¹æ¯å¦æ­¤ãæå¾ï¼æåæåºå¦ä½æ¹é²ç®åçæ¨¡åï¼ä»¥ä½¿ç¨ä¾èªé«é¢ææåçå½±åä¾å¯¦ç¾æ´é«çæºç¢ºåº¦ã

##### **Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**
2310.01828v2 by Hossein Shreim, Abdul Karim Gizzini, Ali J. Ghandour

eXplainable Artificial Intelligence (XAI) has emerged as an essential
requirement when dealing with mission-critical applications, ensuring
transparency and interpretability of the employed black box AI models. The
significance of XAI spans various domains, from healthcare to finance, where
understanding the decision-making process of deep learning algorithms is
essential. Most AI-based computer vision models are often black boxes; hence,
providing explainability of deep neural networks in image processing is crucial
for their wide adoption and deployment in medical image analysis, autonomous
driving, and remote sensing applications. Recently, several XAI methods for
image classification tasks have been introduced. On the contrary, image
segmentation has received comparatively less attention in the context of
explainability, although it is a fundamental task in computer vision
applications, especially in remote sensing. Only some research proposes
gradient-based XAI algorithms for image segmentation. This paper adapts the
recent gradient-free Sobol XAI method for semantic segmentation. To measure the
performance of the Sobol method for segmentation, we propose a quantitative XAI
evaluation method based on a learnable noise model. The main objective of this
model is to induce noise on the explanation maps, where higher induced noise
signifies low accuracy and vice versa. A benchmark analysis is conducted to
evaluate and compare performance of three XAI methods, including Seg-Grad-CAM,
Seg-Grad-CAM++ and Seg-Sobol using the proposed noise-based evaluation
technique. This constitutes the first attempt to run and evaluate XAI methods
using high-resolution satellite images.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) å·²æçºèçä»»åééµæç¨ç¨å¼æçä¸é åºæ¬éæ±ï¼ç¢ºä¿æ¡ç¨é»ç AI æ¨¡åçéæåº¦åå¯è§£éæ§ãXAI çéè¦æ§æ¶µèå¾é«çä¿å¥å°éèçåç¨®é åï¼å¨éäºé åä¸­ï¼äºè§£æ·±åº¦å­¸ç¿æ¼ç®æ³çæ±ºç­å¶å®éç¨è³ééè¦ãå¤§å¤æ¸åºæ¼ AI çé»è¦è¦è¦ºæ¨¡åéå¸¸æ¯é»çå­ï¼å æ­¤ï¼å¨å½±åèçä¸­æä¾æ·±åº¦ç¥ç¶ç¶²è·¯çå¯è§£éæ§å°æ¼å¶å¨é«å­¸å½±ååæãèªåé§é§åéæ¸¬æç¨ä¸­çå»£æ³æ¡ç¨åé¨ç½²è³ééè¦ãæè¿ï¼å·²éå°å½±ååé¡ä»»åå¼å¥äºå¤ç¨® XAI æ¹æ³ãç¸åå°ï¼å½±ååå²å¨å¯è§£éæ§çèæ¯ä¸åå°çéæ³¨ç¸å°è¼å°ï¼åç®¡å®æ¯é»è¦è¦è¦ºæç¨ä¸­çä¸é åºæ¬ä»»åï¼ç¹å¥æ¯å¨éæ¸¬ä¸­ãåªæé¨åç ç©¶æåºç¨æ¼å½±ååå²çåºæ¼æ¢¯åº¦ç XAI æ¼ç®æ³ãæ¬ææ¹ç·¨äºæè¿çç¡æ¢¯åº¦ Sobol XAI æ¹æ³ä»¥é²è¡èªæåå²ãçºäºè¡¡é Sobol æ¹æ³å¨åå²ä¸­çæè½ï¼æåæåºäºä¸ç¨®åºæ¼å¯å­¸ç¿éè¨æ¨¡åçå®é XAI è©ä¼°æ¹æ³ãæ­¤æ¨¡åçä¸»è¦ç®çæ¯å¨è§£éåä¸èªç¼éè¨ï¼å¶ä¸­è¼é«çèªç¼éè¨è¡¨ç¤ºè¼ä½çæºç¢ºåº¦ï¼åä¹äº¦ç¶ãé²è¡åºæºåæä»¥è©ä¼°åæ¯è¼ä¸ç¨® XAI æ¹æ³çæè½ï¼åæ¬ Seg-Grad-CAMãSeg-Grad-CAM++ å Seg-Sobolï¼ä¸¦ä½¿ç¨ææåºçåºæ¼éè¨çè©ä¼°æè¡ãéæ§æäºä½¿ç¨é«è§£æåº¦è¡æå½±åå·è¡åè©ä¼° XAI æ¹æ³çé¦æ¬¡åè©¦ã

##### **Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**
2311.01463v1 by Muhammad Aurangzeb Ahmad, Ilker Yaramis, Taposh Dutta Roy

Large language models have proliferated across multiple domains in as short
period of time. There is however hesitation in the medical and healthcare
domain towards their adoption because of issues like factuality, coherence, and
hallucinations. Give the high stakes nature of healthcare, many researchers
have even cautioned against its usage until these issues are resolved. The key
to the implementation and deployment of LLMs in healthcare is to make these
models trustworthy, transparent (as much possible) and explainable. In this
paper we describe the key elements in creating reliable, trustworthy, and
unbiased models as a necessary condition for their adoption in healthcare.
Specifically we focus on the quantification, validation, and mitigation of
hallucinations in the context in healthcare. Lastly, we discuss how the future
of LLMs in healthcare may look like.

æè¦ï¼å¤§åèªè¨æ¨¡åå¨ç­æéå§å·²å¨å¤åé åä¸­å¤§éæ¿å¢ãç¶èï¼ç±æ¼äºå¯¦æ§ãé£è²«æ§åå¹»è¦ºç­åé¡ï¼é«çåä¿å¥é åå°å¶æ¡ç¨ç¶è±«ä¸æ±ºãéæ¼é«çä¿å¥çé«é¢¨éªæ§è³ªï¼è¨±å¤ç ç©¶äººå¡çè³è­¦åä¸è¦ä½¿ç¨å®ï¼ç´å°éäºåé¡å¾å°è§£æ±ºãå¨é«çä¿å¥ä¸­å¯¦æ½åé¨ç½² LLM çééµæ¯ä½¿éäºæ¨¡åå¼å¾ä¿¡è³´ãéæï¼ç¡å¯è½å¤ï¼ä¸å¯è§£éãå¨æ¬æä¸­ï¼æåæè¿°äºå»ºç«å¯é ãå¼å¾ä¿¡è³´åç¡åè¦æ¨¡åçééµè¦ç´ ï¼ä½çºå®åå¨é«çä¿å¥ä¸­å¾å°æ¡ç¨çå¿è¦æ¢ä»¶ãå·é«ä¾èªªï¼æåå°æ³¨æ¼å¨é«çä¿å¥èæ¯ä¸å°å¹»è¦ºé²è¡éåãé©è­åç·©è§£ãæå¾ï¼æåè¨è«äº LLM å¨é«çä¿å¥ä¸­çæªä¾å¯è½æ¯ä»éº¼æ¨£å­ã

##### **When to Trust AI: Advances and Challenges for Certification of Neural Networks**
2309.11196v1 by Marta Kwiatkowska, Xiyue Zhang

Artificial intelligence (AI) has been advancing at a fast pace and it is now
poised for deployment in a wide range of applications, such as autonomous
systems, medical diagnosis and natural language processing. Early adoption of
AI technology for real-world applications has not been without problems,
particularly for neural networks, which may be unstable and susceptible to
adversarial examples. In the longer term, appropriate safety assurance
techniques need to be developed to reduce potential harm due to avoidable
system failures and ensure trustworthiness. Focusing on certification and
explainability, this paper provides an overview of techniques that have been
developed to ensure safety of AI decisions and discusses future challenges.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å·²å¿«éé²æ­¥ï¼ç¾å·²æºåé¨ç½²æ¼å»£æ³çæç¨ç¨å¼ä¸­ï¼ä¾å¦èªä¸»ç³»çµ±ãé«çè¨ºæ·åèªç¶èªè¨èçãåæ©æ¡ç¨ AI æè¡æ¼å¯¦éæç¨ç¨å¼ä¸¦éæ²æåé¡ï¼ç¹å¥æ¯å°æ¼ç¥ç¶ç¶²è·¯ï¼å®å¯è½ä¸ç©©å®ä¸å®¹æåå°å°ææ§ç¯ä¾çå½±é¿ãå¾é·é ä¾çï¼éè¦éç¼é©ç¶çå®å¨ä¿è­æè¡ï¼ä»¥æ¸å°å å¯é¿åçç³»çµ±æéèé æçæ½å¨å·å®³ï¼ä¸¦ç¢ºä¿å¯ä¿¡è³´æ§ãæ¬æèéæ¼èªè­åå¯è§£éæ§ï¼æ¦è¿°äºå·²éç¼ç¨æ¼ç¢ºä¿ AI æ±ºç­å®å¨çæè¡ï¼ä¸¦è¨è«æªä¾çææ°ã

##### **Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**
2309.10424v1 by Juan M. GarcÃ­a-GÃ³mez, Vicent Blanes-Selva, JosÃ© Carlos de BartolomÃ© Cenzano, Jaime Cebolla-Cornejo, AscensiÃ³n DoÃ±ate-MartÃ­nez

The Directorate General for Parliamentary Research Services of the European
Parliament has prepared a report to the Members of the European Parliament
where they enumerate seven main risks of Artificial Intelligence (AI) in
medicine and healthcare: patient harm due to AI errors, misuse of medical AI
tools, bias in AI and the perpetuation of existing inequities, lack of
transparency, privacy and security issues, gaps in accountability, and
obstacles in implementation.
  In this study, we propose fourteen functional requirements that AI systems
may implement to reduce the risks associated with their medical purpose: AI
passport, User management, Regulation check, Academic use only disclaimer, data
quality assessment, Clinicians double check, Continuous performance evaluation,
Audit trail, Continuous usability test, Review of retrospective/simulated
cases, Bias check, eXplainable AI, Encryption and use of field-tested
libraries, and Semantic interoperability.
  Our intention here is to provide specific high-level specifications of
technical solutions to ensure continuous good performance and use of AI systems
to benefit patients in compliance with the future EU regulatory framework.

æè¦ï¼æ­æ´²è­°æè­°æç ç©¶æåç¸½å±å·²çºæ­æ´²è­°æè­°å¡æºåäºä¸ä»½å ±åï¼å¶ä¸­åèäºäººå·¥æºè½ (AI) å¨é«çä¿å¥é åçä¸é ä¸»è¦é¢¨éªï¼AI é¯èª¤å°è´æ£èåå°å·å®³ãé«ç AI å·¥å·è¢«æ¿«ç¨ãAI å­å¨åè¦ä¸¦å°è´ç¾æ inequities æçºå­å¨ãç¼ºä¹éæåº¦ãé±ç§åå®å¨åé¡ãåè²¬å·®è·ä»¥åå¯¦æ½éç¤ã
  å¨éé ç ç©¶ä¸­ï¼æåæåºäºååé åè½æ§è¦æ±ï¼AI ç³»çµ±å¯ä»¥å¯¦æ½éäºè¦æ±ä¾éä½èå¶é«çç®çç¸éçé¢¨éªï¼AI è­·ç§ãä½¿ç¨èç®¡çãæ³è¦æª¢æ¥ãåéå­¸è¡ç¨éåè²¬è²æãè³æåè³ªè©ä¼°ãè¨åºé«çééæª¢æ¥ãæçºæè½è©ä¼°ãç¨½æ ¸è¿½è¹¤ãæçºå¯ç¨æ§æ¸¬è©¦ãåé¡§åæº¯/æ¨¡æ¬æ¡ä¾ãåè¦æª¢æ¥ãå¯è§£é AIãå å¯åä½¿ç¨ç¶éå¯¦å°æ¸¬è©¦çç¨å¼åº«ï¼ä»¥åèªæäºéæ§ã
  æåå¨æ­¤çç®çæ¯æä¾æè¡è§£æ±ºæ¹æ¡çç¹å®é«éè¦æ ¼ï¼ä»¥ç¢ºä¿æçºè¯å¥½çæè½ï¼ä¸¦ä½¿ç¨ AI ç³»çµ±ï¼ä»¥ç¬¦åæªä¾çæ­çæ³è¦æ¶æ§ï¼å¾èä½¿æ£èåçã

##### **QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**
2309.10293v3 by Thanveer Shaik, Xiaohui Tao, Haoran Xie, Lin Li, Juan D. Velasquez, Niall Higgins

Artificial Intelligence techniques can be used to classify a patient's
physical activities and predict vital signs for remote patient monitoring.
Regression analysis based on non-linear models like deep learning models has
limited explainability due to its black-box nature. This can require
decision-makers to make blind leaps of faith based on non-linear model results,
especially in healthcare applications. In non-invasive monitoring, patient data
from tracking sensors and their predisposing clinical attributes act as input
features for predicting future vital signs. Explaining the contributions of
various features to the overall output of the monitoring application is
critical for a clinician's decision-making. In this study, an Explainable AI
for Quantitative analysis (QXAI) framework is proposed with post-hoc model
explainability and intrinsic explainability for regression and classification
tasks in a supervised learning approach. This was achieved by utilizing the
Shapley values concept and incorporating attention mechanisms in deep learning
models. We adopted the artificial neural networks (ANN) and attention-based
Bidirectional LSTM (BiLSTM) models for the prediction of heart rate and
classification of physical activities based on sensor data. The deep learning
models achieved state-of-the-art results in both prediction and classification
tasks. Global explanation and local explanation were conducted on input data to
understand the feature contribution of various patient data. The proposed QXAI
framework was evaluated using PPG-DaLiA data to predict heart rate and mobile
health (MHEALTH) data to classify physical activities based on sensor data.
Monte Carlo approximation was applied to the framework to overcome the time
complexity and high computation power requirements required for Shapley value
calculations.

æè¦ï¼äººå·¥æºæ§æè¡å¯ç¨æ¼åé¡çæ£çèº«é«æ´»åä¸¦é æ¸¬é è·çæ£ç£æ§çéè¦çå½å¾µè±¡ãåºæ¼æ·±åº¦å­¸ç¿æ¨¡åç­éç·æ§æ¨¡åçåæ­¸åæç±æ¼å¶é»çå­çæ§è³ªèå·ææéçå¯è§£éæ§ãéå¯è½éè¦æ±ºç­èæ ¹æéç·æ§æ¨¡åçµæååºç²ç®çä¿¡ä»°é£èºï¼ç¹å¥æ¯å¨é«çä¿å¥æç¨ä¸­ãå¨éä¾µå¥æ§ç£æ§ä¸­ï¼ä¾èªè¿½è¹¤ææ¸¬å¨åå¶ææè¨åºå±¬æ§ççæ£è³æåç¶é æ¸¬æªä¾çå½å¾µè±¡çè¼¸å¥ç¹å¾µãè§£éåç¨®ç¹å¾µå°ç£æ§æç¨ç¨å¼æ´é«è¼¸åºçè²¢ç»å°æ¼è¨åºé«ççæ±ºç­è³ééè¦ãå¨æ¬ç ç©¶ä¸­ï¼æåºäºä¸åç¨æ¼éååæçå¯è§£éäººå·¥æºæ§ (QXAI) æ¶æ§ï¼è©²æ¶æ§å·æç£ç£å¼å­¸ç¿æ¹æ³ä¸­åæ­¸ååé¡ä»»åçäºå¾æ¨¡åå¯è§£éæ§åå§å¨å¯è§£éæ§ãéééå©ç¨ Shapley å¼æ¦å¿µä¸¦å°æ³¨æåæ©å¶ç´å¥æ·±åº¦å­¸ç¿æ¨¡åä¾å¯¦ç¾ãæåæ¡ç¨äººå·¥ç¥ç¶ç¶²è·¯ (ANN) ååºæ¼æ³¨æåçéå LSTM (BiLSTM) æ¨¡åï¼æ ¹æææ¸¬å¨è³æé æ¸¬å¿çååé¡èº«é«æ´»åãæ·±åº¦å­¸ç¿æ¨¡åå¨é æ¸¬ååé¡ä»»åä¸­é½åå¾äºæåé²çææãå°è¼¸å¥è³æé²è¡å¨å±è§£éåå±é¨è§£éï¼ä»¥äºè§£åç¨®çæ£è³æçç¹å¾µè²¢ç»ãææåºç QXAI æ¶æ§ä½¿ç¨ PPG-DaLiA è³æè©ä¼°ï¼ä»¥é æ¸¬å¿çï¼ä¸¦ä½¿ç¨è¡åå¥åº· (MHEALTH) è³ææ ¹æææ¸¬å¨è³æå°èº«é«æ´»åé²è¡åé¡ãèå°å¡ç¾è¿ä¼¼æ³æç¨æ¼è©²æ¶æ§ï¼ä»¥åæ Shapley å¼è¨ç®æéçæéè¤éåº¦åé«éç®è½åéæ±ã

##### **Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**
2309.09917v1 by Adarsa Sivaprasad, Ehud Reiter, Nava Tintarev, Nir Oren

In explainable artificial intelligence (XAI) research, the predominant focus
has been on interpreting models for experts and practitioners. Model agnostic
and local explanation approaches are deemed interpretable and sufficient in
many applications. However, in domains like healthcare, where end users are
patients without AI or domain expertise, there is an urgent need for model
explanations that are more comprehensible and instil trust in the model's
operations. We hypothesise that generating model explanations that are
narrative, patient-specific and global(holistic of the model) would enable
better understandability and enable decision-making. We test this using a
decision tree model to generate both local and global explanations for patients
identified as having a high risk of coronary heart disease. These explanations
are presented to non-expert users. We find a strong individual preference for a
specific type of explanation. The majority of participants prefer global
explanations, while a smaller group prefers local explanations. A task based
evaluation of mental models of these participants provide valuable feedback to
enhance narrative global explanations. This, in turn, guides the design of
health informatics systems that are both trustworthy and actionable.

æè¦ï¼å¨å¯è§£éäººå·¥æºè½ (XAI) ç ç©¶ä¸­ï¼ä¸»è¦éç¹å¨äºä¸ºä¸å®¶åä»ä¸èè§£éæ¨¡åãæ¨¡åä¸å¯ç¥åå±é¨è§£éæ¹æ³å¨è®¸å¤åºç¨ä¸­è¢«è®¤ä¸ºæ¯å¯è§£éä¸è¶³å¤çãç¶èï¼å¨å»çä¿å¥ç­é¢åï¼æç»ç¨æ·æ¯ç¼ºä¹äººå·¥æºè½æé¢åä¸ä¸ç¥è¯çæ£èï¼å æ­¤è¿«åéè¦æ´æäºçè§£ä¸è½æ¿åå¯¹æ¨¡åæä½çä¿¡ä»»çæ¨¡åè§£éãæä»¬åè®¾çæåè¿°æ§ãæ£èç¹å®ä¸å¨å±ï¼æ¨¡åæ´ä½ï¼çæ¨¡åè§£éå°è½å¤æé«å¯çè§£æ§å¹¶æ¯æå³ç­å¶å®ãæä»¬ä½¿ç¨å³ç­æ æ¨¡åå¯¹æ­¤è¿è¡æµè¯ï¼ä¸ºè¢«è¯å«ä¸ºæ£æå å¿çé«é£é©çæ£èçæå±é¨åå¨å±è§£éãè¿äºè§£éä¼åç°ç»éä¸å®¶ç¨æ·ãæä»¬åç°ç¨æ·å¼ºçåå¥½ç¹å®ç±»åçè§£éãå¤§å¤æ°åä¸èåå¥½å¨å±è§£éï¼èè¾å°çä¸ç»åä¸èåå¥½å±é¨è§£éãåºäºä»»å¡çå¿çæ¨¡åè¯ä¼°ä¸ºè¿äºåä¸èæä¾äºæä»·å¼çåé¦ï¼ä»¥å¢å¼ºåè¿°æ§å¨å±è§£éãè¿åè¿æ¥åæå¯¼äºæ¢å¼å¾ä¿¡èµåå¯æä½çå¥åº·ä¿¡æ¯å­¦ç³»ç»çè®¾è®¡ã

##### **Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**
2308.14321v1 by Yanjun Gao, Ruizhe Li, John Caskey, Dmitriy Dligach, Timothy Miller, Matthew M. Churpek, Majid Afshar

Electronic Health Records (EHRs) and routine documentation practices play a
vital role in patients' daily care, providing a holistic record of health,
diagnoses, and treatment. However, complex and verbose EHR narratives overload
healthcare providers, risking diagnostic inaccuracies. While Large Language
Models (LLMs) have showcased their potential in diverse language tasks, their
application in the healthcare arena needs to ensure the minimization of
diagnostic errors and the prevention of patient harm. In this paper, we outline
an innovative approach for augmenting the proficiency of LLMs in the realm of
automated diagnosis generation, achieved through the incorporation of a medical
knowledge graph (KG) and a novel graph model: Dr.Knows, inspired by the
clinical diagnostic reasoning process. We derive the KG from the National
Library of Medicine's Unified Medical Language System (UMLS), a robust
repository of biomedical knowledge. Our method negates the need for
pre-training and instead leverages the KG as an auxiliary instrument aiding in
the interpretation and summarization of complex medical concepts. Using
real-world hospital datasets, our experimental results demonstrate that the
proposed approach of combining LLMs with KG has the potential to improve the
accuracy of automated diagnosis generation. More importantly, our approach
offers an explainable diagnostic pathway, edging us closer to the realization
of AI-augmented diagnostic decision support systems.

æè¦ï¼é»å­å¥åº·ç´é (EHR) åä¾è¡æä»¶è¨éå¯¦åå¨çæ£çæ¥å¸¸ç§è­·ä¸­æ®æ¼èè³ééè¦çè§è²ï¼æä¾å¥åº·ãè¨ºæ·åæ²»ççæ´é«ç´éãç¶èï¼è¤éä¸åé·ç EHR æè¿°æè®é«çä¿å¥æä¾èè¶è¼ï¼æè¨ºæ·ä¸æºç¢ºçé¢¨éªãå¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾å¶å¨åç¨®èªè¨ä»»åä¸çæ½åï¼ä½å¶å¨é«çä¿å¥é åçæç¨éè¦ç¢ºä¿å°è¨ºæ·é¯èª¤éå°æä½ï¼ä¸¦é²æ­¢çæ£åå°å·å®³ãå¨æ¬æä¸­ï¼æåæ¦è¿°ä¸ç¨®åµæ°çæ¹æ³ï¼ééæ´åé«å­¸ç¥è­åè­ (KG) åä¸ç¨®æ°ç©çåè­æ¨¡åï¼Dr.Knowsï¼éæä¾èªè¨åºè¨ºæ·æ¨çéç¨ï¼ï¼ä¾å¢å¼· LLM å¨èªååè¨ºæ·ç¢çé åçè½åãæåå¾ç¾ååå®¶é«å­¸åæ¸é¤¨ççµ±ä¸é«å­¸èªè¨ç³»çµ± (UMLS) ä¸­è¡çåº KGï¼éæ¯ä¸åå¼·å¤§ççç©é«å­¸ç¥è­å²å­åº«ãæåçåæ³å¦å®äºé åè¨ç·´çéè¦ï¼èæ¯å° KG ä½çºè¼å©å·¥å·ï¼åå©è§£éåç¸½çµè¤éçé«å­¸æ¦å¿µãä½¿ç¨çå¯¦ä¸ççé«é¢è³æéï¼æåçå¯¦é©çµæè­æï¼å° LLM è KG çµåçå»ºè­°æ¹æ³ææ½åæé«èªååè¨ºæ·ç¢ççæºç¢ºæ§ãæ´éè¦çæ¯ï¼æåçåæ³æä¾äºä¸æ¢å¯è§£éçè¨ºæ·éå¾ï¼è®æåæ´æ¥è¿å¯¦ç¾ AI å¢å¼·çè¨ºæ·æ±ºç­æ¯æ´ç³»çµ±ã

##### **Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**
2308.09380v1 by Yun Xin Teoh, Alice Othmani, Siew Li Goh, Juliana Usman, Khin Wee Lai

Existing artificial intelligence (AI) models for diagnosing knee
osteoarthritis (OA) have faced criticism for their lack of transparency and
interpretability, despite achieving medical-expert-like performance. This
opacity makes them challenging to trust in clinical practice. Recently,
explainable artificial intelligence (XAI) has emerged as a specialized
technique that can provide confidence in the model's prediction by revealing
how the prediction is derived, thus promoting the use of AI systems in
healthcare. This paper presents the first survey of XAI techniques used for
knee OA diagnosis. The XAI techniques are discussed from two perspectives: data
interpretability and model interpretability. The aim of this paper is to
provide valuable insights into XAI's potential towards a more reliable knee OA
diagnosis approach and encourage its adoption in clinical practice.

æè¦ï¼ç¾æçç¨æ¼è¨ºæ·èéª¨éç¯ç (OA) çäººå·¥æºæ§ (AI) æ¨¡åå å¶ç¼ºä¹éæåº¦åå¯è§£éæ§èåå°æ¹è©ï¼åç®¡å®åéå°äºé¡ä¼¼é«å­¸å°å®¶çè¡¨ç¾ãéç¨®ä¸éææ§ä½¿å¾å®åå¨è¨åºå¯¦åä¸­é£ä»¥è¢«ä¿¡ä»»ãæè¿ï¼å¯è§£éäººå·¥æºæ§ (XAI) å·²æçºä¸ç¨®å°éæè¡ï¼å®è½ééæ­ç¤ºé æ¸¬çæ¨å°æ¹å¼ä¾æä¾å°æ¨¡åé æ¸¬çä¿¡å¿ï¼å¾èä¿é²å¨é«çä¿å¥ä¸­ä½¿ç¨ AI ç³»çµ±ãæ¬ææä¾äºéå°èéª¨éç¯çè¨ºæ·æä½¿ç¨ç XAI æè¡çç¬¬ä¸ä»½èª¿æ¥ãXAI æè¡å¾å©åè§åº¦é²è¡è¨è«ï¼è³æå¯è§£éæ§åæ¨¡åå¯è§£éæ§ãæ¬æçç®çæ¯æä¾å° XAI å¨æ´å¯é çèéª¨éç¯çè¨ºæ·æ¹æ³ä¸­çæ½åçå¯¶è²´è¦è§£ï¼ä¸¦é¼åµå¨è¨åºå¯¦åä¸­æ¡ç¨å®ã

##### **Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**
2308.08407v1 by Munib Mesinovic, Peter Watkinson, Tingting Zhu

Recent advancements in AI applications to healthcare have shown incredible
promise in surpassing human performance in diagnosis and disease prognosis.
With the increasing complexity of AI models, however, concerns regarding their
opacity, potential biases, and the need for interpretability. To ensure trust
and reliability in AI systems, especially in clinical risk prediction models,
explainability becomes crucial. Explainability is usually referred to as an AI
system's ability to provide a robust interpretation of its decision-making
logic or the decisions themselves to human stakeholders. In clinical risk
prediction, other aspects of explainability like fairness, bias, trust, and
transparency also represent important concepts beyond just interpretability. In
this review, we address the relationship between these concepts as they are
often used together or interchangeably. This review also discusses recent
progress in developing explainable models for clinical risk prediction,
highlighting the importance of quantitative and clinical evaluation and
validation across multiple common modalities in clinical practice. It
emphasizes the need for external validation and the combination of diverse
interpretability methods to enhance trust and fairness. Adopting rigorous
testing, such as using synthetic datasets with known generative factors, can
further improve the reliability of explainability methods. Open access and
code-sharing resources are essential for transparency and reproducibility,
enabling the growth and trustworthiness of explainable research. While
challenges exist, an end-to-end approach to explainability in clinical risk
prediction, incorporating stakeholders from clinicians to developers, is
essential for success.

æè¦ï¼æè¿å¨é«çä¿å¥ä¸­çäººå·¥æºæ§æç¨é²å±é¡¯ç¤ºåºä»¤äººé£ä»¥ç½®ä¿¡çæ¿è«¾ï¼å¨è¨ºæ·åç¾çé å¾æ¹é¢è¶è¶äººé¡è¡¨ç¾ãç¶èï¼é¨èäººå·¥æºè½æ¨¡åçæ¥çè¤éï¼äººåå°å¶ä¸éææ§ãæ½å¨åå·®åå°å¯è§£éæ§çéæ±æå°ææãçºäºç¢ºä¿äººå·¥æºè½ç³»çµ±çä¿¡ä»»åå¯é æ§ï¼å°¤å¶æ¯å¨è¨åºé¢¨éªé æ¸¬æ¨¡åä¸­ï¼å¯è§£éæ§è®å¾è³ééè¦ãå¯è§£éæ§éå¸¸è¢«ç¨±çºäººå·¥æºè½ç³»çµ±æä¾å¶æ±ºç­éè¼¯ææ±ºç­æ¬èº«å°äººé¡å©çç¸éèçå¼·æåè§£éçè½åãå¨è¨åºé¢¨éªé æ¸¬ä¸­ï¼å¯è§£éæ§çå¶ä»æ¹é¢ï¼å¦å¬å¹³æ§ãåè¦ãä¿¡ä»»åéæåº¦ï¼ä¹ä»£è¡¨äºè¶è¶å¯è§£éæ§çéè¦æ¦å¿µãå¨æ¬æ¬¡å¯©æ¥ä¸­ï¼æåæ¢è¨äºéäºæ¦å¿µä¹éçéä¿ï¼å çºå®åç¶å¸¸ä¸èµ·æäºæä½¿ç¨ãæ¬å¯©æ¥éè¨è«äºçºè¨åºé¢¨éªé æ¸¬éç¼å¯è§£éæ¨¡åçææ°é²å±ï¼å¼·èª¿äºå¨è¨åºå¯¦è¸ä¸­å°å¤ç¨®å¸¸è¦æ¨¡å¼é²è¡å®éåè¨åºè©ä¼°åé©è­çéè¦æ§ãå®å¼·èª¿äºå¤é¨é©è­åå¤æ¨£åå¯è§£éæ§æ¹æ³ç¸çµåçå¿è¦æ§ï¼ä»¥å¢å¼·ä¿¡ä»»åå¬å¹³æ§ãæ¡ç¨å´æ ¼çæ¸¬è©¦ï¼ä¾å¦ä½¿ç¨å·æå·²ç¥çæå ç´ çåææ¸æéï¼å¯ä»¥é²ä¸æ­¥æé«å¯è§£éæ§æ¹æ³çå¯é æ§ãéæ¾ç²ååä»£ç¢¼å±äº«è³æºå°æ¼éæåº¦åå¯éè¤æ§è³ééè¦ï¼å¾èä¿é²å¯è§£éç ç©¶çå¢é·åå¯ä¿¡åº¦ãåç®¡å­å¨ææ°ï¼ä½å¾è¨åºé«çå°éç¼äººå¡ï¼æ¡ç¨ç«¯å°ç«¯çå¯è§£éæ§æ¹æ³å°æ¼è¨åºé¢¨éªé æ¸¬çæåè³ééè¦ã

##### **FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**
2309.12325v3 by Karim Lekadir, Aasa Feragen, Abdul Joseph Fofanah, Alejandro F Frangi, Alena Buyx, Anais Emelie, Andrea Lara, Antonio R Porras, An-Wen Chan, Arcadi Navarro, Ben Glocker, Benard O Botwe, Bishesh Khanal, Brigit Beger, Carol C Wu, Celia Cintas, Curtis P Langlotz, Daniel Rueckert, Deogratias Mzurikwao, Dimitrios I Fotiadis, Doszhan Zhussupov, Enzo Ferrante, Erik Meijering, Eva Weicken, Fabio A GonzÃ¡lez, Folkert W Asselbergs, Fred Prior, Gabriel P Krestin, Gary Collins, Geletaw S Tegenaw, Georgios Kaissis, Gianluca Misuraca, Gianna Tsakou, Girish Dwivedi, Haridimos Kondylakis, Harsha Jayakody, Henry C Woodruf, Horst Joachim Mayer, Hugo JWL Aerts, Ian Walsh, Ioanna Chouvarda, IrÃ¨ne Buvat, Isabell Tributsch, Islem Rekik, James Duncan, Jayashree Kalpathy-Cramer, Jihad Zahir, Jinah Park, John Mongan, Judy W Gichoya, Julia A Schnabel, Kaisar Kushibar, Katrine Riklund, Kensaku Mori, Kostas Marias, Lameck M Amugongo, Lauren A Fromont, Lena Maier-Hein, Leonor CerdÃ¡ Alberich, Leticia Rittner, Lighton Phiri, Linda Marrakchi-Kacem, LluÃ­s Donoso-Bach, Luis MartÃ­-BonmatÃ­, M Jorge Cardoso, Maciej Bobowicz, Mahsa Shabani, Manolis Tsiknakis, Maria A Zuluaga, Maria Bielikova, Marie-Christine Fritzsche, Marina Camacho, Marius George Linguraru, Markus Wenzel, Marleen De Bruijne, Martin G Tolsgaard, Marzyeh Ghassemi, Md Ashrafuzzaman, Melanie Goisauf, Mohammad Yaqub, MÃ³nica Cano AbadÃ­a, Mukhtar M E Mahmoud, Mustafa Elattar, Nicola Rieke, Nikolaos Papanikolaou, Noussair Lazrak, Oliver DÃ­az, Olivier Salvado, Oriol Pujol, Ousmane Sall, Pamela Guevara, Peter Gordebeke, Philippe Lambin, Pieta Brown, Purang Abolmaesumi, Qi Dou, Qinghua Lu, Richard Osuala, Rose Nakasi, S Kevin Zhou, Sandy Napel, Sara Colantonio, Shadi Albarqouni, Smriti Joshi, Stacy Carter, Stefan Klein, Steffen E Petersen, Susanna AussÃ³, Suyash Awate, Tammy Riklin Raviv, Tessa Cook, Tinashe E M Mutsvangwa, Wendy A Rogers, Wiro J Niessen, XÃ¨nia Puig-Bosch, Yi Zeng, Yunusa G Mohammed, Yves Saint James Aquino, Zohaib Salahuddin, Martijn P A Starmans

Despite major advances in artificial intelligence (AI) for medicine and
healthcare, the deployment and adoption of AI technologies remain limited in
real-world clinical practice. In recent years, concerns have been raised about
the technical, clinical, ethical and legal risks associated with medical AI. To
increase real world adoption, it is essential that medical AI tools are trusted
and accepted by patients, clinicians, health organisations and authorities.
This work describes the FUTURE-AI guideline as the first international
consensus framework for guiding the development and deployment of trustworthy
AI tools in healthcare. The FUTURE-AI consortium was founded in 2021 and
currently comprises 118 inter-disciplinary experts from 51 countries
representing all continents, including AI scientists, clinicians, ethicists,
and social scientists. Over a two-year period, the consortium defined guiding
principles and best practices for trustworthy AI through an iterative process
comprising an in-depth literature review, a modified Delphi survey, and online
consensus meetings. The FUTURE-AI framework was established based on 6 guiding
principles for trustworthy AI in healthcare, i.e. Fairness, Universality,
Traceability, Usability, Robustness and Explainability. Through consensus, a
set of 28 best practices were defined, addressing technical, clinical, legal
and socio-ethical dimensions. The recommendations cover the entire lifecycle of
medical AI, from design, development and validation to regulation, deployment,
and monitoring. FUTURE-AI is a risk-informed, assumption-free guideline which
provides a structured approach for constructing medical AI tools that will be
trusted, deployed and adopted in real-world practice. Researchers are
encouraged to take the recommendations into account in proof-of-concept stages
to facilitate future translation towards clinical practice of medical AI.

æè¦ï¼åç®¡å¨é«å­¸åé«çä¿å¥æ¹é¢çäººå·¥æºæ§ (AI) æéå¤§çé²å±ï¼ä½ AI æè¡çé¨ç½²åæ¡ç¨å¨ç¾å¯¦ä¸ççè¨åºå¯¦åä¸­ä»ç¶æéãè¿å¹´ä¾ï¼äººåå°æ¼èé«ç AI ç¸éçæè¡ãè¨åºãå«çåæ³å¾é¢¨éªæåºäºçæ®ãçºäºå¢å ç¾å¯¦ä¸ççæ¡ç¨çï¼é«ç AI å·¥å·å¿é ç²å¾æ£èãè¨åºé«çãé«çæ©æ§åç¶å±çä¿¡ä»»åæ¥åãéé å·¥ä½å° FUTURE-AI æåæè¿°çºæå°é«çä¿å¥ä¸­å¯ä¿¡è³´ AI å·¥å·éç¼åé¨ç½²çç¬¬ä¸ååéå±è­æ¶æ§ãFUTURE-AI è¯çæç«æ¼ 2021 å¹´ï¼ç®åç±ä¾èª 51 ååå®¶ç 118 ä½è·¨é åå°å®¶çµæï¼ä»£è¡¨æææ´²ï¼åæ¬ AI ç§å­¸å®¶ãè¨åºé«çãå«çå­¸å®¶åç¤¾æç§å­¸å®¶ãå¨å©å¹´çæéè£¡ï¼è©²è¯çééä¸ååè¦éç®çéç¨å®ç¾©äºå¯ä¿¡è³´ AI çæå°åååæä½³å¯¦åï¼åæ¬æ·±å¥çæç»åé¡§ãä¿®æ¹å¾çå¾·ç¾è²èª¿æ¥åç·ä¸å±è­æè­°ãFUTURE-AI æ¶æ§æ¯åºæ¼é«çä¿å¥ä¸­å¯ä¿¡è³´ AI ç 6 é æå°ååå»ºç«çï¼å³å¬å¹³æ§ãæ®éæ§ãå¯è¿½æº¯æ§ãå¯ç¨æ§ãç©©å¥æ§åå¯è§£éæ§ãééå±è­ï¼å®ç¾©äºä¸çµ 28 é æä½³å¯¦åï¼æ¶µèæè¡ãè¨åºãæ³å¾åç¤¾æå«çå±¤é¢ãå»ºè­°æ¶µèäºé«ç AI çæ´åçå½é±æï¼å¾è¨­è¨ãéç¼åé©è­å°æ³è¦ãé¨ç½²åç£æ§ãFUTURE-AI æ¯ä¸ååºæ¼é¢¨éªãç¡åè¨­çæåï¼æä¾äºä¸åçµæ§åçæ¹æ³ï¼ç¨æ¼å»ºæ§å°å¨ç¾å¯¦ä¸çå¯¦åä¸­åå°ä¿¡ä»»ãé¨ç½²åæ¡ç¨çé«ç AI å·¥å·ãé¼åµç ç©¶äººå¡å¨æ¦å¿µé©è­éæ®µèæ®éäºå»ºè­°ï¼ä»¥ä¿é²æªä¾å°é«ç AI è½åçºè¨åºå¯¦åã

##### **Explainable AI applications in the Medical Domain: a systematic review**
2308.05411v1 by Nicoletta Prentzas, Antonis Kakas, Constantinos S. Pattichis

Artificial Intelligence in Medicine has made significant progress with
emerging applications in medical imaging, patient care, and other areas. While
these applications have proven successful in retrospective studies, very few of
them were applied in practice.The field of Medical AI faces various challenges,
in terms of building user trust, complying with regulations, using data
ethically.Explainable AI (XAI) aims to enable humans understand AI and trust
its results. This paper presents a literature review on the recent developments
of XAI solutions for medical decision support, based on a representative sample
of 198 articles published in recent years. The systematic synthesis of the
relevant articles resulted in several findings. (1) model-agnostic XAI
techniques were mostly employed in these solutions, (2) deep learning models
are utilized more than other types of machine learning models, (3)
explainability was applied to promote trust, but very few works reported the
physicians participation in the loop, (4) visual and interactive user interface
is more useful in understanding the explanation and the recommendation of the
system. More research is needed in collaboration between medical and AI
experts, that could guide the development of suitable frameworks for the
design, implementation, and evaluation of XAI solutions in medicine.

æè¦ï¼äººå·¥æºæ§å¨é«çé åä¸­å·²åå¾é¡¯èé²å±ï¼å¨é«å­¸å½±åãçäººç§è­·åå¶ä»é åä¸­åºç¾äºæ°èæç¨ãéç¶éäºæç¨å·²å¨åé¡§æ§ç ç©¶ä¸­è¢«è­å¯¦æ¯æåçï¼ä½å¯¦éä¸åªææ¥µå°æ¸æç¨æ¼å¯¦åãé«ç AI é åé¢è¨èåç¨®ææ°ï¼åæ¬å»ºç«ä½¿ç¨èä¿¡ä»»ãéµå®æ³è¦ãä½¿ç¨è³æç¬¦åå«çãå¯è§£é AI (XAI) çç®æ¨æ¯è®äººé¡äºè§£ AI ä¸¦ç¸ä¿¡å¶çµæãæ¬æéå°æè¿å¹¾å¹´ç¼è¡¨ç 198 ç¯æç« çå·ä»£è¡¨æ§æ¨£æ¬ï¼æåºæéé«çæ±ºç­æ¯æ´ç XAI è§£æ±ºæ¹æ¡çææ°ç¼å±çæç»åé¡§ãç¸éæç« çç³»çµ±æ§ç¶åæ´çç¢çäºå¤é ç¼ç¾ï¼(1) éäºè§£æ±ºæ¹æ¡å¤§å¤æ¡ç¨èæ¨¡åç¡éç XAI æè¡ï¼(2) æ·±åº¦å­¸ç¿æ¨¡åçä½¿ç¨çé«æ¼å¶ä»é¡åçæ©å¨å­¸ç¿æ¨¡åï¼(3) å¯è§£éæ§è¢«ç¨æ¼ä¿é²ä¿¡ä»»ï¼ä½å¾å°æç ç©¶å ±åé«å¸«åèè¿´åï¼(4) è¦è¦ºåäºåå¼ä½¿ç¨èä»é¢å°æ¼çè§£ç³»çµ±çè§£éåå»ºè­°æ´æç¨ãéè¦æ´å¤é«çå AI å°å®¶åä½é²è¡ç ç©¶ï¼éæå©æ¼çºé«çé åç XAI è§£æ±ºæ¹æ¡çè¨­è¨ãå¯¦ä½åè©ä¼°æä¾é©ç¶æ¶æ§ã

##### **Exploring the Role of Explainability in AI-Assisted Embryo Selection**
2308.02534v1 by Lucia Urcelay, Daniel Hinjos, Pablo A. Martin-Torres, Marta Gonzalez, Marta Mendez, Salva CÃ­vico, Sergio Ãlvarez-Napagao, Dario Garcia-Gasulla

In Vitro Fertilization is among the most widespread treatments for
infertility. One of its main challenges is the evaluation and selection of
embryo for implantation, a process with large inter- and intra-clinician
variability. Deep learning based methods are gaining attention, but their
opaque nature compromises their acceptance in the clinical context, where
transparency in the decision making is key. In this paper we analyze the
current work in the explainability of AI-assisted embryo analysis models,
identifying the limitations. We also discuss how these models could be
integrated in the clinical context as decision support systems, considering the
needs of clinicians and patients. Finally, we propose guidelines for the sake
of increasing interpretability and trustworthiness, pushing this technology
forward towards established clinical practice.

æè¦ï¼é«å¤åç²¾æ¯æ²»çä¸å­çæå»£æ³çæ¹æ³ä¹ä¸ãå¶ä¸»è¦ææ°ä¹ä¸æ¯è©ä¼°åé¸æèèé²è¡æ¤å¥ï¼æ­¤éç¨å·æå¾å¤§çè¨åºéåè¨åºå§è®ç°æ§ãåºæ¼æ·±åº¦å­¸ç¿çæ¹æ³æ­£åå°éæ³¨ï¼ä½å¶ä¸éæçæ§è³ªæå½±é¿å¶å¨è¨åºç°å¢ä¸­çæ¥ååº¦ï¼èéæåº¦å¨æ±ºç­å¶å®ä¸­è³ééè¦ãå¨æ¬æä¸­ï¼æååæäº AI è¼å©èèåææ¨¡åçå¯è§£éæ§æ¹é¢çç¾æå·¥ä½ï¼ä¸¦æ¾åºå¶å±éæ§ãæåéè¨è«äºå¦ä½å°éäºæ¨¡åä½çºæ±ºç­æ¯æç³»çµ±æ´åå°è¨åºç°å¢ä¸­ï¼åæèæ®è¨åºé«çåæ£èçéæ±ãæå¾ï¼æåæåºäºæé«å¯è§£éæ§åå¯ä¿¡åº¦çæºåï¼æ¨é²éé æè¡æèæ¢å®çè¨åºå¯¦åéé²ã

##### **A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**
2307.14246v1 by Timo Speith, Markus Langer

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

æè¦ï¼å¨éæ±å·¥ç¨ (RE) é åä¸­ï¼å¯è§£éäººå·¥æºæ§ (XAI) å¨å° AI æ¯æçç³»çµ±èä½¿ç¨èéæ±ãç¤¾æææåæ³è¦æ¨æºç¸ç¬¦æ¹é¢çéè¦æ§æ¥çé¡¯èï¼å·²ç²å¾èªå¯ãä¸è¬ä¾èªªï¼å¯è§£éæ§å·²æçºå½±é¿ç³»çµ±åè³ªçéè¦éåè½éæ±ãç¶èï¼å¯è§£éæ§èæè½ä¹éçåå®æ¬è¡¡ææ°äºå¯è§£éæ§çåå®æ­£é¢å½±é¿ãå¦ææ»¿è¶³å¯è§£éæ§çéæ±éè¦éä½ç³»çµ±æè½ï¼é£éº¼å¿é ä»ç´°èæ®éäºåè³ªé¢åä¸­åªä¸ååªåï¼ä»¥åå¦ä½å¨å®åä¹éé²è¡æè¡·ãå¨æ¬æä¸­ï¼æåæ¹å¤æ§å°æ¢è¨äºéç¨®åå®çæ¬è¡¡ãæåèªçºï¼æå¥½çæ¹æ³æ¯ä»¥ä¸ç¨®ç´°ç·»çæ¹å¼ä¾èçï¼éç¨®æ¹å¼åå«è³æºå¯ç¨æ§ãé åç¹æ§åé¢¨éªèéãééæä¾æªä¾ç ç©¶åæä½³å¯¦åçåºç¤ï¼éé å·¥ä½æ¨å¨æå AI ç RE é åã

##### **Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**
2307.14239v1 by Barnaby Crook, Maximilian SchlÃ¼ter, Timo Speith

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

æè¦ï¼å¨éæ±å·¥ç¨ï¼REï¼é¢åï¼å¯è§£éäººå·¥æºè½ï¼XAIï¼å¨å°äººå·¥æºè½æ¯æçç³»ç»ä¸ç¨æ·éæ±ãç¤¾ä¼ææåçç®¡æ åç¸ä¸è´æ¹é¢çéè¦æ§æ¥çå¸æ¾ï¼å¹¶è·å¾äºè®¤å¯ãä¸è¬æ¥è¯´ï¼å¯è§£éæ§å·²æä¸ºå½±åç³»ç»è´¨éçéè¦éåè½æ§éæ±ãç¶èï¼å¯è§£éæ§åæ§è½ä¹é´çæè¡¡ææäºå¯è§£éæ§çæ­£é¢å½±åãå¦ææ»¡è¶³å¯è§£éæ§çè¦æ±éè¦éä½ç³»ç»æ§è½ï¼é£ä¹å¿é¡»ä»ç»èèè¿äºè´¨éæ¹é¢ä¸­çåªä¸ä¸ªä¼åï¼ä»¥åå¦ä½å¨å®ä»¬ä¹é´è¿è¡æè¡¡ãå¨æ¬æä¸­ï¼æä»¬æ¹å¤æ§å°èå¯äºæè°çæè¡¡ãæä»¬è®¤ä¸ºï¼æå¥½ä»¥ä¸ç§ç»è´å¥å¾®çæ¹å¼æ¥å¤çå®ï¼è¿ç§æ¹å¼ç»åäºèµæºå¯ç¨æ§ãé¢åç¹å¾åé£é©èèãéè¿ä¸ºæªæ¥çç ç©¶åæä½³å®è·µæä¾åºç¡ï¼è¿é¡¹å·¥ä½æ¨å¨æ¨è¿äººå·¥æºè½ç RE é¢åã

##### **Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough**
2308.02047v1 by Henry Fraser, Jose-Miguel Bello y Villarino

This paper critically evaluates the European Commission's proposed AI Act's
approach to risk management and risk acceptability for high-risk AI systems
that pose risks to fundamental rights and safety. The Act aims to promote
"trustworthy" AI with a proportionate regulatory burden. Its provisions on risk
acceptability require residual risks from high-risk systems to be reduced or
eliminated "as far as possible", having regard to the "state of the art". This
criterion, especially if interpreted narrowly, is unworkable and promotes
neither proportionate regulatory burden, nor trustworthiness. By contrast the
Parliament's most recent draft amendments to the risk management provisions
introduce "reasonableness", cost-benefit analysis, and are more transparent
about the value-laden and contextual nature of risk acceptability judgements.
This paper argues that the Parliament's approach is more workable, and better
balances the goals of proportionality and trustworthiness. It explains what
reasonableness in risk acceptability judgments would entail, drawing on
principles from negligence law and European medical devices regulation. And it
contends that the approach to risk acceptability judgments need a firm
foundation of civic legitimacy: including detailed guidance or involvement from
regulators, and meaningful input from affected stakeholders.

æè¦ï¼æ¬æå´æ ¼è©ä¼°æ­æ´²å§å¡ææåºç AI æ³æ¡å°é¢¨éªç®¡çåé¢¨éªå¯æ¥åæ§çæ¹æ³ï¼ç¨æ¼å°åºæ¬æ¬å©åå®å¨æ§æé¢¨éªçé«é¢¨éª AI ç³»çµ±ãè©²æ³æ¡æ¨å¨ä»¥ç¸ç¨±çç£ç®¡è² æä¿é²ãå¼å¾ä¿¡è³´ãç AIãå¶éæ¼é¢¨éªå¯æ¥åæ§çæ¢æ¬¾è¦æ±å°é«é¢¨éªç³»çµ±çæ®é¤é¢¨éªæ¸ä½ææ¶é¤ãç¡å¯è½ãï¼ä¸¦èæ®ãæè¡çæããæ­¤æºåï¼ç¹å¥æ¯å¦æç¹ç¾©è§£éï¼ç¡æ³å·è¡ï¼æ¢ä¸ä¿é²ç¸ç¨±çç£ç®¡è² æï¼ä¹ä¸ä¿é²å¯ä¿¡è³´æ§ãç¸æ¯ä¹ä¸ï¼è­°æå°é¢¨éªç®¡çæ¢æ¬¾çææ°ä¿®æ­£èæ¡å¼å¥äºãåçæ§ããææ¬æçåæï¼ä¸¦ä¸æ´éæå°èªªæäºé¢¨éªå¯æ¥åæ§å¤æ·çå¹å¼è§åèæ¯æ§è³ªãæ¬æè«è­è­°æçæ¹æ³æ´å¯è¡ï¼ä¸è½æ´å¥½å°å¹³è¡¡ç¸ç¨±æ§åå¯ä¿¡è³´æ§çç®æ¨ãæ¬æèªªæé¢¨éªå¯æ¥åæ§å¤æ·ä¸­çåçæ§æå¸¶ä¾ä»éº¼ï¼ä¸¦æ ¹æéå¤±æ³åæ­æ´²é«çå¨ææ³è¦ä¸­çååé²è¡èªªæãæ¬æä¸»å¼µé¢¨éªå¯æ¥åæ§å¤æ·çæ¹æ³éè¦ç©©åºçå¬æ°åæ³æ§åºç¤ï¼åæ¬ç£ç®¡æ©æ§çè©³ç´°æå°æåèï¼ä»¥ååå½±é¿å©å®³éä¿äººçææç¾©æå¥ã

##### **eXplainable Artificial Intelligence (XAI) in aging clock models**
2307.13704v3 by Alena Kalyakulina, Igor Yusipov, Alexey Moskalev, Claudio Franceschi, Mikhail Ivanchenko

eXplainable Artificial Intelligence (XAI) is a rapidly progressing field of
machine learning, aiming to unravel the predictions of complex models. XAI is
especially required in sensitive applications, e.g. in health care, when
diagnosis, recommendations and treatment choices might rely on the decisions
made by artificial intelligence systems. AI approaches have become widely used
in aging research as well, in particular, in developing biological clock models
and identifying biomarkers of aging and age-related diseases. However, the
potential of XAI here awaits to be fully appreciated. We discuss the
application of XAI for developing the "aging clocks" and present a
comprehensive analysis of the literature categorized by the focus on particular
physiological systems.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) æ¯æ©å¨å­¸ç¿ä¸­å¿«éé²å±çé åï¼æ¨å¨è§£éè¤éæ¨¡åçé æ¸¬ãXAI å¨æææç¨ä¸­ç¹å¥éè¦ï¼ä¾å¦å¨é«çä¿å¥ä¸­ï¼ç¶è¨ºæ·ãå»ºè­°åæ²»çé¸æå¯è½ä¾è³´æ¼äººå·¥æºæ§ç³»çµ±ååºçæ±ºç­æãäººå·¥æºæ§æ¹æ³ä¹å·²å»£æ³ç¨æ¼èåç ç©¶ï¼ç¹å¥æ¯å¨éç¼çç©æéæ¨¡ååè­å¥èååèå¹´é½¡ç¸éç¾çççç©æ¨èªç©æ¹é¢ãç¶èï¼éè£¡ XAI çæ½åæå¾ååèªè­ãæåè¨è«äº XAI å¨éç¼ãèåæéãæ¹é¢çæç¨ï¼ä¸¦å°æç¹å®ççç³»çµ±çéé»åé¡çæç»é²è¡äºå¨é¢çåæã

##### **Interpreting and Correcting Medical Image Classification with PIP-Net**
2307.10404v2 by Meike Nauta, Johannes H. Hegeman, Jeroen Geerdink, JÃ¶rg SchlÃ¶tterer, Maurice van Keulen, Christin Seifert

Part-prototype models are explainable-by-design image classifiers, and a
promising alternative to black box AI. This paper explores the applicability
and potential of interpretable machine learning, in particular PIP-Net, for
automated diagnosis support on real-world medical imaging data. PIP-Net learns
human-understandable prototypical image parts and we evaluate its accuracy and
interpretability for fracture detection and skin cancer diagnosis. We find that
PIP-Net's decision making process is in line with medical classification
standards, while only provided with image-level class labels. Because of
PIP-Net's unsupervised pretraining of prototypes, data quality problems such as
undesired text in an X-ray or labelling errors can be easily identified.
Additionally, we are the first to show that humans can manually correct the
reasoning of PIP-Net by directly disabling undesired prototypes. We conclude
that part-prototype models are promising for medical applications due to their
interpretability and potential for advanced model debugging.

æè¦ï¼é¨åååæ¨¡åæ¯å¯è§£éè¨­è¨çå½±ååé¡å¨ï¼ä¹æ¯é»ç®± AI çä¸åæåéçæ¿ä»£æ¹æ¡ãéç¯è«ææ¢è¨äºè§£éæ§æ©å¨å­¸ç¿ï¼ç¹å¥æ¯ PIP-Netï¼å¨çå¯¦ä¸çé«å­¸å½±åè³æä¸èªååè¨ºæ·æ¯æ´çé©ç¨æ§åæ½åãPIP-Net å­¸ç¿äººé¡å¯çè§£çååå½±åé¨åï¼æåè©ä¼°å¶å¨éª¨ææª¢æ¸¬åç®èçè¨ºæ·æ¹é¢çæºç¢ºæ§åå¯è§£éæ§ãæåç¼ç¾ PIP-Net çæ±ºç­å¶å®éç¨ç¬¦åé«å­¸åé¡æ¨æºï¼åæåæä¾å½±åå±¤ç´é¡å¥æ¨ç±¤ãç±æ¼ PIP-Net å°ååçç¡ç£ç£é è¨ç·´ï¼å æ­¤å¯ä»¥è¼é¬è­å¥è³æåè³ªåé¡ï¼ä¾å¦ X åä¸­çä¸éè¦æå­ææ¨ç±¤é¯èª¤ãæ­¤å¤ï¼æåé¦æ¬¡å±ç¤ºäººé¡å¯ä»¥ééç´æ¥åç¨ä¸éè¦çååä¾æåä¿®æ­£ PIP-Net çæ¨çãæåå¾åºçµè«ï¼é¨åååæ¨¡åç±æ¼å¶å¯è§£éæ§åé²éæ¨¡åé¤é¯çæ½åï¼å æ­¤æææç¨æ¼é«çã

##### **Explaining and visualizing black-box models through counterfactual paths**
2307.07764v3 by Bastian Pfeifer, Mateusz Krzyzinski, Hubert Baniecki, Anna Saranti, Andreas Holzinger, Przemyslaw Biecek

Explainable AI (XAI) is an increasingly important area of machine learning
research, which aims to make black-box models transparent and interpretable. In
this paper, we propose a novel approach to XAI that uses the so-called
counterfactual paths generated by conditional permutations of features. The
algorithm measures feature importance by identifying sequential permutations of
features that most influence changes in model predictions. It is particularly
suitable for generating explanations based on counterfactual paths in knowledge
graphs incorporating domain knowledge. Counterfactual paths introduce an
additional graph dimension to current XAI methods in both explaining and
visualizing black-box models. Experiments with synthetic and medical data
demonstrate the practical applicability of our approach.

æè¦ï¼å¯è§£é AI (XAI) æ¯æ©å¨å­¸ç¿ç ç©¶ä¸­æ¥çéè¦çé åï¼å¶ç®æ¨æ¯è®é»ç®±æ¨¡åéæä¸å¯è§£éãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°ç XAI æ¹æ³ï¼è©²æ¹æ³ä½¿ç¨ç±ç¹å¾µæ¢ä»¶ç½®æç¢ççæè¬åäºå¯¦è·¯å¾ãè©²æ¼ç®æ³ééè­å¥ç¹å¾µçé åºç½®æä¾è¡¡éç¹å¾µéè¦æ§ï¼éäºç½®ææè½å½±é¿æ¨¡åé æ¸¬çè®åãå®ç¹å¥é©åæ ¹æåå«é åç¥è­çç¥è­åè­ä¸­çåäºå¯¦è·¯å¾ä¾ç¢çè§£éãåäºå¯¦è·¯å¾å¨è§£éåè¦è¦ºåé»ç®±æ¨¡åæï¼çºç®åç XAI æ¹æ³å¼å¥äºé¡å¤çåå½¢ç¶­åº¦ãä½¿ç¨åæåé«çè³æé²è¡çå¯¦é©è­æäºæåæ¹æ³çå¯¦ç¨é©ç¨æ§ã

##### **Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research**
2307.02131v5 by Toygar Tanyel, Serkan Ayvaz, Bilgin Keserci

The field of explainability in artificial intelligence (AI) has witnessed a
growing number of studies and increasing scholarly interest. However, the lack
of human-friendly and individual interpretations in explaining the outcomes of
machine learning algorithms has significantly hindered the acceptance of these
methods by clinicians in their research and clinical practice. To address this
issue, our study uses counterfactual explanations to explore the applicability
of "what if?" scenarios in medical research. Our aim is to expand our
understanding of magnetic resonance imaging (MRI) features used for diagnosing
pediatric posterior fossa brain tumors beyond existing boundaries. In our case
study, the proposed concept provides a novel way to examine alternative
decision-making scenarios that offer personalized and context-specific
insights, enabling the validation of predictions and clarification of
variations under diverse circumstances. Additionally, we explore the potential
use of counterfactuals for data augmentation and evaluate their feasibility as
an alternative approach in our medical research case. The results demonstrate
the promising potential of using counterfactual explanations to enhance
acceptance of AI-driven methods in clinical research.

æè¦ï¼å¨äººå·¥æºè½ (AI) çå¯è§£éæ§é åä¸­ï¼å·²ç¶çå°è¶ä¾è¶å¤çç ç©¶åå­¸è¡èè¶£ãç¶èï¼å¨è§£éæ©å¨å­¸ç¿æ¼ç®æ³ççµææç¼ºä¹äººæ§åååäººåçè©®éï¼éé¡¯èé»ç¤äºè¨åºé«çå¨ç ç©¶åè¨åºå¯¦åä¸­æ¥åéäºæ¹æ³ãçºäºè§£æ±ºéååé¡ï¼æåçç ç©¶ä½¿ç¨åäºå¯¦è§£éä¾æ¢è¨ãå¦æï¼ãæå¢å¨é«å­¸ç ç©¶ä¸­çé©ç¨æ§ãæåçç®æ¨æ¯æ´å±æåå°ç¨æ¼è¨ºæ·å°åå¾é¡±çª©è¦è«ç¤çç£å±æ¯æå (MRI) ç¹å¾µççè§£ï¼è¶è¶ç¾æççç·ãå¨æåçæ¡ä¾ç ç©¶ä¸­ï¼ææåºçæ¦å¿µæä¾äºä¸ç¨®æ°ç©çæ¹æ³ä¾æª¢è¦æ¿ä»£æ±ºç­æå¢ï¼æä¾åäººååç¹å®æ¼æå¢çè¦è§£ï¼å¾èè½å¤ é©è­é æ¸¬ä¸¦éæ¸å¨ä¸åææ³ä¸çå·®ç°ãæ­¤å¤ï¼æåæ¢è¨äºåäºå¯¦ç¨æ¼è³ææ´åçæ½å¨ç¨éï¼ä¸¦è©ä¼°å¶ä½çºæåé«å­¸ç ç©¶æ¡ä¾ä¸­æ¿ä»£æ¹æ³çå¯è¡æ§ãçµæè­æäºä½¿ç¨åäºå¯¦è§£éä¾å¢å¼·è¨åºç ç©¶ä¸­ AI é©åæ¹æ³çæ¥ååº¦çæ½åã

##### **AI and Non AI Assessments for Dementia**
2307.01210v1 by Mahboobeh Parsapoor, Hamed Ghodrati, Vincenzo Dentamaro, Christopher R. Madan, Ioulietta Lazarou, Spiros Nikolopoulos, Ioannis Kompatsiaris

Current progress in the artificial intelligence domain has led to the
development of various types of AI-powered dementia assessments, which can be
employed to identify patients at the early stage of dementia. It can
revolutionize the dementia care settings. It is essential that the medical
community be aware of various AI assessments and choose them considering their
degrees of validity, efficiency, practicality, reliability, and accuracy
concerning the early identification of patients with dementia (PwD). On the
other hand, AI developers should be informed about various non-AI assessments
as well as recently developed AI assessments. Thus, this paper, which can be
readable by both clinicians and AI engineers, fills the gap in the literature
in explaining the existing solutions for the recognition of dementia to
clinicians, as well as the techniques used and the most widespread dementia
datasets to AI engineers. It follows a review of papers on AI and non-AI
assessments for dementia to provide valuable information about various dementia
assessments for both the AI and medical communities. The discussion and
conclusion highlight the most prominent research directions and the maturity of
existing solutions.

æè¦ï¼ç®åäººå·¥æºè½é åçé²å±å°è´äºåç¨®é¡åçäººå·¥æºæ§é©åçå¤±æºçè©ä¼°çç¼å±ï¼å¯ç¨æ¼è­å¥èæ¼å¤±æºçæ©æéæ®µçæ£èãå®å¯ä»¥å¾¹åºæ¹è®å¤±æºçè­·çè¨­ç½®ãéè¦çæ¯ï¼é«ççè¦äºè§£åç¨®äººå·¥æºè½è©ä¼°ï¼ä¸¦æ ¹æå¶æææ§ãæçãå¯¦ç¨æ§ãå¯é æ§åæºç¢ºæ§ç¨åº¦ï¼èæ®é¸æå®åä¾æ©æè­å¥å¤±æºçæ£è (PwD)ãå¦ä¸æ¹é¢ï¼äººå·¥æºè½éç¼äººå¡ä¹æè©²äºè§£åç¨®éäººå·¥æºè½è©ä¼°ä»¥åæè¿éç¼çäººå·¥æºè½è©ä¼°ãå æ­¤ï¼éç¯è¨åºé«çåäººå·¥æºè½å·¥ç¨å¸«é½å¯ä»¥é±è®çè«æå¡«è£äºæç»ä¸­éæ¼åè¨åºé«çè§£éç¾æå¤±æºçè­å¥è§£æ±ºæ¹æ¡ä»¥ååäººå·¥æºè½å·¥ç¨å¸«è§£éæç¨æè¡åæå»£æ³çå¤±æºçæ¸æéçç©ºç½ãå®éµå¾ªå°äººå·¥æºè½åéäººå·¥æºè½å¤±æºçè©ä¼°è«æçåé¡§ï¼çºäººå·¥æºè½åé«ççæä¾æéåç¨®å¤±æºçè©ä¼°çå¯¶è²´ä¿¡æ¯ãè¨è«åçµè«éé»ä»ç´¹äºæçªåºçç ç©¶æ¹ååç¾æè§£æ±ºæ¹æ¡çæçåº¦ã

##### **Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation**
2306.07306v1 by Ruitao Xie, Jingbang Chen, Limai Jiang, Rui Xiao, Yi Pan, Yunpeng Cai

Explainability poses a major challenge to artificial intelligence (AI)
techniques. Current studies on explainable AI (XAI) lack the efficiency of
extracting global knowledge about the learning task, thus suffer deficiencies
such as imprecise saliency, context-aware absence and vague meaning. In this
paper, we propose the class association embedding (CAE) approach to address
these issues. We employ an encoder-decoder architecture to embed sample
features and separate them into class-related and individual-related style
vectors simultaneously. Recombining the individual-style code of a given sample
with the class-style code of another leads to a synthetic sample with preserved
individual characters but changed class assignment, following a cyclic
adversarial learning strategy. Class association embedding distills the global
class-related features of all instances into a unified domain with well
separation between classes. The transition rules between different classes can
be then extracted and further employed to individual instances. We then propose
an active XAI framework which manipulates the class-style vector of a certain
sample along guided paths towards the counter-classes, resulting in a series of
counter-example synthetic samples with identical individual characters.
Comparing these counterfactual samples with the original ones provides a
global, intuitive illustration to the nature of the classification tasks. We
adopt the framework on medical image classification tasks, which show that more
precise saliency maps with powerful context-aware representation can be
achieved compared with existing methods. Moreover, the disease pathology can be
directly visualized via traversing the paths in the class-style space.

æè¦ï¼<paragraph>å¯è§£éæ§å°äººå·¥æºæ§ (AI) æè¡æ§æä¸é éå¤§ææ°ãç¶åå°å¯è§£é AI (XAI) çç ç©¶ç¼ºä¹æåå­¸ç¿ä»»åæ´é«ç¥è­çæçï¼å æ­¤å­å¨ä¸ç²¾ç¢ºçé¡¯èæ§ãèæå¢ç¡éçç¼ºå¤±åå«ç³æç¾©ç­ç¼ºé·ãå¨æ¬æä¸­ï¼æåæåºé¡å¥éè¯åµå¥ (CAE) æ¹æ³ä¾è§£æ±ºéäºåé¡ãæåæ¡ç¨ç·¨ç¢¼å¨-è§£ç¢¼å¨æ¶æ§ä¾åµå¥æ¨£æ¬ç¹å¾µï¼ä¸¦åæå°å®ååçºé¡å¥ç¸éååé«ç¸éçæ¨£å¼åéãå°çµ¦å®æ¨£æ¬çåé«æ¨£å¼ä»£ç¢¼èå¦ä¸åæ¨£æ¬çé¡å¥æ¨£å¼ä»£ç¢¼éæ°çµåï¼æç¢çä¸åå·æä¿çåé«ç¹å¾µä½æ¹è®é¡å¥åéçåææ¨£æ¬ï¼éµå¾ªå¾ªç°å°æå­¸ç¿ç­ç¥ãé¡å¥éè¯åµå¥å°ææå¯¦ä¾çå¨å±é¡å¥ç¸éç¹å¾µæçå°ä¸åçµ±ä¸çé åä¸­ï¼ä¸¦å¨é¡å¥ä¹éæè¯å¥½çååãç¶å¾å¯ä»¥æåä¸åé¡å¥ä¹éçè½æè¦åï¼ä¸¦é²ä¸æ­¥æç¨æ¼åå¥å¯¦ä¾ãç¶å¾ï¼æåæåºä¸åä¸»å XAI æ¡æ¶ï¼å®æ²¿èå¼å°è·¯å¾æä½ç¹å®æ¨£æ¬çé¡å¥æ¨£å¼åéï¼æèåé¡å¥ç§»åï¼å¾èç¢çä¸ç³»åå·æç¸ååé«ç¹å¾µçåä¾åææ¨£æ¬ãå°éäºåäºå¯¦æ¨£æ¬èåå§æ¨£æ¬é²è¡æ¯è¼ï¼å¯ä»¥å°åé¡ä»»åçæ§è³ªæä¾å¨å±ãç´è§çèªªæãæåæ¡ç¨è©²æ¡æ¶é²è¡é«å­¸å½±ååé¡ä»»åï¼çµæè¡¨æï¼èç¾ææ¹æ³ç¸æ¯ï¼å¯ä»¥ç²å¾æ´ç²¾ç¢ºçé¡¯èæ§åï¼ä¸¦å·æå¼·å¤§çèæå¢ç¡éçè¡¨ç¤ºãæ­¤å¤ï¼ç¾çççå­¸å¯ä»¥ç´æ¥ééå¨é¡å¥æ¨£å¼ç©ºéä¸­éæ­·è·¯å¾ä¾é²è¡å¯è¦åã</paragraph>

##### **HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine**
2306.06029v1 by Rodrigo Agerri, IÃ±igo Alonso, Aitziber Atutxa, Ander Berrondo, Ainara Estarrona, Iker Garcia-Ferrero, Iakes Goenaga, Koldo Gojenola, Maite Oronoz, Igor Perez-Tejedor, German Rigau, Anar Yeginbergenova

Providing high quality explanations for AI predictions based on machine
learning is a challenging and complex task. To work well it requires, among
other factors: selecting a proper level of generality/specificity of the
explanation; considering assumptions about the familiarity of the explanation
beneficiary with the AI task under consideration; referring to specific
elements that have contributed to the decision; making use of additional
knowledge (e.g. expert evidence) which might not be part of the prediction
process; and providing evidence supporting negative hypothesis. Finally, the
system needs to formulate the explanation in a clearly interpretable, and
possibly convincing, way. Given these considerations, ANTIDOTE fosters an
integrated vision of explainable AI, where low-level characteristics of the
deep learning process are combined with higher level schemes proper of the
human argumentation capacity. ANTIDOTE will exploit cross-disciplinary
competences in deep learning and argumentation to support a broader and
innovative view of explainable AI, where the need for high-quality explanations
for clinical cases deliberation is critical. As a first result of the project,
we publish the Antidote CasiMedicos dataset to facilitate research on
explainable AI in general, and argumentation in the medical domain in
particular.

æè¦ï¼æä¾åºæ¼æ©å¨å­¸ç¿ç AI é æ¸¬çé«åè³ªèªªææ¯ä¸é å·æææ°æ§åè¤éæ§çä»»åãè¦é å©é²è¡ï¼å®éè¦å·åä¸åå ç´ ï¼é¸æé©ç¶çèªªææ®éæ§/ç¹æ®æ§å±¤ç´ï¼èéèªªæåçäººå°æèæ®ç AI ä»»åççæç¨åº¦åè¨­ï¼åç§ä¿ææ±ºç­çç¹å®åç´ ï¼å©ç¨å¯è½ä¸å±¬æ¼é æ¸¬ç¨åºçä¸é¨åçé¡å¤ç¥è­ï¼ä¾å¦å°å®¶è­æï¼ï¼ä¸¦æä¾æ¯æå¦å®åè¨­çè­æãæå¾ï¼ç³»çµ±éè¦ä»¥æ¸æ°å¯è§£éä¸å¯è½ä»¤äººä¿¡æçæ¹å¼å¶å®èªªæãåºæ¼éäºèéï¼ANTIDOTE ä¿æäºå¯è§£é AI çæ´åé¡æ¯ï¼å¶ä¸­æ·±åº¦å­¸ç¿ç¨åºçä½éç¹å¾µèäººé¡è«è­è½åçé«éæ¶æ§ç¸çµåãANTIDOTE å°å©ç¨æ·±åº¦å­¸ç¿èè«è­çè·¨é åè½åï¼ä¾æ¯æå¯è§£é AI æ´å»£æ³ä¸åµæ°çè§é»ï¼å¶ä¸­å°è¨åºæ¡ä¾å¯©è­°çé«åè³ªèªªæéæ±è³ééè¦ãä½çºè©²å°æ¡çç¬¬ä¸åææï¼æåç¼å¸äº Antidote CasiMedicos è³æéï¼ä»¥å©æ¼ä¸è¬å¯è§£é AI çç ç©¶ï¼ç¹å¥æ¯é«çé åçè«è­ã

##### **XInsight: Revealing Model Insights for GNNs with Flow-based Explanations**
2306.04791v1 by Eli Laird, Ayesh Madushanka, Elfi Kraka, Corey Clark

Progress in graph neural networks has grown rapidly in recent years, with
many new developments in drug discovery, medical diagnosis, and recommender
systems. While this progress is significant, many networks are `black boxes'
with little understanding of the `what' exactly the network is learning. Many
high-stakes applications, such as drug discovery, require human-intelligible
explanations from the models so that users can recognize errors and discover
new knowledge. Therefore, the development of explainable AI algorithms is
essential for us to reap the benefits of AI.
  We propose an explainability algorithm for GNNs called eXplainable Insight
(XInsight) that generates a distribution of model explanations using GFlowNets.
Since GFlowNets generate objects with probabilities proportional to a reward,
XInsight can generate a diverse set of explanations, compared to previous
methods that only learn the maximum reward sample. We demonstrate XInsight by
generating explanations for GNNs trained on two graph classification tasks:
classifying mutagenic compounds with the MUTAG dataset and classifying acyclic
graphs with a synthetic dataset that we have open-sourced. We show the utility
of XInsight's explanations by analyzing the generated compounds using QSAR
modeling, and we find that XInsight generates compounds that cluster by
lipophilicity, a known correlate of mutagenicity. Our results show that
XInsight generates a distribution of explanations that uncovers the underlying
relationships demonstrated by the model. They also highlight the importance of
generating a diverse set of explanations, as it enables us to discover hidden
relationships in the model and provides valuable guidance for further analysis.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼åç¥ç¶ç¶²è·¯çé²å±è¿éï¼å¨è¥ç©ç¼ç¾ãé«çè¨ºæ·åæ¨è¦ç³»çµ±æ¹é¢é½æè¨±å¤æ°ç¼å±ãéç¶éäºé²å±å¾éè¦ï¼ä½è¨±å¤ç¶²è·¯é½æ¯ãé»çå­ãï¼å°æ¼ç¶²è·¯å°åºå¨å­¸ç¿ãä»éº¼ãäºè§£çå°ãè¨±å¤é«é¢¨éªæç¨ï¼ä¾å¦è¥ç©ç¼ç¾ï¼éè¦æ¨¡åæä¾äººé¡å¯ä»¥çè§£çè§£éï¼ä»¥ä¾¿ä½¿ç¨èå¯ä»¥è¾¨è­é¯èª¤ä¸¦ç¼ç¾æ°ç¥è­ãå æ­¤ï¼å¯è§£é AI æ¼ç®æ³çéç¼å°æ¼æåç²å AI çå¥½èè³ééè¦ã
æåæåºäºä¸ç¨®ç¨±çº eXplainable Insight (XInsight) ç GNN å¯è§£éæ§æ¼ç®æ³ï¼å®ä½¿ç¨ GFlowNets ç¢çæ¨¡åè§£éåä½ãç±æ¼ GFlowNets æç¢çæ©çèçåµææ­£æ¯çç©ä»¶ï¼å æ­¤èåååå­¸ç¿æå¤§çåµç¯ä¾çæ¹æ³ç¸æ¯ï¼XInsight å¯ä»¥ç¢çå¤æ¨£åçè§£ééåãæåééçºå¨å©ååå½¢åé¡ä»»åä¸­è¨ç·´ç GNN ç¢çè§£éä¾å±ç¤º XInsightï¼ä½¿ç¨ MUTAG è³æéå°è´çªè®ååç©é²è¡åé¡ï¼ä¸¦ä½¿ç¨æåå·²éæ¾åå§ç¢¼çåæè³æéå°éç°çåå½¢é²è¡åé¡ãæåééä½¿ç¨ QSAR å»ºæ¨¡åæç¢ççååç©ä¾å±ç¤º XInsight è§£éçæç¨ï¼æåç¼ç¾ XInsight æç¢çæè¦ªèæ§ï¼å·²ç¥çè´çªè®ç¸éæ§ï¼åç¾¤çååç©ãæåççµæé¡¯ç¤º XInsight æç¢çä¸åè§£éåä½ï¼æ­ç¤ºæ¨¡åæå±ç¤ºçåºå±¤éä¿ãå®åä¹å¼·èª¿ç¢çå¤æ¨£åè§£ééåçéè¦æ§ï¼å çºå®ä½¿æåè½å¤ ç¼ç¾æ¨¡åä¸­çé±èéä¿ï¼ä¸¦çºé²ä¸æ­¥åææä¾æå¹å¼çæå°ã</paragraph>

##### **Explainable AI using expressive Boolean formulas**
2306.03976v1 by Gili Rosenberg, J. Kyle Brubaker, Martin J. A. Schuetz, Grant Salton, Zhihuai Zhu, Elton Yechao Zhu, Serdar KadÄ±oÄlu, Sima E. Borujeni, Helmut G. Katzgraber

We propose and implement an interpretable machine learning classification
model for Explainable AI (XAI) based on expressive Boolean formulas. Potential
applications include credit scoring and diagnosis of medical conditions. The
Boolean formula defines a rule with tunable complexity (or interpretability),
according to which input data are classified. Such a formula can include any
operator that can be applied to one or more Boolean variables, thus providing
higher expressivity compared to more rigid rule-based and tree-based
approaches. The classifier is trained using native local optimization
techniques, efficiently searching the space of feasible formulas. Shallow rules
can be determined by fast Integer Linear Programming (ILP) or Quadratic
Unconstrained Binary Optimization (QUBO) solvers, potentially powered by
special purpose hardware or quantum devices. We combine the expressivity and
efficiency of the native local optimizer with the fast operation of these
devices by executing non-local moves that optimize over subtrees of the full
Boolean formula. We provide extensive numerical benchmarking results featuring
several baselines on well-known public datasets. Based on the results, we find
that the native local rule classifier is generally competitive with the other
classifiers. The addition of non-local moves achieves similar results with
fewer iterations, and therefore using specialized or quantum hardware could
lead to a speedup by fast proposal of non-local moves.

æè¦ï¼æåæåºä¸¦å¯¦ä½ä¸åå¯è§£éæ©å¨å­¸ç¿åé¡æ¨¡åï¼ç¨æ¼åºæ¼è¡¨éå¼å¸æå¬å¼çå¯è§£é AI (XAI)ãæ½å¨æç¨åæ¬ä¿¡ç¨è©ååé«ççæ³è¨ºæ·ãå¸æå¬å¼å®ç¾©äºä¸åå·æå¯èª¿æ´è¤éæ§ï¼æå¯è§£éæ§ï¼çè¦åï¼æ ¹æè©²è¦åå°è¼¸å¥æ¸æé²è¡åé¡ãéæ¨£çå¬å¼å¯ä»¥åå«ä»»ä½å¯æç¨æ¼ä¸åæå¤åå¸æè®æ¸çéç®å­ï¼å¾èèæ´å´æ ¼çåºæ¼è¦åååºæ¼æ¨¹çæ¹æ³ç¸æ¯ï¼æä¾æ´é«çè¡¨éè½åãåé¡å¨ä½¿ç¨åçå±é¨æä½³åæè¡é²è¡è¨ç·´ï¼ææå°æç´¢å¯è¡å¬å¼çç©ºéãæ·ºå±¤è¦åå¯ä»¥ç¨å¿«éçæ´æ¸ç·æ§è¦å (ILP) æäºæ¬¡ç¡ç´æäºåæä½³å (QUBO) æ±è§£å¨ä¾ç¢ºå®ï¼éäºæ±è§£å¨å¯è½ç±ç¹æ®ç¨éçç¡¬é«æéå­è£ç½®æä¾æ¯æ´ãæåå°åçå±é¨æä½³åå¨çè¡¨éè½ååæçèéäºè£ç½®çå¿«ééç®ç¸çµåï¼ééå·è¡éå±é¨ç§»åä¾æä½³åå®æ´å¸æå¬å¼çå­æ¨¹ãæåæä¾å»£æ³çæ¸å¼åºæºæ¸¬è©¦çµæï¼å¶ä¸­åå«å¨ç¾æå¨ç¥çå¬å±è³æéä¸ä½¿ç¨å¤ååºç·ãæ ¹æçµæï¼æåç¼ç¾åçå±é¨è¦ååé¡å¨éå¸¸èå¶ä»åé¡å¨å·æç«¶ç­åãå å¥éå±é¨ç§»åä»¥è¼å°çåè¦éç®æ¬¡æ¸éæé¡ä¼¼ççµæï¼å æ­¤ä½¿ç¨å°ç¨æéå­ç¡¬é«å¯è½æééå¿«éæåºéå±é¨ç§»åä¾å éã

##### **Utterance Classification with Logical Neural Network: Explainable AI for Mental Disorder Diagnosis**
2306.03902v1 by Yeldar Toleubay, Don Joven Agravante, Daiki Kimura, Baihan Lin, Djallel Bouneffouf, Michiaki Tatsubori

In response to the global challenge of mental health problems, we proposes a
Logical Neural Network (LNN) based Neuro-Symbolic AI method for the diagnosis
of mental disorders. Due to the lack of effective therapy coverage for mental
disorders, there is a need for an AI solution that can assist therapists with
the diagnosis. However, current Neural Network models lack explainability and
may not be trusted by therapists. The LNN is a Recurrent Neural Network
architecture that combines the learning capabilities of neural networks with
the reasoning capabilities of classical logic-based AI. The proposed system
uses input predicates from clinical interviews to output a mental disorder
class, and different predicate pruning techniques are used to achieve
scalability and higher scores. In addition, we provide an insight extraction
method to aid therapists with their diagnosis. The proposed system addresses
the lack of explainability of current Neural Network models and provides a more
trustworthy solution for mental disorder diagnosis.

æè¦ï¼çºäºè§£æ±ºå¿çå¥åº·åé¡çå¨çææ°ï¼æåæåºä¸ååºæ¼éè¼¯ç¥ç¶ç¶²è·¯ (LNN) çç¥ç¶ç¬¦è AI æ¹æ³ä¾è¨ºæ·å¿çç¾çãç±æ¼ç¼ºä¹ææçå¿çç¾çæ²»çæ¶µèç¯åï¼å æ­¤éè¦ä¸ç¨® AI è§£æ±ºæ¹æ¡ä¾åå©æ²»çå¸«é²è¡è¨ºæ·ãç¶èï¼ç®åçé¡ç¥ç¶ç¶²è·¯æ¨¡åç¼ºä¹å¯è§£éæ§ï¼æ²»çå¸«å¯è½ç¡æ³ä¿¡ä»»å®åãLNN æ¯ä¸ç¨®éè¿´ç¥ç¶ç¶²è·¯æ¶æ§ï¼å®çµåäºç¥ç¶ç¶²è·¯çå­¸ç¿è½åååºæ¼ç¶å¸éè¼¯ç AI çæ¨çè½åãææåºçç³»çµ±ä½¿ç¨ä¾èªè¨åºè¨ªè«çè¼¸å¥è¬è©ä¾è¼¸åºå¿çç¾çé¡å¥ï¼ä¸¦ä½¿ç¨ä¸åçè¬è©åªææè¡ä¾å¯¦ç¾å¯æ´åæ§åæ´é«çåæ¸ãæ­¤å¤ï¼æåæä¾äºä¸åè¦è§£æåæ¹æ³ä¾åå©æ²»çå¸«é²è¡è¨ºæ·ãææåºçç³»çµ±è§£æ±ºäºç¶åé¡ç¥ç¶ç¶²è·¯æ¨¡åç¼ºä¹å¯è§£éæ§çåé¡ï¼ä¸¦çºå¿çç¾çè¨ºæ·æä¾äºæ´å¼å¾ä¿¡è³´çè§£æ±ºæ¹æ¡ã

##### **XAI Renaissance: Redefining Interpretability in Medical Diagnostic Models**
2306.01668v1 by Sujith K Mandala

As machine learning models become increasingly prevalent in medical
diagnostics, the need for interpretability and transparency becomes paramount.
The XAI Renaissance signifies a significant shift in the field, aiming to
redefine the interpretability of medical diagnostic models. This paper explores
the innovative approaches and methodologies within the realm of Explainable AI
(XAI) that are revolutionizing the interpretability of medical diagnostic
models. By shedding light on the underlying decision-making process, XAI
techniques empower healthcare professionals to understand, trust, and
effectively utilize these models for accurate and reliable medical diagnoses.
This review highlights the key advancements in XAI for medical diagnostics and
their potential to transform the healthcare landscape, ultimately improving
patient outcomes and fostering trust in AI-driven diagnostic systems.

æè¦ï¼é¨èæ©å¨å­¸ç¿æ¨¡åå¨é«çè¨ºæ·ä¸­è¶ä¾è¶æ®éï¼å¯è§£éæ§åéæåº¦çéæ±è®å¾è³ééè¦ãXAI å¾©èæ¨èªèè©²é åçéå¤§è½è®ï¼æ¨å¨éæ°å®ç¾©é«çè¨ºæ·æ¨¡åçå¯è§£éæ§ãæ¬ææ¢è¨äºå¯è§£é AI (XAI) é åå§çåµæ°æ¹æ³åæ¹æ³è«ï¼éäºæ¹æ³åæ¹æ³è«æ­£å¨é©æ°é«çè¨ºæ·æ¨¡åçå¯è§£éæ§ãééé¡æåºç¤æ±ºç­å¶å®éç¨ï¼XAI æè¡ä½¿é«çä¿å¥å°æ¥­äººå¡è½å¤ çè§£ãä¿¡ä»»ä¸¦ææå°å©ç¨éäºæ¨¡åé²è¡æºç¢ºä¸å¯é çé«çè¨ºæ·ãæ¬ç¶è¿°éé»ä»ç´¹äº XAI å¨é«çè¨ºæ·æ¹é¢çééµé²å±åå¶è½è®é«çä¿å¥é åçæ½åï¼æçµæ¹åæ£èçæ²»çææä¸¦å¹é¤å° AI é©åçè¨ºæ·ç³»çµ±çä¿¡ä»»ã

##### **A Novel real-time arrhythmia detection model using YOLOv8**
2305.16727v3 by Guang Jun Nicholas Ang, Aritejh Kr Goil, Henryk Chan, Jieyi Jeric Lew, Xin Chun Lee, Raihan Bin Ahmad Mustaffa, Timotius Jason, Ze Ting Woon, Bingquan Shen

In a landscape characterized by heightened connectivity and mobility, coupled
with a surge in cardiovascular ailments, the imperative to curtail healthcare
expenses through remote monitoring of cardiovascular health has become more
pronounced. The accurate detection and classification of cardiac arrhythmias
are pivotal for diagnosing individuals with heart irregularities. This study
underscores the feasibility of employing electrocardiograms (ECG) measurements
in the home environment for real-time arrhythmia detection. Presenting a fresh
application for arrhythmia detection, this paper leverages the cutting-edge
You-Only-Look-Once (YOLO)v8 algorithm to categorize single-lead ECG signals. We
introduce a novel loss-modified YOLOv8 model, fine-tuned on the MIT-BIH
arrhythmia dataset, enabling real-time continuous monitoring. The obtained
results substantiate the efficacy of our approach, with the model attaining an
average accuracy of 99.5% and 0.992 mAP@50, and a rapid detection time of 0.002
seconds on an NVIDIA Tesla V100. Our investigation exemplifies the potential of
real-time arrhythmia detection, enabling users to visually interpret the model
output within the comfort of their homes. Furthermore, this study lays the
groundwork for an extension into a real-time explainable AI (XAI) model capable
of deployment in the healthcare sector, thereby significantly advancing the
realm of healthcare solutions.

æè¦ï¼<paragraph>å¨ä»¥é«åº¦é£æ¥æ§åæµåæ§çºç¹å¾µçç°å¢ä¸­ï¼å ä¸å¿è¡ç®¡ç¾ççæ¿å¢ï¼ééé ç¨ç£æ§å¿è¡ç®¡å¥åº·ä¾åæ¸é«çä¿å¥æ¯åºçå¿è¦æ§è®å¾æ´å æé¡¯ãæºç¢ºæª¢æ¸¬ååé¡å¿å¾ä¸æ´å°æ¼è¨ºæ·æ£æå¿èä¸è¦åçäººè³ééè¦ãæ¬ç ç©¶å¼·èª¿äºå¨å®¶ä¸­ä½¿ç¨å¿é»å (ECG) æ¸¬éé²è¡å¯¦æå¿å¾ä¸æ´æª¢æ¸¬çå¯è¡æ§ãæ¬ææåºäºä¸ç¨®æ°çå¿å¾ä¸æ´æª¢æ¸¬æç¨ï¼å©ç¨å°ç«¯ç You-Only-Look-Once (YOLO)v8 æ¼ç®æ³å°å®å°è¯ ECG è¨èé²è¡åé¡ãæåå¼å¥äºä¸åæ°ç©çæå¤±ä¿®æ¹ YOLOv8 æ¨¡åï¼ä¸¦éå° MIT-BIH å¿å¾ä¸æ´è³æéé²è¡äºå¾®èª¿ï¼å¾èå¯¦ç¾äºå¯¦æçæçºç£æ§ãç²å¾ççµæè­å¯¦äºæåæ¹æ³çæææ§ï¼è©²æ¨¡åå¨ NVIDIA Tesla V100 ä¸éå°äº 99.5% çå¹³åæºç¢ºåº¦å 0.992 mAP@50ï¼ä»¥å 0.002 ç§çå¿«éæª¢æ¸¬æéãæåçç ç©¶èªªæäºå¯¦æå¿å¾ä¸æ´æª¢æ¸¬çæ½åï¼ä½¿ç¨æ¶è½å¤ å¨å®¶ä¸­èé©å°è¦è¦ºåè§£è®æ¨¡åè¼¸åºãæ­¤å¤ï¼æ¬ç ç©¶çºæ´å±å°å¯¦æå¯è§£é AI (XAI) æ¨¡åå¥ å®äºåºç¤ï¼è©²æ¨¡åè½å¤ é¨ç½²å¨é«çä¿å¥é åï¼å¾èé¡¯èæ¨é²é«çä¿å¥è§£æ±ºæ¹æ¡çé åã</paragraph>

##### **Breast Cancer Segmentation using Attention-based Convolutional Network and Explainable AI**
2305.14389v2 by Jai Vardhan, Taraka Satya Krishna Teja Malisetti

Breast cancer (BC) remains a significant health threat, with no long-term
cure currently available. Early detection is crucial, yet mammography
interpretation is hindered by high false positives and negatives. With BC
incidence projected to surpass lung cancer, improving early detection methods
is vital. Thermography, using high-resolution infrared cameras, offers promise,
especially when combined with artificial intelligence (AI). This work presents
an attention-based convolutional neural network for segmentation, providing
increased speed and precision in BC detection and classification. The system
enhances images and performs cancer segmentation with explainable AI. We
propose a transformer-attention-based convolutional architecture (UNet) for
fault identification and employ Gradient-weighted Class Activation Mapping
(Grad-CAM) to analyze areas of bias and weakness in the UNet architecture with
IRT images. The superiority of our proposed framework is confirmed when
compared with existing deep learning frameworks.

æè¦ï¼ä¹³çï¼BCï¼ä»ç¶æ¯ä¸åéå¤§çå¥åº·å¨èï¼ç®åå°ç¡é·ææ²»ççæ¹æ³ãæ©æç¼ç¾è³ééè¦ï¼ä½ä¹³æ¿æå½±çå¤è®å»åå°é«åé½æ§ååé°æ§çé»ç¤ãç±æ¼ä¹³ççç¼ççé è¨å°è¶éèºçï¼å æ­¤æ¹åæ©ææª¢æ¸¬æ¹æ³è³ééè¦ãç±åæå½±ä½¿ç¨é«è§£æåº¦ç´å¤ç·ç¸æ©ï¼ç¹å¥æ¯å¨èäººå·¥æºæ§ï¼AIï¼çµåä½¿ç¨æï¼æä¾äºå¸æãéé å·¥ä½æåºäºä¸ååºæ¼æ³¨æåçå·ç©ç¥ç¶ç¶²è·¯ç¨æ¼åå²ï¼å¨ä¹³çæª¢æ¸¬ååé¡ä¸­æä¾äºæ´é«çéåº¦åç²¾åº¦ãè©²ç³»çµ±å¢å¼·å½±åä¸¦å·è¡å¯è§£éç AI ççåå²ãæåæåºäºä¸ååºæ¼Transformeræ³¨æåçå·ç©æ¶æ§ï¼UNetï¼ç¨æ¼æéè­å¥ï¼ä¸¦ä½¿ç¨æ¢¯åº¦å æ¬é¡æ¿æ´»æ å°ï¼Grad-CAMï¼ä¾åæ UNet æ¶æ§ä¸­åè¦åå¼±é»çååï¼ä½¿ç¨ IRT å½±åãèç¾æçæ·±åº¦å­¸ç¿æ¡æ¶ç¸æ¯ï¼æåæåºçæ¡æ¶çåªè¶æ§å¾å°è­å¯¦ã

##### **What Symptoms and How Long? An Interpretable AI Approach for Depression Detection in Social Media**
2305.13127v2 by Junwei Kuang, Jiaheng Xie, Zhijun Yan

Depression is the most prevalent and serious mental illness, which induces
grave financial and societal ramifications. Depression detection is key for
early intervention to mitigate those consequences. Such a high-stake decision
inherently necessitates interpretability. Although a few depression detection
studies attempt to explain the decision based on the importance score or
attention weights, these explanations misalign with the clinical depression
diagnosis criterion that is based on depressive symptoms. To fill this gap, we
follow the computational design science paradigm to develop a novel Multi-Scale
Temporal Prototype Network (MSTPNet). MSTPNet innovatively detects and
interprets depressive symptoms as well as how long they last. Extensive
empirical analyses using a large-scale dataset show that MSTPNet outperforms
state-of-the-art depression detection methods with an F1-score of 0.851. This
result also reveals new symptoms that are unnoted in the survey approach, such
as sharing admiration for a different life. We further conduct a user study to
demonstrate its superiority over the benchmarks in interpretability. This study
contributes to IS literature with a novel interpretable deep learning model for
depression detection in social media. In practice, our proposed method can be
implemented in social media platforms to provide personalized online resources
for detected depressed patients.

æè¦ï¼æé¬±çæ¯ææ®éä¸å´éçç²¾ç¥ç¾çï¼æé æå´éçè²¡ååç¤¾æå¾æãæé¬±ççåµæ¸¬å°æ¼æ©æä»å¥ä»¥æ¸è¼éäºå¾æè³ééè¦ãå¦æ­¤éå¤§çæ±ºå®æ¬è³ªä¸éè¦å¯è§£éæ§ãåç®¡ä¸äºæé¬±çåµæ¸¬ç ç©¶åè©¦æ ¹æéè¦æ§åæ¸ææ³¨æåæ¬éä¾è§£ééåæ±ºå®ï¼ä½éäºè§£éèåºæ¼æé¬±çççè¨åºæé¬±çè¨ºæ·æ¨æºä¸ä¸è´ãçºäºå¡«è£éåç¼ºå£ï¼æåéµå¾ªè¨ç®è¨­è¨ç§å­¸ç¯ä¾ä¾éç¼ä¸åæ°ç©çå¤å°ºåº¦æéååç¶²è·¯ (MSTPNet)ãMSTPNet åµæ°å°åµæ¸¬ä¸¦è§£éæé¬±ççä»¥åå®åæçºå¤ä¹ãä½¿ç¨å¤§è¦æ¨¡è³æéé²è¡çå»£æ³å¯¦è­åæé¡¯ç¤ºï¼MSTPNet ä»¥ 0.851 ç F1 åæ¸åªæ¼æåé²çæé¬±çåµæ¸¬æ¹æ³ãæ­¤çµæéæ­ç¤ºäºèª¿æ¥æ¹æ³ä¸­æªæ³¨æå°çæ°ççï¼ä¾å¦åäº«å°ä¸åçæ´»çæ¬½ä½©ãæåé²ä¸æ­¥é²è¡ä½¿ç¨èç ç©¶ï¼ä»¥è­æå¶å¨å¯è§£éæ§æ¹é¢åªæ¼åºæºãæ¬ç ç©¶ä»¥ä¸åæ°ç©çå¯è§£éæ·±åº¦å­¸ç¿æ¨¡åçºæé¬±çåµæ¸¬å¨ç¤¾ç¾¤åªé«ä¸­ç IS æç»ååºè²¢ç»ãå¨å¯¦åä¸ï¼æåæåºçæ¹æ³å¯ä»¥å¯¦ä½å¨ç¤¾ç¾¤åªé«å¹³å°ä¸­ï¼ä»¥æä¾åäººåçç·ä¸è³æºçµ¦è¢«åµæ¸¬åºæé¬±ççæ£èã

##### **Echoes of Biases: How Stigmatizing Language Affects AI Performance**
2305.10201v4 by Yizhi Liu, Weiguang Wang, Guodong Gordon Gao, Ritu Agarwal

Electronic health records (EHRs) serve as an essential data source for the
envisioned artificial intelligence (AI)-driven transformation in healthcare.
However, clinician biases reflected in EHR notes can lead to AI models
inheriting and amplifying these biases, perpetuating health disparities. This
study investigates the impact of stigmatizing language (SL) in EHR notes on
mortality prediction using a Transformer-based deep learning model and
explainable AI (XAI) techniques. Our findings demonstrate that SL written by
clinicians adversely affects AI performance, particularly so for black
patients, highlighting SL as a source of racial disparity in AI model
development. To explore an operationally efficient way to mitigate SL's impact,
we investigate patterns in the generation of SL through a clinicians'
collaborative network, identifying central clinicians as having a stronger
impact on racial disparity in the AI model. We find that removing SL written by
central clinicians is a more efficient bias reduction strategy than eliminating
all SL in the entire corpus of data. This study provides actionable insights
for responsible AI development and contributes to understanding clinician
behavior and EHR note writing in healthcare.

æè¦ï¼é»å­å¥åº·ç´é (EHR) ä½çºé æ³ä¸­ç±äººå·¥æºæ§ (AI) æ¨åçé«çä¿å¥è½åçéè¦è³æä¾æºãç¶èï¼åæ å¨ EHR åè¨»ä¸­çè¨åºåè¦å¯è½å°è´ AI æ¨¡åç¹¼æ¿ä¸¦æ´å¤§éäºåè¦ï¼é²èé æå¥åº·å·®ç°ãæ¬ç ç©¶æ¢è¨ EHR åè¨»ä¸­æ±ååèªè¨ (SL) å°ä½¿ç¨åºæ¼ Transformer çæ·±åº¦å­¸ç¿æ¨¡ååå¯è§£é AI (XAI) æè¡é æ¸¬æ­»äº¡ççå½±é¿ãæåçç ç©¶çµæè¡¨æï¼ç±è¨åºé«çæ°å¯«ç SL æå° AI æè½ç¢çä¸å©å½±é¿ï¼ç¹å¥æ¯å°é»äººæ£èèè¨ï¼çªé¡¯ SL æ¯ AI æ¨¡åéç¼ä¸­ç¨®æå·®ç°çä¾æºãçºäºæ¢ç´¢ä¸ç¨®éä½ä¸ææççæ¹æ³ä¾æ¸è¼ SL çå½±é¿ï¼æåééè¨åºé«ççåä½ç¶²è·¯æ¢è¨ SL ç¢ççæ¨¡å¼ï¼ä¸¦æ¾åºæ ¸å¿è¨åºé«çå° AI æ¨¡åä¸­çç¨®æå·®ç°æè¼å¤§çå½±é¿ãæåç¼ç¾ï¼ç§»é¤ç±æ ¸å¿è¨åºé«çæ°å¯«ç SL æ¯æ¯æ¶é¤è³æéä¸­ææ SL æ´ææççåè¦æ¸å°ç­ç¥ãæ¬ç ç©¶æä¾å¯è¡çè¦è§£ï¼ç¨æ¼è² è²¬ä»»ç AI éç¼ï¼ä¸¦æå©æ¼äºè§£è¨åºé«çè¡çºåé«çä¿å¥ä¸­ç EHR åè¨»æ°å¯«ã

##### **Explaining the ghosts: Feminist intersectional XAI and cartography as methods to account for invisible labour**
2305.03376v1 by Goda Klumbyte, Hannah Piehl, Claude Draude

Contemporary automation through AI entails a substantial amount of
behind-the-scenes human labour, which is often both invisibilised and
underpaid. Since invisible labour, including labelling and maintenance work, is
an integral part of contemporary AI systems, it remains important to sensitise
users to its role. We suggest that this could be done through explainable AI
(XAI) design, particularly feminist intersectional XAI. We propose the method
of cartography, which stems from feminist intersectional research, to draw out
a systemic perspective of AI and include dimensions of AI that pertain to
invisible labour.

æè¦ï¼ç¶ä»£éé AI çèªååéè¦å¤§éçå¹å¾äººåï¼ééå¸¸æ¢ä¸å¯è¦ä¸èªè³éä½ãç±æ¼ä¸å¯è¦çååï¼åæ¬æ¨ç±¤åç¶­è­·å·¥ä½ï¼æ¯ç¶ä»£ AI ç³»çµ±ççµæé¨åï¼å æ­¤è®ä½¿ç¨èäºè§£å¶è§è²ä»ç¶å¾éè¦ãæåå»ºè­°éå¯ä»¥ééå¯è§£éç AIï¼XAIï¼è¨­è¨ä¾å®æï¼ç¹å¥æ¯å¥³æ§ä¸»ç¾©äº¤åç XAIãæåæåºæºèªå¥³æ§ä¸»ç¾©äº¤åç ç©¶çè£½åæ¹æ³ï¼ä»¥æåº AI çç³»çµ±è§é»ï¼ä¸¦ç´å¥èä¸å¯è¦ååç¸éç AI ç¶­åº¦ã

##### **Towards Explainable and Safe Conversational Agents for Mental Health: A Survey**
2304.13191v1 by Surjodeep Sarkar, Manas Gaur, L. Chen, Muskan Garg, Biplav Srivastava, Bhaktee Dongaonkar

Virtual Mental Health Assistants (VMHAs) are seeing continual advancements to
support the overburdened global healthcare system that gets 60 million primary
care visits, and 6 million Emergency Room (ER) visits annually. These systems
are built by clinical psychologists, psychiatrists, and Artificial Intelligence
(AI) researchers for Cognitive Behavioral Therapy (CBT). At present, the role
of VMHAs is to provide emotional support through information, focusing less on
developing a reflective conversation with the patient. A more comprehensive,
safe and explainable approach is required to build responsible VMHAs to ask
follow-up questions or provide a well-informed response. This survey offers a
systematic critical review of the existing conversational agents in mental
health, followed by new insights into the improvements of VMHAs with contextual
knowledge, datasets, and their emerging role in clinical decision support. We
also provide new directions toward enriching the user experience of VMHAs with
explainability, safety, and wholesome trustworthiness. Finally, we provide
evaluation metrics and practical considerations for VMHAs beyond the current
literature to build trust between VMHAs and patients in active communications.

æè¦ï¼èæ¬å¿çå¥åº·å©ç (VMHA) æçºé²æ­¥ï¼ä»¥æ¯æ´æ¯å¹´æ 6000 è¬äººæ¬¡åç´ä¿å¥å°±è¨ºå 600 è¬äººæ¬¡æ¥è¨ºå®¤ (ER) å°±è¨ºçè¶è² è·å¨çé«çä¿å¥ç³»çµ±ãéäºç³»çµ±æ¯ç±è¨åºå¿çå­¸å®¶ãç²¾ç¥ç§é«å¸«åäººå·¥æºæ§ (AI) ç ç©¶äººå¡çºèªç¥è¡çºçæ³ (CBT) æå»ºæ§ãç®åï¼VMHA çè§è²æ¯ééè³è¨æä¾æç·æ¯æï¼è¼å°èéæ¼èæ£èç¼å±åææ§çå°è©±ãéè¦æ´å¨é¢ãå®å¨ä¸å¯è§£éçæ¹æ³ä¾å»ºæ§è² è²¬ä»»ç VMHAï¼ä»¥æåºå¾çºåé¡ææä¾ååçåæãéé èª¿æ¥æä¾äºå°å¿çå¥åº·ä¸­ç¾æå°è©±ä»£ççç³»çµ±æ§æ¹å¤æ§åé¡§ï¼æ¥èæ·±å¥æ¢è¨äº VMHA å¨èçµ¡ç¥è­ãè³æéåå¶å¨è¨åºæ±ºç­æ¯æ´ä¸­æ°èè§è²çæ¹é²ãæåä¹æä¾äºæ°çæ¹åï¼ä»¥ééå¯è§£éæ§ãå®å¨æ§èæ´é«å¯ä¿¡åº¦ä¾è±å¯ VMHA çä½¿ç¨èé«é©ãæå¾ï¼æåæä¾äºè©éææ¨å VMHA çå¯¦åèéï¼è¶è¶ç®åçæç»ï¼å¨ VMHA èæ£èçç©æ¥µæºéä¸­å»ºç«ä¿¡ä»»ã

##### **A Brief Review of Explainable Artificial Intelligence in Healthcare**
2304.01543v1 by Zahra Sadeghi, Roohallah Alizadehsani, Mehmet Akif Cifci, Samina Kausar, Rizwan Rehman, Priyakshi Mahanta, Pranjal Kumar Bora, Ammar Almasri, Rami S. Alkhawaldeh, Sadiq Hussain, Bilal Alatas, Afshin Shoeibi, Hossein Moosaei, Milan Hladik, Saeid Nahavandi, Panos M. Pardalos

XAI refers to the techniques and methods for building AI applications which
assist end users to interpret output and predictions of AI models. Black box AI
applications in high-stakes decision-making situations, such as medical domain
have increased the demand for transparency and explainability since wrong
predictions may have severe consequences. Model explainability and
interpretability are vital successful deployment of AI models in healthcare
practices. AI applications' underlying reasoning needs to be transparent to
clinicians in order to gain their trust. This paper presents a systematic
review of XAI aspects and challenges in the healthcare domain. The primary
goals of this study are to review various XAI methods, their challenges, and
related machine learning models in healthcare. The methods are discussed under
six categories: Features-oriented methods, global methods, concept models,
surrogate models, local pixel-based methods, and human-centric methods. Most
importantly, the paper explores XAI role in healthcare problems to clarify its
necessity in safety-critical applications. The paper intends to establish a
comprehensive understanding of XAI-related applications in the healthcare field
by reviewing the related experimental results. To facilitate future research
for filling research gaps, the importance of XAI models from different
viewpoints and their limitations are investigated.

æè¦ï¼XAI æçæ¯ç¨æ¼å»ºæ§ AI æç¨ç¨å¼çæè¡åæ¹æ³ï¼éäºæç¨ç¨å¼å¯åå©æçµä½¿ç¨èè©®é AI æ¨¡åçè¼¸åºåé æ¸¬ãå¨é«é¢¨éªæ±ºç­æå¢ä¸­ï¼ä¾å¦é«çé åï¼é»ç®± AI æç¨ç¨å¼å¢å äºéæåº¦åå¯è§£éæ§çéæ±ï¼å çºé¯èª¤çé æ¸¬å¯è½æé æå´éçå¾æãæ¨¡åå¯è§£éæ§åå¯è©®éæ§å°æ¼å¨é«çå¯¦åä¸­æåé¨ç½² AI æ¨¡åè³ééè¦ãAI æç¨ç¨å¼çåºæ¬æ¨çéè¦å°è¨åºé«çéæï¼æè½ç²å¾ä»åçä¿¡ä»»ãæ¬ææä¾äºé«çé åä¸­ XAI é¢ååææ°çç³»çµ±æ§åé¡§ãæ¬ç ç©¶çä¸»è¦ç®æ¨æ¯åé¡§åç¨® XAI æ¹æ³ãå¶ææ°ï¼ä»¥åç¸éçé«çä¿å¥æ©å¨å­¸ç¿æ¨¡åãéäºæ¹æ³åçºå­é¡è¨è«ï¼é¢åç¹å¾µçæ¹æ³ãæ´é«æ¹æ³ãæ¦å¿µæ¨¡åãä»£çæ¨¡åãå±é¨åºæ¼åç´ çæ¹æ³ï¼ä»¥åä»¥äººçºä¸­å¿çæ¹æ³ãæéè¦çæ¯ï¼æ¬ææ¢è¨äº XAI å¨é«çä¿å¥åé¡ä¸­çè§è²ï¼ä»¥éæ¸å¶å¨å®å¨ééµæç¨ä¸­çå¿è¦æ§ãæ¬ææ¨å¨ééåé¡§ç¸éçå¯¦é©çµæï¼å»ºç«å°é«çä¿å¥é åä¸­ XAI ç¸éæç¨ç¨å¼çå¨é¢äºè§£ãçºäºä¿é²æªä¾ç ç©¶å¡«è£ç ç©¶å·®è·ï¼æ¬ææ¢è¨äº XAI æ¨¡åå¾ä¸åè§é»ä¾ççéè¦æ§åå¶éå¶ã

##### **Reveal to Revise: An Explainable AI Life Cycle for Iterative Bias Correction of Deep Models**
2303.12641v2 by Frederik Pahde, Maximilian Dreyer, Wojciech Samek, Sebastian Lapuschkin

State-of-the-art machine learning models often learn spurious correlations
embedded in the training data. This poses risks when deploying these models for
high-stake decision-making, such as in medical applications like skin cancer
detection. To tackle this problem, we propose Reveal to Revise (R2R), a
framework entailing the entire eXplainable Artificial Intelligence (XAI) life
cycle, enabling practitioners to iteratively identify, mitigate, and
(re-)evaluate spurious model behavior with a minimal amount of human
interaction. In the first step (1), R2R reveals model weaknesses by finding
outliers in attributions or through inspection of latent concepts learned by
the model. Secondly (2), the responsible artifacts are detected and spatially
localized in the input data, which is then leveraged to (3) revise the model
behavior. Concretely, we apply the methods of RRR, CDEP and ClArC for model
correction, and (4) (re-)evaluate the model's performance and remaining
sensitivity towards the artifact. Using two medical benchmark datasets for
Melanoma detection and bone age estimation, we apply our R2R framework to VGG,
ResNet and EfficientNet architectures and thereby reveal and correct real
dataset-intrinsic artifacts, as well as synthetic variants in a controlled
setting. Completing the XAI life cycle, we demonstrate multiple R2R iterations
to mitigate different biases. Code is available on
https://github.com/maxdreyer/Reveal2Revise.

æè¦ï¼æåè¿çæºå¨å­¦ä¹ æ¨¡åéå¸¸ä¼å­¦ä¹ è®­ç»æ°æ®ä¸­åµå¥çèåå³èãè¿å¨å°è¿äºæ¨¡åé¨ç½²äºé«é£é©å³ç­æ¶ä¼å¸¦æ¥é£é©ï¼ä¾å¦å¨ç®è¤çæ£æµç­å»å­¦åºç¨ä¸­ãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æä»¬æåºäº Reveal to Revise (R2R)ï¼ä¸ä¸ªæ¶µçæ´ä¸ªå¯è§£éäººå·¥æºè½ (XAI) çå½å¨æçæ¡æ¶ï¼ä½¿ä»ä¸èè½å¤ä»¥æå°çäººå·¥äº¤äºè¿­ä»£è¯å«ãç¼è§£åï¼éæ°ï¼è¯ä¼°èåæ¨¡åè¡ä¸ºãå¨ç¬¬ä¸æ­¥ (1) ä¸­ï¼R2R éè¿æ¾åºå½å ä¸­çå¼å¸¸å¼æéè¿æ£æ¥æ¨¡åå­¦ä¹ çæ½å¨æ¦å¿µæ¥æ­ç¤ºæ¨¡åçå¼±ç¹ãå¶æ¬¡ (2)ï¼æ£æµè´è´£çä¼ªåå¹¶å¨è¾å¥æ°æ®ä¸­è¿è¡ç©ºé´å®ä½ï¼ç¶åå©ç¨å®æ¥ (3) ä¿®æ¹æ¨¡åè¡ä¸ºãå·ä½æ¥è¯´ï¼æä»¬åºç¨ RRRãCDEP å ClArC çæ¹æ³æ¥è¿è¡æ¨¡åæ ¡æ­£ï¼å¹¶ (4)ï¼éæ°ï¼è¯ä¼°æ¨¡åçæ§è½åå¯¹ä¼ªåçå©ä½æææ§ãä½¿ç¨ä¸¤ä¸ªç¨äºé»è²ç´ ç¤æ£æµåéª¨é¾ä¼°è®¡çå»å­¦åºåæ°æ®éï¼æä»¬å°æä»¬ç R2R æ¡æ¶åºç¨äº VGGãResNet å EfficientNet æ¶æï¼ä»èæ­ç¤ºåçº æ­£äºçå®æ°æ®éåºæçä¼ªåï¼ä»¥ååæ§è®¾ç½®ä¸­çåæåä½ãå®æ XAI çå½å¨æï¼æä»¬æ¼ç¤ºäºå¤ä¸ª R2R è¿­ä»£ä»¥åè½»ä¸åçåå·®ãä»£ç å¯å¨ https://github.com/maxdreyer/Reveal2Revise ä¸æ¾å°ã

##### **Explainable AI for Time Series via Virtual Inspection Layers**
2303.06365v1 by Johanna Vielhaben, Sebastian Lapuschkin, GrÃ©goire Montavon, Wojciech Samek

The field of eXplainable Artificial Intelligence (XAI) has greatly advanced
in recent years, but progress has mainly been made in computer vision and
natural language processing. For time series, where the input is often not
interpretable, only limited research on XAI is available. In this work, we put
forward a virtual inspection layer, that transforms the time series to an
interpretable representation and allows to propagate relevance attributions to
this representation via local XAI methods like layer-wise relevance propagation
(LRP). In this way, we extend the applicability of a family of XAI methods to
domains (e.g. speech) where the input is only interpretable after a
transformation. Here, we focus on the Fourier transformation which is
prominently applied in the interpretation of time series and LRP and refer to
our method as DFT-LRP. We demonstrate the usefulness of DFT-LRP in various time
series classification settings like audio and electronic health records. We
showcase how DFT-LRP reveals differences in the classification strategies of
models trained in different domains (e.g., time vs. frequency domain) or helps
to discover how models act on spurious correlations in the data.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) é åå¨è¿å¹´ä¾åå¾é·è¶³é²æ­¥ï¼ä½é²å±ä¸»è¦æ¯å¨é»è¦è¦è¦ºåèªç¶èªè¨èçæ¹é¢ãå°æ¼è¼¸å¥éå¸¸ç¡æ³è§£éçæéåºåï¼åªææéçç ç©¶å¯ä¾ä½¿ç¨ XAIãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸åèæ¬æª¢æ¥å±¤ï¼å®å°æéåºåè½æçºå¯è§£éçè¡¨ç¤ºï¼ä¸¦åè¨±ééå±¤ç´ç¸éæ§å³æ­ (LRP) ç­å±é¨ XAI æ¹æ³å°ç¸éæ§æ­¸å å³æ­å°æ­¤è¡¨ç¤ºãèæ­¤ï¼æåå°ä¸ç³»å XAI æ¹æ³çé©ç¨æ§æ´å±å°è¼¸å¥åå¨è½æå¾æè½è§£éçé åï¼ä¾å¦èªé³ï¼ãå¨æ­¤ï¼æåå°æ³¨æ¼åç«èè½æï¼å®ä¸»è¦æç¨æ¼æéåºåå LRP çè§£éï¼ä¸¦å°æåçç¨±ä¹çº DFT-LRPãæåå±ç¤ºäº DFT-LRP å¨åç¨®æéåºååé¡è¨­å®ï¼ä¾å¦é³è¨åé»å­å¥åº·ç´éï¼ä¸­çæç¨ãæåå±ç¤ºäº DFT-LRP å¦ä½æ­ç¤ºå¨ä¸åé åï¼ä¾å¦æéèé »çåï¼è¨ç·´çæ¨¡åçåé¡ç­ç¥å·®ç°ï¼ææå©æ¼ç¼ç¾æ¨¡åå¦ä½èçè³æä¸­çèåéè¯ã

##### **Towards Trust of Explainable AI in Thyroid Nodule Diagnosis**
2303.04731v1 by Truong Thanh Hung Nguyen, Van Binh Truong, Vo Thanh Khang Nguyen, Quoc Hung Cao, Quoc Khanh Nguyen

The ability to explain the prediction of deep learning models to end-users is
an important feature to leverage the power of artificial intelligence (AI) for
the medical decision-making process, which is usually considered
non-transparent and challenging to comprehend. In this paper, we apply
state-of-the-art eXplainable artificial intelligence (XAI) methods to explain
the prediction of the black-box AI models in the thyroid nodule diagnosis
application. We propose new statistic-based XAI methods, namely Kernel Density
Estimation and Density map, to explain the case of no nodule detected. XAI
methods' performances are considered under a qualitative and quantitative
comparison as feedback to improve the data quality and the model performance.
Finally, we survey to assess doctors' and patients' trust in XAI explanations
of the model's decisions on thyroid nodule images.

æè¦ï¼è§£éæ·±åº¦å­¸ç¿æ¨¡åé æ¸¬çµæçè½åå°æçµä½¿ç¨èèè¨æ¯ä¸é éè¦åè½ï¼å¯å©ç¨äººå·¥æºæ§ (AI) çåéé²è¡é«çæ±ºç­æµç¨ï¼ééå¸¸è¢«èªçºæ¯ä¸éæä¸é£ä»¥çè§£çãå¨æ¬æä¸­ï¼æåéç¨æåé²çå¯è§£éäººå·¥æºæ§ (XAI) æ¹æ³ä¾è§£éé»ç AI æ¨¡åå¨ç²çèºçµç¯è¨ºæ·æç¨ä¸­çé æ¸¬çµæãæåæåºæ°çåºæ¼çµ±è¨ç XAI æ¹æ³ï¼å³æ ¸å¯åº¦ä¼°è¨åå¯åº¦åï¼ä¾è§£éæªæª¢æ¸¬å°çµç¯çææ³ãXAI æ¹æ³çæè½æå¨å®æ§åå®éæ¯è¼ä¸è¢«è¦çºæ¹åè³æåè³ªåæ¨¡åæè½çåé¥ãæå¾ï¼æåé²è¡èª¿æ¥ä»¥è©ä¼°é«å¸«åæ£èå° XAI å°æ¨¡åå¨ç²çèºçµç¯å½±åä¸­æ±ºç­çè§£éçä¿¡ä»»åº¦ã

##### **Cybersecurity of AI medical devices: risks, legislation, and challenges**
2303.03140v1 by Elisabetta Biasin, Erik Kamenjasevic, Kaspar Rosager Ludvigsen

Medical devices and artificial intelligence systems rapidly transform
healthcare provisions. At the same time, due to their nature, AI in or as
medical devices might get exposed to cyberattacks, leading to patient safety
and security risks. This book chapter is divided into three parts. The first
part starts by setting the scene where we explain the role of cybersecurity in
healthcare. Then, we briefly define what we refer to when we talk about AI that
is considered a medical device by itself or supports one. To illustrate the
risks such medical devices pose, we provide three examples: the poisoning of
datasets, social engineering, and data or source code extraction. In the second
part, the paper provides an overview of the European Union's regulatory
framework relevant for ensuring the cybersecurity of AI as or in medical
devices (MDR, NIS Directive, Cybersecurity Act, GDPR, the AI Act proposal and
the NIS 2 Directive proposal). Finally, the third part of the paper examines
possible challenges stemming from the EU regulatory framework. In particular,
we look toward the challenges deriving from the two legislative proposals and
their interaction with the existing legislation concerning AI medical devices'
cybersecurity. They are structured as answers to the following questions: (1)
how will the AI Act interact with the MDR regarding the cybersecurity and
safety requirements?; (2) how should we interpret incident notification
requirements from the NIS 2 Directive proposal and MDR?; and (3) what are the
consequences of the evolving term of critical infrastructures?
  [This is a draft chapter. The final version will be available in Research
Handbook on Health, AI and the Law edited by Barry Solaiman & I. Glenn Cohen,
forthcoming 2023, Edward Elgar Publishing Ltd]

æè¦ï¼é«çè¨­ååäººå·¥æºæ§ç³»çµ±å¿«éè½åé«çä¿å¥çæä¾æ¹å¼ãåæï¼ç±æ¼å¶æ¬è³ªï¼é«çè¨­åä¸­æä½çºé«çè¨­åçäººå·¥æºæ§å¯è½æé­åç¶²è·¯æ»æï¼é²èå°è´æ£èå®å¨åå®å¨é¢¨éªãæ¬ç« ç¯åçºä¸é¨åãç¬¬ä¸é¨åå¾è¨­å®å ´æ¯éå§ï¼èªªæç¶²è·¯å®å¨å¨é«çä¿å¥ä¸­çè§è²ãç¶å¾ï¼æåç°¡è¦å®ç¾©æåå¨è«è«è¢«è¦çºé«çè¨­åæ¬èº«ææ¯æ´é«çè¨­åçäººå·¥æºæ§ææææ¶çå§å®¹ãçºäºèªªææ­¤é¡é«çè¨­åå¸¶ä¾çé¢¨éªï¼æåæä¾äºä¸åç¯ä¾ï¼è³æéä¸­æ¯ãç¤¾æå·¥ç¨åè³ææåå§ç¢¼èåãå¨ç¬¬äºé¨åï¼æ¬ææ¦è¿°äºæ­ççç£ç®¡æ¶æ§ï¼èç¢ºä¿é«çè¨­åä¸­æä½çºé«çè¨­åçäººå·¥æºæ§çç¶²è·¯å®å¨ç¸éï¼é«çå¨ææ³è¦ãç¶²è·¯èè³è¨å®å¨æä»¤ãç¶²è·¯å®å¨æ³ãä¸è¬è³æä¿è­·è¦ç¯ãäººå·¥æºæ§æ³ææ¡åç¶²è·¯èè³è¨å®å¨ 2 æä»¤ææ¡ï¼ãæå¾ï¼æ¬æçç¬¬ä¸é¨åæ¢è¨æºèªæ­çç£ç®¡æ¶æ§çæ½å¨ææ°ãç¹å¥æ¯ï¼æåå±ææºèªéå©é ç«æ³ææ¡çææ°ï¼ä»¥åå®åèç¾æéæ¼äººå·¥æºæ§é«çè¨­åç¶²è·¯å®å¨çç«æ³ä¹éçäºåãå®åè¢«æ¶æ§çºä»¥ä¸åé¡çè§£ç­ï¼(1) äººå·¥æºæ§æ³å°å¦ä½èé«çå¨ææ³è¦äºåï¼å°±ç¶²è·¯å®å¨åå®å¨è¦æ±èè¨ï¼(2) æåæå¦ä½è§£è®ç¶²è·¯èè³è¨å®å¨ 2 æä»¤ææ¡åé«çå¨ææ³è¦çäºä»¶éç¥è¦æ±ï¼(3) ééµåºç¤è¨­æ½æ¼é²çè¡èªæå¸¶ä¾ä»éº¼å¾æï¼
[éæ¯èç¨¿ç« ç¯ãæçµçæ¬å°åè¼æ¼ Barry Solaiman å I. Glenn Cohen ç·¨è¼¯çãå¥åº·ãäººå·¥æºæ§èæ³å¾ç ç©¶æåãä¸­ï¼2023 å¹´åºçï¼Edward Elgar Publishing Ltd]

##### **LAVA: Granular Neuron-Level Explainable AI for Alzheimer's Disease Assessment from Fundus Images**
2302.03008v2 by Nooshin Yousefzadeh, Charlie Tran, Adolfo Ramirez-Zamora, Jinghua Chen, Ruogu Fang, My T. Thai

Alzheimer's Disease (AD) is a progressive neurodegenerative disease and the
leading cause of dementia. Early diagnosis is critical for patients to benefit
from potential intervention and treatment. The retina has been hypothesized as
a diagnostic site for AD detection owing to its anatomical connection with the
brain. Developed AI models for this purpose have yet to provide a rational
explanation about the decision and neither infer the stage of disease's
progression. Along this direction, we propose a novel model-agnostic
explainable-AI framework, called Granular Neuron-level Explainer (LAVA), an
interpretation prototype that probes into intermediate layers of the
Convolutional Neural Network (CNN) models to assess the AD continuum directly
from the retinal imaging without longitudinal or clinical evaluation. This
method is applied to validate the retinal vasculature as a biomarker and
diagnostic modality for Alzheimer's Disease (AD) evaluation. UK Biobank
cognitive tests and vascular morphological features suggest LAVA shows strong
promise and effectiveness in identifying AD stages across the progression
continuum.

æè¦ï¼é¿è²æµ·é»ç (AD) æ¯ä¸ç¨®é²è¡æ§çç¥ç¶éåæ§ç¾çï¼ä¹æ¯å°è´å¤±æºççä¸»å ãæ©æè¨ºæ·å°æ¼æ£èæ¥åæ½å¨å¹²é åæ²»çè³ééè¦ãç±æ¼è¦ç¶²èèå¤§è¦æè§£åå­¸ä¸çé£çµï¼å æ­¤åè¨­è¦ç¶²èå¯ä»¥ä½çº AD æª¢æ¸¬çè¨ºæ·é¨ä½ãçºæ­¤ç®çèéç¼ç AI æ¨¡åï¼å°æªå°æ±ºç­æä¾åççè§£éï¼ä¹ç¡æ³æ¨è«ç¾çé²å±çéæ®µãæ²¿èéåæ¹åï¼æåæåºäºä¸åæ°ç©çæ¨¡åä¸å¯ç¥è«å¯è§£é AI æ¶æ§ï¼ç¨±çºé¡ç²ç¥ç¶åç´å¥è§£éå¨ (LAVA)ï¼éæ¯ä¸åè§£éååï¼å¯ä»¥æ¢æ¸¬å·ç©ç¥ç¶ç¶²è·¯ (CNN) æ¨¡åçä¸­éå±¤ï¼ä»¥ç´æ¥å¾è¦ç¶²èå½±åè©ä¼° AD é£çºé«ï¼èç¡éç¸±åæè¨åºè©ä¼°ãæ­¤æ¹æ³ç¨æ¼é©è­è¦ç¶²èè¡ç®¡ä½çºçç©æ¨è¨åé¿è²æµ·é»ç (AD) è©ä¼°çè¨ºæ·æ¹å¼ãè±åçç©è³æåº«çèªç¥æ¸¬è©¦åè¡ç®¡å½¢æç¹å¾µè¡¨æï¼LAVA å¨è­å¥é²å±é£çºé«ä¸­ç AD éæ®µæ¹é¢é¡¯ç¤ºåºå¼·å¤§çåæ¯åæææ§ã

##### **Diagrammatization: Rationalizing with diagrammatic AI explanations for abductive-deductive reasoning on hypotheses**
2302.01241v2 by Brian Y. Lim, Joseph P. Cahaly, Chester Y. F. Sng, Adam Chew

Many visualizations have been developed for explainable AI (XAI), but they
often require further reasoning by users to interpret. We argue that XAI should
support diagrammatic and abductive reasoning for the AI to perform hypothesis
generation and evaluation to reduce the interpretability gap. We propose
Diagrammatization to i) perform Peircean abductive-deductive reasoning, ii)
follow domain conventions, and iii) explain with diagrams visually or verbally.
We implemented DiagramNet for a clinical application to predict cardiac
diagnoses from heart auscultation, and explain with shape-based murmur
diagrams. In modeling studies, we found that DiagramNet not only provides
faithful murmur shape explanations, but also has better prediction performance
than baseline models. We further demonstrate the interpretability and
trustworthiness of diagrammatic explanations in a qualitative user study with
medical students, showing that clinically-relevant, diagrammatic explanations
are preferred over technical saliency map explanations. This work contributes
insights into providing domain-conventional abductive explanations for
user-centric XAI.

æè¦ï¼è¨±å¤è¦è¦ºåå·²è¢«éç¼ç¨æ¼å¯è§£éç AI (XAI)ï¼ä½å®åéå¸¸éè¦ä½¿ç¨èé²ä¸æ­¥æ¨çæè½è§£è®ãæåä¸»å¼µ XAI ææ¯æ´åè§£åæ¼ç¹¹æ¨çï¼è® AI å·è¡åè¨­ç¢çåè©ä¼°ä»¥ç¸®å°å¯è§£éæ§å·®è·ãæåæåºåè§£åä»¥ i) å·è¡ç®ç¾å£«æ¼ç¹¹-æ¼ç¹¹æ¨çï¼ii) éµå¾ªé åæ£ä¾ï¼ä»¥å iii) ä»¥è¦è¦ºæå£èªæ¹å¼èªªæåè¡¨ãæåå¯¦ä½äº DiagramNet é²è¡è¨åºæç¨ï¼ä»¥å¾å¿èè½è¨ºé æ¸¬å¿èè¨ºæ·ï¼ä¸¦ä»¥å½¢ççºåºç¤çéé³åèªªæãå¨å»ºæ¨¡ç ç©¶ä¸­ï¼æåç¼ç¾ DiagramNet ä¸åæä¾äºå¿ å¯¦çéé³å½¢çèªªæï¼èä¸æ¯åºæºæ¨¡åå·ææ´å¥½çé æ¸¬æè½ãæåé²ä¸æ­¥å¨èé«å­¸ççè³ªæ§ä½¿ç¨èç ç©¶ä¸­å±ç¤ºäºåè§£èªªæçå¯è§£éæ§åå¯ä¿¡åº¦ï¼é¡¯ç¤ºåºä»¥è¨åºç¸éçåè§£èªªæåªæ¼æè¡é¡¯èæ§åèªªæãéé å·¥ä½æå©æ¼æä¾ä»¥ä½¿ç¨èçºä¸­å¿ç XAI çé åæ£ä¾æ¼ç¹¹èªªæã

##### **LesionAid: Vision Transformers-based Skin Lesion Generation and Classification**
2302.01104v1 by Ghanta Sai Krishna, Kundrapu Supriya, Mallikharjuna Rao K, Meetiksha Sorgile

Skin cancer is one of the most prevalent forms of human cancer. It is
recognized mainly visually, beginning with clinical screening and continuing
with the dermoscopic examination, histological assessment, and specimen
collection. Deep convolutional neural networks (CNNs) perform highly segregated
and potentially universal tasks against a classified finegrained object. This
research proposes a novel multi-class prediction framework that classifies skin
lesions based on ViT and ViTGAN. Vision transformers-based GANs (Generative
Adversarial Networks) are utilized to tackle the class imbalance. The framework
consists of four main phases: ViTGANs, Image processing, and explainable AI.
Phase 1 consists of generating synthetic images to balance all the classes in
the dataset. Phase 2 consists of applying different data augmentation
techniques and morphological operations to increase the size of the data.
Phases 3 & 4 involve developing a ViT model for edge computing systems that can
identify patterns and categorize skin lesions from the user's skin visible in
the image. In phase 3, after classifying the lesions into the desired class
with ViT, we will use explainable AI (XAI) that leads to more explainable
results (using activation maps, etc.) while ensuring high predictive accuracy.
Real-time images of skin diseases can capture by a doctor or a patient using
the camera of a mobile application to perform an early examination and
determine the cause of the skin lesion. The whole framework is compared with
the existing frameworks for skin lesion detection.

æè¦ï¼ç®èçæ¯äººé¡ææ®éçççé¡åä¹ä¸ãå®çè­å¥ä¸»è¦ä¾è³´è¦è¦ºï¼å¾è¨åºç¯©æª¢éå§ï¼æ¥èæ¯ç®èé¡æª¢æ¥ãçµç¹å­¸è©ä¼°ï¼ä»¥åæª¢é«æ¶éãæ·±åº¦å·ç©ç¥ç¶ç¶²è·¯ (CNN) å¯éå°åé¡çç´°ç²åº¦ç©ä»¶å·è¡é«åº¦åéä¸æ½å¨éç¨çä»»åãæ¬ç ç©¶æåºä¸åæ°ç©çå¤é¡å¥é æ¸¬æ¶æ§ï¼å®ä»¥ ViT å ViTGAN çºåºç¤å°ç®èçç¶é²è¡åé¡ãåºæ¼è¦è¦ºè½æå¨ç GANï¼çæå°æç¶²è·¯ï¼ç¨æ¼è§£æ±ºé¡å¥ä¸å¹³è¡¡åé¡ãæ­¤æ¶æ§åå«ååä¸»è¦éæ®µï¼ViTGANãå½±åèçåå¯è§£é AIãç¬¬ä¸éæ®µåæ¬ç¢çåæå½±åï¼ä»¥å¹³è¡¡è³æéä¸­çææé¡å¥ãç¬¬äºéæ®µåæ¬æç¨ä¸åçè³ææ´åæè¡åå½¢æéç®ï¼ä»¥å¢å è³æå¤§å°ãç¬¬ä¸åç¬¬åéæ®µæ¶åéç¼é©ç¨æ¼éç·£éç®ç³»çµ±ç ViT æ¨¡åï¼è©²æ¨¡åå¯ä»¥è­å¥åæ¡ï¼ä¸¦å°å½±åä¸­ç¨æ¶ç®èå¯è¦çç®èçç¶é²è¡åé¡ãå¨ç¬¬ä¸éæ®µï¼å¨ä½¿ç¨ ViT å°çç¶åé¡å°æéçé¡å¥å¾ï¼æåå°ä½¿ç¨å¯è§£é AI (XAI)ï¼å®æç¢çæ´å·å¯è§£éæ§ççµæï¼ä½¿ç¨åç¨åç­ï¼ï¼åæç¢ºä¿é«é æ¸¬æºç¢ºåº¦ãç®èç¾ççå³æå½±åå¯ä»¥ç¨è¡åæç¨ç¨å¼çç¸æ©ç±é«çææ£èæ·åï¼ä»¥å·è¡æ©ææª¢æ¥ä¸¦ç¢ºå®ç®èçç¶çåå ãæ´åæ¶æ§èç¾æçç®èçç¶åµæ¸¬æ¶æ§é²è¡æ¯è¼ã

##### **SkinCon: A skin disease dataset densely annotated by domain experts for fine-grained model debugging and analysis**
2302.00785v1 by Roxana Daneshjou, Mert Yuksekgonul, Zhuo Ran Cai, Roberto Novoa, James Zou

For the deployment of artificial intelligence (AI) in high-risk settings,
such as healthcare, methods that provide interpretability/explainability or
allow fine-grained error analysis are critical. Many recent methods for
interpretability/explainability and fine-grained error analysis use concepts,
which are meta-labels that are semantically meaningful to humans. However,
there are only a few datasets that include concept-level meta-labels and most
of these meta-labels are relevant for natural images that do not require domain
expertise. Densely annotated datasets in medicine focused on meta-labels that
are relevant to a single disease such as melanoma. In dermatology, skin disease
is described using an established clinical lexicon that allows clinicians to
describe physical exam findings to one another. To provide a medical dataset
densely annotated by domain experts with annotations useful across multiple
disease processes, we developed SkinCon: a skin disease dataset densely
annotated by dermatologists. SkinCon includes 3230 images from the Fitzpatrick
17k dataset densely annotated with 48 clinical concepts, 22 of which have at
least 50 images representing the concept. The concepts used were chosen by two
dermatologists considering the clinical descriptor terms used to describe skin
lesions. Examples include "plaque", "scale", and "erosion". The same concepts
were also used to label 656 skin disease images from the Diverse Dermatology
Images dataset, providing an additional external dataset with diverse skin tone
representations. We review the potential applications for the SkinCon dataset,
such as probing models, concept-based explanations, and concept bottlenecks.
Furthermore, we use SkinCon to demonstrate two of these use cases: debugging
mistakes of an existing dermatology AI model with concepts and developing
interpretable models with post-hoc concept bottleneck models.

æè¦ï¼<paragraph>å¨é«é¢¨éªç°å¢ä¸­é¨ç½²äººå·¥æºæ§ (AI)ï¼ä¾å¦é«çä¿å¥ï¼ï¼æä¾å¯è§£éæ§/å¯èªªææ§çæ¹æ³æåè¨±ç²¾ç´°é¯èª¤åæéå¸¸éè¦ãè¨±å¤è¿æç¨æ¼å¯è§£éæ§/å¯èªªææ§åç²¾ç´°é¯èª¤åæçæ¹æ³é½ä½¿ç¨æ¦å¿µï¼éäºæ¦å¿µæ¯å°äººé¡å·æèªç¾©æç¾©çåæ¨ç±¤ãç¶èï¼åªæå°æ¸è³æéåå«æ¦å¿µå±¤ç´çåæ¨ç±¤ï¼èä¸éäºåæ¨ç±¤å¤§å¤èä¸éè¦é åå°æ¥­ç¥è­çèªç¶å½±åç¸éãå°æ³¨æ¼å®ä¸ç¾çï¼ä¾å¦é»è²ç´ ç¤ï¼çåæ¨ç±¤çé«å­¸å¯éæ¨è¨è³æéãå¨ç®èç§ä¸­ï¼ç®èç¾ççæè¿°ä½¿ç¨æ¢å®çè¨åºè©å½ï¼è®è¨åºé«çå¯ä»¥å½¼æ­¤æè¿°èº«é«æª¢æ¥çµæãçºäºæä¾ç±é åå°å®¶å¯éæ¨è¨çé«å­¸è³æéï¼å¶ä¸­åå«å¯è·¨å¤ç¨®ç¾çéç¨ä½¿ç¨çæ¨è¨ï¼æåéç¼äº SkinConï¼ç±ç®èç§é«å¸«å¯éæ¨è¨çç®èç¾çè³æéãSkinCon åå«ä¾èª Fitzpatrick 17k è³æéç 3230 å¼µå½±åï¼å¯éæ¨è¨äº 48 åè¨åºæ¦å¿µï¼å¶ä¸­ 22 åæ¦å¿µè³å°æ 50 å¼µå½±åä»£è¡¨è©²æ¦å¿µãæä½¿ç¨çæ¦å¿µæ¯ç±å©ä½ç®èç§é«å¸«å¨èéç¨æ¼æè¿°ç®èçè®çè¨åºæè¿°è©å½å¾é¸åºçãç¯ä¾åæ¬ãæå¡ãããé±å±ãåãç³çããç¸åçæ¦å¿µä¹ç¨æ¼æ¨è¨ä¾èª Diverse Dermatology Images è³æéç 656 å¼µç®èç¾çå½±åï¼æä¾å·æå¤æ¨£èè²è¡¨ç¤ºçé¡å¤å¤é¨è³æéãæåæª¢è¦ SkinCon è³æéçæ½å¨æç¨ï¼ä¾å¦æ¢æ¸¬æ¨¡åãåºæ¼æ¦å¿µçèªªæåæ¦å¿µç¶é ¸ãæ­¤å¤ï¼æåä½¿ç¨ SkinCon ä¾å±ç¤ºéå©åä½¿ç¨æ¡ä¾ï¼ä½¿ç¨æ¦å¿µé¤é¯ç¾æç®èç§ AI æ¨¡åçé¯èª¤ï¼ä»¥åä½¿ç¨äºå¾æ¦å¿µç¶é ¸æ¨¡åéç¼å¯è§£éçæ¨¡åã</paragraph>

##### **Decision-Focused Evaluation: Analyzing Performance of Deployed Restless Multi-Arm Bandits**
2301.07835v1 by Paritosh Verma, Shresth Verma, Aditya Mate, Aparna Taneja, Milind Tambe

Restless multi-arm bandits (RMABs) is a popular decision-theoretic framework
that has been used to model real-world sequential decision making problems in
public health, wildlife conservation, communication systems, and beyond.
Deployed RMAB systems typically operate in two stages: the first predicts the
unknown parameters defining the RMAB instance, and the second employs an
optimization algorithm to solve the constructed RMAB instance.
  In this work we provide and analyze the results from a first-of-its-kind
deployment of an RMAB system in public health domain, aimed at improving
maternal and child health. Our analysis is focused towards understanding the
relationship between prediction accuracy and overall performance of deployed
RMAB systems. This is crucial for determining the value of investing in
improving predictive accuracy towards improving the final system performance,
and is useful for diagnosing, monitoring deployed RMAB systems.
  Using real-world data from our deployed RMAB system, we demonstrate that an
improvement in overall prediction accuracy may even be accompanied by a
degradation in the performance of RMAB system -- a broad investment of
resources to improve overall prediction accuracy may not yield expected
results. Following this, we develop decision-focused evaluation metrics to
evaluate the predictive component and show that it is better at explaining
(both empirically and theoretically) the overall performance of a deployed RMAB
system.

æè¦ï¼ä¸å®åçå¤èå¼·ç (RMAB) æ¯ä¸åæµè¡çæ±ºç­çè«æ¶æ§ï¼å·²è¢«ç¨æ¼æ¨¡æ¬å¬å±è¡çãéçåç©ä¿è²ãéè¨ç³»çµ±ç­é åççå¯¦ä¸çé åºæ±ºç­åé¡ãå·²é¨ç½²ç RMAB ç³»çµ±éå¸¸åå©åéæ®µéä½ï¼ç¬¬ä¸åéæ®µé æ¸¬å®ç¾© RMAB å·è¡åé«çæªç¥åæ¸ï¼ç¬¬äºåéæ®µæ¡ç¨æä½³åæ¼ç®æ³ä¾è§£æ±ºå·²å»ºæ§ç RMAB å·è¡åé«ã
å¨æ¬ç ç©¶ä¸­ï¼æåæä¾ä¸¦åæäºå¨å¬å±è¡çé åä¸­é¦æ¬¡é¨ç½² RMAB ç³»çµ±ççµæï¼ç®æ¨æ¯æ¹åå­ç¢å©¦ååç«¥å¥åº·ãæåçåæèéæ¼äºè§£é æ¸¬æºç¢ºåº¦èå·²é¨ç½² RMAB ç³»çµ±çæ´é«æè½ä¹éçéä¿ãéå°æ¼æ±ºå®æè³æ¼æ¹åé æ¸¬æºç¢ºåº¦ä»¥æåæçµç³»çµ±æè½çå¹å¼è³ééè¦ï¼ä¸¦ä¸æå©æ¼è¨ºæ·ãç£æ§å·²é¨ç½²ç RMAB ç³»çµ±ã
ä½¿ç¨æåå·²é¨ç½² RMAB ç³»çµ±ä¸­ççå¯¦ä¸çè³æï¼æåè­æäºæ´é«é æ¸¬æºç¢ºåº¦çæåçè³å¯è½ä¼´é¨è RMAB ç³»çµ±æè½çä¸éââå»£æ³æå¥è³æºä»¥æ¹åæ´é«é æ¸¬æºç¢ºåº¦å¯è½ç¡æ³ç¢çé æççµæãå¨æ­¤ä¹å¾ï¼æåéç¼äºä»¥æ±ºç­çºéé»çè©ä¼°ææ¨ä¾è©ä¼°é æ¸¬åä»¶ï¼ä¸¦è­æå®æ´è½è§£éå·²é¨ç½² RMAB ç³»çµ±çæ´é«æè½ï¼ç¡è«æ¯ç¶é©ä¸æçè«ä¸ï¼ã

##### **Exemplars and Counterexemplars Explanations for Image Classifiers, Targeting Skin Lesion Labeling**
2302.03033v1 by Carlo Metta, Riccardo Guidotti, Yuan Yin, Patrick Gallinari, Salvatore Rinzivillo

Explainable AI consists in developing mechanisms allowing for an interaction
between decision systems and humans by making the decisions of the formers
understandable. This is particularly important in sensitive contexts like in
the medical domain. We propose a use case study, for skin lesion diagnosis,
illustrating how it is possible to provide the practitioner with explanations
on the decisions of a state of the art deep neural network classifier trained
to characterize skin lesions from examples. Our framework consists of a trained
classifier onto which an explanation module operates. The latter is able to
offer the practitioner exemplars and counterexemplars for the classification
diagnosis thus allowing the physician to interact with the automatic diagnosis
system. The exemplars are generated via an adversarial autoencoder. We
illustrate the behavior of the system on representative examples.

æè¦ï¼å¯è§£é AI æ¯å¨éç¼æ©å¶ï¼è®æ±ºç­ç³»çµ±èäººé¡ä¹éè½äºåï¼ä¸¦è®åèçæ±ºç­è®å¾å¯ä»¥çè§£ãéå¨ææçèçµ¡ä¸­ç¹å¥éè¦ï¼ä¾å¦å¨é«çé åãæåæåºä¸åä½¿ç¨æ¡ä¾ç ç©¶ï¼ç¨æ¼ç®èçè®è¨ºæ·ï¼èªªæå¦ä½è®å·æ¥­é«å¸«äºè§£æåé²çæ·±åº¦ç¥ç¶ç¶²è·¯åé¡å¨å¨æ±ºç­ä¸çè§£éï¼è©²åé¡å¨ç¶éè¨ç·´ï¼å¯ä»¥å¾ç¯ä¾ä¸­æè¿°ç®èçè®ãæåçæ¶æ§åå«ä¸åè¨ç·´éçåé¡å¨ï¼è§£éæ¨¡çµæå¨è©²åé¡å¨ä¸éä½ãå¾èè½å¤ çºåé¡è¨ºæ·æä¾å·æ¥­é«å¸«ç¯ä¾ååä¾ï¼å æ­¤è®é«å¸«å¯ä»¥èèªåè¨ºæ·ç³»çµ±äºåãç¯ä¾æ¯ééå°æå¼èªåç·¨ç¢¼å¨ç¢ççãæåèªªæç³»çµ±å¨ä»£è¡¨æ§ç¯ä¾ä¸çè¡çºã


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-16**|**Does Refusal Training in LLMs Generalize to the Past Tense?**|Maksym Andriushchenko et.al.|[2407.11969v1](http://arxiv.org/abs/2407.11969v1)|[link](https://github.com/tml-epfl/llm-past-tense)|
|**2024-07-16**|**Efficient Training with Denoised Neural Weights**|Yifan Gong et.al.|[2407.11966v1](http://arxiv.org/abs/2407.11966v1)|null|
|**2024-07-16**|**NeedleBench: Can LLMs Do Retrieval and Reasoning in 1 Million Context Window?**|Mo Li et.al.|[2407.11963v1](http://arxiv.org/abs/2407.11963v1)|[link](https://github.com/open-compass/opencompass)|
|**2024-07-16**|**Motion-Oriented Compositional Neural Radiance Fields for Monocular Dynamic Human Modeling**|Jaehyeok Kim et.al.|[2407.11962v1](http://arxiv.org/abs/2407.11962v1)|null|
|**2024-07-16**|**Rethinking Transformer-based Multi-document Summarization: An Empirical Investigation**|Congbo Ma et.al.|[2407.11948v1](http://arxiv.org/abs/2407.11948v1)|null|
|**2024-07-16**|**Fine-grained Hallucination Detection and Mitigation in Long-form Question Answering**|Rachneet Sachdeva et.al.|[2407.11930v1](http://arxiv.org/abs/2407.11930v1)|[link](https://github.com/ukplab/arxiv2024-lfqa-hallucination)|
|**2024-07-16**|**Tackling Oversmoothing in GNN via Graph Sparsification: A Truss-based Approach**|Tanvir Hossain et.al.|[2407.11928v1](http://arxiv.org/abs/2407.11928v1)|null|
|**2024-07-16**|**What's Wrong? Refining Meeting Summaries with LLM Feedback**|Frederic Kirstein et.al.|[2407.11919v1](http://arxiv.org/abs/2407.11919v1)|null|
|**2024-07-16**|**Imitation of human motion achieves natural head movements for humanoid robots in an active-speaker detection task**|Bosong Ding et.al.|[2407.11915v1](http://arxiv.org/abs/2407.11915v1)|[link](https://github.com/dingdingding60/humanoids2024hri)|
|**2024-07-16**|**Bridging Weighted First Order Model Counting and Graph Polynomials**|Qipeng Kuang et.al.|[2407.11877v1](http://arxiv.org/abs/2407.11877v1)|[link](https://github.com/l2l7l9p/polynomials-for-wfomc)|
|**2024-07-16**|**Evaluating Task-Oriented Dialogue Consistency through Constraint Satisfaction**|Tiziano Labruna et.al.|[2407.11857v1](http://arxiv.org/abs/2407.11857v1)|null|
|**2024-07-16**|**Scaling Sign Language Translation**|Biao Zhang et.al.|[2407.11855v1](http://arxiv.org/abs/2407.11855v1)|null|
|**2024-07-16**|**Zero-shot Cross-Lingual Transfer for Synthetic Data Generation in Grammatical Error Detection**|Gaetan Lopez Latouche et.al.|[2407.11854v1](http://arxiv.org/abs/2407.11854v1)|null|
|**2024-07-16**|**Schema Matching with Large Language Models: an Experimental Study**|Marcel Parciak et.al.|[2407.11852v1](http://arxiv.org/abs/2407.11852v1)|[link](https://github.com/uhasselt-dsi-data-systems-lab/code-schema-matching-llms-artefacs)|
|**2024-07-16**|**Variational Randomized Smoothing for Sample-Wise Adversarial Robustness**|Ryo Hase et.al.|[2407.11844v1](http://arxiv.org/abs/2407.11844v1)|null|
|**2024-07-16**|**InferAct: Inferring Safe Actions for LLM-Based Agents Through Preemptive Evaluation and Human Feedback**|Haishuo Fang et.al.|[2407.11843v1](http://arxiv.org/abs/2407.11843v1)|null|
|**2024-07-16**|**LoFTI: Localization and Factuality Transfer to Indian Locales**|Sona Elza Simon et.al.|[2407.11833v1](http://arxiv.org/abs/2407.11833v1)|[link](https://github.com/csalt-research/lofti)|
|**2024-07-16**|**Personalized Conversational Travel Assistant powered by Generative AI**|Alexio Cassani et.al.|[2407.11830v1](http://arxiv.org/abs/2407.11830v1)|null|
|**2024-07-16**|**GPT Assisted Annotation of Rhetorical and Linguistic Features for Interpretable Propaganda Technique Detection in News Text**|Kyle Hamilton et.al.|[2407.11827v1](http://arxiv.org/abs/2407.11827v1)|null|
|**2024-07-16**|**The Future of Data Science Education**|Brian Wright et.al.|[2407.11824v1](http://arxiv.org/abs/2407.11824v1)|null|
|**2024-07-16**|**Invariant Consistency for Knowledge Distillation**|Nikolaos Giakoumoglou et.al.|[2407.11802v1](http://arxiv.org/abs/2407.11802v1)|null|
|**2024-07-16**|**PipeInfer: Accelerating LLM Inference using Asynchronous Pipelined Speculation**|Branden Butler et.al.|[2407.11798v1](http://arxiv.org/abs/2407.11798v1)|null|
|**2024-07-16**|**Characterizing and Understanding HGNN Training on GPUs**|Dengke Han et.al.|[2407.11790v1](http://arxiv.org/abs/2407.11790v1)|null|
|**2024-07-16**|**Large Language Models as Misleading Assistants in Conversation**|Betty Li Hou et.al.|[2407.11789v1](http://arxiv.org/abs/2407.11789v1)|null|
|**2024-07-16**|**Data-Juicer Sandbox: A Comprehensive Suite for Multimodal Data-Model Co-development**|Daoyuan Chen et.al.|[2407.11784v1](http://arxiv.org/abs/2407.11784v1)|[link](https://github.com/modelscope/data-juicer)|
|**2024-07-16**|**SwitchCIT: Switching for Continual Instruction Tuning of Large Language Models**|Xinbo Wu et.al.|[2407.11780v1](http://arxiv.org/abs/2407.11780v1)|null|
|**2024-07-16**|**Sharif-MGTD at SemEval-2024 Task 8: A Transformer-Based Approach to Detect Machine Generated Text**|Seyedeh Fatemeh Ebrahimi et.al.|[2407.11774v1](http://arxiv.org/abs/2407.11774v1)|null|
|**2024-07-16**|**Educational Personalized Learning Path Planning with Large Language Models**|Chee Ng et.al.|[2407.11773v1](http://arxiv.org/abs/2407.11773v1)|null|
|**2024-07-16**|**XEdgeAI: A Human-centered Industrial Inspection Framework with Data-centric Explainable Edge AI Approach**|Truong Thanh Hung Nguyen et.al.|[2407.11771v1](http://arxiv.org/abs/2407.11771v1)|null|
|**2024-07-16**|**Robust Utility-Preserving Text Anonymization Based on Large Language Models**|Tianyu Yang et.al.|[2407.11770v1](http://arxiv.org/abs/2407.11770v1)|[link](https://github.com/ukplab/arxiv2024-rupta)|
|**2024-07-16**|**Vectoring Languages**|Joseph Chen et.al.|[2407.11766v1](http://arxiv.org/abs/2407.11766v1)|null|
|**2024-07-16**|**A Channel Attention-Driven Hybrid CNN Framework for Paddy Leaf Disease Detection**|Pandiyaraju V et.al.|[2407.11753v1](http://arxiv.org/abs/2407.11753v1)|null|
|**2024-07-16**|**Universal Sound Separation with Self-Supervised Audio Masked Autoencoder**|Junqi Zhao et.al.|[2407.11745v1](http://arxiv.org/abs/2407.11745v1)|null|
|**2024-07-16**|**How Are LLMs Mitigating Stereotyping Harms? Learning from Search Engine Studies**|Alina Leidinger et.al.|[2407.11733v1](http://arxiv.org/abs/2407.11733v1)|null|
|**2024-07-16**|**NITRO-D: Native Integer-only Training of Deep Convolutional Neural Networks**|Alberto Pirillo et.al.|[2407.11698v1](http://arxiv.org/abs/2407.11698v1)|null|
|**2024-07-16**|**CCoE: A Compact LLM with Collaboration of Experts**|Shaomang Huang et.al.|[2407.11686v2](http://arxiv.org/abs/2407.11686v2)|null|
|**2024-07-16**|**MINI-LLM: Memory-Efficient Structured Pruning for Large Language Models**|Hongrong Cheng et.al.|[2407.11681v1](http://arxiv.org/abs/2407.11681v1)|null|
|**2024-07-16**|**SKADA-Bench: Benchmarking Unsupervised Domain Adaptation Methods with Realistic Validation**|Yanis Lalou et.al.|[2407.11676v1](http://arxiv.org/abs/2407.11676v1)|[link](https://github.com/scikit-adaptation/skada-bench)|
|**2024-07-16**|**ECoh: Turn-level Coherence Evaluation for Multilingual Dialogues**|John MendonÃ§a et.al.|[2407.11660v1](http://arxiv.org/abs/2407.11660v1)|null|
|**2024-07-16**|**R-SFLLM: Jamming Resilient Framework for Split Federated Learning with Large Language Models**|Aladin Djuhera et.al.|[2407.11654v1](http://arxiv.org/abs/2407.11654v1)|null|
|**2024-07-16**|**CCVA-FL: Cross-Client Variations Adaptive Federated Learning for Medical Imaging**|Sunny Gupta et.al.|[2407.11652v1](http://arxiv.org/abs/2407.11652v1)|null|
|**2024-07-16**|**A Comprehensive Evaluation of Large Language Models on Temporal Event Forecasting**|He Chang et.al.|[2407.11638v1](http://arxiv.org/abs/2407.11638v1)|null|
|**2024-07-16**|**Rethinking Fair Graph Neural Networks from Re-balancing**|Zhixun Li et.al.|[2407.11624v1](http://arxiv.org/abs/2407.11624v1)|[link](https://github.com/zhixunlee/fairgb)|
|**2024-07-16**|**Graph Dimension Attention Networks for Enterprise Credit Assessment**|Shaopeng Wei et.al.|[2407.11615v1](http://arxiv.org/abs/2407.11615v1)|null|
|**2024-07-16**|**Bringing AI Participation Down to Scale: A Comment on Open AIs Democratic Inputs to AI Project**|David Moats et.al.|[2407.11613v1](http://arxiv.org/abs/2407.11613v1)|null|
|**2024-07-16**|**Statistical Reachability Analysis of Stochastic Cyber-Physical Systems under Distribution Shift**|Navid Hashemi et.al.|[2407.11609v1](http://arxiv.org/abs/2407.11609v1)|null|
|**2024-07-16**|**The Foundations of Tokenization: Statistical and Computational Concerns**|Juan Luis Gastaldi et.al.|[2407.11606v1](http://arxiv.org/abs/2407.11606v1)|null|
|**2024-07-16**|**Enhancing TinyML Security: Study of Adversarial Attack Transferability**|Parin Shah et.al.|[2407.11599v1](http://arxiv.org/abs/2407.11599v1)|null|
|**2024-07-16**|**DiNO-Diffusion. Scaling Medical Diffusion via Self-Supervised Pre-Training**|Guillermo Jimenez-Perez et.al.|[2407.11594v1](http://arxiv.org/abs/2407.11594v1)|null|
|**2024-07-16**|**AdaptEval: Evaluating Large Language Models on Domain Adaptation for Text Summarization**|Anum Afzal et.al.|[2407.11591v1](http://arxiv.org/abs/2407.11591v1)|null|
|**2024-07-16**|**QVD: Post-training Quantization for Video Diffusion Models**|Shilong Tian et.al.|[2407.11585v2](http://arxiv.org/abs/2407.11585v2)|null|
|**2024-07-16**|**Probing the Efficacy of Federated Parameter-Efficient Fine-Tuning of Vision Transformers for Medical Image Classification**|Naif Alkhunaizi et.al.|[2407.11573v1](http://arxiv.org/abs/2407.11573v1)|null|
|**2024-07-16**|**TGIF: Text-Guided Inpainting Forgery Dataset**|Hannes Mareen et.al.|[2407.11566v1](http://arxiv.org/abs/2407.11566v1)|[link](https://github.com/idlabmedia/tgif-dataset)|
|**2024-07-16**|**Self-Guided Generation of Minority Samples Using Diffusion Models**|Soobin Um et.al.|[2407.11555v1](http://arxiv.org/abs/2407.11555v1)|[link](https://github.com/soobin-um/sg-minority)|
|**2024-07-16**|**Learning Global and Local Features of Power Load Series Through Transformer and 2D-CNN: An image-based Multi-step Forecasting Approach Incorporating Phase Space Reconstruction**|Zihan Tang et.al.|[2407.11553v1](http://arxiv.org/abs/2407.11553v1)|null|
|**2024-07-16**|**Optimizing KV Cache Eviction in LLMs: Adaptive Allocation for Enhanced Budget Utilization**|Yuan Feng et.al.|[2407.11550v1](http://arxiv.org/abs/2407.11550v1)|null|
|**2024-07-16**|**How Personality Traits Influence Negotiation Outcomes? A Simulation based on Large Language Models**|Yin Jou Huang et.al.|[2407.11549v1](http://arxiv.org/abs/2407.11549v1)|null|
|**2024-07-16**|**AEMIM: Adversarial Examples Meet Masked Image Modeling**|Wenzhao Xiang et.al.|[2407.11537v1](http://arxiv.org/abs/2407.11537v1)|null|
|**2024-07-16**|**Fine-Tuning Medical Language Models for Enhanced Long-Contextual Understanding and Domain Expertise**|Qimin Yang et.al.|[2407.11536v1](http://arxiv.org/abs/2407.11536v1)|null|
|**2024-07-16**|**LRQ: Optimizing Post-Training Quantization for Large Language Models by Learning Low-Rank Weight-Scaling Matrices**|Jung Hyun Lee et.al.|[2407.11534v1](http://arxiv.org/abs/2407.11534v1)|[link](https://github.com/onliwad101/flexround_lrq)|
|**2024-07-16**|**Reasoning with Large Language Models, a Survey**|Aske Plaat et.al.|[2407.11511v1](http://arxiv.org/abs/2407.11511v1)|null|
|**2024-07-16**|**Diff-MTS: Temporal-Augmented Conditional Diffusion-based AIGC for Industrial Time Series Towards the Large Model Era**|Lei Ren et.al.|[2407.11501v1](http://arxiv.org/abs/2407.11501v1)|null|
|**2024-07-16**|**An AI System for Continuous Knee Osteoarthritis Severity Grading Using Self-Supervised Anomaly Detection with Limited Data**|Niamh Belton et.al.|[2407.11500v1](http://arxiv.org/abs/2407.11500v1)|[link](https://github.com/niamhbelton/ss-fewsome_disease_severity_knee_osteoarthritis)|
|**2024-07-16**|**MMSD-Net: Towards Multi-modal Stuttering Detection**|Liangyu Nie et.al.|[2407.11492v1](http://arxiv.org/abs/2407.11492v1)|null|
|**2024-07-16**|**A Meta-Learning Approach for Multi-Objective Reinforcement Learning in Sustainable Home Environments**|Junlin Lu et.al.|[2407.11489v1](http://arxiv.org/abs/2407.11489v1)|null|
|**2024-07-16**|**Scientific QA System with Verifiable Answers**|Adela LjajiÄ et.al.|[2407.11485v1](http://arxiv.org/abs/2407.11485v1)|null|
|**2024-07-16**|**The Oscars of AI Theater: A Survey on Role-Playing with Language Models**|Nuo Chen et.al.|[2407.11484v2](http://arxiv.org/abs/2407.11484v2)|[link](https://github.com/nuochenpku/awesome-role-play-papers)|
|**2024-07-16**|**Multi-Channel Masked Autoencoder and Comprehensive Evaluations for Reconstructing 12-Lead ECG from Arbitrary Single-Lead ECG**|Jiarong Chen et.al.|[2407.11481v1](http://arxiv.org/abs/2407.11481v1)|[link](https://github.com/chenjiar3/mcma)|
|**2024-07-16**|**AIGC for Industrial Time Series: From Deep Generative Models to Large Generative Models**|Lei Ren et.al.|[2407.11480v1](http://arxiv.org/abs/2407.11480v1)|null|
|**2024-07-16**|**XTraffic: A Dataset Where Traffic Meets Incidents with Explainability and More**|Xiaochuan Gou et.al.|[2407.11477v1](http://arxiv.org/abs/2407.11477v1)|null|
|**2024-07-16**|**DynSyn: Dynamical Synergistic Representation for Efficient Learning and Control in Overactuated Embodied Systems**|Kaibo He et.al.|[2407.11472v1](http://arxiv.org/abs/2407.11472v1)|null|
|**2024-07-16**|**Beyond Correctness: Benchmarking Multi-dimensional Code Generation for Large Language Models**|Jiasheng Zheng et.al.|[2407.11470v1](http://arxiv.org/abs/2407.11470v1)|[link](https://github.com/jszheng21/race)|
|**2024-07-16**|**Investigating Imperceptibility of Adversarial Attacks on Tabular Data: An Empirical Analysis**|Zhipeng He et.al.|[2407.11463v1](http://arxiv.org/abs/2407.11463v1)|[link](https://github.com/zhipenghe/imperceptibility-of-tabular-adversarial-attack)|
|**2024-07-16**|**Controllable Contextualized Image Captioning: Directing the Visual Narrative through User-Defined Highlights**|Shunqi Mao et.al.|[2407.11449v1](http://arxiv.org/abs/2407.11449v1)|null|
|**2024-07-16**|**EARN Fairness: Explaining, Asking, Reviewing and Negotiating Artificial Intelligence Fairness Metrics Among Stakeholders**|Lin Luo et.al.|[2407.11442v1](http://arxiv.org/abs/2407.11442v1)|null|
|**2024-07-16**|**Repurformer: Transformers for Repurposing-Aware Molecule Generation**|Changhun Lee et.al.|[2407.11439v1](http://arxiv.org/abs/2407.11439v1)|null|
|**2024-07-16**|**Trust No Bot: Discovering Personal Disclosures in Human-LLM Conversations in the Wild**|Niloofar Mireshghallah et.al.|[2407.11438v1](http://arxiv.org/abs/2407.11438v1)|null|
|**2024-07-16**|**Generally-Occurring Model Change for Robust Counterfactual Explanations**|Ao Xu et.al.|[2407.11426v1](http://arxiv.org/abs/2407.11426v1)|null|
|**2024-07-16**|**States Hidden in Hidden States: LLMs Emerge Discrete State Representations Implicitly**|Junhao Chen et.al.|[2407.11421v1](http://arxiv.org/abs/2407.11421v1)|null|
|**2024-07-16**|**LOTUS: Enabling Semantic Queries with LLMs Over Tables of Unstructured and Structured Data**|Liana Patel et.al.|[2407.11418v1](http://arxiv.org/abs/2407.11418v1)|[link](https://github.com/stanford-futuredata/lotus)|
|**2024-07-16**|**SPINACH: SPARQL-Based Information Navigation for Challenging Real-World Questions**|Shicheng Liu et.al.|[2407.11417v1](http://arxiv.org/abs/2407.11417v1)|null|
|**2024-07-16**|**Representation Bias in Political Sample Simulations with Large Language Models**|Weihong Qi et.al.|[2407.11409v1](http://arxiv.org/abs/2407.11409v1)|null|
|**2024-07-16**|**Revisiting the Impact of Pursuing Modularity for Code Generation**|Deokyeong Kang et.al.|[2407.11406v1](http://arxiv.org/abs/2407.11406v1)|null|
|**2024-07-16**|**DreamCatalyst: Fast and High-Quality 3D Editing via Controlling Editability and Identity Preservation**|Jiwook Kim et.al.|[2407.11394v1](http://arxiv.org/abs/2407.11394v1)|[link](https://github.com/kaist-cvml-lab/DreamCatalyst)|
|**2024-07-16**|**CIC-BART-SSA: Controllable Image Captioning with Structured Semantic Augmentation**|Kalliopi Basioti et.al.|[2407.11393v1](http://arxiv.org/abs/2407.11393v1)|[link](https://github.com/SamsungLabs/CIC-BART-SSA)|
|**2024-07-16**|**InvAgent: A Large Language Model based Multi-Agent System for Inventory Management in Supply Chains**|Yinzhu Quan et.al.|[2407.11384v1](http://arxiv.org/abs/2407.11384v1)|null|
|**2024-07-16**|**Segment, Lift and Fit: Automatic 3D Shape Labeling from 2D Prompts**|Jianhao Li et.al.|[2407.11382v2](http://arxiv.org/abs/2407.11382v2)|null|
|**2024-07-16**|**Reliable Reasoning Beyond Natural Language**|Nasim Borazjanizadeh et.al.|[2407.11373v1](http://arxiv.org/abs/2407.11373v1)|null|
|**2024-07-16**|**Estimating Agreement by Chance for Sequence Annotation**|Diya Li et.al.|[2407.11371v1](http://arxiv.org/abs/2407.11371v1)|null|
|**2024-07-16**|**A Pilot Study of GSLM-based Simulation of Foreign Accentuation Only Using Native Speech Corpora**|Kentaro Onda et.al.|[2407.11370v1](http://arxiv.org/abs/2407.11370v1)|null|
|**2024-07-16**|**Ancient Korean Archive Translation: Comparison Analysis on Statistical phrase alignment, LLM in-context learning, and inter-methodological approach**|Sojung Lucia Kim et.al.|[2407.11368v1](http://arxiv.org/abs/2407.11368v1)|null|
|**2024-07-16**|**Feature Inference Attack on Shapley Values**|Xinjian Luo et.al.|[2407.11359v1](http://arxiv.org/abs/2407.11359v1)|null|
|**2024-07-16**|**Beyond Binary: Multiclass Paraphasia Detection with Generative Pretrained Transformers and End-to-End Models**|Matthew Perez et.al.|[2407.11345v1](http://arxiv.org/abs/2407.11345v1)|null|
|**2024-07-16**|**COMET: "Cone of experience" enhanced large multimodal model for mathematical problem generation**|Sannyuya Liu et.al.|[2407.11315v1](http://arxiv.org/abs/2407.11315v1)|null|
|**2024-07-16**|**Large Vision-Language Models as Emotion Recognizers in Context Awareness**|Yuxuan Lei et.al.|[2407.11300v1](http://arxiv.org/abs/2407.11300v1)|null|
|**2024-07-16**|**Zero-Shot Adaptation for Approximate Posterior Sampling of Diffusion Models in Inverse Problems**|YaÅar Utku AlÃ§alar et.al.|[2407.11288v1](http://arxiv.org/abs/2407.11288v1)|null|
|**2024-07-15**|**CLAMS: A System for Zero-Shot Model Selection for Clustering**|Prabhant Singh et.al.|[2407.11286v1](http://arxiv.org/abs/2407.11286v1)|null|
|**2024-07-15**|**Uncertainty is Fragile: Manipulating Uncertainty in Large Language Models**|Qingcheng Zeng et.al.|[2407.11282v2](http://arxiv.org/abs/2407.11282v2)|[link](https://github.com/qcznlp/uncertainty_attack)|
|**2024-07-15**|**Quality Scalable Quantization Methodology for Deep Learning on Edge**|Salman Abdul Khaliq et.al.|[2407.11260v1](http://arxiv.org/abs/2407.11260v1)|null|
|**2024-07-15**|**Pacer and Runner: Cooperative Learning Framework between Single- and Cross-Domain Sequential Recommendation**|Chung Park et.al.|[2407.11245v1](http://arxiv.org/abs/2407.11245v1)|[link](https://github.com/cpark88/syncrec)|

#### Abstracts
##### **Does Refusal Training in LLMs Generalize to the Past Tense?**
2407.11969v1 by Maksym Andriushchenko, Nicolas Flammarion

Refusal training is widely used to prevent LLMs from generating harmful,
undesirable, or illegal outputs. We reveal a curious generalization gap in the
current refusal training approaches: simply reformulating a harmful request in
the past tense (e.g., "How to make a Molotov cocktail?" to "How did people make
a Molotov cocktail?") is often sufficient to jailbreak many state-of-the-art
LLMs. We systematically evaluate this method on Llama-3 8B, GPT-3.5 Turbo,
Gemma-2 9B, Phi-3-Mini, GPT-4o, and R2D2 models using GPT-3.5 Turbo as a
reformulation model. For example, the success rate of this simple attack on
GPT-4o increases from 1% using direct requests to 88% using 20 past tense
reformulation attempts on harmful requests from JailbreakBench with GPT-4 as a
jailbreak judge. Interestingly, we also find that reformulations in the future
tense are less effective, suggesting that refusal guardrails tend to consider
past historical questions more benign than hypothetical future questions.
Moreover, our experiments on fine-tuning GPT-3.5 Turbo show that defending
against past reformulations is feasible when past tense examples are explicitly
included in the fine-tuning data. Overall, our findings highlight that the
widely used alignment techniques -- such as SFT, RLHF, and adversarial training
-- employed to align the studied models can be brittle and do not always
generalize as intended. We provide code and jailbreak artifacts at
https://github.com/tml-epfl/llm-past-tense.

æè¦ï¼æçµè¨ç·´è¢«å»£æ³ç¨æ¼é²æ­¢ LLM ç¢çæå®³ãä¸åæ­¡è¿æéæ³çè¼¸åºãæåæ­ç¤ºäºç¶åæçµè¨ç·´æ¹æ³ä¸­ä¸åå¥æªçæ¦æ¬å·®è·ï¼ååç¨éå»å¼éæ°è¡¨è¿°ä¸åæå®³çè«æ±ï¼ä¾å¦ï¼ãå¦ä½è£½ä½è«æ´æå¤«éå°¾éï¼ãæ¹çºãäººåæ¯å¦ä½è£½ä½è«æ´æå¤«éå°¾éçï¼ãï¼éå¸¸è¶³ä»¥è®è¨±å¤æåé²ç LLM è¶çãæåä½¿ç¨ GPT-3.5 Turbo ä½çºéæ°è¡¨è¿°æ¨¡åï¼ç³»çµ±æ§å°è©ä¼°äºéç¨®æ¹æ³å¨ Llama-3 8BãGPT-3.5 TurboãGemma-2 9BãPhi-3-MiniãGPT-4o å R2D2 æ¨¡åä¸çææãä¾å¦ï¼éç¨®ç°¡å®æ»æå¨ GPT-4o ä¸çæåçå¾ä½¿ç¨ç´æ¥è«æ±æç 1% å¢å å°ä½¿ç¨ 20 æ¬¡éå»å¼éæ°è¡¨è¿°åè©¦å°ä¾èª JailbreakBench çæå®³è«æ±æçº 88%ï¼è GPT-4 åä½çºè¶çè©å¤ãæè¶£çæ¯ï¼æåéç¼ç¾ï¼æªä¾ææçéæ°è¡¨è¿°ææè¼å·®ï¼éè¡¨ææçµé²è­·æªæ½å¾åæ¼å°éå»çæ­·å²åé¡è¦çºæ¯åè¨­çæªä¾åé¡æ´è¯æ§ãæ­¤å¤ï¼æåå°å¾®èª¿ GPT-3.5 Turbo çå¯¦é©è¡¨æï¼å¨å¾®èª¿æ¸æä¸­æç¢ºåå«éå»ææçç¤ºä¾æï¼å¯ä»¥é²ç¦¦éå»çéæ°è¡¨è¿°ãç¸½çä¾èªªï¼æåçç¼ç¾å¼·èª¿äºå»£æ³ä½¿ç¨çå°é½æè¡ââä¾å¦ SFTãRLHF åå°æè¨ç·´ââç¨æ¼å°é½æç ç©¶çæ¨¡åå¯è½æ¯èå¼±çï¼ä¸¦ä¸ä¸¦ä¸ç¸½æ¯æé æçé£æ¨£æ¦æ¬ãæåå¨ https://github.com/tml-epfl/llm-past-tense æä¾ä»£ç¢¼åè¶çå·¥ä»¶ã

##### **Efficient Training with Denoised Neural Weights**
2407.11966v1 by Yifan Gong, Zheng Zhan, Yanyu Li, Yerlan Idelbayev, Andrey Zharkov, Kfir Aberman, Sergey Tulyakov, Yanzhi Wang, Jian Ren

Good weight initialization serves as an effective measure to reduce the
training cost of a deep neural network (DNN) model. The choice of how to
initialize parameters is challenging and may require manual tuning, which can
be time-consuming and prone to human error. To overcome such limitations, this
work takes a novel step towards building a weight generator to synthesize the
neural weights for initialization. We use the image-to-image translation task
with generative adversarial networks (GANs) as an example due to the ease of
collecting model weights spanning a wide range. Specifically, we first collect
a dataset with various image editing concepts and their corresponding trained
weights, which are later used for the training of the weight generator. To
address the different characteristics among layers and the substantial number
of weights to be predicted, we divide the weights into equal-sized blocks and
assign each block an index. Subsequently, a diffusion model is trained with
such a dataset using both text conditions of the concept and the block indexes.
By initializing the image translation model with the denoised weights predicted
by our diffusion model, the training requires only 43.3 seconds. Compared to
training from scratch (i.e., Pix2pix), we achieve a 15x training time
acceleration for a new concept while obtaining even better image generation
quality.

æè¦ï¼è¯å¥½çæ¬éåå§åæ¯æ¸å°æ·±åº¦ç¥ç¶ç¶²è·¯ (DNN) æ¨¡åè¨ç·´ææ¬çæææªæ½ãå¦ä½åå§ååæ¸çé¸æå·æææ°æ§ï¼ä¸å¯è½éè¦æåèª¿æ´ï¼éå¯è½æè±è²»å¤§éæéä¸å®¹æåºé¯ãçºäºåæéäºéå¶ï¼éé å·¥ä½æ¡åäºä¸ååµæ°çæ­¥é©ï¼æèå»ºç«ä¸åæ¬éçæå¨ä¾åæåå§åçç¥ç¶æ¬ééé²ãæåä»¥ä½¿ç¨çæå°æç¶²è·¯ (GAN) çå½±åè½å½±åè½æä»»åçºä¾ï¼å çºæ¶éæ¶µèå»£æ³ç¯åçæ¨¡åæ¬éå¾ç°¡å®ãå·é«ä¾èªªï¼æåé¦åæ¶éä¸ååå«åç¨®å½±åç·¨è¼¯æ¦å¿µåå¶å°æè¨ç·´æ¬éçè³æéï¼éäºæ¬éç¨å¾ç¨æ¼è¨ç·´æ¬éçæå¨ãçºäºæå°å±¤ä¹éçä¸åç¹æ§åå¤§éçå¾é æ¸¬æ¬éï¼æåå°æ¬éåæå¤§å°ç¸ç­çåå¡ï¼ä¸¦çºæ¯ååå¡æå®ä¸åç´¢å¼ãé¨å¾ï¼ä½¿ç¨åå«æ¦å¿µæå­æ¢ä»¶ååå¡ç´¢å¼çè³æéï¼è¨ç·´ä¸åæ´æ£æ¨¡åãééä½¿ç¨æåçæ´æ£æ¨¡åé æ¸¬çå»åªæ¬éåå§åå½±åè½ææ¨¡åï¼è¨ç·´åé 43.3 ç§ãèå¾é ­éå§è¨ç·´ (å³ Pix2pix) ç¸æ¯ï¼æåçºä¸åæ°æ¦å¿µå¯¦ç¾äº 15 åçè¨ç·´æéå éï¼åæç²å¾æ´å¥½çå½±åçæåè³ªã

##### **NeedleBench: Can LLMs Do Retrieval and Reasoning in 1 Million Context Window?**
2407.11963v1 by Mo Li, Songyang Zhang, Yunxin Liu, Kai Chen

In evaluating the long-context capabilities of large language models (LLMs),
identifying content relevant to a user's query from original long documents is
a crucial prerequisite for any LLM to answer questions based on long text. We
present NeedleBench, a framework consisting of a series of progressively more
challenging tasks for assessing bilingual long-context capabilities, spanning
multiple length intervals (4k, 8k, 32k, 128k, 200k, 1000k, and beyond) and
different depth ranges, allowing the strategic insertion of critical data
points in different text depth zones to rigorously test the retrieval and
reasoning capabilities of models in diverse contexts. We use the NeedleBench
framework to assess how well the leading open-source models can identify key
information relevant to the question and apply that information to reasoning in
bilingual long texts. Furthermore, we propose the Ancestral Trace Challenge
(ATC) to mimic the complexity of logical reasoning challenges that are likely
to be present in real-world long-context tasks, providing a simple method for
evaluating LLMs in dealing with complex long-context situations. Our results
suggest that current LLMs have significant room for improvement in practical
long-context applications, as they struggle with the complexity of logical
reasoning challenges that are likely to be present in real-world long-context
tasks. All codes and resources are available at OpenCompass:
https://github.com/open-compass/opencompass.

æè¦ï¼<paragraph>å¨è©ä¼°å¤§åèªè¨æ¨¡å (LLM) çé·èªå¢è½åæï¼å¾åå§é·ç¯æä»¶ä¸­è¾¨è­èä½¿ç¨èæ¥è©¢ç¸éçå§å®¹æ¯ä»»ä½ LLM æ ¹æé·æåç­åé¡çå¿è¦åæ±ºæ¢ä»¶ãæåæåº NeedleBenchï¼ä¸åç±ä¸ç³»åé£åº¦éæ¼¸å¢å çä»»åçµæçæ¶æ§ï¼ç¨æ¼è©ä¼°éèªé·èªå¢è½åï¼æ¶µèå¤åé·åº¦åéï¼4kã8kã32kã128kã200kã1000kï¼ä»¥åæ´å¤ï¼åä¸åçæ·±åº¦ç¯åï¼åè¨±å¨ä¸åçæå­æ·±åº¦ååç­ç¥æ§å°æå¥ééµè³æé»ï¼ä»¥å´æ ¼æ¸¬è©¦æ¨¡åå¨ä¸åèªå¢ä¸­çæª¢ç´¢åæ¨çè½åãæåä½¿ç¨ NeedleBench æ¶æ§ä¾è©ä¼°é åçéæºæ¨¡åå¨è¾¨è­èåé¡ç¸éçééµè³è¨ï¼ä»¥åå°è©²è³è¨æç¨æ¼éèªé·æä¸­æ¨ççè½åãæ­¤å¤ï¼æåæåºç¥åè¿½è¹¤ææ° (ATC)ï¼æ¨¡æ¬å¨ç¾å¯¦ä¸çé·èªå¢ä»»åä¸­å¯è½å­å¨çéè¼¯æ¨çææ°çè¤éæ§ï¼æä¾ä¸åç°¡å®çæ¹æ³ä¾è©ä¼° LLM å¨èçè¤éé·èªå¢ææ³æçè¡¨ç¾ãæåççµæè¡¨æï¼ç®åç LLM å¨å¯¦éé·èªå¢æç¨ä¸­ä»æå¾å¤§çæ¹é²ç©ºéï¼å çºå®åé£ä»¥æä»ç¾å¯¦ä¸çé·èªå¢ä»»åä¸­å¯è½å­å¨çéè¼¯æ¨çææ°çè¤éæ§ãææç¨å¼ç¢¼åè³æºé½å¯ä»¥å¨ OpenCompass åå¾ï¼https://github.com/open-compass/opencompassã</paragraph>

##### **Motion-Oriented Compositional Neural Radiance Fields for Monocular Dynamic Human Modeling**
2407.11962v1 by Jaehyeok Kim, Dongyoon Wee, Dan Xu

This paper introduces Motion-oriented Compositional Neural Radiance Fields
(MoCo-NeRF), a framework designed to perform free-viewpoint rendering of
monocular human videos via novel non-rigid motion modeling approach. In the
context of dynamic clothed humans, complex cloth dynamics generate non-rigid
motions that are intrinsically distinct from skeletal articulations and
critically important for the rendering quality. The conventional approach
models non-rigid motions as spatial (3D) deviations in addition to skeletal
transformations. However, it is either time-consuming or challenging to achieve
optimal quality due to its high learning complexity without a direct
supervision. To target this problem, we propose a novel approach of modeling
non-rigid motions as radiance residual fields to benefit from more direct color
supervision in the rendering and utilize the rigid radiance fields as a prior
to reduce the complexity of the learning process. Our approach utilizes a
single multiresolution hash encoding (MHE) to concurrently learn the canonical
T-pose representation from rigid skeletal motions and the radiance residual
field for non-rigid motions. Additionally, to further improve both training
efficiency and usability, we extend MoCo-NeRF to support simultaneous training
of multiple subjects within a single framework, thanks to our effective design
for modeling non-rigid motions. This scalability is achieved through the
integration of a global MHE and learnable identity codes in addition to
multiple local MHEs. We present extensive results on ZJU-MoCap and MonoCap,
clearly demonstrating state-of-the-art performance in both single- and
multi-subject settings. The code and model will be made publicly available at
the project page: https://stevejaehyeok.github.io/publications/moco-nerf.

æè¦ï¼<paragraph>æ¬æä»ç»äºé¢åè¿å¨çåæç¥ç»è¾å°åº (MoCo-NeRF)ï¼è¿æ¯ä¸ä¸ªæ¨å¨éè¿æ°é¢çéåæ§è¿å¨å»ºæ¨¡æ¹æ³æ§è¡åç¼äººç±»è§é¢çèªç±è§ç¹æ¸²æçæ¡æ¶ãå¨å¨æçè£çäººç±»çèæ¯ä¸ï¼å¤æçå¸æå¨æä¼äº§çéåæ§è¿å¨ï¼è¿äºè¿å¨æ¬è´¨ä¸ä¸åäºéª¨éª¼å³èï¼å¹¶ä¸å¯¹æ¸²æè´¨éè³å³éè¦ãä¼ ç»æ¹æ³å°éåæ§è¿å¨å»ºæ¨¡ä¸ºç©ºé´ (3D) åå·®ä»¥åéª¨éª¼åæ¢ãç¶èï¼ç±äºå¶å­¦ä¹ å¤æåº¦é«ä¸æ²¡æç´æ¥çç£ï¼å æ­¤è¦è¾¾å°æä½³è´¨éæ¢èæ¶åå·ææææ§ãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æä»¬æåºäºä¸ç§æ°é¢çæ¹æ³ï¼å°éåæ§è¿å¨å»ºæ¨¡ä¸ºè¾å°æ®å·®åºï¼ä»¥åçäºæ¸²æä¸­æ´ç´æ¥çé¢è²çç£ï¼å¹¶å°åæ§è¾å°åºç¨ä½åéªæ¥éä½å­¦ä¹ è¿ç¨çå¤ææ§ãæä»¬çæ¹æ³å©ç¨åä¸çå¤åè¾¨çåå¸ç¼ç  (MHE) æ¥åæ¶ä»åæ§éª¨éª¼è¿å¨ä¸­å­¦ä¹ è§èç T å§¿å¿è¡¨ç¤ºï¼ä»¥åç¨äºéåæ§è¿å¨çè¾å°æ®å·®åºãæ­¤å¤ï¼ä¸ºäºè¿ä¸æ­¥æé«è®­ç»æçåå¯ç¨æ§ï¼æä»¬æ©å±äº MoCo-NeRF ä»¥æ¯æå¨åä¸ªæ¡æ¶ååæ¶è®­ç»å¤ä¸ªä¸»ä½ï¼è¿è¦å½åäºæä»¬ç¨äºå»ºæ¨¡éåæ§è¿å¨çææè®¾è®¡ãé¤äºå¤ä¸ªå±é¨ MHE ä¹å¤ï¼è¿ç§å¯æ©å±æ§æ¯éè¿éæå¨å± MHE åå¯å­¦ä¹ çèº«ä»½ä»£ç å®ç°çãæä»¬å¨ ZJU-MoCap å MonoCap ä¸å±ç¤ºäºå¹¿æ³çç»æï¼æ¸æ¥å°å±ç¤ºäºå¨åä¸»ä½åå¤ä¸»ä½è®¾ç½®ä¸­é½è¾¾å°æåè¿çæ§è½ãä»£ç åæ¨¡åå°å¨é¡¹ç®é¡µé¢å¬å¼ï¼https://stevejaehyeok.github.io/publications/moco-nerfã</paragraph>

##### **Rethinking Transformer-based Multi-document Summarization: An Empirical Investigation**
2407.11948v1 by Congbo Ma, Wei Emma Zhang, Dileepa Pitawela, Haojie Zhuang, Yanfeng Shu

The utilization of Transformer-based models prospers the growth of
multi-document summarization (MDS). Given the huge impact and widespread
adoption of Transformer-based models in various natural language processing
tasks, investigating their performance and behaviors in the context of MDS
becomes crucial for advancing the field and enhancing the quality of summary.
To thoroughly examine the behaviours of Transformer-based MDS models, this
paper presents five empirical studies on (1) measuring the impact of document
boundary separators quantitatively; (2) exploring the effectiveness of
different mainstream Transformer structures; (3) examining the sensitivity of
the encoder and decoder; (4) discussing different training strategies; and (5)
discovering the repetition in a summary generation. The experimental results on
prevalent MDS datasets and eleven evaluation metrics show the influence of
document boundary separators, the granularity of different level features and
different model training strategies. The results also reveal that the decoder
exhibits greater sensitivity to noises compared to the encoder. This
underscores the important role played by the decoder, suggesting a potential
direction for future research in MDS. Furthermore, the experimental results
indicate that the repetition problem in the generated summaries has
correlations with the high uncertainty scores.

æè¦ï¼<paragraph>åºæ¼ Transformer çæ¨¡åéç¨è¬åç¼å±äºå¤æä»¶æè¦ (MDS) çæé·ãç±æ¼åºæ¼ Transformer çæ¨¡åå¨åç¨®èªç¶èªè¨èçä»»åä¸­å·æå·¨å¤§çå½±é¿ååå»£æ³çæ¡ç¨ï¼å æ­¤ç ç©¶å®åå¨ MDS èæ¯ä¸çæè½åè¡çºå°æ¼æ¨åè©²é ååæåæè¦åè³ªè³ééè¦ãçºäºå¾¹åºæª¢é©åºæ¼ Transformer ç MDS æ¨¡åçè¡çºï¼æ¬æéå° (1) å®éæ¸¬éæä»¶éçåéç¬¦çå½±é¿ï¼(2) æ¢è¨ä¸åä¸»æµ Transformer çµæ§çæææ§ï¼(3) æª¢é©ç·¨ç¢¼å¨åè§£ç¢¼å¨çæææ§ï¼(4) è¨è«ä¸åçè¨ç·´ç­ç¥ï¼ä»¥å (5) ç¼ç¾æè¦çæä¸­çéè¤æ§ï¼æåºäºäºé å¯¦è­ç ç©¶ãå¨æµè¡ç MDS è³æéå 11 é è©ä¼°ææ¨ä¸çå¯¦é©çµæé¡¯ç¤ºäºæä»¶éçåéç¬¦ãä¸åå±¤ç´ç¹å¾µçç²åº¦åä¸åæ¨¡åè¨ç·´ç­ç¥çå½±é¿ãçµæéæ­ç¤ºï¼èç·¨ç¢¼å¨ç¸æ¯ï¼è§£ç¢¼å¨å°éè¨è¡¨ç¾åºæ´å¤§çæææ§ãéå¼·èª¿äºè§£ç¢¼å¨ææ®æ¼çéè¦è§è²ï¼çº MDS æªä¾çç ç©¶æåºäºæ½å¨çæ¹åãæ­¤å¤ï¼å¯¦é©çµæè¡¨æï¼çæçæè¦ä¸­éè¤åºç¾çåé¡èé«ä¸ç¢ºå®æ§åæ¸æéã</paragraph>

##### **Fine-grained Hallucination Detection and Mitigation in Long-form Question Answering**
2407.11930v1 by Rachneet Sachdeva, Yixiao Song, Mohit Iyyer, Iryna Gurevych

Long-form question answering (LFQA) aims to provide thorough and in-depth
answers to complex questions, enhancing comprehension. However, such detailed
responses are prone to hallucinations and factual inconsistencies, challenging
their faithful evaluation. This work introduces HaluQuestQA, the first
hallucination dataset with localized error annotations for human-written and
model-generated LFQA answers. HaluQuestQA comprises 698 QA pairs with 4.7k
span-level error annotations for five different error types by expert
annotators, along with preference judgments. Using our collected data, we
thoroughly analyze the shortcomings of long-form answers and find that they
lack comprehensiveness and provide unhelpful references. We train an automatic
feedback model on this dataset that predicts error spans with incomplete
information and provides associated explanations. Finally, we propose a
prompt-based approach, Error-informed refinement, that uses signals from the
learned feedback model to refine generated answers, which we show reduces
hallucination and improves answer quality. Furthermore, humans find answers
generated by our approach comprehensive and highly prefer them (84%) over the
baseline answers.

æè¦ï¼é·ç¯åç­ (LFQA) æ¨å¨æä¾å°è¤éåé¡çå¨é¢æ·±å¥çç­æ¡ï¼ä»¥å¢å¼·çè§£åãç¶èï¼å¦æ­¤è©³ç´°çåæå®¹æåºç¾å¹»è¦ºåäºå¯¦ä¸ç¬¦ï¼å°å¶å¿ å¯¦çè©ä¼°æ§æææ°ãéé å·¥ä½å¼å¥äº HaluQuestQAï¼éæ¯ç¬¬ä¸åå·æéå°äººé¡æ°å¯«åæ¨¡åçæç LFQA ç­æ¡çå±é¨é¯èª¤è¨»è§£çå¹»è¦ºæ¸æéãHaluQuestQA åå« 698 å QA å°ï¼å¶ä¸­åå«ç±å°å®¶è¨»è§£èéå°äºç¨®ä¸åé¯èª¤é¡åé²è¡ç 4.7k åè·¨åº¦ç´å¥é¯èª¤è¨»è§£ï¼ä»¥ååå¥½å¤æ·ãå©ç¨æåæ¶éçæ¸æï¼æåå¾¹åºåæäºé·ç¯ç­æ¡çç¼ºé»ï¼ç¼ç¾å®åç¼ºä¹å¨é¢æ§ï¼ä¸¦ä¸æä¾çåèæ²æå¹«å©ãæåå¨éåæ¸æéä¸è¨ç·´äºä¸åèªååé¥æ¨¡åï¼å®å¯ä»¥é æ¸¬å·æä¸å®æ´ä¿¡æ¯çé¯èª¤è·¨åº¦ï¼ä¸¦æä¾ç¸éè§£éãæå¾ï¼æåæåºäºä¸ç¨®åºæ¼æç¤ºçæ¹æ³ï¼å³é¯èª¤ç¥æåªåï¼å®ä½¿ç¨å¾å­¸ç¿çåé¥æ¨¡åä¸­ç²å¾çä¿¡èä¾åªåçæçç­æ¡ï¼æåå±ç¤ºäºéæ¸å°äºå¹»è¦ºä¸¦æé«äºç­æ¡è³ªéãæ­¤å¤ï¼äººé¡ç¼ç¾ç±æåçæ¹æ³çæçç­æ¡å¨é¢ï¼ä¸¦ä¸éå¸¸åæ­¡å®åï¼84%ï¼èä¸æ¯åºæºç­æ¡ã

##### **Tackling Oversmoothing in GNN via Graph Sparsification: A Truss-based Approach**
2407.11928v1 by Tanvir Hossain, Khaled Mohammed Saifuddin, Muhammad Ifte Khairul Islam, Farhan Tanvir, Esra Akbas

Graph Neural Network (GNN) achieves great success for node-level and
graph-level tasks via encoding meaningful topological structures of networks in
various domains, ranging from social to biological networks. However, repeated
aggregation operations lead to excessive mixing of node representations,
particularly in dense regions with multiple GNN layers, resulting in nearly
indistinguishable embeddings. This phenomenon leads to the oversmoothing
problem that hampers downstream graph analytics tasks. To overcome this issue,
we propose a novel and flexible truss-based graph sparsification model that
prunes edges from dense regions of the graph. Pruning redundant edges in dense
regions helps to prevent the aggregation of excessive neighborhood information
during hierarchical message passing and pooling in GNN models. We then utilize
our sparsification model in the state-of-the-art baseline GNNs and pooling
models, such as GIN, SAGPool, GMT, DiffPool, MinCutPool, HGP-SL, DMonPool, and
AdamGNN. Extensive experiments on different real-world datasets show that our
model significantly improves the performance of the baseline GNN models in the
graph classification task.

æè¦ï¼åå½¢ç¥ç¶ç¶²è·¯ (GNN) ééç·¨ç¢¼åç¨®é åä¸­ç¶²è·¯çæç¾©ææ²çµæ§ï¼å¨ç¯é»å±¤ç´ååå½¢å±¤ç´ä»»åä¸­åå¾æ¥µä½³çæåï¼å¾ç¤¾äº¤ç¶²è·¯å°çç©ç¶²è·¯çææ¶çµãç¶èï¼éè¤çèééç®å°è´ç¯é»è¡¨ç¤ºéåº¦æ··åï¼ç¹å¥æ¯å¨å·æå¤å GNN å±¤çå¯éååï¼å°è´åµå¥å¼å¹¾ä¹ç¡æ³ååãéç¨®ç¾è±¡å°è´éåº¦å¹³æ»åé¡ï¼é»ç¤ä¸æ¸¸åå½¢åæä»»åãçºäºåæéååé¡ï¼æåæåºä¸åæ°ç©ä¸éæ´»çåºæ¼æ¡æ¶çåå½¢ç¨çåæ¨¡åï¼å¯å¾åå½¢çå¯éååä¿®åªéç·£ãä¿®åªå¯éååä¸­å¤é¤çéç·£æå©æ¼é²æ­¢å¨ GNN æ¨¡åä¸­é²è¡éå±¤å¼è¨æ¯å³éåå¯ç¸½æééåº¦é°åè³è¨çèéãç¶å¾ï¼æåå¨æåé²çåºç· GNN åå¯ç¸½æ¨¡åä¸­ä½¿ç¨æåçç¨çåæ¨¡åï¼ä¾å¦ GINãSAGPoolãGMTãDiffPoolãMinCutPoolãHGP-SLãDMonPool å AdamGNNãå¨ä¸åçå¯¦ä¸çè³æéä¸é²è¡çå¤§éå¯¦é©è¡¨æï¼æåçæ¨¡åé¡¯èæé«äºåºç· GNN æ¨¡åå¨åå½¢åé¡ä»»åä¸­çæè½ã

##### **What's Wrong? Refining Meeting Summaries with LLM Feedback**
2407.11919v1 by Frederic Kirstein, Terry Ruas, Bela Gipp

Meeting summarization has become a critical task since digital encounters
have become a common practice. Large language models (LLMs) show great
potential in summarization, offering enhanced coherence and context
understanding compared to traditional methods. However, they still struggle to
maintain relevance and avoid hallucination. We introduce a multi-LLM correction
approach for meeting summarization using a two-phase process that mimics the
human review process: mistake identification and summary refinement. We release
QMSum Mistake, a dataset of 200 automatically generated meeting summaries
annotated by humans on nine error types, including structural, omission, and
irrelevance errors. Our experiments show that these errors can be identified
with high accuracy by an LLM. We transform identified mistakes into actionable
feedback to improve the quality of a given summary measured by relevance,
informativeness, conciseness, and coherence. This post-hoc refinement
effectively improves summary quality by leveraging multiple LLMs to validate
output quality. Our multi-LLM approach for meeting summarization shows
potential for similar complex text generation tasks requiring robustness,
action planning, and discussion towards a goal.

æè¦ï¼æè­°æè¦å·²æçºä¸é ééµä»»åï¼å çºæ¸ä½æè­°å·²æçºä¸ç¨®å¸¸è¦çå¯¦åãå¤§åèªè¨æ¨¡å (LLM) å¨æè¦æ¹é¢å±ç¾äºæ¥µå¤§çæ½åï¼èå³çµ±æ¹æ³ç¸æ¯ï¼å®æä¾äºå¢å¼·çä¸è´æ§åèçµ¡çè§£ãç¶èï¼å®åä»ç¶é£ä»¥ç¶­æç¸éæ§ä¸¦é¿åç¢çå¹»è¦ºãæåéå°æè­°æè¦æ¨åºäºä¸ç¨®å¤ LLM ä¿®æ­£æ¹æ³ï¼è©²æ¹æ³ä½¿ç¨ä¸åå©éæ®µæµç¨ä¾æ¨¡æ¬äººé¡å¯©æ¥æµç¨ï¼é¯èª¤è¾¨è­åæè¦ç²¾çãæåç¼å¸äº QMSum Mistakeï¼éæ¯ä¸ååå« 200 åèªåç¢ççæè­°æè¦çè³æéï¼ç±äººé¡éå°ä¹ç¨®é¡åçé¯èª¤é²è¡è¨»è§£ï¼åæ¬çµæ§ãéºæ¼åä¸ç¸éçé¯èª¤ãæåçå¯¦é©é¡¯ç¤ºï¼éäºé¯èª¤å¯ä»¥ç± LLM ä»¥é«æºç¢ºåº¦è¾¨è­åºä¾ãæåå°è¾¨è­åºçé¯èª¤è½æçºå¯è¡çåé¥ï¼ä»¥æ¹åæè¦çåè³ªï¼éäºåè³ªç±ç¸éæ§ãè³è¨æ§ãç°¡æ½æ§åä¸è´æ§ä¾è¡¡éãéç¨®äºå¾ç²¾çææå°æ¹åäºæè¦åè³ªï¼æ¹æ³æ¯å©ç¨å¤å LLM ä¾é©è­è¼¸åºåè³ªãæåå¨æè­°æè¦æ¹é¢æ¡ç¨çå¤ LLM æ¹æ³ï¼é¡¯ç¤ºäºå¨éè¦ç©©å¥æ§ãè¡åè¦ååæåç®æ¨è¨è«çé¡ä¼¼è¤éæå­çæä»»åä¸­å·ææ½åã

##### **Imitation of human motion achieves natural head movements for humanoid robots in an active-speaker detection task**
2407.11915v1 by Bosong Ding, Murat Kirtay, Giacomo Spigler

Head movements are crucial for social human-human interaction. They can
transmit important cues (e.g., joint attention, speaker detection) that cannot
be achieved with verbal interaction alone. This advantage also holds for
human-robot interaction. Even though modeling human motions through generative
AI models has become an active research area within robotics in recent years,
the use of these methods for producing head movements in human-robot
interaction remains underexplored. In this work, we employed a generative AI
pipeline to produce human-like head movements for a Nao humanoid robot. In
addition, we tested the system on a real-time active-speaker tracking task in a
group conversation setting. Overall, the results show that the Nao robot
successfully imitates human head movements in a natural manner while actively
tracking the speakers during the conversation. Code and data from this study
are available at https://github.com/dingdingding60/Humanoids2024HRI

æè¦ï¼é ­é¨åä½å°æ¼äººé¡ä¹éçç¤¾äº¤äºåè³ééè¦ãå®åå¯ä»¥å³ééè¦çç·ç´¢ï¼ä¾å¦ï¼å±åéæ³¨ãèªªè©±èåµæ¸¬ï¼ï¼èåé å£èªäºåç¡æ³éæãéç¨®åªå¢ä¹é©ç¨æ¼äººæ©äºåãåç®¡è¿å¹´ä¾ééçæå¼ AI æ¨¡åæ¨¡æ¬äººé¡åä½å·²æçºæ©å¨äººé åä¸­çæ´»èºç ç©¶é åï¼ä½éäºæ¹æ³ç¨æ¼ç¢çäººæ©äºåä¸­çé ­é¨åä½ä»æªååæ¢è¨ãå¨éé ç ç©¶ä¸­ï¼æåæ¡ç¨çæå¼ AI ç®¡ç·çº Nao é¡äººæ©å¨äººç¢çé¡ä¼¼äººé¡çé ­é¨åä½ãæ­¤å¤ï¼æåå¨ç¾¤çµå°è©±è¨­å®ä¸­å°ä¸åå³æä¸»åèªªè©±èè¿½è¹¤ä»»åæ¸¬è©¦äºéåç³»çµ±ãæ´é«èè¨ï¼çµæé¡¯ç¤º Nao æ©å¨äººå¨å°è©±æéä¸»åè¿½è¹¤èªªè©±èçåæï¼æåä»¥èªç¶çæ¹å¼æ¨¡ä»¿äººé¡çé ­é¨åä½ãæ¬ç ç©¶çç¨å¼ç¢¼åè³æå¯å¨ https://github.com/dingdingding60/Humanoids2024HRI åå¾

##### **Bridging Weighted First Order Model Counting and Graph Polynomials**
2407.11877v1 by Qipeng Kuang, OndÅej KuÅ¾elka, Yuanhong Wang, Yuyi Wang

The Weighted First-Order Model Counting Problem (WFOMC) asks to compute the
weighted sum of models of a given first-order logic sentence over a given
domain. It can be solved in time polynomial in the domain size for sentences
from the two-variable fragment with counting quantifiers, known as $C^2$. This
polynomial-time complexity is also retained when extending $C^2$ by one of the
following axioms: linear order axiom, tree axiom, forest axiom, directed
acyclic graph axiom or connectedness axiom. An interesting question remains as
to which other axioms can be added to the first-order sentences in this way. We
provide a new perspective on this problem by associating WFOMC with graph
polynomials. Using WFOMC, we define Weak Connectedness Polynomial and Strong
Connectedness Polynomials for first-order logic sentences. It turns out that
these polynomials have the following interesting properties. First, they can be
computed in polynomial time in the domain size for sentences from $C^2$.
Second, we can use them to solve WFOMC with all of the existing axioms known to
be tractable as well as with new ones such as bipartiteness, strong
connectedness, being a spanning subgraph, having $k$ connected components, etc.
Third, the well-known Tutte polynomial can be recovered as a special case of
the Weak Connectedness Polynomial, and the Strict and Non-Strict Directed
Chromatic Polynomials can be recovered from the Strong Connectedness
Polynomials, which allows us to show that these important graph polynomials can
be computed in time polynomial in the number of vertices for any graph that can
be encoded by a fixed $C^2$ sentence and a conjunction of an arbitrary number
of ground unary literals.

æè¦ï¼å æ¬ä¸éæ¨¡åè¨ç®åé¡ (WFOMC) è¦æ±è¨ç®çµ¦å®ä¸ééè¼¯å¥å­å¨çµ¦å®ç¶²åä¸çæ¨¡åçå æ¬ç¸½åãå°æ¼å·æè¨æ¸éè©çäºè®æ¸çæ®µï¼ç¨±çº $C^2$ï¼ä¸­çå¥å­ï¼å¯ä»¥å¨å¤é å¼æéå§è§£æ±ºæ­¤åé¡ãç¶ééä»¥ä¸å¬çä¹ä¸ä¾æ´å $C^2$ æï¼æ­¤å¤é å¼æéè¤éåº¦ä¹æä¿çï¼ç·æ§åºå¬çãæ¨¹å¬çãæ£®æå¬çãæåç¡ç°åå¬çæé£éå¬çãä¸åæè¶£çåé¡ä»ç¶æ¯åªäºå¶ä»å¬çå¯ä»¥éæ¨£æ·»å å°ä¸éå¥å­ä¸­ãæåééå° WFOMC èåå¤é å¼éè¯èµ·ä¾ï¼å°éååé¡æä¾äºæ°çè§é»ãä½¿ç¨ WFOMCï¼æåå®ç¾©äºä¸ééè¼¯å¥å­çå¼±é£éå¤é å¼åå¼·é£éå¤é å¼ãçµæè­æï¼éäºå¤é å¼å·æä»¥ä¸æè¶£çæ§è³ªãé¦åï¼å®åå¯ä»¥å¨ $C^2$ å¥å­ä¸­å¤é å¼æéå§è¨ç®ç¶²åå¤§å°ãå¶æ¬¡ï¼æåå¯ä»¥ä½¿ç¨å®åä¾è§£æ±º WFOMCï¼å¶ä¸­åæ¬ææå·²ç¥ææ¼èççå¬çä»¥åæ°çå¬çï¼ä¾å¦äºåæ§ãå¼·é£éæ§ãä½çºçæå­åãå·æ $k$ åé£éçµä»¶ç­ãç¬¬ä¸ï¼ç¾æå¨ç¥ç Tutte å¤é å¼å¯ä»¥ä½çºå¼±é£éå¤é å¼çç¹ä¾æ¢å¾©ï¼èå´æ ¼åéå´æ ¼æåè²å¤é å¼å¯ä»¥å¾å¼·é£éå¤é å¼ä¸­æ¢å¾©ï¼éè®æåå¯ä»¥è­æéäºéè¦çåå¤é å¼å¯ä»¥å¨å¤é å¼æéå§è¨ç®ä»»ä½åçé é»æ¸ï¼è©²åå¯ä»¥ç¨åºå®ç $C^2$ å¥å­åä»»ææ¸éçåºæ¬ä¸åæå­çååä¾ç·¨ç¢¼ã

##### **Evaluating Task-Oriented Dialogue Consistency through Constraint Satisfaction**
2407.11857v1 by Tiziano Labruna, Bernardo Magnini

Task-oriented dialogues must maintain consistency both within the dialogue
itself, ensuring logical coherence across turns, and with the conversational
domain, accurately reflecting external knowledge. We propose to conceptualize
dialogue consistency as a Constraint Satisfaction Problem (CSP), wherein
variables represent segments of the dialogue referencing the conversational
domain, and constraints among variables reflect dialogue properties, including
linguistic, conversational, and domain-based aspects. To demonstrate the
feasibility of the approach, we utilize a CSP solver to detect inconsistencies
in dialogues re-lexicalized by an LLM. Our findings indicate that: (i) CSP is
effective to detect dialogue inconsistencies; and (ii) consistent dialogue
re-lexicalization is challenging for state-of-the-art LLMs, achieving only a
0.15 accuracy rate when compared to a CSP solver. Furthermore, through an
ablation study, we reveal that constraints derived from domain knowledge pose
the greatest difficulty in being respected. We argue that CSP captures core
properties of dialogue consistency that have been poorly considered by
approaches based on component pipelines.

æè¦ï¼ä»»åå°åå°è©±å¿é å¨å°è©±æ¬èº«ä¸­ä¿æä¸è´æ§ï¼ç¢ºä¿è¼ªæµçéè¼¯é£è²«æ§ï¼ä¸¦èå°è©±é åä¸è´ï¼æºç¢ºåæ å¤é¨ç¥è­ãæåå»ºè­°å°å°è©±ä¸è´æ§æ¦å¿µåçºç´ææ»¿è¶³åé¡ (CSP)ï¼å¶ä¸­è®æ¸ä»£è¡¨å°è©±ä¸­åèå°è©±é åçåæ®µï¼èè®æ¸ä¹éçç´æåæ å°è©±å±¬æ§ï¼åæ¬èªè¨ãå°è©±ååºæ¼é åçæ¹é¢ãçºäºè­æéç¨®æ¹æ³çå¯è¡æ§ï¼æåå©ç¨ CSP æ±è§£å¨ä¾æª¢æ¸¬ LLM éæ°è©å½åçå°è©±ä¸­çä¸ä¸è´æ§ãæåçç ç©¶çµæè¡¨æï¼(i) CSP å¯æææª¢æ¸¬å°è©±ä¸ä¸è´æ§ï¼(ii) å°æ¼æåé²ç LLM ä¾èªªï¼ä¸è´çå°è©±éæ°è©å½åå·æææ°æ§ï¼è CSP æ±è§£å¨ç¸æ¯ï¼åéå° 0.15 çæºç¢ºçãæ­¤å¤ï¼ééæ¶èç ç©¶ï¼æåç¼ç¾æºèªé åç¥è­çç´ææé£è¢«éµå®ãæåèªçºï¼CSP ææäºå°è©±ä¸è´æ§çæ ¸å¿å±¬æ§ï¼èåºæ¼çµä»¶ç®¡ç·çæ¹æ³å°æ­¤èæ®ä¸å¨ã

##### **Scaling Sign Language Translation**
2407.11855v1 by Biao Zhang, Garrett Tanzer, Orhan Firat

Sign language translation (SLT) addresses the problem of translating
information from a sign language in video to a spoken language in text.
Existing studies, while showing progress, are often limited to narrow domains
and/or few sign languages and struggle with open-domain tasks. In this paper,
we push forward the frontier of SLT by scaling pretraining data, model size,
and number of translation directions. We perform large-scale SLT pretraining on
different data including 1) noisy multilingual YouTube SLT data, 2) parallel
text corpora, and 3) SLT data augmented by translating video captions to other
languages with off-the-shelf machine translation models. We unify different
pretraining tasks with task-specific prompts under the encoder-decoder
architecture, and initialize the SLT model with pretrained (m/By)T5 models
across model sizes. SLT pretraining results on How2Sign and FLEURS-ASL#0 (ASL
to 42 spoken languages) demonstrate the significance of data/model scaling and
cross-lingual cross-modal transfer, as well as the feasibility of zero-shot
SLT. We finetune the pretrained SLT models on 5 downstream open-domain SLT
benchmarks covering 5 sign languages. Experiments show substantial quality
improvements over the vanilla baselines, surpassing the previous
state-of-the-art (SOTA) by wide margins.

æè¦ï¼æèªç¿»è­¯ (SLT) è§£æ±ºäºå°å½±çä¸­çæèªè³è¨ç¿»è­¯ææå­ä¸­çå£èªåé¡ãç¾æç ç©¶éç¶é¡¯ç¤ºé²å±ï¼ä½éå¸¸åéæ¼ç¹çªçé åå/æå°æ¸æèªï¼ä¸é£ä»¥æä»éæ¾é åä»»åãå¨æ¬æä¸­ï¼æåééæ´åé è¨ç·´è³æãæ¨¡åå¤§å°åç¿»è­¯æ¹åæ¸éï¼æ¨å SLT çåæ²¿ãæåå°ä¸åè³æå·è¡å¤§è¦æ¨¡ SLT é è¨ç·´ï¼å¶ä¸­åæ¬ 1) åéçå¤èªè¨ YouTube SLT è³æã2) å¹³è¡æå­èªæåº«ï¼ä»¥å 3) ééä½¿ç¨ç¾æçæ©å¨ç¿»è­¯æ¨¡åå°å½±çå­å¹ç¿»è­¯æå¶ä»èªè¨èæ´åç SLT è³æãæåå¨ç·¨ç¢¼å¨-è§£ç¢¼å¨æ¶æ§ä¸ï¼ä½¿ç¨ç¹å®æ¼ä»»åçæç¤ºçµ±ä¸ä¸åçé è¨ç·´ä»»åï¼ä¸¦ä½¿ç¨è·¨æ¨¡åå¤§å°çé è¨ç·´ (m/By)T5 æ¨¡ååå§å SLT æ¨¡åãHow2Sign å FLEURS-ASL#0 (ASL å° 42 ç¨®å£èª) ä¸ç SLT é è¨ç·´çµæè­æäºè³æ/æ¨¡åæ´ååè·¨èªè¨è·¨æ¨¡å¼è½ç§»çéè¦æ§ï¼ä»¥åé¶æ¬¡å­¸ç¿ SLT çå¯è¡æ§ãæåå¾®èª¿é è¨ç·´ç SLT æ¨¡åï¼éå°æ¶µè 5 ç¨®æèªç 5 åä¸æ¸¸éæ¾é å SLT è©éæ¨æºé²è¡å¾®èª¿ãå¯¦é©é¡¯ç¤ºï¼èé¦èåºç·ç¸æ¯æé¡¯èçåè³ªæåï¼å¤§å¹è¶è¶ååçæè¡æ°´æº (SOTA)ã

##### **Zero-shot Cross-Lingual Transfer for Synthetic Data Generation in Grammatical Error Detection**
2407.11854v1 by Gaetan Lopez Latouche, Marc-AndrÃ© Carbonneau, Ben Swanson

Grammatical Error Detection (GED) methods rely heavily on human annotated
error corpora. However, these annotations are unavailable in many low-resource
languages. In this paper, we investigate GED in this context. Leveraging the
zero-shot cross-lingual transfer capabilities of multilingual pre-trained
language models, we train a model using data from a diverse set of languages to
generate synthetic errors in other languages. These synthetic error corpora are
then used to train a GED model. Specifically we propose a two-stage fine-tuning
pipeline where the GED model is first fine-tuned on multilingual synthetic data
from target languages followed by fine-tuning on human-annotated GED corpora
from source languages. This approach outperforms current state-of-the-art
annotation-free GED methods. We also analyse the errors produced by our method
and other strong baselines, finding that our approach produces errors that are
more diverse and more similar to human errors.

æè¦ï¼èªæ³é¯èª¤åµæ¸¬ (GED) æ¹æ³æ¥µåº¦ä¾è³´äººå·¥æ¨è¨»çé¯èª¤èªæåº«ãç¶èï¼éäºæ¨è¨»å¨è¨±å¤ä½è³æºèªè¨ä¸­ä¸¦ä¸å¯ç¨ãå¨æ¬æä¸­ï¼æåç ç©¶æ­¤èçµ¡ä¸­ç GEDãå©ç¨å¤èªè¨é è¨ç·´èªè¨æ¨¡åçé¶æ¬¡å­¸ç¿è·¨èªè¨è½ç§»è½åï¼æåä½¿ç¨ä¾èªåç¨®èªè¨çè³æè¨ç·´ä¸åæ¨¡åï¼ä»¥ç¢çå¶ä»èªè¨ä¸­çåæé¯èª¤ãéäºåæé¯èª¤èªæåº«æ¥èç¨æ¼è¨ç·´ GED æ¨¡åãå·é«ä¾èªªï¼æåæåºä¸åå©éæ®µå¾®èª¿ç®¡éï¼å¶ä¸­ GED æ¨¡åé¦åéå°ç®æ¨èªè¨çå¤èªè¨åæè³æé²è¡å¾®èª¿ï¼ç¶å¾éå°ä¾æºèªè¨çäººå·¥æ¨è¨» GED èªæåº«é²è¡å¾®èª¿ãæ­¤æ¹æ³åªæ¼ç®åæåé²çç¡æ¨è¨» GED æ¹æ³ãæåä¹åææåçæ¨¡ååå¶ä»çå¼·å¤§åºæºæç¢ççé¯èª¤ï¼ç¼ç¾æåçæ¨¡åæç¢ççé¯èª¤æ´å¤åä¸æ´é¡ä¼¼æ¼äººé¡çé¯èª¤ã

##### **Schema Matching with Large Language Models: an Experimental Study**
2407.11852v1 by Marcel Parciak, Brecht Vandevoort, Frank Neven, Liesbet M. Peeters, Stijn Vansummeren

Large Language Models (LLMs) have shown useful applications in a variety of
tasks, including data wrangling. In this paper, we investigate the use of an
off-the-shelf LLM for schema matching. Our objective is to identify semantic
correspondences between elements of two relational schemas using only names and
descriptions. Using a newly created benchmark from the health domain, we
propose different so-called task scopes. These are methods for prompting the
LLM to do schema matching, which vary in the amount of context information
contained in the prompt. Using these task scopes we compare LLM-based schema
matching against a string similarity baseline, investigating matching quality,
verification effort, decisiveness, and complementarity of the approaches. We
find that matching quality suffers from a lack of context information, but also
from providing too much context information. In general, using newer LLM
versions increases decisiveness. We identify task scopes that have acceptable
verification effort and succeed in identifying a significant number of true
semantic matches. Our study shows that LLMs have potential in bootstrapping the
schema matching process and are able to assist data engineers in speeding up
this task solely based on schema element names and descriptions without the
need for data instances.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨åç¨®ä»»åä¸­å±ç¾åºæç¨çæç¨ï¼åæ¬è³ææ´çãå¨æ¬æä¸­ï¼æåæ¢è¨ç¾æ LLM å¨æ¶æ§æ¯å°ä¸­çç¨éãæåçç®æ¨æ¯åä½¿ç¨åç¨±åæè¿°ï¼æ¾åºå©åéè¯å¼æ¶æ§çåç´ ä¹éçèªæå°æãä½¿ç¨å¾å¥åº·é åæ°å»ºç«çåºæºï¼æåæåºä¸åçæè¬ä»»åç¯åãéäºæ¹æ³æ¯ç¨æ¼æç¤º LLM é²è¡æ¶æ§æ¯å°ï¼å¶åå«å¨æç¤ºä¸­çèçµ¡è³è¨éææä¸åãä½¿ç¨éäºä»»åç¯åï¼æåå°åºæ¼ LLM çæ¶æ§æ¯å°èå­ä¸²ç¸ä¼¼æ§åºæºé²è¡æ¯è¼ï¼æ¢è¨æ¯å°åè³ªãé©è­å·¥ä½ãææ·æ§ï¼ä»¥åæ¹æ³çäºè£æ§ãæåç¼ç¾æ¯å°åè³ªæåå°èçµ¡è³è¨ä¸è¶³ä»¥åæä¾éå¤èçµ¡è³è¨çå½±é¿ãä¸è¬ä¾èªªï¼ä½¿ç¨è¼æ°ç LLM çæ¬æå¢å ææ·æ§ãæåæ¾åºå·æå¯æ¥åé©è­å·¥ä½ï¼ä¸¦æåæ¾åºå¤§éçå¯¦èªææ¯å°çä»»åç¯åãæåçç ç©¶é¡¯ç¤ºï¼LLM æå©æ¼å¼å°æ¶æ§æ¯å°æµç¨ï¼ä¸¦ä¸è½å¤ åå©è³æå·¥ç¨å¸«åæ ¹ææ¶æ§åç´ åç¨±åæè¿°å éæ­¤ä»»åï¼èä¸éè¦è³æå¯¦ä¾ã

##### **Variational Randomized Smoothing for Sample-Wise Adversarial Robustness**
2407.11844v1 by Ryo Hase, Ye Wang, Toshiaki Koike-Akino, Jing Liu, Kieran Parsons

Randomized smoothing is a defensive technique to achieve enhanced robustness
against adversarial examples which are small input perturbations that degrade
the performance of neural network models. Conventional randomized smoothing
adds random noise with a fixed noise level for every input sample to smooth out
adversarial perturbations. This paper proposes a new variational framework that
uses a per-sample noise level suitable for each input by introducing a noise
level selector. Our experimental results demonstrate enhancement of empirical
robustness against adversarial attacks. We also provide and analyze the
certified robustness for our sample-wise smoothing method.

æè¦ï¼é¨æ©å¹³æ»æ¯ä¸ç¨®é²ç¦¦æè¡ï¼ç¨æ¼å¢å¼·å°æç¯ä¾çé­¯æ£æ§ï¼èå°æç¯ä¾æ¯å°ç¥ç¶ç¶²è·¯æ¨¡åçæè½é ææå®³çå°åè¼¸å¥æ¾åãå³çµ±é¨æ©å¹³æ»æéå°æ¯åè¼¸å¥æ¨£æ¬å å¥åºå®éè¨å±¤ç´çé¨æ©éè¨ï¼ä»¥å¹³æ»å°ææ¾åãæ¬ææåºä¸åæ°çè®åæ¶æ§ï¼ééå¼å¥éè¨å±¤ç´é¸æå¨ï¼ä½¿ç¨é©åæ¯åè¼¸å¥çæ¯åæ¨£æ¬éè¨å±¤ç´ãæåçå¯¦é©çµæè­æäºå°ææ»æçç¶é©é­¯æ£æ§å¾å°å¢å¼·ãæåä¹æä¾ä¸¦åæäºæåæ¨£æ¬å¹³æ»æ¹æ³çèªè­é­¯æ£æ§ã

##### **InferAct: Inferring Safe Actions for LLM-Based Agents Through Preemptive Evaluation and Human Feedback**
2407.11843v1 by Haishuo Fang, Xiaodan Zhu, Iryna Gurevych

A crucial requirement for deploying LLM-based agents in real-life
applications is robustness against risky or irreversible mistakes. However,
existing research lacks a focus on the preemptive evaluation of reasoning
trajectories performed by LLM agents, leading to a gap in ensuring safe and
reliable operations. To explore better solutions, this paper introduces
InferAct, a novel approach that leverages the Theory-of-Mind capability of LLMs
to proactively detect potential errors before critical actions are executed
(e.g., "buy-now" in automatic online trading or web shopping). InferAct is also
capable of integrating human feedback to prevent irreversible risks and enhance
the actor agent's decision-making process. Experiments on three widely used
tasks demonstrate the effectiveness of InferAct. The proposed solution presents
a novel approach and concrete contributions toward developing LLM agents that
can be safely deployed in different environments involving critical
decision-making.

æè¦ï¼é¨ç½²åºæ¼ LLM çä»£çè³å¯¦éæç¨æï¼ééµéæ±ä¹ä¸æ¯è½æµç¦¦é¢¨éªæä¸å¯éè½çé¯èª¤ãç¶èï¼ç¾æç ç©¶ç¼ºä¹å° LLM ä»£çå·è¡æ¨çè»è·¡çåå¶è©ä¼°çéé»ï¼å°è´ç¢ºä¿å®å¨åå¯é éä½å­å¨å·®è·ãçºäºæ¢ç´¢æ´å¥½çè§£æ±ºæ¹æ¡ï¼æ¬æä»ç´¹ InferActï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼å®å©ç¨ LLM çå¿æºçè«è½åå¨å·è¡ééµåä½ä¹åä¸»ååµæ¸¬æ½å¨é¯èª¤ï¼ä¾å¦ï¼èªåç·ä¸äº¤ææç¶²è·¯è³¼ç©çãç«å³è³¼è²·ãï¼ãInferAct ä¹è½æ´åäººé¡åé¥ä»¥é²æ­¢ä¸å¯éè½çé¢¨éªï¼ä¸¦å¢å¼·è¡çºä»£ççæ±ºç­éç¨ãå¨ä¸åå»£æ³ä½¿ç¨çä»»åä¸é²è¡çå¯¦é©è­æäº InferAct çæææ§ãææåºçè§£æ±ºæ¹æ¡åç¾åºä¸ç¨®æ°ç©çæ¹æ³ï¼ä¸¦çºéç¼ LLM ä»£çååºå·é«è²¢ç»ï¼éäºä»£çè½å®å¨å°é¨ç½²å¨æ¶åééµæ±ºç­çä¸åç°å¢ä¸­ã

##### **LoFTI: Localization and Factuality Transfer to Indian Locales**
2407.11833v1 by Sona Elza Simon, Soumen Kumar Mondal, Abhishek Singhania, Sayambhu Sen, Preethi Jyothi

Large language models (LLMs) encode vast amounts of world knowledge acquired
via training on large web-scale datasets crawled from the internet. However,
these datasets typically exhibit a geographical bias towards English-speaking
Western countries. This results in LLMs producing biased or hallucinated
responses to queries that require answers localized to other geographical
regions. In this work, we introduce a new benchmark named LoFTI (Localization
and Factuality Transfer to Indian Locales) that can be used to evaluate an
LLM's localization and factual text transfer capabilities. LoFTI consists of
factual statements about entities in source and target locations; the source
locations are spread across the globe and the target locations are all within
India with varying degrees of hyperlocality (country, states, cities). The
entities span a wide variety of categories. We use LoFTI to evaluate Mixtral,
GPT-4 and two other Mixtral-based approaches well-suited to the task of
localized factual transfer. We demonstrate that LoFTI is a high-quality
evaluation benchmark and all the models, including GPT-4, produce skewed
results across varying levels of hyperlocality.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ç·¨ç¢¼äºå¤§éä¸çç¥è­ï¼éäºç¥è­æ¯ééè¨ç·´å¤§åç¶²è·¯è¦æ¨¡è³æéï¼å¾ç¶²éç¶²è·¯ç¬åï¼èç²å¾çãç¶èï¼éäºè³æééå¸¸æå°è±èªç³»è¥¿æ¹åå®¶è¡¨ç¾åºå°çåè¦ãéå°è´ LLM å°éè¦å°ç­æ¡å¨å°çååæ¬å°åçæ¥è©¢ç¢çæåè¦æèæ§çåæãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºä¸ååçº LoFTIï¼æ¬å°ååäºå¯¦å³è¼¸å°å°åº¦æ¬å°ï¼çæ°åºæºï¼å¯ç¨æ¼è©ä¼° LLM çæ¬å°ååäºå¯¦ææ¬å³è¼¸è½åãLoFTI åå«éæ¼ä¾æºåç®æ¨ä½ç½®å¯¦é«çäºå¯¦é³è¿°ï¼ä¾æºä½ç½®éå¸å¨çï¼èç®æ¨ä½ç½®åå¨å°åº¦å¢å§ï¼å·æä¸åç¨åº¦çè¶å°æ¹æ§ï¼åå®¶ãå·ãåå¸ï¼ãå¯¦é«æ¶µèäºå»£æ³çé¡å¥ãæåä½¿ç¨ LoFTI ä¾è©ä¼° MixtralãGPT-4 åå¶ä»å©ç¨®éå¸¸é©åæ¼æ¬å°åäºå¯¦å³è¼¸ä»»åçåºæ¼ Mixtral çæ¹æ³ãæåè­æ LoFTI æ¯åé«åè³ªçè©ä¼°åºæºï¼åæ¬ GPT-4 å¨å§çæææ¨¡åå¨ä¸åå±¤ç´çè¶å°æ¹æ§ä¸­é½ç¢çäºåæççµæã

##### **Personalized Conversational Travel Assistant powered by Generative AI**
2407.11830v1 by Alexio Cassani, Michele Ruberl, Antonio Salis, Giacomo Giannese, Gianluca Boanelli

The Tourism and Destination Management Organization (DMO) industry is rapidly
evolving to adapt to new technologies and traveler expectations. Generative
Artificial Intelligence (AI) offers an astonishing and innovative opportunity
to enhance the tourism experience by providing personalized, interactive and
engaging assistance. In this article, we propose a generative AI-based chatbot
for tourism assistance. The chatbot leverages AI ability to generate realistic
and creative texts, adopting the friendly persona of the well-known Italian
all-knowledgeable aunties, to provide tourists with personalized information,
tailored and dynamic pre, during and post recommendations and trip plans and
personalized itineraries, using both text and voice commands, and supporting
different languages to satisfy Italian and foreign tourists expectations. This
work is under development in the Molise CTE research project, funded by the
Italian Minister of the Economic Growth (MIMIT), with the aim to leverage the
best emerging technologies available, such as Cloud and AI to produce state of
the art solutions in the Smart City environment.

æè¦ï¼æéåç®çå°ç®¡ççµç¹ (DMO) ç¢æ¥­å¿«éæ¼é²ï¼ä»¥é©ææ°ç§æåæå®¢ææãçæå¼äººå·¥æºæ§ (AI) æä¾é©äººçåµæ°æ©æï¼ééæä¾åäººåãäºåä¸å¼äººå¥åçåå©ï¼ä¾æåæéé«é©ãå¨æ¬æä¸­ï¼æåæåºä¸åç¨æ¼æéåå©ççæå¼ AI èå¤©æ©å¨äººãèå¤©æ©å¨äººå©ç¨ AI ç¢çé¼çä¸å·åµæçæå­ï¼æ¡ç¨èåçç¾©å¤§å©è¬äºéé¿å§¨çååè§è²ï¼ä½¿ç¨æå­åèªé³æä»¤çºæå®¢æä¾åäººåè³è¨ãéèº«æé ä¸åæçæéå»ºè­°åè¡ç¨è¦åï¼ä»¥ååäººåè¡ç¨ï¼ä¸¦æ¯æ´å¤åèªè¨ä»¥æ»¿è¶³ç¾©å¤§å©åå¤åæå®¢çææãæ­¤é å·¥ä½ç®åå¨ç±ç¾©å¤§å©ç¶æ¿æé·é¨ (MIMIT) è³å©ç Molise CTE ç ç©¶è¨ç«ä¸­é²è¡ï¼ç®æ¨æ¯å©ç¨é²ç«¯å AI ç­æä½³æ°èç§æï¼å¨æºæ§åå¸ç°å¢ä¸­ç¢çæåé²çè§£æ±ºæ¹æ¡ã

##### **GPT Assisted Annotation of Rhetorical and Linguistic Features for Interpretable Propaganda Technique Detection in News Text**
2407.11827v1 by Kyle Hamilton, Luca Longo, Bojan Bozic

While the use of machine learning for the detection of propaganda techniques
in text has garnered considerable attention, most approaches focus on
"black-box" solutions with opaque inner workings. Interpretable approaches
provide a solution, however, they depend on careful feature engineering and
costly expert annotated data. Additionally, language features specific to
propagandistic text are generally the focus of rhetoricians or linguists, and
there is no data set labeled with such features suitable for machine learning.
This study codifies 22 rhetorical and linguistic features identified in
literature related to the language of persuasion for the purpose of annotating
an existing data set labeled with propaganda techniques. To help human experts
annotate natural language sentences with these features, RhetAnn, a web
application, was specifically designed to minimize an otherwise considerable
mental effort. Finally, a small set of annotated data was used to fine-tune
GPT-3.5, a generative large language model (LLM), to annotate the remaining
data while optimizing for financial cost and classification accuracy. This
study demonstrates how combining a small number of human annotated examples
with GPT can be an effective strategy for scaling the annotation process at a
fraction of the cost of traditional annotation relying solely on human experts.
The results are on par with the best performing model at the time of writing,
namely GPT-4, at 10x less the cost. Our contribution is a set of features,
their properties, definitions, and examples in a machine-readable format, along
with the code for RhetAnn and the GPT prompts and fine-tuning procedures for
advancing state-of-the-art interpretable propaganda technique detection.

æè¦ï¼<paragraph>åç®¡ä½¿ç¨æ©å¨å­¸ç¿ä¾åµæ¸¬å®£å³æå·§å¨ææ¬ä¸­å·²ç²å¾ç¸ç¶çéæ³¨ï¼ä½å¤§å¤æ¸æ¹æ³é½å°æ³¨æ¼å·æä¸éæå§é¨éä½çãé»çå­ãè§£æ±ºæ¹æ¡ãå¯è§£éçæ¹æ³æä¾äºè§£æ±ºæ¹æ¡ï¼ç¶èï¼å®åä¾è³´æ¼ä»ç´°çç¹å¾µå·¥ç¨åæè²´çå°å®¶è¨»éè³æãæ­¤å¤ï¼å®£å³æ§ææ¬çç¹å®èªè¨ç¹å¾µéå¸¸æ¯ä¿®è¾­å­¸å®¶æèªè¨å­¸å®¶çéæ³¨ç¦é»ï¼ä¸¦ä¸æ²ææ¨è¨ææ­¤é¡ç¹å¾µçè³æéé©åæ©å¨å­¸ç¿ãæ¬ç ç©¶å°åºç¾å¨èèªªæèªè¨ç¸éçæç»ä¸­è­å¥åºç 22 åä¿®è¾­åèªè¨ç¹å¾µç·¨çºææ³å¸ï¼ç®çæ¯çºæ¨è¨æå®£å³æå·§çç¾æè³æéãçºäºå¹«å©äººé¡å°å®¶ä½¿ç¨éäºç¹å¾µè¨»éèªç¶èªè¨å¥å­ï¼å°éè¨­è¨äºç¶²è·¯æç¨ç¨å¼ RhetAnnï¼ä»¥æå¤§ç¨åº¦å°æ¸å°åæ¬ç¸ç¶å¤§çå¿æºè² æãæå¾ï¼ä½¿ç¨ä¸å°çµè¨»éè³æå¾®èª¿äºçæå¼å¤§åèªè¨æ¨¡å (LLM) GPT-3.5ï¼ä»¥è¨»éå©é¤è³æï¼åæéå°è²¡åææ¬ååé¡æºç¢ºåº¦é²è¡æä½³åãæ¬ç ç©¶å±ç¤ºäºå°å°æ¸äººé¡è¨»éç¯ä¾è GPT çµåå¦ä½æçºä»¥å³çµ±åä¾è³´äººé¡å°å®¶çè¨»éææ¬çä¸å°é¨åä¾æ´å±è¨»éç¨åºçææç­ç¥ãå¨æ°å¯«æ¬ææï¼çµæèç¶æè¡¨ç¾æä½³çæ¨¡å GPT-4 ç¸ç¶ï¼ææ¬å»ä½äº 10 åãæåçè²¢ç»æ¯ä¸çµç¹å¾µãå®åçå±¬æ§ãå®ç¾©åç¯ä¾ï¼æ¡ç¨æ©å¨å¯è®æ ¼å¼ï¼ä»¥å RhetAnn çç¨å¼ç¢¼å GPT æç¤ºåå¾®èª¿ç¨åºï¼ç¨æ¼æ¨é²æåé²çå¯è§£éå®£å³æå·§åµæ¸¬ã</paragraph>

##### **The Future of Data Science Education**
2407.11824v1 by Brian Wright, Peter Alonzi, Ali Riveria

The definition of Data Science is a hotly debated topic. For many, the
definition is a simple shortcut to Artificial Intelligence or Machine Learning.
However, there is far more depth and nuance to the field of Data Science than a
simple shortcut can provide. The School of Data Science at the University of
Virginia has developed a novel model for the definition of Data Science. This
model is based on identifying a unified understanding of the data work done
across all areas of Data Science. It represents a generational leap forward in
how we understand and teach Data Science. In this paper we will present the
core features of the model and explain how it unifies various concepts going
far beyond the analytics component of AI. From this foundation we will present
our Undergraduate Major curriculum in Data Science and demonstrate how it
prepares students to be well-rounded Data Science team members and leaders. The
paper will conclude with an in-depth overview of the Foundations of Data
Science course designed to introduce students to the field while also
implementing proven STEM oriented pedagogical methods. These include, for
example, specifications grading, active learning lectures, guest lectures from
industry experts and weekly gamification labs.

æè¦ï¼æ¸æç§å­¸çå®ç¾©æ¯ä¸åç±éçç­è«è©±é¡ãå°è¨±å¤äººä¾èªªï¼éåå®ç¾©æ¯éå¾äººå·¥æºæ§ææ©å¨å­¸ç¿çæ·å¾ãç¶èï¼æ¸æç§å­¸é åçæ·±åº¦åç´°å¾®å·®å¥é é è¶éä¸åç°¡å®çæ·å¾æè½æä¾çãç¶­åå°¼äºå¤§å­¸çæ¸æç§å­¸å­¸é¢çºæ¸æç§å­¸çå®ç¾©éç¼äºä¸åæ°æ¨¡åãéåæ¨¡ååºæ¼å°æ¸æç§å­¸ææé åæåçæ¸æå·¥ä½ççµ±ä¸çè§£ãå®ä»£è¡¨äºæåçè§£åæææ¸æç§å­¸æ¹å¼çä¸ä»£é£èºãå¨æ¬æä¸­ï¼æåå°ä»ç´¹è©²æ¨¡åçæ ¸å¿ç¹å¾µï¼ä¸¦è§£éå®å¦ä½çµ±ä¸åç¨®æ¦å¿µï¼é é è¶åºäº AI çåæçµæé¨åãå¾éååºç¤ä¸ï¼æåå°ä»ç´¹æåçæ¸æç§å­¸æ¬ç§å°æ¥­èª²ç¨ï¼ä¸¦å±ç¤ºå®å¦ä½è®å­¸çåå¥½æºåï¼æçºå¨é¢ç¼å±çæ¸æç§å­¸åéæå¡åé å°èãæ¬æå°ä»¥å°æ¸æç§å­¸åºç¤èª²ç¨çæ·±å¥æ¦è¿°ä½çºçµå°¾ï¼è©²èª²ç¨æ¨å¨åå­¸çä»ç´¹è©²é åï¼åæä¹å¯¦æ½ç¶éé©è­ç STEM å°åæå­¸æ¹æ³ãä¾å¦ï¼éäºæ¹æ³åæ¬è¦ç¯è©åãä¸»åå­¸ç¿è¬åº§ãä¾èªè¡æ¥­å°å®¶çå®¢åº§è¬åº§åæ¯é±çéæ²åå¯¦é©å®¤ã

##### **Invariant Consistency for Knowledge Distillation**
2407.11802v1 by Nikolaos Giakoumoglou, Tania Stathaki

Knowledge distillation (KD) involves transferring the knowledge from one
neural network to another, often from a larger, well-trained model (teacher) to
a smaller, more efficient model (student). Traditional KD methods minimize the
Kullback-Leibler (KL) divergence between the probabilistic outputs of the
teacher and student networks. However, this approach often overlooks crucial
structural knowledge embedded within the teacher's network. In this paper, we
introduce Invariant Consistency Distillation (ICD), a novel methodology
designed to enhance KD by ensuring that the student model's representations are
consistent with those of the teacher. Our approach combines contrastive
learning with an explicit invariance penalty, capturing significantly more
information from the teacher's representation of the data. Our results on
CIFAR-100 demonstrate that ICD outperforms traditional KD techniques and
surpasses 13 state-of-the-art methods. In some cases, the student model even
exceeds the teacher model in terms of accuracy. Furthermore, we successfully
transfer our method to other datasets, including Tiny ImageNet and STL-10. The
code will be made public soon.

æè¦ï¼ç¥è­è¸é¤¾ (KD) æ¶åå°ç¥è­å¾ä¸åç¥ç¶ç¶²è·¯è½ç§»å°å¦ä¸åç¥ç¶ç¶²è·¯ï¼éå¸¸å¾ä¸åè¼å¤§ãè¨ç·´è¯å¥½çæ¨¡åï¼æå¸«ï¼è½ç§»å°ä¸åè¼å°ãæ´ææççæ¨¡åï¼å­¸çï¼ãå³çµ±ç KD æ¹æ³å°æå¸«åå­¸çç¶²è·¯çæ©çè¼¸åºä¹éç Kullback-Leibler (KL) å·®ç°æå°åãç¶èï¼éç¨®æ¹æ³éå¸¸å¿½ç¥äºæå¸«ç¶²è·¯ä¸­åµå¥çééµçµæ§ç¥è­ãå¨æ¬æä¸­ï¼æåå¼å¥äºä¸è®ä¸è´æ§è¸é¤¾ (ICD)ï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼æ¨å¨ééç¢ºä¿å­¸çæ¨¡åçè¡¨å¾µèæå¸«çè¡¨å¾µä¸è´ä¾å¢å¼· KDãæåçåæ³çµåäºå°æ¯å­¸ç¿èæç¢ºçä¸è®ç½°åï¼å¾æå¸«å°è³æçè¡¨å¾µä¸­æ·åæ´å¤è³è¨ãæåå¨ CIFAR-100 ä¸ççµæè­æï¼ICD åªæ¼å³çµ±ç KD æè¡ï¼ä¸¦è¶è¶äº 13 ç¨®æåé²çæ¹æ³ãå¨æäºææ³ä¸ï¼å­¸çæ¨¡åçè³å¨æºç¢ºåº¦æ¹é¢è¶éäºæå¸«æ¨¡åãæ­¤å¤ï¼æåæåå°å°æåçæ¨¡åè½ç§»å°å¶ä»è³æéï¼åæ¬ Tiny ImageNet å STL-10ãç¨å¼ç¢¼å°å¾å¿«å¬éã

##### **PipeInfer: Accelerating LLM Inference using Asynchronous Pipelined Speculation**
2407.11798v1 by Branden Butler, Sixing Yu, Arya Mazaheri, Ali Jannesari

Inference of Large Language Models (LLMs) across computer clusters has become
a focal point of research in recent times, with many acceleration techniques
taking inspiration from CPU speculative execution. These techniques reduce
bottlenecks associated with memory bandwidth, but also increase end-to-end
latency per inference run, requiring high speculation acceptance rates to
improve performance. Combined with a variable rate of acceptance across tasks,
speculative inference techniques can result in reduced performance.
Additionally, pipeline-parallel designs require many user requests to maintain
maximum utilization. As a remedy, we propose PipeInfer, a pipelined speculative
acceleration technique to reduce inter-token latency and improve system
utilization for single-request scenarios while also improving tolerance to low
speculation acceptance rates and low-bandwidth interconnects. PipeInfer
exhibits up to a 2.15$\times$ improvement in generation speed over standard
speculative inference. PipeInfer achieves its improvement through Continuous
Asynchronous Speculation and Early Inference Cancellation, the former improving
latency and generation speed by running single-token inference simultaneously
with several speculative runs, while the latter improves speed and latency by
skipping the computation of invalidated runs, even in the middle of inference.

æè¦ï¼è¿ä¾ï¼å¤§åèªè¨æ¨¡å (LLM) å¨é»è¦å¢éä¸­çæ¨è«å·²æçºç ç©¶çéé»ï¼è¨±å¤å éæè¡å¾ CPU æ¨æ¸¬å·è¡ä¸­æ±²åéæãéäºæè¡æ¸å°äºèè¨æ¶é«é »å¯¬ç¸éçç¶é ¸ï¼ä½ä¹å¢å äºæ¯åæ¨è«éè¡çç«¯å°ç«¯å»¶é²ï¼éè¦å¾é«çæ¨æ¸¬æ¥åçæè½æåæè½ãçµåè·¨ä»»åçå¯è®æ¥åçï¼æ¨æ¸¬æ¨è«æè¡å¯è½æå°è´æè½ä¸éãæ­¤å¤ï¼ç®¡ç·å¹³è¡è¨­è¨éè¦è¨±å¤ä½¿ç¨èè¦æ±æè½ç¶­ææå¤§çä½¿ç¨çãä½çºè£ææªæ½ï¼æåæåº PipeInferï¼ä¸ç¨®ç®¡ç·æ¨æ¸¬å éæè¡ï¼ç¨æ¼æ¸å°ä»£å¹£éå»¶é²ä¸¦æ¹åå®ä¸è¦æ±å ´æ¯çç³»çµ±ä½¿ç¨çï¼åæä¹æé«å°ä½æ¨æ¸¬æ¥åçåä½é »å¯¬äºé£çå®¹å¿åº¦ãèæ¨æºæ¨æ¸¬æ¨è«ç¸æ¯ï¼PipeInfer å¨ç¢çéåº¦ä¸å±ç¾åºé«é 2.15 åçé²æ­¥ãPipeInfer ééé£çºéåæ­¥æ¨æ¸¬åæ©ææ¨è«åæ¶ä¾éæé²æ­¥ï¼åèééåæå·è¡å®ä¸ä»£å¹£æ¨è«åå¤åæ¨æ¸¬éè¡ä¾æ¹åå»¶é²åç¢çéåº¦ï¼èå¾èééç¥éç¡æéè¡çè¨ç®ï¼å³ä½¿æ¯å¨æ¨è«éç¨ä¸­ï¼ä¾æ¹åéåº¦åå»¶é²ã

##### **Characterizing and Understanding HGNN Training on GPUs**
2407.11790v1 by Dengke Han, Mingyu Yan, Xiaochun Ye, Dongrui Fan, Ninghui Sun

Owing to their remarkable representation capabilities for heterogeneous graph
data, Heterogeneous Graph Neural Networks (HGNNs) have been widely adopted in
many critical real-world domains such as recommendation systems and medical
analysis. Prior to their practical application, identifying the optimal HGNN
model parameters tailored to specific tasks through extensive training is a
time-consuming and costly process. To enhance the efficiency of HGNN training,
it is essential to characterize and analyze the execution semantics and
patterns within the training process to identify performance bottlenecks. In
this study, we conduct an in-depth quantification and analysis of two
mainstream HGNN training scenarios, including single-GPU and multi-GPU
distributed training. Based on the characterization results, we disclose the
performance bottlenecks and their underlying causes in different HGNN training
scenarios and provide optimization guidelines from both software and hardware
perspectives.

æè¦ï¼ç±æ¼ç°è³ªåç¥ç¶ç¶²è·¯ (HGNN) å·æåè¶çç°è³ªåå½¢æ¸æè¡¨ç¤ºè½åï¼å æ­¤å·²å»£æ³æç¨æ¼è¨±å¤éè¦ççå¯¦ä¸çé åï¼ä¾å¦æ¨è¦ç³»çµ±åé«çåæãå¨å¯¦éæç¨ä¹åï¼ééå»£æ³çè¨ç·´ä¾è­å¥éå°ç¹å®ä»»åèª¿æ´çæä½³ HGNN æ¨¡ååæ¸æ¯ä¸åèæä¸æè²´çéç¨ãçºäºæé« HGNN è¨ç·´çæçï¼å¿é æè¿°ååæè¨ç·´éç¨ä¸­çå·è¡èªç¾©åæ¨¡å¼ï¼ä»¥è­å¥æè½ç¶é ¸ãå¨æ¬ç ç©¶ä¸­ï¼æåå°å©åä¸»æµç HGNN è¨ç·´å ´æ¯ï¼åæ¬å® GPU åå¤ GPU åæ£å¼è¨ç·´ï¼é²è¡æ·±å¥çéåååæãæ ¹ææè¿°çµæï¼æåæ­ç¤ºäºä¸å HGNN è¨ç·´å ´æ¯ä¸­çæè½ç¶é ¸åå¶æ ¹æ¬åå ï¼ä¸¦å¾è»é«åç¡¬é«çè§åº¦æä¾äºæä½³åæåã

##### **Large Language Models as Misleading Assistants in Conversation**
2407.11789v1 by Betty Li Hou, Kejian Shi, Jason Phang, James Aung, Steven Adler, Rosie Campbell

Large Language Models (LLMs) are able to provide assistance on a wide range
of information-seeking tasks. However, model outputs may be misleading, whether
unintentionally or in cases of intentional deception. We investigate the
ability of LLMs to be deceptive in the context of providing assistance on a
reading comprehension task, using LLMs as proxies for human users. We compare
outcomes of (1) when the model is prompted to provide truthful assistance, (2)
when it is prompted to be subtly misleading, and (3) when it is prompted to
argue for an incorrect answer. Our experiments show that GPT-4 can effectively
mislead both GPT-3.5-Turbo and GPT-4, with deceptive assistants resulting in up
to a 23% drop in accuracy on the task compared to when a truthful assistant is
used. We also find that providing the user model with additional context from
the passage partially mitigates the influence of the deceptive model. This work
highlights the ability of LLMs to produce misleading information and the
effects this may have in real-world situations.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) è½å¤ å¨åç¨®è³è¨æå°ä»»åä¸­æä¾åå©ãç¶èï¼æ¨¡åçè¼¸åºå¯è½å·æèª¤å°æ§ï¼ç¡è«æ¯ç¡æçææ¯æææ¬ºé¨ãæåèª¿æ¥äº LLM å¨é±è®çè§£ä»»åä¸­æä¾åå©æå·ææ¬ºé¨æ§çè½åï¼ä½¿ç¨ LLM ä½çºäººé¡ä½¿ç¨èçä»£çãæåæ¯è¼äº (1) ç¶æ¨¡åè¢«æç¤ºæä¾çå¯¦åå©ã(2) ç¶å®è¢«æç¤ºé²è¡å¾®å¦çèª¤å°ãä»¥å (3) ç¶å®è¢«æç¤ºçºé¯èª¤ç­æ¡è¾¯è­·ççµæãæåçå¯¦é©è¡¨æï¼GPT-4 å¯ä»¥ææå°èª¤å° GPT-3.5-Turbo å GPT-4ï¼èä½¿ç¨çå¯¦å©çç¸æ¯ï¼å·ææ¬ºé¨æ§çå©çå°è´ä»»åæºç¢ºåº¦ä¸éå¤é 23%ãæåéç¼ç¾ï¼çºä½¿ç¨èæ¨¡åæä¾ä¾èªæ®µè½çé¡å¤èæ¯ï¼å¯ä»¥é¨åæ¸è¼æ¬ºé¨æ§æ¨¡åçå½±é¿ãéé å·¥ä½çªé¡¯äº LLM ç¢çèª¤å°æ§è³è¨çè½åï¼ä»¥åéå¯è½å¨ç¾å¯¦ä¸çä¸­ç¢ççå½±é¿ã

##### **Data-Juicer Sandbox: A Comprehensive Suite for Multimodal Data-Model Co-development**
2407.11784v1 by Daoyuan Chen, Haibin Wang, Yilun Huang, Ce Ge, Yaliang Li, Bolin Ding, Jingren Zhou

The emergence of large-scale multi-modal generative models has drastically
advanced artificial intelligence, introducing unprecedented levels of
performance and functionality. However, optimizing these models remains
challenging due to historically isolated paths of model-centric and
data-centric developments, leading to suboptimal outcomes and inefficient
resource utilization. In response, we present a novel sandbox suite tailored
for integrated data-model co-development. This sandbox provides a comprehensive
experimental platform, enabling rapid iteration and insight-driven refinement
of both data and models. Our proposed "Probe-Analyze-Refine" workflow,
validated through applications on state-of-the-art LLaVA-like and DiT based
models, yields significant performance boosts, such as topping the VBench
leaderboard. We also uncover fruitful insights gleaned from exhaustive
benchmarks, shedding light on the critical interplay between data quality,
diversity, and model behavior. With the hope of fostering deeper understanding
and future progress in multi-modal data and generative modeling, our codes,
datasets, and models are maintained and accessible at
https://github.com/modelscope/data-juicer/blob/main/docs/Sandbox.md.

æè¦ï¼é¨èå¤§è¦æ¨¡å¤æ¨¡æçææ¨¡åçåºç¾ï¼å¤§å¹æåäºäººå·¥æºæ§ï¼ä¸¦å°å¥äºåææªæçæè½ååè½å±¤ç´ãç¶èï¼ç±æ¼æ¨¡åä¸­å¿åè³æä¸­å¿ç¼å±è·¯å¾é·æä»¥ä¾åèªç¨ç«ï¼å°è´æ¬¡ä½³çµæåè³æºå©ç¨çä½è½ï¼å æ­¤æä½³åéäºæ¨¡åä»ç¶å·æææ°æ§ãçºäºè§£æ±ºéååé¡ï¼æåæåºä¸åéå°æ´åè³ææ¨¡åå±åéç¼éèº«æé çæ°æ²çå¥ä»¶ãéåæ²çæä¾äºä¸åå¨é¢çå¯¦é©å¹³å°ï¼è½å¿«éåè¦éç®ï¼ä¸¦æ ¹ææ·±å¥æ´å¯æ¹é²è³æåæ¨¡åãæåæåºçãæ¢æ¸¬åæç²¾é²ãå·¥ä½æµç¨ï¼å·²ééæç¨æ¼æåé²ç LLaVA é¡ä¼¼æ¨¡åååºæ¼ DiT çæ¨¡åç²å¾é©è­ï¼å¯å¤§å¹æåæè½ï¼ä¾å¦ç»ä¸ VBench æè¡æ¦é¦ä½ãæåä¹å¾è©³ç¡çåºæºæ¸¬è©¦ä¸­ç¼ç¾æç¨çæ·±å¥æ´å¯ï¼é¡æäºè³æåè³ªãå¤æ¨£æ§åæ¨¡åè¡çºä¹éçééµäº¤äºä½ç¨ãçºäºä¿é²å°å¤æ¨¡æè³æåçææ¨¡åçæ´æ·±å¥çè§£åæªä¾é²å±ï¼æåçç¨å¼ç¢¼ãè³æéåæ¨¡ååå·²ç¶­è­·ä¸¦å¯æ¼ https://github.com/modelscope/data-juicer/blob/main/docs/Sandbox.md åå¾ã

##### **SwitchCIT: Switching for Continual Instruction Tuning of Large Language Models**
2407.11780v1 by Xinbo Wu, Max Hartman, Vidhata Arjun Jayaraman, Lav R. Varshney

Large language models (LLMs) have exhibited impressive capabilities in
various domains, particularly in general language understanding. However these
models, trained on massive text data, may not be finely optimized for specific
tasks triggered by instructions. Continual instruction tuning is crucial to
adapt LLMs to evolving tasks and domains, ensuring their effectiveness and
relevance across a wide range of applications. In the context of continual
instruction tuning, where models are sequentially trained on different tasks,
catastrophic forgetting can occur, leading to performance degradation on
previously learned tasks. This work addresses the catastrophic forgetting in
continual instruction learning for LLMs through a switching mechanism for
routing computations to parameter-efficient tuned models. We demonstrate the
effectiveness of our method through experiments on continual instruction tuning
of different natural language generation tasks.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®é åä¸­å±ç¤ºäºä»¤äººå°è±¡æ·±å»çè½åï¼ç¹å¥æ¯å¨ä¸è¬èªè¨çè§£æ¹é¢ãç¶èï¼éäºå¨å¤§éæå­è³æä¸è¨ç·´çæ¨¡åå¯è½ç¡æ³éå°ç±æä»¤è§¸ç¼çç¹å®ä»»åé²è¡ç²¾ç´°æä½³åãæçºçæä»¤èª¿æ´å°æ¼è® LLM é©æä¸æ·è®åçä»»ååé åè³ééè¦ï¼ç¢ºä¿å®åå¨å»£æ³çæç¨ä¸­é½è½ç¼æ®æç¨åç¸éæ§ãå¨æçºæä»¤èª¿æ´çèæ¯ä¸ï¼æ¨¡åæä¾åºå¨ä¸åçä»»åä¸é²è¡è¨ç·´ï¼æ­¤æå¯è½æç¼çç½é£æ§éºå¿ï¼å°è´ååå­¸ç¿çä»»åæè½ä¸éãéé å·¥ä½ééåææ©å¶ä¾è§£æ±º LLM æçºæä»¤å­¸ç¿ä¸­çç½é£æ§éºå¿ï¼å°éç®è·¯ç±å°åæ¸æçæä½³åçèª¿æ´æ¨¡åãæåéééå°ä¸åèªç¶èªè¨ç¢çä»»åçæçºæä»¤èª¿æ´é²è¡å¯¦é©ï¼ä¾è­ææåçæ¹æ³ææã

##### **Sharif-MGTD at SemEval-2024 Task 8: A Transformer-Based Approach to Detect Machine Generated Text**
2407.11774v1 by Seyedeh Fatemeh Ebrahimi, Karim Akhavan Azari, Amirmasoud Iravani, Arian Qazvini, Pouya Sadeghi, Zeinab Sadat Taghavi, Hossein Sameti

Detecting Machine-Generated Text (MGT) has emerged as a significant area of
study within Natural Language Processing. While language models generate text,
they often leave discernible traces, which can be scrutinized using either
traditional feature-based methods or more advanced neural language models. In
this research, we explore the effectiveness of fine-tuning a RoBERTa-base
transformer, a powerful neural architecture, to address MGT detection as a
binary classification task. Focusing specifically on Subtask A
(Monolingual-English) within the SemEval-2024 competition framework, our
proposed system achieves an accuracy of 78.9% on the test dataset, positioning
us at 57th among participants. Our study addresses this challenge while
considering the limited hardware resources, resulting in a system that excels
at identifying human-written texts but encounters challenges in accurately
discerning MGTs.

æè¦ï¼æ©å¨ç¢ççæå­ï¼MGTï¼åµæ¸¬å·²æçºèªç¶èªè¨èçä¸­ä¸åéè¦çç ç©¶é åãéç¶èªè¨æ¨¡åæç¢çæå­ï¼ä½å®åéå¸¸æçä¸å¯è¾¨è­ççè·¡ï¼å¯ä»¥ä½¿ç¨å³çµ±çåºæ¼ç¹å¾µçæ¹æ³ææ´åé²çç¥ç¶èªè¨æ¨¡åä¾æª¢è¦éäºçè·¡ãå¨éé ç ç©¶ä¸­ï¼æåæ¢è¨äºå¾®èª¿ RoBERTa-base è½æå¨ï¼ä¸ç¨®å¼·å¤§çç¥ç¶æ¶æ§ï¼ä¾èç MGT åµæ¸¬ä½çºäºååé¡ä»»åçæææ§ãç¹å¥å°æ³¨æ¼ SemEval-2024 ç«¶è³½æ¶æ§ä¸­çå­ä»»å Aï¼å®èªè±èªï¼ï¼æåæåºçç³»çµ±å¨æ¸¬è©¦è³æéä¸éå°äº 78.9% çæºç¢ºåº¦ï¼å¨åèèä¸­æåç¬¬ 57 ä½ãæåçç ç©¶å¨èæ®æéç¡¬é«è³æºçåææå°äºéä¸ææ°ï¼å¾èç¢çäºä¸åå¨è­å¥äººé¡æ°å¯«çæå­æ¹é¢è¡¨ç¾åºè²ï¼ä½å¨æºç¢ºè¾¨å¥ MGT æ¹é¢éå°ææ°çç³»çµ±ã

##### **Educational Personalized Learning Path Planning with Large Language Models**
2407.11773v1 by Chee Ng, Yuen Fung

Educational Personalized Learning Path Planning (PLPP) aims to tailor
learning experiences to individual learners' needs, enhancing learning
efficiency and engagement. Despite its potential, traditional PLPP systems
often lack adaptability, interactivity, and transparency. This paper proposes a
novel approach integrating Large Language Models (LLMs) with prompt engineering
to address these challenges. By designing prompts that incorporate
learner-specific information, our method guides LLMs like LLama-2-70B and GPT-4
to generate personalized, coherent, and pedagogically sound learning paths. We
conducted experiments comparing our method with a baseline approach across
various metrics, including accuracy, user satisfaction, and the quality of
learning paths. The results show significant improvements in all areas,
particularly with GPT-4, demonstrating the effectiveness of prompt engineering
in enhancing PLPP. Additional long-term impact analysis further validates our
method's potential to improve learner performance and retention. This research
highlights the promise of LLMs and prompt engineering in advancing personalized
education.

æè¦ï¼æè²åäººåå­¸ç¿è·¯å¾è¦å (PLPP) æ¨å¨æ ¹æåå¥å­¸ç¿èçéæ±éèº«æé å­¸ç¿é«é©ï¼æåå­¸ç¿æçååèåº¦ãåç®¡ PLPP ç³»çµ±å·ææ½åï¼ä½å³çµ±ç PLPP ç³»çµ±éå¸¸ç¼ºä¹é©ææ§ãäºåæ§åéæåº¦ãæ¬ææåºäºä¸ç¨®åµæ°çæ¹æ³ï¼å°å¤§åèªè¨æ¨¡å (LLM) èæç¤ºå·¥ç¨ç¸çµåï¼ä»¥æå°éäºææ°ãééè¨­è¨åå«å­¸ç¿èç¹å®è³è¨çæç¤ºï¼æåçæ¨¡åå¼å° LLMï¼ä¾å¦ LLama-2-70B å GPT-4ï¼çæåæ§åãé£è²«ä¸å·ææå­¸æç¾©çå­¸ç¿è·¯å¾ãæåé²è¡äºå¯¦é©ï¼å¨æºç¢ºåº¦ãä½¿ç¨èæ»¿æåº¦åå­¸ç¿è·¯å¾åè³ªç­åç¨®ææ¨ä¸ï¼æ¯è¼äºæåçæ¹æ³èåºç·æ¹æ³ãçµæé¡¯ç¤ºå¨ææé åé½æé¡¯èçé²æ­¥ï¼ç¹å¥æ¯ GPT-4ï¼éè­æäºæç¤ºå·¥ç¨å¨å¢å¼· PLPP ä¸­çæææ§ãé²ä¸æ­¥çé·æå½±é¿åæé²ä¸æ­¥é©è­äºæåçæ¹æ³å¨æ¹åå­¸ç¿èè¡¨ç¾åä¿çæ¹é¢çæ½åãæ¬ç ç©¶å¼·èª¿äº LLM åæç¤ºå·¥ç¨å¨ä¿é²åäººåæè²æ¹é¢çæ½åã

##### **XEdgeAI: A Human-centered Industrial Inspection Framework with Data-centric Explainable Edge AI Approach**
2407.11771v1 by Truong Thanh Hung Nguyen, Phuc Truong Loc Nguyen, Hung Cao

Recent advancements in deep learning have significantly improved visual
quality inspection and predictive maintenance within industrial settings.
However, deploying these technologies on low-resource edge devices poses
substantial challenges due to their high computational demands and the inherent
complexity of Explainable AI (XAI) methods. This paper addresses these
challenges by introducing a novel XAI-integrated Visual Quality Inspection
framework that optimizes the deployment of semantic segmentation models on
low-resource edge devices. Our framework incorporates XAI and the Large Vision
Language Model to deliver human-centered interpretability through visual and
textual explanations to end-users. This is crucial for end-user trust and model
interpretability. We outline a comprehensive methodology consisting of six
fundamental modules: base model fine-tuning, XAI-based explanation generation,
evaluation of XAI approaches, XAI-guided data augmentation, development of an
edge-compatible model, and the generation of understandable visual and textual
explanations. Through XAI-guided data augmentation, the enhanced model
incorporating domain expert knowledge with visual and textual explanations is
successfully deployed on mobile devices to support end-users in real-world
scenarios. Experimental results showcase the effectiveness of the proposed
framework, with the mobile model achieving competitive accuracy while
significantly reducing model size. This approach paves the way for the broader
adoption of reliable and interpretable AI tools in critical industrial
applications, where decisions must be both rapid and justifiable.

æè¦ï¼æ·±åº¦å­¸ç¿çææ°é²å±é¡¯èæ¹åäºå·¥æ¥­ç°å¢ä¸­çè¦è¦ºåè³ªæª¢æ¸¬åé æ¸¬æ§ç¶­è­·ã
ç¶èï¼ç±æ¼é«è¨ç®éæ±åå¯è§£é AI (XAI) æ¹æ³çåºæè¤éæ§ï¼å¨ä½è³æºéç·£è£ç½®ä¸é¨ç½²éäºæè¡æå¸¶ä¾ç¸ç¶å¤§çææ°ãæ¬æééå¼å¥ä¸åæ°ç©ç XAI æ´åè¦è¦ºåè³ªæª¢æ¸¬æ¶æ§ä¾è§£æ±ºéäºææ°ï¼è©²æ¶æ§æä½³åäºèªæåå²æ¨¡åå¨ä½è³æºéç·£è£ç½®ä¸çé¨ç½²ãæåçæ¶æ§æ´åäº XAI åå¤§åè¦è¦ºèªè¨æ¨¡åï¼ééè¦è¦ºåæå­èªªææä¾ä»¥äººçºä¸­å¿çè©®éï¼è®æçµä½¿ç¨èçè§£ãéå°æ¼æçµä½¿ç¨èçä¿¡ä»»åæ¨¡åè©®éè³ééè¦ãæåæ¦è¿°äºä¸åå¨é¢çæ¹æ³è«ï¼åå«å­ååºæ¬æ¨¡çµï¼åºç¤æ¨¡åå¾®èª¿ãåºæ¼ XAI çèªªæç¢çãXAI æ¹æ³è©ä¼°ãXAI å¼å°è³ææ´åãéç·£ç¸å®¹æ¨¡åéç¼ï¼ä»¥åç¢çå¯çè§£çè¦è¦ºåæå­èªªæãéé XAI å¼å°çè³ææ´åï¼çµåé åå°å®¶ç¥è­ä»¥åè¦è¦ºåæå­èªªæçå¢å¼·æ¨¡åå·²æåé¨ç½²å¨è¡åè£ç½®ä¸ï¼ä»¥æ¯æ´æçµä½¿ç¨èå¨çå¯¦ä¸ççå ´æ¯ä¸­ãå¯¦é©çµæå±ç¤ºäºææåºæ¶æ§çæææ§ï¼è¡åæ¨¡åå¨é¡¯èæ¸å°æ¨¡åå¤§å°çåæï¼éå°äºç«¶ç­åçæºç¢ºåº¦ãæ­¤æ¹æ³çºå¨ééµå·¥æ¥­æç¨ä¸­æ´å»£æ³æ¡ç¨å¯é ä¸å¯è§£éç AI å·¥å·éªè·¯ï¼å¨éäºæç¨ä¸­ï¼æ±ºç­å¿é å¿«éä¸åçã

##### **Robust Utility-Preserving Text Anonymization Based on Large Language Models**
2407.11770v1 by Tianyu Yang, Xiaodan Zhu, Iryna Gurevych

Text anonymization is crucial for sharing sensitive data while maintaining
privacy. Existing techniques face the emerging challenges of re-identification
attack ability of Large Language Models (LLMs), which have shown advanced
capability in memorizing detailed information and patterns as well as
connecting disparate pieces of information. In defending against LLM-based
re-identification attacks, anonymization could jeopardize the utility of the
resulting anonymized data in downstream tasks -- the trade-off between privacy
and data utility requires deeper understanding within the context of LLMs. This
paper proposes a framework composed of three LLM-based components -- a privacy
evaluator, a utility evaluator, and an optimization component, which work
collaboratively to perform anonymization. To provide a practical model for
large-scale and real-time environments, we distill the anonymization
capabilities into a lightweight model using Direct Preference Optimization
(DPO). Extensive experiments demonstrate that the proposed models outperform
baseline models, showing robustness in reducing the risk of re-identification
while preserving greater data utility in downstream tasks. Our code and dataset
are available at https://github.com/UKPLab/arxiv2024-rupta.

æè¦ï¼æå­å¿ååå°æ¼å¨ç¶­è­·é±ç§çåæå±äº«ææè³æè³ééè¦ãç¾ææè¡é¢è¨èå¤§åèªè¨æ¨¡å (LLM) éæ°è­å¥æ»æè½åçæ°ææ°ï¼LLM å¨è¨æ¶è©³ç´°è³è¨åæ¨¡å¼ä»¥åé£æ¥ä¸åè³è¨æ¹é¢å±ç¾äºé²éåè½ãå¨é²ç¦¦åºæ¼ LLM çéæ°è­å¥æ»ææï¼å¿ååå¯è½æå±å®³å¿ååè³æå¨ä¸æ¸¸ä»»åä¸­çæç¨ ââ é±ç§åè³ææç¨ä¹éçæ¬è¡¡éè¦å¨ LLM çèæ¯ä¸æ·±å¥çè§£ãæ¬ææåºäºä¸åç±ä¸ååºæ¼ LLM ççµæé¨åçµæçæ¡æ¶ ââ ä¸åé±ç§è©ä¼°å¨ãä¸åæç¨è©ä¼°å¨åä¸åæä½³åçµæé¨åï¼å®åååå·¥ä½ä»¥å·è¡å¿ååãçºäºçºå¤§è¦æ¨¡åå¯¦æç°å¢æä¾ä¸åå¯¦ç¨çæ¨¡åï¼æåä½¿ç¨ç´æ¥åå¥½æä½³å (DPO) å°å¿åååè½æçæä¸åè¼éç´æ¨¡åãå¤§éçå¯¦é©è¡¨æï¼ææåºçæ¨¡ååªæ¼åºæºæ¨¡åï¼å¨éä½éæ°è­å¥é¢¨éªçåæï¼å±ç¾åºå¨ä¿çä¸æ¸¸ä»»åä¸­æ´å¤§è³ææç¨æ¹é¢çç©©å¥æ§ãæåçç¨å¼ç¢¼åè³æéå¯å¨ https://github.com/UKPLab/arxiv2024-rupta åå¾ã

##### **Vectoring Languages**
2407.11766v1 by Joseph Chen

Recent breakthroughs in large language models (LLM) have stirred up global
attention, and the research has been accelerating non-stop since then.
Philosophers and psychologists have also been researching the structure of
language for decades, but they are having a hard time finding a theory that
directly benefits from the breakthroughs of LLMs. In this article, we propose a
novel structure of language that reflects well on the mechanisms behind
language models and go on to show that this structure is also better at
capturing the diverse nature of language compared to previous methods. An
analogy of linear algebra is adapted to strengthen the basis of this
perspective. We further argue about the difference between this perspective and
the design philosophy for current language models. Lastly, we discuss how this
perspective can lead us to research directions that may accelerate the
improvements of science fastest.

æè¦ï¼è¿æå¤§åèªè¨æ¨¡å (LLM) ççªç ´æ§é²å±å¼èµ·äºå¨çéæ³¨ï¼èç¸éçç ç©¶ä¹èªæ­¤æçºå éã
å²å­¸å®¶åå¿çå­¸å®¶æ¸åå¹´ä¾ä¹ä¸ç´å¨ç ç©¶èªè¨çµæ§ï¼ä½ä»åå¾é£æ¾å°ä¸ç¨®çè«ï¼è½ç´æ¥å¾ LLM ççªç ´ä¸­åçãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°ç©çèªè¨çµæ§ï¼å¯ä»¥å¾å¥½å°åæ èªè¨æ¨¡åèå¾çæ©å¶ï¼ä¸¦é²ä¸æ­¥è¡¨æï¼èååçèªè¨æ¨¡åç¸æ¯ï¼éç¨®çµæ§æ´è½ææèªè¨çå¤æ¨£æ§ãç·æ§ä»£æ¸çé¡æ¯è¢«ç¨ä¾å¼·åéç¨®è§é»çåºç¤ãæåé²ä¸æ­¥è«è¿°äºéç¨®è§é»èç¶åèªè¨æ¨¡åçè¨­è¨çå¿µä¹éçå·®ç°ãæå¾ï¼æåè¨è«äºéç¨®è§é»å¦ä½å¼é æåé²è¡ç ç©¶ï¼ä»¥æå¿«éåº¦ä¿é²ç§å­¸çé²æ­¥ã

##### **A Channel Attention-Driven Hybrid CNN Framework for Paddy Leaf Disease Detection**
2407.11753v1 by Pandiyaraju V, Shravan Venkatraman, Abeshek A, Pavan Kumar S, Aravintakshan S A, Senthil Kumar A M, Kannan A

Farmers face various challenges when it comes to identifying diseases in rice
leaves during their early stages of growth, which is a major reason for poor
produce. Therefore, early and accurate disease identification is important in
agriculture to avoid crop loss and improve cultivation. In this research, we
propose a novel hybrid deep learning (DL) classifier designed by extending the
Squeeze-and-Excitation network architecture with a channel attention mechanism
and the Swish ReLU activation function. The channel attention mechanism in our
proposed model identifies the most important feature channels required for
classification during feature extraction and selection. The dying ReLU problem
is mitigated by utilizing the Swish ReLU activation function, and the
Squeeze-andExcitation blocks improve information propagation and cross-channel
interaction. Upon evaluation, our model achieved a high F1-score of 99.76% and
an accuracy of 99.74%, surpassing the performance of existing models. These
outcomes demonstrate the potential of state-of-the-art DL techniques in
agriculture, contributing to the advancement of more efficient and reliable
disease detection systems.

æè¦ï¼å¨æ°´ç¨»çé·åæï¼è¾²æ°å¨è¾¨è­ç¨»èç¾çæé¢è¨åç¨®ææ°ï¼éæ¯é æç¢éä¸ä½³çä¸»è¦åå ãå æ­¤ï¼å¨è¾²æ¥­ä¸­åæ©æºç¢ºå°è¾¨è­ç¾çå°æ¼é¿åä½ç©æå¤±åæ¹åèä½è³ééè¦ãå¨æ¬ç ç©¶ä¸­ï¼æåæåºäºä¸ç¨®æ°ç©çæ··åæ·±åº¦å­¸ç¿ (DL) åé¡å¨ï¼å¶è¨­è¨æ¹å¼çºæ´å Squeeze-and-Excitation ç¶²è·¯æ¶æ§ï¼ä¸¦æ­éééæ³¨æåæ©å¶å Swish ReLU åç¨å½æ¸ãæåæåºçæ¨¡åä¸­çééæ³¨æåæ©å¶æå¨ç¹å¾µèååé¸ææéæ¾åºåé¡æéæéè¦çç¹å¾µééãééä½¿ç¨ Swish ReLU åç¨å½æ¸ï¼å¯ä»¥æ¸è¼ ReLU åé¡ï¼è Squeeze-and-Excitation åå¡åå¯ä»¥æ¹åè³è¨å³éåè·¨ééäºåãå¨è©ä¼°æï¼æåçæ¨¡åéå°äº 99.76% çé« F1 åæ¸å 99.74% çæºç¢ºçï¼è¶è¶äºç¾ææ¨¡åçæè½ãéäºçµæè­æäºæåé²ç DL æè¡å¨è¾²æ¥­ä¸­çæ½åï¼æå©æ¼æ¨åæ´ææçä¸å¯é çç¾çåµæ¸¬ç³»çµ±ã

##### **Universal Sound Separation with Self-Supervised Audio Masked Autoencoder**
2407.11745v1 by Junqi Zhao, Xubo Liu, Jinzheng Zhao, Yi Yuan, Qiuqiang Kong, Mark D. Plumbley, Wenwu Wang

Universal sound separation (USS) is a task of separating mixtures of
arbitrary sound sources. Typically, universal separation models are trained
from scratch in a supervised manner, using labeled data. Self-supervised
learning (SSL) is an emerging deep learning approach that leverages unlabeled
data to obtain task-agnostic representations, which can benefit many downstream
tasks. In this paper, we propose integrating a self-supervised pre-trained
model, namely the audio masked autoencoder (A-MAE), into a universal sound
separation system to enhance its separation performance. We employ two
strategies to utilize SSL embeddings: freezing or updating the parameters of
A-MAE during fine-tuning. The SSL embeddings are concatenated with the
short-time Fourier transform (STFT) to serve as input features for the
separation model. We evaluate our methods on the AudioSet dataset, and the
experimental results indicate that the proposed methods successfully enhance
the separation performance of a state-of-the-art ResUNet-based USS model.

æè¦ï¼éç¨è²é³åé¢ (USS) æ¯ä¸é å°ä»»æé³æºçæ··åç©åéçä»»åãéå¸¸ï¼éç¨åé¢æ¨¡åæä½¿ç¨æ¨ç±¤è³æä»¥ç£ç£çæ¹å¼å¾é ­éå§è¨ç·´ãèªç£ç£å­¸ç¿ (SSL) æ¯ä¸ç¨®æ°èçæ·±åº¦å­¸ç¿æ¹æ³ï¼å®å©ç¨æªæ¨ç±¤çè³æä¾åå¾èä»»åç¡éçè¡¨ç¤ºï¼éå¯ä»¥è®è¨±å¤ä¸æ¸¸ä»»ååçãå¨æ¬æä¸­ï¼æåå»ºè­°å°èªç£ç£é è¨ç·´æ¨¡åï¼å³é³è¨é®ç½©èªåç·¨ç¢¼å¨ (A-MAE)ï¼æ´åå°éç¨è²é³åé¢ç³»çµ±ä¸­ï¼ä»¥å¢å¼·å¶åé¢æè½ãæåæ¡ç¨å©ç¨®ç­ç¥ä¾å©ç¨ SSL åµå¥ï¼å¨å¾®èª¿éç¨ä¸­åçµææ´æ° A-MAE çåæ¸ãSSL åµå¥èç­æè·åç«èè½æ (STFT) é£æ¥ï¼ä½çºåé¢æ¨¡åçè¼¸å¥ç¹å¾µãæåå¨ AudioSet è³æéä¸è©ä¼°æåçæ¨¡åï¼å¯¦é©çµæè¡¨æï¼ææåºçæ¹æ³æåå°å¢å¼·äºæåé²çåºæ¼ ResUNet ç USS æ¨¡åçåé¢æè½ã

##### **How Are LLMs Mitigating Stereotyping Harms? Learning from Search Engine Studies**
2407.11733v1 by Alina Leidinger, Richard Rogers

With the widespread availability of LLMs since the release of ChatGPT and
increased public scrutiny, commercial model development appears to have focused
their efforts on 'safety' training concerning legal liabilities at the expense
of social impact evaluation. This mimics a similar trend which we could observe
for search engine autocompletion some years prior. We draw on scholarship from
NLP and search engine auditing and present a novel evaluation task in the style
of autocompletion prompts to assess stereotyping in LLMs. We assess LLMs by
using four metrics, namely refusal rates, toxicity, sentiment and regard, with
and without safety system prompts. Our findings indicate an improvement to
stereotyping outputs with the system prompt, but overall a lack of attention by
LLMs under study to certain harms classified as toxic, particularly for prompts
about peoples/ethnicities and sexual orientation. Mentions of intersectional
identities trigger a disproportionate amount of stereotyping. Finally, we
discuss the implications of these findings about stereotyping harms in light of
the coming intermingling of LLMs and search and the choice of stereotyping
mitigation policy to adopt. We address model builders, academics, NLP
practitioners and policy makers, calling for accountability and awareness
concerning stereotyping harms, be it for training data curation, leader board
design and usage, or social impact measurement.

æè¦ï¼é¨è ChatGPT ç¼å¸å¾ LLM å»£æ³å¯ç¨ä»¥åå¬ç¾çå¯©æ¥å¢å ï¼åæ¥­æ¨¡åéç¼ä¼¼ä¹å°å¶éé»æ¾å¨ãå®å¨ãè¨ç·´ä¸ï¼ä»¥æå°æ³å¾è²¬ä»»ï¼èç§ç²äºç¤¾æå½±é¿è©ä¼°ãéæ¨¡ä»¿äºæåå¹¾å¹´åå¨æå°å¼æèªåå®æä¸­è§å¯å°çé¡ä¼¼è¶¨å¢ãæåå©ç¨ NLP åæå°å¼æç¨½æ ¸çå­¸è¡ç ç©¶ï¼ä¸¦æåºä»¥èªåå®ææç¤ºçé¢¨æ ¼é²è¡çæ°ç©è©ä¼°ä»»åï¼ä»¥è©ä¼° LLM ä¸­çå»æ¿å°è±¡ãæåä½¿ç¨ååææ¨ï¼æçµçãæ¯æ§ãæç·åéè¦ï¼è©ä¼° LLMï¼ä¸¦ä½¿ç¨åä¸ä½¿ç¨å®å¨ç³»çµ±æç¤ºãæåçç ç©¶çµæè¡¨æï¼ç³»çµ±æç¤ºæ¹é²äºå»æ¿å°è±¡è¼¸åºï¼ä½ç¸½é«èè¨ï¼ç ç©¶ä¸­ç LLM å°æ¼æäºè¢«æ­¸é¡çºææ¯çå·å®³ç¼ºä¹éæ³¨ï¼ç¹å¥æ¯éæ¼äºº/ç¨®æåæ§ååçæç¤ºãäº¤åèº«åçæåæå¼ç¼ä¸ææ¯ä¾çå»æ¿å°è±¡ãæå¾ï¼æåæ ¹æ LLM åæå°å³å°äº¤ç¹ä»¥åé¸æè¦æ¡ç¨çå»æ¿å°è±¡ç·©è§£æ¿ç­ï¼è¨è«éäºéæ¼å»æ¿å°è±¡å·å®³çç¼ç¾çå½±é¿ãæåå¼ç±²æ¨¡åå»ºæ§èãå­¸èãNLP å¾æ¥­èåæ¿ç­å¶å®èï¼å°å»æ¿å°è±¡å·å®³è² è²¬ä¸¦æé«èªè­ï¼ç¡è«æ¯éå°è¨ç·´è³æç­å±ãæè¡æ¦è¨­è¨åä½¿ç¨ï¼éæ¯ç¤¾æå½±é¿è¡¡éã

##### **NITRO-D: Native Integer-only Training of Deep Convolutional Neural Networks**
2407.11698v1 by Alberto Pirillo, Luca Colombo, Manuel Roveri

Quantization has become increasingly pivotal in addressing the steadily
increasing computational and memory requirements of Deep Neural Networks
(DNNs). By reducing the number of bits used to represent weights and
activations (typically from 32-bit floating-point to 16-bit or 8-bit integers),
quantization reduces the memory footprint, energy consumption, and execution
time of DNN models. However, traditional quantization methods typically focus
on the inference of DNNs, while the training process still relies on
floating-point operations. To date, only one work in the literature has
addressed integer-only training for Multi-Layer Perceptron (MLP) architectures.
This work introduces NITRO-D, a new framework for training arbitrarily deep
integer-only Convolutional Neural Networks (CNNs) that operate entirely< in the
integer-only domain for both training and inference. NITRO-D is the first
framework in the literature enabling the training of integer-only CNNs without
the need to introduce a quantization scheme. Specifically, NITRO-D introduces a
novel architecture integrating multiple integer local-loss blocks, which
include the proposed NITRO Scaling Layer and the NITRO-ReLU activation
function. Additionally, it introduces a novel integer-only learning algorithm
derived from Local Error Signals (LES), utilizing IntegerSGD, an optimizer
specifically designed to operate in an integer-only context. NITRO-D is
implemented in an open-source Python library. Extensive experimental
evaluations demonstrate its effectiveness across several state-of-the-art image
recognition datasets. Results show significant performance improvements from
2.47% to 5.96% for integer-only MLP architectures over the state-of-the-art
solution, and the capability of training integer-only CNN architectures with
minimal accuracy degradation from -0.15% to -4.22% compared to floating-point
LES.

æè¦ï¼<paragraph>éåå¨è§£å³æ·±åº¦ç¥ç»ç½ç» (DNN) ä¸æ­å¢å çè®¡ç®åå­å¨éæ±æ¹é¢åå¾æåå³é®ãéè¿åå°ç¨äºè¡¨ç¤ºæéåæ¿æ´»çä½æ°ï¼éå¸¸ä» 32 ä½æµ®ç¹æ°åå°å° 16 ä½æ 8 ä½æ´æ°ï¼ï¼éåå¯ä»¥åå° DNN æ¨¡åçå­å¨ç©ºé´ãè½èåæ§è¡æ¶é´ãä½æ¯ï¼ä¼ ç»çéåæ¹æ³éå¸¸ä¸æ³¨äº DNN çæ¨çï¼èè®­ç»è¿ç¨ä»ç¶ä¾èµäºæµ®ç¹è¿ç®ãè¿ä»ä¸ºæ­¢ï¼æç®ä¸­åªæä¸é¡¹å·¥ä½è§£å³äºå¤å±æç¥å¨ (MLP) æ¶æçä»æ´æ°è®­ç»ãè¿é¡¹å·¥ä½ä»ç»äº NITRO-Dï¼è¿æ¯ä¸ä¸ªç¨äºè®­ç»ä»»ææ·±åº¦ä»æ´æ°å·ç§¯ç¥ç»ç½ç» (CNN) çæ°æ¡æ¶ï¼è¯¥æ¡æ¶å¨è®­ç»åæ¨çä¸­å®å¨å¨ä»æ´æ°åä¸­è¿è¡ãNITRO-D æ¯æç®ä¸­ç¬¬ä¸ä¸ªè½å¤å¨ä¸å¼å¥éåæ¹æ¡çæåµä¸è®­ç»ä»æ´æ° CNN çæ¡æ¶ãå·ä½æ¥è¯´ï¼NITRO-D å¼å¥äºä¸ç§æ°é¢çæ¶æï¼éæäºå¤ä¸ªæ´æ°å±é¨æå¤±åï¼å¶ä¸­åæ¬æåºç NITRO ç¼©æ¾å±å NITRO-ReLU æ¿æ´»å½æ°ãæ­¤å¤ï¼å®è¿å¼å¥äºä¸ç§æ°é¢çä»æ´æ°å­¦ä¹ ç®æ³ï¼è¯¥ç®æ³æºèªå±é¨è¯¯å·®ä¿¡å· (LES)ï¼å¹¶å©ç¨ IntegerSGDï¼ä¸ç§ä¸é¨è®¾è®¡ä¸ºå¨ä»æ´æ°ä¸ä¸æä¸­è¿è¡çä¼åå¨ï¼ãNITRO-D å¨ä¸ä¸ªå¼æº Python åºä¸­å®ç°ãå¹¿æ³çå®éªè¯ä¼°è¯æäºå®å¨å ä¸ªæåè¿çå¾åè¯å«æ°æ®éä¸çæææ§ãç»ææ¾ç¤ºï¼ä»æ´æ° MLP æ¶æçæ§è½ä» 2.47% å° 5.96% ææ¾æé«ï¼è¶è¿äºæåè¿çè§£å³æ¹æ¡ï¼å¹¶ä¸è½å¤è®­ç»ä»æ´æ° CNN æ¶æï¼ä¸æµ®ç¹ LES ç¸æ¯ï¼ç²¾åº¦ä¸éå¹åº¦ä» -0.15% å° -4.22%ã</paragraph>

##### **CCoE: A Compact LLM with Collaboration of Experts**
2407.11686v2 by Shaomang Huang, Jianfeng Pan, Hanzhong Zheng

In the domain of Large Language Model (LLM), LLMs demonstrate significant
capabilities in natural language understanding and generation. With the growing
needs of applying LLMs on various domains, it is a research question that how
to efficiently train and build a model that has expertise in different domains
but with a low training cost. We propose CCoE architecture, a framework of
easily coupling multiple strong domain experts together to fuse into a big LLM,
provides a collective way of utilizing the different domain expert LLMs.
Besides, training a large collaborative of multiple expert LLMs requires a high
requirements on training sources. CCoE bypasses this problem through isolating
other experts and train each expert separately. The design of CCoE assembles
multiple expert LLMs through the CoE (Collaboration of Experts) layer. Each CoE
layer could have one or more expert LLMs. Expert LLMs have different number of
layers and have been well-trained for different domain tasks. Each expert is
fine-tuned to be able to achieve the comparable results with SOTA domain LLMs.
We start from 5 experts in the domain of Code, Math, Law, text-to-SQL and
Medical. The results indicate that our CCoE framework can easily and
efficiently boost nearly 10%-20% performance on original base model in
different domains but using less resources on training, as well as inference.

æè¦ï¼å¨å¤§èªè¨æ¨¡å (LLM) é åä¸­ï¼LLM å¨èªç¶èªè¨çè§£åçææ¹é¢å±ç¾åºé¡¯èçè½åãé¨èå¨ååé åæç¨ LLM çéæ±æ¥çå¢å ï¼å¦ä½ææè¨ç·´åå»ºç«ä¸åå¨ä¸åé åä¸­å·åå°æ¥­ç¥è­ï¼ä½è¨ç·´ææ¬å»å¾ä½çæ¨¡åï¼æçºä¸åç ç©¶èª²é¡ãæåæåº CCoE æ¶æ§ï¼ä¸åå°å¤åå¼·å¤§çé åå°å®¶è¼é¬çµåå¨ä¸èµ·ä»¥èåæä¸åå¤§å LLM çæ¡æ¶ï¼æä¾ä¸ç¨®å±åå©ç¨ä¸åé åå°å®¶ LLM çæ¹å¼ãæ­¤å¤ï¼è¨ç·´å¤åå°å®¶ LLM çå¤§ååä½éè¦å°è¨ç·´ä¾æºæå¾é«çè¦æ±ãCCoE éééé¢å¶ä»å°å®¶ä¸¦åå¥è¨ç·´æ¯åå°å®¶ä¾ç¹ééååé¡ãCCoE çè¨­è¨éé CoEï¼å°å®¶åä½ï¼å±¤çµåå¤åå°å®¶ LLMãæ¯å CoE å±¤å¯ä»¥æä¸åæå¤åå°å®¶ LLMãå°å®¶ LLM å·æä¸åçå±¤æ¸ï¼ä¸¦ä¸å·²ç¶éå°ä¸åçé åä»»åé²è¡äºå¾å¥½çè¨ç·´ãæ¯åå°å®¶é½ç¶éå¾®èª¿ï¼è½å¤ éå°è SOTA é å LLM ç¸ç¶ççµæãæåå¾ç¨å¼ç¢¼ãæ¸å­¸ãæ³å¾ãæå­è½ SQL åé«å­¸é åç 5 ä½å°å®¶éå§ãçµæè¡¨æï¼æåç CCoE æ¡æ¶å¯ä»¥è¼é¬ãææå°æåä¸åé åä¸­åå§åºç¤æ¨¡åè¿ 10%-20% çæè½ï¼ä½è¨ç·´åæ¨çä½¿ç¨çè³æºæ´å°ã

##### **MINI-LLM: Memory-Efficient Structured Pruning for Large Language Models**
2407.11681v1 by Hongrong Cheng, Miao Zhang, Javen Qinfeng Shi

As Large Language Models (LLMs) grow dramatically in size, there is an
increasing trend in compressing and speeding up these models. Previous studies
have highlighted the usefulness of gradients for importance scoring in neural
network compressing, especially in pruning medium-size networks. However, the
substantial memory requirements involved in calculating gradients with
backpropagation impede the utilization of gradients in guiding LLM pruning. As
a result, most pruning strategies for LLMs rely on gradient-free criteria, such
as weight magnitudes or a mix of magnitudes and activations. In this paper, we
devise a hybrid pruning criterion, which appropriately integrates magnitude,
activation, and gradient to capitalize on feature map sensitivity for pruning
LLMs. To overcome memory requirement barriers, we estimate gradients using only
forward passes. Based on this, we propose a Memory-effIcieNt structured prunIng
procedure for LLMs (MINI-LLM) to remove no-critical channels and
multi-attention heads. Experimental results demonstrate the superior
performance of MINI-LLM over existing gradient-free methods on three LLMs:
LLaMA, BLOOM, and OPT across various downstream tasks (classification,
multiple-choice, and generation), while MINI-LLM maintains a GPU memory
footprint akin to gradient-free methods.

æè¦ï¼éçå¤§è¯­è¨æ¨¡å (LLM) è§æ¨¡çæ¥å§å¢é¿ï¼åç¼©åå éè¿äºæ¨¡åçè¶å¿ä¹å¨ä¸æ­å¢å ãååçç ç©¶å¼ºè°äºæ¢¯åº¦å¨ç¥ç»ç½ç»åç¼©ä¸­ç¨äºéè¦æ§è¯åçå®ç¨æ§ï¼å°¤å¶æ¯å¨ä¿®åªä¸­ç­è§æ¨¡çç½ç»ä¸­ãç¶èï¼ä½¿ç¨ååä¼ æ­è®¡ç®æ¢¯åº¦ææ¶åçå¤§éåå­éæ±é»ç¢äºæ¢¯åº¦å¨æå¯¼ LLM ä¿®åªä¸­çå©ç¨ãå æ­¤ï¼å¤§å¤æ° LLM çä¿®åªç­ç¥ä¾èµäºæ æ¢¯åº¦çæ åï¼ä¾å¦æéå¤§å°æå¤§å°åæ¿æ´»çæ··åãå¨æ¬æä¸­ï¼æä»¬è®¾è®¡äºä¸ä¸ªæ··åä¿®åªæ åï¼è¯¥æ åéå½å°éæäºå¤§å°ãæ¿æ´»åæ¢¯åº¦ï¼ä»¥å©ç¨ç¹å¾å¾æææ§æ¥ä¿®åª LLMãä¸ºäºåæåå­éæ±éç¢ï¼æä»¬ä»ä½¿ç¨ååä¼ éæ¥ä¼°è®¡æ¢¯åº¦ãåºäºæ­¤ï¼æä»¬æåºäºç¨äº LLM çåå­é«æç»æåä¿®åªç¨åº (MINI-LLM)ï¼ä»¥å é¤éå³é®ééåå¤å¤´æ³¨æåãå®éªç»æè¡¨æï¼å¨ä¸ä¸ª LLMï¼LLaMAãBLOOM å OPTï¼ä¸ï¼MINI-LLM å¨åç§ä¸æ¸¸ä»»å¡ï¼åç±»ãå¤é¡¹éæ©åçæï¼ä¸ä¼äºç°æçæ æ¢¯åº¦æ¹æ³ï¼è MINI-LLM ä¿æäºä¸æ æ¢¯åº¦æ¹æ³ç±»ä¼¼ç GPU åå­å ç¨ç©ºé´ã

##### **SKADA-Bench: Benchmarking Unsupervised Domain Adaptation Methods with Realistic Validation**
2407.11676v1 by Yanis Lalou, ThÃ©o Gnassounou, Antoine Collas, Antoine de Mathelin, Oleksii Kachaiev, Ambroise Odonnat, Alexandre Gramfort, Thomas Moreau, RÃ©mi Flamary

Unsupervised Domain Adaptation (DA) consists of adapting a model trained on a
labeled source domain to perform well on an unlabeled target domain with some
data distribution shift. While many methods have been proposed in the
literature, fair and realistic evaluation remains an open question,
particularly due to methodological difficulties in selecting hyperparameters in
the unsupervised setting. With SKADA-Bench, we propose a framework to evaluate
DA methods and present a fair evaluation of existing shallow algorithms,
including reweighting, mapping, and subspace alignment. Realistic
hyperparameter selection is performed with nested cross-validation and various
unsupervised model selection scores, on both simulated datasets with controlled
shifts and real-world datasets across diverse modalities, such as images, text,
biomedical, and tabular data with specific feature extraction. Our benchmark
highlights the importance of realistic validation and provides practical
guidance for real-life applications, with key insights into the choice and
impact of model selection approaches. SKADA-Bench is open-source, reproducible,
and can be easily extended with novel DA methods, datasets, and model selection
criteria without requiring re-evaluating competitors. SKADA-Bench is available
on GitHub at https://github.com/scikit-adaptation/skada-bench.

æè¦ï¼ç¡ç£ç£åé©æ (DA) æ¯å°å¨æ¨ç±¤ä¾æºåä¸è¨ç·´çæ¨¡åèª¿æ´çºå¨å·ææäºè³æåä½è½ç§»çæªæ¨ç±¤ç®æ¨åä¸è¡¨ç¾è¯å¥½ãéç¶æç»ä¸­å·²æåºè¨±å¤æ¹æ³ï¼ä½å¬å¹³ä¸ç¾å¯¦çè©ä¼°ä»ç¶æ¯ä¸åå¬éçåé¡ï¼ç¹å¥æ¯å çºå¨ç¡ç£ç£ç°å¢ä¸­é¸æè¶åæ¸çæ¹æ³è«å°é£ãæäº SKADA-Benchï¼æåæåºäºä¸åè©ä¼° DA æ¹æ³çæ¶æ§ï¼ä¸¦å°ç¾æçæ·ºå±¤æ¼ç®æ³é²è¡å¬å¹³çè©ä¼°ï¼åæ¬éæ°å æ¬ãå°æåå­ç©ºéå°é½ãå¨æ¨¡æ¬è³æéï¼å·æåæ§è½ç§»ï¼åè·¨ä¸åæ¨¡å¼ï¼ä¾å¦å½±åãæå­ãçç©é«å­¸åå·æç¹å®ç¹å¾µèåçè¡¨æ ¼è³æï¼ççå¯¦ä¸çè³æéä¸ï¼ä½¿ç¨åµå¥äº¤åé©è­ååç¨®ç¡ç£ç£æ¨¡åé¸æè©åä¾å·è¡ç¾å¯¦çè¶åæ¸é¸æãæåçåºæºå¼·èª¿äºç¾å¯¦é©è­çéè¦æ§ï¼ä¸¦çºå¯¦éæç¨æä¾å¯¦ç¨çæå°ï¼æ·±å¥äºè§£æ¨¡åé¸ææ¹æ³çé¸æåå½±é¿ãSKADA-Bench æ¯éæºçãå¯è¤è£½çï¼ä¸¦ä¸å¯ä»¥è¼é¬å°æ´åæ°ç DA æ¹æ³ãè³æéåæ¨¡åé¸ææ¨æºï¼èä¸éè¦éæ°è©ä¼°ç«¶ç­èãSKADA-Bench å¯å¨ GitHub ä¸ç https://github.com/scikit-adaptation/skada-bench åå¾ã

##### **ECoh: Turn-level Coherence Evaluation for Multilingual Dialogues**
2407.11660v1 by John MendonÃ§a, Isabel Trancoso, Alon Lavie

Despite being heralded as the new standard for dialogue evaluation, the
closed-source nature of GPT-4 poses challenges for the community. Motivated by
the need for lightweight, open source, and multilingual dialogue evaluators,
this paper introduces GenResCoh (Generated Responses targeting Coherence).
GenResCoh is a novel LLM generated dataset comprising over 130k negative and
positive responses and accompanying explanations seeded from XDailyDialog and
XPersona covering English, French, German, Italian, and Chinese. Leveraging
GenResCoh, we propose ECoh (Evaluation of Coherence), a family of evaluators
trained to assess response coherence across multiple languages. Experimental
results demonstrate that ECoh achieves multilingual detection capabilities
superior to the teacher model (GPT-3.5-Turbo) on GenResCoh, despite being based
on a much smaller architecture. Furthermore, the explanations provided by ECoh
closely align in terms of quality with those generated by the teacher model.

æè¦ï¼åç®¡è¢«å®£å³çºå°è©±è©ä¼°çæ°æ¨æºï¼ä½ GPT-4 çå°éåå§ç¢¼ç¹æ§å°ç¤¾ç¾¤ä¾èªªæ¯åææ°ãåºæ¼å°è¼éåãéæ¾åå§ç¢¼åå¤èªè¨å°è©±è©ä¼°å¨çéæ±ï¼æ¬æä»ç´¹äº GenResCohï¼éå°ç¸å¹²æ§ççæåæï¼ãGenResCoh æ¯ä¸åæ°ç©ç LLM çæè³æéï¼åå«è¶é 13 è¬åè² é¢åæ­£é¢åæï¼ä»¥åä¾èª XDailyDialog å XPersona çç¸éèªªæï¼æ¶µèè±èªãæ³èªãå¾·èªãç¾©å¤§å©èªåä¸­æãå©ç¨ GenResCohï¼æåæåºäº ECohï¼ç¸å¹²æ§è©ä¼°ï¼ï¼ä¸åè©ä¼°å¨å®¶æï¼ç¶éè¨ç·´å¯ä»¥è©ä¼°å¤ç¨®èªè¨çåæç¸å¹²æ§ãå¯¦é©çµæè¡¨æï¼åç®¡åºæ¼ä¸åå°å¾å¤çæ¶æ§ï¼ä½ ECoh å¨ GenResCoh ä¸éå°äºå¤èªè¨åµæ¸¬è½åï¼åªæ¼æå¸«æ¨¡å (GPT-3.5-Turbo)ãæ­¤å¤ï¼ECoh æä¾çèªªæå¨åè³ªä¸èæå¸«æ¨¡åçæçèªªæéå¸¸æ¥è¿ã

##### **R-SFLLM: Jamming Resilient Framework for Split Federated Learning with Large Language Models**
2407.11654v1 by Aladin Djuhera, Vlad C. Andrei, Xinyang Li, Ullrich J. MÃ¶nich, Holger Boche, Walid Saad

Split federated learning (SFL) is a compute-efficient paradigm in distributed
machine learning (ML), where components of large ML models are outsourced to
remote servers. A significant challenge in SFL, particularly when deployed over
wireless channels, is the susceptibility of transmitted model parameters to
adversarial jamming that could jeopardize the learning process. This is
particularly pronounced for word embedding parameters in large language models
(LLMs), which are crucial for language understanding. In this paper, rigorous
insights are provided into the influence of jamming LLM word embeddings in SFL
by deriving an expression for the ML training loss divergence and showing that
it is upper-bounded by the mean squared error (MSE). Based on this analysis, a
physical layer framework is developed for resilient SFL with LLMs (R-SFLLM)
over wireless networks. R-SFLLM leverages wireless sensing data to gather
information on the jamming directions-of-arrival (DoAs) for the purpose of
devising a novel, sensing-assisted anti-jamming strategy while jointly
optimizing beamforming, user scheduling, and resource allocation. Extensive
experiments using BERT and RoBERTa models demonstrate R-SFLLM's effectiveness,
achieving close-to-baseline performance across various natural language
processing (NLP) tasks and datasets. The proposed methodology further
introduces an adversarial training component, where controlled noise exposure
significantly enhances the LLM's resilience to perturbed parameters during
training. The results show that more noise-sensitive models, such as RoBERTa,
benefit from this feature, especially when resource allocation is unfair. It is
also shown that worst-case jamming in particular translates into worst-case
model outcomes, thereby necessitating the need for jamming-resilient SFL
protocols.

æè¦ï¼åå²èé¦å­¸ç¿ (SFL) æ¯ä¸ç¨®å¨åæ£å¼æ©å¨å­¸ç¿ (ML) ä¸­è¨ç®æçé«çç¯ä¾ï¼å¶ä¸­å¤§å ML æ¨¡åççµææå¤åå°é ç«¯ä¼ºæå¨ãSFL ä¸­çä¸é éå¤§ææ°ï¼ç¹å¥æ¯å¨ç¡ç·é »éä¸é¨ç½²æï¼å¨æ¼å³è¼¸çæ¨¡ååæ¸å®¹æåå°å°ææ§å¹²æ¾ï¼å¯è½æå±åå­¸ç¿éç¨ãéå°æ¼å¤§åèªè¨æ¨¡å (LLM) ä¸­çè©åµå¥åæ¸ä¾èªªå°¤å¶æé¡¯ï¼éäºåæ¸å°æ¼èªè¨çè§£è³ééè¦ãå¨æ¬æä¸­ï¼ééæ¨å° ML è¨ç·´æå¤±å·®ç°çè¡¨éå¼ï¼ä¸¦è­æå®ä»¥ä¸éåæ¹èª¤å·® (MSE) çºçï¼æ·±å¥æ¢è¨äºå¹²æ¾ SFL ä¸­ç LLM è©åµå¥çå½±é¿ãæ ¹ææ­¤åæï¼éç¼äºä¸åç¨æ¼ç¡ç·ç¶²è·¯ä¸çå½æ§ SFL è LLM (R-SFLLM) çç©çå±¤æ¶æ§ãR-SFLLM å©ç¨ç¡ç·ææ¸¬è³æä¾æ¶éå¹²æ¾å°ä¾æ¹å (DoA) çè³è¨ï¼ç®çæ¯è¨­è¨ä¸ç¨®æ°ç©çææ¸¬è¼å©æå¹²æ¾ç­ç¥ï¼åææä½³åæ³¢ææå½¢ãä½¿ç¨èæç¨åè³æºåéãä½¿ç¨ BERT å RoBERTa æ¨¡åé²è¡çå»£æ³å¯¦é©è­æäº R-SFLLM çæææ§ï¼å¨åç¨®èªç¶èªè¨èç (NLP) ä»»ååè³æéä¸å¯¦ç¾äºæ¥è¿åºç·çæè½ãææåºçæ¹æ³é²ä¸æ­¥å¼å¥äºå°æè¨ç·´çµæï¼å¶ä¸­åæ§çéè¨æ´é²æå¨è¨ç·´æéé¡¯èå¢å¼· LLM å°æ¾ååæ¸çå½æ§ãçµæè¡¨æï¼å°éè¨æ´ææçæ¨¡åï¼ä¾å¦ RoBERTaï¼åçæ¼æ­¤åè½ï¼ç¹å¥æ¯å¨è³æºåéä¸å¬å¹³çææ³ä¸ãå®ä¹è¡¨æï¼æå£ææ³ä¸çå¹²æ¾ç¹å¥æè½åçºæå£ææ³ä¸çæ¨¡åçµæï¼å æ­¤éè¦é²å¹²æ¾ SFL åå®ã

##### **CCVA-FL: Cross-Client Variations Adaptive Federated Learning for Medical Imaging**
2407.11652v1 by Sunny Gupta, Amit Sethi

Federated Learning (FL) offers a privacy-preserving approach to train models
on decentralized data. Its potential in healthcare is significant, but
challenges arise due to cross-client variations in medical image data,
exacerbated by limited annotations. This paper introduces Cross-Client
Variations Adaptive Federated Learning (CCVA-FL) to address these issues.
CCVA-FL aims to minimize cross-client variations by transforming images into a
common feature space. It involves expert annotation of a subset of images from
each client, followed by the selection of a client with the least data
complexity as the target. Synthetic medical images are then generated using
Scalable Diffusion Models with Transformers (DiT) based on the target client's
annotated images. These synthetic images, capturing diversity and representing
the original data, are shared with other clients. Each client then translates
its local images into the target image space using image-to-image translation.
The translated images are subsequently used in a federated learning setting to
develop a server model. Our results demonstrate that CCVA-FL outperforms
Vanilla Federated Averaging by effectively addressing data distribution
differences across clients without compromising privacy.

æè¦ï¼èé¦å­¦ä¹  (FL) æä¾äºä¸ç§å¨åæ£å¼æ°æ®ä¸è®­ç»æ¨¡åçéç§ä¿æ¤æ¹æ³ãå®å¨å»çä¿å¥ä¸­çæ½åå¾å¤§ï¼ä½ç±äºå»çå¾åæ°æ®ä¸­å­å¨è·¨å®¢æ·ç«¯å·®å¼ï¼å æ­¤å¸¦æ¥äºææï¼èæéçæ³¨éå å§äºè¿ä¸é®é¢ãæ¬æä»ç»äºè·¨å®¢æ·ç«¯å·®å¼èªéåºèé¦å­¦ä¹  (CCVA-FL) æ¥è§£å³è¿äºé®é¢ãCCVA-FL æ¨å¨éè¿å°å¾åè½¬æ¢ä¸ºå¬å±ç¹å¾ç©ºé´æ¥æå°åè·¨å®¢æ·ç«¯å·®å¼ãå®æ¶åä»æ¯ä¸ªå®¢æ·ç«¯æ³¨éå¾åå­éçä¸å®¶æ³¨éï¼ç¶åéæ©æ°æ®å¤ææ§æä½çå®¢æ·ç«¯ä½ä¸ºç®æ ãç¶åä½¿ç¨åºäºç®æ å®¢æ·ç«¯æ³¨éå¾åçå¯æ©å±æ©æ£æ¨¡åä¸ Transformer (DiT) çæåæå»å­¦å¾åãè¿äºåæå¾åææäºå¤æ ·æ§å¹¶ä»£è¡¨äºåå§æ°æ®ï¼ä¸å¶ä»å®¢æ·ç«¯å±äº«ãç¶åï¼æ¯ä¸ªå®¢æ·ç«¯ä½¿ç¨å¾åå°å¾åç¿»è¯å°å¶æ¬å°å¾åè½¬æ¢ä¸ºç®æ å¾åç©ºé´ãç¿»è¯åçå¾åéåå¨èé¦å­¦ä¹ è®¾ç½®ä¸­ç¨äºå¼åæå¡å¨æ¨¡åãæä»¬çç»æè¡¨æï¼CCVA-FL éè¿ææè§£å³è·¨å®¢æ·ç«¯çæ°æ®åå¸å·®å¼å¨ä¸æå®³éç§çæåµä¸ä¼äºé¦èèé¦å¹³åã

##### **A Comprehensive Evaluation of Large Language Models on Temporal Event Forecasting**
2407.11638v1 by He Chang, Chenchen Ye, Zhulin Tao, Jie Wu, Zhengmao Yang, Yunshan Ma, Xianglin Huang, Tat-Seng Chua

Recently, Large Language Models (LLMs) have demonstrated great potential in
various data mining tasks, such as knowledge question answering, mathematical
reasoning, and commonsense reasoning. However, the reasoning capability of LLMs
on temporal event forecasting has been under-explored. To systematically
investigate their abilities in temporal event forecasting, we conduct a
comprehensive evaluation of LLM-based methods for temporal event forecasting.
Due to the lack of a high-quality dataset that involves both graph and textual
data, we first construct a benchmark dataset, named MidEast-TE-mini. Based on
this dataset, we design a series of baseline methods, characterized by various
input formats and retrieval augmented generation(RAG) modules. From extensive
experiments, we find that directly integrating raw texts into the input of LLMs
does not enhance zero-shot extrapolation performance. In contrast,
incorporating raw texts in specific complex events and fine-tuning LLMs
significantly improves performance. Moreover, enhanced with retrieval modules,
LLM can effectively capture temporal relational patterns hidden in historical
events. Meanwhile, issues such as popularity bias and the long-tail problem
still persist in LLMs, particularly in the RAG-based method. These findings not
only deepen our understanding of LLM-based event forecasting methods but also
highlight several promising research directions.We consider that this
comprehensive evaluation, along with the identified research opportunities,
will significantly contribute to future research on temporal event forecasting
through LLMs.

æè¦ï¼è¿æï¼å¤§åè¯­è¨æ¨¡å (LLM) å¨åç§èµææ¢åä»»å¡ä¸­å±ç°åºæå¤§çæ½åï¼ä¾å¦ç¥è¯é®ç­ãæ°å­¦æ¨çåå¸¸è¯æ¨çãç¶èï¼LLM å¨æ¶é´äºä»¶é¢æµæ¹é¢çæ¨çè½åå°æªè¢«ååæ¢ç´¢ãä¸ºäºç³»ç»æ§å°è°æ¥å¶å¨æ¶é´äºä»¶é¢æµæ¹é¢çè½åï¼æä»¬å¯¹åºäº LLM çæ¶é´äºä»¶é¢æµæ¹æ³è¿è¡äºå¨é¢çè¯ä¼°ãç±äºç¼ºä¹åæ¶åå«å¾è¡¨åææ¬èµæçé«åè´¨æ°æ®éï¼æä»¬é¦åæå»ºäºä¸ä¸ªåä¸º MidEast-TE-mini çåºåæ°æ®éãåºäºæ­¤æ°æ®éï¼æä»¬è®¾è®¡äºä¸ç³»ååºçº¿æ¹æ³ï¼å¶ç¹ç¹æ¯åç§è¾å¥æ ¼å¼åæ£ç´¢å¢å¼ºçæ (RAG) æ¨¡åãä»å¹¿æ³çå®éªä¸­ï¼æä»¬åç°ç´æ¥å°åå§ææ¬æ´åå° LLM çè¾å¥ä¸­å¹¶ä¸ä¼å¢å¼ºé¶æ¬¡å­¦ä¹ å¤æ¨æ§è½ãç¸æ¯ä¹ä¸ï¼å¨ç¹å®å¤æäºä»¶ä¸­çº³å¥åå§ææ¬å¹¶å¾®è° LLM ä¼æ¾èæé«æ§è½ãæ­¤å¤ï¼éè¿æ£ç´¢æ¨¡åçå¢å¼ºï¼LLM å¯ä»¥ææå°ææéèå¨åå²äºä»¶ä¸­çæ¶é´å³ç³»æ¨¡å¼ãåæ¶ï¼è¯¸å¦æµè¡åº¦åå·®åé¿å°¾é®é¢ç­é®é¢ä»ç¶å­å¨äº LLM ä¸­ï¼å°¤å¶æ¯å¨åºäº RAG çæ¹æ³ä¸­ãè¿äºåç°ä¸ä»å æ·±äºæä»¬å¯¹åºäº LLM çäºä»¶é¢æµæ¹æ³ççè§£ï¼è¿çªåºäºå ä¸ªæåæ¯çç ç©¶æ¹åãæä»¬è®¤ä¸ºï¼è¿é¡¹å¨é¢çè¯ä¼°ï¼è¿åå·²ç¡®å®çç ç©¶æºä¼ï¼å°æå¤§å°ä¿è¿éè¿ LLM è¿è¡æ¶é´äºä»¶é¢æµçæªæ¥ç ç©¶ã

##### **Rethinking Fair Graph Neural Networks from Re-balancing**
2407.11624v1 by Zhixun Li, Yushun Dong, Qiang Liu, Jeffrey Xu Yu

Driven by the powerful representation ability of Graph Neural Networks
(GNNs), plentiful GNN models have been widely deployed in many real-world
applications. Nevertheless, due to distribution disparities between different
demographic groups, fairness in high-stake decision-making systems is receiving
increasing attention. Although lots of recent works devoted to improving the
fairness of GNNs and achieved considerable success, they all require
significant architectural changes or additional loss functions requiring more
hyper-parameter tuning. Surprisingly, we find that simple re-balancing methods
can easily match or surpass existing fair GNN methods. We claim that the
imbalance across different demographic groups is a significant source of
unfairness, resulting in imbalanced contributions from each group to the
parameters updating. However, these simple re-balancing methods have their own
shortcomings during training. In this paper, we propose FairGB, Fair Graph
Neural Network via re-Balancing, which mitigates the unfairness of GNNs by
group balancing. Technically, FairGB consists of two modules: counterfactual
node mixup and contribution alignment loss. Firstly, we select counterfactual
pairs across inter-domain and inter-class, and interpolate the ego-networks to
generate new samples. Guided by analysis, we can reveal the debiasing mechanism
of our model by the causal view and prove that our strategy can make sensitive
attributes statistically independent from target labels. Secondly, we reweigh
the contribution of each group according to gradients. By combining these two
modules, they can mutually promote each other. Experimental results on
benchmark datasets show that our method can achieve state-of-the-art results
concerning both utility and fairness metrics. Code is available at
https://github.com/ZhixunLEE/FairGB.

æè¦ï¼<paragraph>å¨å¾ç¥ç»ç½ç» (GNN) å¼ºå¤§çè¡¨ç¤ºè½åçæ¨å¨ä¸ï¼å¤§éç GNN æ¨¡åå·²å¹¿æ³é¨ç½²å¨è®¸å¤å®éåºç¨ä¸­ãç¶èï¼ç±äºä¸åäººå£ç¾¤ä½ä¹é´çåå¸å·®å¼ï¼é«é£é©å³ç­ç³»ç»ä¸­çå¬å¹³æ§æ­£åå°è¶æ¥è¶å¤çå³æ³¨ãå°½ç®¡æè¿æè®¸å¤è´åäºæé« GNN å¬å¹³æ§çå·¥ä½å¹¶åå¾äºç¸å½å¤§çæåï¼ä½å®ä»¬é½éè¦å¤§éçæ¶ææ´æ¹æéå æå¤±å½æ°ï¼éè¦æ´å¤è¶åæ°è°æ´ãä»¤äººæè®¶çæ¯ï¼æä»¬åç°ç®åçéæ°å¹³è¡¡æ¹æ³å¯ä»¥è½»æ¾å¹éæè¶è¶ç°æçå¬å¹³ GNN æ¹æ³ãæä»¬å£°ç§°ï¼ä¸åäººå£ç¾¤ä½ä¹é´çä¸å¹³è¡¡æ¯é æä¸å¬å¹³çä¸ä¸ªéè¦æ ¹æºï¼å¯¼è´æ¯ä¸ªç¾¤ä½å¯¹åæ°æ´æ°çè´¡ç®ä¸å¹³è¡¡ãç¶èï¼è¿äºç®åçéæ°å¹³è¡¡æ¹æ³å¨è®­ç»è¿ç¨ä¸­æå¶èªèº«çç¼ºç¹ãå¨æ¬æä¸­ï¼æä»¬æåºäº FairGBï¼å³éè¿éæ°å¹³è¡¡å®ç°å¬å¹³å¾ç¥ç»ç½ç»ï¼å®éè¿ç»å¹³è¡¡æ¥åè½» GNN çä¸å¬å¹³æ§ãä»ææ¯ä¸è®²ï¼FairGB ç±ä¸¤ä¸ªæ¨¡åç»æï¼åäºå®èç¹æ··ååè´¡ç®å¯¹é½æå¤±ãé¦åï¼æä»¬å¨åé´åç±»é´éæ©åäºå®å¯¹ï¼å¹¶æå¼èªæç½ç»ä»¥çææ°æ ·æ¬ãå¨åæçæå¯¼ä¸ï¼æä»¬å¯ä»¥éè¿å æè§å¾æ­ç¤ºæä»¬æ¨¡åçå»åæºå¶ï¼å¹¶è¯ææä»¬çç­ç¥å¯ä»¥ä½¿ææå±æ§å¨ç»è®¡ä¸ç¬ç«äºç®æ æ ç­¾ãå¶æ¬¡ï¼æä»¬æ ¹æ®æ¢¯åº¦éæ°æè¡¡æ¯ä¸ªç»çè´¡ç®ãéè¿ç»åè¿ä¸¤ä¸ªæ¨¡åï¼å®ä»¬å¯ä»¥ç¸äºä¿è¿ãåºåæ°æ®éä¸çå®éªç»æè¡¨æï¼æä»¬çæ¹æ³å¯ä»¥å®ç°æå³æç¨åå¬å¹³æ§ææ çæåè¿ç»æãä»£ç å¯å¨ https://github.com/ZhixunLEE/FairGB è·å¾ã</paragraph>

##### **Graph Dimension Attention Networks for Enterprise Credit Assessment**
2407.11615v1 by Shaopeng Wei, Beni Egressy, Xingyan Chen, Yu Zhao, Fuzhen Zhuang, Roger Wattenhofer, Gang Kou

Enterprise credit assessment is critical for evaluating financial risk, and
Graph Neural Networks (GNNs), with their advanced capability to model
inter-entity relationships, are a natural tool to get a deeper understanding of
these financial networks. However, existing GNN-based methodologies
predominantly emphasize entity-level attention mechanisms for contagion risk
aggregation, often overlooking the heterogeneous importance of different
feature dimensions, thus falling short in adequately modeling credit risk
levels. To address this issue, we propose a novel architecture named Graph
Dimension Attention Network (GDAN), which incorporates a dimension-level
attention mechanism to capture fine-grained risk-related characteristics.
Furthermore, we explore the interpretability of the GNN-based method in
financial scenarios and propose a simple but effective data-centric explainer
for GDAN, called GDAN-DistShift. DistShift provides edge-level interpretability
by quantifying distribution shifts during the message-passing process.
Moreover, we collected a real-world, multi-source Enterprise Credit Assessment
Dataset (ECAD) and have made it accessible to the research community since
high-quality datasets are lacking in this field. Extensive experiments
conducted on ECAD demonstrate the effectiveness of our methods. In addition, we
ran GDAN on the well-known datasets SMEsD and DBLP, also with excellent
results.

æè¦ï¼ä¼æ¥­ä¿¡ç¨è©ä¼°å°æ¼è©ä¼°è²¡åé¢¨éªè³ééè¦ï¼åå½¢ç¥ç¶ç¶²è·¯ (GNN) å·æå»ºæ¨¡å¯¦é«ééä¿çåé²è½åï¼æ¯æ·±å¥äºè§£éäºéèç¶²è·¯çèªç¶å·¥å·ãç¶èï¼ç¾æçåºæ¼ GNN çæ¹æ³ä¸»è¦å¼·èª¿å¯¦é«å±¤ç´çéæ³¨æ©å¶ï¼ç¨æ¼å³æé¢¨éªå½ç¸½ï¼å¸¸å¸¸å¿½ç¥ä¸åç¹å¾µç¶­åº¦çç°è³ªéè¦æ§ï¼å æ­¤å¨ååå»ºæ¨¡ä¿¡ç¨é¢¨éªå±¤ç´æ¹é¢ææä¸è¶³ãçºäºè§£æ±ºéååé¡ï¼æåæåºä¸ååçºåå½¢ç¶­åº¦éæ³¨ç¶²è·¯ (GDAN) çæ°æ¶æ§ï¼å®çµåäºç¶­åº¦å±¤ç´çéæ³¨æ©å¶ä¾ææç´°ç·»çé¢¨éªç¸éç¹å¾µãæ­¤å¤ï¼æåæ¢è¨äºåºæ¼ GNN çæ¹æ³å¨è²¡åæå¢ä¸­çå¯è§£éæ§ï¼ä¸¦çº GDAN æåºäºä¸åç°¡å®ä½ææçä»¥è³æçºä¸­å¿çè§£éå¨ï¼ç¨±çº GDAN-DistShiftãDistShift éééåè¨æ¯å³ééç¨ä¸­çåä½è½ç§»ï¼æä¾éç·£å±¤ç´çå¯è§£éæ§ãæ­¤å¤ï¼æåæ¶éäºä¸åçå¯¦ä¸ççå¤ä¾æºä¼æ¥­ä¿¡ç¨è©ä¼°è³æé (ECAD)ï¼ä¸¦å·²æä¾çµ¦ç ç©¶ç¤¾ç¾¤ï¼å çºéåé åç¼ºä¹é«åè³ªçè³æéãå¨ ECAD ä¸é²è¡çå»£æ³å¯¦é©è­æäºæåæ¹æ³çæææ§ãæ­¤å¤ï¼æåå¨èåçè³æé SMEsD å DBLP ä¸å·è¡äº GDANï¼ä¹ç²å¾äºæ¥µä½³ççµæã

##### **Bringing AI Participation Down to Scale: A Comment on Open AIs Democratic Inputs to AI Project**
2407.11613v1 by David Moats, Chandrima Ganguly

This commentary piece reviews the recent Open AI Democratic Inputs programme,
which funded 10 teams to design procedures for public participation in
generative AI. While applauding the technical innovations in these projects, we
identify several shared assumptions including the generality of LLMs,
extracting abstract values, soliciting solutions not problems and equating
participation with democracy. We call instead for AI participation which
involves specific communities and use cases and solicits concrete problems to
be remedied. We also find it important that these communities have a stake in
the outcome, including ownership of data or models.

æè¦ï¼éç¯è©è«æç« åé¡§äºæè¿ç Open AI æ°ä¸»è¼¸å¥è¨ç«ï¼
è©²è¨ç«è³å©äº 10 ååéï¼ä»¥è¨­è¨å¬ç¾åèçæå¼ AI çç¨åºãéç¶è®è³éäºå°æ¡ä¸­çæè¡åµæ°ï¼æå
æ¾åºå¹¾åå±åçåè¨­ï¼åæ¬ LLM çæ®éæ§ï¼
æåæ½è±¡å¹å¼ï¼å¾µæ±è§£æ±ºæ¹æ¡èéåé¡ï¼ä»¥åå°åèç­åæ¼æ°ä¸»ãæåå¼ç±²ä»¥ AI åèåèä»£ä¹ï¼
å¶ä¸­æ¶åç¹å®ç¤¾ç¾¤åä½¿ç¨æ¡ä¾ï¼ä¸¦å¾µæ±å·é«åé¡ä»¥ç²å¾è£æãæåä¹ç¼ç¾éäºç¤¾ç¾¤å¨ææä¸­å·æå©å®³éä¿éå¸¸éè¦ï¼åæ¬è³æææ¨¡åçæææ¬ã

##### **Statistical Reachability Analysis of Stochastic Cyber-Physical Systems under Distribution Shift**
2407.11609v1 by Navid Hashemi, Lars Lindemann, Jyotirmoy V. Deshmukh

Reachability analysis is a popular method to give safety guarantees for
stochastic cyber-physical systems (SCPSs) that takes in a symbolic description
of the system dynamics and uses set-propagation methods to compute an
overapproximation of the set of reachable states over a bounded time horizon.
In this paper, we investigate the problem of performing reachability analysis
for an SCPS that does not have a symbolic description of the dynamics, but
instead is described using a digital twin model that can be simulated to
generate system trajectories. An important challenge is that the simulator
implicitly models a probability distribution over the set of trajectories of
the SCPS; however, it is typical to have a sim2real gap, i.e., the actual
distribution of the trajectories in a deployment setting may be shifted from
the distribution assumed by the simulator. We thus propose a statistical
reachability analysis technique that, given a user-provided threshold
$1-\epsilon$, provides a set that guarantees that any reachable state during
deployment lies in this set with probability not smaller than this threshold.
Our method is based on three main steps: (1) learning a deterministic surrogate
model from sampled trajectories, (2) conducting reachability analysis over the
surrogate model, and (3) employing {\em robust conformal inference} using an
additional set of sampled trajectories to quantify the surrogate model's
distribution shift with respect to the deployed SCPS. To counter conservatism
in reachable sets, we propose a novel method to train surrogate models that
minimizes a quantile loss term (instead of the usual mean squared loss), and a
new method that provides tighter guarantees using conformal inference using a
normalized surrogate error. We demonstrate the effectiveness of our technique
on various case studies.

æè¦ï¼å¯éæ§åææ¯ä¸ç¨®æµè¡çæ¹æ³ï¼ç¨æ¼å°é¨æ©ç¶²è·¯ç©çç³»çµ± (SCPS) æä¾å®å¨ä¿è­ï¼å®æ¡ç¨ç³»çµ±åæçç¬¦èæè¿°ï¼ä¸¦ä½¿ç¨éåå³æ­æ¹æ³è¨ç®åºå¨æçæéç¯åå§å¯éçæéåçéåº¦è¿ä¼¼ãå¨æ¬æä¸­ï¼æåæ¢è¨äºå°æ²æåæç¬¦èæè¿°ç SCPS å·è¡å¯éæ§åæçåé¡ï¼èæ¯ä½¿ç¨å¯ä»¥æ¨¡æ¬ä»¥çæç³»çµ±è»è·¡çæ¸ä½éèèæ¨¡åé²è¡æè¿°ãä¸åéè¦çææ°æ¯ï¼æ¨¡æ¬å¨é±å¼å°å° SCPS è»è·¡éåå»ºæ¨¡æ©çåä½ï¼ç¶èï¼éå¸¸ææ sim2real å·®è·ï¼å³ï¼é¨ç½²è¨­å®ä¸­è»è·¡çå¯¦éåä½å¯è½æåé¢æ¨¡æ¬å¨åè¨­çåä½ãå æ­¤ï¼æåæåºäºä¸ç¨®çµ±è¨å¯éæ§åææè¡ï¼çµ¦å®ä½¿ç¨èæä¾çé¾å¼ $1-\epsilon$ï¼æä¾ä¸åéåï¼ä¿è­é¨ç½²æéçä»»ä½å¯éçæé½ä½æ¼æ­¤éåä¸­ï¼æ©çä¸å°æ¼æ­¤é¾å¼ãæåçæè¡åºæ¼ä¸åä¸»è¦æ­¥é©ï¼(1) å¾æ¡æ¨£è»è·¡å­¸ç¿ç¢ºå®æ§æ¿ä»£æ¨¡åï¼(2) å°æ¿ä»£æ¨¡åé²è¡å¯éæ§åæï¼ä»¥å (3) ä½¿ç¨å¦ä¸çµæ¡æ¨£è»è·¡æ¡ç¨ãç©©å¥å±å½¢æ¨è«ãä¾éåæ¿ä»£æ¨¡åç¸å°æ¼å·²é¨ç½² SCPS çåä½è½ç§»ãçºäºæå°å¯ééåä¸­çä¿å®ä¸»ç¾©ï¼æåæåºäºä¸ç¨®æ°æ¹æ³ä¾è¨ç·´æ¿ä»£æ¨¡åï¼ä»¥æå°ååä½æ¸æå¤±é ï¼èä¸æ¯éå¸¸çåæ¹æå¤±ï¼ï¼ä»¥åä¸ç¨®ä½¿ç¨å±å½¢æ¨è«çæ°æ¹æ³ï¼ä½¿ç¨æ­£è¦åçæ¿ä»£èª¤å·®æä¾æ´å´æ ¼çä¿è­ãæåå¨åç¨®æ¡ä¾ç ç©¶ä¸­å±ç¤ºäºæåæè¡çæææ§ã

##### **The Foundations of Tokenization: Statistical and Computational Concerns**
2407.11606v1 by Juan Luis Gastaldi, John Terilla, Luca Malagutti, Brian DuSell, Tim Vieira, Ryan Cotterell

Tokenization - the practice of converting strings of characters over an
alphabet into sequences of tokens over a vocabulary - is a critical yet
under-theorized step in the NLP pipeline. Notably, it remains the only major
step not fully integrated into widely used end-to-end neural models. This paper
aims to address this theoretical gap by laying the foundations of tokenization
from a formal perspective. By articulating and extending basic properties about
the category of stochastic maps, we propose a unified framework for
representing and analyzing tokenizer models. This framework allows us to
establish general conditions for the use of tokenizers. In particular, we
formally establish the necessary and sufficient conditions for a tokenizer
model to preserve the consistency of statistical estimators. Additionally, we
discuss statistical and computational concerns crucial for the design and
implementation of tokenizer models. The framework and results advanced in this
paper represent a step toward a robust theoretical foundation for neural
language modeling.

æè¦ï¼åè© - å°å­æ¯è¡¨ä¸çå­åä¸²è½æçºè©å½ä¸çç¬¦èåºåçåæ³ - æ¯ NLP ç®¡ç·ä¸­ä¸åééµä½çè«åä¸è¶³çæ­¥é©ãå¼å¾æ³¨æçæ¯ï¼å®ä»ç¶æ¯å¯ä¸ä¸åå°æªå®å¨æ´åå°å»£æ³ä½¿ç¨çç«¯å°ç«¯ç¥ç¶æ¨¡åä¸­çä¸»è¦æ­¥é©ãæ¬ææ¨å¨ééå¾å½¢å¼çè§åº¦å¥ å®åè©çåºç¤ä¾è§£æ±ºéåçè«å·®è·ãééé¡è¿°åæ´å±éæ¼é¨æ©æ å°é¡å¥çåºæ¬å±¬æ§ï¼æåæåºäºç¨æ¼è¡¨ç¤ºååæåè©å¨æ¨¡åççµ±ä¸æ¡æ¶ãéåæ¡æ¶è®æåè½å¤ çºåè©å¨çä½¿ç¨å»ºç«ä¸è¬æ¢ä»¶ãç¹å¥æ¯ï¼æåæ­£å¼å»ºç«äºåè©å¨æ¨¡åä¿æçµ±è¨ä¼°è¨å¨ä¸è´æ§çå¿è¦åååæ¢ä»¶ãæ­¤å¤ï¼æåè¨è«äºå°åè©å¨æ¨¡åçè¨­è¨åå¯¦ä½è³ééè¦ççµ±è¨åè¨ç®åé¡ãæ¬ææåºçæ¡æ¶åçµæä»£è¡¨äºæåç©©å¥çç¥ç¶èªè¨æ¨¡åçè«åºç¤éåºçä¸æ­¥ã

##### **Enhancing TinyML Security: Study of Adversarial Attack Transferability**
2407.11599v1 by Parin Shah, Yuvaraj Govindarajulu, Pavan Kulkarni, Manojkumar Parmar

The recent strides in artificial intelligence (AI) and machine learning (ML)
have propelled the rise of TinyML, a paradigm enabling AI computations at the
edge without dependence on cloud connections. While TinyML offers real-time
data analysis and swift responses critical for diverse applications, its
devices' intrinsic resource limitations expose them to security risks. This
research delves into the adversarial vulnerabilities of AI models on
resource-constrained embedded hardware, with a focus on Model Extraction and
Evasion Attacks. Our findings reveal that adversarial attacks from powerful
host machines could be transferred to smaller, less secure devices like ESP32
and Raspberry Pi. This illustrates that adversarial attacks could be extended
to tiny devices, underscoring vulnerabilities, and emphasizing the necessity
for reinforced security measures in TinyML deployments. This exploration
enhances the comprehension of security challenges in TinyML and offers insights
for safeguarding sensitive data and ensuring device dependability in AI-powered
edge computing settings.

æè¦ï¼æè¿å¨äººå·¥æºæ§ï¼AIï¼åæ©å¨å­¸ç¿ï¼MLï¼çé²å±ï¼æ¨åäº TinyML çå´èµ·ï¼éæ¯ä¸åå¨éç·£é²è¡ AI è¨ç®çç¯ä¾ï¼ä¸éè¦ä¾è³´é²ç«¯é£ç·ãåç®¡ TinyML æä¾äºå³æè³æåæåå¿«éåæï¼éå°åç¨®æç¨ç¨å¼ä¾èªªè³ééè¦ï¼ä½å¶è£ç½®å§å¨çè³æºéå¶ä½¿å®åé¢è¨å®å¨é¢¨éªãéé ç ç©¶æ¢è¨äºå¨è³æºåéçåµå¥å¼ç¡¬é«ä¸ï¼AI æ¨¡åçå°ææ§æ¼æ´ï¼éé»å¨æ¼æ¨¡åèååè¦é¿æ»æãæåçç ç©¶çµæé¡¯ç¤ºï¼å¼·å¤§çä¸»æ©é»è¦çå°ææ§æ»æå¯ä»¥è½ç§»å°è¼å°ãå®å¨æ§è¼ä½çè£ç½®ï¼ä¾å¦ ESP32 å Raspberry Piãéèªªæäºå°ææ§æ»æå¯ä»¥æ´å±å°å¾®åè£ç½®ï¼å¸é¡¯äºæ¼æ´ï¼ä¸¦å¼·èª¿å¨ TinyML é¨ç½²ä¸­å¼·åå®å¨æªæ½çå¿è¦æ§ãéé æ¢è¨å¢å¼·äºå° TinyML å®å¨ææ°ççè§£ï¼ä¸¦æä¾äºè¦è§£ï¼ç¨æ¼ä¿è­·ææè³æï¼ä¸¦ç¢ºä¿å¨ AI é©åçéç·£éç®è¨­å®ä¸­è£ç½®çå¯é æ§ã

##### **DiNO-Diffusion. Scaling Medical Diffusion via Self-Supervised Pre-Training**
2407.11594v1 by Guillermo Jimenez-Perez, Pedro Osorio, Josef Cersovsky, Javier Montalt-Tordera, Jens Hooge, Steffen Vogler, Sadegh Mohammadi

Diffusion models (DMs) have emerged as powerful foundation models for a
variety of tasks, with a large focus in synthetic image generation. However,
their requirement of large annotated datasets for training limits their
applicability in medical imaging, where datasets are typically smaller and
sparsely annotated. We introduce DiNO-Diffusion, a self-supervised method for
training latent diffusion models (LDMs) that conditions the generation process
on image embeddings extracted from DiNO. By eliminating the reliance on
annotations, our training leverages over 868k unlabelled images from public
chest X-Ray (CXR) datasets. Despite being self-supervised, DiNO-Diffusion shows
comprehensive manifold coverage, with FID scores as low as 4.7, and emerging
properties when evaluated in downstream tasks. It can be used to generate
semantically-diverse synthetic datasets even from small data pools,
demonstrating up to 20% AUC increase in classification performance when used
for data augmentation. Images were generated with different sampling strategies
over the DiNO embedding manifold and using real images as a starting point.
Results suggest, DiNO-Diffusion could facilitate the creation of large datasets
for flexible training of downstream AI models from limited amount of real data,
while also holding potential for privacy preservation. Additionally,
DiNO-Diffusion demonstrates zero-shot segmentation performance of up to 84.4%
Dice score when evaluating lung lobe segmentation. This evidences good CXR
image-anatomy alignment, akin to segmenting using textual descriptors on
vanilla DMs. Finally, DiNO-Diffusion can be easily adapted to other medical
imaging modalities or state-of-the-art diffusion models, opening the door for
large-scale, multi-domain image generation pipelines for medical imaging.

æè¦ï¼æ´æ£æ¨¡å (DM) å·²æçºåç¨®ä»»åä¸­å¼·å¤§çåºç¤æ¨¡åï¼ç¹å¥æ¯åæå½±åçæãç¶èï¼å®åå¨è¨ç·´ä¸­å°å¤§åæ¨è¨»è³æéçè¦æ±éå¶äºå®åå¨é«çå½±åä¸­çæç¨ï¼èé«çå½±åçè³æééå¸¸è¼å°ä¸æ¨è¨»ç¨çãæåå¼å¥äº DiNO-Diffusionï¼éæ¯ä¸ç¨®ç¨æ¼è¨ç·´æ¢ä»¶çæéç¨çæ½å¨æ´æ£æ¨¡å (LDM) çèªç£ç£æ¹æ³ï¼è©²éç¨åºæ¼å¾ DiNO ä¸­æåçå½±ååµå¥ãééæ¶é¤å°æ¨è¨»çä¾è³´ï¼æåçè¨ç·´å©ç¨äºä¾èªå¬å±è¸é¨ X å (CXR) è³æéçè¶é 868k å¼µæªæ¨è¨»å½±åãåç®¡æ¯èªç£ç£çï¼ä½ DiNO-Diffusion é¡¯ç¤ºåºå¨é¢çæµå½¢è¦èï¼FID åæ¸ä½è³ 4.7ï¼ä¸¦ä¸å¨è©ä¼°ä¸æ¸¸ä»»åæåºç¾äºæ°èçå±¬æ§ãå®å¯ç¨æ¼å¾å°åè³æåº«çæèªç¾©å¤æ¨£çåæè³æéï¼å¨ç¨æ¼è³ææ´åæï¼åé¡æè½æåå¹åº¦é«é 20% AUCãå½±åæ¯å¨ DiNO åµå¥æµå½¢ä¸ä½¿ç¨ä¸åçåæ¨£ç­ç¥çæçï¼ä¸¦ä½¿ç¨çå¯¦å½±åä½çºèµ·é»ãçµæé¡¯ç¤ºï¼DiNO-Diffusion å¯ä»¥ä¿é²å¾æéççå¯¦è³æä¸­éæ´»è¨ç·´ä¸æ¸¸ AI æ¨¡åçå¤§åè³æéçå»ºç«ï¼åæä¹å·æé±ç§ä¿è­·çæ½åãæ­¤å¤ï¼DiNO-Diffusion å¨è©ä¼°èºèåå²æå±ç¤ºäºé«é 84.4% ç Dice åæ¸çé¶æ¬¡å­¸ç¿åå²æè½ãéè­æäºè¯å¥½ç CXR å½±åè§£åå°é½ï¼é¡ä¼¼æ¼å¨é¦è DM ä¸ä½¿ç¨æå­æè¿°ç¬¦é²è¡åå²ãæå¾ï¼DiNO-Diffusion å¯ä»¥è¼é¬é©æå¶ä»é«çå½±åæ¹å¼ææåé²çæ´æ£æ¨¡åï¼çºé«çå½±åçå¤§è¦æ¨¡ãå¤é åå½±åçæç®¡ééåäºå¤§éã

##### **AdaptEval: Evaluating Large Language Models on Domain Adaptation for Text Summarization**
2407.11591v1 by Anum Afzal, Ribin Chalumattu, Florian Matthes, Laura Mascarell Espuny

Despite the advances in the abstractive summarization task using Large
Language Models (LLM), there is a lack of research that asses their abilities
to easily adapt to different domains. We evaluate the domain adaptation
abilities of a wide range of LLMs on the summarization task across various
domains in both fine-tuning and in-context learning settings. We also present
AdaptEval, the first domain adaptation evaluation suite. AdaptEval includes a
domain benchmark and a set of metrics to facilitate the analysis of domain
adaptation. Our results demonstrate that LLMs exhibit comparable performance in
the in-context learning setting, regardless of their parameter scale.

æè¦ï¼åç®¡ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) å¨æ½è±¡æè¦ä»»åä¸­åå¾é²å±ï¼ä½ç¼ºä¹ç ç©¶è©ä¼°å¶è¼é¬é©æä¸åé åçè½åãæåè©ä¼°äºåç¨® LLM å¨æè¦ä»»åä¸­å°ä¸åé åçé åé©æè½åï¼åæ¬å¾®èª¿åæå¢å­¸ç¿è¨­å®ãæåéæåºäº AdaptEvalï¼éæ¯ç¬¬ä¸åé åé©æè©ä¼°å¥ä»¶ãAdaptEval åå«ä¸åé ååºæºåä¸çµææ¨ï¼ä»¥å©æ¼åæé åé©æãæåççµæè¡¨æï¼ç¡è« LLM çåæ¸è¦æ¨¡å¦ä½ï¼å®åå¨æå¢å­¸ç¿è¨­å®ä¸­é½è¡¨ç¾åºç¸ç¶çæè½ã

##### **QVD: Post-training Quantization for Video Diffusion Models**
2407.11585v2 by Shilong Tian, Hong Chen, Chengtao Lv, Yu Liu, Jinyang Guo, Xianglong Liu, Shengxi Li, Hao Yang, Tao Xie

Recently, video diffusion models (VDMs) have garnered significant attention
due to their notable advancements in generating coherent and realistic video
content. However, processing multiple frame features concurrently, coupled with
the considerable model size, results in high latency and extensive memory
consumption, hindering their broader application. Post-training quantization
(PTQ) is an effective technique to reduce memory footprint and improve
computational efficiency. Unlike image diffusion, we observe that the temporal
features, which are integrated into all frame features, exhibit pronounced
skewness. Furthermore, we investigate significant inter-channel disparities and
asymmetries in the activation of video diffusion models, resulting in low
coverage of quantization levels by individual channels and increasing the
challenge of quantization. To address these issues, we introduce the first PTQ
strategy tailored for video diffusion models, dubbed QVD. Specifically, we
propose the High Temporal Discriminability Quantization (HTDQ) method, designed
for temporal features, which retains the high discriminability of quantized
features, providing precise temporal guidance for all video frames. In
addition, we present the Scattered Channel Range Integration (SCRI) method
which aims to improve the coverage of quantization levels across individual
channels. Experimental validations across various models, datasets, and
bit-width settings demonstrate the effectiveness of our QVD in terms of diverse
metrics. In particular, we achieve near-lossless performance degradation on
W8A8, outperforming the current methods by 205.12 in FVD.

æè¦ï¼<paragraph>è¿æï¼å½±çæ©æ£æ¨¡å (VDM) å å¶å¨çæè¿è´¯ä¸é¼ççå½±çåå®¹æ¹é¢åå¾æ¾èè¿å±èå¤åå³æ³¨ãç¶èï¼åæ¶å¤çå¤ä¸ªå¸§ç¹å¾ï¼å ä¸æ¨¡åè§æ¨¡åºå¤§ï¼å¯¼è´å»¶è¿é«ä¸åå­æ¶èå¤§ï¼é»ç¢äºå¶æ´å¹¿æ³çåºç¨ãè®­ç»åéå (PTQ) æ¯ä¸ç§ææçææ¯ï¼å¯åå°åå­å ç¨å¹¶æé«è®¡ç®æçãä¸å¾åæ©æ£ä¸åï¼æä»¬è§å¯å°æ´åå°ææå¸§ç¹å¾ä¸­çæ¶é´ç¹å¾è¡¨ç°åºææ¾çååº¦ãæ­¤å¤ï¼æä»¬è°æ¥äºå½±çæ©æ£æ¨¡åæ¿æ´»ä¸­çæ¾èçééé´å·®å¼åä¸å¯¹ç§°æ§ï¼å¯¼è´åä¸ªééçéåçº§å«è¦ççä½ï¼å¢å äºéåçé¾åº¦ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬å¼å¥äºç¬¬ä¸ä¸ªä¸ä¸ºå½±çæ©æ£æ¨¡åéèº«å®å¶ç PTQ ç­ç¥ï¼ç§°ä¸º QVDãå·ä½æ¥è¯´ï¼æä»¬æåºäºéå¯¹æ¶é´ç¹å¾è®¾è®¡çé«æ¶é´å¯è¾¨å«æ§éå (HTDQ) æ¹æ³ï¼å®ä¿çäºéåç¹å¾çé«å¯è¾¨å«æ§ï¼ä¸ºææå½±çå¸§æä¾ç²¾ç¡®çæ¶é´æå¯¼ãæ­¤å¤ï¼æä»¬æåºäºåæ£ééèå´æ´å (SCRI) æ¹æ³ï¼æ¨å¨æé«åä¸ªééçéåçº§å«è¦ççãè·¨è¶åç§æ¨¡åãæ°æ®éåä½å®½è®¾ç½®çå®éªéªè¯è¯æäºæä»¬ç QVD å¨åç§ææ æ¹é¢çæææ§ãç¹å«æ¯ï¼æä»¬å¨ W8A8 ä¸å®ç°äºæ¥è¿æ æçæ§è½ä¸éï¼å¨ FVD ä¸­æ¯å½åæ¹æ³é«åº 205.12ã</paragraph>

##### **Probing the Efficacy of Federated Parameter-Efficient Fine-Tuning of Vision Transformers for Medical Image Classification**
2407.11573v1 by Naif Alkhunaizi, Faris Almalik, Rouqaiah Al-Refai, Muzammal Naseer, Karthik Nandakumar

With the advent of large pre-trained transformer models, fine-tuning these
models for various downstream tasks is a critical problem. Paucity of training
data, the existence of data silos, and stringent privacy constraints exacerbate
this fine-tuning problem in the medical imaging domain, creating a strong need
for algorithms that enable collaborative fine-tuning of pre-trained models.
Moreover, the large size of these models necessitates the use of
parameter-efficient fine-tuning (PEFT) to reduce the communication burden in
federated learning. In this work, we systematically investigate various
federated PEFT strategies for adapting a Vision Transformer (ViT) model
(pre-trained on a large natural image dataset) for medical image
classification. Apart from evaluating known PEFT techniques, we introduce new
federated variants of PEFT algorithms such as visual prompt tuning (VPT),
low-rank decomposition of visual prompts, stochastic block attention
fine-tuning, and hybrid PEFT methods like low-rank adaptation (LoRA)+VPT.
Moreover, we perform a thorough empirical analysis to identify the optimal PEFT
method for the federated setting and understand the impact of data distribution
on federated PEFT, especially for out-of-domain (OOD) and non-IID data. The key
insight of this study is that while most federated PEFT methods work well for
in-domain transfer, there is a substantial accuracy vs. efficiency trade-off
when dealing with OOD and non-IID scenarios, which is commonly the case in
medical imaging. Specifically, every order of magnitude reduction in
fine-tuned/exchanged parameters can lead to a 4% drop in accuracy. Thus, the
initial model choice is crucial for federated PEFT. It is preferable to use
medical foundation models learned from in-domain medical image data (if
available) rather than general vision models.

æè¦ï¼<paragraph>é¨èå¤§åé è¨ç·´è½æå¨æ¨¡åçåºç¾ï¼éå°åç¨®ä¸æ¸¸ä»»åå¾®èª¿éäºæ¨¡åæ¯ä¸åééµåé¡ãè¨ç·´è³æçç¨ç¼ºæ§ãè³æå­¤å³¶çå­å¨ä»¥åå´æ ¼çé±ç§éå¶æå åé«çå½±åé åä¸­çå¾®èª¿åé¡ï¼éå°è½è®é è¨ç·´æ¨¡åé²è¡åä½å¾®èª¿çæ¼ç®æ³ç¢çäºå¼·çéæ±ãæ­¤å¤ï¼éäºæ¨¡åçé¾å¤§è¦æ¨¡éè¦ä½¿ç¨åæ¸ææå¾®èª¿ (PEFT) ä¾éä½è¯åå­¸ç¿ä¸­çéè¨è² æãå¨éé å·¥ä½ä¸­ï¼æåç³»çµ±æ§å°æ¢è¨äºåç¨®è¯å PEFT ç­ç¥ï¼ä»¥èª¿æ´è¦è¦ºè½æå¨ (ViT) æ¨¡åï¼å¨å¤§åèªç¶å½±åè³æéä¸é åè¨ç·´ï¼ä»¥é²è¡é«çå½±ååé¡ãé¤äºè©ä¼°å·²ç¥ç PEFT æè¡å¤ï¼æåéå¼å¥äº PEFT æ¼ç®æ³çæ°è¯åè®é«ï¼ä¾å¦è¦è¦ºæç¤ºèª¿æ´ (VPT)ãè¦è¦ºæç¤ºçä½ç§©åè§£ãé¨æ©åå¡æ³¨æåå¾®èª¿ï¼ä»¥åä½ç§©é©æ (LoRA)+VPT ç­æ··å PEFT æ¹æ³ãæ­¤å¤ï¼æåé²è¡äºå¾¹åºçç¶é©åæï¼ä»¥æ¾åºè¯åè¨­å®çæä½³ PEFT æ¹æ³ï¼ä¸¦äºè§£è³æåä½å°è¯å PEFT çå½±é¿ï¼ç¹å¥æ¯å°æ¼é åå¤ (OOD) åéç¨ç«ååä½ (non-IID) è³æãéé ç ç©¶çä¸»è¦è¦è§£æ¯ï¼åç®¡å¤§å¤æ¸è¯å PEFT æ¹æ³é½é©ç¨æ¼é åå§è½ç§»ï¼ä½å¨èç OOD åéç¨ç«ååä½å ´æ¯æï¼ææå¤§å¹çæºç¢ºåº¦èæçæè¡·ï¼ééå¸¸æ¯é«çå½±åä¸­çææ³ãå·é«ä¾èªªï¼å¾®èª¿/äº¤æåæ¸çæ¯åæ¸éç´æ¸å°é½å¯è½å°è´æºç¢ºåº¦ä¸é 4%ãå æ­¤ï¼åå§æ¨¡åçé¸æå°æ¼è¯å PEFT è³ééè¦ãæå¥½ä½¿ç¨å¾é åå§é«å­¸å½±åè³æï¼å¦ææçè©±ï¼å­¸ç¿çé«å­¸åºç¤æ¨¡åï¼èä¸æ¯ä¸è¬è¦è¦ºæ¨¡åã</paragraph>

##### **TGIF: Text-Guided Inpainting Forgery Dataset**
2407.11566v1 by Hannes Mareen, Dimitrios Karageorgiou, Glenn Van Wallendael, Peter Lambert, Symeon Papadopoulos

Digital image manipulation has become increasingly accessible and realistic
with the advent of generative AI technologies. Recent developments allow for
text-guided inpainting, making sophisticated image edits possible with minimal
effort. This poses new challenges for digital media forensics. For example,
diffusion model-based approaches could either splice the inpainted region into
the original image, or regenerate the entire image. In the latter case,
traditional image forgery localization (IFL) methods typically fail. This paper
introduces the Text-Guided Inpainting Forgery (TGIF) dataset, a comprehensive
collection of images designed to support the training and evaluation of image
forgery localization and synthetic image detection (SID) methods. The TGIF
dataset includes approximately 80k forged images, originating from popular
open-source and commercial methods; SD2, SDXL, and Adobe Firefly. Using this
data, we benchmark several state-of-the-art IFL and SID methods. Whereas
traditional IFL methods can detect spliced images, they fail to detect
regenerated inpainted images. Moreover, traditional SID may detect the
regenerated inpainted images to be fake, but cannot localize the inpainted
area. Finally, both types of methods fail when exposed to stronger compression,
while they are less robust to modern compression algorithms, such as WEBP. As
such, this work demonstrates the inefficiency of state-of-the-art detectors on
local manipulations performed by modern generative approaches, and aspires to
help with the development of more capable IFL and SID methods. The dataset can
be downloaded at https://github.com/IDLabMedia/tgif-dataset.

æè¦ï¼æ¸ä½å½±åèçé¨èçæå¼ AI æè¡çåºç¾ï¼è®å¾è¶ä¾è¶å®¹æåå¾ä¸é¼çãæè¿çç¼å±åè¨±æå­å¼å°çå¡«è£ï¼è®è¤éçå½±åç·¨è¼¯è®å¾è¼èæèãéçºæ¸ä½åªé«éè­å¸¶ä¾äºæ°çææ°ãä¾å¦ï¼åºæ¼æ´æ£æ¨¡åçæ¹æ³å¯ä»¥å°å¡«è£ååæ¼æ¥è³åå§å½±åï¼æéæ°ç¢çæ´å¼µå½±åãå¨å¾èçææ³ä¸ï¼å³çµ±çå½±åå½é å®ä½ (IFL) æ¹æ³éå¸¸æå¤±æãæ¬æä»ç´¹äºæå­å¼å°å¡«è£å½é  (TGIF) è³æéï¼éæ¯ä¸åå¨é¢çå½±åéåï¼æ¨å¨æ¯æ´å½±åå½é å®ä½ååæå½±ååµæ¸¬ (SID) æ¹æ³çè¨ç·´åè©ä¼°ãTGIF è³æéåå«ç´ 80k å¼µå½é å½±åï¼æºèªæ¼ç±éçéæºååæ¥­æ¹æ³ï¼SD2ãSDXL å Adobe Fireflyãä½¿ç¨éäºè³æï¼æåè©å®äºæ¸ç¨®æåé²ç IFL å SID æ¹æ³ãéç¶å³çµ±ç IFL æ¹æ³å¯ä»¥åµæ¸¬æ¼æ¥å½±åï¼ä½ç¡æ³åµæ¸¬éæ°ç¢ççå¡«è£å½±åãæ­¤å¤ï¼å³çµ±ç SID éç¶å¯ä»¥åµæ¸¬éæ°ç¢ççå¡«è£å½±åçºåï¼ä½ç¡æ³å®ä½å¡«è£ååãæå¾ï¼éå©ç¨®æ¹æ³å¨éå°è¼å¼·çå£ç¸®æé½æå¤±æï¼èå®åå°ç¾ä»£å£ç¸®æ¼ç®æ³ï¼ä¾å¦ WEBPï¼çé­¯æ£æ§è¼å·®ãå æ­¤ï¼éé ç ç©¶è­æäºæåé²çåµæ¸¬å¨å°æ¼ç¾ä»£çææ¹æ³å·è¡çå±é¨èççæçä½ä¸ï¼ä¸¦å¸ææå©æ¼éç¼æ´å¼·å¤§ç IFL å SID æ¹æ³ãè©²è³æéå¯æ¼ https://github.com/IDLabMedia/tgif-dataset ä¸è¼ã

##### **Self-Guided Generation of Minority Samples Using Diffusion Models**
2407.11555v1 by Soobin Um, Jong Chul Ye

We present a novel approach for generating minority samples that live on
low-density regions of a data manifold. Our framework is built upon diffusion
models, leveraging the principle of guided sampling that incorporates an
arbitrary energy-based guidance during inference time. The key defining feature
of our sampler lies in its \emph{self-contained} nature, \ie, implementable
solely with a pretrained model. This distinguishes our sampler from existing
techniques that require expensive additional components (like external
classifiers) for minority generation. Specifically, we first estimate the
likelihood of features within an intermediate latent sample by evaluating a
reconstruction loss w.r.t. its posterior mean. The generation then proceeds
with the minimization of the estimated likelihood, thereby encouraging the
emergence of minority features in the latent samples of subsequent timesteps.
To further improve the performance of our sampler, we provide several
time-scheduling techniques that properly manage the influence of guidance over
inference steps. Experiments on benchmark real datasets demonstrate that our
approach can greatly improve the capability of creating realistic
low-likelihood minority instances over the existing techniques without the
reliance on costly additional elements. Code is available at
\url{https://github.com/soobin-um/sg-minority}.

æè¦ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ä¾ç¢çå°æ¸æ¨£æ¬ï¼éäºæ¨£æ¬å­å¨æ¼è³ææµå½¢ä¸­çä½å¯åº¦ååãæåçæ¶æ§å»ºç«å¨æ´æ£æ¨¡åä¸ï¼å©ç¨äºå¼å°åæ¨£çåçï¼è©²åçå¨æ¨è«æéå§åå«äºåºæ¼ä»»æè½éçå¼å°ãæåçåæ¨£å¨çééµå®ç¾©ç¹å¾µå¨æ¼å¶ãèªæå°éãçæ¬è³ªï¼ä¹å°±æ¯èªªï¼åä½¿ç¨é è¨ç·´æ¨¡åå°±è½å¯¦ç¾ãéä½¿å¾æåçåæ¨£å¨æå¥æ¼ç¾æçæè¡ï¼å¾èéè¦æè²´çé¡å¤çµä»¶ï¼å¦å¤é¨åé¡å¨ï¼ä¾ç¢çå°æ¸ãå·é«ä¾èªªï¼æåé¦åééè©ä¼°éå»ºæå¤±ç¸å°æ¼å¶å¾é©å¹³åå¼ä¾ä¼°è¨ä¸­éæ½å¨æ¨£æ¬ä¸­ç¹å¾µçå¯è½æ§ãç¶å¾ï¼çææé¨èä¼°è¨å¯è½æ§çæå°åèé²è¡ï¼å¾èä¿é²å°æ¸ç¹å¾µå¨å¾çºæéæ­¥é·çæ½å¨æ¨£æ¬ä¸­åºç¾ãçºäºé²ä¸æ­¥æé«æååæ¨£å¨çæè½ï¼æåæä¾äºå¹¾ç¨®æéæç¨æè¡ï¼éäºæè¡å¯ä»¥é©ç¶å°ç®¡çå¼å°å°æ¨è«æ­¥é©çå½±é¿ãåºæºçå¯¦è³æéä¸çå¯¦é©è¡¨æï¼èç¾ææè¡ç¸æ¯ï¼æåçåæ³å¯ä»¥å¤§å¹æé«å»ºç«é¼ççä½å¯è½æ§å°æ¸åé«çè½åï¼èç¡éä¾è³´æè²´çé¡å¤åç´ ãç¨å¼ç¢¼å¯å¨ https://github.com/soobin-um/sg-minority åå¾ã

##### **Learning Global and Local Features of Power Load Series Through Transformer and 2D-CNN: An image-based Multi-step Forecasting Approach Incorporating Phase Space Reconstruction**
2407.11553v1 by Zihan Tang, Tianyao Ji, Wenhu Tang

As modern power systems continue to evolve, accurate power load forecasting
remains a critical issue. The phase space reconstruction method can effectively
retain the chaotic characteristics of power load from a system dynamics
perspective and thus is a promising knowledge-based preprocessing method for
power load forecasting. However, limited by its fundamental theory, there is
still a gap in implementing a multi-step forecasting scheme in current studies.
To bridge this gap, this study proposes a novel multi-step forecasting approach
by integrating the PSR with neural networks. Firstly, the useful features in
the phase trajectory obtained from the preprocessing of PSR are discussed in
detail. Through mathematical derivation, the equivalent characterization of the
PSR and another time series preprocessing method, patch segmentation, is
demonstrated for the first time. Based on this prior knowledge, an image-based
modeling perspective with the global and local feature extraction strategy is
introduced. Subsequently, a novel deep learning model, namely PSR-GALIEN, is
designed for end-to-end processing, in which the Transformer Encoder and
2D-convolutional neural networks are employed for the extraction of the global
and local patterns in the image, and a multi-layer perception based predictor
is used for the efficient correlation modeling. Then, extensive experiments are
conducted on five real-world benchmark datasets to verify the effectiveness as
well as to have an insight into the detailed properties. The results show that,
comparing it with six state-of-the-art deep learning models, the forecasting
performance of PSR-GALIEN consistently surpasses these baselines, which
achieves superior accuracy in both intra-day and day-ahead forecasting
scenarios. At the same time, a visualization-based method is proposed to
explain the attributions of the forecasting results.

æè¦ï¼é¨èç¾ä»£é»åç³»çµ±æçºæ¼é²ï¼æºç¢ºçé»åè² è¼é æ¸¬ä»çºä¸é ééµè­°é¡ãç¸ç©ºééå»ºæ³è½ææä¿çé»åè² è¼èªç³»çµ±ååå­¸è§é»çæ··æ²ç¹æ§ï¼å æ­¤æçºé»åè² è¼é æ¸¬ä¸­æ¥µå·åæ¯çç¥è­ååèçæ¹æ³ãç¶èï¼åéæ¼å¶åºç¤çè«ï¼ç¾è¡ç ç©¶ä»å­å¨ç¡æ³å¯¦ä½å¤æ­¥é©é æ¸¬æ©å¶çç¼ºå£ãçºå½è£æ­¤ç¼ºå£ï¼æ¬ç ç©¶æåºçµåç¸ç©ºééå»ºæ³èç¥ç¶ç¶²è·¯çåµæ°å¤æ­¥é©é æ¸¬æ¹æ³ãé¦åï¼è©³ç´°æ¢è¨èªç¸ç©ºééå»ºæ³åèçæå¾ç¸è»è·¡ä¸­çæç¨ç¹å¾µãééæ¸å­¸æ¨å°ï¼é¦æ¬¡è­æç¸ç©ºééå»ºæ³èå¦ä¸æåºåèçæ¹æ³ââåå¡åå²ââçç­å¹ç¹æ§ãåºæ¼æ­¤ååç¥è­ï¼å¼å¥å·åå¨åèå±é¨ç¹å¾µèåç­ç¥çå½±ååå»ºæ¨¡è§é»ãé¨å¾ï¼è¨­è¨åµæ°çæ·±åº¦å­¸ç¿æ¨¡å PSR-GALIEN ä»¥é²è¡ç«¯å°ç«¯èçï¼å¶ä¸­æ¡ç¨ Transformer ç·¨ç¢¼å¨è 2D æ²ç©ç¥ç¶ç¶²è·¯èåå½±åä¸­çå¨åèå±é¨æ¨¡å¼ï¼ä¸¦ä½¿ç¨åºæ¼å¤å±¤æç¥å¨çé æ¸¬å¨é²è¡ææççéè¯æ§å»ºæ¨¡ãæ¥èï¼å¨äºåçå¯¦ä¸çåºæºè³æéä¸é²è¡å»£æ³çå¯¦é©ï¼ä»¥é©è­å¶æææ§ä¸¦æ·±å¥äºè§£å¶è©³ç´°ç¹æ§ãçµæé¡¯ç¤ºï¼èå­ç¨®æåé²çæ·±åº¦å­¸ç¿æ¨¡åç¸æ¯è¼ï¼PSR-GALIEN çé æ¸¬æè½å§çµè¶è¶éäºåºæºï¼å¨æ¥å§èæ¥å¾é æ¸¬æå¢ä¸­åéå°åªç°çæºç¢ºåº¦ãåæï¼æåºåºæ¼è¦è¦ºåçæ¹æ³ä¾è§£éé æ¸¬çµæçæ­¸å ã

##### **Optimizing KV Cache Eviction in LLMs: Adaptive Allocation for Enhanced Budget Utilization**
2407.11550v1 by Yuan Feng, Junlin Lv, Yukun Cao, Xike Xie, S. Kevin Zhou

Large Language Models have excelled in various fields but encounter
efficiency limitations due to the extensive KV cache required for long
sequences inference. Many efforts try to evict non-critical cache elements
during runtime, thereby reducing cache size within a given memory budget while
preserving generation quality. Our reexamination of their underlying principles
discerns that prevailing strategies essentially aim to minimize an upper bound
of eviction loss within a specific budget allocation. However, we observe that
the current practice of uniformly allocating budgets across different attention
heads during the eviction procedure tends to degrade the quality of generation
posten-eviction. In light of these findings, we propose a simple yet effective
adaptive allocation algorithm that not only theoretically ensures its loss
upper bound does not exceed that of previous uniform allocation methods, but
also effectively aligns with the characteristics of the self-attention
mechanism, thus practically reducing the upper bound. Further, integrating this
algorithm with two of the most advanced methods yields Ada-SnapKV and
Ada-Pyramid. Extensive experimental validation across 16 datasets and the
Needle-in-a-Haystack test confirm that Ada-SnapKV and Ada-Pyramid achieve
further enhancements, establishing new benchmarks in state-of-the-art
performance.

æè¦ï¼å¤§åèªè¨æ¨¡åå¨åç¨®é åè¡¨ç¾åºè²ï¼ä½ç±æ¼é·åºåæ¨è«éè¦å¤§éç KV å¿«åï¼å æ­¤æéå°æçéå¶ãè¨±å¤æ¹æ³åè©¦å¨å·è¡æéé©ééééµå¿«ååç´ ï¼å¾èå¨çµ¦å®çè¨æ¶é«é ç®ä¸­æ¸å°å¿«åå¤§å°ï¼åæä¿æçæåè³ªãæåéæ°å¯©è¦å¶åºæ¬ååï¼ç¼ç¾æ®éçç­ç¥åºæ¬ä¸æ¨å¨æå°åç¹å®é ç®åéä¸­çé©éæå¤±çä¸éãç¶èï¼æåè§å¯å°å¨é©ééç¨ä¸­å°é ç®åå»åéçµ¦ä¸åæ³¨æåå±¤çç¾è¡åæ³å¾å¾æéä½é©éå¾ççæåè³ªãæ ¹æéäºç¼ç¾ï¼æåæåºä¸åç°¡å®ä½ææçèªé©æåéæ¼ç®æ³ï¼å®ä¸åå¨çè«ä¸ç¢ºä¿å¶æå¤±ä¸éä¸è¶éååçåå»åéæ¹æ³ï¼èä¸ææå°ç¬¦åèªæ³¨æåæ©å¶çç¹æ§ï¼å¾èå¯¦éä¸éä½äºä¸éãæ­¤å¤ï¼å°æ­¤æ¼ç®æ³èå©ç¨®æåé²çæ¹æ³æ´åï¼ç¢ç Ada-SnapKV å Ada-Pyramidãå¨ 16 åè³æéå Needle-in-a-Haystack æ¸¬è©¦ä¸­çå»£æ³å¯¦é©é©è­è­å¯¦ï¼Ada-SnapKV å Ada-Pyramid é²ä¸æ­¥æåï¼å¨æåé²çæè½ä¸­å»ºç«æ°çåºæºã

##### **How Personality Traits Influence Negotiation Outcomes? A Simulation based on Large Language Models**
2407.11549v1 by Yin Jou Huang, Rafik Hadfi

Psychological evidence reveals the influence of personality traits on
decision-making. For instance, agreeableness is generally associated with
positive outcomes in negotiations, whereas neuroticism is often linked to less
favorable outcomes. This paper introduces a simulation framework centered on
Large Language Model (LLM) agents endowed with synthesized personality traits.
The agents negotiate within bargaining domains and possess customizable
personalities and objectives. The experimental results show that the behavioral
tendencies of LLM-based simulations could reproduce behavioral patterns
observed in human negotiations. The contribution is twofold. First, we propose
a simulation methodology that investigates the alignment between the linguistic
and economic capabilities of LLM agents. Secondly, we offer empirical insights
into the strategic impact of Big-Five personality traits on the outcomes of
bilateral negotiations. We also provide a case study based on synthesized
bargaining dialogues to reveal intriguing behaviors, including deceitful and
compromising behaviors.

æè¦ï¼å¿çå­¸è­ææ­ç¤ºäºäººæ ¼ç¹è³ªå°æ±ºç­çå½±é¿ãä¾å¦ï¼å®äººæ§éå¸¸èè«å¤ä¸­çç©æ¥µçµææéï¼èç¥ç¶è³ªåç¶å¸¸èè¼ä¸çæ³ççµææéãæ¬æä»ç´¹äºä¸åæ¨¡æ¬æ¶æ§ï¼è©²æ¶æ§ä»¥å·æç¶åäººæ ¼ç¹è³ªçå¤§èªè¨æ¨¡å (LLM) ä»£ççºä¸­å¿ãä»£çå¨è­°å¹é åå§é²è¡è«å¤ï¼ä¸¦ææå¯èªè¨çäººæ ¼åç®æ¨ãå¯¦é©çµæè¡¨æï¼åºæ¼ LLM çæ¨¡æ¬çè¡çºå¾åå¯ä»¥éç¾äººé¡è«å¤ä¸­è§å¯å°çè¡çºæ¨¡å¼ãè²¢ç»æå©åæ¹é¢ãé¦åï¼æåæåºäºä¸ç¨®æ¨¡æ¬æ¹æ³ï¼è©²æ¹æ³ç ç©¶äº LLM ä»£ççèªè¨åç¶æ¿è½åä¹éçä¸è´æ§ãå¶æ¬¡ï¼æåæä¾äºéæ¼å¤§äºäººæ ¼ç¹è³ªå°ééè«å¤çµæçç­ç¥æ§å½±é¿çå¯¦è­è¦è§£ãæåéæä¾äºä¸ååºæ¼ç¶åè­°å¹å°è©±çæ¡ä¾ç ç©¶ï¼ä»¥æ­ç¤ºæè¶£çè¡çºï¼åæ¬æ¬ºé¨åå¦¥åè¡çºã

##### **AEMIM: Adversarial Examples Meet Masked Image Modeling**
2407.11537v1 by Wenzhao Xiang, Chang Liu, Hang Su, Hongyang Yu

Masked image modeling (MIM) has gained significant traction for its
remarkable prowess in representation learning. As an alternative to the
traditional approach, the reconstruction from corrupted images has recently
emerged as a promising pretext task. However, the regular corrupted images are
generated using generic generators, often lacking relevance to the specific
reconstruction task involved in pre-training. Hence, reconstruction from
regular corrupted images cannot ensure the difficulty of the pretext task,
potentially leading to a performance decline. Moreover, generating corrupted
images might introduce an extra generator, resulting in a notable computational
burden. To address these issues, we propose to incorporate adversarial examples
into masked image modeling, as the new reconstruction targets. Adversarial
examples, generated online using only the trained models, can directly aim to
disrupt tasks associated with pre-training. Therefore, the incorporation not
only elevates the level of challenge in reconstruction but also enhances
efficiency, contributing to the acquisition of superior representations by the
model. In particular, we introduce a novel auxiliary pretext task that
reconstructs the adversarial examples corresponding to the original images. We
also devise an innovative adversarial attack to craft more suitable adversarial
examples for MIM pre-training. It is noted that our method is not restricted to
specific model architectures and MIM strategies, rendering it an adaptable
plug-in capable of enhancing all MIM methods. Experimental findings
substantiate the remarkable capability of our approach in amplifying the
generalization and robustness of existing MIM methods. Notably, our method
surpasses the performance of baselines on various tasks, including ImageNet,
its variants, and other downstream tasks.

æè¦ï¼<paragraph>é®ç½©å½±åæ¨¡å (MIM) å å¶å¨è¡¨å¾µå­¸ç¿ä¸çé¡¯èè½åèç²å¾æ¥µå¤§çéæ³¨ãä½çºå³çµ±æ¹æ³çæ¿ä»£æ¹æ¡ï¼å¾æå£å½±åä¸­éå»ºæè¿å·²æçºä¸é æåæ¯çé è¨­ä»»åãç¶èï¼ä¸è¬çæå£å½±åä½¿ç¨éç¨ç¢çå¨ç¢çï¼éå¸¸ç¼ºä¹èé è¨ç·´ä¸­æ¶åçç¹å®éå»ºä»»åç¸éæ§ãå æ­¤ï¼å¾ä¸è¬æå£å½±åé²è¡éå»ºç¡æ³ç¢ºä¿é è¨­ä»»åçé£åº¦ï¼å¯è½æå°è´æè½ä¸éãæ­¤å¤ï¼ç¢çæå£å½±åå¯è½æå¼å¥é¡å¤çç¢çå¨ï¼å°è´é¡¯èçéç®è² æãçºäºè§£æ±ºéäºåé¡ï¼æåå»ºè­°å°å°æç¯ä¾ç´å¥é®ç½©å½±åæ¨¡åï¼ä½çºæ°çéå»ºç®æ¨ãå°æç¯ä¾åä½¿ç¨è¨ç·´éçæ¨¡åç·ä¸ç¢çï¼å¯ä»¥ç´æ¥éå°èé è¨ç·´ç¸éçä»»åé²è¡ç ´å£ãå æ­¤ï¼éç¨®ç´å¥ä¸åæåäºéå»ºçææ°é£åº¦ï¼éæé«äºæçï¼æå©æ¼æ¨¡åç²å¾æ´åªè¶çè¡¨å¾µãç¹å¥æ¯ï¼æåå¼å¥äºä¸é æ°ç©çè¼å©é è¨­ä»»åï¼ç¨ä¾éå»ºå°ææ¼åå§å½±åçå°æç¯ä¾ãæåéè¨­è¨äºä¸ç¨®åµæ°çå°ææ»æï¼ç¨æ¼çº MIM é è¨ç·´è£½ä½æ´åé©çå°æç¯ä¾ãè«æ³¨æï¼æåçæ¹æ³ä¸åç¹å®æ¨¡åæ¶æ§å MIM ç­ç¥çéå¶ï¼ä½¿å¶æçºä¸ç¨®é©ææ§å¤æç¨å¼ï¼è½å¤ å¢å¼·ææ MIM æ¹æ³ãå¯¦é©çµæè­å¯¦äºæåçæ¹æ³å¨æ´å¤§ç¾æ MIM æ¹æ³çæ³åè½ååç©©å¥æ§æ¹é¢çé¡¯èè½åãå¼å¾æ³¨æçæ¯ï¼æåçæ¹æ³å¨åç¨®ä»»åä¸çæè½é½è¶è¶äºåºç·ï¼åæ¬ ImageNetãå¶è®é«åå¶ä»ä¸æ¸¸ä»»åã</paragraph>

##### **Fine-Tuning Medical Language Models for Enhanced Long-Contextual Understanding and Domain Expertise**
2407.11536v1 by Qimin Yang, Rongsheng Wang, Jiexin Chen, Runqi Su, Tao Tan

Large Language Models (LLMs) have been widely applied in various professional
fields. By fine-tuning the models using domain specific question and answer
datasets, the professional domain knowledge and Q\&A abilities of these models
have significantly improved, for example, medical professional LLMs that use
fine-tuning of doctor-patient Q\&A data exhibit extraordinary disease
diagnostic abilities. However, we observed that despite improvements in
specific domain knowledge, the performance of medical LLM in long-context
understanding has significantly declined, especially compared to general
language models with similar parameters. The purpose of this study is to
investigate the phenomenon of reduced performance in understanding long-context
in medical LLM. We designed a series of experiments to conduct open-book
professional knowledge exams on all models to evaluate their ability to read
long-context. By adjusting the proportion and quantity of general data and
medical data in the process of fine-tuning, we can determine the best data
composition to optimize the professional model and achieve a balance between
long-context performance and specific domain knowledge.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å»£æ³æç¨æ¼åç¨®å°æ¥­é åãééä½¿ç¨ç¹å®é åçåç­è³æéå¾®èª¿æ¨¡åï¼éäºæ¨¡åçå°æ¥­é åç¥è­ååç­è½åå·²é¡¯èæåï¼ä¾å¦ï¼ä½¿ç¨é«ç-æ£èåç­è³æé²è¡å¾®èª¿çé«çå°æ¥­ LLM å±ç¾åºéå¡çç¾çè¨ºæ·è½åãç¶èï¼æåè§å¯å°ï¼åç®¡ç¹å®é åç¥è­æææåï¼ä½é«ç LLM å¨é·èªå¢çè§£æ¹é¢çè¡¨ç¾å»å¤§å¹ä¸éï¼å°¤å¶æ¯èå·æé¡ä¼¼åæ¸çä¸è¬èªè¨æ¨¡åç¸æ¯ãæ¬ç ç©¶çç®çæ¯æ¢è¨é«ç LLM å¨çè§£é·èªå¢æ¹é¢çè¡¨ç¾ä¸éç¾è±¡ãæåè¨­è¨äºä¸ç³»åå¯¦é©ï¼å°æææ¨¡åé²è¡éæ¾å¼å°æ¥­ç¥è­èè©¦ï¼ä»¥è©ä¼°å®åé±è®é·èªå¢ççè§£è½åãééèª¿æ´å¾®èª¿éç¨ä¸­ä¸è¬è³æåé«çè³æçæ¯ä¾åæ¸éï¼æåå¯ä»¥ç¢ºå®æä½³è³æçµåï¼ä»¥åªåå°æ¥­æ¨¡åï¼ä¸¦å¨é·èªå¢è¡¨ç¾åç¹å®é åç¥è­ä¹éåå¾å¹³è¡¡ã

##### **LRQ: Optimizing Post-Training Quantization for Large Language Models by Learning Low-Rank Weight-Scaling Matrices**
2407.11534v1 by Jung Hyun Lee, Jeonghoon Kim, June Yong Yang, Se Jung Kwon, Eunho Yang, Kang Min Yoo, Dongsoo Lee

With the commercialization of large language models (LLMs), weight-activation
quantization has emerged to compress and accelerate LLMs, achieving high
throughput while reducing inference costs. However, existing post-training
quantization (PTQ) techniques for quantizing weights and activations of LLMs
still suffer from non-negligible accuracy drops, especially on massive
multitask language understanding. To address this issue, we propose Low-Rank
Quantization (LRQ) $-$ a simple yet effective post-training weight quantization
method for LLMs that reconstructs the outputs of an intermediate Transformer
block by leveraging low-rank weight-scaling matrices, replacing the
conventional full weight-scaling matrices that entail as many learnable scales
as their associated weights. Thanks to parameter sharing via low-rank
structure, LRQ only needs to learn significantly fewer parameters while
enabling the individual scaling of weights, thus boosting the generalization
capability of quantized LLMs. We show the superiority of LRQ over prior LLM PTQ
works under (i) $8$-bit weight and per-tensor activation quantization, (ii)
$4$-bit weight and $8$-bit per-token activation quantization, and (iii) low-bit
weight-only quantization schemes. Our code is available at
\url{https://github.com/onliwad101/FlexRound_LRQ} to inspire LLM researchers
and engineers.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡åï¼LLMï¼åæ¥­åï¼æ¬éæ´»åéåæéèçï¼ç¨æ¼å£ç¸®åå é LLMï¼å¨éä½æ¨çææ¬çåæå¯¦ç¾é«ååéãç¶èï¼ç¾æç LLM æ¬éåæ´»åéåçè¨ç·´å¾éåï¼PTQï¼æè¡ä»ç¶æå°è´éå¯å¿½ç¥çæºç¢ºåº¦ä¸éï¼ç¹å¥æ¯å¨å¤§è¦æ¨¡å¤ä»»åèªè¨çè§£ä¸ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä½ç§©éåï¼LRQï¼$-$ä¸ç¨®ç°¡å®ä½ææç LLM è¨ç·´å¾æ¬ééåæ¹æ³ï¼å®ééå©ç¨ä½ç§©æ¬éç¸®æ¾ç©é£ä¾éå»ºä¸­é Transformer å¡çè¼¸åºï¼åä»£äºåå«èå¶éè¯æ¬éä¸æ¨£å¤å¯å­¸ç¿ç¸®æ¾çå³çµ±å¨æ¬éç¸®æ¾ç©é£ãç±æ¼ééä½ç§©çµæ§å±äº«åæ¸ï¼LRQ åªéå­¸ç¿é¡¯èæ´å°çåæ¸ï¼åæåç¨æ¬éçåå¥ç¸®æ¾ï¼å¾èæåéå LLM çæ³åè½åãæåå±ç¤ºäº LRQ å¨ä»¥ä¸ææ³ä¸åªæ¼ååç LLM PTQ å·¥ä½ï¼(i) 8 ä½åæ¬éåæ¯åå¼µéæ´»åéåï¼(ii) 4 ä½åæ¬éå 8 ä½åæ¯åç¬¦èæ´»åéåï¼ä»¥å (iii) ä½ä½ååæ¬ééåæ¹æ¡ãæåçç¨å¼ç¢¼å¯å¨ \url{https://github.com/onliwad101/FlexRound_LRQ} åå¾ï¼ä»¥åç¼ LLM ç ç©¶äººå¡åå·¥ç¨å¸«ã

##### **Reasoning with Large Language Models, a Survey**
2407.11511v1 by Aske Plaat, Annie Wong, Suzan Verberne, Joost Broekens, Niki van Stein, Thomas Back

Scaling up language models to billions of parameters has opened up
possibilities for in-context learning, allowing instruction tuning and few-shot
learning on tasks that the model was not specifically trained for. This has
achieved breakthrough performance on language tasks such as translation,
summarization, and question-answering. Furthermore, in addition to these
associative "System 1" tasks, recent advances in Chain-of-thought prompt
learning have demonstrated strong "System 2" reasoning abilities, answering a
question in the field of artificial general intelligence whether LLMs can
reason. The field started with the question whether LLMs can solve grade school
math word problems. This paper reviews the rapidly expanding field of
prompt-based reasoning with LLMs. Our taxonomy identifies different ways to
generate, evaluate, and control multi-step reasoning. We provide an in-depth
coverage of core approaches and open problems, and we propose a research agenda
for the near future. Finally, we highlight the relation between reasoning and
prompt-based learning, and we discuss the relation between reasoning,
sequential decision processes, and reinforcement learning. We find that
self-improvement, self-reflection, and some metacognitive abilities of the
reasoning processes are possible through the judicious use of prompts. True
self-improvement and self-reasoning, to go from reasoning with LLMs to
reasoning by LLMs, remains future work.

æè¦ï¼<paragraph>å°èªè¨æ¨¡åæ´å±å°æ¸ååååæ¸éåäºæå¢å­¸ç¿çå¯è½æ§ï¼åè¨±å°æ¨¡åæªç¶ç¹å¥è¨ç·´çä»»åé²è¡æä»¤èª¿æ´åå°éå­¸ç¿ãéå¨ç¿»è­¯ãæè¦ååç­ç­èªè¨ä»»åä¸å¯¦ç¾äºçªç ´æ§çè¡¨ç¾ãæ­¤å¤ï¼é¤äºéäºè¯æ³å¼çãç³»çµ± 1ãä»»åä¹å¤ï¼æèéæç¤ºå­¸ç¿çææ°é²å±å±ç¤ºäºå¼·å¤§çãç³»çµ± 2ãæ¨çè½åï¼åç­äºäººå·¥éç¨æºæ§é åä¸­ LLM æ¯å¦å¯ä»¥æ¨ççåé¡ãè©²é åå§æ¼ LLM æ¯å¦è½è§£æ±ºå°å­¸æ¸å­¸æå­é¡çåé¡ãæ¬æåé¡§äº LLM æç¤ºå¼æ¨çå¿«éæ´å±çé åãæåçåé¡æ³è­å¥äºçæãè©ä¼°åæ§å¶å¤æ­¥é©æ¨ççä¸åæ¹æ³ãæåæ·±å¥æ¢è¨äºæ ¸å¿æ¹æ³åéæ¾æ§åé¡ï¼ä¸¦æåºäºè¿æç ç©¶è­°ç¨ãæå¾ï¼æåå¼·èª¿äºæ¨çåæç¤ºå¼å­¸ç¿ä¹éçéä¿ï¼ä¸¦è¨è«äºæ¨çãåºåæ±ºç­éç¨åå¼·åå­¸ç¿ä¹éçéä¿ãæåç¼ç¾ï¼ééææºå°ä½¿ç¨æç¤ºï¼æ¨çéç¨çèªå®åãèªæåæåä¸äºåèªç¥è½åæ¯å¯è½çãçæ­£çèªæå®ååèªææ¨çï¼å¾ä½¿ç¨ LLM æ¨çè½è®çºç± LLM æ¨çï¼ä»ç¶æ¯æªä¾çç ç©¶å·¥ä½ã</paragraph>

##### **Diff-MTS: Temporal-Augmented Conditional Diffusion-based AIGC for Industrial Time Series Towards the Large Model Era**
2407.11501v1 by Lei Ren, Haiteng Wang, Yuanjun Laili

Industrial Multivariate Time Series (MTS) is a critical view of the
industrial field for people to understand the state of machines. However, due
to data collection difficulty and privacy concerns, available data for building
industrial intelligence and industrial large models is far from sufficient.
Therefore, industrial time series data generation is of great importance.
Existing research usually applies Generative Adversarial Networks (GANs) to
generate MTS. However, GANs suffer from unstable training process due to the
joint training of the generator and discriminator. This paper proposes a
temporal-augmented conditional adaptive diffusion model, termed Diff-MTS, for
MTS generation. It aims to better handle the complex temporal dependencies and
dynamics of MTS data. Specifically, a conditional Adaptive Maximum-Mean
Discrepancy (Ada-MMD) method has been proposed for the controlled generation of
MTS, which does not require a classifier to control the generation. It improves
the condition consistency of the diffusion model. Moreover, a Temporal
Decomposition Reconstruction UNet (TDR-UNet) is established to capture complex
temporal patterns and further improve the quality of the synthetic time series.
Comprehensive experiments on the C-MAPSS and FEMTO datasets demonstrate that
the proposed Diff-MTS performs substantially better in terms of diversity,
fidelity, and utility compared with GAN-based methods. These results show that
Diff-MTS facilitates the generation of industrial data, contributing to
intelligent maintenance and the construction of industrial large models.

æè¦ï¼å·¥æ¥­å¤åæéåºå (MTS) æ¯å·¥æ¥­é åä¸­ééµçè§é»ï¼è®äººåäºè§£æ©å¨çæãç¶èï¼ç±æ¼è³ææ¶éå°é£åé±ç§åé¡ï¼å¯ç¨æ¼å»ºç«å·¥æ¥­æºæ§åå·¥æ¥­å¤§åæ¨¡åçè³æé é ä¸è¶³ãå æ­¤ï¼å·¥æ¥­æéåºåè³æçæéå¸¸éè¦ãç¾æç ç©¶éå¸¸æç¨çæå°æç¶²è·¯ (GAN) ä¾ç¢ç MTSãç¶èï¼ç±æ¼çæå¨åéå¥å¨çè¯åè¨ç·´ï¼GAN è¨ç·´éç¨ä¸ç©©å®ãæ¬ææåºäºä¸åæéå¢å¼·æ¢ä»¶é©ææ´æ£æ¨¡åï¼ç¨±çº Diff-MTSï¼ç¨æ¼ MTS çæãå®æ¨å¨æ´å¥½å°èç MTS è³æçè¤éæéä¾è³´æ§ååææ§ãå·é«ä¾èªªï¼æåºäºä¸åæ¢ä»¶é©ææå¤§åå¼å·®ç° (Ada-MMD) æ¹æ³ï¼ç¨æ¼åæ§çæ MTSï¼å®ä¸éè¦åé¡å¨ä¾æ§å¶çæãå®æ¹é²äºæ´æ£æ¨¡åçæ¢ä»¶ä¸è´æ§ãæ­¤å¤ï¼å»ºç«äºä¸åæéåè§£éå»º UNet (TDR-UNet) ä¾ææè¤éçæéæ¨¡å¼ï¼ä¸¦é²ä¸æ­¥æé«åææéåºåçåè³ªãå¨ C-MAPSS å FEMTO è³æéä¸çç¶åå¯¦é©è¡¨æï¼èåºæ¼ GAN çæ¹æ³ç¸æ¯ï¼ææåºç Diff-MTS å¨å¤æ¨£æ§ãä¿çåº¦åæç¨æ¹é¢è¡¨ç¾å¾é¡¯èæ´å¥½ãéäºçµæè¡¨æï¼Diff-MTS ä¿é²äºå·¥æ¥­è³æççæï¼æå©æ¼æºæ§ç¶­è­·åå·¥æ¥­å¤§åæ¨¡åçæ§å»ºã

##### **An AI System for Continuous Knee Osteoarthritis Severity Grading Using Self-Supervised Anomaly Detection with Limited Data**
2407.11500v1 by Niamh Belton, Aonghus Lawlor, Kathleen M. Curran

The diagnostic accuracy and subjectivity of existing Knee Osteoarthritis (OA)
ordinal grading systems has been a subject of on-going debate and concern.
Existing automated solutions are trained to emulate these imperfect systems,
whilst also being reliant on large annotated databases for fully-supervised
training. This work proposes a three stage approach for automated continuous
grading of knee OA that is built upon the principles of Anomaly Detection (AD);
learning a robust representation of healthy knee X-rays and grading disease
severity based on its distance to the centre of normality. In the first stage,
SS-FewSOME is proposed, a self-supervised AD technique that learns the 'normal'
representation, requiring only examples of healthy subjects and <3% of the
labels that existing methods require. In the second stage, this model is used
to pseudo label a subset of unlabelled data as 'normal' or 'anomalous',
followed by denoising of pseudo labels with CLIP. The final stage involves
retraining on labelled and pseudo labelled data using the proposed Dual Centre
Representation Learning (DCRL) which learns the centres of two representation
spaces; normal and anomalous. Disease severity is then graded based on the
distance to the learned centres. The proposed methodology outperforms existing
techniques by margins of up to 24% in terms of OA detection and the disease
severity scores correlate with the Kellgren-Lawrence grading system at the same
level as human expert performance. Code available at
https://github.com/niamhbelton/SS-FewSOME_Disease_Severity_Knee_Osteoarthritis.

æè¦ï¼ç¾æèéª¨éç¯ç (OA)
åºæ¸åç´ç³»çµ±çè¨ºæ·æºç¢ºåº¦åä¸»è§æ§ä¸ç´æ¯æçºç­è«åéæ³¨çä¸»é¡ã
ç¾æçèªååè§£æ±ºæ¹æ¡ç¶éè¨ç·´ä»¥æ¨¡æ¬éäºä¸å®ç¾çç³»çµ±ï¼
åæä¹ä¾è³´æ¼å¤§åè¨»éè³æåº«é²è¡å®å¨ç£ç£ç
è¨ç·´ãéé å·¥ä½æåºäºä¸åä¸éæ®µæ¹æ³ï¼ç¨æ¼èéª¨éç¯ççèªåé£çº
åç´ï¼è©²æ¹æ³å»ºç«å¨ç°å¸¸æª¢æ¸¬ (AD) çåçä¹ä¸ï¼
å­¸ç¿å¥åº·èè X åççç©©å¥è¡¨ç¾ï¼ä¸¦æ ¹æå¶èå¸¸æä¸­å¿çè·é¢å°ç¾ç
å´éç¨åº¦é²è¡åç´ãå¨ç¬¬ä¸éæ®µï¼
SS-FewSOME è¢«æåºï¼éæ¯ä¸ç¨®èªç£ç£ AD æè¡ï¼å®å­¸ç¿ãæ­£å¸¸ã
è¡¨ç¾ï¼åªéè¦å¥åº·åè©¦èçç¯ä¾å <3% ç¾ææ¹æ³æéç
æ¨ç±¤ãå¨ç¬¬äºéæ®µï¼æ­¤æ¨¡åç¨æ¼å°æªæ¨è¨è³æçå­éå½æ¨è¨çºãæ­£å¸¸ãæãç°å¸¸ãï¼
æ¥èä½¿ç¨ CLIP å°å½æ¨ç±¤é²è¡å»éè¨ãæå¾çéæ®µæ¶å
ä½¿ç¨æåºçéä¸­å¿è¡¨ç¤ºå­¸ç¿ (DCRL) å°æ¨è¨åå½æ¨è¨è³æé²è¡éæ°è¨ç·´ï¼è©²å­¸ç¿å­¸ç¿å©åè¡¨ç¤º
ç©ºéçä¸­å¿ï¼æ­£å¸¸åç°å¸¸ãç¶å¾æ ¹æ
å­¸ç¿ä¸­å¿ä¹éçè·é¢å°ç¾çå´éç¨åº¦é²è¡åç´ãææåºçæ¹æ³å¨ OA æª¢æ¸¬æ¹é¢æ¯ç¾æ
æè¡é«åº 24%ï¼ä¸¦ä¸ç¾ç
å´éç¨åº¦å¾åè Kellgren-Lawrence åç´ç³»çµ±ç¸éï¼èäººé¡å°å®¶è¡¨ç¾ç¸å
ç­ç´ãç¨å¼ç¢¼å¯å¨
https://github.com/niamhbelton/SS-FewSOME_Disease_Severity_Knee_Osteoarthritis åå¾ã

##### **MMSD-Net: Towards Multi-modal Stuttering Detection**
2407.11492v1 by Liangyu Nie, Sudarsana Reddy Kadiri, Ruchit Agrawal

Stuttering is a common speech impediment that is caused by irregular
disruptions in speech production, affecting over 70 million people across the
world. Standard automatic speech processing tools do not take speech ailments
into account and are thereby not able to generate meaningful results when
presented with stuttered speech as input. The automatic detection of stuttering
is an integral step towards building efficient, context-aware speech processing
systems. While previous approaches explore both statistical and neural
approaches for stuttering detection, all of these methods are uni-modal in
nature. This paper presents MMSD-Net, the first multi-modal neural framework
for stuttering detection. Experiments and results demonstrate that
incorporating the visual signal significantly aids stuttering detection, and
our model yields an improvement of 2-17% in the F1-score over existing
state-of-the-art uni-modal approaches.

æè¦ï¼å£åæ¯ä¸ç§å¸¸è§çè¨è¯­éç¢ï¼æ¯ç±è¨è¯­äº§çä¸­çä¸è§åä¸­æ­æå¼èµ·çï¼å½±åäºå¨çè¶è¿ 7000 ä¸äººãæ åçèªå¨è¯­é³å¤çå·¥å·ä¸ä¼èèè¨è¯­éç¢ï¼å æ­¤å¨è¾å¥å£åè¯­é³æ¶æ æ³çæææä¹çç»æãå£åçèªå¨æ£æµæ¯æå»ºé«æä¸å·ææå¢æç¥çè¯­é³å¤çç³»ç»ä¸­ä¸å¯æç¼ºçä¸æ­¥ãè½ç¶ååçåæ³æ¢ç´¢äºç»è®¡åç¥ç»æ¹æ³æ¥è¿è¡å£åæ£æµï¼ä½ææè¿äºæ¹æ³æ¬è´¨ä¸é½æ¯åæ¨¡æçãæ¬ææåºäº MMSD-Netï¼è¿æ¯ç¬¬ä¸ä¸ªç¨äºå£åæ£æµçå¤æ¨¡æç¥ç»æ¡æ¶ãå®éªåç»æè¡¨æï¼ç»åè§è§ä¿¡å·å¯ä»¥æå¤§å°å¸®å©å£åæ£æµï¼å¹¶ä¸æä»¬çæ¨¡åå¨ F1 åæ°ä¸æ¯ç°æçæåè¿çåæ¨¡ææ¹æ³æé«äº 2-17%ã

##### **A Meta-Learning Approach for Multi-Objective Reinforcement Learning in Sustainable Home Environments**
2407.11489v1 by Junlin Lu, Patrick Mannion, Karl Mason

Effective residential appliance scheduling is crucial for sustainable living.
While multi-objective reinforcement learning (MORL) has proven effective in
balancing user preferences in appliance scheduling, traditional MORL struggles
with limited data in non-stationary residential settings characterized by
renewable generation variations. Significant context shifts that can invalidate
previously learned policies. To address these challenges, we extend
state-of-the-art MORL algorithms with the meta-learning paradigm, enabling
rapid, few-shot adaptation to shifting contexts. Additionally, we employ an
auto-encoder (AE)-based unsupervised method to detect environment context
changes. We have also developed a residential energy environment to evaluate
our method using real-world data from London residential settings. This study
not only assesses the application of MORL in residential appliance scheduling
but also underscores the effectiveness of meta-learning in energy management.
Our top-performing method significantly surpasses the best baseline, while the
trained model saves 3.28% on electricity bills, a 2.74% increase in user
comfort, and a 5.9% improvement in expected utility. Additionally, it reduces
the sparsity of solutions by 62.44%. Remarkably, these gains were accomplished
using 96.71% less training data and 61.1% fewer training steps.

æè¦ï¼ææä½å®è¨­åæç¨å°æ¼æ°¸çºçæ´»è³ééè¦ã
éç¶å¤ç®æ¨å¢å¼·å­¸ç¿ (MORL) å·²è¢«è­æè½ææå¹³è¡¡è¨­åæç¨ä¸­çä½¿ç¨èåå¥½ï¼ä½å³çµ± MORL å¨ä»¥åçè½æºè®åçºç¹å¾µçééæ­¢ä½å®ç°å¢ä¸­ï¼æå è³ææéèéå°å°é£ãéå¤§çæå¢è½è®å¯è½æä½¿ååå­¸ç¿çæ¿ç­å¤±æãçºäºæå°éäºææ°ï¼æåä½¿ç¨åå­¸ç¿ç¯ä¾ä¾æ´åæåé²ç MORL æ¼ç®æ³ï¼å¯¦ç¾å¿«éãå°éé©æè®åçæå¢ãæ­¤å¤ï¼æåæ¡ç¨åºæ¼èªåç·¨ç¢¼å¨ (AE) çéç£ç£å¼æ¹æ³ä¾åµæ¸¬ç°å¢æå¢è®åãæåééç¼äºä¸åä½å®è½æºç°å¢ï¼ä½¿ç¨ä¾èªå«æ¦ä½å®ç°å¢ççå¯¦ä¸çè³æä¾è©ä¼°æåçåæ³ãæ¬ç ç©¶ä¸åè©ä¼° MORL å¨ä½å®è¨­åæç¨ä¸­çæç¨ï¼ä¹å¼·èª¿äºåå­¸ç¿å¨è½æºç®¡çä¸­çæææ§ãæåæè½æä½³çæ¹æ³é¡¯èè¶è¶æä½³åºæºï¼èè¨ç·´å¾çæ¨¡åå¯ç¯ç 3.28% çé»è²»ãä½¿ç¨èèé©åº¦æé« 2.74%ï¼é ææç¨æ¹å 5.9%ãæ­¤å¤ï¼å®éå°è§£çç¨çæ§éä½äº 62.44%ãå¼å¾æ³¨æçæ¯ï¼éäºé²å±æ¯ä½¿ç¨å° 96.71% çè¨ç·´è³æåå° 61.1% çè¨ç·´æ­¥é©æéæçã

##### **Scientific QA System with Verifiable Answers**
2407.11485v1 by Adela LjajiÄ, MiloÅ¡ KoÅ¡prdiÄ, Bojana BaÅ¡aragin, Darija Medvecki, Lorenzo Cassano, Nikola MiloÅ¡eviÄ

In this paper, we introduce the VerifAI project, a pioneering open-source
scientific question-answering system, designed to provide answers that are not
only referenced but also automatically vetted and verifiable. The components of
the system are (1) an Information Retrieval system combining semantic and
lexical search techniques over scientific papers (PubMed), (2) a
Retrieval-Augmented Generation (RAG) module using fine-tuned generative model
(Mistral 7B) and retrieved articles to generate claims with references to the
articles from which it was derived, and (3) a Verification engine, based on a
fine-tuned DeBERTa and XLM-RoBERTa models on Natural Language Inference task
using SciFACT dataset. The verification engine cross-checks the generated claim
and the article from which the claim was derived, verifying whether there may
have been any hallucinations in generating the claim. By leveraging the
Information Retrieval and RAG modules, Verif.ai excels in generating factual
information from a vast array of scientific sources. At the same time, the
Verification engine rigorously double-checks this output, ensuring its accuracy
and reliability. This dual-stage process plays a crucial role in acquiring and
confirming factual information, significantly enhancing the information
landscape. Our methodology could significantly enhance scientists'
productivity, concurrently fostering trust in applying generative language
models within scientific domains, where hallucinations and misinformation are
unacceptable.

æè¦ï¼å¨æ¬æä¸­ï¼æåä»ç´¹äº VerifAI è¨ç«ï¼éæ¯ä¸åéåµæ§çéæ¾åå§ç¢¼ç§å­¸åç­ç³»çµ±ï¼æ¨å¨æä¾ä¸åæåèä¾æï¼èä¸ç¶éèªåå¯©æ¥åé©è­çç­æ¡ãè©²ç³»çµ±ççµæé¨åçºï¼(1) ä¸åè³è¨æª¢ç´¢ç³»çµ±ï¼çµåèªæåè©å½æå°æè¡ï¼ç¨æ¼ç§å­¸è«æ(PubMed)ï¼(2) ä¸åæª¢ç´¢å¢å¼·çæ (RAG) æ¨¡çµï¼ä½¿ç¨å¾®èª¿çææ¨¡å (Mistral 7B) åæª¢ç´¢çæç« ï¼ééå¼è¿°æç« çæä¸»å¼µï¼(3) ä¸åé©è­å¼æï¼åºæ¼å¾®èª¿ç DeBERTa å XLM-RoBERTa æ¨¡åï¼ä½¿ç¨ SciFACT è³æéé²è¡èªç¶èªè¨æ¨è«ä»»åãé©è­å¼æäº¤åæ¯å°ç¢ççä¸»å¼µåä¸»å¼µè¡ççæç« ï¼é©è­å¨ç¢çä¸»å¼µææ¯å¦åºç¾ä»»ä½å¹»è¦ºãééå©ç¨è³è¨æª¢ç´¢å RAG æ¨¡çµï¼Verif.ai æé·å¾å¤§éçç§å­¸ä¾æºç¢çäºå¯¦è³è¨ãåæï¼é©è­å¼æå´æ ¼å°å°æ­¤è¼¸åºé²è¡ééæª¢æ¥ï¼ç¢ºä¿å¶æºç¢ºæ§åå¯é æ§ãéåééæ®µæµç¨å¨ç²ååç¢ºèªäºå¯¦è³è¨ä¸­ç¼æ®ééµä½ç¨ï¼å¤§å¹æåè³è¨ç°å¢ãæåçåæ³å¯ä»¥å¤§å¹æåç§å­¸å®¶ççç¢åï¼åæä¿é²å¨ç§å­¸é åæç¨çæèªè¨æ¨¡åçä¿¡ä»»ï¼å¨è©²é åä¸­å¹»è¦ºåé¯èª¤è³è¨æ¯ä¸å¯æ¥åçã

##### **The Oscars of AI Theater: A Survey on Role-Playing with Language Models**
2407.11484v2 by Nuo Chen, Yang Deng, Jia Li

This survey explores the burgeoning field of role-playing with language
models, focusing on their development from early persona-based models to
advanced character-driven simulations facilitated by Large Language Models
(LLMs). Initially confined to simple persona consistency due to limited model
capabilities, role-playing tasks have now expanded to embrace complex character
portrayals involving character consistency, behavioral alignment, and overall
attractiveness. We provide a comprehensive taxonomy of the critical components
in designing these systems, including data, models and alignment, agent
architecture and evaluation. This survey not only outlines the current
methodologies and challenges, such as managing dynamic personal profiles and
achieving high-level persona consistency but also suggests avenues for future
research in improving the depth and realism of role-playing applications. The
goal is to guide future research by offering a structured overview of current
methodologies and identifying potential areas for improvement. Related
resources and papers are available at
https://github.com/nuochenpku/Awesome-Role-Play-Papers.

æè¦ï¼æ¬èª¿æ¥æ¢è¨äºè§è²æ®æ¼èèªè¨æ¨¡åçæ°èé åï¼éé»éæ³¨å¶å¾æ©æåºæ¼è§è²çæ¨¡åç¼å±å°ç±å¤§åèªè¨æ¨¡å (LLM) ä¿æçé²éè§è²é©åæ¨¡æ¬ãè§è²æ®æ¼ä»»åæååéæ¼ç°¡å®çè§è²ä¸è´æ§ï¼å çºæ¨¡ååè½æéï¼ç¾å¨å·²æ´å±å°åå«è§è²ä¸è´æ§ãè¡çºå°é½åæ´é«å¸å¼åçè¤éè§è²æç¹ªãæåæä¾äºéäºç³»çµ±è¨­è¨ä¸­ééµçµæçå¨é¢åé¡ï¼åæ¬è³æãæ¨¡ååå°é½ãä»£çæ¶æ§åè©ä¼°ãæ¬èª¿æ¥ä¸åæ¦è¿°äºç¶åçæ¹æ³åææ°ï¼ä¾å¦ç®¡çåæåäººæªæ¡åå¯¦ç¾é«éè§è²ä¸è´æ§ï¼éæåºäºæ¹é²è§è²æ®æ¼æç¨æ·±åº¦åçå¯¦æ§çæªä¾ç ç©¶éå¾ãç®æ¨æ¯ééæä¾ç¶åæ¹æ³ççµæ§åæ¦è§åæ¾åºæ½å¨çæ¹é²é åï¼ä¾å¼å°æªä¾çç ç©¶ãç¸éè³æºåè«æå¯æ¼ https://github.com/nuochenpku/Awesome-Role-Play-Papers åå¾ã

##### **Multi-Channel Masked Autoencoder and Comprehensive Evaluations for Reconstructing 12-Lead ECG from Arbitrary Single-Lead ECG**
2407.11481v1 by Jiarong Chen, Wanqing Wu, Tong Liu, Shenda Hong

In the context of cardiovascular diseases (CVD) that exhibit an elevated
prevalence and mortality, the electrocardiogram (ECG) is a popular and standard
diagnostic tool for doctors, commonly utilizing a 12-lead configuration in
clinical practice. However, the 10 electrodes placed on the surface would cause
a lot of inconvenience and discomfort, while the rapidly advancing wearable
devices adopt the reduced-lead or single-lead ECG to reduce discomfort as a
solution in long-term monitoring. Since the single-lead ECG is a subset of
12-lead ECG, it provides insufficient cardiac health information and plays a
substandard role in real-world healthcare applications. Hence, it is necessary
to utilize signal generation technologies to reduce their clinical importance
gap by reconstructing 12-lead ECG from the real single-lead ECG. Specifically,
this study proposes a multi-channel masked autoencoder (MCMA) for this goal. In
the experimental results, the visualized results between the generated and real
signals can demonstrate the effectiveness of the proposed framework. At the
same time, this study introduces a comprehensive evaluation benchmark named
ECGGenEval, encompassing the signal-level, feature-level, and diagnostic-level
evaluations, providing a holistic assessment of 12-lead ECG signals and
generative model. Further, the quantitative experimental results are as
follows, the mean square errors of 0.0178 and 0.0658, correlation coefficients
of 0.7698 and 0.7237 in the signal-level evaluation, the average F1-score with
two generated 12-lead ECG is 0.8319 and 0.7824 in the diagnostic-level
evaluation, achieving the state-of-the-art performance. The open-source code is
publicly available at \url{https://github.com/CHENJIAR3/MCMA}.

æè¦ï¼<paragraph>å¨è¡¨ç¾åºé«çè¡çåæ­»äº¡ççå¿è¡ç®¡ç¾ç (CVD) çææ³ä¸ï¼å¿é»å (ECG) æ¯ä¸ç¨®é«çå¸¸ç¨çæ¨æºè¨ºæ·å·¥å·ï¼å¨è¨åºå¯¦åä¸­éå¸¸ä½¿ç¨ 12 å°ç¨çµæãç¶èï¼æ¾ç½®å¨è¡¨é¢ç 10 åé»æ¥µæé æè¨±å¤ä¸ä¾¿åä¸é©ï¼èå¿«éé²æ­¥çå¯ç©¿æ´å¼è£ç½®æ¡ç¨æ¸å°å°ç¨æå®å°ç¨ ECG ä¾éä½ä¸é©ï¼ä½çºé·æç£æ¸¬çè§£æ±ºæ¹æ¡ãç±æ¼å®å°ç¨ ECG æ¯ 12 å°ç¨ ECG çå­éï¼å®æä¾çå¥åº·è³è¨ä¸è¶³ï¼å¨çå¯¦ä¸ççé«çä¿å¥æç¨ä¸­æ®æ¼èæ¬¡æ¨æºçè§è²ãå æ­¤ï¼æå¿è¦å©ç¨è¨èç¢çæè¡ä¾ç¸®å°å¶è¨åºéè¦æ§å·®è·ï¼æ¹æ³æ¯å¾çå¯¦çå®å°ç¨ ECG éå»º 12 å°ç¨ ECGãå·é«ä¾èªªï¼æ¬ç ç©¶æåºäºä¸åå¤ééé®ç½©èªåç·¨ç¢¼å¨ (MCMA) ä¾éææ­¤ç®æ¨ãå¨å¯¦é©çµæä¸­ï¼çæçè¨èèçå¯¦è¨èä¹éçå¯è¦åçµæå¯ä»¥è­æææåºæ¶æ§çæææ§ãåæï¼æ¬ç ç©¶å¼å¥äºç¨±çº ECGGenEval çç¶åè©ä¼°åºæºï¼æ¶µèè¨èå±¤ç´ãç¹å¾µå±¤ç´åè¨ºæ·å±¤ç´è©ä¼°ï¼æä¾ 12 å°ç¨ ECG è¨èåçææ¨¡åçæ´é«è©ä¼°ãæ­¤å¤ï¼å®éçå¯¦é©çµæå¦ä¸ï¼å¨è¨èå±¤ç´è©ä¼°ä¸­ï¼åæ¹èª¤å·®çº 0.0178 å 0.0658ï¼ç¸éä¿æ¸çº 0.7698 å 0.7237ï¼å¨è¨ºæ·å±¤ç´è©ä¼°ä¸­ï¼å©åçæç 12 å°ç¨ ECG çå¹³å F1 åæ¸çº 0.8319 å 0.7824ï¼éå°äºæåé²çæè½ãéæ¾åå§ç¢¼å¯ä»¥å¨ \url{https://github.com/CHENJIAR3/MCMA} å¬éåå¾ã</paragraph>

##### **AIGC for Industrial Time Series: From Deep Generative Models to Large Generative Models**
2407.11480v1 by Lei Ren, Haiteng Wang, Yang Tang, Chunhua Yang

With the remarkable success of generative models like ChatGPT, Artificial
Intelligence Generated Content (AIGC) is undergoing explosive development. Not
limited to text and images, generative models can generate industrial time
series data, addressing challenges such as the difficulty of data collection
and data annotation. Due to their outstanding generation ability, they have
been widely used in Internet of Things, metaverse, and cyber-physical-social
systems to enhance the efficiency of industrial production. In this paper, we
present a comprehensive overview of generative models for industrial time
series from deep generative models (DGMs) to large generative models (LGMs).
First, a DGM-based AIGC framework is proposed for industrial time series
generation. Within this framework, we survey advanced industrial DGMs and
present a multi-perspective categorization. Furthermore, we systematically
analyze the critical technologies required to construct industrial LGMs from
four aspects: large-scale industrial dataset, LGMs architecture for complex
industrial characteristics, self-supervised training for industrial time
series, and fine-tuning of industrial downstream tasks. Finally, we conclude
the challenges and future directions to enable the development of generative
models in industry.

æè¦ï¼é¨è ChatGPT ç­çæå¼æ¨¡åçé¡¯èæåï¼äººå·¥æºæ§çæå§å®¹ (AIGC) æ­£ç¶æ­·çç¸æ§çç¼å±ãçæå¼æ¨¡åä¸åéæ¼æå­åå½±åï¼éè½çæå·¥æ¥­æéåºåè³æï¼è§£æ±ºè³ææ¶éåè³ææ¨è¨»çå°é£ç­ææ°ãç±æ¼å¶åºè²ççæè½åï¼å·²å»£æ³æç¨æ¼ç©è¯ç¶²ãåå®å®åç¶²è·¯ç©çç¤¾æç³»çµ±ä¸­ï¼ä»¥æé«å·¥æ¥­çç¢çæçãå¨æ¬æä¸­ï¼æåå°å·¥æ¥­æéåºåççæå¼æ¨¡åé²è¡äºå¨é¢çæ¦è¿°ï¼å¾æ·±åº¦çæå¼æ¨¡å (DGM) å°å¤§åçæå¼æ¨¡å (LGM)ãé¦åï¼æåºäºä¸ååºæ¼ DGM ç AIGC æ¶æ§ï¼ç¨æ¼çæå·¥æ¥­æéåºåãå¨éåæ¶æ§ä¸­ï¼æåèª¿æ¥äºåé²çå·¥æ¥­ DGMï¼ä¸¦æåºäºå¤è§åº¦åé¡ãæ­¤å¤ï¼æåå¾å¤§åå·¥æ¥­è³æéãè¤éå·¥æ¥­ç¹å¾µç LGM æ¶æ§ãå·¥æ¥­æéåºåçèªç£ç£è¨ç·´åå·¥æ¥­ä¸æ¸¸ä»»åçå¾®èª¿ç­ååæ¹é¢ï¼ç³»çµ±å°åæäºæ§å»ºå·¥æ¥­ LGM æéçééµæè¡ãæå¾ï¼æåç¸½çµäºææ°åæªä¾çæ¹åï¼ä»¥ä¿é²çæå¼æ¨¡åå¨å·¥æ¥­ä¸­çç¼å±ã

##### **XTraffic: A Dataset Where Traffic Meets Incidents with Explainability and More**
2407.11477v1 by Xiaochuan Gou, Ziyue Li, Tian Lan, Junpeng Lin, Zhishuai Li, Bingyu Zhao, Chen Zhang, Di Wang, Xiangliang Zhang

Long-separated research has been conducted on two highly correlated tracks:
traffic and incidents. Traffic track witnesses complicating deep learning
models, e.g., to push the prediction a few percent more accurate, and the
incident track only studies the incidents alone, e.g., to infer the incident
risk. We, for the first time, spatiotemporally aligned the two tracks in a
large-scale region (16,972 traffic nodes) over the whole year of 2023: our
XTraffic dataset includes traffic, i.e., time-series indexes on traffic flow,
lane occupancy, and average vehicle speed, and incidents, whose records are
spatiotemporally-aligned with traffic data, with seven different incident
classes. Additionally, each node includes detailed physical and policy-level
meta-attributes of lanes. Our data can revolutionalize traditional
traffic-related tasks towards higher interpretability and practice: instead of
traditional prediction or classification tasks, we conduct: (1) post-incident
traffic forecasting to quantify the impact of different incidents on traffic
indexes; (2) incident classification using traffic indexes to determine the
incidents types for precautions measures; (3) global causal analysis among the
traffic indexes, meta-attributes, and incidents to give high-level guidance of
the interrelations of various factors; (4) local causal analysis within road
nodes to examine how different incidents affect the road segments' relations.
The dataset is available at http://xaitraffic.github.io.

æè¦ï¼<paragraph>é·æä»¥ä¾ï¼éå°å©åé«åº¦ç¸éçè»éé²è¡äºåéçç ç©¶ï¼
äº¤éåäºæãäº¤éè»éè¦è­äºè¤éçæ·±åº¦å­¸ç¿
æ¨¡åï¼ä¾å¦ï¼å°é æ¸¬åæé«å¹¾åç¾åé»çæºç¢ºåº¦ï¼è
äºæè»éåç ç©¶å®ç¨çäºæï¼ä¾å¦ï¼æ¨è«äºæ
é¢¨éªãæåé¦æ¬¡å¨
å¤§è¦æ¨¡ååï¼16,972 åäº¤éç¯é»ï¼ä¸­æç©ºå°é½äºéå©åè»é
2023 å¹´å¨å¹´ï¼æåç
XTraffic æ¸æéåæ¬äº¤éï¼å³äº¤éæµéçæéåºåç´¢å¼ï¼
è»éå ç¨çåå¹³åè»éï¼ä»¥åäºæï¼å¶è¨éèäº¤éæ¸æå¨æç©ºä¸­å°é½ï¼æä¸åä¸åçäºæ
é¡å¥ãæ­¤å¤ï¼æ¯åç¯é»é½åå«è»éçè©³ç´°ç©çåæ¿ç­ç´
åå±¬æ§ãæåçæ¸æå¯ä»¥å¾¹åºæ¹è®å³çµ±ç
èäº¤éç¸éçä»»åï¼æé«å¯è§£éæ§åå¯¦è¸æ§ï¼èä¸æ¯
å³çµ±çé æ¸¬æåé¡ä»»åï¼æåé²è¡ï¼(1) äºå¾äºæ
äº¤éé æ¸¬ï¼ä»¥éåä¸åäºæå°äº¤éçå½±é¿
ç´¢å¼ï¼(2) ä½¿ç¨äº¤éç´¢å¼çäºæåé¡ï¼ä»¥ç¢ºå®äºæ
é é²æªæ½çé¡åï¼(3) äº¤éç´¢å¼ä¹éçå¨å±å æåæï¼
åå±¬æ§åäºæï¼ä»¥æä¾åç¨®å ç´ ç¸äºéä¿çé«ç´æå°ï¼(4) éè·¯å§çå±é¨å æåæ
ç¯é»ï¼ä»¥æª¢æ¥ä¸åäºæå¦ä½å½±é¿éè·¯è·¯æ®µçéä¿ã
è©²æ¸æéå¯å¨ http://xaitraffic.github.io ä¸ç²å¾ã</paragraph>

##### **DynSyn: Dynamical Synergistic Representation for Efficient Learning and Control in Overactuated Embodied Systems**
2407.11472v1 by Kaibo He, Chenhui Zuo, Chengtian Ma, Yanan Sui

Learning an effective policy to control high-dimensional, overactuated
systems is a significant challenge for deep reinforcement learning algorithms.
Such control scenarios are often observed in the neural control of vertebrate
musculoskeletal systems. The study of these control mechanisms will provide
insights into the control of high-dimensional, overactuated systems. The
coordination of actuators, known as muscle synergies in neuromechanics, is
considered a presumptive mechanism that simplifies the generation of motor
commands. The dynamical structure of a system is the basis of its function,
allowing us to derive a synergistic representation of actuators. Motivated by
this theory, we propose the Dynamical Synergistic Representation (DynSyn)
algorithm. DynSyn aims to generate synergistic representations from dynamical
structures and perform task-specific, state-dependent adaptation to the
representations to improve motor control. We demonstrate DynSyn's efficiency
across various tasks involving different musculoskeletal models, achieving
state-of-the-art sample efficiency and robustness compared to baseline
algorithms. DynSyn generates interpretable synergistic representations that
capture the essential features of dynamical structures and demonstrates
generalizability across diverse motor tasks.

æè¦ï¼å­¸ç¿ä¸åææç­ç¥ä¾æ§å¶é«ç¶­åº¦ãéåº¦é©åçç³»çµ±ï¼å°æ¼æ·±åº¦å¼·åå­¸ç¿æ¼ç®æ³ä¾èªªæ¯ä¸åéå¤§çææ°ã
éç¨®æ§å¶å ´æ¯éå¸¸å¨èæ¤åç©èèéª¨éª¼ç³»çµ±çç¥ç¶æ§å¶ä¸­è§å¯å°ã
å°éäºæ§å¶æ©å¶çæ¢è¨ï¼å°æä¾å°é«ç¶­åº¦ãéåº¦é©åç³»çµ±æ§å¶çè¦è§£ã
å¨ç¥ç¶åå­¸ä¸­ç¨±çºèèååä½ç¨çè´åå¨åèª¿ï¼è¢«èªçºæ¯ä¸ç¨®ç°¡åéåæä»¤ç¢ççåè¨­æ©å¶ã
ç³»çµ±çåæçµæ§æ¯å¶åè½çåºç¤ï¼ä½¿æåè½å¤ æ¨å°åºè´åå¨çååè¡¨ç¤ºã
åå°éåçè«çåç¼ï¼æåæåºäºåæååè¡¨ç¤º (DynSyn) æ¼ç®æ³ã
DynSyn æ¨å¨å¾åæçµæ§ä¸­ç¢çååè¡¨ç¤ºï¼ä¸¦å°è¡¨ç¤ºå·è¡ç¹å®æ¼ä»»åççæä¾è³´æ§é©æï¼ä»¥æ¹åéåæ§å¶ã
æåå±ç¤ºäº DynSyn å¨æ¶åä¸åèèéª¨éª¼æ¨¡åçåç¨®ä»»åä¸­çæçï¼èåºç·æ¼ç®æ³ç¸æ¯ï¼éå°äºæåé²çæ¨£æ¬æçåç©©å¥æ§ã
DynSyn ç¢çå¯è§£éçååè¡¨ç¤ºï¼ææåæçµæ§çæ¬è³ªç¹å¾µï¼ä¸¦å±ç¤ºäºè·¨ä¸åéåä»»åçæ³åæ§ã

##### **Beyond Correctness: Benchmarking Multi-dimensional Code Generation for Large Language Models**
2407.11470v1 by Jiasheng Zheng, Boxi Cao, Zhengzhao Ma, Ruotong Pan, Hongyu Lin, Yaojie Lu, Xianpei Han, Le Sun

In recent years, researchers have proposed numerous benchmarks to evaluate
the impressive coding capabilities of large language models (LLMs). However,
existing benchmarks primarily focus on assessing the correctness of code
generated by LLMs, while neglecting other critical dimensions that also
significantly impact code quality. Therefore, this paper proposes the RACE
benchmark, which comprehensively evaluates the quality of code generated by
LLMs across 4 dimensions: Readability, mAintainability, Correctness, and
Efficiency. Specifically, considering the demand-dependent nature of dimensions
beyond correctness, we design various types of user requirements for each
dimension to assess the model's ability to generate correct code that also
meets user demands. We evaluate 18 representative LLMs on RACE and find that:
1) the current LLMs' ability to generate high-quality code on demand does not
yet meet the requirements of software development; 2) readability serves as a
critical indicator of the overall quality of generated code; 3) most LLMs
exhibit an inherent preference for specific coding style. These findings can
help researchers gain a deeper understanding of the coding capabilities of
current LLMs and shed light on future directions for model improvement.

æè¦ï¼è¿å¹´æ¥ï¼ç ç©¶äººåæåºäºè®¸å¤åºåæ¥è¯ä¼°å¤§åè¯­è¨æ¨¡å (LLM) ä»¤äººå°è±¡æ·±å»çç¼ç è½åãç¶èï¼ç°æçåºåä¸»è¦ä¾§éäºè¯ä¼° LLM çæçä»£ç çæ­£ç¡®æ§ï¼èå¿½ç¥äºå¶ä»ä¹æ¾èå½±åä»£ç è´¨éçå³é®ç»´åº¦ãå æ­¤ï¼æ¬ææåºäº RACE åºåï¼å®å¨é¢è¯ä¼°äº LLM çæçä»£ç å¨ 4 ä¸ªç»´åº¦ä¸çè´¨éï¼å¯è¯»æ§ãå¯ç»´æ¤æ§ãæ­£ç¡®æ§åæçãå·ä½æ¥è¯´ï¼èèå°æ­£ç¡®æ§ä¹å¤çç»´åº¦å¯¹éæ±çä¾èµæ§ï¼æä»¬ä¸ºæ¯ä¸ªç»´åº¦è®¾è®¡äºä¸åç±»åçç¨æ·éæ±ï¼ä»¥è¯ä¼°æ¨¡åçææ­£ç¡®ä»£ç çè½åï¼åæ¶æ»¡è¶³ç¨æ·éæ±ãæä»¬å¨ RACE ä¸è¯ä¼°äº 18 ä¸ªå·æä»£è¡¨æ§ç LLMï¼åç°ï¼1ï¼å½å LLM æ ¹æ®éæ±çæé«è´¨éä»£ç çè½åå°æªè¾¾å°è½¯ä»¶å¼åçè¦æ±ï¼2ï¼å¯è¯»æ§æ¯çæä»£ç æ´ä½è´¨éçå³é®ææ ï¼3ï¼å¤§å¤æ° LLM å¯¹ç¹å®çç¼ç é£æ ¼è¡¨ç°åºåºæçåå¥½ãè¿äºåç°å¯ä»¥å¸®å©ç ç©¶äººåæ´æ·±å¥å°äºè§£å½å LLM çç¼ç è½åï¼å¹¶ä¸ºæ¨¡åæ¹è¿çæªæ¥æ¹åæä¾å¯ç¤ºã

##### **Investigating Imperceptibility of Adversarial Attacks on Tabular Data: An Empirical Analysis**
2407.11463v1 by Zhipeng He, Chun Ouyang, Laith Alzubaidi, Alistair Barros, Catarina Moreira

Adversarial attacks are a potential threat to machine learning models, as
they can cause the model to make incorrect predictions by introducing
imperceptible perturbations to the input data. While extensively studied in
unstructured data like images, their application to structured data like
tabular data presents unique challenges due to the heterogeneity and intricate
feature interdependencies of tabular data. Imperceptibility in tabular data
involves preserving data integrity while potentially causing misclassification,
underscoring the need for tailored imperceptibility criteria for tabular data.
However, there is currently a lack of standardised metrics for assessing
adversarial attacks specifically targeted at tabular data. To address this gap,
we derive a set of properties for evaluating the imperceptibility of
adversarial attacks on tabular data. These properties are defined to capture
seven perspectives of perturbed data: proximity to original inputs, sparsity of
alterations, deviation to datapoints in the original dataset, sensitivity of
altering sensitive features, immutability of perturbation, feasibility of
perturbed values and intricate feature interdepencies among tabular features.
Furthermore, we conduct both quantitative empirical evaluation and case-based
qualitative examples analysis for seven properties. The evaluation reveals a
trade-off between attack success and imperceptibility, particularly concerning
proximity, sensitivity, and deviation. Although no evaluated attacks can
achieve optimal effectiveness and imperceptibility simultaneously, unbounded
attacks prove to be more promised for tabular data in crafting imperceptible
adversarial examples. The study also highlights the limitation of evaluated
algorithms in controlling sparsity effectively. We suggest incorporating a
sparsity metric in future attack design to regulate the number of perturbed
features.

æè¦ï¼å°ææ»æå°æ©å¨å­¸ç¿æ¨¡åä¾èªªæ¯ä¸åæ½å¨çå¨èï¼å çºå®åæééå¨è¼¸å¥è³æä¸­å¼å¥é£ä»¥å¯è¦ºçæ¾åï¼å°è´æ¨¡åååºä¸æ­£ç¢ºçé æ¸¬ãéç¶å¨å½±åç­éçµæ§åè³æä¸­å·²å»£æ³ç ç©¶ï¼ä½ç±æ¼è¡¨æ ¼è³æçç°è³ªæ§åè¤éçç¹æ§ç¸äºä¾è³´æ§ï¼å°å¶æç¨æ¼è¡¨æ ¼è³æç­çµæ§åè³ææå¸¶ä¾ç¨ç¹çææ°ãè¡¨æ ¼è³æä¸­çé£ä»¥å¯è¦ºæ§æ¶åå¨æ½å¨å°è´é¯èª¤åé¡çåæï¼ä¿æè³æçå®æ´æ§ï¼éå¸é¡¯äºçºè¡¨æ ¼è³æéèº«æé é£ä»¥å¯è¦ºæ§æ¨æºçå¿è¦æ§ãç¶èï¼ç®åéå°è¡¨æ ¼è³æçå°ææ»æè©ä¼°æ¨æºåææ¨ä»æä¸è¶³ãçºäºè§£æ±ºéåå·®è·ï¼æåæ¨å°åºä¸çµç¨æ¼è©ä¼°è¡¨æ ¼è³æå°ææ»æé£ä»¥å¯è¦ºæ§çå±¬æ§ãéäºå±¬æ§è¢«å®ç¾©çºæææ¾åè³æçä¸åè§é»ï¼èåå§è¼¸å¥çæ¥è¿ç¨åº¦ãè®åçç¨çæ§ãèåå§è³æéä¸­è³æé»çåå·®ãè®åææç¹æ§çæææ§ãæ¾åçä¸è®æ§ãæ¾åå¼çå¯è½æ§ï¼ä»¥åè¡¨æ ¼ç¹æ§ä¹éè¤éçç¹æ§ç¸äºä¾è³´æ§ãæ­¤å¤ï¼æåå°ä¸åå±¬æ§é²è¡å®éå¯¦è­è©ä¼°ååºæ¼æ¡ä¾çå®æ§ç¯ä¾åæãè©ä¼°çµææ­ç¤ºäºæ»ææåèé£ä»¥å¯è¦ºæ§ä¹éçæ¬è¡¡ï¼ç¹å¥æ¯éæ¼æ¥è¿åº¦ãæææ§ååå·®ãåç®¡æ²æè©ä¼°çæ»æå¯ä»¥åæéå°æä½³çæææ§åé£ä»¥å¯è¦ºæ§ï¼ä½ç¡çæ»æè¢«è­æå¨è£½ä½é£ä»¥å¯è¦ºçå°æç¯ä¾æ¹é¢å°è¡¨æ ¼è³ææ´æåæ¯ãç ç©¶éå¼·èª¿äºè©ä¼°æ¼ç®æ³å¨æææ§å¶ç¨çæ§æ¹é¢çéå¶ãæåå»ºè­°å¨æªä¾çæ»æè¨­è¨ä¸­ç´å¥ç¨çæ§ææ¨ï¼ä»¥è¦ç¯æ¾åç¹æ§çæ¸éã

##### **Controllable Contextualized Image Captioning: Directing the Visual Narrative through User-Defined Highlights**
2407.11449v1 by Shunqi Mao, Chaoyi Zhang, Hang Su, Hwanjun Song, Igor Shalyminov, Weidong Cai

Contextualized Image Captioning (CIC) evolves traditional image captioning
into a more complex domain, necessitating the ability for multimodal reasoning.
It aims to generate image captions given specific contextual information. This
paper further introduces a novel domain of Controllable Contextualized Image
Captioning (Ctrl-CIC). Unlike CIC, which solely relies on broad context,
Ctrl-CIC accentuates a user-defined highlight, compelling the model to tailor
captions that resonate with the highlighted aspects of the context. We present
two approaches, Prompting-based Controller (P-Ctrl) and Recalibration-based
Controller (R-Ctrl), to generate focused captions. P-Ctrl conditions the model
generation on highlight by prepending captions with highlight-driven prefixes,
whereas R-Ctrl tunes the model to selectively recalibrate the encoder
embeddings for highlighted tokens. Additionally, we design a GPT-4V empowered
evaluator to assess the quality of the controlled captions alongside standard
assessment methods. Extensive experimental results demonstrate the efficient
and effective controllability of our method, charting a new direction in
achieving user-adaptive image captioning. Code is available at
https://github.com/ShunqiM/Ctrl-CIC .

æè¦ï¼è¯­å¢å¾åæè¿° (CIC) å°ä¼ ç»å¾åæè¿°æ¼åä¸ºæ´å¤æçé¢åï¼éè¦å¤æ¨¡ææ¨ççè½åãå®æ¨å¨æ ¹æ®ç¹å®çè¯­å¢ä¿¡æ¯çæå¾åæè¿°ãæ¬æè¿ä¸æ­¥ä»ç»äºå¯æ§è¯­å¢å¾åæè¿° (Ctrl-CIC) çä¸ä¸ªæ°é¢åãä¸ä»ä¾èµå¹¿æ³è¯­å¢ç CIC ä¸åï¼Ctrl-CIC å¼ºè°ç¨æ·å®ä¹çéç¹ï¼è¿«ä½¿æ¨¡åå®å¶ä¸è¯­å¢ä¸­çªåºæ¹é¢äº§çå±é¸£çæè¿°ãæä»¬æåºäºä¸¤ç§æ¹æ³ï¼åºäºæç¤ºçæ§å¶å¨ (P-Ctrl) ååºäºéæ°æ ¡åçæ§å¶å¨ (R-Ctrl)ï¼ä»¥çæéç¹æè¿°ãP-Ctrl éè¿ä½¿ç¨çªåºé©±å¨çåç¼æ¥æ·»å çªåºæ¾ç¤ºï¼å¯¹æ¨¡åçæè¿è¡æ¡ä»¶åï¼è R-Ctrl è°æ´æ¨¡åä»¥éæ©æ§å°éæ°æ ¡åçªåºæ è®°çç¼ç å¨åµå¥ãæ­¤å¤ï¼æä»¬è®¾è®¡äºä¸ä¸ªç± GPT-4V é©±å¨çè¯ä¼°å¨æ¥è¯ä¼°åæ§æè¿°çè´¨éä»¥åæ åè¯ä¼°æ¹æ³ãå¹¿æ³çå®éªç»æè¯æäºæä»¬æ¹æ³çé«æåææå¯æ§æ§ï¼ä¸ºå®ç°ç¨æ·èªéåºå¾åæè¿°ææäºä¸ä¸ªæ°æ¹åãä»£ç å¯å¨ https://github.com/ShunqiM/Ctrl-CIC è·å¾ã

##### **EARN Fairness: Explaining, Asking, Reviewing and Negotiating Artificial Intelligence Fairness Metrics Among Stakeholders**
2407.11442v1 by Lin Luo, Yuri Nakao, Mathieu Chollet, Hiroya Inakoshi, Simone Stumpf

Numerous fairness metrics have been proposed and employed by artificial
intelligence (AI) experts to quantitatively measure bias and define fairness in
AI models. Recognizing the need to accommodate stakeholders' diverse fairness
understandings, efforts are underway to solicit their input. However, conveying
AI fairness metrics to stakeholders without AI expertise, capturing their
personal preferences, and seeking a collective consensus remain challenging and
underexplored. To bridge this gap, we propose a new framework, EARN Fairness,
which facilitates collective metric decisions among stakeholders without
requiring AI expertise. The framework features an adaptable interactive system
and a stakeholder-centered EARN Fairness process to Explain fairness metrics,
Ask stakeholders' personal metric preferences, Review metrics collectively, and
Negotiate a consensus on metric selection. To gather empirical results, we
applied the framework to a credit rating scenario and conducted a user study
involving 18 decision subjects without AI knowledge. We identify their personal
metric preferences and their acceptable level of unfairness in individual
sessions. Subsequently, we uncovered how they reached metric consensus in team
sessions. Our work shows that the EARN Fairness framework enables stakeholders
to express personal preferences and reach consensus, providing practical
guidance for implementing human-centered AI fairness in high-risk contexts.
Through this approach, we aim to harmonize fairness expectations of diverse
stakeholders, fostering more equitable and inclusive AI fairness.

æè¦ï¼äººå·¥æºè½ (AI) å°å®¶å·²æåºä¸¦æ¡ç¨è¨±å¤å¬å¹³æ§ææ¨ï¼ä»¥éåè¡¡éåè¦ä¸¦å®ç¾© AI æ¨¡åä¸­çå¬å¹³æ§ãèªè­å°éè¦é©æå©å®³éä¿äººå°å¬å¹³æ§çä¸åçè§£ï¼ç®åæ­£åªåå¾µæ±ä»åçæè¦ãç¶èï¼åæ²æ AI å°æ¥­ç¥è­çå©å®³éä¿äººå³é AI å¬å¹³æ§ææ¨ãææ¡ä»åçåäººåå¥½ï¼ä¸¦å°æ±éé«å±è­ä»ç¶å·æææ°æ§ï¼ä¸å°æªååæ¢è¨ãçºäºå½åéä¸å·®è·ï¼æåæåºä¸åæ°çæ¶æ§ï¼EARN å¬å¹³æ§ï¼å®å¯ä»¥å¨ä¸é AI å°æ¥­ç¥è­çææ³ä¸ï¼ä¿é²å©å®³éä¿äººä¹éçéé«ææ¨æ±ºç­ãè©²æ¶æ§å·æé©ææ§äºåç³»çµ±ï¼ä»¥åä»¥å©å®³éä¿äººçºä¸­å¿ç EARN å¬å¹³æ§æµç¨ï¼ç¨æ¼èªªæå¬å¹³æ§ææ¨ãè©¢åå©å®³éä¿äººçåäººææ¨åå¥½ãå±åæª¢è¦ææ¨ï¼ä¸¦ååææ¨é¸æçå±è­ãçºäºæ¶éå¯¦è­çµæï¼æåå°æ­¤æ¶æ§æç¨æ¼ä¿¡ç¨è©åæå¢ï¼ä¸¦é²è¡äºä¸é ä½¿ç¨èç ç©¶ï¼å¶ä¸­åå« 18 ä½æ²æ AI ç¥è­çæ±ºç­ä¸»é«ãæåå¨åå¥æè­°ä¸­æ¾åºä»åçåäººææ¨åå¥½åä»åå¯æ¥åçä¸å¬å¹³ç¨åº¦ãé¨å¾ï¼æåæ­é²ä»åå¦ä½å¨åéæè­°ä¸­éæææ¨å±è­ãæåçç ç©¶é¡¯ç¤ºï¼EARN å¬å¹³æ§æ¶æ§è®å©å®³éä¿äººè½å¤ è¡¨éåäººåå¥½ä¸¦éæå±è­ï¼çºå¨é«é¢¨éªç°å¢ä¸­å¯¦æ½ä»¥äººçºä¸­å¿ç AI å¬å¹³æ§æä¾å¯¦åæå°ãééæ­¤æ¹æ³ï¼æåæ¨å¨èª¿åä¸åå©å®³éä¿äººçå¬å¹³æ§ææï¼ä¿é²æ´å¬å¹³ä¸åå®¹ç AI å¬å¹³æ§ã

##### **Repurformer: Transformers for Repurposing-Aware Molecule Generation**
2407.11439v1 by Changhun Lee, Gyumin Lee

Generating as diverse molecules as possible with desired properties is
crucial for drug discovery research, which invokes many approaches based on
deep generative models today. Despite recent advancements in these models,
particularly in variational autoencoders (VAEs), generative adversarial
networks (GANs), Transformers, and diffusion models, a significant challenge
known as \textit{the sample bias problem} remains. This problem occurs when
generated molecules targeting the same protein tend to be structurally similar,
reducing the diversity of generation. To address this, we propose leveraging
multi-hop relationships among proteins and compounds. Our model, Repurformer,
integrates bi-directional pretraining with Fast Fourier Transform (FFT) and
low-pass filtering (LPF) to capture complex interactions and generate diverse
molecules. A series of experiments on BindingDB dataset confirm that
Repurformer successfully creates substitutes for anchor compounds that resemble
positive compounds, increasing diversity between the anchor and generated
compounds.

æè¦ï¼è¦çæå·ææéå±æ§çå°½å¯è½å¤æ¨£åçåå­å°æ¼è¥ç©ç¼ç¾ç ç©¶è³ééè¦ï¼éé ç ç©¶æ¡ç¨äºè¨±å¤åºæ¼æ·±åº¦çææ¨¡åçæ¹æ³ãåç®¡éäºæ¨¡åæè¿æäºé²å±ï¼ç¹å¥æ¯å¨è®åèªç·¨ç¢¼å¨ (VAE)ãçæå°æç¶²è·¯ (GAN)ãTransformeråæ´æ£æ¨¡åæ¹é¢ï¼ä½ä»å­å¨ä¸åéå¤§çææ°ï¼ç¨±çºãæ¨£æ¬åå·®åé¡ããç¶éå°åä¸èç½è³ªç¢ççåå­å¨çµæ§ä¸å¾åæ¼ç¸ä¼¼æï¼å°±æç¼çéååé¡ï¼é²èéä½çæçæ¨£æ¬å¤æ¨£æ§ãçºäºè§£æ±ºéååé¡ï¼æåå»ºè­°å©ç¨èç½è³ªåååç©ä¹éçå¤è·³éä¿ãæåçæ¨¡å Repurformer å°éåé è¨ç·´èå¿«éåç«èè½æ (FFT) åä½éæ¿¾æ³¢ (LPF) æ´åå¨ä¸èµ·ï¼ä»¥ææè¤éçäº¤äºä½ç¨ä¸¦çæå¤æ¨£åçåå­ãä¸ç³»åéå° BindingDB è³æéçå¯¦é©è­å¯¦ï¼Repurformer æåå°çºé¨å®ååç©åµé äºæ¿ä»£ç©ï¼éäºæ¿ä»£ç©é¡ä¼¼æ¼æ­£åååç©ï¼å¢å äºé¨å®ååç©åçæååç©ä¹éçå¤æ¨£æ§ã

##### **Trust No Bot: Discovering Personal Disclosures in Human-LLM Conversations in the Wild**
2407.11438v1 by Niloofar Mireshghallah, Maria Antoniak, Yash More, Yejin Choi, Golnoosh Farnadi

Measuring personal disclosures made in human-chatbot interactions can provide
a better understanding of users' AI literacy and facilitate privacy research
for large language models (LLMs). We run an extensive, fine-grained analysis on
the personal disclosures made by real users to commercial GPT models,
investigating the leakage of personally identifiable and sensitive information.
To understand the contexts in which users disclose to chatbots, we develop a
taxonomy of tasks and sensitive topics, based on qualitative and quantitative
analysis of naturally occurring conversations. We discuss these potential
privacy harms and observe that: (1) personally identifiable information (PII)
appears in unexpected contexts such as in translation or code editing (48% and
16% of the time, respectively) and (2) PII detection alone is insufficient to
capture the sensitive topics that are common in human-chatbot interactions,
such as detailed sexual preferences or specific drug use habits. We believe
that these high disclosure rates are of significant importance for researchers
and data curators, and we call for the design of appropriate nudging mechanisms
to help users moderate their interactions.

æè¦ï¼ééè¡¡éäººé¡èèå¤©æ©å¨äººäºåä¸­æåçåäººæ­é²ï¼å¯ä»¥æ´äºè§£ä½¿ç¨èç AI ç´ é¤ï¼ä¸¦ä¿é²å¤§åèªè¨æ¨¡å (LLM) çé±ç§ç ç©¶ãæåå°çå¯¦ä½¿ç¨èå°åæ¥­ GPT æ¨¡åæåçåäººæ­é²é²è¡å»£æ³çç´°ç·»åæï¼èª¿æ¥åäººå¯è­å¥åææè³è¨çæ´©æ¼ãçºäºäºè§£ä½¿ç¨èå¨åªäºææ³ä¸å°èå¤©æ©å¨äººæ­é²è³è¨ï¼æåæ ¹æèªç¶ç¼ççå°è©±é²è¡å®æ§åå®éåæï¼å¶å®äºä¸å¥ä»»ååææä¸»é¡åé¡æ³ãæåè¨è«éäºæ½å¨çé±ç§å±å®³ï¼ä¸¦è§å¯å°ï¼(1) åäººå¯è­å¥è³è¨ (PII) åºç¾å¨ææ³ä¸å°çææ³ä¸­ï¼ä¾å¦ç¿»è­¯æç¨å¼ç¢¼ç·¨è¼¯ä¸­ (åå¥çº 48% å 16% çæé)ï¼ä»¥å (2) å PII åµæ¸¬ä¸è¶³ä»¥ææ¡å¨äººé¡èèå¤©æ©å¨äººäºåä¸­å¸¸è¦çææä¸»é¡ï¼ä¾å¦è©³ç´°çæ§åå¥½æç¹å®çè¥ç©ä½¿ç¨ç¿æ£ãæåç¸ä¿¡éäºé«æ­é²çå°ç ç©¶äººå¡åè³æç®¡çå¡ä¾èªªéå¸¸éè¦ï¼æåå¼ç±²è¨­è¨é©ç¶çæ¨åæ©å¶ä¾å¹«å©ä½¿ç¨èèª¿ç¯ä»åçäºåã

##### **Generally-Occurring Model Change for Robust Counterfactual Explanations**
2407.11426v1 by Ao Xu, Tieru Wu

With the increasing impact of algorithmic decision-making on human lives, the
interpretability of models has become a critical issue in machine learning.
Counterfactual explanation is an important method in the field of interpretable
machine learning, which can not only help users understand why machine learning
models make specific decisions, but also help users understand how to change
these decisions. Naturally, it is an important task to study the robustness of
counterfactual explanation generation algorithms to model changes. Previous
literature has proposed the concept of Naturally-Occurring Model Change, which
has given us a deeper understanding of robustness to model change. In this
paper, we first further generalize the concept of Naturally-Occurring Model
Change, proposing a more general concept of model parameter changes,
Generally-Occurring Model Change, which has a wider range of applicability. We
also prove the corresponding probabilistic guarantees. In addition, we consider
a more specific problem, data set perturbation, and give relevant theoretical
results by combining optimization theory.

æè¦ï¼é¨èæ¼ç®æ³æ±ºç­å°äººé¡çæ´»ç¢çè¶ä¾è¶å¤§çå½±é¿ï¼æ¨¡åçå¯è§£éæ§å·²æçºæ©å¨å­¸ç¿ä¸­çä¸åééµåé¡ãåäºå¯¦è§£éæ¯å¯è§£éæ©å¨å­¸ç¿é åä¸­çä¸ç¨®éè¦æ¹æ³ï¼å®ä¸åå¯ä»¥å¹«å©ä½¿ç¨èäºè§£æ©å¨å­¸ç¿æ¨¡åååºç¹å®æ±ºç­çåå ï¼éå¯ä»¥å¹«å©ä½¿ç¨èäºè§£å¦ä½æ¹è®éäºæ±ºç­ãèªç¶å°ï¼ç ç©¶åäºå¯¦è§£éçææ¼ç®æ³å°æ¨¡åè®åçç©©å¥æ§æ¯ä¸é éè¦çä»»åãååçæç»æåºäºèªç¶ç¼ççæ¨¡åè®åçæ¦å¿µï¼éè®æåå°æ¨¡åè®åçç©©å¥æ§æäºæ´æ·±å¥çäºè§£ãå¨æ¬æä¸­ï¼æåé¦åé²ä¸æ­¥æ¦æ¬èªç¶ç¼ççæ¨¡åè®åçæ¦å¿µï¼æåºäºä¸åæ´éç¨çæ¨¡ååæ¸è®åçæ¦å¿µï¼å³æ®éç¼ççæ¨¡åè®åï¼å®å·ææ´å»£æ³çé©ç¨æ§ãæåä¹è­æäºç¸æçæ©çä¿è­ãæ­¤å¤ï¼æåèæ®äºä¸åæ´å·é«çåé¡ï¼å³è³æéæ¾åï¼ä¸¦ééçµåæä½³åçè«çµ¦åºç¸éççè«çµæã

##### **States Hidden in Hidden States: LLMs Emerge Discrete State Representations Implicitly**
2407.11421v1 by Junhao Chen, Shengding Hu, Zhiyuan Liu, Maosong Sun

Large Language Models (LLMs) exhibit various emergent abilities. Among these
abilities, some might reveal the internal working mechanisms of models. In this
paper, we uncover a novel emergent capability in models: the intrinsic ability
to perform extended sequences of calculations without relying on
chain-of-thought step-by-step solutions. Remarkably, the most advanced models
can directly output the results of two-digit number additions with lengths
extending up to 15 addends. We hypothesize that the model emerges Implicit
Discrete State Representations (IDSRs) within its hidden states and performs
symbolic calculations internally. To test this hypothesis, we design a sequence
of experiments that look into the hidden states. Specifically, we first confirm
that IDSRs exist. Then, we provide interesting observations about the formation
of IDSRs from layer, digit, and sequence perspectives. Finally, we confirm that
models indeed use IDSRs to produce the final answers. However, we also discover
that these state representations are far from lossless in current open-sourced
models, leading to inaccuracies in their final performance. Our work presents a
novel exploration of LLMs' symbolic calculation abilities and the underlying
mechanisms.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å±ç¾åºåç¨®æ°èçè½åãå¨éäºè½åä¸­ï¼æäºå¯è½æ­ç¤ºäºæ¨¡åçå§é¨å·¥ä½æ©å¶ãå¨æ¬æä¸­ï¼æåç¼ç¾äºæ¨¡åä¸­ä¸ç¨®æ°èçæ°è½åï¼å¨ä¸ä¾è³´æ¼éæ­¥çæç¶­éè§£æ±ºæ¹æ¡çææ³ä¸å·è¡æ´å±çè¨ç®åºåçå§å¨è½åãå¼å¾æ³¨æçæ¯ï¼æåé²çæ¨¡åå¯ä»¥ç´æ¥è¼¸åºå©ä½æ¸å æ³ççµæï¼é·åº¦é·é 15 åå æ¸ãæååè¨­æ¨¡åå¨å¶é±èçæä¸­åºç¾äºé±å«é¢æ£çæè¡¨ç¤º (IDSR)ï¼ä¸¦å¨å§é¨å·è¡ç¬¦èè¨ç®ãçºäºé©è­éååè¨­ï¼æåè¨­è¨äºä¸ç³»åå¯¦é©ä¾ç ç©¶é±èçæãå·é«ä¾èªªï¼æåé¦åç¢ºèª IDSR ç¢ºå¯¦å­å¨ãç¶å¾ï¼æåæä¾äºéæ¼å¾å±¤ãæ¸å­ååºåè§åº¦å½¢æ IDSR çæè¶£è§å¯ãæå¾ï¼æåç¢ºèªæ¨¡åç¢ºå¯¦ä½¿ç¨ IDSR ä¾ç¢çæçµç­æ¡ãç¶èï¼æåä¹ç¼ç¾éäºçæè¡¨ç¤ºé éç¶åéæºæ¨¡åä¸­çç¡æå¤±ï¼å°è´å¶æçµæ§è½ä¸æºç¢ºãæåçç ç©¶å±ç¤ºäºå° LLM çç¬¦èè¨ç®è½åååºå±¤æ©å¶çæ¢ç´¢ã

##### **LOTUS: Enabling Semantic Queries with LLMs Over Tables of Unstructured and Structured Data**
2407.11418v1 by Liana Patel, Siddharth Jha, Carlos Guestrin, Matei Zaharia

The semantic capabilities of language models (LMs) have the potential to
enable rich analytics and reasoning over vast knowledge corpora. Unfortunately,
existing systems lack high-level abstractions to perform semantic queries at
scale. We introduce semantic operators, a declarative programming interface
that extends the relational model with composable AI-based operations for
semantic queries over datasets (e.g., sorting or aggregating records using
natural language criteria). Each operator can be implemented and optimized in
multiple ways, opening a rich space for execution plans similar to relational
operators. We implement our operators and several optimizations for them in
LOTUS, an open-source query engine with a Pandas-like API.
  We demonstrate LOTUS' effectiveness across a series of real applications,
including fact-checking, extreme multi-label classification, and search. We
find that LOTUS' programming model is highly expressive, capturing
state-of-the-art query pipelines with low development overhead. Specifically,
on the FEVER dataset, LOTUS' programs can reproduce FacTool, a recent
state-of-the-art fact-checking pipeline, in few lines of code, and implement a
new pipeline that improves accuracy by $9.5\%$, while offering $7-34\times$
lower execution time. In the extreme multi-label classification task on the
BioDEX dataset, LOTUS reproduces state-of-the art result quality with its join
operator, while providing an efficient algorithm that runs $800\times$ faster
than a naive join. In the search and ranking application, LOTUS allows a simple
composition of operators to achieve $5.9 - 49.4\%$ higher nDCG@10 than the
vanilla retriever and re-ranker, while also providing query efficiency, with
$1.67 - 10\times$ lower execution time than LM-based ranking methods used by
prior works. LOTUS is publicly available at
https://github.com/stanford-futuredata/lotus.

æè¦ï¼<paragraph>èªè¨æ¨¡å (LM) çèªç¾©åè½ææ½åè½éå°é¾å¤§çç¥è­è³æåº«é²è¡è±å¯çåæåæ¨çãä¸å¹¸çæ¯ï¼ç¾æçç³»çµ±ç¼ºä¹é«éæ½è±¡ï¼ç¡æ³å¤§è¦æ¨¡å·è¡èªç¾©æ¥è©¢ãæåå¼å¥äºèªç¾©éç®å­ï¼éæ¯ä¸ç¨®å®£åå¼ç¨å¼è¨­è¨ä»é¢ï¼å®æ´åäºéä¿æ¨¡åï¼ä¸¦ééèªç¾©æ¥è©¢è³æéï¼ä¾å¦ï¼ä½¿ç¨èªç¶èªè¨æºåå°è¨éé²è¡æåºæå½ç¸½ï¼ç AI çºåºç¤éç®é²è¡çµåãæ¯åéç®å­é½å¯ä»¥ééå¤ç¨®æ¹å¼å¯¦ä½åæä½³åï¼çºé¡ä¼¼æ¼éä¿éç®å­çå·è¡è¨ç«éåäºè±å¯çç©ºéãæåå¨ LOTUS ä¸­å¯¦ä½äºæåçéç®å­ä»¥åå®åçè¥å¹²æä½³åï¼LOTUS æ¯ä¸åéæºæ¥è©¢å¼æï¼å·æé¡ä¼¼ Pandas ç APIã
æåééä¸ç³»åå¯¦éæç¨å±ç¤ºäº LOTUS çæè½ï¼åæ¬äºå¯¦æ¥æ ¸ãæ¥µç«¯å¤æ¨ç±¤åé¡åæå°ãæåç¼ç¾ LOTUS çç¨å¼è¨­è¨æ¨¡åæ¥µå·è¡¨ç¾åï¼å¯ä»¥æ·åæåé²çæ¥è©¢ç®¡ç·ï¼ä¸éç¼ææ¬ä½ãç¹å¥æ¯å¨ FEVER è³æéä¸ï¼LOTUS çç¨å¼å¯ä»¥ç¨å¹¾è¡ç¨å¼ç¢¼è¤è£½ FacToolï¼éæ¯ä¸åæè¿æåé²çäºå¯¦æ¥æ ¸ç®¡ç·ï¼ä¸¦å¯¦ä½ä¸åæ°çç®¡ç·ï¼å°æºç¢ºçæé«äº 9.5%ï¼åæå·è¡æééä½äº 7-34 åãå¨ BioDEX è³æéä¸çæ¥µç«¯å¤æ¨ç±¤åé¡ä»»åä¸­ï¼LOTUS ä½¿ç¨å¶è¯çµéç®å­è¤è£½äºæåé²ççµæåè³ªï¼åææä¾äºä¸åé«æçæ¼ç®æ³ï¼å·è¡éåº¦æ¯å®ç´è¯çµå¿«äº 800 åãå¨æå°åæåæç¨ç¨å¼ä¸­ï¼LOTUS åè¨±ç°¡å®å°çµåéç®å­ï¼ä»¥å¯¦ç¾æ¯é¦èæª¢ç´¢å¨åéæ°æåå¨é« 5.9 - 49.4% ç nDCG@10ï¼åæä¹æä¾æ¥è©¢æçï¼å·è¡æéæ¯ååå·¥ä½ä½¿ç¨çåºæ¼ LM çæåæ¹æ³ä½ 1.67 - 10 åãLOTUS å·²å¬éæ¼ https://github.com/stanford-futuredata/lotusã</paragraph>

##### **SPINACH: SPARQL-Based Information Navigation for Challenging Real-World Questions**
2407.11417v1 by Shicheng Liu, Sina J. Semnani, Harold Triedman, Jialiang Xu, Isaac Dan Zhao, Monica S. Lam

Recent work integrating Large Language Models (LLMs) has led to significant
improvements in the Knowledge Base Question Answering (KBQA) task. However, we
posit that existing KBQA datasets that either have simple questions, use
synthetically generated logical forms, or are based on small knowledge base
(KB) schemas, do not capture the true complexity of KBQA tasks.
  To address this, we introduce the SPINACH dataset, an expert-annotated KBQA
dataset collected from forum discussions on Wikidata's "Request a Query" forum
with 320 decontextualized question-SPARQL pairs. Much more complex than
existing datasets, SPINACH calls for strong KBQA systems that do not rely on
training data to learn the KB schema, but can dynamically explore large and
often incomplete schemas and reason about them.
  Along with the dataset, we introduce the SPINACH agent, a new KBQA approach
that mimics how a human expert would write SPARQLs for such challenging
questions. Experiments on existing datasets show SPINACH's capability in KBQA,
achieving a new state of the art on the QALD-7, QALD-9 Plus and QALD-10
datasets by 30.1%, 27.0%, and 10.0% in F1, respectively, and coming within 1.6%
of the fine-tuned LLaMA SOTA model on WikiWebQuestions. On our new SPINACH
dataset, SPINACH agent outperforms all baselines, including the best
GPT-4-based KBQA agent, by 38.1% in F1.

æè¦ï¼<paragraph>æè¿æ´åå¤§åè¯­è¨æ¨¡å (LLM) çå·¥ä½å·²å¤§å¹æ¹åç¥è¯åºé®ç­ (KBQA) ä»»å¡ãç¶èï¼æä»¬è®¤ä¸ºç°æç KBQA æ°æ®éè¦ä¹æç®åçé®é¢ï¼è¦ä¹ä½¿ç¨åæçæçé»è¾å½¢å¼ï¼æèåºäºå°åç¥è¯åº (KB) æ¶æï¼å¹¶æªææå° KBQA ä»»å¡ççæ­£å¤ææ§ã
ä¸ºè§£å³è¿ä¸ªé®é¢ï¼æä»¬å¼å¥äº SPINACH æ°æ®éï¼è¿æ¯ä¸ä¸ªä» Wikidata çãè¯·æ±æ¥è¯¢ãè®ºåä¸çè®ºåè®¨è®ºä¸­æ¶éçä¸å®¶æ³¨é KBQA æ°æ®éï¼å¶ä¸­æ 320 ä¸ªå»è¯­å¢åç question-SPARQL å¯¹ãSPINACH æ¯ç°ææ°æ®éå¤æå¾å¤ï¼éè¦å¼ºå¤§ç KBQA ç³»ç»ï¼è¿äºç³»ç»ä¸ä¾èµè®­ç»æ°æ®æ¥å­¦ä¹  KB æ¶æï¼ä½å¯ä»¥å¨ææ¢ç´¢å¤§åä¸éå¸¸ä¸å®æ´çæ¶æå¹¶å¯¹å¶è¿è¡æ¨çã
é¤äºæ°æ®éä¹å¤ï¼æä»¬è¿å¼å¥äº SPINACH agentï¼è¿æ¯ä¸ç§æ°ç KBQA æ¹æ³ï¼å®æ¨¡ä»¿äººç±»ä¸å®¶å¦ä½ä¸ºå¦æ­¤å·ææææ§çé®é¢ç¼å SPARQLãç°ææ°æ®éä¸çå®éªæ¾ç¤ºäº SPINACH å¨ KBQA ä¸­çè½åï¼å¨ QALD-7ãQALD-9 Plus å QALD-10 æ°æ®éä¸åå«ä»¥ F1 åå«æé«äº 30.1%ã27.0% å 10.0%ï¼å¹¶ä¸å¨ WikiWebQuestions ä¸è¾¾å°å¾®è°ç LLaMA SOTA æ¨¡åç 1.6%ãå¨æä»¬çæ° SPINACH æ°æ®éä¸ï¼SPINACH agent å¨ F1 ä¸ä¼äºææåºåï¼åæ¬åºäº GPT-4 çæä½³ KBQA agentï¼æé«äº 38.1%ã</paragraph>

##### **Representation Bias in Political Sample Simulations with Large Language Models**
2407.11409v1 by Weihong Qi, Hanjia Lyu, Jiebo Luo

This study seeks to identify and quantify biases in simulating political
samples with Large Language Models, specifically focusing on vote choice and
public opinion. Using the GPT-3.5-Turbo model, we leverage data from the
American National Election Studies, German Longitudinal Election Study, Zuobiao
Dataset, and China Family Panel Studies to simulate voting behaviors and public
opinions. This methodology enables us to examine three types of representation
bias: disparities based on the the country's language, demographic groups, and
political regime types. The findings reveal that simulation performance is
generally better for vote choice than for public opinions, more accurate in
English-speaking countries, more effective in bipartisan systems than in
multi-partisan systems, and stronger in democratic settings than in
authoritarian regimes. These results contribute to enhancing our understanding
and developing strategies to mitigate biases in AI applications within the
field of computational social science.

æè¦ï¼æ¬ç ç©¶æ¨å¨è­å¥åéåä½¿ç¨å¤§åèªè¨æ¨¡åæ¨¡æ¬æ¿æ²»æ¨£æ¬ä¸­çåå·®ï¼ç¹å¥éæ³¨æç¥¨é¸æåæ°æãä½¿ç¨ GPT-3.5-Turbo æ¨¡åï¼æåå©ç¨ç¾ååå®¶é¸èç ç©¶ãå¾·åç¸±åé¸èç ç©¶ãåº§æ¨æ¸æéåä¸­åå®¶åº­è¿½è¹¤èª¿æ¥çæ¸æä¾æ¨¡æ¬æç¥¨è¡çºåæ°æãéç¨®æ¹æ³ä½¿æåè½å¤ æª¢æ¥ä¸ç¨®é¡åçä»£è¡¨æ§åå·®ï¼åºæ¼åå®¶èªè¨ãäººå£ç¾¤é«åæ¿æ²»å¶åº¦é¡åçå·®ç°ãç ç©¶çµæè¡¨æï¼æ¨¡æ¬æè½éå¸¸å¨æç¥¨é¸ææ¹é¢åªæ¼æ°æï¼å¨è±èªåå®¶æ´æºç¢ºï¼å¨å©é»¨å¶ç³»çµ±ä¸­æ¯å¨å¤é»¨å¶ç³»çµ±ä¸­æ´ææï¼å¨æ°ä¸»ç°å¢ä¸­æ¯å¨å¨æ¬æ¿æ¬ä¸­æ´å¼·ãéäºçµææå©æ¼å æ·±æåå°è¨ç®ç¤¾æç§å­¸é åå§äººå·¥æºè½æç¨åå·®ççè§£ï¼ä¸¦å¶å®ç­ç¥ä¾æ¸è¼åå·®ã

##### **Revisiting the Impact of Pursuing Modularity for Code Generation**
2407.11406v1 by Deokyeong Kang, Ki Jung Seo, Taeuk Kim

Modular programming, which aims to construct the final program by integrating
smaller, independent building blocks, has been regarded as a desirable practice
in software development. However, with the rise of recent code generation
agents built upon large language models (LLMs), a question emerges: is this
traditional practice equally effective for these new tools? In this work, we
assess the impact of modularity in code generation by introducing a novel
metric for its quantitative measurement. Surprisingly, unlike conventional
wisdom on the topic, we find that modularity is not a core factor for improving
the performance of code generation models. We also explore potential
explanations for why LLMs do not exhibit a preference for modular code compared
to non-modular code.

æè¦ï¼æ¨¡çµåç¨å¼è¨­è¨æ¨å¨ééæ´åè¼å°ãç¨ç«çå»ºæ§åå¡ä¾å»ºæ§æçµç¨å¼ï¼ä¸ç´è¢«è¦çºè»é«éç¼ä¸­çæ³çåæ³ãç¶èï¼é¨èå»ºç«æ¼å¤§åèªè¨æ¨¡å (LLM) çææ°ç¨å¼ç¢¼ç¢çä»£çç¨å¼èèµ·ï¼ä¸ååé¡æµ®ç¾ï¼éç¨®å³çµ±åæ³å°æ¼éäºæ°å·¥å·æ¯å¦åæ¨£ææï¼å¨éé å·¥ä½ä¸­ï¼æåééå¼é²ä¸ç¨®ç¨æ¼éåæ¸¬éçæ°ç©ææ¨ä¾è©ä¼°æ¨¡çµåå°ç¨å¼ç¢¼ç¢ççå½±é¿ãä»¤äººé©è¨çæ¯ï¼èè©²ä¸»é¡ä¸çå³çµ±æºæ§ä¸åï¼æåç¼ç¾æ¨¡çµåä¸¦éæ¹åç¨å¼ç¢¼ç¢çæ¨¡åæè½çæ ¸å¿å ç´ ãæåä¹æ¢è¨äº LLM èéæ¨¡çµåç¨å¼ç¢¼ç¸æ¯ï¼çºä½ä¸åå¥½æ¨¡çµåç¨å¼ç¢¼çæ½å¨è§£éã

##### **DreamCatalyst: Fast and High-Quality 3D Editing via Controlling Editability and Identity Preservation**
2407.11394v1 by Jiwook Kim, Seonho Lee, Jaeyo Shin, Jiho Choi, Hyunjung Shim

Score distillation sampling (SDS) has emerged as an effective framework in
text-driven 3D editing tasks due to its inherent 3D consistency. However,
existing SDS-based 3D editing methods suffer from extensive training time and
lead to low-quality results, primarily because these methods deviate from the
sampling dynamics of diffusion models. In this paper, we propose DreamCatalyst,
a novel framework that interprets SDS-based editing as a diffusion reverse
process. Our objective function considers the sampling dynamics, thereby making
the optimization process of DreamCatalyst an approximation of the diffusion
reverse process in editing tasks. DreamCatalyst aims to reduce training time
and improve editing quality. DreamCatalyst presents two modes: (1) a faster
mode, which edits the NeRF scene in only about 25 minutes, and (2) a
high-quality mode, which produces superior results in less than 70 minutes.
Specifically, our high-quality mode outperforms current state-of-the-art NeRF
editing methods both in terms of speed and quality. See more extensive results
on our project page: https://dream-catalyst.github.io.

æè¦ï¼åæ¸è¸é¤¾æ¡æ¨£ (SDS) ç±æ¼å¶å§å¨ç 3D ä¸è´æ§ï¼å·²æçºæå­é©å 3D ç·¨è¼¯ä»»åä¸­ä¸åææçæ¡æ¶ãç¶èï¼ç¾æçåºæ¼ SDS ç 3D ç·¨è¼¯æ¹æ³è¨ç·´æéé·ï¼ä¸æç¢çä½åè³ªççµæï¼ä¸»è¦æ¯å çºéäºæ¹æ³åé¢äºæ´æ£æ¨¡åçæ¡æ¨£åæãå¨æ¬æä¸­ï¼æåæåº DreamCatalystï¼ä¸åå°åºæ¼ SDS çç·¨è¼¯è§£éçºååæ´æ£éç¨çæ°ç©æ¡æ¶ãæåçç®æ¨å½æ¸èéäºæ¡æ¨£åæï¼å¾èä½¿ DreamCatalyst çæä½³åéç¨æçºç·¨è¼¯ä»»åä¸­ååæ´æ£éç¨çè¿ä¼¼å¼ãDreamCatalyst æ¨å¨æ¸å°è¨ç·´æéä¸¦æåç·¨è¼¯åè³ªãDreamCatalyst æåºå©ç¨®æ¨¡å¼ï¼(1) ä¸ç¨®è¼å¿«çæ¨¡å¼ï¼åå¨ç´ 25 åéå§ç·¨è¼¯ NeRF å ´æ¯ï¼ä»¥å (2) ä¸ç¨®é«åè³ªæ¨¡å¼ï¼å¯å¨ä¸å° 70 åéå§ç¢çåªç°ççµæãå·é«ä¾èªªï¼æåçé«åè³ªæ¨¡å¼å¨éåº¦ååè³ªæ¹é¢é½åªæ¼ç®åç NeRF ç·¨è¼¯æ¹æ³ãå¨æåçå°æ¡é é¢ä¸æ¥çæ´å¨é¢ççµæï¼https://dream-catalyst.github.ioã

##### **CIC-BART-SSA: Controllable Image Captioning with Structured Semantic Augmentation**
2407.11393v1 by Kalliopi Basioti, Mohamed A. Abdelsalam, Federico Fancellu, Vladimir Pavlovic, Afsaneh Fazly

Controllable Image Captioning (CIC) aims at generating natural language
descriptions for an image, conditioned on information provided by end users,
e.g., regions, entities or events of interest. However, available
image--language datasets mainly contain captions that describe the entirety of
an image, making them ineffective for training CIC models that can potentially
attend to any subset of regions or relationships. To tackle this challenge, we
propose a novel, fully automatic method to sample additional focused and
visually grounded captions using a unified structured semantic representation
built on top of the existing set of captions associated with an image. We
leverage Abstract Meaning Representation (AMR), a cross-lingual graph-based
semantic formalism, to encode all possible spatio-semantic relations between
entities, beyond the typical spatial-relations-only focus of current methods.
We use this Structured Semantic Augmentation (SSA) framework to augment
existing image--caption datasets with the grounded controlled captions,
increasing their spatial and semantic diversity and focal coverage. We then
develop a new model, CIC-BART-SSA, specifically tailored for the CIC task, that
sources its control signals from SSA-diversified datasets. We empirically show
that, compared to SOTA CIC models, CIC-BART-SSA generates captions that are
superior in diversity and text quality, are competitive in controllability,
and, importantly, minimize the gap between broad and highly focused controlled
captioning performance by efficiently generalizing to the challenging highly
focused scenarios. Code is available at
https://github.com/SamsungLabs/CIC-BART-SSA.

æè¦ï¼å¯æ§å¾åå­å¹ï¼CICï¼æ¨å¨ä¸ºå¾åçæèªç¶è¯­è¨æè¿°ï¼æ¡ä»¶æ¯æ ¹æ®æç»ç¨æ·æä¾çä¿¡æ¯ï¼ä¾å¦æå´è¶£çåºåãå®ä½æäºä»¶ãç¶èï¼å¯ç¨çå¾åè¯­è¨æ°æ®éä¸»è¦åå«æè¿°å¾åæ´ä½çå­å¹ï¼è¿ä½¿å¾å®ä»¬æ æ³ææè®­ç» CIC æ¨¡åï¼è CIC æ¨¡åæå¯è½å³æ³¨ä»»ä½åºåæå³ç³»å­éãä¸ºäºåºå¯¹è¿ä¸ææï¼æä»¬æåºäºä¸ç§æ°é¢çãå¨èªå¨çæ¹æ³æ¥ä½¿ç¨åºäºç°æä¸å¾åå³èçå­å¹éæå»ºçç»ä¸ç»æåè¯­ä¹è¡¨ç¤ºæ¥éæ ·éå çãéä¸­çåè§è§æ¥å°çå­å¹ãæä»¬å©ç¨è·¨è¯­è¨å¾å½¢å¼è¯­ä¹å½¢å¼ä¸»ä¹ââæ½è±¡æä¹è¡¨ç¤ºï¼AMRï¼æ¥å¯¹å®ä½ä¹é´çææå¯è½çæ¶ç©ºè¯­ä¹å³ç³»è¿è¡ç¼ç ï¼èä¸ä»ä»æ¯å½åæ¹æ³éå¸¸åªå³æ³¨çç©ºé´å³ç³»ãæä»¬ä½¿ç¨è¿ç§ç»æåè¯­ä¹å¢å¼ºï¼SSAï¼æ¡æ¶æ¥ä½¿ç¨æ¥å°æ§å¶å­å¹å¢å¼ºç°æçå¾åå­å¹æ°æ®éï¼ä»èå¢å å¶ç©ºé´åè¯­ä¹å¤æ ·æ§ä»¥åç¦ç¹è¦çèå´ãç¶åï¼æä»¬å¼åäºä¸ä¸ªæ°æ¨¡å CIC-BART-SSAï¼è¯¥æ¨¡åä¸é¨éå¯¹ CIC ä»»å¡å®å¶ï¼å®ä» SSA å¤ååæ°æ®éè·åå¶æ§å¶ä¿¡å·ãæä»¬éè¿å®éªè¯æï¼ä¸ SOTA CIC æ¨¡åç¸æ¯ï¼CIC-BART-SSA çæçå­å¹å¨å¤æ ·æ§åææ¬è´¨éæ¹é¢æ´èä¸ç­¹ï¼å¨å¯æ§æ§æ¹é¢å·æç«äºåï¼èä¸éè¦çæ¯ï¼å®æå¤§ç¨åº¦å°ç¼©å°äºå¹¿æ³åé«åº¦éä¸­çåæ§å­å¹æ§è½ä¹é´çå·®è·ï¼ä»èææå°æ¨å¹¿å°æå·æææ§çé«åº¦éä¸­çåºæ¯ãä»£ç å¯å¨ https://github.com/SamsungLabs/CIC-BART-SSA è·å¾ã

##### **InvAgent: A Large Language Model based Multi-Agent System for Inventory Management in Supply Chains**
2407.11384v1 by Yinzhu Quan, Zefang Liu

Supply chain management (SCM) involves coordinating the flow of goods,
information, and finances across various entities to deliver products
efficiently. Effective inventory management is crucial in today's volatile,
uncertain, complex, and ambiguous (VUCA) world. Previous research has
demonstrated the superiority of heuristic methods and reinforcement learning
applications in inventory management. However, the application of large
language models (LLMs) as autonomous agents in multi-agent systems for
inventory management remains underexplored. This study introduces a novel
approach using LLMs to manage multi-agent inventory systems. Leveraging their
zero-shot learning capabilities, our model, InvAgent, enhances resilience and
improves efficiency across the supply chain network. Our contributions include
utilizing LLMs for zero-shot learning to enable adaptive and informed
decision-making without prior training, providing significant explainability
and clarity through Chain-of-Thought (CoT), and demonstrating dynamic
adaptability to varying demand scenarios while minimizing costs and avoiding
stockouts. Extensive evaluations across different scenarios highlight the
efficiency of our model in SCM.

æè¦ï¼ä¾æéç®¡ç (SCM) åå«åèª¿è²¨ç©ãè³è¨åè³éå¨åç¨®å¯¦é«ä¹éçæµåï¼ä»¥ææçå°äº¤ä»ç¢åãå¨ç¾ä»æè®ãä¸ç¢ºå®ãè¤éä¸æ¨¡ç³ (VUCA) çä¸çä¸­ï¼ææçåº«å­ç®¡çè³ééè¦ãååçç ç©¶å·²è­æåç¼å¼æ¹æ³åå¼·åå­¸ç¿æç¨å¨åº«å­ç®¡çä¸­çåªè¶æ§ãç¶èï¼å°å¤§åèªè¨æ¨¡å (LLM) ä½çºå¤ä¸»é«ç³»çµ±ä¸­ç¨æ¼åº«å­ç®¡ççèªä¸»ä»£çäººçæç¨ä»æªè¢«ååæ¢è¨ãæ¬ç ç©¶æåºäºä¸ç¨®ä½¿ç¨ LLM ä¾ç®¡çå¤ä¸»é«åº«å­ç³»çµ±çæ°æ¹æ³ãæåçæ¨¡å InvAgent éééç¨å¶é¶æ¬¡å­¸ç¿è½åï¼å¢å¼·äºå¾©ååä¸¦æåäºæ´åä¾æéç¶²è·¯çæçãæåçè²¢ç»åæ¬å©ç¨ LLM é²è¡é¶æ¬¡å­¸ç¿ï¼ä»¥å¨æ²æäºåè¨ç·´çææ³ä¸åç¨é©ææ§åææºçæ±ºç­å¶å®ï¼ééæèé (CoT) æä¾é¡¯èçå¯è§£éæ§åæ¸æ°åº¦ï¼ä¸¦å±ç¤ºå°ä¸åéæ±æå¢çåæé©æè½åï¼åæå°ææ¬éè³æä½ä¸¦é¿åç¼ºè²¨ãå¨ä¸åæå¢ä¸­çå»£æ³è©ä¼°çªé¡¯äºæåçæ¨¡åå¨ SCM ä¸­çæçã

##### **Segment, Lift and Fit: Automatic 3D Shape Labeling from 2D Prompts**
2407.11382v2 by Jianhao Li, Tianyu Sun, Zhongdao Wang, Enze Xie, Bailan Feng, Hongbo Zhang, Ze Yuan, Ke Xu, Jiaheng Liu, Ping Luo

This paper proposes an algorithm for automatically labeling 3D objects from
2D point or box prompts, especially focusing on applications in autonomous
driving. Unlike previous arts, our auto-labeler predicts 3D shapes instead of
bounding boxes and does not require training on a specific dataset. We propose
a Segment, Lift, and Fit (SLF) paradigm to achieve this goal. Firstly, we
segment high-quality instance masks from the prompts using the Segment Anything
Model (SAM) and transform the remaining problem into predicting 3D shapes from
given 2D masks. Due to the ill-posed nature of this problem, it presents a
significant challenge as multiple 3D shapes can project into an identical mask.
To tackle this issue, we then lift 2D masks to 3D forms and employ gradient
descent to adjust their poses and shapes until the projections fit the masks
and the surfaces conform to surrounding LiDAR points. Notably, since we do not
train on a specific dataset, the SLF auto-labeler does not overfit to biased
annotation patterns in the training set as other methods do. Thus, the
generalization ability across different datasets improves. Experimental results
on the KITTI dataset demonstrate that the SLF auto-labeler produces
high-quality bounding box annotations, achieving an AP@0.5 IoU of nearly 90\%.
Detectors trained with the generated pseudo-labels perform nearly as well as
those trained with actual ground-truth annotations. Furthermore, the SLF
auto-labeler shows promising results in detailed shape predictions, providing a
potential alternative for the occupancy annotation of dynamic objects.

æè¦ï¼<paragraph>éç¯è«ææåºäºä¸ç¨®æ¼ç®æ³ï¼ç¨æ¼èªåæ¨è¨ 3D ç©ä»¶ï¼å¾ 2D é»ææ¹æ¡æç¤ºï¼ç¹å¥èéæ¼èªåé§é§çæç¨ãèååçæè¡ä¸åï¼æåçèªåæ¨ç±¤å¨é æ¸¬ 3D å½¢çï¼èä¸æ¯éçæ¹æ¡ï¼ä¸¦ä¸ä¸éè¦éå°ç¹å®è³æéé²è¡è¨ç·´ãæåæåºäºä¸ååæ®µãæååæ¬å (SLF) çç¯ä¾ä¾éæéåç®æ¨ãé¦åï¼æåä½¿ç¨ Segment Anything Model (SAM) å¾æç¤ºä¸­åæ®µåºé«åè³ªçå¯¦ä¾é®ç½©ï¼ä¸¦å°å©ä¸çåé¡è½æçºå¾çµ¦å®ç 2D é®ç½©é æ¸¬ 3D å½¢çãç±æ¼éååé¡çæ§è³ªä¸ä½³ï¼å æ­¤å®æåºäºéå¤§çææ°ï¼å çºå¤å 3D å½¢çå¯ä»¥æå½±å°ä¸åç¸åçé®ç½©ãçºäºè§£æ±ºéååé¡ï¼æåæ¥èå° 2D é®ç½©æåå° 3D å½¢å¼ï¼ä¸¦ä½¿ç¨æ¢¯åº¦ä¸éä¾èª¿æ´å®åçå§¿å¢åå½¢çï¼ç´å°æå½±ç¬¦åé®ç½©ï¼ä¸¦ä¸è¡¨é¢ç¬¦åå¨åç LiDAR é»ãå¼å¾æ³¨æçæ¯ï¼ç±æ¼æåæ²æéå°ç¹å®è³æéé²è¡è¨ç·´ï¼å æ­¤ SLF èªåæ¨ç±¤å¨ä¸æéåº¦æ¬åè¨ç·´éä¸­æåå·®çè¨»è§£æ¨¡å¼ï¼å°±åå¶ä»æ¹æ³ä¸æ¨£ãå æ­¤ï¼è·¨ä¸åè³æéçæ³åè½åå¾å°æ¹åãå¨ KITTI è³æéä¸çå¯¦é©çµæè­æï¼SLF èªåæ¨ç±¤å¨ç¢çäºé«åè³ªçéçæ¹æ¡è¨»è§£ï¼éå°äºå°è¿ 90% ç AP@0.5 IoUãä½¿ç¨ç¢ççå½æ¨ç±¤è¨ç·´çåµæ¸¬å¨å·è¡å¾å¹¾ä¹åä½¿ç¨å¯¦éåºæ¬äºå¯¦è¨»è§£è¨ç·´çé£äºä¸æ¨£å¥½ãæ­¤å¤ï¼SLF èªåæ¨ç±¤å¨å¨è©³ç´°å½¢çé æ¸¬ä¸­é¡¯ç¤ºåºæå¸æççµæï¼çºåæç©é«çä½ç¨è¨»è§£æä¾äºæ½å¨çæ¿ä»£æ¹æ¡ã</paragraph>

##### **Reliable Reasoning Beyond Natural Language**
2407.11373v1 by Nasim Borazjanizadeh, Steven T. Piantadosi

Despite their linguistic competence, Large Language models (LLMs) often
exhibit limitations in their ability to reason reliably and flexibly. To
address this, we propose a neurosymbolic approach that prompts LLMs to extract
and encode all relevant information from a problem statement as logical code
statements, and then use a logic programming language (Prolog) to conduct the
iterative computations of explicit deductive reasoning. Our approach
significantly enhances the performance of LLMs on the standard mathematical
reasoning benchmark, GSM8k, and the Navigate dataset from the BIG-bench
dataset. Additionally, we introduce a novel dataset, the Non-Linear Reasoning
(NLR) dataset, consisting of 55 unique word problems that target the
shortcomings of the next token prediction paradigm of LLMs and require complex
non-linear reasoning but only basic arithmetic skills to solve. Our findings
demonstrate that the integration of Prolog enables LLMs to achieve high
performance on the NLR dataset, which even the most advanced language models
(including GPT4) fail to solve using text only.

æè¦ï¼åç®¡å·åèªè¨è½åï¼å¤§åèªè¨æ¨¡å (LLM) ç¶å¸¸å¨å¯é ä¸éæ´»å°æ¨ççè½åä¸å±ç¾åºéå¶ãçºäºè§£æ±ºæ­¤åé¡ï¼æåæåºäºä¸ç¨®ç¥ç¶ç¬¦èæ¹æ³ï¼æç¤º LLM å¾åé¡é³è¿°ä¸­æååç·¨ç¢¼ææç¸éè³è¨ä½çºéè¼¯ç¨å¼ç¢¼é³è¿°ï¼ç¶å¾ä½¿ç¨éè¼¯ç¨å¼è¨­è¨èªè¨ (Prolog) é²è¡æç¢ºæ¼ç¹¹æ¨ççè¿­ä»£éç®ãæåçåæ³é¡¯èæå LLM å¨æ¨æºæ¸å­¸æ¨çåºæº GSM8k å BIG-bench è³æéä¸­ç Navigate è³æéä¸çæè½ãæ­¤å¤ï¼æåå¼é²äºä¸åæ°ç©çè³æéï¼éç·æ§æ¨ç (NLR) è³æéï¼åå« 55 åç¨ç¹çæå­é¡ï¼éå° LLM çä¸ä¸åç¬¦èé æ¸¬ç¯ä¾çç¼ºé»ï¼éè¦è¤éçéç·æ§æ¨çï¼ä½åªéè¦åºæ¬çç®è¡æå·§å°±è½è§£é¡ãæåçç¼ç¾è­æï¼æ´å Prolog è½è® LLM å¨ NLR è³æéä¸éæé«æè½ï¼éçè³æ¯é²éçèªè¨æ¨¡åï¼åå« GPT4ï¼é½ç¡æ³åä½¿ç¨æå­è§£é¡çã

##### **Estimating Agreement by Chance for Sequence Annotation**
2407.11371v1 by Diya Li, Carolyn RosÃ©, Ao Yuan, Chunxiao Zhou

In the field of natural language processing, correction of performance
assessment for chance agreement plays a crucial role in evaluating the
reliability of annotations. However, there is a notable dearth of research
focusing on chance correction for assessing the reliability of sequence
annotation tasks, despite their widespread prevalence in the field. To address
this gap, this paper introduces a novel model for generating random
annotations, which serves as the foundation for estimating chance agreement in
sequence annotation tasks. Utilizing the proposed randomization model and a
related comparison approach, we successfully derive the analytical form of the
distribution, enabling the computation of the probable location of each
annotated text segment and subsequent chance agreement estimation. Through a
combination simulation and corpus-based evaluation, we successfully assess its
applicability and validate its accuracy and efficacy.

æè¦ï¼å¨èªç¶èªè¨èçé åï¼ä¿®æ­£æ©æä¸è´æ§çè¡¨ç¾è©ä¼°å¨è©ä¼°è¨»éçå¯ä¿¡åº¦æ¹é¢æ®æ¼èè³ééè¦çè§è²ãç¶èï¼åç®¡åºåè¨»éä»»åå¨è©²é åå»£æ³çè¡ï¼ä½å°æ³¨æ¼æ©æä¿®æ­£ä»¥è©ä¼°åºåè¨»éä»»åå¯ä¿¡åº¦çç ç©¶å»ç¸ç¶å±ä¹ãçºäºè§£æ±ºéåå·®è·ï¼æ¬æä»ç´¹äºä¸åç¨æ¼ç¢çé¨æ©è¨»éçæ°ç©æ¨¡åï¼ä½çºå¨åºåè¨»éä»»åä¸­ä¼°è¨æ©æä¸è´æ§çåºç¤ãå©ç¨ææåºçé¨æ©åæ¨¡ååç¸éçæ¯è¼æ¹æ³ï¼æåæåå°æ¨å°åºåä½çè§£æå½¢å¼ï¼é²èè½è¨ç®æ¯åè¨»éææ¬åæ®µçå¯è½ä½ç½®åå¾çºçæ©æä¸è´æ§ä¼°è¨ãééçµåæ¨¡æ¬ååºæ¼èªæåº«çè©ä¼°ï¼æåæåå°è©ä¼°äºå¶é©ç¨æ§ï¼ä¸¦é©è­äºå¶æºç¢ºæ§åæææ§ã

##### **A Pilot Study of GSLM-based Simulation of Foreign Accentuation Only Using Native Speech Corpora**
2407.11370v1 by Kentaro Onda, Joonyong Park, Nobuaki Minematsu, Daisuke Saito

We propose a method of simulating the human process of foreign accentuation
using Generative Spoken Language Model (GSLM) only with native speech corpora.
When one listens to spoken words of a foreign language and repeats them, the
repeated speech is often with the accent of that listener's L1. This is said to
be because the spoken words are mentally represented as a sequence of
phonological units of the L1, and those units are used for oral reproduction.
We simulate this process by inputting speech of language A into GSLM of
language B to add B's accent onto the input speech. The process of running ASR
of the L1 for foreign input speech and giving the ASR result to TTS of the L1
can be viewed as a naive implementation of this approach. The results of our
experiments show that the synthesized accent of the output speech is highly
natural, compared to real samples of A generated by speakers whose L1 is B, and
that the degree of accentuation is controllable.

æè¦ï¼æåæåºä¸åæ¨¡æ¬äººé¡å¤èªç¼é³éç¨çæ¹æ³ï¼åä½¿ç¨çæå¼å£èªèªè¨æ¨¡å (GSLM) åæ¯èªèªæåº«ãç¶æäººè½å°å¤èªçå£èªä¸¦éè¤æï¼éè¤çèªé³éå¸¸å¸¶æè½èç L1 å£é³ãæèªªéæ¯å çºå£èªå¨å¿æºä¸­è¢«è¡¨å¾µçº L1 çé³ä½å®ååºåï¼èéäºå®åç¨æ¼å£èªåç¾ãæåæ¨¡æ¬éåéç¨ï¼å°èªè¨ A çèªé³è¼¸å¥å°èªè¨ B ç GSLM ä¸­ï¼å° B çå£é³æ·»å å°è¼¸å¥èªé³ä¸­ãçºå¤èªè¼¸å¥èªé³å·è¡ L1 ç ASRï¼ä¸¦å° ASR çµææä¾çµ¦ L1 ç TTS çéç¨ï¼å¯ä»¥è¦çºéç¨®æ¹æ³çå¹¼ç¨å¯¦ç¾ãæåçå¯¦é©çµæè¡¨æï¼è L1 çº B çè¬èç¢çç A ççå¯¦æ¨£æ¬ç¸æ¯ï¼è¼¸åºèªé³çåæå£é³éå¸¸èªç¶ï¼ä¸¦ä¸å£é³ç¨åº¦æ¯å¯ä»¥æ§å¶çã

##### **Ancient Korean Archive Translation: Comparison Analysis on Statistical phrase alignment, LLM in-context learning, and inter-methodological approach**
2407.11368v1 by Sojung Lucia Kim, Taehong Jang, Joonmo Ahn

This study aims to compare three methods for translating ancient texts with
sparse corpora: (1) the traditional statistical translation method of phrase
alignment, (2) in-context LLM learning, and (3) proposed inter methodological
approach - statistical machine translation method using sentence piece tokens
derived from unified set of source-target corpus. The performance of the
proposed approach in this study is 36.71 in BLEU score, surpassing the scores
of SOLAR-10.7B context learning and the best existing Seq2Seq model. Further
analysis and discussion are presented.

æè¦ï¼æ¬ç ç©¶æ¨å¨æ¯è¼ä¸ç¨®ç¿»è­¯ç¨çèªæåº«çå¤ä»£ææ¬çæ¹æ³ï¼(1) å³çµ±ççµ±è¨ç¿»è­¯æ¹æ³çç­èªå°é½ï¼(2) ä¸ä¸æ LLM å­¸ç¿ï¼ä»¥å (3) æåºçæ¹æ³è«éæ¹æ³ - ä½¿ç¨æºç®æ¨èªæåº«çµ±ä¸éåä¸­è¡ççå¥å­çæ®µä»¤çççµ±è¨æ©å¨ç¿»è­¯æ¹æ³ãæ¬ç ç©¶ä¸­æåºçæ¹æ³ç BLEU åæ¸è¡¨ç¾çº 36.71ï¼è¶éäº SOLAR-10.7B ä¸ä¸æå­¸ç¿åç¾ææä½³ Seq2Seq æ¨¡åçåæ¸ãæä¾äºé²ä¸æ­¥çåæåè¨è«ã

##### **Feature Inference Attack on Shapley Values**
2407.11359v1 by Xinjian Luo, Yangfan Jiang, Xiaokui Xiao

As a solution concept in cooperative game theory, Shapley value is highly
recognized in model interpretability studies and widely adopted by the leading
Machine Learning as a Service (MLaaS) providers, such as Google, Microsoft, and
IBM. However, as the Shapley value-based model interpretability methods have
been thoroughly studied, few researchers consider the privacy risks incurred by
Shapley values, despite that interpretability and privacy are two foundations
of machine learning (ML) models.
  In this paper, we investigate the privacy risks of Shapley value-based model
interpretability methods using feature inference attacks: reconstructing the
private model inputs based on their Shapley value explanations. Specifically,
we present two adversaries. The first adversary can reconstruct the private
inputs by training an attack model based on an auxiliary dataset and black-box
access to the model interpretability services. The second adversary, even
without any background knowledge, can successfully reconstruct most of the
private features by exploiting the local linear correlations between the model
inputs and outputs. We perform the proposed attacks on the leading MLaaS
platforms, i.e., Google Cloud, Microsoft Azure, and IBM aix360. The
experimental results demonstrate the vulnerability of the state-of-the-art
Shapley value-based model interpretability methods used in the leading MLaaS
platforms and highlight the significance and necessity of designing
privacy-preserving model interpretability methods in future studies. To our
best knowledge, this is also the first work that investigates the privacy risks
of Shapley values.

æè¦ï¼ä½çºåä½åå¼è«ä¸­çè§£æ±ºæ¦å¿µï¼Shapley å¼å¨æ¨¡åå¯è§£éæ§ç ç©¶ä¸­åå°é«åº¦éè¦ï¼ä¸¦è¢« GoogleãMicrosoft å IBM ç­é åçæ©å¨å­¸ç¿å³æå (MLaaS) ä¾æåå»£æ³æ¡ç¨ãç¶èï¼åç®¡åºæ¼ Shapley å¼çæ¨¡åå¯è§£éæ§æ¹æ³å·²å¾å°æ·±å¥ç ç©¶ï¼ä½å¾å°æç ç©¶äººå¡èæ® Shapley å¼å¸¶ä¾çé±ç§é¢¨éªï¼åç®¡å¯è§£éæ§åé±ç§æ¯æ©å¨å­¸ç¿ (ML) æ¨¡åçå©ååºç¤ãå¨æ¬æä¸­ï¼æåä½¿ç¨ç¹å¾µæ¨è«æ»æä¾ç ç©¶åºæ¼ Shapley å¼çæ¨¡åå¯è§£éæ§æ¹æ³çé±ç§é¢¨éªï¼æ ¹æå¶ Shapley å¼è§£ééå»ºç§ææ¨¡åè¼¸å¥ãå·é«ä¾èªªï¼æåæåºäºå©åå°æãç¬¬ä¸åå°æå¯ä»¥ééåºæ¼è¼å©æ¸æéè¨ç·´æ»ææ¨¡åä¸¦é»çè¨ªåæ¨¡åå¯è§£éæ§æåä¾éå»ºç§æè¼¸å¥ãç¬¬äºåå°æï¼å³ä½¿æ²æä»»ä½èæ¯ç¥è­ï¼ä¹å¯ä»¥ééå©ç¨æ¨¡åè¼¸å¥åè¼¸åºä¹éçå±é¨ç·æ§ç¸éæ§æåéå»ºå¤§é¨åç§æç¹å¾µãæåå¨é åç MLaaS å¹³å°ï¼å³ Google CloudãMicrosoft Azure å IBM aix360ï¼ä¸å·è¡æè­°çæ»æãå¯¦é©çµæè­æäºé åç MLaaS å¹³å°ä¸­ä½¿ç¨çåºæ¼ Shapley å¼çææ°æ¨¡åå¯è§£éæ§æ¹æ³çèå¼±æ§ï¼ä¸¦å¼·èª¿äºå¨æªä¾çç ç©¶ä¸­è¨­è¨é±ç§ä¿è­·æ¨¡åå¯è§£éæ§æ¹æ³çéè¦æ§èå¿è¦æ§ãææåæç¥ï¼éä¹æ¯ç¬¬ä¸åç ç©¶ Shapley å¼çé±ç§é¢¨éªçå·¥ä½ã

##### **Beyond Binary: Multiclass Paraphasia Detection with Generative Pretrained Transformers and End-to-End Models**
2407.11345v1 by Matthew Perez, Aneesha Sampath, Minxue Niu, Emily Mower Provost

Aphasia is a language disorder that can lead to speech errors known as
paraphasias, which involve the misuse, substitution, or invention of words.
Automatic paraphasia detection can help those with Aphasia by facilitating
clinical assessment and treatment planning options. However, most automatic
paraphasia detection works have focused solely on binary detection, which
involves recognizing only the presence or absence of a paraphasia. Multiclass
paraphasia detection represents an unexplored area of research that focuses on
identifying multiple types of paraphasias and where they occur in a given
speech segment. We present novel approaches that use a generative pretrained
transformer (GPT) to identify paraphasias from transcripts as well as two
end-to-end approaches that focus on modeling both automatic speech recognition
(ASR) and paraphasia classification as multiple sequences vs. a single
sequence. We demonstrate that a single sequence model outperforms GPT baselines
for multiclass paraphasia detection.

æè¦ï¼å¤±èªçæ¯ä¸ç¨®èªè¨éç¤ï¼å¯è½å°è´è¨èªé¯èª¤ï¼ç¨±çºé¯èªçï¼å¶ä¸­æ¶åå­è©çèª¤ç¨ãæ¿ææåµé ã
èªåé¯èªçåµæ¸¬å¯ä»¥ééä¿é²è¨åºè©ä¼°åæ²»çè¦åé¸é ï¼å¹«å©å¤±èªçæ£èã
ç¶èï¼å¤§å¤æ¸èªåé¯èªçåµæ¸¬å·¥ä½åå°æ³¨æ¼äºååµæ¸¬ï¼å¶ä¸­åªæ¶åè¾¨è­é¯èªççå­å¨æä¸å­å¨ã
å¤é¡å¥é¯èªçåµæ¸¬ä»£è¡¨äºä¸åå°æªæ¢ç´¢çç ç©¶é åï¼å¶å°æ³¨æ¼è­å¥å¤ç¨®é¡åçé¯èªçï¼ä»¥åå®åå¨ç¹å®èªé³çæ®µä¸­åºç¾çä½ç½®ã
æåæåºä½¿ç¨çæå¼é è¨ç·´è½æå¨ (GPT) çæ°æ¹æ³ï¼å¾è½éä¸­è­å¥é¯èªçï¼ä»¥åå©ç¨®ç«¯å°ç«¯æ¹æ³ï¼å¶å°æ³¨æ¼å°èªåèªé³è¾¨è­ (ASR) åé¯èªçåé¡å»ºæ¨¡çºå¤ååºåèå®ä¸åºåã
æåè­æå®ä¸åºåæ¨¡åå¨å¤é¡å¥é¯èªçåµæ¸¬æ¹é¢åªæ¼ GPT åºæºã

##### **COMET: "Cone of experience" enhanced large multimodal model for mathematical problem generation**
2407.11315v1 by Sannyuya Liu, Jintian Feng, Zongkai Yang, Yawei Luo, Qian Wan, Xiaoxuan Shen, Jianwen Sun

The automatic generation of high-quality mathematical problems is practically
valuable in many educational scenarios. Large multimodal model provides a novel
technical approach for the mathematical problem generation because of its wide
success in cross-modal data scenarios. However, the traditional method of
separating problem solving from problem generation and the mainstream
fine-tuning framework of monotonous data structure with homogeneous training
objectives limit the application of large multimodal model in mathematical
problem generation. Addressing these challenges, this paper proposes COMET, a
"Cone of Experience" enhanced large multimodal model for mathematical problem
generation. Firstly, from the perspective of mutual ability promotion and
application logic, we unify stem generation and problem solving into
mathematical problem generation. Secondly, a three-stage fine-turning framework
guided by the "Cone of Experience" is proposed. The framework divides the
fine-tuning data into symbolic experience, iconic experience, and direct
experience to draw parallels with experiences in the career growth of teachers.
Several fine-grained data construction and injection methods are designed in
this framework. Finally, we construct a Chinese multimodal mathematical problem
dataset to fill the vacancy of Chinese multimodal data in this field. Combined
with objective and subjective indicators, experiments on multiple datasets
fully verify the effectiveness of the proposed framework and model.

æè¦ï¼å¨è¨±å¤æè²å ´æ¯ä¸­ï¼èªåç¢çé«åè³ªçæ¸å­¸é¡ç®å¨å¯¦åä¸å¾æå¹å¼ãå¤§åå¤æ¨¡ææ¨¡åå¨è·¨æ¨¡æè³æå ´æ¯ä¸­åå¾å»£æ³çæåï¼çºæ¸å­¸é¡ç®ç¢çæä¾äºä¸ç¨®æ°ç©çæè¡æ¹æ³ãç¶èï¼å³çµ±ä¸å°åé¡æ±è§£èåé¡ç¢çåéçæ¹æ³ï¼ä»¥åä¸»æµå¾®èª¿æ¡æ¶ä½¿ç¨å®èª¿è³æçµæ§æ­éåè³ªè¨ç·´ç®æ¨ï¼éå¶äºå¤§åå¤æ¨¡ææ¨¡åå¨æ¸å­¸é¡ç®ç¢çä¸­çæç¨ãçºäºæå°éäºææ°ï¼æ¬ææåºäº COMETï¼ä¸ç¨®ãç¶é©éé«ãå¢å¼·å¤§åå¤æ¨¡ææ¨¡åï¼ç¨æ¼æ¸å­¸é¡ç®ç¢çãé¦åï¼å¾ç¸äºè½åä¿é²åæç¨éè¼¯çè§åº¦ï¼æåå°é¡å¹¹ç¢çååé¡æ±è§£çµ±ä¸å°æ¸å­¸é¡ç®ç¢çä¸­ãå¶æ¬¡ï¼æåºäºä¸åç±ãç¶é©éé«ãæå°çä¸éæ®µå¾®èª¿æ¡æ¶ãè©²æ¡æ¶å°å¾®èª¿è³æåçºç¬¦èç¶é©ãååç¶é©åç´æ¥ç¶é©ï¼ä»¥èæå¸«è·æ¥­æé·ä¸­çç¶é©ç¸å¼æãå¨æ­¤æ¡æ¶ä¸­è¨­è¨äºå¹¾ç¨®ç´°ç²åº¦çè³æå»ºæ§åæ³¨å¥æ¹æ³ãæå¾ï¼æåå»ºæ§äºä¸åä¸­æå¤æ¨¡ææ¸å­¸é¡ç®è³æéï¼ä»¥å¡«è£è©²é åä¸­ä¸­æå¤æ¨¡æè³æçç©ºç½ãçµåå®¢è§åä¸»è§ææ¨ï¼å¨å¤åè³æéä¸çå¯¦é©ååé©è­äºææåºçæ¡æ¶åæ¨¡åçæææ§ã

##### **Large Vision-Language Models as Emotion Recognizers in Context Awareness**
2407.11300v1 by Yuxuan Lei, Dingkang Yang, Zhaoyu Chen, Jiawei Chen, Peng Zhai, Lihua Zhang

Context-aware emotion recognition (CAER) is a complex and significant task
that requires perceiving emotions from various contextual cues. Previous
approaches primarily focus on designing sophisticated architectures to extract
emotional cues from images. However, their knowledge is confined to specific
training datasets and may reflect the subjective emotional biases of the
annotators. Furthermore, acquiring large amounts of labeled data is often
challenging in real-world applications. In this paper, we systematically
explore the potential of leveraging Large Vision-Language Models (LVLMs) to
empower the CAER task from three paradigms: 1) We fine-tune LVLMs on two CAER
datasets, which is the most common way to transfer large models to downstream
tasks. 2) We design zero-shot and few-shot patterns to evaluate the performance
of LVLMs in scenarios with limited data or even completely unseen. In this
case, a training-free framework is proposed to fully exploit the In-Context
Learning (ICL) capabilities of LVLMs. Specifically, we develop an image
similarity-based ranking algorithm to retrieve examples; subsequently, the
instructions, retrieved examples, and the test example are combined to feed
LVLMs to obtain the corresponding sentiment judgment. 3) To leverage the rich
knowledge base of LVLMs, we incorporate Chain-of-Thought (CoT) into our
framework to enhance the model's reasoning ability and provide interpretable
results. Extensive experiments and analyses demonstrate that LVLMs achieve
competitive performance in the CAER task across different paradigms. Notably,
the superior performance in few-shot settings indicates the feasibility of
LVLMs for accomplishing specific tasks without extensive training.

æè¦ï¼æå¢æç¥æç·è¾¨è­ (CAER) æ¯ä¸é è¤éä¸éè¦çä»»åï¼éè¦å¾åç¨®æå¢ç·ç´¢ä¸­æç¥æç·ãååçåæ³ä¸»è¦å°æ³¨æ¼è¨­è¨ç²¾å¯æ¶æ§ï¼å¾å½±åä¸­æ·åæç·ç·ç´¢ãç¶èï¼å¶ç¥è­åéæ¼ç¹å®è¨ç·´è³æéï¼ä¸å¯è½åæ æ¨è¨»èçä¸»è§æç·åè¦ãæ­¤å¤ï¼å¨çå¯¦ä¸çæç¨ä¸­ï¼åå¾å¤§éçæ¨ç±¤è³æéå¸¸å·æææ°æ§ãå¨æ¬æä¸­ï¼æåç³»çµ±æ§å°æ¢è¨å©ç¨å¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) ä¾å¼·å CAER ä»»åçä¸ç¨®ç¯ä¾ï¼1) æåå°å©å CAER è³æéå¾®èª¿ LVLMsï¼éæ¯å°å¤§åæ¨¡åè½ç§»å°ä¸æ¸¸ä»»åæå¸¸è¦çæ¹æ³ã2) æåè¨­è¨é¶æ¬¡å­¸ç¿åå°éå­¸ç¿æ¨¡å¼ï¼ä»¥è©ä¼° LVLMs å¨è³ææéçè³å®å¨æªè¦çææ³ä¸çæè½ãå¨éç¨®ææ³ä¸ï¼æåæåºä¸ååè¨ç·´æ¶æ§ï¼ä»¥ååå©ç¨ LVLMs çæå¢å­¸ç¿ (ICL) è½åãå·é«ä¾èªªï¼æåéç¼ä¸ååºæ¼å½±åç¸ä¼¼åº¦çæåæ¼ç®æ³ä¾æ·åç¯ä¾ï¼é¨å¾ï¼å°æç¤ºãæ·åçç¯ä¾åæ¸¬è©¦ç¯ä¾çµåèµ·ä¾ï¼æä¾çµ¦ LVLMs ä»¥åå¾ç¸æçæç·å¤æ·ã3) çºäºå©ç¨ LVLMs è±å¯çç¥è­åº«ï¼æåå°æèé (CoT) ç´å¥æåçæ¶æ§ä¸­ï¼ä»¥å¢å¼·æ¨¡åçæ¨çè½åä¸¦æä¾å¯è§£éççµæãå»£æ³çå¯¦é©ååæè­æï¼LVLMs å¨ä¸åçç¯ä¾ä¸­å¯¦ç¾äº CAER ä»»åçç«¶ç­æè½ãå¼å¾æ³¨æçæ¯ï¼å¨å°éå­¸ç¿è¨­å®ä¸­çåªç°æè½ï¼è¡¨ç¤º LVLMs ç¡éå»£æ³è¨ç·´å³å¯å®æç¹å®ä»»åçå¯è¡æ§ã

##### **Zero-Shot Adaptation for Approximate Posterior Sampling of Diffusion Models in Inverse Problems**
2407.11288v1 by YaÅar Utku AlÃ§alar, Mehmet AkÃ§akaya

Diffusion models have emerged as powerful generative techniques for solving
inverse problems. Despite their success in a variety of inverse problems in
imaging, these models require many steps to converge, leading to slow inference
time. Recently, there has been a trend in diffusion models for employing
sophisticated noise schedules that involve more frequent iterations of
timesteps at lower noise levels, thereby improving image generation and
convergence speed. However, application of these ideas for solving inverse
problems with diffusion models remain challenging, as these noise schedules do
not perform well when using empirical tuning for the forward model
log-likelihood term weights. To tackle these challenges, we propose zero-shot
approximate posterior sampling (ZAPS) that leverages connections to zero-shot
physics-driven deep learning. ZAPS fixes the number of sampling steps, and uses
zero-shot training with a physics-guided loss function to learn log-likelihood
weights at each irregular timestep. We apply ZAPS to the recently proposed
diffusion posterior sampling method as baseline, though ZAPS can also be used
with other posterior sampling diffusion models. We further approximate the
Hessian of the logarithm of the prior using a diagonalization approach with
learnable diagonal entries for computational efficiency. These parameters are
optimized over a fixed number of epochs with a given computational budget. Our
results for various noisy inverse problems, including Gaussian and motion
deblurring, inpainting, and super-resolution show that ZAPS reduces inference
time, provides robustness to irregular noise schedules and improves
reconstruction quality. Code is available at https://github.com/ualcalar17/ZAPS

æè¦ï¼æ´æ£æ¨¡åå·²æçºè§£æ±ºéåé¡çå¼·å¤§çææè¡ãåç®¡å®åå¨åç¨®å½±åéåé¡ä¸­åå¾æåï¼ä½éäºæ¨¡åéè¦è¨±å¤æ­¥é©æè½æ¶æï¼å°è´æ¨è«æéè®æ¢ãæè¿ï¼æ´æ£æ¨¡ååºç¾äºä¸ç¨®è¶¨å¢ï¼æ¡ç¨ç²¾å¯çéè¨æç¨ï¼å¶ä¸­æ¶åå¨è¼ä½éè¨ç´å¥ä¸å°æéæ­¥é·é²è¡æ´é »ç¹çè¿­ä»£ï¼å¾èæ¹åå½±åçæåæ¶æéåº¦ãç¶èï¼å°éäºæ³æ³æç¨æ¼ä½¿ç¨æ´æ£æ¨¡åè§£æ±ºéåé¡ä»ç¶å·æææ°æ§ï¼å çºéäºéè¨æç¨å¨ä½¿ç¨ç¶é©èª¿æ´é²è¡ååæ¨¡åå°æ¸ä¼¼ç¶é æ¬éæè¡¨ç¾ä¸ä½³ãçºäºæå°éäºææ°ï¼æåæåºäºé¶æ¬¡è¿ä¼¼å¾é©æ½æ¨£ (ZAPS)ï¼å®å©ç¨äºèé¶æ¬¡ç©çé©åæ·±åº¦å­¸ç¿çè¯ç¹«ãZAPS ä¿®å¾©äºæ½æ¨£æ­¥é©çæ¸éï¼ä¸¦ä½¿ç¨å·æç©çæå°æå¤±å½æ¸çé¶æ¬¡è¨ç·´ä¾å­¸ç¿æ¯åä¸è¦åæéæ­¥é·çå°æ¸ä¼¼ç¶æ¬éãæåå° ZAPS æç¨æ¼æè¿æåºçæ´æ£å¾é©æ½æ¨£æ¹æ³ä½çºåºæºï¼åç®¡ ZAPS ä¹å¯ç¨æ¼å¶ä»å¾é©æ½æ¨£æ´æ£æ¨¡åãæåé²ä¸æ­¥ä½¿ç¨å·æå¯å­¸ç¿å°è§ç·æ¢ç®çå°è§åæ¹æ³ä¾è¿ä¼¼åé©å°æ¸ç Hessianï¼ä»¥æé«è¨ç®æçãéäºåæ¸å¨çµ¦å®çè¨ç®é ç®ä¸ç¶éåºå®æ¸éç epoch åªåãæåå°åç¨®éè¨éåé¡ï¼åæ¬é«æ¯åéåå»æ¨¡ç³ãä¿®å¾©åè¶è§£æåº¦ï¼ççµæè¡¨æï¼ZAPS æ¸å°äºæ¨è«æéï¼æä¾äºå°ä¸è¦åéè¨æç¨çé­¯æ£æ§ï¼ä¸¦æé«äºéå»ºåè³ªãç¨å¼ç¢¼å¯å¨ https://github.com/ualcalar17/ZAPS åå¾

##### **CLAMS: A System for Zero-Shot Model Selection for Clustering**
2407.11286v1 by Prabhant Singh, Pieter Gijsbers, Murat Onur Yildirim, Elif Ceren Gok, Joaquin Vanschoren

We propose an AutoML system that enables model selection on clustering
problems by leveraging optimal transport-based dataset similarity. Our
objective is to establish a comprehensive AutoML pipeline for clustering
problems and provide recommendations for selecting the most suitable
algorithms, thus opening up a new area of AutoML beyond the traditional
supervised learning settings. We compare our results against multiple
clustering baselines and find that it outperforms all of them, hence
demonstrating the utility of similarity-based automated model selection for
solving clustering applications.

æè¦ï¼æåæåºä¸åèªåæ©å¨å­¸ç¿ç³»çµ±ï¼å®ééå©ç¨æä½³å³è¼¸åºç¤çè³æéç¸ä¼¼æ§ï¼å¨åç¾¤åé¡ä¸é²è¡æ¨¡åé¸æãæåçç®æ¨æ¯å»ºç«ä¸åå¨é¢çèªåæ©å¨å­¸ç¿ç®¡éï¼ä»¥è§£æ±ºåç¾¤åé¡ï¼ä¸¦æä¾å»ºè­°ï¼ä»¥é¸ææåé©çæ¼ç®æ³ï¼å¾èéåä¸åè¶è¶å³çµ±ç£ç£å¼å­¸ç¿è¨­å®çèªåæ©å¨å­¸ç¿æ°é åãæåå°æåççµæèå¤ååç¾¤åºæºé²è¡æ¯è¼ï¼ä¸¦ç¼ç¾å®åªæ¼ææåºæºï¼å æ­¤è­æäºåºæ¼ç¸ä¼¼æ§çèªååæ¨¡åé¸æå°æ¼è§£æ±ºåç¾¤æç¨ç¨å¼çæç¨ã

##### **Uncertainty is Fragile: Manipulating Uncertainty in Large Language Models**
2407.11282v2 by Qingcheng Zeng, Mingyu Jin, Qinkai Yu, Zhenting Wang, Wenyue Hua, Zihao Zhou, Guangyan Sun, Yanda Meng, Shiqing Ma, Qifan Wang, Felix Juefei-Xu, Kaize Ding, Fan Yang, Ruixiang Tang, Yongfeng Zhang

Large Language Models (LLMs) are employed across various high-stakes domains,
where the reliability of their outputs is crucial. One commonly used method to
assess the reliability of LLMs' responses is uncertainty estimation, which
gauges the likelihood of their answers being correct. While many studies focus
on improving the accuracy of uncertainty estimations for LLMs, our research
investigates the fragility of uncertainty estimation and explores potential
attacks. We demonstrate that an attacker can embed a backdoor in LLMs, which,
when activated by a specific trigger in the input, manipulates the model's
uncertainty without affecting the final output. Specifically, the proposed
backdoor attack method can alter an LLM's output probability distribution,
causing the probability distribution to converge towards an attacker-predefined
distribution while ensuring that the top-1 prediction remains unchanged. Our
experimental results demonstrate that this attack effectively undermines the
model's self-evaluation reliability in multiple-choice questions. For instance,
we achieved a 100 attack success rate (ASR) across three different triggering
strategies in four models. Further, we investigate whether this manipulation
generalizes across different prompts and domains. This work highlights a
significant threat to the reliability of LLMs and underscores the need for
future defenses against such attacks. The code is available at
https://github.com/qcznlp/uncertainty_attack.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) è¢«ç¨æ¼åç¨®é«é¢¨éªé åä¸­ï¼å¶ä¸­å¶è¼¸åºçå¯é æ§è³ééè¦ãä¸ç¨®å¸¸ç¨çæ¹æ³ä¾è©ä¼° LLM åæçå¯é æ§æ¯ä¸ç¢ºå®æ§ä¼°è¨ï¼å®è¡¡éå¶ç­æ¡æ­£ç¢ºçå¯è½æ§ãåç®¡è¨±å¤ç ç©¶å°æ³¨æ¼æé« LLM ä¸ç¢ºå®æ§ä¼°è¨çæºç¢ºæ§ï¼ä½æåçç ç©¶èª¿æ¥äºä¸ç¢ºå®æ§ä¼°è¨çèå¼±æ§ä¸¦æ¢ç´¢äºæ½å¨çæ»æãæåè­æï¼æ»æèå¯ä»¥å¨ LLM ä¸­åµå¥å¾éï¼ç¶è¼¸å¥ä¸­çç¹å®è§¸ç¼å¨æ¿æ´»æï¼å®æå¨ä¸å½±é¿æçµè¼¸åºçææ³ä¸æç¸±æ¨¡åçä¸ç¢ºå®æ§ãå·é«ä¾èªªï¼ææåºçå¾éæ»ææ¹æ³å¯ä»¥æ¹è® LLM çè¼¸åºæ¦çåä½ï¼å°è´æ¦çåä½æèæ»æèé åå®ç¾©çåä½æ¶æï¼åæç¢ºä¿ top-1 é æ¸¬ä¿æä¸è®ãæåçå¯¦é©çµæè¡¨æï¼éç¨®æ»æææå°ç ´å£äºæ¨¡åå¨å¤é¸é¡ä¸­çèªæè©ä¼°å¯é æ§ãä¾å¦ï¼æåå¨ååæ¨¡åä¸­çä¸ç¨®ä¸åçè§¸ç¼ç­ç¥ä¸­å¯¦ç¾äº 100 çæ»ææåç (ASR)ãæ­¤å¤ï¼æåç ç©¶äºéç¨®æç¸±æ¯å¦å¨ä¸åçæç¤ºåé åä¸­å¾å°æ¨å»£ãéé å·¥ä½å¼·èª¿äºå° LLM å¯é æ§çéå¤§å¨èï¼ä¸¦å¼·èª¿äºæªä¾éè¦å°æ­¤é¡æ»æé²è¡é²ç¦¦ãä»£ç¢¼å¯å¨ https://github.com/qcznlp/uncertainty_attack ä¸­æ¾å°ã

##### **Quality Scalable Quantization Methodology for Deep Learning on Edge**
2407.11260v1 by Salman Abdul Khaliq, Rehan Hafiz

Deep Learning Architectures employ heavy computations and bulk of the
computational energy is taken up by the convolution operations in the
Convolutional Neural Networks. The objective of our proposed work is to reduce
the energy consumption and size of CNN for using machine learning techniques in
edge computing on ubiquitous computing devices. We propose Systematic Quality
Scalable Design Methodology consisting of Quality Scalable Quantization on a
higher abstraction level and Quality Scalable Multipliers at lower abstraction
level. The first component consists of parameter compression where we
approximate representation of values in filters of deep learning models by
encoding in 3 bits. A shift and scale based on-chip decoding hardware is
proposed which can decode these 3-bit representations to recover approximate
filter values. The size of the DNN model is reduced this way and can be sent
over a communication channel to be decoded on the edge computing devices. This
way power is reduced by limiting data bits by approximation. In the second
component we propose a quality scalable multiplier which reduces the number of
partial products by converting numbers in canonic sign digit representations
and further approximating the number by reducing least significant bits. These
quantized CNNs provide almost same ac-curacy as network with original weights
with little or no fine-tuning. The hardware for the adaptive multipliers
utilize gate clocking for reducing energy consumption during multiplications.
The proposed methodology greatly reduces the memory and power requirements of
DNN models making it a feasible approach to deploy Deep Learning on edge
computing. The experiments done on LeNet and ConvNets show an increase upto 6%
of zeros and memory savings upto 82.4919% while keeping the accuracy near the
state of the art.

æè¦ï¼æ·±åº¦å­¸ç¿æ¶æ§æ¡ç¨å¤§éçéç®ï¼èå¤§é¨åçéç®è½éé½è¢«å·ç©ç¥ç¶ç¶²è·¯ä¸­çå·ç©éç®æå¸æ¶ãæåæåºçå·¥ä½ç®æ¨æ¯éä½ CNN çè½èåå¤§å°ï¼ä»¥ä¾¿å¨æ®é©éç®è£ç½®ä¸çéç·£éç®ä¸­ä½¿ç¨æ©å¨å­¸ç¿æè¡ãæåæåºç³»çµ±ååè³ªå¯æ´åè¨­è¨æ¹æ³ï¼å¶ä¸­åå«è¼é«æ½è±¡å±¤ç´çåè³ªå¯æ´åéååè¼ä½æ½è±¡å±¤ç´çåè³ªå¯æ´åä¹æ³å¨ãç¬¬ä¸åçµä»¶åå«åæ¸å£ç¸®ï¼å¶ä¸­æåéé 3 ä½åç·¨ç¢¼ä¾è¿ä¼¼è¡¨ç¤ºæ·±åº¦å­¸ç¿æ¨¡åä¸­æ¿¾æ³¢å¨çå¼ãæåæåºäºä¸ååºæ¼ä½ç§»åç¸®æ¾çæ¶çè§£ç¢¼ç¡¬é«ï¼å®å¯ä»¥è§£ç¢¼éäº 3 ä½åè¡¨ç¤ºä»¥éåè¿ä¼¼çæ¿¾æ³¢å¨å¼ãDNN æ¨¡åçå¤§å°æä»¥éç¨®æ¹å¼ç¸®å°ï¼ä¸¦ä¸å¯ä»¥éééè¨ç®¡éå³éï¼ä»¥ä¾¿å¨éç·£éç®è£ç½®ä¸è§£ç¢¼ãéç¨®æ¹å¼å¯ééè¿ä¼¼ä¾éå¶è³æä½åï¼é²èéä½åèãå¨ç¬¬äºåçµä»¶ä¸­ï¼æåæåºäºä¸ååè³ªå¯æ´åä¹æ³å¨ï¼å®ééå°æ¸å­è½æçºæ­£è¦ç¬¦èä½åè¡¨ç¤ºï¼ä¸¦é²ä¸æ­¥ééæ¸å°æä½ææä½åä¾è¿ä¼¼æ¸å­ï¼é²èæ¸å°é¨åä¹ç©çæ¸éãéäºéåç CNN æä¾å¹¾ä¹èåå§æ¬éçç¶²è·¯ç¸åçæºç¢ºåº¦ï¼å¹¾ä¹ä¸éè¦å¾®èª¿ãèªé©æä¹æ³å¨çç¡¬é«å©ç¨éæ¥µæèä¾éä½ä¹æ³éç®ä¸­çè½èãææåºçæ¹æ³å¤§å¹éä½äº DNN æ¨¡åçè¨æ¶é«ååèéæ±ï¼ä½¿å¶æçºå¨éç·£éç®ä¸­é¨ç½²æ·±åº¦å­¸ç¿çå¯è¡æ¹æ³ãå¨ LeNet å ConvNets ä¸é²è¡çå¯¦é©é¡¯ç¤ºï¼é¶çå¢å å¹åº¦é«é 6%ï¼è¨æ¶é«ç¯çå¹åº¦é«é 82.4919%ï¼åæå°æºç¢ºåº¦ç¶­æå¨æ¥è¿æåé²çæ°´å¹³ã

##### **Pacer and Runner: Cooperative Learning Framework between Single- and Cross-Domain Sequential Recommendation**
2407.11245v1 by Chung Park, Taesan Kim, Hyungjun Yoon, Junui Hong, Yelim Yu, Mincheol Cho, Minsung Choi, Jaegul Choo

Cross-Domain Sequential Recommendation (CDSR) improves recommendation
performance by utilizing information from multiple domains, which contrasts
with Single-Domain Sequential Recommendation (SDSR) that relies on a historical
interaction within a specific domain. However, CDSR may underperform compared
to the SDSR approach in certain domains due to negative transfer, which occurs
when there is a lack of relation between domains or different levels of data
sparsity. To address the issue of negative transfer, our proposed CDSR model
estimates the degree of negative transfer of each domain and adaptively assigns
it as a weight factor to the prediction loss, to control gradient flows through
domains with significant negative transfer. To this end, our model compares the
performance of a model trained on multiple domains (CDSR) with a model trained
solely on the specific domain (SDSR) to evaluate the negative transfer of each
domain using our asymmetric cooperative network. In addition, to facilitate the
transfer of valuable cues between the SDSR and CDSR tasks, we developed an
auxiliary loss that maximizes the mutual information between the representation
pairs from both tasks on a per-domain basis. This cooperative learning between
SDSR and CDSR tasks is similar to the collaborative dynamics between pacers and
runners in a marathon. Our model outperformed numerous previous works in
extensive experiments on two real-world industrial datasets across ten service
domains. We also have deployed our model in the recommendation system of our
personal assistant app service, resulting in 21.4% increase in click-through
rate compared to existing models, which is valuable to real-world business.

æè¦ï¼è·¨ç¶²ååºåæ¨è¦ (CDSR) ééå©ç¨å¤åç¶²åä¸­çè³è¨ä¾æåæ¨è¦æè½ï¼éèä¾è³´ç¹å®ç¶²åå§æ­·å²äºåçå®ä¸ç¶²ååºåæ¨è¦ (SDSR) å½¢æå°æ¯ãç¶èï¼ç±æ¼è² é¢è½ç§»ï¼CDSR å¨æäºç¶²åä¸­å¯è½è¡¨ç¾ä¸å¦ SDSR æ¹æ³ï¼è² é¢è½ç§»ç¼çå¨ç¶²åä¹éç¼ºä¹éè¯æè³æç¨çç¨åº¦ä¸åæãçºäºè§£æ±ºè² é¢è½ç§»çåé¡ï¼æåæåºç CDSR æ¨¡åæä¼°è¨æ¯åç¶²åçè² é¢è½ç§»ç¨åº¦ï¼ä¸¦å°å¶èªé©æå°æå®çºé æ¸¬æå¤±çæ¬éå å­ï¼ä»¥æ§å¶ééå·æé¡¯èè² é¢è½ç§»çç¶²åçæ¢¯åº¦æµãçºæ­¤ï¼æåçæ¨¡åææ¯è¼å¨å¤åç¶²å (CDSR) ä¸è¨ç·´çæ¨¡åèåå¨ç¹å®ç¶²å (SDSR) ä¸è¨ç·´çæ¨¡åçæè½ï¼ä»¥ä½¿ç¨æåçéå°ç¨±åä½ç¶²è·¯è©ä¼°æ¯åç¶²åçè² é¢è½ç§»ãæ­¤å¤ï¼çºäºä¿é² SDSR å CDSR ä»»åä¹éæå¹å¼ç·ç´¢çè½ç§»ï¼æåéç¼äºä¸åè¼å©æå¤±ï¼ä»¥æå¤§åä¾èªå©åä»»åçè¡¨ç¤ºå°å¨æ¯åç¶²ååºç¤ä¸çäºæ è³è¨ãSDSR å CDSR ä»»åä¹éçéç¨®åä½å­¸ç¿é¡ä¼¼æ¼é¦¬ææ¾æ¯è³½ä¸­ééå¡åè·èä¹éçåä½åæãæåçæ¨¡åå¨å©åçå¯¦ä¸çç¢æ¥­è³æéä¸­çååæåç¶²åä¸­ï¼å¨å»£æ³çå¯¦é©ä¸­è¡¨ç¾åªæ¼è¨±å¤ååçä½åãæåä¹å·²å°æåçæ¨¡åé¨ç½²å¨æåçåäººå©çæç¨ç¨å¼æåçæ¨è¦ç³»çµ±ä¸­ï¼èç¾ææ¨¡åç¸æ¯ï¼é»æçå¢å äº 21.4%ï¼éå°æ¼çå¯¦ä¸ççæ¥­åä¾èªªæ¯æå¹å¼çã

