{"2502.14815": {"publish_time": "2025-02-20", "title": "Optimizing Model Selection for Compound AI Systems", "paper_summary": "Compound AI systems that combine multiple LLM calls, such as self-refine and\nmulti-agent-debate, achieve strong performance on many AI tasks. We address a\ncore question in optimizing compound systems: for each LLM call or module in\nthe system, how should one decide which LLM to use? We show that these LLM\nchoices have a large effect on quality, but the search space is exponential. We\npropose LLMSelector, an efficient framework for model selection in compound\nsystems, which leverages two key empirical insights: (i) end-to-end performance\nis often monotonic in how well each module performs, with all other modules\nheld fixed, and (ii) per-module performance can be estimated accurately by an\nLLM. Building upon these insights, LLMSelector iteratively selects one module\nand allocates to it the model with the highest module-wise performance, as\nestimated by an LLM, until no further gain is possible. LLMSelector is\napplicable to any compound system with a bounded number of modules, and its\nnumber of API calls scales linearly with the number of modules, achieving\nhigh-quality model allocation both empirically and theoretically. Experiments\nwith popular compound systems such as multi-agent debate and self-refine using\nLLMs such as GPT-4o, Claude 3.5 Sonnet and Gemini 1.5 show that LLMSelector\nconfers 5%-70% accuracy gains compared to using the same LLM for all modules.", "paper_summary_zh": "\u8907\u5408\u5f0f AI \u7cfb\u7d71\u7d50\u5408\u591a\u500b LLM \u547c\u53eb\uff0c\u4f8b\u5982\u81ea\u6211\u7cbe\u7149\u548c\u591a\u4ee3\u7406\u8faf\u8ad6\uff0c\u5728\u8a31\u591a AI \u4efb\u52d9\u4e2d\u90fd\u80fd\u7372\u5f97\u5f37\u5927\u7684\u6548\u80fd\u3002\u6211\u5011\u89e3\u6c7a\u4e86\u6700\u4f73\u5316\u8907\u5408\u5f0f\u7cfb\u7d71\u4e2d\u7684\u6838\u5fc3\u554f\u984c\uff1a\u5c0d\u65bc\u7cfb\u7d71\u4e2d\u7684\u6bcf\u500b LLM \u547c\u53eb\u6216\u6a21\u7d44\uff0c\u61c9\u8a72\u5982\u4f55\u6c7a\u5b9a\u8981\u4f7f\u7528\u54ea\u500b LLM\uff1f\u6211\u5011\u8868\u660e\u9019\u4e9b LLM \u9078\u64c7\u5c0d\u54c1\u8cea\u6709\u5f88\u5927\u7684\u5f71\u97ff\uff0c\u4f46\u641c\u5c0b\u7a7a\u9593\u662f\u5448\u6307\u6578\u589e\u9577\u7684\u3002\u6211\u5011\u63d0\u51fa LLMSelector\uff0c\u4e00\u7a2e\u7528\u65bc\u8907\u5408\u5f0f\u7cfb\u7d71\u4e2d\u6a21\u578b\u9078\u64c7\u7684\u6709\u6548\u67b6\u69cb\uff0c\u5b83\u5229\u7528\u4e86\u5169\u500b\u4e3b\u8981\u7684\u7d93\u9a57\u898b\u89e3\uff1a(i) \u7aef\u5c0d\u7aef\u6548\u80fd\u901a\u5e38\u6703\u96a8\u8457\u6bcf\u500b\u6a21\u7d44\u57f7\u884c\u5f97\u6709\u591a\u597d\u800c\u55ae\u8abf\u8b8a\u5316\uff0c\u800c\u5176\u4ed6\u6240\u6709\u6a21\u7d44\u4fdd\u6301\u56fa\u5b9a\uff0c\u4ee5\u53ca (ii) \u6bcf\u500b\u6a21\u7d44\u7684\u6548\u80fd\u90fd\u53ef\u4ee5\u7531 LLM \u7cbe\u6e96\u4f30\u8a08\u3002LLMSelector \u5efa\u7acb\u5728\u9019\u4e9b\u898b\u89e3\u4e4b\u4e0a\uff0c\u53cd\u8986\u9078\u64c7\u4e00\u500b\u6a21\u7d44\uff0c\u4e26\u6839\u64da LLM \u4f30\u8a08\u7684\u6a21\u7d44\u6700\u4f73\u6548\u80fd\uff0c\u5c07\u6a21\u578b\u5206\u914d\u7d66\u5b83\uff0c\u76f4\u5230\u7121\u6cd5\u518d\u9032\u4e00\u6b65\u63d0\u5347\u70ba\u6b62\u3002LLMSelector \u9069\u7528\u65bc\u4efb\u4f55\u5177\u6709\u6709\u9650\u6578\u91cf\u7684\u6a21\u7d44\u7684\u8907\u5408\u5f0f\u7cfb\u7d71\uff0c\u5176 API \u547c\u53eb\u6578\u91cf\u8207\u6a21\u7d44\u6578\u91cf\u6210\u7dda\u6027\u6bd4\u4f8b\uff0c\u5728\u7d93\u9a57\u548c\u7406\u8ad6\u4e0a\u90fd\u5be6\u73fe\u4e86\u9ad8\u54c1\u8cea\u7684\u6a21\u578b\u914d\u7f6e\u3002\u4f7f\u7528 GPT-4o\u3001Claude 3.5 Sonnet \u548c Gemini 1.5 \u7b49 LLM\uff0c\u5c0d\u591a\u4ee3\u7406\u8faf\u8ad6\u548c\u81ea\u6211\u7cbe\u7149\u7b49\u71b1\u9580\u8907\u5408\u5f0f\u7cfb\u7d71\u9032\u884c\u7684\u5be6\u9a57\u8868\u660e\uff0c\u8207\u5c0d\u6240\u6709\u6a21\u7d44\u4f7f\u7528\u76f8\u540c\u7684 LLM \u76f8\u6bd4\uff0cLLMSelector \u53ef\u5e36\u4f86 5%-70% \u7684\u6e96\u78ba\u5ea6\u63d0\u5347\u3002", "author": "Lingjiao Chen et.al.", "authors": "Lingjiao Chen, Jared Quincy Davis, Boris Hanin, Peter Bailis, Matei Zaharia, James Zou, Ion Stoica", "id": "2502.14815v1", "paper_url": "http://arxiv.org/abs/2502.14815v1", "repo": "null"}}