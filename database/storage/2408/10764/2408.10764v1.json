{"2408.10764": {"publish_time": "2024-08-20", "title": "Predicting Rewards Alongside Tokens: Non-disruptive Parameter Insertion for Efficient Inference Intervention in Large Language Model", "paper_summary": "Transformer-based large language models (LLMs) exhibit limitations such as\ngenerating unsafe responses, unreliable reasoning, etc. Existing inference\nintervention approaches attempt to mitigate these issues by finetuning\nadditional models to produce calibration signals (such as rewards) that guide\nthe LLM's decoding process. However, this solution introduces substantial time\nand space overhead due to the separate models required. This work proposes\nNon-disruptive parameters insertion (Otter), inserting extra parameters into\nthe transformer architecture to predict calibration signals along with the\noriginal LLM output. Otter offers state-of-the-art performance on multiple\ndemanding tasks while saving up to 86.5\\% extra space and 98.5\\% extra time.\nFurthermore, Otter seamlessly integrates with existing inference engines,\nrequiring only a one-line code change, and the original model response remains\naccessible after the parameter insertion. Our code is publicly available at\n\\url{https://github.com/chenhan97/Otter}", "paper_summary_zh": "\u57fa\u65bc Transformer \u7684\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6703\u7522\u751f\u4e0d\u5b89\u5168\u56de\u61c9\u3001\u63a8\u7406\u4e0d\u53ef\u9760\u7b49\u9650\u5236\u3002\u73fe\u6709\u7684\u63a8\u7406\u4ecb\u5165\u65b9\u6cd5\u5617\u8a66\u900f\u904e\u5fae\u8abf\u5176\u4ed6\u6a21\u578b\u4f86\u7522\u751f\u6821\u6e96\u4fe1\u865f (\u4f8b\u5982\u734e\u52f5) \u4f86\u7de9\u89e3\u9019\u4e9b\u554f\u984c\uff0c\u4ee5\u5f15\u5c0e LLM \u7684\u89e3\u78bc\u904e\u7a0b\u3002\u7136\u800c\uff0c\u7531\u65bc\u9700\u8981\u4f7f\u7528\u55ae\u7368\u7684\u6a21\u578b\uff0c\u6b64\u89e3\u6c7a\u65b9\u6848\u6703\u9020\u6210\u5927\u91cf\u6642\u9593\u548c\u7a7a\u9593\u7684\u958b\u92b7\u3002\u672c\u7814\u7a76\u63d0\u51fa\u975e\u7834\u58de\u6027\u53c3\u6578\u63d2\u5165 (Otter)\uff0c\u5c07\u984d\u5916\u7684\u53c3\u6578\u63d2\u5165Transformer\u67b6\u69cb\u4e2d\uff0c\u4ee5\u9810\u6e2c\u6821\u6e96\u4fe1\u865f\u4ee5\u53ca\u539f\u59cb LLM \u8f38\u51fa\u3002Otter \u5728\u591a\u9805\u8981\u6c42\u56b4\u683c\u7684\u4efb\u52d9\u4e2d\u63d0\u4f9b\u6700\u5148\u9032\u7684\u6548\u80fd\uff0c\u540c\u6642\u7bc0\u7701\u9ad8\u9054 86.5% \u7684\u984d\u5916\u7a7a\u9593\u548c 98.5% \u7684\u984d\u5916\u6642\u9593\u3002\u6b64\u5916\uff0cOtter \u80fd\u8207\u73fe\u6709\u7684\u63a8\u7406\u5f15\u64ce\u7121\u7e2b\u6574\u5408\uff0c\u50c5\u9700\u4e00\u884c\u7a0b\u5f0f\u78bc\u8b8a\u66f4\uff0c\u4e14\u539f\u59cb\u6a21\u578b\u56de\u61c9\u5728\u53c3\u6578\u63d2\u5165\u5f8c\u4ecd\u7136\u53ef\u7528\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u5df2\u516c\u958b\u65bc \\url{https://github.com/chenhan97/Otter}", "author": "Chenhan Yuan et.al.", "authors": "Chenhan Yuan, Fei Huang, Ru Peng, Keming Lu, Bowen Yu, Chang Zhou, Jingren Zhou", "id": "2408.10764v1", "paper_url": "http://arxiv.org/abs/2408.10764v1", "repo": "null"}}