
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-21**|**Reflection-Bench: probing AI intelligence with reflection**|Lingyu Li et.al.|[2410.16270v1](http://arxiv.org/abs/2410.16270v1)|[link](https://github.com/yabyum/reflectionbench)|
|**2024-10-21**|**xGen-MM-Vid (BLIP-3-Video): You Only Need 32 Tokens to Represent a Video Even in VLMs**|Michael S. Ryoo et.al.|[2410.16267v1](http://arxiv.org/abs/2410.16267v1)|null|
|**2024-10-21**|**3DGS-Enhancer: Enhancing Unbounded 3D Gaussian Splatting with View-consistent 2D Diffusion Priors**|Xi Liu et.al.|[2410.16266v1](http://arxiv.org/abs/2410.16266v1)|null|
|**2024-10-21**|**CompassJudger-1: All-in-one Judge Model Helps Model Evaluation and Evolution**|Maosong Cao et.al.|[2410.16256v1](http://arxiv.org/abs/2410.16256v1)|[link](https://github.com/open-compass/compassjudger)|
|**2024-10-21**|**Can Knowledge Editing Really Correct Hallucinations?**|Baixiang Huang et.al.|[2410.16251v1](http://arxiv.org/abs/2410.16251v1)|[link](https://github.com/llm-editing/HalluEditBench)|
|**2024-10-21**|**Analyzing Context Contributions in LLM-based Machine Translation**|Emmanouil Zaranis et.al.|[2410.16246v1](http://arxiv.org/abs/2410.16246v1)|null|
|**2024-10-21**|**MoRE: Multi-Modal Contrastive Pre-training with Transformers on X-Rays, ECGs, and Diagnostic Report**|Samrajya Thapa et.al.|[2410.16239v1](http://arxiv.org/abs/2410.16239v1)|[link](https://github.com/svthapa/more)|
|**2024-10-21**|**ToW: Thoughts of Words Improve Reasoning in Large Language Models**|Zhikun Xu et.al.|[2410.16235v1](http://arxiv.org/abs/2410.16235v1)|null|
|**2024-10-21**|**Sketch2Code: Evaluating Vision-Language Models for Interactive Web Design Prototyping**|Ryan Li et.al.|[2410.16232v1](http://arxiv.org/abs/2410.16232v1)|null|
|**2024-10-21**|**Building A Coding Assistant via the Retrieval-Augmented Language Model**|Xinze Li et.al.|[2410.16229v1](http://arxiv.org/abs/2410.16229v1)|null|
|**2024-10-21**|**On Creating an English-Thai Code-switched Machine Translation in Medical Domain**|Parinthapat Pengpun et.al.|[2410.16221v1](http://arxiv.org/abs/2410.16221v1)|null|
|**2024-10-21**|**Pre-training Distillation for Large Language Models: A Design Space Exploration**|Hao Peng et.al.|[2410.16215v1](http://arxiv.org/abs/2410.16215v1)|null|
|**2024-10-21**|**Comprehensive benchmarking of large language models for RNA secondary structure prediction**|L. I. Zablocki et.al.|[2410.16212v1](http://arxiv.org/abs/2410.16212v1)|[link](https://github.com/sinc-lab/rna-llm-folding)|
|**2024-10-21**|**Compute-Constrained Data Selection**|Junjie Oscar Yin et.al.|[2410.16208v1](http://arxiv.org/abs/2410.16208v1)|[link](https://github.com/oseyosey/ccds)|
|**2024-10-21**|**CoT-TL: Low-Resource Temporal Knowledge Representation of Planning Instructions Using Chain-of-Thought Reasoning**|Kumar Manas et.al.|[2410.16207v1](http://arxiv.org/abs/2410.16207v1)|null|
|**2024-10-21**|**Systematic Review: Text Processing Algorithms in Machine Learning and Deep Learning for Mental Health Detection on Social Media**|Yuchen Cao et.al.|[2410.16204v1](http://arxiv.org/abs/2410.16204v1)|null|
|**2024-10-21**|**Improve Vision Language Model Chain-of-thought Reasoning**|Ruohong Zhang et.al.|[2410.16198v1](http://arxiv.org/abs/2410.16198v1)|null|
|**2024-10-21**|**Information for Conversation Generation: Proposals Utilising Knowledge Graphs**|Alex Clay et.al.|[2410.16196v1](http://arxiv.org/abs/2410.16196v1)|null|
|**2024-10-21**|**Contamination Report for Multilingual Benchmarks**|Sanchit Ahuja et.al.|[2410.16186v1](http://arxiv.org/abs/2410.16186v1)|null|
|**2024-10-21**|**RM-Bench: Benchmarking Reward Models of Language Models with Subtlety and Style**|Yantao Liu et.al.|[2410.16184v1](http://arxiv.org/abs/2410.16184v1)|[link](https://github.com/thu-keg/rm-bench)|
|**2024-10-21**|**MagicPIG: LSH Sampling for Efficient LLM Generation**|Zhuoming Chen et.al.|[2410.16179v1](http://arxiv.org/abs/2410.16179v1)|null|
|**2024-10-21**|**Exploring Pretraining via Active Forgetting for Improving Cross Lingual Transfer for Decoder Language Models**|Divyanshu Aggarwal et.al.|[2410.16168v1](http://arxiv.org/abs/2410.16168v1)|null|
|**2024-10-21**|**Beyond Filtering: Adaptive Image-Text Quality Enhancement for MLLM Pretraining**|Han Huang et.al.|[2410.16166v1](http://arxiv.org/abs/2410.16166v1)|[link](https://github.com/hanhuang22/aitqe)|
|**2024-10-21**|**From Tokens to Materials: Leveraging Language Models for Scientific Discovery**|Yuwei Wan et.al.|[2410.16165v1](http://arxiv.org/abs/2410.16165v1)|null|
|**2024-10-21**|**Sparkle: Mastering Basic Spatial Capabilities in Vision Language Models Elicits Generalization to Composite Spatial Reasoning**|Yihong Tang et.al.|[2410.16162v1](http://arxiv.org/abs/2410.16162v1)|null|
|**2024-10-21**|**Limpeh ga li gong: Challenges in Singlish Annotations**|Lynnette Hui Xian Ng et.al.|[2410.16156v1](http://arxiv.org/abs/2410.16156v1)|null|
|**2024-10-21**|**A Troublemaker with Contagious Jailbreak Makes Chaos in Honest Towns**|Tianyi Men et.al.|[2410.16155v1](http://arxiv.org/abs/2410.16155v1)|null|
|**2024-10-21**|**Pangea: A Fully Open Multilingual Multimodal LLM for 39 Languages**|Xiang Yue et.al.|[2410.16153v1](http://arxiv.org/abs/2410.16153v1)|null|
|**2024-10-21**|**Warped Diffusion: Solving Video Inverse Problems with Image Diffusion Models**|Giannis Daras et.al.|[2410.16152v2](http://arxiv.org/abs/2410.16152v2)|null|
|**2024-10-21**|**Small Contributions, Small Networks: Efficient Neural Network Pruning Based on Relative Importance**|Mostafa Hussien et.al.|[2410.16151v1](http://arxiv.org/abs/2410.16151v1)|null|
|**2024-10-21**|**PODTILE: Facilitating Podcast Episode Browsing with Auto-generated Chapters**|Azin Ghazimatin et.al.|[2410.16148v1](http://arxiv.org/abs/2410.16148v1)|null|
|**2024-10-21**|**1-bit AI Infra: Part 1.1, Fast and Lossless BitNet b1.58 Inference on CPUs**|Jinheng Wang et.al.|[2410.16144v1](http://arxiv.org/abs/2410.16144v1)|[link](https://github.com/microsoft/bitnet)|
|**2024-10-21**|**A Psycholinguistic Evaluation of Language Models' Sensitivity to Argument Roles**|Eun-Kyoung Rosa Lee et.al.|[2410.16139v1](http://arxiv.org/abs/2410.16139v1)|null|
|**2024-10-21**|**Modeling dynamic neural activity by combining naturalistic video stimuli and stimulus-independent latent factors**|Finn Schmidt et.al.|[2410.16136v1](http://arxiv.org/abs/2410.16136v1)|null|
|**2024-10-21**|**Beyond 2:4: exploring V:N:M sparsity for efficient transformer inference on GPUs**|Kang Zhao et.al.|[2410.16135v1](http://arxiv.org/abs/2410.16135v1)|null|
|**2024-10-21**|**A Data-driven Crowd Simulation Framework Integrating Physics-informed Machine Learning with Navigation Potential Fields**|Runkang Guo et.al.|[2410.16132v1](http://arxiv.org/abs/2410.16132v1)|null|
|**2024-10-21**|**Can Large Audio-Language Models Truly Hear? Tackling Hallucinations with Multi-Task Assessment and Stepwise Audio Reasoning**|Chun-Yi Kuan et.al.|[2410.16130v1](http://arxiv.org/abs/2410.16130v1)|null|
|**2024-10-21**|**SMART: Self-learning Meta-strategy Agent for Reasoning Tasks**|Rongxing Liu et.al.|[2410.16128v1](http://arxiv.org/abs/2410.16128v1)|[link](https://github.com/kumar-shridhar/smart)|
|**2024-10-21**|**SeaDAG: Semi-autoregressive Diffusion for Conditional Directed Acyclic Graph Generation**|Xinyi Zhou et.al.|[2410.16119v1](http://arxiv.org/abs/2410.16119v1)|null|
|**2024-10-21**|**Multimodal Flare Forecasting with Deep Learning**|Grégoire Francisco et.al.|[2410.16116v1](http://arxiv.org/abs/2410.16116v1)|null|
|**2024-10-21**|**Do LLMs write like humans? Variation in grammatical and rhetorical styles**|Alex Reinhart et.al.|[2410.16107v1](http://arxiv.org/abs/2410.16107v1)|null|
|**2024-10-21**|**Addressing Spectral Bias of Deep Neural Networks by Multi-Grade Deep Learning**|Ronglong Fang et.al.|[2410.16105v1](http://arxiv.org/abs/2410.16105v1)|[link](https://github.com/ronglong-fang/addressingspectralbiasviamgdl)|
|**2024-10-21**|**Neural Quantum Propagators for Driven-Dissipative Quantum Dynamics**|Jiaji Zhang et.al.|[2410.16091v1](http://arxiv.org/abs/2410.16091v1)|null|
|**2024-10-21**|**Analysing the Residual Stream of Language Models Under Knowledge Conflicts**|Yu Zhao et.al.|[2410.16090v1](http://arxiv.org/abs/2410.16090v1)|null|
|**2024-10-21**|**Multi-Sensor Fusion for UAV Classification Based on Feature Maps of Image and Radar Data**|Nikos Sakellariou et.al.|[2410.16089v1](http://arxiv.org/abs/2410.16089v1)|null|
|**2024-10-21**|**Fine-Tuning LLMs for Reliable Medical Question-Answering Services**|Ali Anaissi et.al.|[2410.16088v1](http://arxiv.org/abs/2410.16088v1)|null|
|**2024-10-21**|**Critical Example Mining for Vehicle Trajectory Prediction using Flow-based Generative Models**|Zhezhang Ding et.al.|[2410.16083v1](http://arxiv.org/abs/2410.16083v1)|null|
|**2024-10-21**|**CartesianMoE: Boosting Knowledge Sharing among Experts via Cartesian Product Routing in Mixture-of-Experts**|Zhenpeng Su et.al.|[2410.16077v2](http://arxiv.org/abs/2410.16077v2)|null|
|**2024-10-21**|**On-Device LLMs for SMEs: Challenges and Opportunities**|Jeremy Stephen Gabriel Yee et.al.|[2410.16070v2](http://arxiv.org/abs/2410.16070v2)|null|
|**2024-10-21**|**Rolling the DICE on Idiomaticity: How LLMs Fail to Grasp Context**|Maggie Mi et.al.|[2410.16069v1](http://arxiv.org/abs/2410.16069v1)|null|
|**2024-10-21**|**Integrated Image-Text Based on Semi-supervised Learning for Small Sample Instance Segmentation**|Ruting Chi et.al.|[2410.16063v1](http://arxiv.org/abs/2410.16063v1)|null|
|**2024-10-21**|**Surprise! Uniform Information Density Isn't the Whole Story: Predicting Surprisal Contours in Long-form Discourse**|Eleftheria Tsipidi et.al.|[2410.16062v1](http://arxiv.org/abs/2410.16062v1)|null|
|**2024-10-21**|**Large Language Models Know What To Say But Not When To Speak**|Muhammad Umair et.al.|[2410.16044v1](http://arxiv.org/abs/2410.16044v1)|null|
|**2024-10-21**|**TimeMixer++: A General Time Series Pattern Machine for Universal Predictive Analysis**|Shiyu Wang et.al.|[2410.16032v1](http://arxiv.org/abs/2410.16032v1)|null|
|**2024-10-21**|**ComPO: Community Preferences for Language Model Personalization**|Sachin Kumar et.al.|[2410.16027v1](http://arxiv.org/abs/2410.16027v1)|null|
|**2024-10-21**|**A New Approach to Solving SMAC Task: Generating Decision Tree Code from Large Language Models**|Yue Deng et.al.|[2410.16024v1](http://arxiv.org/abs/2410.16024v1)|[link](https://github.com/devindeng94/llm-smac)|
|**2024-10-21**|**Massimo: Public Queue Monitoring and Management using Mass-Spring Model**|Abhijeet Kumar et.al.|[2410.16012v1](http://arxiv.org/abs/2410.16012v1)|null|
|**2024-10-21**|**Resilient Temporal GCN for Smart Grid State Estimation Under Topology Inaccuracies**|Seyed Hamed Haghshenas et.al.|[2410.16008v1](http://arxiv.org/abs/2410.16008v1)|null|
|**2024-10-21**|**Are Language Model Logits Calibrated?**|Charles Lovering et.al.|[2410.16007v1](http://arxiv.org/abs/2410.16007v1)|null|
|**2024-10-21**|**Exploring Continual Fine-Tuning for Enhancing Language Ability in Large Language Model**|Divyanshu Aggarwal et.al.|[2410.16006v1](http://arxiv.org/abs/2410.16006v1)|null|
|**2024-10-21**|**Steering Knowledge Selection Behaviours in LLMs via SAE-Based Representation Engineering**|Yu Zhao et.al.|[2410.15999v1](http://arxiv.org/abs/2410.15999v1)|null|
|**2024-10-21**|**1024m at SMM4H 2024: Tasks 3, 5 & 6 -- Ensembles of Transformers and Large Language Models for Medical Text Classification**|Ram Mohan Rao Kadiyala et.al.|[2410.15998v1](http://arxiv.org/abs/2410.15998v1)|null|
|**2024-10-21**|**Augmenting Legal Decision Support Systems with LLM-based NLI for Analyzing Social Media Evidence**|Ram Mohan Rao Kadiyala et.al.|[2410.15990v1](http://arxiv.org/abs/2410.15990v1)|null|
|**2024-10-21**|**Analyzing Closed-loop Training Techniques for Realistic Traffic Agent Models in Autonomous Highway Driving Simulations**|Matthias Bitzer et.al.|[2410.15987v1](http://arxiv.org/abs/2410.15987v1)|null|
|**2024-10-21**|**PROMPTHEUS: A Human-Centered Pipeline to Streamline SLRs with LLMs**|João Pedro Fernandes Torres et.al.|[2410.15978v2](http://arxiv.org/abs/2410.15978v2)|[link](https://github.com/joaopftorres/promptheus)|
|**2024-10-21**|**Enabling Energy-Efficient Deployment of Large Language Models on Memristor Crossbar: A Synergy of Large and Small**|Zhehui Wang et.al.|[2410.15977v1](http://arxiv.org/abs/2410.15977v1)|null|
|**2024-10-21**|**Large Language Models for Cross-lingual Emotion Detection**|Ram Mohan Rao Kadiyala et.al.|[2410.15974v1](http://arxiv.org/abs/2410.15974v1)|[link](https://github.com/1024-m/acl-2024-wassa-exalt)|
|**2024-10-21**|**Karush-Kuhn-Tucker Condition-Trained Neural Networks (KKT Nets)**|Shreya Arvind et.al.|[2410.15973v1](http://arxiv.org/abs/2410.15973v1)|null|
|**2024-10-21**|**Policy-driven Knowledge Selection and Response Generation for Document-grounded Dialogue**|Longxuan Ma et.al.|[2410.15970v1](http://arxiv.org/abs/2410.15970v1)|null|
|**2024-10-21**|**Self-Explained Keywords Empower Large Language Models for Code Generation**|Lishui Fan et.al.|[2410.15966v1](http://arxiv.org/abs/2410.15966v1)|null|
|**2024-10-21**|**Systematic Exploration of Dialogue Summarization Approaches for Reproducibility, Comparative Assessment, and Methodological Innovations for Advancing Natural Language Processing in Abstractive Summarization**|Yugandhar Reddy Gogireddy et.al.|[2410.15962v1](http://arxiv.org/abs/2410.15962v1)|null|
|**2024-10-21**|**Do Large Language Models Have an English Accent? Evaluating and Improving the Naturalness of Multilingual LLMs**|Yanzhu Guo et.al.|[2410.15956v1](http://arxiv.org/abs/2410.15956v1)|null|
|**2024-10-21**|**TS-ACL: A Time Series Analytic Continual Learning Framework for Privacy-Preserving and Class-Incremental Pattern Recognition**|Kejia Fan et.al.|[2410.15954v1](http://arxiv.org/abs/2410.15954v1)|null|
|**2024-10-21**|**User-centric evaluation of explainability of AI with and for humans: a comprehensive empirical study**|Szymon Bobek et.al.|[2410.15952v1](http://arxiv.org/abs/2410.15952v1)|null|
|**2024-10-21**|**Findings of the Third Shared Task on Multilingual Coreference Resolution**|Michal Novák et.al.|[2410.15949v1](http://arxiv.org/abs/2410.15949v1)|null|
|**2024-10-21**|**Developing Retrieval Augmented Generation (RAG) based LLM Systems from PDFs: An Experience Report**|Ayman Asad Khan et.al.|[2410.15944v1](http://arxiv.org/abs/2410.15944v1)|[link](https://github.com/gpt-laboratory/rag-llm-development-guidebook-from-pdfs)|
|**2024-10-21**|**CausalGraph2LLM: Evaluating LLMs for Causal Queries**|Ivaxi Sheth et.al.|[2410.15939v1](http://arxiv.org/abs/2410.15939v1)|[link](https://github.com/ivaxi0s/causalgraph2llm)|
|**2024-10-21**|**Centrality-aware Product Retrieval and Ranking**|Hadeel Saadany et.al.|[2410.15930v1](http://arxiv.org/abs/2410.15930v1)|null|
|**2024-10-21**|**Yeah, Un, Oh: Continuous and Real-time Backchannel Prediction with Fine-tuning of Voice Activity Projection**|Koji Inoue et.al.|[2410.15929v1](http://arxiv.org/abs/2410.15929v1)|null|
|**2024-10-21**|**GReFEL: Geometry-Aware Reliable Facial Expression Learning under Bias and Imbalanced Data Distribution**|Azmine Toushik Wasi et.al.|[2410.15927v1](http://arxiv.org/abs/2410.15927v1)|null|
|**2024-10-21**|**Mitigating Object Hallucination via Concentric Causal Attention**|Yun Xing et.al.|[2410.15926v1](http://arxiv.org/abs/2410.15926v1)|[link](https://github.com/xing0047/cca-llava)|
|**2024-10-21**|**Bench4Merge: A Comprehensive Benchmark for Merging in Realistic Dense Traffic with Micro-Interactive Vehicles**|Zhengming Wang et.al.|[2410.15912v1](http://arxiv.org/abs/2410.15912v1)|null|
|**2024-10-21**|**DefVerify: Do Hate Speech Models Reflect Their Dataset's Definition?**|Urja Khurana et.al.|[2410.15911v1](http://arxiv.org/abs/2410.15911v1)|null|
|**2024-10-21**|**IGMaxHS -- An Incremental MaxSAT Solver with Support for XOR Clauses**|Ole Lübke et.al.|[2410.15897v1](http://arxiv.org/abs/2410.15897v1)|null|
|**2024-10-21**|**Model Mimic Attack: Knowledge Distillation for Provably Transferable Adversarial Examples**|Kirill Lukyanov et.al.|[2410.15889v1](http://arxiv.org/abs/2410.15889v1)|null|
|**2024-10-21**|**How to Build a Pre-trained Multimodal model for Simultaneously Chatting and Decision-making?**|Zuojin Tang et.al.|[2410.15885v1](http://arxiv.org/abs/2410.15885v1)|null|
|**2024-10-21**|**Using GPT Models for Qualitative and Quantitative News Analytics in the 2024 US Presidental Election Process**|Bohdan M. Pavlyshenko et.al.|[2410.15884v1](http://arxiv.org/abs/2410.15884v1)|null|
|**2024-10-21**|**MI-VisionShot: Few-shot adaptation of vision-language models for slide-level classification of histopathological images**|Pablo Meseguer et.al.|[2410.15881v1](http://arxiv.org/abs/2410.15881v1)|null|
|**2024-10-21**|**FlickerFusion: Intra-trajectory Domain Generalizing Multi-Agent RL**|Woosung Koh et.al.|[2410.15876v1](http://arxiv.org/abs/2410.15876v1)|null|
|**2024-10-21**|**Principles of semantic and functional efficiency in grammatical patterning**|Emily Cheng et.al.|[2410.15865v1](http://arxiv.org/abs/2410.15865v1)|null|
|**2024-10-21**|**Mesa-Extrapolation: A Weave Position Encoding Method for Enhanced Extrapolation in LLMs**|Xin Ma et.al.|[2410.15859v2](http://arxiv.org/abs/2410.15859v2)|null|
|**2024-10-21**|**Random Token Fusion for Multi-View Medical Diagnosis**|Jingyu Guo et.al.|[2410.15847v1](http://arxiv.org/abs/2410.15847v1)|null|
|**2024-10-21**|**LLM4GRN: Discovering Causal Gene Regulatory Networks with LLMs -- Evaluation through Synthetic Data Generation**|Tejumade Afonja et.al.|[2410.15828v1](http://arxiv.org/abs/2410.15828v1)|null|
|**2024-10-21**|**The effect of fine-tuning on language model toxicity**|Will Hawkins et.al.|[2410.15821v1](http://arxiv.org/abs/2410.15821v1)|[link](https://github.com/willhawkins3/finetuningtoxicity)|
|**2024-10-21**|**LiMTR: Time Series Motion Prediction for Diverse Road Users through Multimodal Feature Integration**|Camiel Oerlemans et.al.|[2410.15819v1](http://arxiv.org/abs/2410.15819v1)|[link](https://github.com/cing2/limtr)|
|**2024-10-21**|**Kaninfradet3D:A Road-side Camera-LiDAR Fusion 3D Perception Model based on Nonlinear Feature Extraction and Intrinsic Correlation**|Pei Liu et.al.|[2410.15814v1](http://arxiv.org/abs/2410.15814v1)|null|
|**2024-10-21**|**RAG4ITOps: A Supervised Fine-Tunable and Comprehensive RAG Framework for IT Operations and Maintenance**|Tianyang Zhang et.al.|[2410.15805v1](http://arxiv.org/abs/2410.15805v1)|null|
|**2024-10-21**|**Deep Learning and Data Augmentation for Detecting Self-Admitted Technical Debt**|Edi Sutoyo et.al.|[2410.15804v1](http://arxiv.org/abs/2410.15804v1)|[link](https://github.com/edisutoyo/satd-augmentation)|
|**2024-10-21**|**Habaek: High-performance water segmentation through dataset expansion and inductive bias optimization**|Hanseon Joo et.al.|[2410.15794v1](http://arxiv.org/abs/2410.15794v1)|[link](https://github.com/HanseonJoo/Habaek)|
|**2024-10-21**|**Arithmetic Transformers Can Length-Generalize in Both Operand Length and Count**|Hanseul Cho et.al.|[2410.15787v1](http://arxiv.org/abs/2410.15787v1)|[link](https://github.com/hanseuljo/position-coupling)|

#### Abstracts
##### **Reflection-Bench: probing AI intelligence with reflection**
2410.16270v1 by Lingyu Li, Yixu Wang, Haiquan Zhao, Shuqi Kong, Yan Teng, Chunbo Li, Yingchun Wang

The ability to adapt beliefs or behaviors in response to unexpected outcomes,
reflection, is fundamental to intelligent systems' interaction with the world.
From a cognitive science perspective, this serves as a core principle of
intelligence applicable to both human and AI systems. To address the debate on
the intelligence of large language models (LLMs), we propose Reflection-Bench,
a comprehensive benchmark comprising 7 tasks spanning core cognitive functions
crucial for reflection, including perception, memory, belief updating,
decision-making, prediction, counterfactual thinking, and meta-reflection. We
evaluate the performances of 13 prominent LLMs such as OpenAI o1, GPT-4, Claude
3.5 Sonnet, etc. The results indicate that current LLMs still lack satisfactory
reflection ability. We discuss the underlying causes of these results and
suggest potential avenues for future research. In conclusion, Reflection-Bench
offers both evaluation tools and inspiration for developing AI capable of
reliably interacting with the environment. Our data and code are available at
https://github.com/YabYum/ReflectionBench.

摘要：適應信念或行為以應對意外結果的能力，反思，是智慧系統與世界互動的基礎。
從認知科學的角度來看，這作為適用於人類和 AI 系統的智慧核心原則。為了探討大型語言模型 (LLM) 的智慧爭議，我們提出 Reflection-Bench，一個全面的基準，包含涵蓋反思核心認知功能的 7 項任務，包括感知、記憶、信念更新、決策制定、預測、反事實思考和元反思。我們評估了 13 個著名的 LLM 的性能，例如 OpenAI o1、GPT-4、Claude 3.5 Sonnet 等。結果表明，目前的 LLM 仍然缺乏令人滿意的反思能力。我們討論了這些結果的根本原因，並建議了未來研究的潛在途徑。總之，Reflection-Bench 提供了評估工具和靈感，用於開發能夠可靠地與環境互動的 AI。我們的資料和程式碼可在 https://github.com/YabYum/ReflectionBench 取得。

##### **xGen-MM-Vid (BLIP-3-Video): You Only Need 32 Tokens to Represent a Video Even in VLMs**
2410.16267v1 by Michael S. Ryoo, Honglu Zhou, Shrikant Kendre, Can Qin, Le Xue, Manli Shu, Silvio Savarese, Ran Xu, Caiming Xiong, Juan Carlos Niebles

We present xGen-MM-Vid (BLIP-3-Video): a multimodal language model for
videos, particularly designed to efficiently capture temporal information over
multiple frames. BLIP-3-Video takes advantage of the 'temporal encoder' in
addition to the conventional visual tokenizer, which maps a sequence of tokens
over multiple frames into a compact set of visual tokens. This enables
BLIP3-Video to use much fewer visual tokens than its competing models (e.g., 32
vs. 4608 tokens). We explore different types of temporal encoders, including
learnable spatio-temporal pooling as well as sequential models like Token
Turing Machines. We experimentally confirm that BLIP-3-Video obtains video
question-answering accuracies comparable to much larger state-of-the-art models
(e.g., 34B), while being much smaller (i.e., 4B) and more efficient by using
fewer visual tokens. The project website is at
https://www.salesforceairesearch.com/opensource/xGen-MM-Vid/index.html

摘要：我們提出了 xGen-MM-Vid (BLIP-3-Video)：一種多模態語言模型，適用於影片，特別設計用於有效捕捉多個畫格的時間資訊。BLIP-3-Video 除了傳統的視覺標記化器外，還利用「時間編碼器」，將多個畫格的標記序列對應到一組精簡的視覺標記。這使得 BLIP3-Video 能夠使用的視覺標記比競爭模型少得多（例如，32 個標記對 4608 個標記）。我們探索了不同類型的時間編碼器，包括可學習的時空池化以及序列模型，例如標記圖靈機。我們透過實驗確認，BLIP-3-Video 獲得的影片問答準確度可與更大的最先進模型（例如，34B）相媲美，同時體積小得多（即 4B），並且透過使用較少的視覺標記而更有效率。專案網站位於 https://www.salesforceairesearch.com/opensource/xGen-MM-Vid/index.html

##### **3DGS-Enhancer: Enhancing Unbounded 3D Gaussian Splatting with View-consistent 2D Diffusion Priors**
2410.16266v1 by Xi Liu, Chaoyi Zhou, Siyu Huang

Novel-view synthesis aims to generate novel views of a scene from multiple
input images or videos, and recent advancements like 3D Gaussian splatting
(3DGS) have achieved notable success in producing photorealistic renderings
with efficient pipelines. However, generating high-quality novel views under
challenging settings, such as sparse input views, remains difficult due to
insufficient information in under-sampled areas, often resulting in noticeable
artifacts. This paper presents 3DGS-Enhancer, a novel pipeline for enhancing
the representation quality of 3DGS representations. We leverage 2D video
diffusion priors to address the challenging 3D view consistency problem,
reformulating it as achieving temporal consistency within a video generation
process. 3DGS-Enhancer restores view-consistent latent features of rendered
novel views and integrates them with the input views through a spatial-temporal
decoder. The enhanced views are then used to fine-tune the initial 3DGS model,
significantly improving its rendering performance. Extensive experiments on
large-scale datasets of unbounded scenes demonstrate that 3DGS-Enhancer yields
superior reconstruction performance and high-fidelity rendering results
compared to state-of-the-art methods. The project webpage is
https://xiliu8006.github.io/3DGS-Enhancer-project .

摘要：新視圖合成旨在從多個輸入影像或影片產生場景的新視圖，而 3D 高斯散射 (3DGS) 等近期進展已在產生具有高效管線的光寫實渲染方面取得顯著成功。然而，在具有挑戰性的設定下產生高品質的新視圖（例如輸入視圖稀疏）仍然很困難，因為在採樣不足區域中資訊不足，通常會導致明顯的人工製品。本文提出 3DGS-Enhancer，這是一個用於增強 3DGS 表徵品質的新管線。我們利用 2D 影片擴散先驗來解決具有挑戰性的 3D 視圖一致性問題，並將其重新表述為在影片產生過程中實現時間一致性。3DGS-Enhancer 還原渲染新視圖的視圖一致潛在特徵，並透過時空解碼器將它們與輸入視圖整合。然後使用增強的視圖微調初始 3DGS 模型，顯著改善其渲染效能。在無界場景的大規模資料集上進行的廣泛實驗證明，與最先進的方法相比，3DGS-Enhancer 產生了優異的重建效能和高保真渲染結果。專案網頁為 https://xiliu8006.github.io/3DGS-Enhancer-project 。

##### **CompassJudger-1: All-in-one Judge Model Helps Model Evaluation and Evolution**
2410.16256v1 by Maosong Cao, Alexander Lam, Haodong Duan, Hongwei Liu, Songyang Zhang, Kai Chen

Efficient and accurate evaluation is crucial for the continuous improvement
of large language models (LLMs). Among various assessment methods, subjective
evaluation has garnered significant attention due to its superior alignment
with real-world usage scenarios and human preferences. However, human-based
evaluations are costly and lack reproducibility, making precise automated
evaluators (judgers) vital in this process. In this report, we introduce
\textbf{CompassJudger-1}, the first open-source \textbf{all-in-one} judge LLM.
CompassJudger-1 is a general-purpose LLM that demonstrates remarkable
versatility. It is capable of: 1. Performing unitary scoring and two-model
comparisons as a reward model; 2. Conducting evaluations according to specified
formats; 3. Generating critiques; 4. Executing diverse tasks like a general
LLM. To assess the evaluation capabilities of different judge models under a
unified setting, we have also established \textbf{JudgerBench}, a new benchmark
that encompasses various subjective evaluation tasks and covers a wide range of
topics. CompassJudger-1 offers a comprehensive solution for various evaluation
tasks while maintaining the flexibility to adapt to diverse requirements. Both
CompassJudger and JudgerBench are released and available to the research
community athttps://github.com/open-compass/CompassJudger. We believe that by
open-sourcing these tools, we can foster collaboration and accelerate progress
in LLM evaluation methodologies.

摘要：<paragraph>對於大型語言模型 (LLM) 的持續改進而言，有效且準確的評估至關重要。在各種評估方法中，主觀評估因其與真實使用場景和人類偏好的出色對齊而備受關注。然而，基於人類的評估成本高昂且缺乏可複製性，這使得精確的自動化評估器（評審員）在此過程中至關重要。在此報告中，我們介紹了\textbf{CompassJudger-1}，第一個開源的\textbf{一體化}評審 LLM。CompassJudger-1 是一款通用 LLM，展示了非凡的多功能性。它能夠：1. 作為獎勵模型執行單元評分和兩個模型比較；2. 根據指定格式進行評估；3. 生成評論；4. 像通用 LLM 一樣執行多樣化的任務。為了在統一的環境下評估不同評審模型的評估能力，我們還建立了\textbf{JudgerBench}，一個新的基準，涵蓋各種主觀評估任務並涵蓋廣泛的主題。CompassJudger-1 為各種評估任務提供了一個全面的解決方案，同時保持了適應不同需求的靈活性。CompassJudger 和 JudgerBench 都已發布，並可供研究社群在 athttps://github.com/open-compass/CompassJudger 使用。我們相信通過開源這些工具，我們可以促進協作並加速 LLM 評估方法的進展。</paragraph>

##### **Can Knowledge Editing Really Correct Hallucinations?**
2410.16251v1 by Baixiang Huang, Canyu Chen, Xiongxiao Xu, Ali Payani, Kai Shu

Large Language Models (LLMs) suffer from hallucinations, referring to the
non-factual information in generated content, despite their superior capacities
across tasks. Meanwhile, knowledge editing has been developed as a new popular
paradigm to correct the erroneous factual knowledge encoded in LLMs with the
advantage of avoiding retraining from scratch. However, one common issue of
existing evaluation datasets for knowledge editing is that they do not ensure
LLMs actually generate hallucinated answers to the evaluation questions before
editing. When LLMs are evaluated on such datasets after being edited by
different techniques, it is hard to directly adopt the performance to assess
the effectiveness of different knowledge editing methods in correcting
hallucinations. Thus, the fundamental question remains insufficiently
validated: Can knowledge editing really correct hallucinations in LLMs? We
proposed HalluEditBench to holistically benchmark knowledge editing methods in
correcting real-world hallucinations. First, we rigorously construct a massive
hallucination dataset with 9 domains, 26 topics and more than 6,000
hallucinations. Then, we assess the performance of knowledge editing methods in
a holistic way on five dimensions including Efficacy, Generalization,
Portability, Locality, and Robustness. Through HalluEditBench, we have provided
new insights into the potentials and limitations of different knowledge editing
methods in correcting hallucinations, which could inspire future improvements
and facilitate the progress in the field of knowledge editing.

摘要：大型語言模型 (LLM) 儘管在各項任務中表現優異，但仍存在產生的內容中出現非事實資訊的幻覺問題。與此同時，知識編輯已被開發為一種新的流行範例，用於修正 LLM 中編碼的錯誤事實知識，並具有避免從頭開始重新訓練的優點。然而，現有知識編輯評估資料集的一個常見問題是，它們並未確保 LLM 在編輯前實際對評估問題產生幻覺答案。當 LLM 在經過不同技術編輯後在這些資料集上進行評估時，很難直接採用效能來評估不同知識編輯方法在修正幻覺方面的有效性。因此，一個基本問題仍然驗證不足：知識編輯是否真的可以修正 LLM 中的幻覺？我們提出了 HalluEditBench，以全面評量知識編輯方法在修正真實世界幻覺方面的表現。首先，我們嚴謹地建構了一個包含 9 個領域、26 個主題和超過 6,000 個幻覺的龐大幻覺資料集。然後，我們在包括效能、概化、可攜性、局部性和健全性等五個面向全面評估知識編輯方法的表現。透過 HalluEditBench，我們提供了對不同知識編輯方法在修正幻覺方面的潛力和限制的新見解，這可以激勵未來的改進，並促進知識編輯領域的進展。

##### **Analyzing Context Contributions in LLM-based Machine Translation**
2410.16246v1 by Emmanouil Zaranis, Nuno M. Guerreiro, André F. T. Martins

Large language models (LLMs) have achieved state-of-the-art performance in
machine translation (MT) and demonstrated the ability to leverage in-context
learning through few-shot examples. However, the mechanisms by which LLMs use
different parts of the input context remain largely unexplored. In this work,
we provide a comprehensive analysis of context utilization in MT, studying how
LLMs use various context parts, such as few-shot examples and the source text,
when generating translations. We highlight several key findings: (1) the source
part of few-shot examples appears to contribute more than its corresponding
targets, irrespective of translation direction; (2) finetuning LLMs with
parallel data alters the contribution patterns of different context parts; and
(3) there is a positional bias where earlier few-shot examples have higher
contributions to the translated sequence. Finally, we demonstrate that
inspecting anomalous context contributions can potentially uncover pathological
translations, such as hallucinations. Our findings shed light on the internal
workings of LLM-based MT which go beyond those known for standard
encoder-decoder MT models.

摘要：大型語言模型 (LLM) 在機器翻譯 (MT) 中已達到最先進的效能，並證明了透過少數範例進行情境學習的能力。然而，LLM 使用輸入情境不同部分的機制在很大程度上仍未被探索。在這項工作中，我們提供了 MT 中情境利用的全面分析，研究 LLM 在產生翻譯時如何使用各種情境部分，例如少數範例和原始文字。我們強調了幾個關鍵發現：(1) 少數範例的原始部分似乎比其對應的目標貢獻更多，與翻譯方向無關；(2) 使用平行資料微調 LLM 會改變不同情境部分的貢獻模式；(3) 存在位置偏差，其中較早的少數範例對翻譯序列的貢獻較高。最後，我們證明檢查異常的情境貢獻可能會揭露病態的翻譯，例如幻覺。我們的發現闡明了基於 LLM 的 MT 的內部運作，這超出了標準編碼器-解碼器 MT 模型所知的範圍。

##### **MoRE: Multi-Modal Contrastive Pre-training with Transformers on X-Rays, ECGs, and Diagnostic Report**
2410.16239v1 by Samrajya Thapa, Koushik Howlader, Subhankar Bhattacharjee, Wei le

In this paper, we introduce a novel Multi-Modal Contrastive Pre-training
Framework that synergistically combines X-rays, electrocardiograms (ECGs), and
radiology/cardiology reports. Our approach leverages transformers to encode
these diverse modalities into a unified representation space, aiming to enhance
diagnostic accuracy and facilitate comprehensive patient assessments. We
utilize LoRA-Peft to significantly reduce trainable parameters in the LLM and
incorporate recent linear attention dropping strategy in the Vision
Transformer(ViT) for smoother attention. Furthermore, we provide novel
multimodal attention explanations and retrieval for our model. To the best of
our knowledge, we are the first to propose an integrated model that combines
X-ray, ECG, and Radiology/Cardiology Report with this approach. By utilizing
contrastive loss, MoRE effectively aligns modality-specific features into a
coherent embedding, which supports various downstream tasks such as zero-shot
classification and multimodal retrieval. Employing our proposed methodology, we
achieve state-of-the-art (SOTA) on the Mimic-IV, CheXpert, Edema Severity, and
PtbXl downstream datasets, surpassing existing multimodal approaches. Our
proposed framework shows significant improvements in capturing intricate
inter-modal relationships and its robustness in medical diagnosis that
establishes a framework for future research in multimodal learning in the
healthcare sector.

摘要：在本文中，我們介紹了一種新穎的多模態對比預訓練框架，該框架協同結合了 X 射線、心電圖 (ECG) 和放射學/心臟病學報告。我們的做法利用Transformer將這些不同的模態編碼到一個統一的表示空間中，旨在提高診斷準確性並促進全面的患者評估。我們利用 LoRA-Peft 來顯著減少 LLM 中的可訓練參數，並在 Vision Transformer (ViT) 中納入最近的線性注意力下降策略以實現更平滑的注意力。此外，我們為我們的模型提供了新穎的多模態注意力解釋和檢索。據我們所知，我們是第一個提出結合 X 射線、ECG 和放射學/心臟病學報告的整合模型。通過利用對比損失，MoRE 有效地將特定於模態的特徵對齊到一個連貫的嵌入中，這支持了各種下游任務，例如零次分類和多模態檢索。採用我們提出的方法，我們在 Mimic-IV、CheXpert、Edema Severity 和 PtbXl 下游數據集上取得了最先進 (SOTA) 的成就，超越了現有的多模態方法。我們提出的框架在捕捉複雜的模間關係及其在醫療診斷中的穩健性方面顯示出顯著的改進，這為醫療保健領域的多模態學習的未來研究建立了一個框架。

##### **ToW: Thoughts of Words Improve Reasoning in Large Language Models**
2410.16235v1 by Zhikun Xu, Ming Shen, Jacob Dineen, Zhaonan Li, Xiao Ye, Shijie Lu, Aswin RRV, Chitta Baral, Ben Zhou

We introduce thoughts of words (ToW), a novel training-time data-augmentation
method for next-word prediction. ToW views next-word prediction as a core
reasoning task and injects fine-grained thoughts explaining what the next word
should be and how it is related to the previous contexts in pre-training texts.
Our formulation addresses two fundamental drawbacks of existing next-word
prediction learning schemes: they induce factual hallucination and are
inefficient for models to learn the implicit reasoning processes in raw texts.
While there are many ways to acquire such thoughts of words, we explore the
first step of acquiring ToW annotations through distilling from larger models.
After continual pre-training with only 70K ToW annotations, we effectively
improve models' reasoning performances by 7% to 9% on average and reduce model
hallucination by up to 10%. At the same time, ToW is entirely agnostic to tasks
and applications, introducing no additional biases on labels or semantics.

摘要：我們引入了文字思考 (ToW)，一種新穎的訓練時間資料擴充方法，用於下一個字詞預測。ToW 將下一個字詞預測視為一項核心推理任務，並注入精細的思考，說明下一個字詞應該是什麼，以及它如何與預訓練文本中的先前內容相關。我們的表述解決了現有下一個字詞預測學習方案的兩個基本缺點：它們會導致事實性幻覺，而且對於模型學習原始文本中的隱含推理過程而言效率低下。儘管有許多方法可以獲取此類文字思考，但我們探索了透過從較大的模型中萃取來獲取 ToW 標註的第一步。在僅使用 70K ToW 標註進行持續預訓練後，我們有效地將模型的推理效能平均提高了 7% 至 9%，並將模型幻覺減少了多達 10%。同時，ToW 完全不依賴任務和應用，不會對標籤或語義引入額外的偏差。

##### **Sketch2Code: Evaluating Vision-Language Models for Interactive Web Design Prototyping**
2410.16232v1 by Ryan Li, Yanzhe Zhang, Diyi Yang

Sketches are a natural and accessible medium for UI designers to
conceptualize early-stage ideas. However, existing research on UI/UX automation
often requires high-fidelity inputs like Figma designs or detailed screenshots,
limiting accessibility and impeding efficient design iteration. To bridge this
gap, we introduce Sketch2Code, a benchmark that evaluates state-of-the-art
Vision Language Models (VLMs) on automating the conversion of rudimentary
sketches into webpage prototypes. Beyond end-to-end benchmarking, Sketch2Code
supports interactive agent evaluation that mimics real-world design workflows,
where a VLM-based agent iteratively refines its generations by communicating
with a simulated user, either passively receiving feedback instructions or
proactively asking clarification questions. We comprehensively analyze ten
commercial and open-source models, showing that Sketch2Code is challenging for
existing VLMs; even the most capable models struggle to accurately interpret
sketches and formulate effective questions that lead to steady improvement.
Nevertheless, a user study with UI/UX experts reveals a significant preference
for proactive question-asking over passive feedback reception, highlighting the
need to develop more effective paradigms for multi-turn conversational agents.

摘要：草圖是 UI 設計師概念化早期階段想法的自然且易於使用的媒介。然而，現有的 UI/UX 自動化研究通常需要高保真輸入，例如 Figma 設計或詳細螢幕截圖，這限制了可及性並阻礙了高效的設計迭代。為了彌合這一差距，我們引入了 Sketch2Code，這是一個基準測試，用於評估最先進的視覺語言模型 (VLM) 在自動將基本草圖轉換為網頁原型方面的能力。除了端到端基準測試之外，Sketch2Code 還支援互動式代理評估，模擬真實世界的設計工作流程，其中基於 VLM 的代理通過與模擬使用者溝通，被動接收回饋說明或主動詢問澄清問題，以反覆優化其生成。我們全面分析了十個商業和開源模型，表明 Sketch2Code 對現有的 VLM 來說具有挑戰性；即使是最有能力的模型也很難準確地解釋草圖並制定有效的問題，從而導致穩步改進。儘管如此，一項針對 UI/UX 專家的使用者研究顯示，與被動接收回饋相比，主動提問具有顯著的偏好，這凸顯了開發更有效的多輪對話代理範例的必要性。

##### **Building A Coding Assistant via the Retrieval-Augmented Language Model**
2410.16229v1 by Xinze Li, Hanbin Wang, Zhenghao Liu, Shi Yu, Shuo Wang, Shuo Wang, Yukun Yan, Yukai Fu, Yu Gu, Ge Yu

Pretrained language models have shown strong effectiveness in code-related
tasks, such as code retrieval, code generation, code summarization, and code
completion tasks. In this paper, we propose COde assistaNt viA
retrieval-augmeNted language model (CONAN), which aims to build a code
assistant by mimicking the knowledge-seeking behaviors of humans during coding.
Specifically, it consists of a code structure aware retriever (CONAN-R) and a
dual-view code representation-based retrieval-augmented generation model
(CONAN-G). CONAN-R pretrains CodeT5 using Code-Documentation Alignment and
Masked Entity Prediction tasks to make language models code structure-aware and
learn effective representations for code snippets and documentation. Then
CONAN-G designs a dual-view code representation mechanism for implementing a
retrieval-augmented code generation model. CONAN-G regards the code
documentation descriptions as prompts, which help language models better
understand the code semantics. Our experiments show that CONAN achieves
convincing performance on different code generation tasks and significantly
outperforms previous retrieval augmented code generation models. Our further
analyses show that CONAN learns tailored representations for both code snippets
and documentation by aligning code-documentation data pairs and capturing
structural semantics by masking and predicting entities in the code data.
Additionally, the retrieved code snippets and documentation provide necessary
information from both program language and natural language to assist the code
generation process. CONAN can also be used as an assistant for Large Language
Models (LLMs), providing LLMs with external knowledge in shorter code document
lengths to improve their effectiveness on various code tasks. It shows the
ability of CONAN to extract necessary information and help filter out the noise
from retrieved code documents.

摘要：<paragraph>預訓練語言模型在與程式碼相關的任務中展現出強大的效能，例如程式碼擷取、程式碼產生、程式碼摘要和程式碼完成任務。在本文中，我們提出透過擷取增強語言模型（CONAN）的程式碼助理（CONAN），其目的是透過模擬人類在編碼期間尋求知識的行為來建構程式碼助理。具體來說，它包含一個程式碼結構感知擷取器（CONAN-R）和一個基於雙視角程式碼表示的擷取增強產生模型（CONAN-G）。CONAN-R 使用程式碼文件對齊和遮罩實體預測任務預訓練 CodeT5，以使語言模型具有程式碼結構感知，並學習程式碼片段和文件的有效表示。然後，CONAN-G 設計一個雙視角程式碼表示機制，用於實作擷取增強程式碼產生模型。CONAN-G 將程式碼文件描述視為提示，這有助於語言模型更了解程式碼語義。我們的實驗顯示，CONAN 在不同的程式碼產生任務上都能達到令人信服的效能，並且顯著優於先前的擷取增強程式碼產生模型。我們進一步的分析顯示，CONAN 透過對齊程式碼文件資料對並遮罩和預測程式碼資料中的實體來捕捉結構語義，學習程式碼片段和文件的客製化表示。此外，擷取的程式碼片段和文件提供了程式語言和自然語言的必要資訊，以協助程式碼產生過程。CONAN 也可以用作大型語言模型（LLM）的助理，為 LLM 提供較短程式碼文件長度的外部知識，以提高其在各種程式碼任務上的效能。這顯示了 CONAN 從擷取的程式碼文件中擷取必要資訊並協助過濾雜訊的能力。</paragraph>

##### **On Creating an English-Thai Code-switched Machine Translation in Medical Domain**
2410.16221v1 by Parinthapat Pengpun, Krittamate Tiankanon, Amrest Chinkamol, Jiramet Kinchagawat, Pitchaya Chairuengjitjaras, Pasit Supholkhan, Pubordee Aussavavirojekul, Chiraphat Boonnag, Kanyakorn Veerakanjana, Hirunkul Phimsiri, Boonthicha Sae-jia, Nattawach Sataudom, Piyalitt Ittichaiwong, Peerat Limkonchotiwat

Machine translation (MT) in the medical domain plays a pivotal role in
enhancing healthcare quality and disseminating medical knowledge. Despite
advancements in English-Thai MT technology, common MT approaches often
underperform in the medical field due to their inability to precisely translate
medical terminologies. Our research prioritizes not merely improving
translation accuracy but also maintaining medical terminology in English within
the translated text through code-switched (CS) translation. We developed a
method to produce CS medical translation data, fine-tuned a CS translation
model with this data, and evaluated its performance against strong baselines,
such as Google Neural Machine Translation (NMT) and GPT-3.5/GPT-4. Our model
demonstrated competitive performance in automatic metrics and was highly
favored in human preference evaluations. Our evaluation result also shows that
medical professionals significantly prefer CS translations that maintain
critical English terms accurately, even if it slightly compromises fluency. Our
code and test set are publicly available
https://github.com/preceptorai-org/NLLB_CS_EM_NLP2024.

摘要：機器翻譯 (MT) 在醫學領域扮演著關鍵角色，能提升醫療保健品質並傳播醫學知識。儘管英泰機器翻譯技術已有進展，但常見的機器翻譯方法在醫學領域往往表現不佳，因為它們無法精確翻譯醫學術語。我們的研究不僅優先改善翻譯準確度，也透過代碼轉換 (CS) 翻譯，在翻譯後的文字中保留英文醫學術語。我們開發了一種產生 CS 醫學翻譯資料的方法，並使用這些資料微調 CS 翻譯模型，並針對 Google 神經機器翻譯 (NMT) 和 GPT-3.5/GPT-4 等強大的基準進行評估。我們的模型在自動化指標中展現出競爭力，且在人類偏好評估中備受青睞。我們的評估結果也顯示，即使會稍微影響流暢度，醫學專業人員也顯著偏好能精確保留關鍵英文術語的 CS 翻譯。我們的程式碼和測試集已公開 https://github.com/preceptorai-org/NLLB_CS_EM_NLP2024。

##### **Pre-training Distillation for Large Language Models: A Design Space Exploration**
2410.16215v1 by Hao Peng, Xin Lv, Yushi Bai, Zijun Yao, Jiajie Zhang, Lei Hou, Juanzi Li

Knowledge distillation (KD) aims to transfer knowledge from a large teacher
model to a smaller student model. Previous work applying KD in the field of
large language models (LLMs) typically focused on the post-training phase,
where the student LLM learns directly from instructions and corresponding
responses generated by the teacher model. In this paper, we extend KD to the
pre-training phase of LLMs, named pre-training distillation (PD). We first
conduct a preliminary experiment using GLM-4-9B as the teacher LLM to distill a
1.9B parameter student LLM, validating the effectiveness of PD. Considering the
key impact factors of distillation, we systematically explore the design space
of pre-training distillation across four aspects: logits processing, loss
selection, scaling law, and offline or online logits. We conduct extensive
experiments to explore the design space of pre-training distillation and find
better configurations and interesting conclusions, such as larger student LLMs
generally benefiting more from pre-training distillation, while a larger
teacher LLM does not necessarily guarantee better results. We hope our
exploration of the design space will inform future practices in pre-training
distillation.

摘要：知識蒸餾 (KD) 的目標是將知識從大型教師模型傳輸到小型學生模型。先前在大型語言模型 (LLM) 領域中應用 KD 的工作通常專注於後訓練階段，其中學生 LLM 直接從教師模型產生的說明和對應回應中學習。在本文中，我們將 KD 擴展到 LLM 的預訓練階段，稱為預訓練蒸餾 (PD)。我們首先使用 GLM-4-9B 作為教師 LLM 進行初步實驗，以蒸餾 1.9B 參數學生 LLM，驗證 PD 的有效性。考慮到蒸餾的主要影響因素，我們系統地探索了預訓練蒸餾的設計空間，涵蓋四個方面：對數處理、損失選擇、比例定律和離線或線上對數。我們進行了廣泛的實驗，以探索預訓練蒸餾的設計空間，並找出更好的配置和有趣的結論，例如，較大的學生 LLM 通常從預訓練蒸餾中獲益更多，而較大的教師 LLM 並不一定能保證更好的結果。我們希望我們對設計空間的探索將為預訓練蒸餾中的未來實務提供資訊。

##### **Comprehensive benchmarking of large language models for RNA secondary structure prediction**
2410.16212v1 by L. I. Zablocki, L. A. Bugnon, M. Gerard, L. Di Persia, G. Stegmayer, D. H. Milone

Inspired by the success of large language models (LLM) for DNA and proteins,
several LLM for RNA have been developed recently. RNA-LLM uses large datasets
of RNA sequences to learn, in a self-supervised way, how to represent each RNA
base with a semantically rich numerical vector. This is done under the
hypothesis that obtaining high-quality RNA representations can enhance
data-costly downstream tasks. Among them, predicting the secondary structure is
a fundamental task for uncovering RNA functional mechanisms. In this work we
present a comprehensive experimental analysis of several pre-trained RNA-LLM,
comparing them for the RNA secondary structure prediction task in an unified
deep learning framework. The RNA-LLM were assessed with increasing
generalization difficulty on benchmark datasets. Results showed that two LLM
clearly outperform the other models, and revealed significant challenges for
generalization in low-homology scenarios.

摘要：受 DNA 和蛋白质的大语言模型 (LLM) 的成功启发，最近已经开发出几种用于 RNA 的 LLM。RNA-LLM 使用大型 RNA 序列数据集以自监督的方式学习如何用语义丰富的数字向量表示每个 RNA 碱基。这是在假设获得高质量的 RNA 表示可以增强数据成本高昂的下游任务的前提下完成的。其中，预测二级结构是揭示 RNA 功能机制的一项基本任务。在这项工作中，我们对几个经过预训练的 RNA-LLM 进行了全面的实验分析，在统一的深度学习框架中将它们用于 RNA 二级结构预测任务进行了比较。RNA-LLM 在基准数据集上以越来越大的泛化难度进行了评估。结果表明，两个 LLM 明显优于其他模型，并揭示了在低同源性场景中泛化的重大挑战。

##### **Compute-Constrained Data Selection**
2410.16208v1 by Junjie Oscar Yin, Alexander M. Rush

Data selection can reduce the amount of training data needed to finetune
LLMs; however, the efficacy of data selection scales directly with its compute.
Motivated by the practical challenge of compute-constrained finetuning, we
consider the setting in which both the cost of selecting data and training are
budgeted for. We first formalize the problem of data selection with a
cost-aware utility function, and model the data selection problem as trading
off initial-selection cost for training gain. We run a comprehensive sweep of
experiments across multiple tasks, varying compute budget by scaling finetuning
tokens, model sizes, and data selection compute. These experiments show the
validity of this model in real-world experiments. Interestingly we find that
many powerful data selection methods are almost never compute-optimal, and that
cheaper data selection alternatives dominate both from a theoretical and
empirical perspective.

摘要：資料選擇可以減少微調 LLM 所需的訓練資料量；然而，資料選擇的效率與其運算量成正比。在運算量受限的微調的實際挑戰的驅使下，我們考慮了資料選擇和訓練成本都編列預算的設定。我們首先使用具有成本效益的效用函數形式化資料選擇問題，並將資料選擇問題建模為以訓練收益換取初始選擇成本。我們對多項任務執行全面的實驗掃描，透過調整微調權杖、模型大小和資料選擇運算量來改變運算預算。這些實驗顯示了此模型在實際實驗中的有效性。有趣的是，我們發現許多強大的資料選擇方法幾乎從未在運算上達到最佳，而且從理論和經驗角度來看，更便宜的資料選擇替代方案都占優勢。

##### **CoT-TL: Low-Resource Temporal Knowledge Representation of Planning Instructions Using Chain-of-Thought Reasoning**
2410.16207v1 by Kumar Manas, Stefan Zwicklbauer, Adrian Paschke

Autonomous agents often face the challenge of interpreting uncertain natural
language instructions for planning tasks. Representing these instructions as
Linear Temporal Logic (LTL) enables planners to synthesize actionable plans. We
introduce CoT-TL, a data-efficient in-context learning framework for
translating natural language specifications into LTL representations. CoT-TL
addresses the limitations of large language models, which typically rely on
extensive fine-tuning data, by extending chain-of-thought reasoning and
semantic roles to align with the requirements of formal logic creation. This
approach enhances the transparency and rationale behind LTL generation,
fostering user trust. CoT-TL achieves state-of-the-art accuracy across three
diverse datasets in low-data scenarios, outperforming existing methods without
fine-tuning or intermediate translations. To improve reliability and minimize
hallucinations, we incorporate model checking to validate the syntax of the
generated LTL output. We further demonstrate CoT-TL's effectiveness through
ablation studies and evaluations on unseen LTL structures and formulas in a new
dataset. Finally, we validate CoT-TL's practicality by integrating it into a
QuadCopter for multi-step drone planning based on natural language
instructions.

摘要：自主代理經常面臨解讀不確定的自然語言指令以規劃任務的挑戰。將這些指令表示為線性時序邏輯 (LTL) 能讓規劃者綜合可行的計畫。我們引入了 CoT-TL，這是一個資料效率高的情境學習框架，用於將自然語言規格轉換為 LTL 表示。CoT-TL 透過擴展思考鏈推理和語意角色來符合形式邏輯建立的要求，來解決大型語言模型的限制，而大型語言模型通常仰賴廣泛的微調資料。這種方法增強了 LTL 生成的透明度和依據，促進使用者信任。CoT-TL 在三個不同的資料集中，於低資料情境中達成最先進的準確度，在沒有微調或中間轉換的情況下，表現優於現有方法。為了提升可靠度並將幻覺降至最低，我們納入了模型檢查來驗證所產生 LTL 輸出的語法。我們進一步透過消融研究，以及對新資料集中前所未見的 LTL 結構和公式的評估，來證明 CoT-TL 的效能。最後，我們透過將 CoT-TL 整合到四旋翼飛行器中，根據自然語言指令進行多步驟無人機規劃，來驗證 CoT-TL 的實用性。

##### **Systematic Review: Text Processing Algorithms in Machine Learning and Deep Learning for Mental Health Detection on Social Media**
2410.16204v1 by Yuchen Cao, Jianglai Dai, Zhongyan Wang, Yeyubei Zhang, Xiaorui Shen, Yunchong Liu, Yexin Tian

The global rise in depression necessitates innovative detection methods for
early intervention. Social media provides a unique opportunity to identify
depression through user-generated posts. This systematic review evaluates
machine learning (ML) models for depression detection on social media, focusing
on biases and methodological challenges throughout the ML lifecycle. A search
of PubMed, IEEE Xplore, and Google Scholar identified 47 relevant studies
published after 2010. The Prediction model Risk Of Bias ASsessment Tool
(PROBAST) was utilized to assess methodological quality and risk of bias.
Significant biases impacting model reliability and generalizability were found.
There is a predominant reliance on Twitter (63.8%) and English-language content
(over 90%), with most studies focusing on users from the United States and
Europe. Non-probability sampling methods (approximately 80%) limit
representativeness. Only 23% of studies explicitly addressed linguistic nuances
like negations, crucial for accurate sentiment analysis. Inconsistent
hyperparameter tuning was observed, with only 27.7% properly tuning models.
About 17% did not adequately partition data into training, validation, and test
sets, risking overfitting. While 74.5% used appropriate evaluation metrics for
imbalanced data, others relied on accuracy without addressing class imbalance,
potentially skewing results. Reporting transparency varied, often lacking
critical methodological details. These findings highlight the need to diversify
data sources, standardize preprocessing protocols, ensure consistent model
development practices, address class imbalance, and enhance reporting
transparency. By overcoming these challenges, future research can develop more
robust and generalizable ML models for depression detection on social media,
contributing to improved mental health outcomes globally.

摘要：全球憂鬱症的上升趨勢需要創新的偵測方法，以便早期介入。社群媒體透過使用者產生的貼文，提供了一個獨特的機會來識別憂鬱症。這篇系統性回顧針對社群媒體上的憂鬱症偵測，評估機器學習 (ML) 模型，重點關注 ML 生命週期中的偏誤和方法論挑戰。在 PubMed、IEEE Xplore 和 Google Scholar 中搜尋，找出 2010 年後發表的 47 項相關研究。預測模型風險偏誤評估工具 (PROBAST) 被用於評估方法論品質和偏誤風險。發現顯著的偏誤會影響模型的可靠性和概括性。過度依賴 Twitter (63.8%) 和英文內容 (超過 90%)，而且大多數研究都專注於來自美國和歐洲的使用者。非機率抽樣方法 (約 80%) 限制了代表性。只有 23% 的研究明確說明了語言上的細微差別，例如否定，這對於準確的情緒分析至關重要。觀察到不一致的超參數調整，只有 27.7% 適當地調整模型。約 17% 沒有適當地將資料分割成訓練、驗證和測試集，有過度擬合的風險。雖然 74.5% 使用了適當的評估指標來處理不平衡的資料，但其他指標依賴於準確性，而沒有解決類別不平衡的問題，可能會扭曲結果。報告的透明度有所不同，通常缺乏重要的方法論細節。這些發現突顯了多樣化資料來源、標準化前處理協定、確保一致的模型開發實務、解決類別不平衡以及提高報告透明度的必要性。透過克服這些挑戰，未來的研究可以開發出更強大且更具概括性的 ML 模型，用於社群媒體上的憂鬱症偵測，進而改善全球的心理健康成果。

##### **Improve Vision Language Model Chain-of-thought Reasoning**
2410.16198v1 by Ruohong Zhang, Bowen Zhang, Yanghao Li, Haotian Zhang, Zhiqing Sun, Zhe Gan, Yinfei Yang, Ruoming Pang, Yiming Yang

Chain-of-thought (CoT) reasoning in vision language models (VLMs) is crucial
for improving interpretability and trustworthiness. However, current training
recipes lack robust CoT reasoning data, relying on datasets dominated by short
annotations with minimal rationales. In this work, we show that training VLM on
short answers does not generalize well to reasoning tasks that require more
detailed responses. To address this, we propose a two-fold approach. First, we
distill rationales from GPT-4o model to enrich the training data and fine-tune
VLMs, boosting their CoT performance. Second, we apply reinforcement learning
to further calibrate reasoning quality. Specifically, we construct positive
(correct) and negative (incorrect) pairs of model-generated reasoning chains,
by comparing their predictions with annotated short answers. Using this
pairwise data, we apply the Direct Preference Optimization algorithm to refine
the model's reasoning abilities. Our experiments demonstrate significant
improvements in CoT reasoning on benchmark datasets and better generalization
to direct answer prediction as well. This work emphasizes the importance of
incorporating detailed rationales in training and leveraging reinforcement
learning to strengthen the reasoning capabilities of VLMs.

摘要：在視覺語言模型 (VLM) 中，思想鏈 (CoT) 推理對於提升可解釋性和可信度至關重要。然而，目前的訓練範例缺乏穩健的 CoT 推理資料，依賴於由簡短註解（提供最少理由）所主導的資料集。在這項工作中，我們展示在簡短答案上訓練 VLM 無法廣泛應用於需要更詳細回應的推理任務。為了解決這個問題，我們提出一個雙管齊下的方法。首先，我們從 GPT-4o 模型中萃取出理由，以豐富訓練資料並微調 VLM，提升其 CoT 效能。其次，我們運用強化學習進一步校準推理品質。具體來說，我們透過比較模型產生的推理鏈與註解的簡短答案，建構正向（正確）和負向（不正確）的成對資料。使用此成對資料，我們運用直接偏好最佳化演算法來改善模型的推理能力。我們的實驗證明，在基準資料集上的 CoT 推理有顯著的進步，並且在直接答案預測上也有更好的廣泛性。這項工作強調了在訓練中納入詳細理由，並利用強化學習來強化 VLM 推理能力的重要性。

##### **Information for Conversation Generation: Proposals Utilising Knowledge Graphs**
2410.16196v1 by Alex Clay, Ernesto Jiménez-Ruiz

LLMs are frequently used tools for conversational generation. Without
additional information LLMs can generate lower quality responses due to lacking
relevant content and hallucinations, as well as the perception of poor
emotional capability, and an inability to maintain a consistent character.
Knowledge graphs are commonly used forms of external knowledge and may provide
solutions to these challenges. This paper introduces three proposals, utilizing
knowledge graphs to enhance LLM generation. Firstly, dynamic knowledge graph
embeddings and recommendation could allow for the integration of new
information and the selection of relevant knowledge for response generation.
Secondly, storing entities with emotional values as additional features may
provide knowledge that is better emotionally aligned with the user input.
Thirdly, integrating character information through narrative bubbles would
maintain character consistency, as well as introducing a structure that would
readily incorporate new information.

摘要：LLM 經常被用作對話生成工具。沒有
額外資訊，LLM 會產生品質較低的回應，因為缺乏
相關內容和幻覺，以及對情緒能力差的認知，而且無法維持一致的角色。
知識圖譜通常用於外部知識形式，並且可能提供
這些挑戰的解決方案。本文介紹了三項建議，利用
知識圖譜來增強 LLM 生成。首先，動態知識圖譜
嵌入和建議可以整合新的
資訊，並選擇相關知識來產生回應。
其次，將具有情緒價值的實體儲存為額外功能可能
提供與使用者輸入在情緒上更一致的知識。
第三，透過敘事氣泡整合角色資訊會
維持角色一致性，並引入一個結構，可以
輕鬆納入新資訊。

##### **Contamination Report for Multilingual Benchmarks**
2410.16186v1 by Sanchit Ahuja, Varun Gumma, Sunayana Sitaram

Benchmark contamination refers to the presence of test datasets in Large
Language Model (LLM) pre-training or post-training data. Contamination can lead
to inflated scores on benchmarks, compromising evaluation results and making it
difficult to determine the capabilities of models. In this work, we study the
contamination of popular multilingual benchmarks in LLMs that support multiple
languages. We use the Black Box test to determine whether $7$ frequently used
multilingual benchmarks are contaminated in $7$ popular open and closed LLMs
and find that almost all models show signs of being contaminated with almost
all the benchmarks we test. Our findings can help the community determine the
best set of benchmarks to use for multilingual evaluation.

摘要：基準汚染とは、大規模言語モデル (LLM) の事前トレーニングまたは事後トレーニングデータにテストデータセットが存在することを指します。汚染は基準でのスコアを水増しし、評価結果を損ない、モデルの能力を判断することを困難にします。この研究では、複数の言語をサポートする LLM で一般的な多言語基準の汚染を調査します。ブラックボックステストを使用して、7 つの頻繁に使用される多言語基準が 7 つの一般的なオープン LLM およびクローズ LLM で汚染されているかどうかを判断し、ほとんどすべてのモデルがテストしたほとんどすべての基準で汚染の兆候を示していることがわかりました。私たちの調査結果は、コミュニティが多言語評価に使用する基準の最適なセットを決定するのに役立ちます。

##### **RM-Bench: Benchmarking Reward Models of Language Models with Subtlety and Style**
2410.16184v1 by Yantao Liu, Zijun Yao, Rui Min, Yixin Cao, Lei Hou, Juanzi Li

Reward models are critical in techniques like Reinforcement Learning from
Human Feedback (RLHF) and Inference Scaling Laws, where they guide language
model alignment and select optimal responses. Despite their importance,
existing reward model benchmarks often evaluate models by asking them to
distinguish between responses generated by models of varying power. However,
this approach fails to assess reward models on subtle but critical content
changes and variations in style, resulting in a low correlation with policy
model performance. To this end, we introduce RM-Bench, a novel benchmark
designed to evaluate reward models based on their sensitivity to subtle content
differences and resistance to style biases. Extensive experiments demonstrate
that RM-Bench strongly correlates with policy model performance, making it a
reliable reference for selecting reward models to align language models
effectively. We evaluate nearly 40 reward models on RM-Bench. Our results
reveal that even state-of-the-art models achieve an average performance of only
46.6%, which falls short of random-level accuracy (50%) when faced with style
bias interference. These findings highlight the significant room for
improvement in current reward models. Related code and data are available at
https://github.com/THU-KEG/RM-Bench.

摘要：獎勵模型在人類回饋強化學習 (RLHF) 和推論規模定律等技術中至關重要，它們指導語言模型對齊並選擇最佳回應。儘管它們很重要，但現有的獎勵模型基準通常會要求模型區分由不同能力模型產生的回應來評估模型。然而，這種方法無法評估獎勵模型對微妙但重要的內容變更和風格變化的影響，導致與政策模型效能相關性低。為此，我們引入了 RM-Bench，這是一個新基準，旨在根據獎勵模型對微妙內容差異的敏感性和對風格偏見的抵抗力來評估獎勵模型。廣泛的實驗證明 RM-Bench 與政策模型效能密切相關，使其成為選擇獎勵模型以有效對齊語言模型的可靠參考。我們在 RM-Bench 上評估了近 40 個獎勵模型。我們的結果表明，即使是最先進的模型，其平均效能也僅達到 46.6%，在面對風格偏見干擾時，低於隨機層級準確度 (50%)。這些發現突顯了當前獎勵模型有顯著的改進空間。相關程式碼和資料可於 https://github.com/THU-KEG/RM-Bench 取得。

##### **MagicPIG: LSH Sampling for Efficient LLM Generation**
2410.16179v1 by Zhuoming Chen, Ranajoy Sadhukhan, Zihao Ye, Yang Zhou, Jianyu Zhang, Niklas Nolte, Yuandong Tian, Matthijs Douze, Leon Bottou, Zhihao Jia, Beidi Chen

Large language models (LLMs) with long context windows have gained
significant attention. However, the KV cache, stored to avoid re-computation,
becomes a bottleneck. Various dynamic sparse or TopK-based attention
approximation methods have been proposed to leverage the common insight that
attention is sparse. In this paper, we first show that TopK attention itself
suffers from quality degradation in certain downstream tasks because attention
is not always as sparse as expected. Rather than selecting the keys and values
with the highest attention scores, sampling with theoretical guarantees can
provide a better estimation for attention output. To make the sampling-based
approximation practical in LLM generation, we propose MagicPIG, a heterogeneous
system based on Locality Sensitive Hashing (LSH). MagicPIG significantly
reduces the workload of attention computation while preserving high accuracy
for diverse tasks. MagicPIG stores the LSH hash tables and runs the attention
computation on the CPU, which allows it to serve longer contexts and larger
batch sizes with high approximation accuracy. MagicPIG can improve decoding
throughput by $1.9\sim3.9\times$ across various GPU hardware and achieve 110ms
decoding latency on a single RTX 4090 for Llama-3.1-8B-Instruct model with a
context of 96k tokens. The code is available at
\url{https://github.com/Infini-AI-Lab/MagicPIG}.

摘要：具有長背景視窗的大語言模型 (LLM) 獲得廣泛關注。然而，用於避免重新計算的 KV 快取已成為瓶頸。已經提出各種動態稀疏或基於 TopK 的注意力近似方法，以利用注意力是稀疏的共同見解。在本文中，我們首先表明 TopK 注意力本身在某些下游任務中會導致品質下降，因為注意力並非總是像預期的那麼稀疏。與其選擇具有最高注意力分數的鍵和值，不如使用具有理論保證的抽樣可以為注意力輸出提供更好的估計。為了在 LLM 生成中實現基於抽樣的近似，我們提出了 MagicPIG，這是一個基於局部敏感雜湊 (LSH) 的異質系統。MagicPIG 大幅減少了注意力計算的工作負載，同時為各種任務保留了高準確度。MagicPIG 儲存 LSH 雜湊表，並在 CPU 上執行注意力計算，這允許它使用高近似準確度提供更長的背景和更大的批次大小。MagicPIG 可以將各種 GPU 硬體的解碼吞吐量提高 $1.9\sim3.9\times$，並在單個 RTX 4090 上實現 110ms 的解碼延遲，適用於具有 96k 令牌背景的 Llama-3.1-8B-Instruct 模型。程式碼可在
\url{https://github.com/Infini-AI-Lab/MagicPIG} 取得。

##### **Exploring Pretraining via Active Forgetting for Improving Cross Lingual Transfer for Decoder Language Models**
2410.16168v1 by Divyanshu Aggarwal, Ashutosh Sathe, Sunayana Sitaram

Large Language Models (LLMs) demonstrate exceptional capabilities in a
multitude of NLP tasks. However, the efficacy of such models to languages other
than English is often limited. Prior works have shown that encoder-only models
such as BERT or XLM-RoBERTa show impressive cross lingual transfer of their
capabilities from English to other languages. In this work, we propose a
pretraining strategy that uses active forgetting to achieve similar cross
lingual transfer in decoder-only LLMs. We show that LLMs pretrained with active
forgetting are highly effective when adapting to new and unseen languages.
Through extensive experimentation, we find that LLMs pretrained with active
forgetting are able to learn better multilingual representations which
translates to better performance in many downstream tasks.

摘要：大型語言模型 (LLM) 在大量自然語言處理任務中展現出非凡的效能。然而，此類模型在英語以外的語言中，其效能往往受到限制。先前的研究顯示，僅編碼器模型（例如 BERT 或 XLM-RoBERTa）展現出其能力從英語轉移至其他語言的驚人跨語言轉移。在這項研究中，我們提出了一種預訓練策略，該策略使用主動遺忘來達成僅解碼器 LLM 中類似的跨語言轉移。我們證明了使用主動遺忘進行預訓練的 LLM 在適應新的和未見過的語言時非常有效。透過廣泛的實驗，我們發現使用主動遺忘進行預訓練的 LLM 能夠學習到更好的多語言表徵，這轉化為在許多下游任務中獲得更好的效能。

##### **Beyond Filtering: Adaptive Image-Text Quality Enhancement for MLLM Pretraining**
2410.16166v1 by Han Huang, Yuqi Huo, Zijia Zhao, Haoyu Lu, Shu Wu, Bingning Wang, Qiang Liu, Weipeng Chen, Liang Wang

Multimodal large language models (MLLMs) have made significant strides by
integrating visual and textual modalities. A critical factor in training MLLMs
is the quality of image-text pairs within multimodal pretraining datasets.
However, $\textit {de facto}$ filter-based data quality enhancement paradigms
often discard a substantial portion of high-quality image data due to
inadequate semantic alignment between images and texts, leading to
inefficiencies in data utilization and scalability. In this paper, we propose
the Adaptive Image-Text Quality Enhancer (AITQE), a model that dynamically
assesses and enhances the quality of image-text pairs. AITQE employs a text
rewriting mechanism for low-quality pairs and incorporates a negative sample
learning strategy to improve evaluative capabilities by integrating
deliberately selected low-quality samples during training. Unlike prior
approaches that significantly alter text distributions, our method minimally
adjusts text to preserve data volume while enhancing quality. Experimental
results demonstrate that AITQE surpasses existing methods on various benchmark,
effectively leveraging raw data and scaling efficiently with increasing data
volumes. We hope our work will inspire future works. The code and model are
available at: https://github.com/hanhuang22/AITQE.

摘要：多模态大型语言模型 (MLLM) 透过整合视觉和文本模态，取得了重大进展。训练 MLLM 的关键因素是多模态预训练数据集中的图像文本对的质量。然而，事实上基于过滤器的资料品质提升范例，常常会因为图像和文本之间的语意对齐不足，而丢弃大量高品质的图像资料，导致资料使用和可扩展性的低效率。在本文中，我们提出自适应图像文本品质强化器 (AITQE)，这是一个动态评估和提升图像文本对品质的模型。AITQE 对低品质的对使用文本改写机制，并结合负样本学习策略，透过在训练期间整合刻意选取的低品质样本，来提升评估能力。与大幅度改变文本分布的先前方法不同，我们的方法最小幅度地调整文本，以在提升品质的同时保留资料量。实验结果显示，AITQE 在各种基准上都超越现有的方法，有效利用原始资料，并随着资料量的增加而有效扩展。我们希望我们的工作能启发未来的研究。代码和模型可在以下网址取得：https://github.com/hanhuang22/AITQE。

##### **From Tokens to Materials: Leveraging Language Models for Scientific Discovery**
2410.16165v1 by Yuwei Wan, Tong Xie, Nan Wu, Wenjie Zhang, Chunyu Kit, Bram Hoex

Exploring the predictive capabilities of language models in material science
is an ongoing interest. This study investigates the application of language
model embeddings to enhance material property prediction in materials science.
By evaluating various contextual embedding methods and pre-trained models,
including Bidirectional Encoder Representations from Transformers (BERT) and
Generative Pre-trained Transformers (GPT), we demonstrate that domain-specific
models, particularly MatBERT significantly outperform general-purpose models in
extracting implicit knowledge from compound names and material properties. Our
findings reveal that information-dense embeddings from the third layer of
MatBERT, combined with a context-averaging approach, offer the most effective
method for capturing material-property relationships from the scientific
literature. We also identify a crucial "tokenizer effect," highlighting the
importance of specialized text processing techniques that preserve complete
compound names while maintaining consistent token counts. These insights
underscore the value of domain-specific training and tokenization in materials
science applications and offer a promising pathway for accelerating the
discovery and development of new materials through AI-driven approaches.

摘要：探索語言模型在材料科學中的預測能力是一項持續的興趣。本研究探討了語言模型嵌入應用於增強材料科學中材料屬性預測。通過評估各種上下文嵌入方法和預訓練模型，包括來自 Transformer 的雙向編碼器表示（BERT）和生成式預訓練 Transformer（GPT），我們證明了特定領域的模型，特別是 MatBERT 在從化合物名稱和材料屬性中提取隱含知識方面明顯優於通用模型。我們的研究結果表明，來自 MatBERT 第三層的信息密集嵌入與上下文平均方法相結合，提供了一種最有效的方法，可以從科學文獻中獲取材料屬性關係。我們還發現了一個至關重要的「分詞器效應」，強調了專業文本處理技術的重要性，這些技術在保持一致的令牌計數的同時保留了完整的化合物名稱。這些見解強調了特定領域的訓練和分詞在材料科學應用中的價值，並為通過人工智能驅動的方法加速發現和開發新材料提供了一條有前景的途徑。

##### **Sparkle: Mastering Basic Spatial Capabilities in Vision Language Models Elicits Generalization to Composite Spatial Reasoning**
2410.16162v1 by Yihong Tang, Ao Qu, Zhaokai Wang, Dingyi Zhuang, Zhaofeng Wu, Wei Ma, Shenhao Wang, Yunhan Zheng, Zhan Zhao, Jinhua Zhao

Vision language models (VLMs) have demonstrated impressive performance across
a wide range of downstream tasks. However, their proficiency in spatial
reasoning remains limited, despite its crucial role in tasks involving
navigation and interaction with physical environments. Specifically, much of
the spatial reasoning in these tasks occurs in two-dimensional (2D)
environments, and our evaluation reveals that state-of-the-art VLMs frequently
generate implausible and incorrect responses to composite spatial reasoning
problems, including simple pathfinding tasks that humans can solve effortlessly
at a glance. To address this, we explore an effective approach to enhance 2D
spatial reasoning within VLMs by training the model on basic spatial
capabilities. We begin by disentangling the key components of 2D spatial
reasoning: direction comprehension, distance estimation, and localization. Our
central hypothesis is that mastering these basic spatial capabilities can
significantly enhance a model's performance on composite spatial tasks
requiring advanced spatial understanding and combinatorial problem-solving. To
investigate this hypothesis, we introduce Sparkle, a framework that fine-tunes
VLMs on these three basic spatial capabilities by synthetic data generation and
targeted supervision to form an instruction dataset for each capability. Our
experiments demonstrate that VLMs fine-tuned with Sparkle achieve significant
performance gains, not only in the basic tasks themselves but also in
generalizing to composite and out-of-distribution spatial reasoning tasks
(e.g., improving from 13.5% to 40.0% on the shortest path problem). These
findings underscore the effectiveness of mastering basic spatial capabilities
in enhancing composite spatial problem-solving, offering insights for improving
VLMs' spatial reasoning capabilities.

摘要：視覺語言模型 (VLM) 已在廣泛的下游任務中展現出令人印象深刻的效能。然而，儘管它們在空間推理中的熟練度在涉及導航和與物理環境互動的任務中扮演著至關重要的角色，但仍受到限制。具體來說，這些任務中的許多空間推理都發生在二維 (2D) 環境中，而我們的評估顯示，最先進的 VLM 經常對複合空間推理問題產生難以置信且不正確的回應，包括人類可以一瞥而輕鬆解決的簡單尋徑任務。為了解決這個問題，我們探索了一種有效的方法，透過訓練模型的基本空間能力，來增強 VLM 中的 2D 空間推理。我們首先解開 2D 空間推理的關鍵組成部分：方向理解、距離估計和定位。我們的核心假設是，掌握這些基本空間能力可以顯著增強模型在需要進階空間理解和組合問題解決的複合空間任務上的效能。為了研究這個假設，我們引入了 Sparkle，一個透過合成資料產生和針對性監督，針對這三個基本空間能力微調 VLM 的架構，以形成每個能力的指令資料集。我們的實驗證明，使用 Sparkle 微調的 VLM 不僅在基本任務本身中獲得顯著的效能提升，還能推廣到複合和非分佈空間推理任務（例如，在最短路徑問題上從 13.5% 提升到 40.0%）。這些發現強調了掌握基本空間能力在增強複合空間問題解決中的有效性，為改善 VLM 的空間推理能力提供了見解。

##### **Limpeh ga li gong: Challenges in Singlish Annotations**
2410.16156v1 by Lynnette Hui Xian Ng, Luo Qi Chan

Singlish, or Colloquial Singapore English, is a language formed from oral and
social communication within multicultural Singapore. In this work, we work on a
fundamental Natural Language Processing (NLP) task: Parts-Of-Speech (POS)
tagging of Singlish sentences. For our analysis, we build a parallel Singlish
dataset containing direct English translations and POS tags, with translation
and POS annotation done by native Singlish speakers. Our experiments show that
automatic transition- and transformer- based taggers perform with only $\sim
80\%$ accuracy when evaluated against human-annotated POS labels, suggesting
that there is indeed room for improvement on computation analysis of the
language. We provide an exposition of challenges in Singlish annotation: its
inconsistencies in form and semantics, the highly context-dependent particles
of the language, its structural unique expressions, and the variation of the
language on different mediums. Our task definition, resultant labels and
results reflects the challenges in analysing colloquial languages formulated
from a variety of dialects, and paves the way for future studies beyond POS
tagging.

摘要：新加坡式英語，又稱新加坡口語英語，是一種在新加坡多元文化社會中由口頭和社交溝通形成的語言。在這項工作中，我們從事一項基本的自然語言處理 (NLP) 任務：新加坡式英語句子的詞性標記 (POS)。對於我們的分析，我們建立了一個平行的新加坡式英語數據集，其中包含直接的英文翻譯和詞性標記，翻譯和詞性標記是由新加坡式英語母語人士完成的。我們的實驗表明，在根據人工標記的詞性標籤進行評估時，基於自動轉換和變換器的標記器僅能執行約 80% 的準確度，這表明語言的計算分析確實有改進的空間。我們闡述了新加坡式英語標記中的挑戰：其形式和語義的不一致性、高度依賴於語境的語言粒子、其結構獨特的表達方式以及語言在不同媒介上的變化。我們的任務定義、結果標籤和結果反映了分析由各種方言構成的口語語言的挑戰，並為超越詞性標記的未來研究鋪平了道路。

##### **A Troublemaker with Contagious Jailbreak Makes Chaos in Honest Towns**
2410.16155v1 by Tianyi Men, Pengfei Cao, Zhuoran Jin, Yubo Chen, Kang Liu, Jun Zhao

With the development of large language models, they are widely used as agents
in various fields. A key component of agents is memory, which stores vital
information but is susceptible to jailbreak attacks. Existing research mainly
focuses on single-agent attacks and shared memory attacks. However, real-world
scenarios often involve independent memory. In this paper, we propose the
Troublemaker Makes Chaos in Honest Town (TMCHT) task, a large-scale,
multi-agent, multi-topology text-based attack evaluation framework. TMCHT
involves one attacker agent attempting to mislead an entire society of agents.
We identify two major challenges in multi-agent attacks: (1) Non-complete graph
structure, (2) Large-scale systems. We attribute these challenges to a
phenomenon we term toxicity disappearing. To address these issues, we propose
an Adversarial Replication Contagious Jailbreak (ARCJ) method, which optimizes
the retrieval suffix to make poisoned samples more easily retrieved and
optimizes the replication suffix to make poisoned samples have contagious
ability. We demonstrate the superiority of our approach in TMCHT, with 23.51%,
18.95%, and 52.93% improvements in line topology, star topology, and 100-agent
settings. Encourage community attention to the security of multi-agent systems.

摘要：随着大型语言模型的发展，它们被广泛用作各个领域的代理。代理的关键组成部分是记忆，它存储重要信息，但容易受到越狱攻击。现有研究主要集中在单一代理攻击和共享内存攻击上。然而，现实世界中的场景通常涉及独立的内存。在本文中，我们提出了 Troublemaker Makes Chaos in Honest Town (TMCHT) 任务，这是一个大规模、多代理、多拓扑基于文本的攻击评估框架。TMCHT 涉及一个攻击者代理试图误导整个代理社会。我们确定了多代理攻击中的两个主要挑战：(1) 非完整图结构，(2) 大规模系统。我们将这些挑战归因于我们称之为毒性消失的现象。为了解决这些问题，我们提出了一种对抗性复制传染性越狱 (ARCJ) 方法，该方法优化了检索后缀以使中毒样本更容易被检索，并优化了复制后缀以使中毒样本具有传染性。我们在 TMCHT 中展示了我们方法的优越性，在直线拓扑、星形拓扑和 100 代理设置中分别提高了 23.51%、18.95% 和 52.93%。鼓励社区关注多代理系统的安全性。

##### **Pangea: A Fully Open Multilingual Multimodal LLM for 39 Languages**
2410.16153v1 by Xiang Yue, Yueqi Song, Akari Asai, Seungone Kim, Jean de Dieu Nyandwi, Simran Khanuja, Anjali Kantharuban, Lintang Sutawika, Sathyanarayanan Ramamoorthy, Graham Neubig

Despite recent advances in multimodal large language models (MLLMs), their
development has predominantly focused on English- and western-centric datasets
and tasks, leaving most of the world's languages and diverse cultural contexts
underrepresented. This paper introduces Pangea, a multilingual multimodal LLM
trained on PangeaIns, a diverse 6M instruction dataset spanning 39 languages.
PangeaIns features: 1) high-quality English instructions, 2) carefully
machine-translated instructions, and 3) culturally relevant multimodal tasks to
ensure cross-cultural coverage. To rigorously assess models' capabilities, we
introduce PangeaBench, a holistic evaluation suite encompassing 14 datasets
covering 47 languages. Results show that Pangea significantly outperforms
existing open-source models in multilingual settings and diverse cultural
contexts. Ablation studies further reveal the importance of English data
proportions, language popularity, and the number of multimodal training samples
on overall performance. We fully open-source our data, code, and trained
checkpoints, to facilitate the development of inclusive and robust multilingual
MLLMs, promoting equity and accessibility across a broader linguistic and
cultural spectrum.

摘要：儘管多模態大型語言模型 (MLLM) 近期有長足進展，它們的開發主要集中於以英語和西方為中心的資料集和任務上，導致世界上大多數語言和多元文化脈絡都未得到充分的代表。本文介紹了 Pangea，這是一個多語言多模態 LLM，經過 PangeaIns 訓練，PangeaIns 是一個跨越 39 種語言的多元化 6M 指令資料集。PangeaIns 的特色：1) 高品質的英語指令，2) 經過仔細機器翻譯的指令，以及 3) 與文化相關的多模態任務，以確保跨文化涵蓋範圍。為了嚴格評估模型的能力，我們引入了 PangeaBench，這是一個全面的評估套件，涵蓋了 14 個資料集，涵蓋 47 種語言。結果顯示，Pangea 在多語言環境和多元文化脈絡中明顯優於現有的開放原始碼模型。消融研究進一步揭示了英語資料比例、語言普及程度和多模態訓練樣本數量對整體效能的重要性。我們完全開放原始碼、代碼和訓練過的檢查點，以促進包容且強大的多語言 MLLM 的開發，在更廣泛的語言和文化領域推廣公平性和可及性。

##### **Warped Diffusion: Solving Video Inverse Problems with Image Diffusion Models**
2410.16152v2 by Giannis Daras, Weili Nie, Karsten Kreis, Alex Dimakis, Morteza Mardani, Nikola Borislavov Kovachki, Arash Vahdat

Using image models naively for solving inverse video problems often suffers
from flickering, texture-sticking, and temporal inconsistency in generated
videos. To tackle these problems, in this paper, we view frames as continuous
functions in the 2D space, and videos as a sequence of continuous warping
transformations between different frames. This perspective allows us to train
function space diffusion models only on images and utilize them to solve
temporally correlated inverse problems. The function space diffusion models
need to be equivariant with respect to the underlying spatial transformations.
To ensure temporal consistency, we introduce a simple post-hoc test-time
guidance towards (self)-equivariant solutions. Our method allows us to deploy
state-of-the-art latent diffusion models such as Stable Diffusion XL to solve
video inverse problems. We demonstrate the effectiveness of our method for
video inpainting and $8\times$ video super-resolution, outperforming existing
techniques based on noise transformations. We provide generated video results:
https://giannisdaras.github.io/warped_diffusion.github.io/.

摘要：使用图像模型来解决逆视频问题时，通常会出现闪烁、纹理粘连和生成视频的时间不一致问题。为了解决这些问题，在本文中，我们将帧视为 2D 空间中的连续函数，并将视频视为不同帧之间的连续扭曲变换序列。这种观点使我们能够仅在图像上训练函数空间扩散模型，并利用它们来解决时间相关逆问题。函数空间扩散模型需要相对于底层空间变换保持等变性。为了确保时间一致性，我们在事后测试时间指导中引入了一个简单的（自）等变解。我们的方法使我们能够部署最先进的潜在扩散模型（例如 Stable Diffusion XL）来解决视频逆问题。我们展示了我们的方法在视频修复和 8 倍视频超分辨率方面的有效性，优于基于噪声变换的现有技术。我们提供了生成的视频结果：https://giannisdaras.github.io/warped_diffusion.github.io/。

##### **Small Contributions, Small Networks: Efficient Neural Network Pruning Based on Relative Importance**
2410.16151v1 by Mostafa Hussien, Mahmoud Afifi, Kim Khoa Nguyen, Mohamed Cheriet

Recent advancements have scaled neural networks to unprecedented sizes,
achieving remarkable performance across a wide range of tasks. However,
deploying these large-scale models on resource-constrained devices poses
significant challenges due to substantial storage and computational
requirements. Neural network pruning has emerged as an effective technique to
mitigate these limitations by reducing model size and complexity. In this
paper, we introduce an intuitive and interpretable pruning method based on
activation statistics, rooted in information theory and statistical analysis.
Our approach leverages the statistical properties of neuron activations to
identify and remove weights with minimal contributions to neuron outputs.
Specifically, we build a distribution of weight contributions across the
dataset and utilize its parameters to guide the pruning process. Furthermore,
we propose a Pruning-aware Training strategy that incorporates an additional
regularization term to enhance the effectiveness of our pruning method.
Extensive experiments on multiple datasets and network architectures
demonstrate that our method consistently outperforms several baseline and
state-of-the-art pruning techniques.

摘要：最近的進展已將神經網路擴展到前所未有的規模，在廣泛的任務中實現了顯著的效能。然而，由於大量的儲存和運算需求，在資源受限的裝置上部署這些大規模模型會帶來重大的挑戰。神經網路剪枝已成為一種有效的技術，可透過減少模型大小和複雜度來減輕這些限制。在本文中，我們介紹了一種基於啟用統計的直覺且可解釋的剪枝方法，其根植於資訊理論和統計分析。我們的做法利用神經元啟用的統計特性來識別並移除對神經元輸出貢獻最小的權重。具體來說，我們建立了跨資料集的權重貢獻分佈，並利用其參數來指導剪枝過程。此外，我們提出了一個剪枝感知訓練策略，其中包含一個額外的正則化項，以增強我們剪枝方法的有效性。在多個資料集和網路架構上的廣泛實驗表明，我們的模型始終優於多種基線和最先進的剪枝技術。

##### **PODTILE: Facilitating Podcast Episode Browsing with Auto-generated Chapters**
2410.16148v1 by Azin Ghazimatin, Ekaterina Garmash, Gustavo Penha, Kristen Sheets, Martin Achenbach, Oguz Semerci, Remi Galvez, Marcus Tannenberg, Sahitya Mantravadi, Divya Narayanan, Ofeliya Kalaydzhyan, Douglas Cole, Ben Carterette, Ann Clifton, Paul N. Bennett, Claudia Hauff, Mounia Lalmas

Listeners of long-form talk-audio content, such as podcast episodes, often
find it challenging to understand the overall structure and locate relevant
sections. A practical solution is to divide episodes into
chapters--semantically coherent segments labeled with titles and timestamps.
Since most episodes on our platform at Spotify currently lack creator-provided
chapters, automating the creation of chapters is essential. Scaling the
chapterization of podcast episodes presents unique challenges. First, episodes
tend to be less structured than written texts, featuring spontaneous
discussions with nuanced transitions. Second, the transcripts are usually
lengthy, averaging about 16,000 tokens, which necessitates efficient processing
that can preserve context. To address these challenges, we introduce PODTILE, a
fine-tuned encoder-decoder transformer to segment conversational data. The
model simultaneously generates chapter transitions and titles for the input
transcript. To preserve context, each input text is augmented with global
context, including the episode's title, description, and previous chapter
titles. In our intrinsic evaluation, PODTILE achieved an 11% improvement in
ROUGE score over the strongest baseline. Additionally, we provide insights into
the practical benefits of auto-generated chapters for listeners navigating
episode content. Our findings indicate that auto-generated chapters serve as a
useful tool for engaging with less popular podcasts. Finally, we present
empirical evidence that using chapter titles can enhance effectiveness of
sparse retrieval in search tasks.

摘要：<paragraph>聆聽長篇談話式音訊內容（例如播客節目）的聽眾，通常很難理解整體結構並找到相關部分。一個實用的解決方案是將節目分為章節，即標記有標題和時間戳的語義連貫區段。由於 Spotify 上我們平台上的大多數節目目前缺乏創作者提供的章節，因此自動建立章節至關重要。對播客節目進行章節化的擴展提出了獨特的挑戰。首先，節目往往不如書面文本結構化，而是以自發的討論和微妙的過渡為特色。其次，謄本通常很長，平均約 16,000 個詞彙，這需要能夠保留上下文的有效處理。為了應對這些挑戰，我們引入了 PODTILE，一個經過微調的編碼器-解碼器轉換器，用於對話數據進行分段。該模型同時為輸入謄本生成章節轉換和標題。為了保留上下文，每個輸入文本都附有全局上下文，包括節目的標題、描述和前一章節的標題。在我們的內部評估中，PODTILE 的 ROUGE 得分比最強的基準線提高了 11%。此外，我們提供了對自動生成章節對聽眾瀏覽節目內容的實際好處的見解。我們的研究結果表明，自動生成的章節可用作與不太流行的播客互動的有用工具。最後，我們提出了經實證證明的證據，表明使用章節標題可以提高搜索任務中稀疏檢索的有效性。</paragraph>

##### **1-bit AI Infra: Part 1.1, Fast and Lossless BitNet b1.58 Inference on CPUs**
2410.16144v1 by Jinheng Wang, Hansong Zhou, Ting Song, Shaoguang Mao, Shuming Ma, Hongyu Wang, Yan Xia, Furu Wei

Recent advances in 1-bit Large Language Models (LLMs), such as BitNet and
BitNet b1.58, present a promising approach to enhancing the efficiency of LLMs
in terms of speed and energy consumption. These developments also enable local
LLM deployment across a broad range of devices. In this work, we introduce
bitnet.cpp, a tailored software stack designed to unlock the full potential of
1-bit LLMs. Specifically, we develop a set of kernels to support fast and
lossless inference of ternary BitNet b1.58 LLMs on CPUs. Extensive experiments
demonstrate that bitnet.cpp achieves significant speedups, ranging from 2.37x
to 6.17x on x86 CPUs and from 1.37x to 5.07x on ARM CPUs, across various model
sizes. The code is available at https://github.com/microsoft/BitNet.

摘要：最近在 1 位大型語言模型 (LLM) 的進展，例如 BitNet 和 BitNet b1.58，提供了一個有希望的方法來提高 LLM 在速度和能源消耗方面的效率。這些發展也讓 LLM 在廣泛的裝置上進行本機部署。在這個工作中，我們介紹 bitnet.cpp，一個量身打造的軟體堆疊，旨在釋放 1 位 LLM 的全部潛力。具體來說，我們開發了一組核心來支援 CPU 上三元 BitNet b1.58 LLM 的快速且無損推論。廣泛的實驗證明，bitnet.cpp 獲得顯著的加速，在 x86 CPU 上從 2.37 倍到 6.17 倍，在 ARM CPU 上從 1.37 倍到 5.07 倍，涵蓋各種模型大小。程式碼可在 https://github.com/microsoft/BitNet 取得。

##### **A Psycholinguistic Evaluation of Language Models' Sensitivity to Argument Roles**
2410.16139v1 by Eun-Kyoung Rosa Lee, Sathvik Nair, Naomi Feldman

We present a systematic evaluation of large language models' sensitivity to
argument roles, i.e., who did what to whom, by replicating psycholinguistic
studies on human argument role processing. In three experiments, we find that
language models are able to distinguish verbs that appear in plausible and
implausible contexts, where plausibility is determined through the relation
between the verb and its preceding arguments. However, none of the models
capture the same selective patterns that human comprehenders exhibit during
real-time verb prediction. This indicates that language models' capacity to
detect verb plausibility does not arise from the same mechanism that underlies
human real-time sentence processing.

摘要：我們透過複製心理語言學中關於人類論元角色處理的研究，對大型語言模型對論元角色（即誰對誰做了什麼）的敏感度進行系統評估。在三個實驗中，我們發現語言模型能夠區分出在合理和不合理語境中出現的動詞，其中合理性是由動詞及其前置論元之間的關係決定的。然而，沒有任何模型能捕捉到人類理解者在動詞預測的實時過程中表現出的相同選擇模式。這表明語言模型檢測動詞合理性的能力並非源自人類實時句子處理的基礎機制。

##### **Modeling dynamic neural activity by combining naturalistic video stimuli and stimulus-independent latent factors**
2410.16136v1 by Finn Schmidt, Suhas Shrinivasan, Polina Turishcheva, Fabian H. Sinz

Understanding how the brain processes dynamic natural stimuli remains a
fundamental challenge in neuroscience. Current dynamic neural encoding models
either take stimuli as input but ignore shared variability in neural responses,
or they model this variability by deriving latent embeddings from neural
responses or behavior while ignoring the visual input. To address this gap, we
propose a probabilistic model that incorporates video inputs along with
stimulus-independent latent factors to capture variability in neuronal
responses, predicting a joint distribution for the entire population. After
training and testing our model on mouse V1 neuronal responses, we found that it
outperforms video-only models in terms of log-likelihood and achieves further
improvements when conditioned on responses from other neurons. Furthermore, we
find that the learned latent factors strongly correlate with mouse behavior,
although the model was trained without behavior data.

摘要：了解大脑如何处理动态自然刺激仍然是神经科学中的一个基本挑战。当前的动态神经编码模型要么将刺激作为输入，但忽略神经反应中的共享变异性，要么通过从神经反应或行为中导出潜在嵌入来建模这种变异性，同时忽略视觉输入。为了解决这一差距，我们提出了一个概率模型，该模型将视频输入与独立于刺激的潜在因素结合起来，以捕获神经元反应中的变异性，预测整个种群的联合分布。在对小鼠 V1 神经元反应进行模型训练和测试后，我们发现它在对数似然方面优于仅视频模型，并且在以其他神经元的反应为条件时取得了进一步的改进。此外，我们发现学习到的潜在因素与小鼠行为密切相关，尽管该模型是在没有行为数据的情况下进行训练的。

##### **Beyond 2:4: exploring V:N:M sparsity for efficient transformer inference on GPUs**
2410.16135v1 by Kang Zhao, Tao Yuan, Han Bao, Zhenfeng Su, Chang Gao, Zhaofeng Sun, Zichen Liang, Liping Jing, Jianfei Chen

To date, 2:4 sparsity has stood as the only sparse pattern that can be
accelerated using sparse tensor cores on GPUs. In practice, 2:4 sparsity often
possesses low actual speedups ($\leq 1.3$) and requires fixed sparse ratios,
meaning that other ratios, such as 4:8, 8:16, or those exceeding 50% sparsity,
do not incur any speedups on GPUs. Recent studies suggest that V:N:M sparsity
is promising in addressing these limitations of 2:4 sparsity. However,
regarding accuracy, the effects of V:N:M sparsity on broader Transformer
models, such as vision Transformers and large language models (LLMs), are
largely unexamined. Moreover, Some specific issues related to V:N:M sparsity,
such as how to select appropriate V and M values, remain unresolved. In this
study, we thoroughly investigate the application of V:N:M sparsity in vision
models and LLMs across multiple tasks, from pertaining to downstream tasks. We
propose three key approaches to enhance the applicability and accuracy of
V:N:M-sparse Transformers, including heuristic V and M selection,
V:N:M-specific channel permutation, and three-staged LoRA training techniques.
Experimental results show that, with our methods, the DeiT-small achieves
lossless accuracy at 64:2:5 sparsity, while the DeiT-base maintains accuracy
even at 64:2:8 sparsity. In addition, the fine-tuned LLama2-7B at 64:2:5
sparsity performs comparably or better than training-free 2:4 sparse
alternatives on downstream tasks. More importantly, V:N:M-sparse Transformers
offer a wider range of speedup-accuracy trade-offs compared to 2:4 sparsity.
Overall, our exploration largely facilitates the V:N:M sparsity to act as a
truly effective acceleration solution for Transformers in cost-sensitive
inference scenarios.

摘要：迄今为止，2:4 稀疏性一直是唯一可以使用 GPU 上的稀疏张量核加速的稀疏模式。在实践中，2:4 稀疏性通常具有较低的实际加速（≤ 1.3），并且需要固定的稀疏比率，这意味着其他比率，例如 4:8、8:16 或超过 50% 稀疏性的比率，不会在 GPU 上产生任何加速。最近的研究表明，V:N:M 稀疏性有望解决 2:4 稀疏性的这些限制。然而，在准确性方面，V:N:M 稀疏性对更广泛的 Transformer 模型（例如视觉 Transformer 和大型语言模型 (LLM)）的影响在很大程度上尚未得到检验。此外，与 V:N:M 稀疏性相关的一些具体问题，例如如何选择合适的 V 和 M 值，仍然没有得到解决。在这项研究中，我们彻底研究了 V:N:M 稀疏性在视觉模型和 LLM 中的应用，涵盖从属于下游任务的多个任务。我们提出了三种关键方法来增强 V:N:M 稀疏 Transformer 的适用性和准确性，包括启发式 V 和 M 选择、V:N:M 特定通道置换和三阶段 LoRA 训练技术。实验结果表明，使用我们的方法，DeiT-small 在 64:2:5 稀疏性下实现了无损准确性，而 DeiT-base 即使在 64:2:8 稀疏性下也能保持准确性。此外，在 64:2:5 稀疏性下微调的 LLama2-7B 在下游任务上的表现与无训练 2:4 稀疏替代方案相当或更好。更重要的是，与 2:4 稀疏性相比，V:N:M 稀疏 Transformer 提供了更广泛的加速精度权衡。总体而言，我们的探索极大地促进了 V:N:M 稀疏性作为成本敏感型推理场景中 Transformer 的真正有效的加速解决方案。

##### **A Data-driven Crowd Simulation Framework Integrating Physics-informed Machine Learning with Navigation Potential Fields**
2410.16132v1 by Runkang Guo, Bin Chen, Qi Zhang, Yong Zhao, Xiao Wang, Zhengqiu Zhu

Traditional rule-based physical models are limited by their reliance on
singular physical formulas and parameters, making it difficult to effectively
tackle the intricate tasks associated with crowd simulation. Recent research
has introduced deep learning methods to tackle these issues, but most current
approaches focus primarily on generating pedestrian trajectories, often lacking
interpretability and failing to provide real-time dynamic simulations.To
address the aforementioned issues, we propose a novel data-driven crowd
simulation framework that integrates Physics-informed Machine Learning (PIML)
with navigation potential fields. Our approach leverages the strengths of both
physical models and PIML. Specifically, we design an innovative
Physics-informed Spatio-temporal Graph Convolutional Network (PI-STGCN) as a
data-driven module to predict pedestrian movement trends based on crowd
spatio-temporal data. Additionally, we construct a physical model of navigation
potential fields based on flow field theory to guide pedestrian movements,
thereby reinforcing physical constraints during the simulation. In our
framework, navigation potential fields are dynamically computed and updated
based on the movement trends predicted by the PI-STGCN, while the updated crowd
dynamics, guided by these fields, subsequently feed back into the PI-STGCN.
Comparative experiments on two publicly available large-scale real-world
datasets across five scenes demonstrate that our proposed framework outperforms
existing rule-based methods in accuracy and fidelity. The similarity between
simulated and actual pedestrian trajectories increases by 10.8%, while the
average error is reduced by 4%. Moreover, our framework exhibits greater
adaptability and better interpretability compared to methods that rely solely
on deep learning for trajectory generation.

摘要：<paragraph>傳統的基於規則的物理模型受到對單一物理公式和參數的依賴所限，這使得有效應對與群體模擬相關的複雜任務變得困難。最近的研究引入了深度學習方法來解決這些問題，但目前大多數方法主要集中在生成行人軌跡上，往往缺乏可解釋性，並且無法提供實時的動態模擬。為了解決上述問題，我們提出了一個新穎的數據驅動型群體模擬框架，該框架將物理信息機器學習 (PIML) 與導航勢場相結合。我們的做法利用了物理模型和 PIML 的優勢。具體來說，我們設計了一個創新的物理信息時空圖卷積神經網絡 (PI-STGCN) 作為一個數據驅動模塊，基於群體時空數據預測行人運動趨勢。此外，我們基於流場理論構建了一個導航勢場物理模型來指導行人運動，從而加強了模擬過程中的物理約束。在我們的框架中，導航勢場是根據 PI-STGCN 預測的運動趨勢動態計算和更新的，而由這些場引導的更新後的群體動態隨後反饋到 PI-STGCN 中。在五個場景中對兩個公開可用的大型真實世界數據集進行的比較實驗表明，我們提出的框架在準確性和保真度方面優於現有的基於規則的方法。模擬行人軌跡與實際行人軌跡之間的相似性提高了 10.8%，而平均誤差降低了 4%。此外，與僅依賴深度學習進行軌跡生成的那些方法相比，我們的框架表現出更高的適應性和更好的可解釋性。</paragraph>

##### **Can Large Audio-Language Models Truly Hear? Tackling Hallucinations with Multi-Task Assessment and Stepwise Audio Reasoning**
2410.16130v1 by Chun-Yi Kuan, Hung-yi Lee

Recent advancements in large audio-language models (LALMs) have shown
impressive capabilities in understanding and reasoning about audio and speech
information. However, these models still face challenges, including
hallucinating non-existent sound events, misidentifying the order of sound
events, and incorrectly attributing sound sources, which undermine their
reliability and real-world application. To systematically evaluate these
issues, we propose three distinct tasks: object existence, temporal order, and
object attribute within audio. These tasks assess the models' comprehension of
critical audio information aspects. Our experimental results reveal limitations
in these fundamental tasks, underscoring the need for better models in
recognizing specific sound events, determining event sequences, and identifying
sound sources. To improve performance in these areas, we introduce a multi-turn
chain-of-thought approach, which demonstrates significantly improved model
performance across the proposed tasks.

摘要：大型語言音訊模型 (LALM) 近期的進展顯示出在理解和推論音訊和語音資訊方面具有令人印象深刻的能力。然而，這些模型仍然面臨挑戰，包括產生不存在的聲音事件、誤認聲音事件的順序，以及錯誤地歸因聲音來源，這會損害它們的可靠性和實際應用。為了系統地評估這些問題，我們提出了三個不同的任務：物件存在、時間順序和音訊中的物件屬性。這些任務評估模型對關鍵音訊資訊面向的理解。我們的實驗結果揭示了這些基本任務的限制，強調了需要更好的模型來識別特定聲音事件、確定事件順序和識別聲音來源。為了改善這些領域的效能，我們引入了一個多輪思考鏈方法，該方法證明了在所提出的任務中模型效能顯著提升。

##### **SMART: Self-learning Meta-strategy Agent for Reasoning Tasks**
2410.16128v1 by Rongxing Liu, Kumar Shridhar, Manish Prajapat, Patrick Xia, Mrinmaya Sachan

Tasks requiring deductive reasoning, especially those involving multiple
steps, often demand adaptive strategies such as intermediate generation of
rationales or programs, as no single approach is universally optimal. While
Language Models (LMs) can enhance their outputs through iterative
self-refinement and strategy adjustments, they frequently fail to apply the
most effective strategy in their first attempt. This inefficiency raises the
question: Can LMs learn to select the optimal strategy in the first attempt,
without a need for refinement? To address this challenge, we introduce SMART
(Self-learning Meta-strategy Agent for Reasoning Tasks), a novel framework that
enables LMs to autonomously learn and select the most effective strategies for
various reasoning tasks. We model the strategy selection process as a Markov
Decision Process and leverage reinforcement learning-driven continuous
self-improvement to allow the model to find the suitable strategy to solve a
given task. Unlike traditional self-refinement methods that rely on multiple
inference passes or external feedback, SMART allows an LM to internalize the
outcomes of its own reasoning processes and adjust its strategy accordingly,
aiming for correct solutions on the first attempt. Our experiments across
various reasoning datasets and with different model architectures demonstrate
that SMART significantly enhances the ability of models to choose optimal
strategies without external guidance (+15 points on the GSM8K dataset). By
achieving higher accuracy with a single inference pass, SMART not only improves
performance but also reduces computational costs for refinement-based
strategies, paving the way for more efficient and intelligent reasoning in LMs.

摘要：<paragraph>需要演绎推理的任务，特别是涉及多个步骤的任务，通常需要自适应策略，例如中间生成原理或程序，因为没有一种方法在所有情况下都是最优的。虽然语言模型 (LM) 可以通过迭代自我优化和策略调整来增强其输出，但它们经常无法在第一次尝试中应用最有效的策略。这种低效率提出了一个问题：LM 能否在第一次尝试中学会选择最佳策略，而不需要优化？为了应对这一挑战，我们引入了 SMART（推理任务的自学习元策略代理），这是一个新框架，使 LM 能够自主学习和选择各种推理任务的最有效策略。我们将策略选择过程建模为马尔可夫决策过程，并利用强化学习驱动的持续自我改进，让模型找到解决给定任务的合适策略。与依赖于多次推理传递或外部反馈的传统自我优化方法不同，SMART 允许 LM 内化其自身推理过程的结果，并相应地调整其策略，旨在在第一次尝试中找到正确的解决方案。我们在各种推理数据集和不同模型架构上的实验表明，SMART 显着增强了模型在没有外部指导的情况下选择最佳策略的能力（在 GSM8K 数据集上提高了 15 分）。通过单次推理传递实现更高的准确性，SMART 不仅提高了性能，而且还降低了基于优化策略的计算成本，为 LM 中更有效和智能的推理铺平了道路。</paragraph>

##### **SeaDAG: Semi-autoregressive Diffusion for Conditional Directed Acyclic Graph Generation**
2410.16119v1 by Xinyi Zhou, Xing Li, Yingzhao Lian, Yiwen Wang, Lei Chen, Mingxuan Yuan, Jianye Hao, Guangyong Chen, Pheng Ann Heng

We introduce SeaDAG, a semi-autoregressive diffusion model for conditional
generation of Directed Acyclic Graphs (DAGs). Considering their inherent
layer-wise structure, we simulate layer-wise autoregressive generation by
designing different denoising speed for different layers. Unlike conventional
autoregressive generation that lacks a global graph structure view, our method
maintains a complete graph structure at each diffusion step, enabling
operations such as property control that require the full graph structure.
Leveraging this capability, we evaluate the DAG properties during training by
employing a graph property decoder. We explicitly train the model to learn
graph conditioning with a condition loss, which enhances the diffusion model's
capacity to generate graphs that are both realistic and aligned with specified
properties. We evaluate our method on two representative conditional DAG
generation tasks: (1) circuit generation from truth tables, where precise DAG
structures are crucial for realizing circuit functionality, and (2) molecule
generation based on quantum properties. Our approach demonstrates promising
results, generating high-quality and realistic DAGs that closely align with
given conditions.

摘要：我們介紹 SeaDAG，一種用於有向無環圖 (DAG) 條件生成的半自迴歸擴散模型。考慮到它們固有的逐層結構，我們透過為不同層設計不同的去噪速度，來模擬逐層自迴歸生成。與缺乏全局圖結構觀點的傳統自迴歸生成不同，我們的方法在每個擴散步驟中維護一個完整的圖結構，從而能夠執行需要完整圖結構的運算，例如屬性控制。利用此功能，我們在訓練期間透過使用圖屬性解碼器來評估 DAG 屬性。我們明確訓練模型，以條件損失學習圖條件，這增強了擴散模型生成既真實又與指定屬性對齊的圖形的能力。我們在兩個具代表性的條件 DAG 生成任務上評估我們的方法：(1) 從真值表中生成電路，其中精確的 DAG 結構對於實現電路功能至關重要，以及 (2) 基於量子屬性的分子生成。我們的做法展示了有希望的結果，生成了與給定條件緊密對齊的高品質且真實的 DAG。

##### **Multimodal Flare Forecasting with Deep Learning**
2410.16116v1 by Grégoire Francisco, Sabrina Guastavino, Teresa Barata, João Fernandes, Dario Del Moro

Solar flare forecasting mainly relies on photospheric magnetograms and
associated physical features to predict forthcoming flares. However, it is
believed that flare initiation mechanisms often originate in the chromosphere
and the lower corona. In this study, we employ deep learning as a purely
data-driven approach to compare the predictive capabilities of chromospheric
and coronal UV and EUV emissions across different wavelengths with those of
photospheric line-of-sight magnetograms. Our findings indicate that individual
EUV wavelengths can provide discriminatory power comparable or better to that
of line-of-sight magnetograms. Moreover, we identify simple multimodal neural
network architectures that consistently outperform single-input models, showing
complementarity between the flare precursors that can be extracted from the
distinct layers of the solar atmosphere. To mitigate potential biases from
known misattributions in Active Region flare catalogs, our models are trained
and evaluated using full-disk images and a comprehensive flare event catalog at
the full-disk level. We introduce a deep-learning architecture suited for
extracting temporal features from full-disk videos.

摘要：太陽耀斑預測主要依賴光球磁像儀和相關物理特徵來預測即將發生的耀斑。然而，人們認為耀斑引發機制通常起源於色球和日冕下層。在本研究中，我們採用深度學習作為純粹的資料驅動方法，比較不同波長的色球和日冕紫外線和極紫外線發射的預測能力，以及光球視線磁像儀的預測能力。我們的研究結果表明，個別極紫外線波長可以提供與視線磁像儀相當或更好的區分能力。此外，我們識別出簡單的多模式神經網路架構，其始終優於單輸入模型，顯示了可以從太陽大氣不同層中提取的耀斑前兆之間的互補性。為了減輕已知活動區耀斑目錄中錯誤歸因的潛在偏差，我們的模型使用全圓盤影像和全圓盤層級的綜合耀斑事件目錄進行訓練和評估。我們引入了一種深度學習架構，適用於從全圓盤影片中提取時間特徵。

##### **Do LLMs write like humans? Variation in grammatical and rhetorical styles**
2410.16107v1 by Alex Reinhart, David West Brown, Ben Markey, Michael Laudenbach, Kachatad Pantusen, Ronald Yurko, Gordon Weinberg

Large language models (LLMs) are capable of writing grammatical text that
follows instructions, answers questions, and solves problems. As they have
advanced, it has become difficult to distinguish their output from
human-written text. While past research has found some differences in surface
features such as word choice and punctuation, and developed classifiers to
detect LLM output, none has studied the rhetorical styles of LLMs.
  Using several variants of Llama 3 and GPT-4o, we construct two parallel
corpora of human- and LLM-written texts from common prompts. Using Douglas
Biber's set of lexical, grammatical, and rhetorical features, we identify
systematic differences between LLMs and humans and between different LLMs.
These differences persist when moving from smaller models to larger ones, and
are larger for instruction-tuned models than base models. This demonstrates
that despite their advanced abilities, LLMs struggle to match human styles, and
hence more advanced linguistic features can detect patterns in their behavior
not previously recognized.

摘要：大型語言模型 (LLM) 能撰寫符合文法規範的文字，遵循指示、回答問題和解決問題。隨著它們的進步，要區分它們的輸出和人類撰寫的文字已變得困難。雖然過去的研究發現了一些表層特徵的差異，例如詞彙選擇和標點符號，並開發了分類器來偵測 LLM 輸出，但沒有研究探討 LLM 的修辭風格。
我們使用 Llama 3 和 GPT-4o 的幾個變體，從常見提示中建構了兩組人類和 LLM 撰寫的平行語料庫。使用 Douglas Biber 的一組詞彙、語法和修辭特徵，我們辨識出 LLM 和人類之間以及不同 LLM 之間的系統性差異。這些差異在從較小的模型轉移到較大的模型時仍然存在，並且對於經過指令調整的模型來說比基礎模型更大。這表明儘管 LLM 具有先進的能力，但它們仍難以匹配人類的風格，因此更先進的語言特徵可以偵測到它們行為中以前無法辨識的模式。

##### **Addressing Spectral Bias of Deep Neural Networks by Multi-Grade Deep Learning**
2410.16105v1 by Ronglong Fang, Yuesheng Xu

Deep neural networks (DNNs) suffer from the spectral bias, wherein DNNs
typically exhibit a tendency to prioritize the learning of lower-frequency
components of a function, struggling to capture its high-frequency features.
This paper is to address this issue. Notice that a function having only low
frequency components may be well-represented by a shallow neural network (SNN),
a network having only a few layers. By observing that composition of low
frequency functions can effectively approximate a high-frequency function, we
propose to learn a function containing high-frequency components by composing
several SNNs, each of which learns certain low-frequency information from the
given data. We implement the proposed idea by exploiting the multi-grade deep
learning (MGDL) model, a recently introduced model that trains a DNN
incrementally, grade by grade, a current grade learning from the residue of the
previous grade only an SNN composed with the SNNs trained in the preceding
grades as features. We apply MGDL to synthetic, manifold, colored images, and
MNIST datasets, all characterized by presence of high-frequency features. Our
study reveals that MGDL excels at representing functions containing
high-frequency information. Specifically, the neural networks learned in each
grade adeptly capture some low-frequency information, allowing their
compositions with SNNs learned in the previous grades effectively representing
the high-frequency features. Our experimental results underscore the efficacy
of MGDL in addressing the spectral bias inherent in DNNs. By leveraging MGDL,
we offer insights into overcoming spectral bias limitation of DNNs, thereby
enhancing the performance and applicability of deep learning models in tasks
requiring the representation of high-frequency information. This study confirms
that the proposed method offers a promising solution to address the spectral
bias of DNNs.

摘要：深度神经網路 (DNN) 存在頻譜偏差，其中 DNN 通常表現出優先學習函數的低頻率組成部分的傾向，難以擷取其高頻率特徵。本文旨在解決此問題。請注意，僅具有低頻率組成部分的函數可以用淺層神經網路 (SNN)（僅有少數層的網路）很好地表示。透過觀察低頻率函數的組合可以有效逼近高頻率函數，我們建議透過組合多個 SNN 來學習包含高頻率組成部分的函數，每個 SNN 都從給定的資料中學習某些低頻率資訊。我們透過利用多級深度學習 (MGDL) 模型來實作所提出的構想，MGDL 是一個最近推出的模型，它會逐步訓練 DNN，逐級進行，目前的級別僅從前一個級別的殘差學習一個 SNN，並將其與在先前級別訓練的 SNN 組合成特徵。我們將 MGDL 應用於合成、流形、彩色影像和 MNIST 資料集，這些資料集的特徵是存在高頻率特徵。我們的研究顯示，MGDL 擅長表示包含高頻率資訊的函數。具體來說，在每個級別中學習的神經網路都能靈活地擷取一些低頻率資訊，讓其與先前級別中學習的 SNN 組合有效地表示高頻率特徵。我們的實驗結果強調了 MGDL 在解決 DNN 中固有的頻譜偏差方面的效能。透過利用 MGDL，我們提供了克服 DNN 的頻譜偏差限制的見解，從而增強深度學習模型在需要表示高頻率資訊的任務中的效能和適用性。本研究證實，所提出的方法提供了一個有希望的解決方案來解決 DNN 的頻譜偏差。

##### **Neural Quantum Propagators for Driven-Dissipative Quantum Dynamics**
2410.16091v1 by Jiaji Zhang, Carlos L. Benavides-Riveros, Lipeng Chen

Describing the dynamics of strong-laser driven open quantum systems is a very
challenging task that requires the solution of highly involved equations of
motion. While machine learning techniques are being applied with some success
to simulate the time evolution of individual quantum states, their use to
approximate time-dependent operators (that can evolve various states) remains
largely unexplored. In this work, we develop driven neural quantum propagators
(NQP), a universal neural network framework that solves driven-dissipative
quantum dynamics by approximating propagators rather than wavefunctions or
density matrices. NQP can handle arbitrary initial quantum states, adapt to
various external fields, and simulate long-time dynamics, even when trained on
far shorter time windows. Furthermore, by appropriately configuring the
external fields, our trained NQP can be transferred to systems governed by
different Hamiltonians. We demonstrate the effectiveness of our approach by
studying the spin-boson and the three-state transition Gamma models.

摘要：描述強雷射驅動開放量子系統的動力學是一個非常具有挑戰性的任務，需要求解高度複雜的運動方程式。儘管機器學習技術已成功應用於模擬個別量子態的時間演化，但其用於近似時間相關算符（可演化各種態）的用途仍未被廣泛探討。在這項工作中，我們開發了驅動神經量子傳播器 (NQP)，這是一種通用的神經網路架構，透過近似傳播器，而不是波函數或密度矩陣，來求解驅動耗散量子動力學。NQP 可以處理任意初始量子態，適應各種外場，並模擬長時間動力學，即使是在遠短時間窗上訓練時也是如此。此外，透過適當地配置外場，我們訓練好的 NQP 可以轉移到受不同哈密頓量支配的系統。我們透過研究自旋玻色子和三態轉換 Gamma 模型來證明我們方法的有效性。

##### **Analysing the Residual Stream of Language Models Under Knowledge Conflicts**
2410.16090v1 by Yu Zhao, Xiaotang Du, Giwon Hong, Aryo Pradipta Gema, Alessio Devoto, Hongru Wang, Xuanli He, Kam-Fai Wong, Pasquale Minervini

Large language models (LLMs) can store a significant amount of factual
knowledge in their parameters. However, their parametric knowledge may conflict
with the information provided in the context. Such conflicts can lead to
undesirable model behaviour, such as reliance on outdated or incorrect
information. In this work, we investigate whether LLMs can identify knowledge
conflicts and whether it is possible to know which source of knowledge the
model will rely on by analysing the residual stream of the LLM. Through probing
tasks, we find that LLMs can internally register the signal of knowledge
conflict in the residual stream, which can be accurately detected by probing
the intermediate model activations. This allows us to detect conflicts within
the residual stream before generating the answers without modifying the input
or model parameters. Moreover, we find that the residual stream shows
significantly different patterns when the model relies on contextual knowledge
versus parametric knowledge to resolve conflicts. This pattern can be employed
to estimate the behaviour of LLMs when conflict happens and prevent unexpected
answers before producing the answers. Our analysis offers insights into how
LLMs internally manage knowledge conflicts and provides a foundation for
developing methods to control the knowledge selection processes.

摘要：大型語言模型 (LLM) 可以將大量的實際知識儲存在其參數中。然而，它們的參數化知識可能與文中提供的資訊相衝突。此類衝突可能會導致不理想的模型行為，例如依賴於過時或不正確的資訊。在這項工作中，我們探討 LLM 是否能識別知識衝突，以及是否可以透過分析 LLM 的殘差流來得知模型將依賴於哪個知識來源。透過探測任務，我們發現 LLM 能在殘差流中內部註冊知識衝突訊號，而這能透過探測中間模型的激活來準確地偵測。這讓我們得以在產生答案之前偵測殘差流中的衝突，而無需修改輸入或模型參數。此外，我們發現當模型依賴於脈絡知識與參數化知識來解決衝突時，殘差流會顯示出顯著不同的模式。此模式可用於預測 LLM 在發生衝突時的行為，並在產生答案之前防止出現意外的答案。我們的分析提供了 LLM 如何在內部管理知識衝突的見解，並為開發控制知識選擇程序的方法奠定了基礎。

##### **Multi-Sensor Fusion for UAV Classification Based on Feature Maps of Image and Radar Data**
2410.16089v1 by Nikos Sakellariou, Antonios Lalas, Konstantinos Votis, Dimitrios Tzovaras

The unique cost, flexibility, speed, and efficiency of modern UAVs make them
an attractive choice in many applications in contemporary society. This,
however, causes an ever-increasing number of reported malicious or accidental
incidents, rendering the need for the development of UAV detection and
classification mechanisms essential. We propose a methodology for developing a
system that fuses already processed multi-sensor data into a new Deep Neural
Network to increase its classification accuracy towards UAV detection. The DNN
model fuses high-level features extracted from individual object detection and
classification models associated with thermal, optronic, and radar data.
Additionally, emphasis is given to the model's Convolutional Neural Network
(CNN) based architecture that combines the features of the three sensor
modalities by stacking the extracted image features of the thermal and optronic
sensor achieving higher classification accuracy than each sensor alone.

摘要：現代無人機的獨特成本、靈活性、速度和效率使其成為當代社會許多應用中的誘人選擇。然而，這導致惡意或意外事件的報告數量不斷增加，使得開發無人機檢測和分類機制的需求變得至關重要。我們提出了一種方法，用於開發一個系統，將已處理的多傳感器數據融合到一個新的深度神經網路中，以提高其無人機檢測的分類準確性。DNN 模型融合了從與熱、光電和雷達數據相關的個別對象檢測和分類模型中提取的高級特徵。此外，重點放在基於卷積神經網路 (CNN) 的模型架構上，該架構通過堆疊熱和光電傳感器的提取圖像特徵，將三種傳感器模式的特徵結合起來，從而比單個傳感器實現更高的分類準確性。

##### **Fine-Tuning LLMs for Reliable Medical Question-Answering Services**
2410.16088v1 by Ali Anaissi, Ali Braytee, Junaid Akram

We present an advanced approach to medical question-answering (QA) services,
using fine-tuned Large Language Models (LLMs) to improve the accuracy and
reliability of healthcare information. Our study focuses on optimizing models
like LLaMA-2 and Mistral, which have shown great promise in delivering precise,
reliable medical answers. By leveraging comprehensive datasets, we applied
fine-tuning techniques such as rsDoRA+ and ReRAG. rsDoRA+ enhances model
performance through a combination of decomposed model weights, varied learning
rates for low-rank matrices, and rank stabilization, leading to improved
efficiency. ReRAG, which integrates retrieval on demand and question rewriting,
further refines the accuracy of the responses. This approach enables healthcare
providers to access fast, dependable information, aiding in more efficient
decision-making and fostering greater patient trust. Our work highlights the
potential of fine-tuned LLMs to significantly improve the quality and
accessibility of medical information services, ultimately contributing to
better healthcare outcomes for all.

摘要：我們提出了一種先進的醫療問答 (QA) 服務方法，
使用微調過的大型語言模型 (LLM) 來提高醫療保健資訊的準確性和
可靠性。我們的研究專注於優化模型，例如 LLaMA-2 和 Mistral，這些模型在提供精確、
可靠的醫療答案方面已展現出巨大的前景。透過利用全面的資料集，我們應用
了微調技術，例如 rsDoRA+ 和 ReRAG。rsDoRA+ 透過分解模型權重、針對低階矩陣使用不同的學習
率，以及秩穩定化來增強模型效能，從而提高效率。ReRAG 整合了依需求檢索和問題重寫，
進一步精煉了回應的準確性。此方法讓醫療保健提供者能夠存取快速、可靠的資訊，協助更有效率地進行
決策制定並增進病患的信任。我們的研究重點說明了微調 LLM 的潛力，能大幅改善醫療資訊服務的品質和
可近性，最終為所有人帶來更好的醫療保健成果。

##### **Critical Example Mining for Vehicle Trajectory Prediction using Flow-based Generative Models**
2410.16083v1 by Zhezhang Ding, Huijing Zhao

Precise trajectory prediction in complex driving scenarios is essential for
autonomous vehicles. In practice, different driving scenarios present varying
levels of difficulty for trajectory prediction models. However, most existing
research focuses on the average precision of prediction results, while ignoring
the underlying distribution of the input scenarios. This paper proposes a
critical example mining method that utilizes a data-driven approach to estimate
the rareness of the trajectories. By combining the rareness estimation of
observations with whole trajectories, the proposed method effectively
identifies a subset of data that is relatively hard to predict BEFORE feeding
them to a specific prediction model. The experimental results show that the
mined subset has higher prediction error when applied to different downstream
prediction models, which reaches +108.1% error (greater than two times compared
to the average on dataset) when mining 5% samples. Further analysis indicates
that the mined critical examples include uncommon cases such as sudden brake
and cancelled lane-change, which helps to better understand and improve the
performance of prediction models.

摘要：在複雜的駕駛情境中進行精準的軌跡預測對於自駕車而言至關重要。在實務上，不同的駕駛情境會為軌跡預測模型帶來不同的難度。然而，現有的研究大多關注預測結果的平均準確度，而忽略了輸入情境的底層分佈。本文提出了一種關鍵範例挖掘方法，該方法利用資料驅動的方法來估計軌跡的稀有性。透過結合觀測的稀有性估計與整個軌跡，所提出的方法有效地識別了一組相對難以預測的資料子集，在將其提供給特定的預測模型之前。實驗結果顯示，挖掘出的子集在應用於不同的下游預測模型時具有較高的預測誤差，在挖掘 5% 樣本時達到 +108.1% 的誤差（比資料集上的平均值高出兩倍以上）。進一步的分析表明，挖掘出的關鍵範例包括突然煞車和取消換車道等不常見的案例，這有助於更好地了解和改善預測模型的效能。

##### **CartesianMoE: Boosting Knowledge Sharing among Experts via Cartesian Product Routing in Mixture-of-Experts**
2410.16077v2 by Zhenpeng Su, Xing Wu, Zijia Lin, Yizhe Xiong, Minxuan Lv, Guangyuan Ma, Hui Chen, Songlin Hu, Guiguang Ding

Large language models (LLM) have been attracting much attention from the
community recently, due to their remarkable performance in all kinds of
downstream tasks. According to the well-known scaling law, scaling up a dense
LLM enhances its capabilities, but also significantly increases the
computational complexity. Mixture-of-Experts (MoE) models address that by
allowing the model size to grow without substantially raising training or
inference costs. Yet MoE models face challenges regarding knowledge sharing
among experts, making their performance somehow sensitive to routing accuracy.
To tackle that, previous works introduced shared experts and combined their
outputs with those of the top $K$ routed experts in an ``addition'' manner. In
this paper, inspired by collective matrix factorization to learn shared
knowledge among data, we propose CartesianMoE, which implements more effective
knowledge sharing among experts in more like a ``multiplication'' manner.
Extensive experimental results indicate that CartesianMoE outperforms previous
MoE models for building LLMs, in terms of both perplexity and downstream task
performance. And we also find that CartesianMoE achieves better expert routing
robustness.

摘要：大型語言模型 (LLM) 近期廣受社群關注，因為它們在各種下游任務中表現傑出。根據著名的規模定律，擴大密集 LLM 能增強其功能，但也大幅增加運算複雜度。專家混合 (MoE) 模型透過允許模型規模擴大而不會大幅增加訓練或推論成本來解決這個問題。然而，MoE 模型在專家之間的知識共享方面面臨挑戰，使得它們的效能多少會受到路由精準度的影響。為了解決這個問題，先前的研究引入了共享專家，並以「加法」的方式將他們的輸出與路由前 $K$ 名專家的輸出結合。在本文中，我們受到集體矩陣分解的啟發，從資料中學習共享知識，並提出笛卡兒 MoE，它以更像是「乘法」的方式在專家之間實作更有效的知識共享。廣泛的實驗結果表明，笛卡兒 MoE 在困惑度和下游任務效能方面都優於先前的 MoE 模型，用於建構 LLM。我們也發現笛卡兒 MoE 達到更好的專家路由穩健性。

##### **On-Device LLMs for SMEs: Challenges and Opportunities**
2410.16070v2 by Jeremy Stephen Gabriel Yee, Pai Chet Ng, Zhengkui Wang, Ian McLoughlin, Aik Beng Ng, Simon See

This paper presents a systematic review of the infrastructure requirements
for deploying Large Language Models (LLMs) on-device within the context of
small and medium-sized enterprises (SMEs), focusing on both hardware and
software perspectives. From the hardware viewpoint, we discuss the utilization
of processing units like GPUs and TPUs, efficient memory and storage solutions,
and strategies for effective deployment, addressing the challenges of limited
computational resources typical in SME settings. From the software perspective,
we explore framework compatibility, operating system optimization, and the use
of specialized libraries tailored for resource-constrained environments. The
review is structured to first identify the unique challenges faced by SMEs in
deploying LLMs on-device, followed by an exploration of the opportunities that
both hardware innovations and software adaptations offer to overcome these
obstacles. Such a structured review provides practical insights, contributing
significantly to the community by enhancing the technological resilience of
SMEs in integrating LLMs.

摘要：本文針對中小型企業 (SME) 的情境，系統性探討了在裝置上部署大型語言模型 (LLM) 的基礎設施需求，重點在硬體和軟體的觀點。從硬體觀點來看，我們探討處理單元（如 GPU 和 TPU）的利用、高效能記憶體和儲存解決方案，以及有效部署策略，以解決 SME 環境中常見的運算資源受限挑戰。從軟體觀點來看，我們探討架構相容性、作業系統最佳化，以及使用專門為資源受限環境量身打造的函式庫。本探討的架構首先找出 SME 在裝置上部署 LLM 時面臨的獨特挑戰，接著探討硬體創新和軟體調整所提供的機會，以克服這些障礙。這樣一個結構化的探討提供了實用的見解，透過提升 SME 整合 LLM 的技術韌性，為社群做出重大貢獻。

##### **Rolling the DICE on Idiomaticity: How LLMs Fail to Grasp Context**
2410.16069v1 by Maggie Mi, Aline Villavicencio, Nafise Sadat Moosavi

Human processing of idioms relies on understanding the contextual sentences
in which idioms occur, as well as language-intrinsic features such as frequency
and speaker-intrinsic factors like familiarity. While LLMs have shown high
performance on idiomaticity detection tasks, this success may be attributed to
reasoning shortcuts in existing datasets. To this end, we construct a novel,
controlled contrastive dataset designed to test whether LLMs can effectively
use context to disambiguate idiomatic meaning. Additionally, we explore how
collocational frequency and sentence probability influence model performance.
Our findings reveal that LLMs often fail to resolve idiomaticity when it is
required to attend to the surrounding context, and that models perform better
on sentences that have higher likelihood. The collocational frequency of
expressions also impacts performance. We make our code and dataset publicly
available.

摘要：人類對慣用語的處理依賴於理解慣用語出現的語境句子，以及語言內在特徵（例如頻率）和說話者內在因素（例如熟悉度）。雖然大語言模型在慣用語檢測任務上表現出高性能，但這種成功可能是歸因於現有資料集中的推理捷徑。為此，我們構建了一個新穎、受控的對比資料集，旨在測試大語言模型是否能有效使用語境來消除慣用語含義的歧義。此外，我們探討了搭配頻率和句子機率如何影響模型效能。我們的研究結果顯示，當需要關注周圍語境時，大語言模型常常無法解決慣用語，而且模型在機率較高的句子中表現得更好。表達式的搭配頻率也影響效能。我們公開我們的程式碼和資料集。

##### **Integrated Image-Text Based on Semi-supervised Learning for Small Sample Instance Segmentation**
2410.16063v1 by Ruting Chi, Zhiyi Huang, Yuexing Han

Small sample instance segmentation is a very challenging task, and many
existing methods follow the training strategy of meta-learning which pre-train
models on support set and fine-tune on query set. The pre-training phase, which
is highly task related, requires a significant amount of additional training
time and the selection of datasets with close proximity to ensure
effectiveness. The article proposes a novel small sample instance segmentation
solution from the perspective of maximizing the utilization of existing
information without increasing annotation burden and training costs. The
proposed method designs two modules to address the problems encountered in
small sample instance segmentation. First, it helps the model fully utilize
unlabeled data by learning to generate pseudo labels, increasing the number of
available samples. Second, by integrating the features of text and image, more
accurate classification results can be obtained. These two modules are suitable
for box-free and box-dependent frameworks. In the way, the proposed method not
only improves the performance of small sample instance segmentation, but also
greatly reduce reliance on pre-training. We have conducted experiments in three
datasets from different scenes: on land, underwater and under microscope. As
evidenced by our experiments, integrated image-text corrects the confidence of
classification, and pseudo labels help the model obtain preciser masks. All the
results demonstrate the effectiveness and superiority of our method.

摘要：小样本实例分割是一项极具挑战性的任务，许多现有方法遵循元学习的训练策略，即在支持集上预训练模型并在查询集上进行微调。与任务高度相关的预训练阶段需要大量的额外训练时间，并且需要选择与数据集密切相关的确保有效性。本文提出了一种新颖的小样本实例分割解决方案，从最大化利用现有信息而不增加注释负担和训练成本的角度出发。所提出的方法设计了两个模块来解决小样本实例分割中遇到的问题。首先，它通过学习生成伪标签来帮助模型充分利用未标记数据，从而增加可用样本的数量。其次，通过整合文本和图像的特征，可以获得更准确的分类结果。这两个模块适用于无框和依赖框的框架。通过这种方式，所提出的方法不仅提高了小样本实例分割的性能，而且极大地减少了对预训练的依赖。我们在来自不同场景的三个数据集上进行了实验：陆地、水下和显微镜下。正如我们的实验所证明的，集成的图像文本纠正了分类的置信度，伪标签帮助模型获得了更精确的掩码。所有结果都证明了我们方法的有效性和优越性。

##### **Surprise! Uniform Information Density Isn't the Whole Story: Predicting Surprisal Contours in Long-form Discourse**
2410.16062v1 by Eleftheria Tsipidi, Franz Nowak, Ryan Cotterell, Ethan Wilcox, Mario Giulianelli, Alex Warstadt

The Uniform Information Density (UID) hypothesis posits that speakers tend to
distribute information evenly across linguistic units to achieve efficient
communication. Of course, information rate in texts and discourses is not
perfectly uniform. While these fluctuations can be viewed as theoretically
uninteresting noise on top of a uniform target, another explanation is that UID
is not the only functional pressure regulating information content in a
language. Speakers may also seek to maintain interest, adhere to writing
conventions, and build compelling arguments. In this paper, we propose one such
functional pressure; namely that speakers modulate information rate based on
location within a hierarchically-structured model of discourse. We term this
the Structured Context Hypothesis and test it by predicting the surprisal
contours of naturally occurring discourses extracted from large language models
using predictors derived from discourse structure. We find that hierarchical
predictors are significant predictors of a discourse's information contour and
that deeply nested hierarchical predictors are more predictive than shallow
ones. This work takes an initial step beyond UID to propose testable hypotheses
for why the information rate fluctuates in predictable ways

摘要：均匀信息密度 (UID) 假设认为说话者倾向于将信息均匀分布在语言单位中，以实现有效的沟通。当然，文本和话语中的信息率并不是完全均匀的。虽然这些波动可以被视为均匀目标之上的理论上无趣的噪音，但另一种解释是 UID 并不是唯一调节语言中信息内容的功能压力。说话者还可能寻求保持兴趣、遵守写作惯例并构建有说服力的论据。在本文中，我们提出了一个这样的功能压力；即说话者根据分层结构的话语模型中的位置来调节信息率。我们称之为结构化上下文假设，并通过预测从大型语言模型中提取的自然发生的话语的意外轮廓来对其进行测试，这些预测源自话语结构。我们发现分层预测因子是话语信息轮廓的重要预测因子，并且深度嵌套的分层预测因子比浅层预测因子更具预测性。这项工作超越了 UID，提出了可测试的假设，说明为什么信息率以可预测的方式波动

##### **Large Language Models Know What To Say But Not When To Speak**
2410.16044v1 by Muhammad Umair, Vasanth Sarathy, JP de Ruiter

Turn-taking is a fundamental mechanism in human communication that ensures
smooth and coherent verbal interactions. Recent advances in Large Language
Models (LLMs) have motivated their use in improving the turn-taking
capabilities of Spoken Dialogue Systems (SDS), such as their ability to respond
at appropriate times. However, existing models often struggle to predict
opportunities for speaking -- called Transition Relevance Places (TRPs) -- in
natural, unscripted conversations, focusing only on turn-final TRPs and not
within-turn TRPs. To address these limitations, we introduce a novel dataset of
participant-labeled within-turn TRPs and use it to evaluate the performance of
state-of-the-art LLMs in predicting opportunities for speaking. Our experiments
reveal the current limitations of LLMs in modeling unscripted spoken
interactions, highlighting areas for improvement and paving the way for more
naturalistic dialogue systems.

摘要：輪流發言是人類溝通中的一種基本機制，可確保言語互動順暢且連貫。大型語言模型 (LLM) 的最新進展激勵了它們在改進口語對話系統 (SDS) 輪流發言能力方面的應用，例如它們在適當時間做出回應的能力。然而，現有的模型通常難以預測自然、非腳本對話中的發言機會——稱為轉換相關位置 (TRP)——僅關注回合結束的 TRP，而不關注回合內的 TRP。為了解決這些限制，我們引入了一個由參與者標記的回合內 TRP 的新數據集，並使用它來評估最先進的 LLM 在預測發言機會方面的性能。我們的實驗揭示了 LLM 在建模非腳本口語互動方面的當前限制，突出了改進領域，並為更自然的對話系統鋪平了道路。

##### **TimeMixer++: A General Time Series Pattern Machine for Universal Predictive Analysis**
2410.16032v1 by Shiyu Wang, Jiawei Li, Xiaoming Shi, Zhou Ye, Baichuan Mo, Wenze Lin, Shengtong Ju, Zhixuan Chu, Ming Jin

Time series analysis plays a critical role in numerous applications,
supporting tasks such as forecasting, classification, anomaly detection, and
imputation. In this work, we present the time series pattern machine (TSPM), a
model designed to excel in a broad range of time series tasks through powerful
representation and pattern extraction capabilities. Traditional time series
models often struggle to capture universal patterns, limiting their
effectiveness across diverse tasks. To address this, we define multiple scales
in the time domain and various resolutions in the frequency domain, employing
various mixing strategies to extract intricate, task-adaptive time series
patterns. Specifically, we introduce a general-purpose TSPM that processes
multi-scale time series using (1) multi-resolution time imaging (MRTI), (2)
time image decomposition (TID), (3) multi-scale mixing (MCM), and (4)
multi-resolution mixing (MRM) to extract comprehensive temporal patterns. MRTI
transforms multi-scale time series into multi-resolution time images, capturing
patterns across both temporal and frequency domains. TID leverages dual-axis
attention to extract seasonal and trend patterns, while MCM hierarchically
aggregates these patterns across scales. MRM adaptively integrates all
representations across resolutions. This method achieves state-of-the-art
performance across 8 time series analytical tasks, consistently surpassing both
general-purpose and task-specific models. Our work marks a promising step
toward the next generation of TSPMs, paving the way for further advancements in
time series analysis.

摘要：<paragraph>時序分析在許多應用中扮演著至關重要的角色，
支援預測、分類、異常偵測和估算等任務。在這項研究中，我們提出時序模式機器 (TSPM)，這是一個旨在透過強大的表徵和模式萃取能力在廣泛時序任務中表現優異的模型。傳統時序模型經常難以擷取通用模式，限制了它們在不同任務中的效能。為了解決這個問題，我們在時域中定義多個尺度，在頻域中定義各種解析度，並採用各種混合策略來萃取複雜且適應任務的時序模式。具體來說，我們引入了使用 (1) 多解析度時間影像 (MRTI)、(2) 時間影像分解 (TID)、(3) 多尺度混合 (MCM) 和 (4) 多解析度混合 (MRM) 來萃取全面性時間模式的通用 TSPM，以處理多尺度時序。MRTI 將多尺度時序轉換成多解析度時間影像，擷取時間和頻域中的模式。TID 利用雙軸注意力來萃取季節性和趨勢模式，而 MCM 則在不同尺度上階層性地彙總這些模式。MRM 自適應地整合所有解析度中的表徵。此方法在 8 項時序分析任務中達到了最先進的效能，始終超越通用和特定任務模型。我們的研究標誌著邁向下一代 TSPM 的有希望的一步，為時序分析的進一步發展鋪平了道路。</paragraph>

##### **ComPO: Community Preferences for Language Model Personalization**
2410.16027v1 by Sachin Kumar, Chan Young Park, Yulia Tsvetkov, Noah A. Smith, Hannaneh Hajishirzi

Conventional algorithms for training language models (LMs) with human
feedback rely on preferences that are assumed to account for an "average" user,
disregarding subjectivity and finer-grained variations. Recent studies have
raised concerns that aggregating such diverse and often contradictory human
feedback to finetune models results in generic models that generate outputs not
preferred by many user groups, as they tend to average out styles and norms. To
address this issue, we draw inspiration from recommendation systems and propose
ComPO, a method to personalize preference optimization in LMs by
contextualizing the probability distribution of model outputs with the
preference provider. Focusing on group-level preferences rather than
individuals, we collect and release ComPRed, a question answering dataset with
community-level preferences from Reddit. This dataset facilitates studying
diversity in preferences without incurring privacy concerns associated with
individual feedback. Our experiments reveal that conditioning language models
on a community identifier (i.e., subreddit name) during preference tuning
substantially enhances model performance. Conversely, replacing this context
with random subreddit identifiers significantly diminishes performance,
highlighting the effectiveness of our approach in tailoring responses to
communities' preferences.

摘要：傳統用於訓練語言模型 (LM) 的演算法，仰賴於被假設為「平均」使用者的偏好，忽略了主觀性和更細微的差異。最近的研究指出，彙整如此多樣且經常相互矛盾的人類偏好來微調模型，會導致產生不受許多使用者群體偏好的通用模型，因為這些模型往往會平均出各種風格和規範。為了解決這個問題，我們從推薦系統中汲取靈感，並提出 ComPO，這是一種透過將模型輸出的機率分佈與偏好提供者脈絡化的方式，來個人化 LM 中的偏好最佳化。我們著重於群組層級的偏好，而非個人，因此我們收集並發布 ComPRed，這是一個來自 Reddit 社群層級偏好的問答資料集。這個資料集有助於研究偏好的多樣性，而不會招致與個人偏好相關的隱私問題。我們的實驗顯示，在偏好調整期間，將語言模型置於社群識別碼（例如，subreddit 名稱）的條件下，會大幅提升模型效能。相反地，若將此脈絡替換為隨機的 subreddit 識別碼，則會顯著降低效能，突顯了我們在根據社群偏好調整回應方面的有效性。

##### **A New Approach to Solving SMAC Task: Generating Decision Tree Code from Large Language Models**
2410.16024v1 by Yue Deng, Weiyu Ma, Yuxin Fan, Yin Zhang, Haifeng Zhang, Jian Zhao

StarCraft Multi-Agent Challenge (SMAC) is one of the most commonly used
experimental environments in multi-agent reinforcement learning (MARL), where
the specific task is to control a set number of allied units to defeat enemy
forces. Traditional MARL algorithms often require interacting with the
environment for up to 1 million steps to train a model, and the resulting
policies are typically non-interpretable with weak transferability. In this
paper, we propose a novel approach to solving SMAC tasks called LLM-SMAC. In
our framework, agents leverage large language models (LLMs) to generate
decision tree code by providing task descriptions. The model is further
self-reflection using feedback from the rewards provided by the environment. We
conduct experiments in the SMAC and demonstrate that our method can produce
high-quality, interpretable decision trees with minimal environmental
exploration. Moreover, these models exhibit strong transferability,
successfully applying to similar SMAC environments without modification. We
believe this approach offers a new direction for solving decision-making tasks
in the future.

摘要：星海爭霸多智能體挑戰 (SMAC) 是多智能體強化學習 (MARL) 中最常使用的實驗環境之一，其中具體任務是控制一定數量的盟軍單位來擊敗敵軍。傳統的 MARL 演算法通常需要與環境互動多達 100 萬步才能訓練模型，而產生的策略通常難以解釋，且可轉移性較弱。在本文中，我們提出了一種解決 SMAC 任務的新方法，稱為 LLM-SMAC。在我們的框架中，智能體利用大型語言模型 (LLM) 透過提供任務描述來產生決策樹程式碼。該模型進一步利用環境提供的回饋進行自我反省。我們在 SMAC 中進行實驗，並證明我們的模型可以產生高品質、可解釋的決策樹，且環境探索最少。此外，這些模型展現出強大的可轉移性，成功應用於類似的 SMAC 環境而無需修改。我們相信這種方法為未來解決決策制定任務提供了新的方向。

##### **Massimo: Public Queue Monitoring and Management using Mass-Spring Model**
2410.16012v1 by Abhijeet Kumar, Unnati Singh, Rajdeep Chatterjee, Tathagata Bandyopadhyay

An efficient system of a queue control and regulation in public spaces is
very important in order to avoid the traffic jams and to improve the customer
satisfaction. This article offers a detailed road map based on a merger of
intelligent systems and creating an efficient systems of queues in public
places. Through the utilization of different technologies i.e. computer vision,
machine learning algorithms, deep learning our system provide accurate
information about the place is crowded or not and the necessary efforts to be
taken.

摘要：一個有效率的公共空間隊伍控制和管理系統，對於避免交通堵塞和提升顧客滿意度非常重要。本文提供了詳細的路徑圖，基於智慧系統的合併和建立一個有效的公共空間隊伍系統。透過使用不同的技術，例如電腦視覺、機器學習演算法、深度學習，我們的系統提供了準確的資訊，表示這個地方是否擁擠，以及需要採取的必要措施。

##### **Resilient Temporal GCN for Smart Grid State Estimation Under Topology Inaccuracies**
2410.16008v1 by Seyed Hamed Haghshenas, Mia Naeini

State Estimation is a crucial task in power systems. Graph Neural Networks
have demonstrated significant potential in state estimation for power systems
by effectively analyzing measurement data and capturing the complex
interactions and interrelations among the measurements through the system's
graph structure. However, the information about the system's graph structure
may be inaccurate due to noise, attack or lack of accurate information about
the topology of the system. This paper studies these scenarios under topology
uncertainties and evaluates the impact of the topology uncertainties on the
performance of a Temporal Graph Convolutional Network (TGCN) for state
estimation in power systems. In order to make the model resilient to topology
uncertainties, modifications in the TGCN model are proposed to incorporate a
knowledge graph, generated based on the measurement data. This knowledge graph
supports the assumed uncertain system graph. Two variations of the TGCN
architecture are introduced to integrate the knowledge graph, and their
performances are evaluated and compared to demonstrate improved resilience
against topology uncertainties. The evaluation results indicate that while the
two proposed architecture show different performance, they both improve the
performance of the TGCN state estimation under topology uncertainties.

摘要：狀態估計是電力系統中的一項關鍵任務。圖神經網路已證明其在電力系統狀態估計中具有顯著的潛力，方法是有效分析測量資料並透過系統圖結構擷取測量中複雜的互動和相互關係。然而，由於雜訊、攻擊或缺乏關於系統拓撲結構的準確資訊，系統圖結構的資訊可能不準確。本文研究了拓撲結構不確定性下的這些情境，並評估拓撲結構不確定性對時態圖形卷積網路 (TGCN) 在電力系統狀態估計上的效能影響。為了使模型對拓撲結構不確定性具有復原力，提出了 TGCN 模型的修改，以納入基於測量資料產生的知識圖。此知識圖支援假設的不確定系統圖。引入了 TGCN 架構的兩個變體來整合知識圖，並評估其效能並與之比較，以證明對拓撲結構不確定性具有改善的復原力。評估結果表明，雖然兩個提出的架構表現出不同的效能，但它們都改善了 TGCN 狀態估計在拓撲結構不確定性下的效能。

##### **Are Language Model Logits Calibrated?**
2410.16007v1 by Charles Lovering, Michael Krumdick, Viet Dac Lai, Nilesh Kumar, Varshini Reddy, Rik Koncel-Kedziorski, Chris Tanner

Some information is factual (e.g., "Paris is in France"), whereas other
information is probabilistic (e.g., "the coin flip will be a [Heads/Tails].").
We believe that good Language Models (LMs) should understand and reflect this
nuance. Our work investigates this by testing if LMs' output probabilities are
calibrated to their textual contexts. We define model "calibration" as the
degree to which the output probabilities of candidate tokens are aligned with
the relative likelihood that should be inferred from the given context. For
example, if the context concerns two equally likely options (e.g., heads or
tails for a fair coin), the output probabilities should reflect this. Likewise,
context that concerns non-uniformly likely events (e.g., rolling a six with a
die) should also be appropriately captured with proportionate output
probabilities. We find that even in simple settings the best LMs (1) are poorly
calibrated, and (2) have systematic biases (e.g., preferred colors and
sensitivities to word orderings). For example, gpt-4o-mini often picks the
first of two options presented in the prompt regardless of the options' implied
likelihood, whereas Llama-3.1-8B picks the second. Our other consistent finding
is mode-collapse: Instruction-tuned models often over-allocate probability mass
on a single option. These systematic biases introduce non-intuitive model
behavior, making models harder for users to understand.

摘要：某些資訊是事實（例如：「巴黎在法國」），而其他資訊則是機率性的（例如：「拋硬幣會是 [正面/反面]」）。我們相信良好的語言模型 (LM) 應理解並反映這種差異。我們的研究透過測試語言模型的輸出機率是否校準至其文字脈絡來探討這一點。我們將模型「校準」定義為候選詞彙的輸出機率與應從給定脈絡推論出的相對可能性一致的程度。例如，如果脈絡涉及兩個可能性相等的選項（例如公平硬幣的正面或反面），輸出機率應反映這一點。同樣地，涉及可能性不均等的事件（例如用骰子擲出六點）的脈絡也應透過相應的輸出機率適當地捕捉。我們發現，即使在簡單的設定中，最佳的語言模型 (1) 校準不良，且 (2) 具有系統性偏差（例如，偏好的顏色和對字序的敏感性）。例如，gpt-4o-mini 通常會選擇提示中呈現的兩個選項中的第一個，而不管選項暗示的可能性如何，而 Llama-3.1-8B 則會選擇第二個。我們另一個一致的發現是模式崩潰：經過指令微調的模型通常會過度分配單一選項的機率質量。這些系統性偏差會導致非直覺的模型行為，讓使用者更難理解模型。

##### **Exploring Continual Fine-Tuning for Enhancing Language Ability in Large Language Model**
2410.16006v1 by Divyanshu Aggarwal, Sankarshan Damle, Navin Goyal, Satya Lokam, Sunayana Sitaram

A common challenge towards the adaptability of Large Language Models (LLMs)
is their ability to learn new languages over time without hampering the model's
performance on languages in which the model is already proficient (usually
English). Continual fine-tuning (CFT) is the process of sequentially
fine-tuning an LLM to enable the model to adapt to downstream tasks with
varying data distributions and time shifts. This paper focuses on the language
adaptability of LLMs through CFT. We study a two-phase CFT process in which an
English-only end-to-end fine-tuned LLM from Phase 1 (predominantly Task
Ability) is sequentially fine-tuned on a multilingual dataset -- comprising
task data in new languages -- in Phase 2 (predominantly Language Ability). We
observe that the ``similarity'' of Phase 2 tasks with Phase 1 determines the
LLM's adaptability. For similar phase-wise datasets, the LLM after Phase 2 does
not show deterioration in task ability. In contrast, when the phase-wise
datasets are not similar, the LLM's task ability deteriorates. We test our
hypothesis on the open-source \mis\ and \llm\ models with multiple phase-wise
dataset pairs. To address the deterioration, we analyze tailored variants of
two CFT methods: layer freezing and generative replay. Our findings demonstrate
their effectiveness in enhancing the language ability of LLMs while preserving
task performance, in comparison to relevant baselines.

摘要：<paragraph>大型語言模型 (LLM) 適應性的常見挑戰是它們在不影響模型在已經熟練的語言（通常是英語）上的表現的情況下，隨著時間推移學習新語言的能力。持續微調 (CFT) 是按順序微調 LLM 的過程，使模型能夠適應具有不同資料分佈和時間變化的下游任務。本文重點關注 LLM 通過 CFT 的語言適應性。我們研究了一個兩階段 CFT 過程，其中一個僅限英語的端到端微調 LLM（第 1 階段，主要是任務能力）在第 2 階段（主要是語言能力）中在一個多語言資料集（包括新語言的任務資料）上按順序微調。我們觀察到第 2 階段任務與第 1 階段的「相似性」決定了 LLM 的適應性。對於相似的階段資料集，第 2 階段後的 LLM 任務能力沒有下降。相反，當階段資料集不相似的，LLM 的任務能力會下降。我們使用多個階段資料集對在開源 \mis\ 和 \llm\ 模型上測試我們的假設。為了解決惡化問題，我們分析了兩種 CFT 方法的定制變體：層凍結和生成式重播。我們的研究結果證明了它們在增強 LLM 的語言能力的同時保持任務表現方面的有效性，與相關基準相比。</paragraph>

##### **Steering Knowledge Selection Behaviours in LLMs via SAE-Based Representation Engineering**
2410.15999v1 by Yu Zhao, Alessio Devoto, Giwon Hong, Xiaotang Du, Aryo Pradipta Gema, Hongru Wang, Kam-Fai Wong, Pasquale Minervini

Large language models (LLMs) can store a significant amount of factual
knowledge in their parameters. However, their parametric knowledge may conflict
with the information provided in the context -- this phenomenon, known as
\emph{context-memory knowledge conflicts}, can lead to undesirable model
behaviour, such as reliance on outdated or incorrect information. Analysing the
internal activations of LLMs, we find that they can internally register the
signals of knowledge conflict at mid-layers. Such signals allow us to detect
whether a knowledge conflict occurs and use \emph{inference-time} intervention
strategies to resolve it. In this work, we propose \textsc{SpARE}, a
\emph{training-free} representation engineering method that uses pre-trained
sparse auto-encoders (SAEs) to control the knowledge selection behaviour of
LLMs. \textsc{SpARE} identifies the functional features that control the
knowledge selection behaviours and applies them to edit the internal
activations of LLMs at inference time. Our experimental results show that
\textsc{SpARE} can effectively control the usage of either knowledge source to
resolve knowledge conflict in open-domain question-answering tasks, surpassing
existing representation engineering methods ($+10\%$) as well as contrastive
decoding methods ($+15\%$).

摘要：大型語言模型 (LLM) 可以將大量的實際知識儲存在其參數中。然而，它們的參數化知識可能會與上下文中提供的資訊產生衝突——這種現象稱為「上下文記憶知識衝突」，可能會導致不良的模型行為，例如依賴過時或不正確的資訊。分析 LLM 的內部激活，我們發現它們可以在中間層內部註冊知識衝突的信號。此類信號使我們能夠偵測知識衝突是否發生，並使用「推論時間」介入策略來解決它。在這項工作中，我們提出 \textsc{SpARE}，一種「無訓練」的表示工程方法，它使用預先訓練的稀疏自動編碼器 (SAE) 來控制 LLM 的知識選擇行為。\textsc{SpARE} 識別控制知識選擇行為的功能特徵，並將它們應用於編輯 LLM 在推論時間的內部激活。我們的實驗結果表明，\textsc{SpARE} 可以有效控制任一知識來源的使用，以解決開放領域問答任務中的知識衝突，超越現有的表示工程方法（+10%）以及對比解碼方法（+15%）。

##### **1024m at SMM4H 2024: Tasks 3, 5 & 6 -- Ensembles of Transformers and Large Language Models for Medical Text Classification**
2410.15998v1 by Ram Mohan Rao Kadiyala, M. V. P. Chandra Sekhara Rao

Social media is a great source of data for users reporting information and
regarding their health and how various things have had an effect on them. This
paper presents various approaches using Transformers and Large Language Models
and their ensembles, their performance along with advantages and drawbacks for
various tasks of SMM4H'24 - Classifying texts on impact of nature and outdoor
spaces on the author's mental health (Task 3), Binary classification of tweets
reporting their children's health disorders like Asthma, Autism, ADHD and
Speech disorder (task 5), Binary classification of users self-reporting their
age (task 6).

摘要：社群媒體是使用者回報資訊的絕佳資料來源，關於他們的健康以及各種事物對他們的影響。本文提出各種使用 Transformer 和大型語言模型及其合奏的方法，以及它們在 SMM4H'24 各種任務中的表現，以及優缺點 - 分類影響作者心理健康的自然和戶外空間文本（任務 3），回報其兒童健康障礙（例如氣喘、自閉症、注意力不足過動症和言語障礙）的推文二元分類（任務 5），使用者自行回報其年齡的二元分類（任務 6）。

##### **Augmenting Legal Decision Support Systems with LLM-based NLI for Analyzing Social Media Evidence**
2410.15990v1 by Ram Mohan Rao Kadiyala, Siddartha Pullakhandam, Kanwal Mehreen, Subhasya Tippareddy, Ashay Srivastava

This paper presents our system description and error analysis of our entry
for NLLP 2024 shared task on Legal Natural Language Inference (L-NLI)
\citep{hagag2024legallenssharedtask2024}. The task required classifying these
relationships as entailed, contradicted, or neutral, indicating any association
between the review and the complaint. Our system emerged as the winning
submission, significantly outperforming other entries with a substantial margin
and demonstrating the effectiveness of our approach in legal text analysis. We
provide a detailed analysis of the strengths and limitations of each model and
approach tested, along with a thorough error analysis and suggestions for
future improvements. This paper aims to contribute to the growing field of
legal NLP by offering insights into advanced techniques for natural language
inference in legal contexts, making it accessible to both experts and newcomers
in the field.

摘要：本文介紹我們系統說明和錯誤分析，我們在 NLLP 2024 共享任務中提交的法律自然語言推論 (L-NLI) 項目
\citep{hagag2024legallenssharedtask2024}。該任務需要將這些關係分類為蘊含、矛盾或中立，指出評論與申訴之間的任何關聯。我們的系統成為獲勝提交，顯著優於其他條目，並在法律文本分析中證明了我們方法的有效性。我們對每個模型和已測試方法的優勢和限制進行了詳細分析，並提供了徹底的錯誤分析和未來改進建議。本文旨在通過提供對法律背景中自然語言推論的先進技術的見解，為法律 NLP 的成長領域做出貢獻，讓該領域的專家和新手都能理解。

##### **Analyzing Closed-loop Training Techniques for Realistic Traffic Agent Models in Autonomous Highway Driving Simulations**
2410.15987v1 by Matthias Bitzer, Reinis Cimurs, Benjamin Coors, Johannes Goth, Sebastian Ziesche, Philipp Geiger, Maximilian Naumann

Simulation plays a crucial role in the rapid development and safe deployment
of autonomous vehicles. Realistic traffic agent models are indispensable for
bridging the gap between simulation and the real world. Many existing
approaches for imitating human behavior are based on learning from
demonstration. However, these approaches are often constrained by focusing on
individual training strategies. Therefore, to foster a broader understanding of
realistic traffic agent modeling, in this paper, we provide an extensive
comparative analysis of different training principles, with a focus on
closed-loop methods for highway driving simulation. We experimentally compare
(i) open-loop vs. closed-loop multi-agent training, (ii) adversarial vs.
deterministic supervised training, (iii) the impact of reinforcement losses,
and (iv) the impact of training alongside log-replayed agents to identify
suitable training techniques for realistic agent modeling. Furthermore, we
identify promising combinations of different closed-loop training methods.

摘要：模擬在自動駕駛車輛的快速開發和安全部署中扮演著至關重要的角色。逼真的交通代理模型對於縮小模擬和現實世界之間的差距至關重要。許多現有的模仿人類行為的方法都是基於示範學習。然而，這些方法通常受到關注於個別訓練策略的限制。因此，為了促進對現實交通代理建模的更廣泛理解，在本文中，我們提供了對不同訓練原則的廣泛比較分析，重點關注用於高速公路駕駛模擬的閉環方法。我們通過實驗比較了 (i) 開環與閉環多代理訓練，(ii) 對抗式與確定性監督訓練，(iii) 強化損失的影響，以及 (iv) 與日誌重播代理一起訓練的影響，以識別適合於現實代理建模的訓練技術。此外，我們還確定了不同閉環訓練方法的有希望的組合。

##### **PROMPTHEUS: A Human-Centered Pipeline to Streamline SLRs with LLMs**
2410.15978v2 by João Pedro Fernandes Torres, Catherine Mulligan, Joaquim Jorge, Catarina Moreira

The growing volume of academic publications poses significant challenges for
researchers conducting timely and accurate Systematic Literature Reviews,
particularly in fast-evolving fields like artificial intelligence. This growth
of academic literature also makes it increasingly difficult for lay people to
access scientific knowledge effectively, meaning academic literature is often
misrepresented in the popular press and, more broadly, in society. Traditional
SLR methods are labor-intensive and error-prone, and they struggle to keep up
with the rapid pace of new research. To address these issues, we developed
\textit{PROMPTHEUS}: an AI-driven pipeline solution that automates the SLR
process using Large Language Models. We aimed to enhance efficiency by reducing
the manual workload while maintaining the precision and coherence required for
comprehensive literature synthesis. PROMPTHEUS automates key stages of the SLR
process, including systematic search, data extraction, topic modeling using
BERTopic, and summarization with transformer models. Evaluations conducted
across five research domains demonstrate that PROMPTHEUS reduces review time,
achieves high precision, and provides coherent topic organization, offering a
scalable and effective solution for conducting literature reviews in an
increasingly crowded research landscape. In addition, such tools may reduce the
increasing mistrust in science by making summarization more accessible to
laypeople.
  The code for this project can be found on the GitHub repository at
https://github.com/joaopftorres/PROMPTHEUS.git

摘要：<paragraph>學術出版品的數量持續增加，對於進行及時且準確的系統性文獻回顧的研究人員來說，這構成了重大的挑戰，特別是在像人工智慧等快速發展的領域中。學術文獻的增長也使得一般人越來越難以有效地獲取科學知識，這意味著學術文獻經常在通俗媒體中被錯誤呈現，更廣泛地說，在社會中也是如此。傳統的系統性文獻回顧方法既費力又容易出錯，而且難以跟上新研究的快速步伐。為了解決這些問題，我們開發了PROMPTHEUS：一種由大型語言模型自動化系統性文獻回顧流程的 AI 驅動管道解決方案。我們的目標是通過減少手動工作量來提高效率，同時保持綜合文獻合成所需的精確性和一致性。PROMPTHEUS 自動化了系統性文獻回顧流程的主要階段，包括系統性搜尋、資料萃取、使用 BERTopic 的主題建模，以及使用轉換器模型進行摘要。在五個研究領域進行的評估表明，PROMPTHEUS 縮短了回顧時間，達到了高精度，並提供了連貫的主題組織，為在日益擁擠的研究領域中進行文獻回顧提供了一個可擴充且有效的解決方案。此外，此類工具可以讓一般人更容易取得摘要，從而減少對科學的不信任。這個專案的程式碼可以在 GitHub 儲存庫中找到，網址為 https://github.com/joaopftorres/PROMPTHEUS.git</paragraph>

##### **Enabling Energy-Efficient Deployment of Large Language Models on Memristor Crossbar: A Synergy of Large and Small**
2410.15977v1 by Zhehui Wang, Tao Luo, Cheng Liu, Weichen Liu, Rick Siow Mong Goh, Weng-Fai Wong

Large language models (LLMs) have garnered substantial attention due to their
promising applications in diverse domains. Nevertheless, the increasing size of
LLMs comes with a significant surge in the computational requirements for
training and deployment. Memristor crossbars have emerged as a promising
solution, which demonstrated a small footprint and remarkably high energy
efficiency in computer vision (CV) models. Memristors possess higher density
compared to conventional memory technologies, making them highly suitable for
effectively managing the extreme model size associated with LLMs. However,
deploying LLMs on memristor crossbars faces three major challenges. Firstly,
the size of LLMs increases rapidly, already surpassing the capabilities of
state-of-the-art memristor chips. Secondly, LLMs often incorporate multi-head
attention blocks, which involve non-weight stationary multiplications that
traditional memristor crossbars cannot support. Third, while memristor
crossbars excel at performing linear operations, they are not capable of
executing complex nonlinear operations in LLM such as softmax and layer
normalization. To address these challenges, we present a novel architecture for
the memristor crossbar that enables the deployment of state-of-the-art LLM on a
single chip or package, eliminating the energy and time inefficiencies
associated with off-chip communication. Our testing on BERT_Large showed
negligible accuracy loss. Compared to traditional memristor crossbars, our
architecture achieves enhancements of up to 39X in area overhead and 18X in
energy consumption. Compared to modern TPU/GPU systems, our architecture
demonstrates at least a 68X reduction in the area-delay product and a
significant 69% energy consumption reduction.

摘要：大型語言模型 (LLM) 因其在各種領域中具有廣泛的應用前景而備受關注。儘管如此，LLM 的規模日益龐大，對訓練和部署的計算需求也大幅增加。憶阻器交叉陣列已成為一種有前途的解決方案，它在計算機視覺 (CV) 模型中展示了較小的佔用空間和極高的能效。與傳統記憶體技術相比，憶阻器具有更高的密度，這使其非常適合有效管理與 LLM 相關的極端模型大小。然而，在憶阻器交叉陣列上部署 LLM 面臨三大挑戰。首先，LLM 的規模迅速擴大，已經超過了最先進的憶阻器晶片的效能。其次，LLM 通常包含多頭注意力區塊，其中涉及非權重平穩乘法，而傳統的憶阻器交叉陣列無法支援。第三，儘管憶阻器交叉陣列擅長執行線性運算，但它們無法執行 LLM 中的複雜非線性運算，例如 softmax 和層標準化。為了應對這些挑戰，我們提出了一種用於憶阻器交叉陣列的新架構，該架構可以在單一晶片或封裝上部署最先進的 LLM，從而消除與晶片外通訊相關的能耗和時間效率低下。我們在 BERT_Large 上的測試顯示出可以忽略不計的準確度損失。與傳統的憶阻器交叉陣列相比，我們的架構在面積開銷方面提升了 39 倍，在能耗方面提升了 18 倍。與現代 TPU/GPU 系統相比，我們的架構在面積延遲乘積方面至少減少了 68 倍，能耗方面顯著減少了 69%。

##### **Large Language Models for Cross-lingual Emotion Detection**
2410.15974v1 by Ram Mohan Rao Kadiyala

This paper presents a detailed system description of our entry for the WASSA
2024 Task 2, focused on cross-lingual emotion detection. We utilized a
combination of large language models (LLMs) and their ensembles to effectively
understand and categorize emotions across different languages. Our approach not
only outperformed other submissions with a large margin, but also demonstrated
the strength of integrating multiple models to enhance performance.
Additionally, We conducted a thorough comparison of the benefits and
limitations of each model used. An error analysis is included along with
suggested areas for future improvement. This paper aims to offer a clear and
comprehensive understanding of advanced techniques in emotion detection, making
it accessible even to those new to the field.

摘要：本文詳細說明我們在 WASSA 2024 任務 2 中的參賽系統，重點在於跨語言的情緒偵測。我們利用大型語言模型 (LLM) 及其合奏，有效地理解並分類不同語言的情緒。我們的做法不僅大幅超越其他提交的作品，也證明整合多種模型可以提升效能。此外，我們徹底比較了各個模型的優缺點。本文包含錯誤分析，以及建議的未來改進領域。本文旨在提供清晰且全面的進階情緒偵測技術說明，即使是該領域的新手也能理解。

##### **Karush-Kuhn-Tucker Condition-Trained Neural Networks (KKT Nets)**
2410.15973v1 by Shreya Arvind, Rishabh Pomaje, Rajshekhar V Bhat

This paper presents a novel approach to solving convex optimization problems
by leveraging the fact that, under certain regularity conditions, any set of
primal or dual variables satisfying the Karush-Kuhn-Tucker (KKT) conditions is
necessary and sufficient for optimality. Similar to Theory-Trained Neural
Networks (TTNNs), the parameters of the convex optimization problem are input
to the neural network, and the expected outputs are the optimal primal and dual
variables. A choice for the loss function in this case is a loss, which we
refer to as the KKT Loss, that measures how well the network's outputs satisfy
the KKT conditions. We demonstrate the effectiveness of this approach using a
linear program as an example. For this problem, we observe that minimizing the
KKT Loss alone outperforms training the network with a weighted sum of the KKT
Loss and a Data Loss (the mean-squared error between the ground truth optimal
solutions and the network's output). Moreover, minimizing only the Data Loss
yields inferior results compared to those obtained by minimizing the KKT Loss.
While the approach is promising, the obtained primal and dual solutions are not
sufficiently close to the ground truth optimal solutions. In the future, we aim
to develop improved models to obtain solutions closer to the ground truth and
extend the approach to other problem classes.

摘要：本文提出了一種解決凸優化問題的新方法，方法是利用在特定規則條件下，任何滿足 Karush-Kuhn-Tucker (KKT) 條件的原始或對偶變數組對於最優性而言是必要且充分的事實。類似於理論訓練神經網路 (TTNN)，凸優化問題的參數會輸入神經網路，而預期的輸出是最佳原始和對偶變數。在這種情況下，損失函數的選擇是一種損失，我們稱之為 KKT 損失，它衡量網路輸出滿足 KKT 條件的程度。我們以線性規劃為例，展示了這種方法的有效性。對於這個問題，我們觀察到僅最小化 KKT 損失就優於使用 KKT 損失和資料損失（地面實況最佳解與網路輸出之間的均方誤差）的加權和來訓練網路。此外，僅最小化資料損失會產生劣於最小化 KKT 損失的結果。雖然這種方法很有希望，但獲得的原始和對偶解並不足以接近地面實況的最佳解。未來，我們旨在開發改進的模型，以獲得更接近地面實況的解，並將這種方法擴展到其他問題類別。

##### **Policy-driven Knowledge Selection and Response Generation for Document-grounded Dialogue**
2410.15970v1 by Longxuan Ma, Jiapeng Li, Mingda Li, Wei-Nan Zhang, Ting Liu

Document-grounded dialogue (DGD) uses documents as external knowledge for
dialogue generation. Correctly understanding the dialogue context is crucial
for selecting knowledge from the document and generating proper responses. In
this paper, we propose using a dialogue policy to help the dialogue
understanding in DGD. Our dialogue policy consists of two kinds of guiding
signals: utterance function and topic transfer intent. The utterance function
reflects the purpose and style of an utterance, and the topic transfer intent
reflects the topic and content of an utterance. We propose a novel framework
exploiting our dialogue policy for two core tasks in DGD, namely knowledge
selection (KS) and response generation (RG). The framework consists of two
modules: the Policy planner leverages policy-aware dialogue representation to
select knowledge and predict the policy of the response; the generator uses
policy/knowledge-aware dialogue representation for response generation. Our
policy-driven model gets state-of-the-art performance on three public
benchmarks and we provide a detailed analysis of the experimental results. Our
code/data will be released on GitHub.

摘要：文件基礎對話 (DGD) 使用文件作為對話產生的外部知識。正確理解對話內容對於從文件中選取知識並產生適當回應至關重要。在本文中，我們建議使用對話策略來協助 DGD 中的對話理解。我們的對話策略包含兩種指導信號：發話功能和主題轉移意圖。發話功能反映發話的目的和風格，而主題轉移意圖反映發話的主題和內容。我們提出一個新穎的架構，利用我們的對話策略來執行 DGD 中的兩個核心任務，即知識選取 (KS) 和回應產生 (RG)。該架構包含兩個模組：策略規劃器利用策略感知對話表示來選取知識並預測回應的策略；產生器使用策略/知識感知對話表示來產生回應。我們的策略驅動模型在三個公共基準測試中獲得最先進的效能，我們提供了實驗結果的詳細分析。我們的程式碼/資料將在 GitHub 上發布。

##### **Self-Explained Keywords Empower Large Language Models for Code Generation**
2410.15966v1 by Lishui Fan, Mouxiang Chen, Zhongxin Liu

Large language models (LLMs) have achieved impressive performance in code
generation. However, due to the long-tail distribution of LLMs' training data,
low-frequency terms are typically underrepresented in the training process.
Consequently, LLMs often misunderstand or overlook problem-specific,
low-frequency keywords during code generation, compromising the accuracy of the
generated code. To address this, we propose a novel technique named
SEK(\textbf{S}elf-\textbf{E}xplained \textbf{K}eywords), which empowers an LLM
for better code generation by extracting and explaining the key terms in the
problem description with the LLM itself and ranking them based on frequency.
Comprehensive experiments across three benchmarks, i.e., HumanEval(+), MBPP(+),
and APPS, with five representative LLMs, show that SEK can significantly
improve LLMs in code generation, yielding substantial and consistent gains. For
instance, SEK improves the Pass@1 of DeepSeek-Coder-V2-Instruct from 85.4\% to
93.3\% on the Humaneval benchmark. Further analysis confirms that SEK enables
the LLMs to shift their attention from low-frequency keywords to their
corresponding high-frequency counterparts.

摘要：大型語言模型 (LLM) 在程式碼生成中已取得令人印象深刻的表現。然而，由於 LLM 訓練資料的長尾分布，低頻率術語通常在訓練過程中代表性不足。因此，LLM 在程式碼生成過程中經常誤解或忽略特定於問題的低頻率關鍵字，損害了所生成程式碼的準確性。為了解決這個問題，我們提出了一種名為 SEK（**S**elf-**E**xplained **K**eywords）的新技術，它通過使用 LLM 本身從問題描述中提取和解釋關鍵術語並根據頻率對它們進行排序，賦予 LLM 更好的程式碼生成能力。在三個基準，即 HumanEval(+)、MBPP(+) 和 APPS，以及五個具有代表性的 LLM 上進行的綜合實驗表明，SEK 可以顯著改善 LLM 在程式碼生成中的表現，產生顯著且一致的收益。例如，SEK 將 DeepSeek-Coder-V2-Instruct 在 Humaneval 基準上的 Pass@1 從 85.4% 提高到 93.3%。進一步的分析證實，SEK 使 LLM 能夠將注意力從低頻率關鍵字轉移到它們對應的高頻率對應詞。

##### **Systematic Exploration of Dialogue Summarization Approaches for Reproducibility, Comparative Assessment, and Methodological Innovations for Advancing Natural Language Processing in Abstractive Summarization**
2410.15962v1 by Yugandhar Reddy Gogireddy, Jithendra Reddy Gogireddy

Reproducibility in scientific research, particularly within the realm of
natural language processing (NLP), is essential for validating and verifying
the robustness of experimental findings. This paper delves into the
reproduction and evaluation of dialogue summarization models, focusing
specifically on the discrepancies observed between original studies and our
reproduction efforts. Dialogue summarization is a critical aspect of NLP,
aiming to condense conversational content into concise and informative
summaries, thus aiding in efficient information retrieval and decision-making
processes. Our research involved a thorough examination of several dialogue
summarization models using the AMI (Augmented Multi-party Interaction) dataset.
The models assessed include Hierarchical Memory Networks (HMNet) and various
versions of Pointer-Generator Networks (PGN), namely PGN(DKE), PGN(DRD),
PGN(DTS), and PGN(DALL). The primary objective was to evaluate the
informativeness and quality of the summaries generated by these models through
human assessment, a method that introduces subjectivity and variability in the
evaluation process. The analysis began with Dataset 1, where the sample
standard deviation of 0.656 indicated a moderate dispersion of data points
around the mean.

摘要：在科學研究中，特別是在自然語言處理 (NLP) 領域，可重複性對於驗證和驗證實驗結果的穩健性至關重要。本文深入探討對話摘要模型的重現和評估，特別關注原始研究和我們的重現工作之間觀察到的差異。對話摘要是 NLP 的一個關鍵方面，旨在將對話內容濃縮成簡潔且有資訊性的摘要，從而有助於有效的資訊檢索和決策制定過程。我們的研究涉及使用 AMI（擴增多方互動）資料集對幾個對話摘要模型進行徹底的檢驗。評估的模型包括階層記憶網路 (HMNet) 和各種版本的指標生成器網路 (PGN)，即 PGN(DKE)、PGN(DRD)、PGN(DTS) 和 PGN(DALL)。主要目標是透過人工評估來評估這些模型產生的摘要的資訊性和品質，這種方法在評估過程中引入了主觀性和可變性。分析從資料集 1 開始，其中樣本標準差為 0.656，表示資料點在平均值周圍有適度的分散。

##### **Do Large Language Models Have an English Accent? Evaluating and Improving the Naturalness of Multilingual LLMs**
2410.15956v1 by Yanzhu Guo, Simone Conia, Zelin Zhou, Min Li, Saloni Potdar, Henry Xiao

Current Large Language Models (LLMs) are predominantly designed with English
as the primary language, and even the few that are multilingual tend to exhibit
strong English-centric biases. Much like speakers who might produce awkward
expressions when learning a second language, LLMs often generate unnatural
outputs in non-English languages, reflecting English-centric patterns in both
vocabulary and grammar. Despite the importance of this issue, the naturalness
of multilingual LLM outputs has received limited attention. In this paper, we
address this gap by introducing novel automatic corpus-level metrics to assess
the lexical and syntactic naturalness of LLM outputs in a multilingual context.
Using our new metrics, we evaluate state-of-the-art LLMs on a curated benchmark
in French and Chinese, revealing a tendency towards English-influenced
patterns. To mitigate this issue, we also propose a simple and effective
alignment method to improve the naturalness of an LLM in a target language and
domain, achieving consistent improvements in naturalness without compromising
the performance on general-purpose benchmarks. Our work highlights the
importance of developing multilingual metrics, resources and methods for the
new wave of multilingual LLMs.

摘要：目前的大型語言模型（LLM）主要是以英語作為主要語言設計的，即使是少數的多語言模型也傾向於表現出強烈的以英語為中心的偏見。就像學習第二語言時可能會產生奇怪表達方式的說話者一樣，LLM 通常會以非英語語言產生不自然的輸出，反映在詞彙和語法中以英語為中心的模式。儘管這個問題很重要，但多語言 LLM 產出的自然性卻很少受到關注。在本文中，我們透過引入新的自動語料庫級度量度來解決這個差距，以評估多語言環境中 LLM 產出的詞彙和句法自然性。使用我們新的度量標準，我們評估了法語和中文精選基準上的最新 LLM，揭示了受英語影響的模式的趨勢。為了減輕這個問題，我們還提出了一種簡單且有效的方法，以提高 LLM 在目標語言和領域中的自然性，在不影響通用基準效能的情況下，持續改善自然性。我們的研究重點說明了為新一波的多語言 LLM 開發多語言度量標準、資源和方法的重要性。

##### **TS-ACL: A Time Series Analytic Continual Learning Framework for Privacy-Preserving and Class-Incremental Pattern Recognition**
2410.15954v1 by Kejia Fan, Jiaxu Li, Songning Lai, Linpu Lv, Anfeng Liu, Jianheng Tang, Houbing Herbert Song, Huiping Zhuang

Class-incremental Learning (CIL) in Time Series Classification (TSC) aims to
incrementally train models using the streaming time series data that arrives
continuously. The main problem in this scenario is catastrophic forgetting,
i.e., training models with new samples inevitably leads to the forgetting of
previously learned knowledge. Among existing methods, the replay-based methods
achieve satisfactory performance but compromise privacy, while exemplar-free
methods protect privacy but suffer from low accuracy. However, more critically,
owing to their reliance on gradient-based update techniques, these existing
methods fundamentally cannot solve the catastrophic forgetting problem. In TSC
scenarios with continuously arriving data and temporally shifting
distributions, these methods become even less practical. In this paper, we
propose a Time Series Analytic Continual Learning framework, called TS-ACL.
Inspired by analytical learning, TS-ACL transforms neural network updates into
gradient-free linear regression problems, thereby fundamentally mitigating
catastrophic forgetting. Specifically, employing a pre-trained and frozen
feature extraction encoder, TS-ACL only needs to update its analytic classifier
recursively in a lightweight manner that is highly suitable for real-time
applications and large-scale data processing. Additionally, we theoretically
demonstrate that the model obtained recursively through the TS-ACL is exactly
equivalent to a model trained on the complete dataset in a centralized manner,
thereby establishing the property of absolute knowledge memory. Extensive
experiments validate the superior performance of our TS-ACL.

摘要：時間序列分類 (TSC) 中的類別增量學習 (CIL) 旨在使用持續抵達的串流時間序列資料逐步訓練模型。此情境中的主要問題是災難性遺忘，即使用新範例訓練模型無可避免地會遺忘先前學習到的知識。在現有方法中，基於重播的方法可達成令人滿意的效能，但會危害隱私，而無範例方法則可保護隱私，但準確度較低。然而，更重要的是，由於這些現有方法依賴於基於梯度的更新技術，因此它們在根本上無法解決災難性遺忘問題。在資料持續抵達且分佈會隨時間推移的 TSC 情境中，這些方法變得更不切實際。在本文中，我們提出了一個名為 TS-ACL 的時間序列分析持續學習架構。受到分析學習的啟發，TS-ACL 將神經網路更新轉換為無梯度的線性回歸問題，從而從根本上減輕災難性遺忘。具體來說，TS-ACL 僅需使用預先訓練且凍結的特徵萃取編碼器，就能以輕量級的方式遞迴更新其分析分類器，非常適合於即時應用程式和大規模資料處理。此外，我們在理論上證明，透過 TS-ACL 遞迴取得的模型與以集中方式在完整資料集上訓練的模型完全等效，從而建立絕對知識記憶的特性。廣泛的實驗驗證了我們的 TS-ACL 的卓越效能。

##### **User-centric evaluation of explainability of AI with and for humans: a comprehensive empirical study**
2410.15952v1 by Szymon Bobek, Paloma Korycińska, Monika Krakowska, Maciej Mozolewski, Dorota Rak, Magdalena Zych, Magdalena Wójcik, Grzegorz J. Nalepa

This study is located in the Human-Centered Artificial Intelligence (HCAI)
and focuses on the results of a user-centered assessment of commonly used
eXplainable Artificial Intelligence (XAI) algorithms, specifically
investigating how humans understand and interact with the explanations provided
by these algorithms. To achieve this, we employed a multi-disciplinary approach
that included state-of-the-art research methods from social sciences to measure
the comprehensibility of explanations generated by a state-of-the-art lachine
learning model, specifically the Gradient Boosting Classifier (XGBClassifier).
We conducted an extensive empirical user study involving interviews with 39
participants from three different groups, each with varying expertise in data
science, data visualization, and domain-specific knowledge related to the
dataset used for training the machine learning model. Participants were asked a
series of questions to assess their understanding of the model's explanations.
To ensure replicability, we built the model using a publicly available dataset
from the UC Irvine Machine Learning Repository, focusing on edible and
non-edible mushrooms. Our findings reveal limitations in existing XAI methods
and confirm the need for new design principles and evaluation techniques that
address the specific information needs and user perspectives of different
classes of AI stakeholders. We believe that the results of our research and the
cross-disciplinary methodology we developed can be successfully adapted to
various data types and user profiles, thus promoting dialogue and address
opportunities in HCAI research. To support this, we are making the data
resulting from our study publicly available.

摘要：本研究位於以人為中心的 AI (HCAI) 中，重點在於針對常見的 eXplainable AI (XAI) 演算法進行以使用者為中心的評估結果，特別是探討人類如何理解和與這些演算法提供的說明互動。為達成此目的，我們採用多學科方法，其中包含社會科學的最新研究方法，用於衡量最先進的機器學習模型所產生的說明的可理解性，特別是梯度提升分類器 (XGBClassifier)。我們進行了一項廣泛的經驗使用者研究，包括訪談來自三個不同群組的 39 位參與者，每位參與者在資料科學、資料視覺化和與用於訓練機器學習模型的資料集相關的特定領域知識方面都有不同的專業知識。我們詢問參與者一系列問題，以評估他們對模型說明的理解。為了確保可複製性，我們使用來自 UC Irvine 機器學習儲存庫的公開資料集建立模型，重點關注可食用和不可食用的蘑菇。我們的研究結果揭示了現有 XAI 方法的限制，並確認需要新的設計原則和評估技術，以滿足不同類別的 AI 利益相關者的特定資訊需求和使用者觀點。我們相信，我們的研究結果和我們開發的跨領域方法可以成功地應用於各種資料類型和使用者設定檔，從而促進對話並解決 HCAI 研究中的機會。為了支持這一點，我們將研究中產生的資料公開。

##### **Findings of the Third Shared Task on Multilingual Coreference Resolution**
2410.15949v1 by Michal Novák, Barbora Dohnalová, Miloslav Konopík, Anna Nedoluzhko, Martin Popel, Ondřej Pražák, Jakub Sido, Milan Straka, Zdeněk Žabokrtský, Daniel Zeman

The paper presents an overview of the third edition of the shared task on
multilingual coreference resolution, held as part of the CRAC 2024 workshop.
Similarly to the previous two editions, the participants were challenged to
develop systems capable of identifying mentions and clustering them based on
identity coreference.
  This year's edition took another step towards real-world application by not
providing participants with gold slots for zero anaphora, increasing the task's
complexity and realism. In addition, the shared task was expanded to include a
more diverse set of languages, with a particular focus on historical languages.
The training and evaluation data were drawn from version 1.2 of the
multilingual collection of harmonized coreference resources CorefUD,
encompassing 21 datasets across 15 languages. 6 systems competed in this shared
task.

摘要：本文概述了多语言共指消解共享任务的第三版，该任务作为 CRAC 2024 研讨会的一部分举行。
与前两版类似，参与者面临的挑战是开发能够识别提及并根据身份共指对它们进行聚类的系统。
今年的版本通过不为参与者提供零代词指代的金槽位，向现实世界应用迈出了又一步，从而增加了任务的复杂性和真实性。此外，共享任务已扩展到包括更多样化的语言集，特别关注历史语言。
训练和评估数据取自多语言协调化共指资源 CorefUD 的 1.2 版，涵盖 15 种语言的 21 个数据集。6 个系统参加了此共享任务。

##### **Developing Retrieval Augmented Generation (RAG) based LLM Systems from PDFs: An Experience Report**
2410.15944v1 by Ayman Asad Khan, Md Toufique Hasan, Kai Kristian Kemell, Jussi Rasku, Pekka Abrahamsson

This paper presents an experience report on the development of Retrieval
Augmented Generation (RAG) systems using PDF documents as the primary data
source. The RAG architecture combines generative capabilities of Large Language
Models (LLMs) with the precision of information retrieval. This approach has
the potential to redefine how we interact with and augment both structured and
unstructured knowledge in generative models to enhance transparency, accuracy,
and contextuality of responses. The paper details the end-to-end pipeline, from
data collection, preprocessing, to retrieval indexing and response generation,
highlighting technical challenges and practical solutions. We aim to offer
insights to researchers and practitioners developing similar systems using two
distinct approaches: OpenAI's Assistant API with GPT Series and Llama's
open-source models. The practical implications of this research lie in
enhancing the reliability of generative AI systems in various sectors where
domain-specific knowledge and real-time information retrieval is important. The
Python code used in this work is also available at:
https://github.com/GPT-Laboratory/RAG-LLM-Development-Guidebook-from-PDFs.

摘要：這篇論文提出了一份經驗報告，說明如何使用 PDF 文件作為主要資料來源來開發檢索增強生成 (RAG) 系統。RAG 架構結合了大型語言模型 (LLM) 的生成能力和資訊檢索的精確度。這種方法有可能重新定義我們如何與生成模型中的結構化和非結構化知識互動並加以增強，以提高回應的透明度、準確性和脈絡性。這篇論文詳細說明了端到端管線，從資料收集、預處理到檢索索引和回應產生，重點說明技術挑戰和實際解決方案。我們旨在為使用兩種不同方法開發類似系統的研究人員和從業人員提供見解：OpenAI 的助理 API 與 GPT 系列和 Llama 的開源模型。這項研究的實際意義在於提高生成式 AI 系統在各種領域的可靠性，這些領域重視特定領域的知識和即時資訊檢索。這項工作中使用的 Python 程式碼也可在以下網址取得：https://github.com/GPT-Laboratory/RAG-LLM-Development-Guidebook-from-PDFs。

##### **CausalGraph2LLM: Evaluating LLMs for Causal Queries**
2410.15939v1 by Ivaxi Sheth, Bahare Fatemi, Mario Fritz

Causality is essential in scientific research, enabling researchers to
interpret true relationships between variables. These causal relationships are
often represented by causal graphs, which are directed acyclic graphs. With the
recent advancements in Large Language Models (LLMs), there is an increasing
interest in exploring their capabilities in causal reasoning and their
potential use to hypothesize causal graphs. These tasks necessitate the LLMs to
encode the causal graph effectively for subsequent downstream tasks. In this
paper, we propose a comprehensive benchmark, \emph{CausalGraph2LLM},
encompassing a variety of causal graph settings to assess the causal graph
understanding capability of LLMs. We categorize the causal queries into two
types: graph-level and node-level queries. We benchmark both open-sourced and
closed models for our study. Our findings reveal that while LLMs show promise
in this domain, they are highly sensitive to the encoding used. Even capable
models like GPT-4 and Gemini-1.5 exhibit sensitivity to encoding, with
deviations of about $60\%$. We further demonstrate this sensitivity for
downstream causal intervention tasks. Moreover, we observe that LLMs can often
display biases when presented with contextual information about a causal graph,
potentially stemming from their parametric memory.

摘要：因果关系在科学研究中至关重要，它使研究人员能够解释变量之间的真实关系。这些因果关系通常用因果图表示，因果图是有向无环图。随着大语言模型 (LLM) 的最新进展，人们越来越有兴趣探索它们在因果推理中的能力以及它们在假设因果图中的潜在用途。这些任务需要 LLM 有效地对因果图进行编码，以便后续的下游任务。在本文中，我们提出了一个综合基准，\emph{CausalGraph2LLM}，它包含了各种因果图设置，以评估 LLM 的因果图理解能力。我们将因果查询分为两类：图级查询和节点级查询。我们对开源模型和封闭模型进行了基准测试。我们的研究结果表明，虽然 LLM 在该领域显示出前景，但它们对所使用的编码非常敏感。即使像 GPT-4 和 Gemini-1.5 这样的强大模型也对编码表现出敏感性，偏差约为 60%。我们进一步证明了这种对下游因果干预任务的敏感性。此外，我们观察到，当 LLM 获得有关因果图的上下文信息时，它们通常会表现出偏见，这可能源于它们的参数记忆。

##### **Centrality-aware Product Retrieval and Ranking**
2410.15930v1 by Hadeel Saadany, Swapnil Bhosale, Samarth Agrawal, Diptesh Kanojia, Constantin Orasan, Zhe Wu

This paper addresses the challenge of improving user experience on e-commerce
platforms by enhancing product ranking relevant to users' search queries.
Ambiguity and complexity of user queries often lead to a mismatch between the
user's intent and retrieved product titles or documents. Recent approaches have
proposed the use of Transformer-based models, which need millions of annotated
query-title pairs during the pre-training stage, and this data often does not
take user intent into account. To tackle this, we curate samples from existing
datasets at eBay, manually annotated with buyer-centric relevance scores and
centrality scores, which reflect how well the product title matches the users'
intent. We introduce a User-intent Centrality Optimization (UCO) approach for
existing models, which optimises for the user intent in semantic product
search. To that end, we propose a dual-loss based optimisation to handle hard
negatives, i.e., product titles that are semantically relevant but do not
reflect the user's intent. Our contributions include curating challenging
evaluation sets and implementing UCO, resulting in significant product ranking
efficiency improvements observed for different evaluation metrics. Our work
aims to ensure that the most buyer-centric titles for a query are ranked
higher, thereby, enhancing the user experience on e-commerce platforms.

摘要：本文探讨了通过提升与用户搜寻查询相关的产品排名，进而改善电子商务平台用户体验的挑战。用户查询的模糊性和复杂性通常会导致用户意图与检索到的产品标题或文件之间出现不匹配。最近的方法提出了使用基于 Transformer 的模型，该模型在预训练阶段需要数百万个带注释的查询-标题对，而这些数据通常未将用户意图考虑在内。为了解决这个问题，我们从 eBay 的现有数据集整理样本，并用以买家为中心的关联性得分和中心性得分手动进行注释，这些得分反映了产品标题与用户意图的匹配程度。我们为现有模型引入了用户意图中心性优化 (UCO) 方法，该方法优化了语义产品搜索中的用户意图。为此，我们提出了基于双损失的优化来处理硬否定，即语义相关的产品标题，但不能反映用户的意图。我们的贡献包括整理具有挑战性的评估集和实现 UCO，从而导致观察到针对不同评估指标的产品排名效率有显著提升。我们的工作旨在确保针对查询的最以买家为中心标题获得更高的排名，从而提升电子商务平台的用户体验。

##### **Yeah, Un, Oh: Continuous and Real-time Backchannel Prediction with Fine-tuning of Voice Activity Projection**
2410.15929v1 by Koji Inoue, Divesh Lala, Gabriel Skantze, Tatsuya Kawahara

In human conversations, short backchannel utterances such as "yeah" and "oh"
play a crucial role in facilitating smooth and engaging dialogue. These
backchannels signal attentiveness and understanding without interrupting the
speaker, making their accurate prediction essential for creating more natural
conversational agents. This paper proposes a novel method for real-time,
continuous backchannel prediction using a fine-tuned Voice Activity Projection
(VAP) model. While existing approaches have relied on turn-based or
artificially balanced datasets, our approach predicts both the timing and type
of backchannels in a continuous and frame-wise manner on unbalanced, real-world
datasets. We first pre-train the VAP model on a general dialogue corpus to
capture conversational dynamics and then fine-tune it on a specialized dataset
focused on backchannel behavior. Experimental results demonstrate that our
model outperforms baseline methods in both timing and type prediction tasks,
achieving robust performance in real-time environments. This research offers a
promising step toward more responsive and human-like dialogue systems, with
implications for interactive spoken dialogue applications such as virtual
assistants and robots.

摘要：在人類對話中，諸如「嗯」和「喔」等簡短的回饋語句在促進順暢且引人入勝的對話中扮演著至關重要的角色。這些回饋語句傳達了注意力和理解，卻不中斷說話者，因此準確預測這些語句對於創造更自然的對話代理至關重要。本文提出了一種使用微調語音活動預測 (VAP) 模型進行實時、連續回饋語句預測的新方法。雖然現有方法依賴於回合制或人工平衡的數據集，但我們的做法是以連續且逐幀的方式在不平衡的真實世界數據集上預測回饋語句的時機和類型。我們首先在一般對話語料庫上預訓練 VAP 模型以捕捉對話動態，然後在專注於回饋語句行為的專門數據集上微調它。實驗結果表明，我們的模型在時機和類型預測任務中都優於基線方法，在實時環境中實現了穩健的性能。這項研究為更具回應性和更擬人的對話系統邁出了有希望的一步，對互動式口語對話應用（例如虛擬助理和機器人）具有影響。

##### **GReFEL: Geometry-Aware Reliable Facial Expression Learning under Bias and Imbalanced Data Distribution**
2410.15927v1 by Azmine Toushik Wasi, Taki Hasan Rafi, Raima Islam, Karlo Serbetar, Dong Kyu Chae

Reliable facial expression learning (FEL) involves the effective learning of
distinctive facial expression characteristics for more reliable, unbiased and
accurate predictions in real-life settings. However, current systems struggle
with FEL tasks because of the variance in people's facial expressions due to
their unique facial structures, movements, tones, and demographics. Biased and
imbalanced datasets compound this challenge, leading to wrong and biased
prediction labels. To tackle these, we introduce GReFEL, leveraging Vision
Transformers and a facial geometry-aware anchor-based reliability balancing
module to combat imbalanced data distributions, bias, and uncertainty in facial
expression learning. Integrating local and global data with anchors that learn
different facial data points and structural features, our approach adjusts
biased and mislabeled emotions caused by intra-class disparity, inter-class
similarity, and scale sensitivity, resulting in comprehensive, accurate, and
reliable facial expression predictions. Our model outperforms current
state-of-the-art methodologies, as demonstrated by extensive experiments on
various datasets.

摘要：可靠的面部表情學習 (FEL) 涉及有效學習獨特的面部表情特徵，以便在現實生活中進行更可靠、無偏見和準確的預測。然而，由於人們的面部結構、動作、語調和人口統計資料的差異，當前系統難以應對 FEL 任務。有偏見和不平衡的資料集加劇了這一挑戰，導致錯誤和有偏見的預測標籤。為了解決這些問題，我們引入了 GReFEL，利用視覺Transformer和一個面部幾何感知的基於錨點的可靠性平衡模組，以應對面部表情學習中的不平衡資料分佈、偏見和不確定性。通過將局部和全局資料與學習不同面部資料點和結構特徵的錨點相整合，我們的做法調整了由類內差異、類間相似性和尺度敏感性導致的有偏見和標籤錯誤的情緒，從而產生全面、準確和可靠的面部表情預測。我們的模型優於當前的最先進方法，這已通過在各種資料集上進行的廣泛實驗得到證明。

##### **Mitigating Object Hallucination via Concentric Causal Attention**
2410.15926v1 by Yun Xing, Yiheng Li, Ivan Laptev, Shijian Lu

Recent Large Vision Language Models (LVLMs) present remarkable zero-shot
conversational and reasoning capabilities given multimodal queries.
Nevertheless, they suffer from object hallucination, a phenomenon where LVLMs
are prone to generate textual responses not factually aligned with image
inputs. Our pilot study reveals that object hallucination is closely tied with
Rotary Position Encoding (RoPE), a widely adopted positional dependency
modeling design in existing LVLMs. Due to the long-term decay in RoPE, LVLMs
tend to hallucinate more when relevant visual cues are distant from instruction
tokens in the multimodal input sequence. Additionally, we observe a similar
effect when reversing the sequential order of visual tokens during multimodal
alignment. Our tests indicate that long-term decay in RoPE poses challenges to
LVLMs while capturing visual-instruction interactions across long distances. We
propose Concentric Causal Attention (CCA), a simple yet effective positional
alignment strategy that mitigates the impact of RoPE long-term decay in LVLMs
by naturally reducing relative distance between visual and instruction tokens.
With CCA, visual tokens can better interact with instruction tokens, thereby
enhancing model's perception capability and alleviating object hallucination.
Without bells and whistles, our positional alignment method surpasses existing
hallucination mitigation strategies by large margins on multiple object
hallucination benchmarks.

摘要：最近的大型视觉语言模型 (LVLMs) 在给定多模态查询时呈现出非凡的零次学习对话和推理能力。
尽管如此，它们还是会产生对象幻觉，这是一个现象，即 LVLMs 容易生成与图像输入事实不符的文本响应。我们的试点研究表明，对象幻觉与旋转位置编码 (RoPE) 密切相关，旋转位置编码是现有 LVLMs 中广泛采用的位置依赖建模设计。由于 RoPE 中的长期衰减，当相关视觉线索与多模态输入序列中的指令标记相距较远时，LVLMs 往往会产生更多的幻觉。此外，我们在多模态对齐期间反转视觉标记的顺序时观察到了类似的效果。我们的测试表明，RoPE 中的长期衰减对 LVLMs 在远距离捕获视觉指令交互时构成了挑战。我们提出了同心因果注意力 (CCA)，这是一种简单而有效的定位对齐策略，通过自然地缩短视觉标记和指令标记之间的相对距离来减轻 RoPE 长期衰减对 LVLMs 的影响。借助 CCA，视觉标记可以更好地与指令标记交互，从而增强模型的感知能力并减轻对象幻觉。在没有花里胡哨的情况下，我们的位置对齐方法在多个对象幻觉基准上以大幅优势超越了现有的幻觉缓解策略。

##### **Bench4Merge: A Comprehensive Benchmark for Merging in Realistic Dense Traffic with Micro-Interactive Vehicles**
2410.15912v1 by Zhengming Wang, Junli Wang, Pengfei Li, Zhaohan Li, Peng Li, Yilun Chen

While the capabilities of autonomous driving have advanced rapidly, merging
into dense traffic remains a significant challenge, many motion planning
methods for this scenario have been proposed but it is hard to evaluate them.
Most existing closed-loop simulators rely on rule-based controls for other
vehicles, which results in a lack of diversity and randomness, thus failing to
accurately assess the motion planning capabilities in highly interactive
scenarios. Moreover, traditional evaluation metrics are insufficient for
comprehensively evaluating the performance of merging in dense traffic. In
response, we proposed a closed-loop evaluation benchmark for assessing motion
planning capabilities in merging scenarios. Our approach involves other
vehicles trained in large scale datasets with micro-behavioral characteristics
that significantly enhance the complexity and diversity. Additionally, we have
restructured the evaluation mechanism by leveraging large language models to
assess each autonomous vehicle merging onto the main road. Extensive
experiments have demonstrated the advanced nature of this evaluation benchmark.
Through this benchmark, we have obtained an evaluation of existing methods and
identified common issues. The environment and vehicle motion planning models we
have designed can be accessed at
https://anonymous.4open.science/r/Bench4Merge-EB5D

摘要：儘管自動駕駛的能力進展迅速，但融入密集的交通仍然是一項重大挑戰，針對此情境的許多運動規劃方法已被提出，但很難對它們進行評估。
現有的封閉迴路模擬器大多依賴於其他車輛的基於規則的控制，這導致缺乏多樣性和隨機性，因此無法準確評估在高度互動情境中的運動規劃能力。
此外，傳統的評估指標不足以全面評估在密集交通中合併的性能。
作為回應，我們提出了一個封閉迴路評估基準，用於評估合併情境中的運動規劃能力。
我們的做法涉及在具有微行為特徵的大規模數據集中訓練的其他車輛，這顯著提高了複雜性和多樣性。
此外，我們通過利用大型語言模型重新調整了評估機制，以評估每個自主車輛併入主幹道。
廣泛的實驗證明了這個評估基準的先進性。
通過這個基準，我們獲得了對現有方法的評估，並找出常見的問題。
我們設計的環境和車輛運動規劃模型可以在
https://anonymous.4open.science/r/Bench4Merge-EB5D 獲得

##### **DefVerify: Do Hate Speech Models Reflect Their Dataset's Definition?**
2410.15911v1 by Urja Khurana, Eric Nalisnick, Antske Fokkens

When building a predictive model, it is often difficult to ensure that
domain-specific requirements are encoded by the model that will eventually be
deployed. Consider researchers working on hate speech detection. They will have
an idea of what is considered hate speech, but building a model that reflects
their view accurately requires preserving those ideals throughout the workflow
of data set construction and model training. Complications such as sampling
bias, annotation bias, and model misspecification almost always arise, possibly
resulting in a gap between the domain specification and the model's actual
behavior upon deployment. To address this issue for hate speech detection, we
propose DefVerify: a 3-step procedure that (i) encodes a user-specified
definition of hate speech, (ii) quantifies to what extent the model reflects
the intended definition, and (iii) tries to identify the point of failure in
the workflow. We use DefVerify to find gaps between definition and model
behavior when applied to six popular hate speech benchmark datasets.

摘要：在建立預測模型時，通常難以確保模型編碼了特定領域的要求，而這些要求最終將會被部署。考慮研究仇恨言論偵測的研究人員。他們將會了解什麼被視為仇恨言論，但建立一個準確反映他們觀點的模型需要在資料集建構和模型訓練的工作流程中保留這些理想。幾乎總是會出現像抽樣偏差、註解偏差和模型錯誤規範等複雜情況，可能導致領域規範和模型在部署後的實際行為之間出現差距。為了解決仇恨言論偵測的這個問題，我們提出 DefVerify：一個 3 步驟程序，它 (i) 編碼使用者指定的仇恨言論定義，(ii) 量化模型反映預期定義的程度，以及 (iii) 嘗試找出工作流程中的失敗點。我們使用 DefVerify 來找出定義和模型行為之間的差距，並將其應用於六個流行的仇恨言論基準資料集。

##### **IGMaxHS -- An Incremental MaxSAT Solver with Support for XOR Clauses**
2410.15897v1 by Ole Lübke

Recently, a novel, MaxSAT-based method for error correction in quantum
computing has been proposed that requires both incremental MaxSAT solving
capabilities and support for XOR constraints, but no dedicated MaxSAT solver
fulfilling these criteria existed yet. We alleviate that and introduce IGMaxHS,
which is based on the existing solvers iMaxHS and GaussMaxHS, but poses fewer
restrictions on the XOR constraints than GaussMaxHS. IGMaxHS is fuzz tested
with xwcnfuzz, an extension of wcnfuzz that can directly output XOR
constraints. As a result, IGMaxHS is the only solver that reported neither
incorrect unsatisfiability verdicts nor invalid models nor incoherent cost
model combinations in a final fuzz testing comparison of all three solvers with
10000 instances. We detail the steps required for implementing Gaussian
elimination on XOR constraints in CDCL SAT solvers, and extend the recently
proposed re-entrant incremental MaxSAT solver application program interface to
allow for incremental addition of XOR constraints. Finally, we show that
IGMaxHS is capable of decoding quantum color codes through simulation with the
Munich Quantum Toolkit.

摘要：最近，提出了一种基于 MaxSAT 的量子计算纠错新方法，该方法需要增量式 MaxSAT 求解能力和对 XOR 约束的支持，但还没有专门的 MaxSAT 求解器满足这些标准。我们缓解了这个问题，并引入了 IGMaxHS，它基于现有的求解器 iMaxHS 和 GaussMaxHS，但对 XOR 约束的限制比 GaussMaxHS 少。IGMaxHS 使用 xwcnfuzz 进行模糊测试，xwcnfuzz 是 wcnfuzz 的扩展，可以直接输出 XOR 约束。因此，IGMaxHS 是唯一一个在所有三个求解器的最终模糊测试比较中既没有报告不正确的不可满足性结果，也没有报告无效模型或不连贯的成本模型组合的求解器，测试实例为 10000 个。我们详细介绍了在 CDCL SAT 求解器中对 XOR 约束实现高斯消元所需的步骤，并扩展了最近提出的可重入增量 MaxSAT 求解器应用程序编程接口，以允许增量添加 XOR 约束。最后，我们展示了 IGMaxHS 能够通过使用慕尼黑量子工具包进行模拟来解码量子颜色码。

##### **Model Mimic Attack: Knowledge Distillation for Provably Transferable Adversarial Examples**
2410.15889v1 by Kirill Lukyanov, Andrew Perminov, Denis Turdakov, Mikhail Pautov

The vulnerability of artificial neural networks to adversarial perturbations
in the black-box setting is widely studied in the literature. The majority of
attack methods to construct these perturbations suffer from an impractically
large number of queries required to find an adversarial example. In this work,
we focus on knowledge distillation as an approach to conduct transfer-based
black-box adversarial attacks and propose an iterative training of the
surrogate model on an expanding dataset. This work is the first, to our
knowledge, to provide provable guarantees on the success of knowledge
distillation-based attack on classification neural networks: we prove that if
the student model has enough learning capabilities, the attack on the teacher
model is guaranteed to be found within the finite number of distillation
iterations.

摘要：人工神經網路在黑箱設定中對抗擾動的脆弱性在文獻中廣泛研究。大多數用於建構這些擾動的攻擊方法都存在一個不切實際的缺點，即需要大量的查詢才能找到對抗範例。在這項工作中，我們專注於知識萃取作為執行基於傳輸的黑箱對抗攻擊的方法，並提出在擴充資料集上對代理模型進行反覆訓練。據我們所知，這項工作是第一個針對基於知識萃取的分類神經網路攻擊的成功提供可證明保證：我們證明，如果學生模型有足夠的學習能力，則保證可以在有限的萃取反覆運算中找到對教師模型的攻擊。

##### **How to Build a Pre-trained Multimodal model for Simultaneously Chatting and Decision-making?**
2410.15885v1 by Zuojin Tang, Bin Hu, Chenyang Zhao, De Ma, Gang Pan, Bin Liu

Existing large pre-trained models typically map text input to text output in
an end-to-end manner, such as ChatGPT, or map a segment of text input to a
hierarchy of action decisions, such as OpenVLA. However, humans can
simultaneously generate text and actions when receiving specific input signals.
For example, a driver can make precise driving decisions while conversing with
a friend in the passenger seat. Motivated by this observation, we consider the
following question in this work: is it possible to construct a pre-trained
model that can provide both language interaction and precise decision-making
capabilities in dynamic open scenarios. We provide a definitive answer to this
question by developing a new model architecture termed Visual Language Action
model for Chatting and Decision Making (VLA4CD), and further demonstrating its
performance in challenging autonomous driving tasks. Specifically, we leverage
LoRA to fine-tune a pre-trained LLM with data of multiple modalities covering
language, visual, and action. Unlike the existing LoRA operations used for LLM
fine-tuning, we have designed new computational modules and training cost
functions for VLA4CD. These designs enable VLA4CD to provide continuous-valued
action decisions while outputting text responses. In contrast, existing LLMs
can only output text responses, and current VLA models can only output action
decisions. Moreover, these VLA models handle action data by discretizing and
then tokenizing the discretized actions, a method unsuitable for complex
decision-making tasks involving high-dimensional continuous-valued action
vectors, such as autonomous driving. The experimental results on CARLA validate
that: (1) our proposed model construction method is effective; (2) compared to
the SOTA VLA model, VLA4CD can provide more accurate real-time decision-making
while retaining the text interaction capability inherent to LLMs.

摘要：現有的大型預訓練模型通常會以端對端的方式將文字輸入對應到文字輸出，例如 ChatGPT，或將一段文字輸入對應到一連串動作決策的階層，例如 OpenVLA。然而，人類在收到特定的輸入訊號時，可以同時產生文字和動作。例如，一名駕駛在與坐在副駕駛座的朋友交談時，可以做出精確的駕駛決策。受到此項觀察的啟發，我們在這項工作中思考以下問題：是否可以建構一個預訓練模型，在動態開放場景中同時提供語言互動和精確決策的能力。我們透過開發一種稱為聊天和決策製作的視覺語言動作模型（VLA4CD）的新模型架構，並進一步展示其在具有挑戰性的自動駕駛任務中的效能，對此問題給出明確的答案。具體來說，我們利用 LoRA 微調一個預訓練的 LLM，其資料包含語言、視覺和動作等多種模式。與用於 LLM 微調的現有 LoRA 操作不同，我們為 VLA4CD 設計了新的運算模組和訓練成本函數。這些設計使 VLA4CD 能夠在輸出文字回應的同時，提供連續值動作決策。相比之下，現有的 LLM 只能輸出文字回應，而現有的 VLA 模型只能輸出動作決策。此外，這些 VLA 模型透過將離散化動作離散化並進行標記化來處理動作資料，這種方法不適合涉及高維連續值動作向量的複雜決策任務，例如自動駕駛。CARLA 上的實驗結果驗證了：(1) 我們提出的模型建構方法是有效的；(2) 與 SOTA VLA 模型相比，VLA4CD 能夠在保有 LLM 固有的文字互動能力的同時，提供更準確的即時決策。

##### **Using GPT Models for Qualitative and Quantitative News Analytics in the 2024 US Presidental Election Process**
2410.15884v1 by Bohdan M. Pavlyshenko

The paper considers an approach of using Google Search API and GPT-4o model
for qualitative and quantitative analyses of news through retrieval-augmented
generation (RAG). This approach was applied to analyze news about the 2024 US
presidential election process. Different news sources for different time
periods have been analyzed. Quantitative scores generated by GPT model have
been analyzed using Bayesian regression to derive trend lines. The
distributions found for the regression parameters allow for the analysis of
uncertainty in the election process. The obtained results demonstrate that
using the GPT models for news analysis, one can get informative analytics and
provide key insights that can be applied in further analyses of election
processes.

摘要：本文考慮使用 Google Search API 和 GPT-4o 模型的方法，透過檢索增強生成 (RAG) 進行新聞的定性和定量分析。此方法用於分析有關 2024 年美國總統選舉過程的新聞。已分析不同時間段的不同新聞來源。已使用貝氏迴歸分析 GPT 模型產生的量化分數，以導出趨勢線。迴歸參數中發現的分布允許分析選舉過程中的不確定性。獲得的結果表明，使用 GPT 模型進行新聞分析，可以獲得有意義的分析並提供關鍵見解，這些見解可以應用於選舉過程的進一步分析中。

##### **MI-VisionShot: Few-shot adaptation of vision-language models for slide-level classification of histopathological images**
2410.15881v1 by Pablo Meseguer, Rocío del Amor, Valery Naranjo

Vision-language supervision has made remarkable strides in learning visual
representations from textual guidance. In digital pathology, vision-language
models (VLM), pre-trained on curated datasets of histological image-captions,
have been adapted to downstream tasks, such as region of interest
classification. Zero-shot transfer for slide-level prediction has been
formulated by MI-Zero, but it exhibits high variability depending on the
textual prompts. Inspired by prototypical learning, we propose MI-VisionShot, a
training-free adaptation method on top of VLMs to predict slide-level labels in
few-shot learning scenarios. Our framework takes advantage of the excellent
representation learning of VLM to create prototype-based classifiers under a
multiple-instance setting by retrieving the most discriminative patches within
each slide. Experimentation through different settings shows the ability of
MI-VisionShot to surpass zero-shot transfer with lower variability, even in
low-shot scenarios. Code coming soon at
thttps://github.com/cvblab/MIVisionShot.

摘要：視覺語言監督在從文本指導中學習視覺表徵方面取得了顯著進展。在數位病理學中，經過組織學影像標題的精選資料集預先訓練的視覺語言模型 (VLM) 已調整為下游任務，例如感興趣區域分類。MI-Zero 已制定幻燈片級別預測的零次轉移，但它會根據文字提示而表現出高度變異性。受到原型學習的啟發，我們提出 MI-VisionShot，這是一種建立在 VLM 之上的無訓練適應方法，用於在少次學習場景中預測幻燈片級別標籤。我們的架構利用 VLM 優異的表徵學習，在多個實例設定下透過擷取每個幻燈片中最具區別性的修補程式來建立基於原型的分類器。透過不同設定的實驗顯示，MI-VisionShot 有能力超越變異性較低的零次轉移，即使在少次場景中也是如此。程式碼即將在 thttps://github.com/cvblab/MIVisionShot 上提供。

##### **FlickerFusion: Intra-trajectory Domain Generalizing Multi-Agent RL**
2410.15876v1 by Woosung Koh, Wonbeen Oh, Siyeol Kim, Suhin Shin, Hyeongjin Kim, Jaein Jang, Junghyun Lee, Se-Young Yun

Multi-agent reinforcement learning has demonstrated significant potential in
addressing complex cooperative tasks across various real-world applications.
However, existing MARL approaches often rely on the restrictive assumption that
the number of entities (e.g., agents, obstacles) remains constant between
training and inference. This overlooks scenarios where entities are dynamically
removed or added during the inference trajectory -- a common occurrence in
real-world environments like search and rescue missions and dynamic combat
situations. In this paper, we tackle the challenge of intra-trajectory dynamic
entity composition under zero-shot out-of-domain (OOD) generalization, where
such dynamic changes cannot be anticipated beforehand. Our empirical studies
reveal that existing MARL methods suffer significant performance degradation
and increased uncertainty in these scenarios. In response, we propose
FlickerFusion, a novel OOD generalization method that acts as a universally
applicable augmentation technique for MARL backbone methods. Our results show
that FlickerFusion not only achieves superior inference rewards but also
uniquely reduces uncertainty vis-\`a-vis the backbone, compared to existing
methods. For standardized evaluation, we introduce MPEv2, an enhanced version
of Multi Particle Environments (MPE), consisting of 12 benchmarks. Benchmarks,
implementations, and trained models are organized and open-sourced at
flickerfusion305.github.io, accompanied by ample demo video renderings.

摘要：多智能體強化學習已在處理各種真實世界應用中的複雜協作任務方面展現出顯著的潛力。
然而，現有的多智能體強化學習方法通常依賴於一個限制性假設，即實體（例如，智能體、障礙物）的數量在訓練和推理之間保持不變。這忽視了在推理軌跡期間實體會動態移除或新增的情況——這在現實世界環境（例如搜救任務和動態戰鬥情況）中很常見。在本文中，我們應對了在零次學習領域外 (OOD) 概括下的軌跡內動態實體組成的挑戰，其中無法預先預測此類動態變化。我們的實證研究表明，現有的多智能體強化學習方法在這些情況下會遭受顯著的效能下降和不確定性增加。為了解決這個問題，我們提出了 FlickerFusion，這是一種新穎的 OOD 概括方法，可用作多智能體強化學習主幹方法的通用擴充技術。我們的結果表明，與現有方法相比，FlickerFusion 不僅實現了優異的推理獎勵，而且獨特地降低了與主幹相比的不確定性。為了進行標準化評估，我們引入了多粒子環境 (MPE) 的增強版本 MPEv2，其中包含 12 個基準。基準、實作和訓練模型已組織並開放原始碼於 flickerfusion305.github.io，並附有大量的示範影片渲染。

##### **Principles of semantic and functional efficiency in grammatical patterning**
2410.15865v1 by Emily Cheng, Francesca Franzon

Grammatical features such as number and gender serve two central functions in
human languages. While they encode salient semantic attributes like numerosity
and animacy, they also offload sentence processing cost by predictably linking
words together via grammatical agreement. Grammars exhibit consistent
organizational patterns across diverse languages, invariably rooted in a
semantic foundation, a widely confirmed but still theoretically unexplained
phenomenon. To explain the basis of universal grammatical patterns, we unify
two fundamental properties of grammar, semantic encoding and agreement-based
predictability, into a single information-theoretic objective under cognitive
constraints. Our analyses reveal that grammatical organization provably
inherits from perceptual attributes, but that grammars empirically prioritize
functional goals, promoting efficient language processing over semantic
encoding.

摘要：語法特徵，例如數目和性別，在人類語言中具有兩個核心功能。雖然它們編碼了顯著的語義屬性，例如數量和動物性，但它們也通過語法一致性可預測地將單詞聯繫在一起，從而降低了句子處理成本。語法在不同的語言中表現出一致的組織模式，這些模式總是植根於語義基礎，這是一個得到廣泛證實但仍然無法從理論上解釋的現象。為了解釋普遍語法模式的基礎，我們將語法的兩個基本屬性，語義編碼和基於一致性的可預測性，統一到認知約束下的單一資訊理論目標中。我們的分析表明，語法組織顯然繼承自感知屬性，但語法在經驗上優先考慮功能目標，促進了對語義編碼的高效語言處理。

##### **Mesa-Extrapolation: A Weave Position Encoding Method for Enhanced Extrapolation in LLMs**
2410.15859v2 by Xin Ma, Yang Liu, Jingjing Liu, Xiaoxu Ma

Large language models (LLMs), although having revolutionized many fields,
still suffer from the challenging extrapolation problem, where the inference
ability of LLMs sharply declines beyond their max training lengths. In this
work, we conduct a theoretical analysis to better understand why No Position
Encoding (NoPE) fails outside its effective range, as well as examining the
power of Position Encoding (PE) in this context. Our findings reveal that with
meticulous weave position, PE can indeed be extended beyond effective range.
Our theorems establish that LLMs equipped with weave PE can achieve improved
extrapolation performance without additional cost. Furthermore, we introduce a
novel weave PE method, Mesa-Extrapolation, which utilizes a chunk-based
triangular attention matrix and applies Stair PE to manage the final chunk.
This method not only retains competitive performance but also offers
substantial benefits such as significantly reduced memory demand and faster
inference speed. Extensive experiments validate the effectiveness of
Mesa-Extrapolation, demonstrating its potential as a scalable solution to
enhancing LLMs applicative reach.

摘要：大型語言模型 (LLM) 儘管已經革新許多領域，
仍受限於具有挑戰性的外推問題，其中 LLM 的推論
能力在其最大訓練長度之外急劇下降。在這
項工作中，我們進行理論分析，以更好地理解為什麼無位置
編碼 (NoPE) 在其有效範圍之外會失敗，以及在此情況下探討
位置編碼 (PE) 的能力。我們的發現顯示，透過
細緻的編織位置，PE 確實可以擴展到有效範圍之外。
我們的定理表明配備編織 PE 的 LLM 可以實現改進
的外推效能，而無需額外成本。此外，我們引入一種
新穎的編織 PE 方法，Mesa-Extrapolation，它利用基於塊的
三角形注意力矩陣，並應用階梯 PE 來管理最後一個塊。
此方法不僅保持競爭力，而且還提供
顯著降低記憶體需求和更快的推論速度等實質性優點。廣泛的實驗驗證了
Mesa-Extrapolation 的有效性，證明其作為可擴充解決方案的潛力，以
增強 LLM 的應用範圍。

##### **Random Token Fusion for Multi-View Medical Diagnosis**
2410.15847v1 by Jingyu Guo, Christos Matsoukas, Fredrik Strand, Kevin Smith

In multi-view medical diagnosis, deep learning-based models often fuse
information from different imaging perspectives to improve diagnostic
performance. However, existing approaches are prone to overfitting and rely
heavily on view-specific features, which can lead to trivial solutions. In this
work, we introduce Random Token Fusion (RTF), a novel technique designed to
enhance multi-view medical image analysis using vision transformers. By
integrating randomness into the feature fusion process during training, RTF
addresses the issue of overfitting and enhances the robustness and accuracy of
diagnostic models without incurring any additional cost at inference. We
validate our approach on standard mammography and chest X-ray benchmark
datasets. Through extensive experiments, we demonstrate that RTF consistently
improves the performance of existing fusion methods, paving the way for a new
generation of multi-view medical foundation models.

摘要：在多視圖醫療診斷中，基於深度學習的模型通常融合來自不同影像視角的資訊，以提升診斷效能。然而，現有方法容易過度擬合，並過度依賴特定視角的特徵，這可能導致瑣碎的解決方案。在這項工作中，我們引入了隨機特徵融合 (RTF)，這是一種新技術，旨在使用視覺轉換器增強多視圖醫療影像分析。透過在訓練期間將隨機性整合到特徵融合過程中，RTF 解決了過度擬合的問題，並增強了診斷模型的穩健性和準確性，而不會在推論中產生任何額外的成本。我們在標準乳房攝影和胸部 X 光基準資料集上驗證了我們的方法。透過廣泛的實驗，我們證明 RTF 持續改善現有融合方法的效能，為新一代多視圖醫療基礎模型鋪平了道路。

##### **LLM4GRN: Discovering Causal Gene Regulatory Networks with LLMs -- Evaluation through Synthetic Data Generation**
2410.15828v1 by Tejumade Afonja, Ivaxi Sheth, Ruta Binkyte, Waqar Hanif, Thomas Ulas, Matthias Becker, Mario Fritz

Gene regulatory networks (GRNs) represent the causal relationships between
transcription factors (TFs) and target genes in single-cell RNA sequencing
(scRNA-seq) data. Understanding these networks is crucial for uncovering
disease mechanisms and identifying therapeutic targets. In this work, we
investigate the potential of large language models (LLMs) for GRN discovery,
leveraging their learned biological knowledge alone or in combination with
traditional statistical methods. We develop a task-based evaluation strategy to
address the challenge of unavailable ground truth causal graphs. Specifically,
we use the GRNs suggested by LLMs to guide causal synthetic data generation and
compare the resulting data against the original dataset. Our statistical and
biological assessments show that LLMs can support statistical modeling and data
synthesis for biological research.

摘要：基因調控網路 (GRN) 代表單細胞 RNA 定序 (scRNA-seq) 資料中轉錄因子 (TF) 與目標基因之間的因果關係。了解這些網路對於揭露疾病機制和找出治療目標至關重要。在這項工作中，我們探討大型語言模型 (LLM) 在 GRN 探索中的潛力，利用它們學習到的生物知識，單獨或與傳統統計方法結合使用。我們制定了一項基於任務的評估策略，以解決無法取得地面真相因果圖表的挑戰。具體來說，我們使用 LLM 建議的 GRN 來引導因果合成資料產生，並將產生的資料與原始資料集進行比較。我們的統計和生物評估顯示，LLM 可以支援生物研究的統計建模和資料合成。

##### **The effect of fine-tuning on language model toxicity**
2410.15821v1 by Will Hawkins, Brent Mittelstadt, Chris Russell

Fine-tuning language models has become increasingly popular following the
proliferation of open models and improvements in cost-effective parameter
efficient fine-tuning. However, fine-tuning can influence model properties such
as safety. We assess how fine-tuning can impact different open models'
propensity to output toxic content. We assess the impacts of fine-tuning Gemma,
Llama, and Phi models on toxicity through three experiments. We compare how
toxicity is reduced by model developers during instruction-tuning. We show that
small amounts of parameter-efficient fine-tuning on developer-tuned models via
low-rank adaptation on a non-adversarial dataset can significantly alter these
results across models. Finally, we highlight the impact of this in the wild,
demonstrating how toxicity rates of models fine-tuned by community contributors
can deviate in hard-to-predict ways.

摘要：隨著開放模型的普及和成本效益參數高效微調的進步，語言模型的微調變得越來越普遍。然而，微調會影響模型屬性，例如安全性。我們評估微調如何影響不同開放模型輸出有害內容的傾向。我們透過三個實驗評估微調對 Gemma、Llama 和 Phi 模型毒性的影響。我們比較模型開發人員在指令微調期間如何降低毒性。我們表明，透過非對抗性資料集上的低秩適應，在開發人員調整的模型上進行少量參數高效微調，可以在這些模型上顯著改變這些結果。最後，我們強調這在實際情況中的影響，展示由社群貢獻者微調的模型的毒性率如何以難以預測的方式偏離。

##### **LiMTR: Time Series Motion Prediction for Diverse Road Users through Multimodal Feature Integration**
2410.15819v1 by Camiel Oerlemans, Bram Grooten, Michiel Braat, Alaa Alassi, Emilia Silvas, Decebal Constantin Mocanu

Predicting the behavior of road users accurately is crucial to enable the
safe operation of autonomous vehicles in urban or densely populated areas.
Therefore, there has been a growing interest in time series motion prediction
research, leading to significant advancements in state-of-the-art techniques in
recent years. However, the potential of using LiDAR data to capture more
detailed local features, such as a person's gaze or posture, remains largely
unexplored. To address this, we develop a novel multimodal approach for motion
prediction based on the PointNet foundation model architecture, incorporating
local LiDAR features. Evaluation on the Waymo Open Dataset shows a performance
improvement of 6.20% and 1.58% in minADE and mAP respectively, when integrated
and compared with the previous state-of-the-art MTR. We open-source the code of
our LiMTR model.

摘要：準確預測道路使用者的行為對於在市區或人口稠密地區安全操作自動駕駛車輛至關重要。因此，時序運動預測研究引起了越來越大的興趣，並在近年來促成了最先進技術的重大進展。然而，利用 LiDAR 資料捕捉更多詳細的局部特徵（例如人的視線或姿勢）的潛力在很大程度上仍未開發。為了解決這個問題，我們基於 PointNet 基礎模型架構開發了一種新穎的多模式運動預測方法，並結合了局部 LiDAR 特徵。在 Waymo 開放資料集上的評估顯示，與先前的最先進 MTR 整合並進行比較時，minADE 和 mAP 分別改進了 6.20% 和 1.58%。我們開放了 LiMTR 模型的程式碼。

##### **Kaninfradet3D:A Road-side Camera-LiDAR Fusion 3D Perception Model based on Nonlinear Feature Extraction and Intrinsic Correlation**
2410.15814v1 by Pei Liu, Nanfang Zheng, Yiqun Li, Junlan Chen, Ziyuan Pu

With the development of AI-assisted driving, numerous methods have emerged
for ego-vehicle 3D perception tasks, but there has been limited research on
roadside perception. With its ability to provide a global view and a broader
sensing range, the roadside perspective is worth developing. LiDAR provides
precise three-dimensional spatial information, while cameras offer semantic
information. These two modalities are complementary in 3D detection. However,
adding camera data does not increase accuracy in some studies since the
information extraction and fusion procedure is not sufficiently reliable.
Recently, Kolmogorov-Arnold Networks (KANs) have been proposed as replacements
for MLPs, which are better suited for high-dimensional, complex data. Both the
camera and the LiDAR provide high-dimensional information, and employing KANs
should enhance the extraction of valuable features to produce better fusion
outcomes. This paper proposes Kaninfradet3D, which optimizes the feature
extraction and fusion modules. To extract features from complex
high-dimensional data, the model's encoder and fuser modules were improved
using KAN Layers. Cross-attention was applied to enhance feature fusion, and
visual comparisons verified that camera features were more evenly integrated.
This addressed the issue of camera features being abnormally concentrated,
negatively impacting fusion. Compared to the benchmark, our approach shows
improvements of +9.87 mAP and +10.64 mAP in the two viewpoints of the TUMTraf
Intersection Dataset and an improvement of +1.40 mAP in the roadside end of the
TUMTraf V2X Cooperative Perception Dataset. The results indicate that
Kaninfradet3D can effectively fuse features, demonstrating the potential of
applying KANs in roadside perception tasks.

摘要：<paragraph>隨著 AI 輔助駕駛的發展，已出現許多用於自我車輛 3D 感知任務的方法，但對於路側感知的研究卻很有限。路側視角由於能提供全局視角和更廣泛的感測範圍，因此值得發展。LiDAR 可提供精確的三維空間資訊，而相機則提供語意資訊。這兩種方式在 3D 偵測中是互補的。然而，在某些研究中，新增相機資料並未提高準確度，因為資訊擷取和融合程序不夠可靠。最近，Kolmogorov-Arnold 網路 (KAN) 已被提出作為 MLP 的替代方案，更適合於高維度、複雜的資料。相機和 LiDAR 都提供高維度資訊，而採用 KAN 應可增強有價值特徵的擷取，以產生更好的融合結果。本文提出 Kaninfradet3D，它最佳化了特徵擷取和融合模組。為了從複雜的高維度資料中擷取特徵，使用 KAN 層改進了模型的編碼器和融合器模組。應用交叉注意力來增強特徵融合，而視覺比較驗證了相機特徵更均勻地整合。這解決了相機特徵異常集中的問題，對融合產生負面影響。與基準相比，我們的做法在 TUMTraf 交叉路口資料集的兩個視點中顯示出 +9.87 mAP 和 +10.64 mAP 的改進，以及在 TUMTraf V2X 合作感知資料集的路側端改進了 +1.40 mAP。結果表明，Kaninfradet3D 可以有效融合特徵，展示了將 KAN 應用於路側感知任務的潛力。</paragraph>

##### **RAG4ITOps: A Supervised Fine-Tunable and Comprehensive RAG Framework for IT Operations and Maintenance**
2410.15805v1 by Tianyang Zhang, Zhuoxuan Jiang, Shengguang Bai, Tianrui Zhang, Lin Lin, Yang Liu, Jiawei Ren

With the ever-increasing demands on Question Answering (QA) systems for IT
operations and maintenance, an efficient and supervised fine-tunable framework
is necessary to ensure the data security, private deployment and continuous
upgrading. Although Large Language Models (LLMs) have notably improved the
open-domain QA's performance, how to efficiently handle enterprise-exclusive
corpora and build domain-specific QA systems are still less-studied for
industrial applications. In this paper, we propose a general and comprehensive
framework based on Retrieval Augmented Generation (RAG) and facilitate the
whole business process of establishing QA systems for IT operations and
maintenance. In accordance with the prevailing RAG method, our proposed
framework, named with RAG4ITOps, composes of two major stages: (1) Models
Fine-tuning \& Data Vectorization, and (2) Online QA System Process. At the
Stage 1, we leverage a contrastive learning method with two negative sampling
strategies to fine-tune the embedding model, and design the instruction
templates to fine-tune the LLM with a Retrieval Augmented Fine-Tuning method.
At the Stage 2, an efficient process of QA system is built for serving. We
collect enterprise-exclusive corpora from the domain of cloud computing, and
the extensive experiments show that our method achieves superior results than
counterparts on two kinds of QA tasks. Our experiment also provide a case for
applying the RAG4ITOps to real-world enterprise-level applications.

摘要：隨著對 IT 運作和維護中問答 (QA) 系統需求的持續增加，一個高效且可監督微調的框架對於確保資料安全性、私有部署和持續升級是必要的。儘管大型語言模型 (LLM) 已顯著改善開放領域 QA 的效能，但如何有效處理企業專屬語料庫並建構特定領域的 QA 系統，對於產業應用來說仍較少被研究。在本文中，我們提出一個基於檢索擴充生成 (RAG) 的通用且全面的框架，並促進建立 QA 系統以進行 IT 運作和維護的整個業務流程。根據現行的 RAG 方法，我們提出的框架命名為 RAG4ITOps，由兩個主要階段組成：(1) 模型微調與資料向量化，以及 (2) 線上 QA 系統流程。在階段 1 中，我們利用對比學習方法和兩種負面抽樣策略來微調嵌入模型，並設計指令範本以使用檢索擴充微調方法微調 LLM。在階段 2 中，建構一個高效的 QA 系統流程以提供服務。我們從雲端運算領域收集企業專屬語料庫，廣泛的實驗顯示，我們的模型在兩種 QA 任務上都優於其他模型。我們的實驗也提供了將 RAG4ITOps 應用於實際世界企業級應用的案例。

##### **Deep Learning and Data Augmentation for Detecting Self-Admitted Technical Debt**
2410.15804v1 by Edi Sutoyo, Paris Avgeriou, Andrea Capiluppi

Self-Admitted Technical Debt (SATD) refers to circumstances where developers
use textual artifacts to explain why the existing implementation is not
optimal. Past research in detecting SATD has focused on either identifying SATD
(classifying SATD items as SATD or not) or categorizing SATD (labeling
instances as SATD that pertain to requirement, design, code, test debt, etc.).
However, the performance of these approaches remains suboptimal, particularly
for specific types of SATD, such as test and requirement debt, primarily due to
extremely imbalanced datasets. To address these challenges, we build on earlier
research by utilizing BiLSTM architecture for the binary identification of SATD
and BERT architecture for categorizing different types of SATD. Despite their
effectiveness, both architectures struggle with imbalanced data. Therefore, we
employ a large language model data augmentation strategy to mitigate this
issue. Furthermore, we introduce a two-step approach to identify and categorize
SATD across various datasets derived from different artifacts. Our
contributions include providing a balanced dataset for future SATD researchers
and demonstrating that our approach significantly improves SATD identification
and categorization performance compared to baseline methods.

摘要：自我承認技術負債 (SATD) 指的是開發人員使用文字人工製品來解釋為何現有實作並非最佳。過去在偵測 SATD 的研究，重點在於識別 SATD (將 SATD 項目分類為 SATD 或非 SATD) 或分類 SATD (將實例標記為與需求、設計、程式碼、測試負債等相關的 SATD)。然而，這些方法的效能仍然次佳，特別是對於特定類型的 SATD，例如測試和需求負債，這主要是因為資料集極度不平衡。為了應對這些挑戰，我們根據先前的研究，利用 BiLSTM 架構進行 SATD 的二元識別，並利用 BERT 架構對不同類型的 SATD 進行分類。儘管它們很有效，但這兩種架構都難以應付不平衡的資料。因此，我們採用大型語言模型資料擴充策略來減輕這個問題。此外，我們提出一個兩步驟方法來識別和分類來自不同人工製品的不同資料集中的 SATD。我們的貢獻包括為未來的 SATD 研究人員提供一個平衡的資料集，並證明與基線方法相比，我們的做法顯著改善了 SATD 識別和分類效能。

##### **Habaek: High-performance water segmentation through dataset expansion and inductive bias optimization**
2410.15794v1 by Hanseon Joo, Eunji Lee, Minjong Cheon

Water segmentation is critical to disaster response and water resource
management. Authorities may employ high-resolution photography to monitor
rivers, lakes, and reservoirs, allowing for more proactive management in
agriculture, industry, and conservation. Deep learning has improved flood
monitoring by allowing models like CNNs, U-Nets, and transformers to handle
large volumes of satellite and aerial data. However, these models usually have
significant processing requirements, limiting their usage in real-time
applications. This research proposes upgrading the SegFormer model for water
segmentation by data augmentation with datasets such as ADE20K and RIWA to
boost generalization. We examine how inductive bias affects attention-based
models and discover that SegFormer performs better on bigger datasets. To
further demonstrate the function of data augmentation, Low-Rank Adaptation
(LoRA) is used to lower processing complexity while preserving accuracy. We
show that the suggested Habaek model outperforms current models in
segmentation, with an Intersection over Union (IoU) ranging from 0.91986 to
0.94397. In terms of F1-score, recall, accuracy, and precision, Habaek performs
better than rival models, indicating its potential for real-world applications.
This study highlights the need to enhance structures and include datasets for
effective water segmentation.

摘要：水體分割對於災害應變和水資源管理至關重要。當局可以採用高解析度攝影來監控河流、湖泊和水庫，以便在農業、工業和保育方面進行更積極的管理。深度學習透過讓 CNN、U-Net 和 Transformer 等模型處理大量衛星和空中資料，改進了洪水監測。然而，這些模型通常有大量的處理需求，限制了它們在即時應用中的使用。本研究提出透過資料擴充，例如 ADE20K 和 RIWA 等資料集，升級 SegFormer 模型以進行水體分割，以提升泛化能力。我們探討歸納偏差如何影響基於注意力的模型，並發現 SegFormer 在較大的資料集上表現得更好。為了進一步展示資料擴充的功能，低秩適應 (LoRA) 用於降低處理複雜度，同時保持準確度。我們展示建議的 Habaek 模型在分割方面優於目前的模型，其交集並集 (IoU) 介於 0.91986 到 0.94397。在 F1 分數、召回率、準確度和精確度方面，Habaek 的表現優於競爭模型，顯示其在實際應用中的潛力。本研究強調了增強結構和納入資料集以進行有效水體分割的必要性。

##### **Arithmetic Transformers Can Length-Generalize in Both Operand Length and Count**
2410.15787v1 by Hanseul Cho, Jaeyoung Cha, Srinadh Bhojanapalli, Chulhee Yun

Transformers often struggle with length generalization, meaning they fail to
generalize to sequences longer than those encountered during training. While
arithmetic tasks are commonly used to study length generalization, certain
tasks are considered notoriously difficult, e.g., multi-operand addition
(requiring generalization over both the number of operands and their lengths)
and multiplication (requiring generalization over both operand lengths). In
this work, we achieve approximately 2-3x length generalization on both tasks,
which is the first such achievement in arithmetic Transformers. We design
task-specific scratchpads enabling the model to focus on a fixed number of
tokens per each next-token prediction step, and apply multi-level versions of
Position Coupling (Cho et al., 2024; McLeish et al., 2024) to let Transformers
know the right position to attend to. On the theory side, we prove that a
1-layer Transformer using our method can solve multi-operand addition, up to
operand length and operand count that are exponential in embedding dimension.

摘要：變形金剛通常難以應付長度概括，表示它們無法概括到比訓練期間遇到的更長的序列。雖然數學任務通常用於研究長度概括，但某些任務被認為非常困難，例如多運算元加法（需要對運算元數目及其長度進行概括）和乘法（需要對兩個運算元長度進行概括）。在這項工作中，我們在兩個任務上實現了大約 2-3 倍的長度概括，這是算術變形金剛中的首次此類成就。我們設計了特定於任務的暫存器，使模型能夠專注於每個下一個代幣預測步驟中的固定代幣數，並應用多級版本的 Position Coupling（Cho 等人，2024；McLeish 等人，2024）讓變形金剛知道要關注的正確位置。在理論方面，我們證明使用我們方法的 1 層變形金剛可以解決多運算元加法，直到運算元長度和運算元數量在嵌入維度中呈指數級增長。

