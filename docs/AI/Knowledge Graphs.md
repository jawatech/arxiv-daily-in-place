
### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-05**|**A Few-Shot Approach for Relation Extraction Domain Adaptation using Large Language Models**|Vanni Zavarella et.al.|[2408.02377v1](http://arxiv.org/abs/2408.02377v1)|null|
|**2024-08-05**|**Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction**|Albert Sawczyn et.al.|[2408.02337v1](http://arxiv.org/abs/2408.02337v1)|null|
|**2024-08-04**|**MedSyn: LLM-based Synthetic Medical Text Generation Framework**|Gleb Kumichev et.al.|[2408.02056v1](http://arxiv.org/abs/2408.02056v1)|null|
|**2024-08-04**|**DiReCT: Diagnostic Reasoning for Clinical Notes via Large Language Models**|Bowen Wang et.al.|[2408.01933v2](http://arxiv.org/abs/2408.01933v2)|null|
|**2024-08-03**|**Integrating Large Language Models and Knowledge Graphs for Extraction and Validation of Textual Test Data**|Antonio De Santis et.al.|[2408.01700v1](http://arxiv.org/abs/2408.01700v1)|null|
|**2024-08-02**|**DERA: Dense Entity Retrieval for Entity Alignment in Knowledge Graphs**|Zhichun Wang et.al.|[2408.01154v1](http://arxiv.org/abs/2408.01154v1)|null|
|**2024-08-02**|**Bridging Information Gaps in Dialogues With Grounded Exchanges Using Knowledge Graphs**|Phillip Schneider et.al.|[2408.01088v1](http://arxiv.org/abs/2408.01088v1)|null|
|**2024-08-02**|**Automatic Extraction of Relationships among Motivations, Emotions and Actions from Natural Language Texts**|Fei Yang et.al.|[2408.00966v1](http://arxiv.org/abs/2408.00966v1)|null|
|**2024-08-01**|**DisTrack: a new Tool for Semi-automatic Misinformation Tracking in Online Social Networks**|Guillermo Villar-Rodríguez et.al.|[2408.00633v1](http://arxiv.org/abs/2408.00633v1)|null|
|**2024-08-01**|**On the Limitations and Prospects of Machine Unlearning for Generative AI**|Shiji Zhou et.al.|[2408.00376v1](http://arxiv.org/abs/2408.00376v1)|null|
|**2024-08-01**|**Multi-Modal Parameter-Efficient Fine-tuning via Graph Neural Network**|Bin Cheng et.al.|[2408.00290v1](http://arxiv.org/abs/2408.00290v1)|null|
|**2024-07-31**|**CEAR: Automatic construction of a knowledge graph of chemical entities and roles from scientific literature**|Stefan Langer et.al.|[2407.21708v1](http://arxiv.org/abs/2407.21708v1)|null|
|**2024-07-31**|**eSPARQL: Representing and Reconciling Agnostic and Atheistic Beliefs in RDF-star Knowledge Graphs**|Xinyi Pan et.al.|[2407.21483v3](http://arxiv.org/abs/2407.21483v3)|null|
|**2024-07-31**|**Navigating Beyond Instructions: Vision-and-Language Navigation in Obstructed Environments**|Haodong Hong et.al.|[2407.21452v1](http://arxiv.org/abs/2407.21452v1)|null|
|**2024-07-31**|**Tree-of-Traversals: A Zero-Shot Reasoning Algorithm for Augmenting Black-box Language Models with Knowledge Graphs**|Elan Markowitz et.al.|[2407.21358v1](http://arxiv.org/abs/2407.21358v1)|null|
|**2024-07-31**|**SimpleLLM4AD: An End-to-End Vision-Language Model with Graph Visual Question Answering for Autonomous Driving**|Peiru Zheng et.al.|[2407.21293v1](http://arxiv.org/abs/2407.21293v1)|null|
|**2024-07-30**|**Be aware of overfitting by hyperparameter optimization!**|Igor V. Tetko et.al.|[2407.20786v1](http://arxiv.org/abs/2407.20786v1)|null|
|**2024-07-30**|**Harvesting Textual and Structured Data from the HAL Publication Repository**|Francis Kulumba et.al.|[2407.20595v1](http://arxiv.org/abs/2407.20595v1)|null|
|**2024-07-30**|**CLR-Fact: Evaluating the Complex Logical Reasoning Capability of Large Language Models over Factual Knowledge**|Tianshi Zheng et.al.|[2407.20564v1](http://arxiv.org/abs/2407.20564v1)|null|
|**2024-07-30**|**Prompt2DeModel: Declarative Neuro-Symbolic Modeling with Natural Language**|Hossein Rajaby Faghihi et.al.|[2407.20513v1](http://arxiv.org/abs/2407.20513v1)|null|
|**2024-07-29**|**What if Red Can Talk? Dynamic Dialogue Generation Using Large Language Models**|Navapat Nananukul et.al.|[2407.20382v1](http://arxiv.org/abs/2407.20382v1)|null|
|**2024-07-29**|**MindSearch: Mimicking Human Minds Elicits Deep AI Searcher**|Zehui Chen et.al.|[2407.20183v1](http://arxiv.org/abs/2407.20183v1)|[link](https://github.com/internlm/mindsearch)|
|**2024-07-29**|**rLLM: Relational Table Learning with LLMs**|Weichen Li et.al.|[2407.20157v1](http://arxiv.org/abs/2407.20157v1)|[link](https://github.com/rllm-project/rllm)|
|**2024-07-29**|**Prometheus Chatbot: Knowledge Graph Collaborative Large Language Model for Computer Components Recommendation**|Yunsheng Wang et.al.|[2407.19643v2](http://arxiv.org/abs/2407.19643v2)|[link](https://github.com/iamryanshengwang/prometheus-chatbot)|
|**2024-07-29**|**TopicTag: Automatic Annotation of NMF Topic Models Using Chain of Thought and Prompt Tuning with LLMs**|Selma Wanna et.al.|[2407.19616v1](http://arxiv.org/abs/2407.19616v1)|null|
|**2024-07-27**|**Semantic Communication Enhanced by Knowledge Graph Representation Learning**|Nour Hello et.al.|[2407.19338v1](http://arxiv.org/abs/2407.19338v1)|null|
|**2024-07-26**|**GraphBPE: Molecular Graphs Meet Byte-Pair Encoding**|Yuchen Shen et.al.|[2407.19039v1](http://arxiv.org/abs/2407.19039v1)|null|
|**2024-07-26**|**Knowledge Graph Structure as Prompt: Improving Small Language Models Capabilities for Knowledge-based Causal Discovery**|Yuni Susanti et.al.|[2407.18752v3](http://arxiv.org/abs/2407.18752v3)|[link](https://github.com/littleflow3r/kg-structure-as-prompt)|
|**2024-07-26**|**Using GPT-4 to guide causal machine learning**|Anthony C. Constantinou et.al.|[2407.18607v1](http://arxiv.org/abs/2407.18607v1)|null|
|**2024-07-26**|**Multi-turn Response Selection with Commonsense-enhanced Language Models**|Yuandong Wang et.al.|[2407.18479v1](http://arxiv.org/abs/2407.18479v1)|null|
|**2024-07-25**|**Gene Regulatory Network Inference from Pre-trained Single-Cell Transcriptomics Transformer with Joint Graph Learning**|Sindhura Kommu et.al.|[2407.18181v1](http://arxiv.org/abs/2407.18181v1)|null|
|**2024-07-24**|**MathViz-E: A Case-study in Domain-Specialized Tool-Using Agents**|Arya Bulusu et.al.|[2407.17544v1](http://arxiv.org/abs/2407.17544v1)|[link](https://github.com/emergenceai/mathviz-e)|
|**2024-07-23**|**Ranking protein-protein models with large language models and graph neural networks**|Xiaotong Xu et.al.|[2407.16375v1](http://arxiv.org/abs/2407.16375v1)|[link](https://github.com/haddocking/deeprank-gnn-esm)|
|**2024-07-23**|**PhenoFlow: A Human-LLM Driven Visual Analytics System for Exploring Large and Complex Stroke Datasets**|Jaeyoung Kim et.al.|[2407.16329v1](http://arxiv.org/abs/2407.16329v1)|null|
|**2024-07-23**|**Graph-Structured Speculative Decoding**|Zhuocheng Gong et.al.|[2407.16207v1](http://arxiv.org/abs/2407.16207v1)|null|
|**2024-07-23**|**Evaluating Long Range Dependency Handling in Code Generation Models using Multi-Step Key Retrieval**|Yannick Assogba et.al.|[2407.21049v1](http://arxiv.org/abs/2407.21049v1)|null|
|**2024-07-23**|**Finetuning Generative Large Language Models with Discrimination Instructions for Knowledge Graph Completion**|Yang Liu et.al.|[2407.16127v1](http://arxiv.org/abs/2407.16127v1)|[link](https://github.com/nju-websoft/dift)|
|**2024-07-22**|**Unsupervised Robust Cross-Lingual Entity Alignment via Joint Modeling of Entity and Relation Texts**|Soojin Yoon et.al.|[2407.15588v1](http://arxiv.org/abs/2407.15588v1)|[link](https://github.com/eralign/eralign)|
|**2024-07-22**|**Pre-Training and Prompting for Few-Shot Node Classification on Text-Attributed Graphs**|Huanjing Zhao et.al.|[2407.15431v1](http://arxiv.org/abs/2407.15431v1)|null|
|**2024-07-22**|**LLMExplainer: Large Language Model based Bayesian Inference for Graph Explanation Generation**|Jiaxing Zhang et.al.|[2407.15351v2](http://arxiv.org/abs/2407.15351v2)|null|
|**2024-07-21**|**Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation**|Yu Zhang et.al.|[2407.15141v1](http://arxiv.org/abs/2407.15141v1)|null|
|**2024-07-20**|**On the Design and Analysis of LLM-Based Algorithms**|Yanxi Chen et.al.|[2407.14788v1](http://arxiv.org/abs/2407.14788v1)|[link](https://github.com/modelscope/agentscope)|
|**2024-07-19**|**LaMAGIC: Language-Model-based Topology Generation for Analog Integrated Circuits**|Chen-Chia Chang et.al.|[2407.18269v1](http://arxiv.org/abs/2407.18269v1)|null|
|**2024-07-19**|**Hierarchical Windowed Graph Attention Network and a Large Scale Dataset for Isolated Indian Sign Language Recognition**|Suvajit Patra et.al.|[2407.14224v1](http://arxiv.org/abs/2407.14224v1)|null|
|**2024-07-19**|**Enhancing Data-Limited Graph Neural Networks by Actively Distilling Knowledge from Large Language Models**|Quan Li et.al.|[2407.13989v1](http://arxiv.org/abs/2407.13989v1)|null|
|**2024-07-18**|**A Comprehensive Review of Recommender Systems: Transitioning from Theory to Practice**|Shaina Raza et.al.|[2407.13699v1](http://arxiv.org/abs/2407.13699v1)|null|
|**2024-07-18**|**MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains**|Guoli Yin et.al.|[2407.18961v2](http://arxiv.org/abs/2407.18961v2)|[link](https://github.com/apple/axlearn)|
|**2024-07-17**|**Is Sarcasm Detection A Step-by-Step Reasoning Process in Large Language Models?**|Ben Yao et.al.|[2407.12725v1](http://arxiv.org/abs/2407.12725v1)|null|
|**2024-07-17**|**Subgraph-Aware Training of Text-based Methods for Knowledge Graph Completion**|Youmin Ko et.al.|[2407.12703v3](http://arxiv.org/abs/2407.12703v3)|null|
|**2024-07-17**|**Abstraction Alignment: Comparing Model and Human Conceptual Relationships**|Angie Boggust et.al.|[2407.12543v1](http://arxiv.org/abs/2407.12543v1)|[link](https://github.com/mitvis/abstraction-alignment)|
|**2024-07-17**|**Struct-X: Enhancing Large Language Models Reasoning with Structured Data**|Xiaoyu Tan et.al.|[2407.12522v1](http://arxiv.org/abs/2407.12522v1)|null|
|**2024-07-17**|**Explainable Biomedical Hypothesis Generation via Retrieval Augmented Generation enabled Large Language Models**|Alexander R. Pelletier et.al.|[2407.12888v1](http://arxiv.org/abs/2407.12888v1)|[link](https://github.com/pinglab-utils/rugged)|
|**2024-07-16**|**A Comprehensive Evaluation of Large Language Models on Temporal Event Forecasting**|He Chang et.al.|[2407.11638v1](http://arxiv.org/abs/2407.11638v1)|null|
|**2024-07-16**|**Learning on Graphs with Large Language Models(LLMs): A Deep Dive into Model Robustness**|Kai Guo et.al.|[2407.12068v2](http://arxiv.org/abs/2407.12068v2)|null|
|**2024-07-16**|**CIC-BART-SSA: Controllable Image Captioning with Structured Semantic Augmentation**|Kalliopi Basioti et.al.|[2407.11393v2](http://arxiv.org/abs/2407.11393v2)|[link](https://github.com/SamsungLabs/CIC-BART-SSA)|
|**2024-07-15**|**Think-on-Graph 2.0: Deep and Interpretable Large Language Model Reasoning with Knowledge Graph-guided Retrieval**|Shengjie Ma et.al.|[2407.10805v3](http://arxiv.org/abs/2407.10805v3)|null|
|**2024-07-15**|**Graphusion: Leveraging Large Language Models for Scientific Knowledge Graph Fusion and Construction in NLP Education**|Rui Yang et.al.|[2407.10794v1](http://arxiv.org/abs/2407.10794v1)|[link](https://github.com/irenezihuili/cgprompt)|
|**2024-07-15**|**GraphEval: A Knowledge-Graph Based LLM Hallucination Evaluation Framework**|Hannah Sansford et.al.|[2407.10793v1](http://arxiv.org/abs/2407.10793v1)|null|
|**2024-07-15**|**Scaling 3D Reasoning with LMMs to Large Robot Mission Environments Using Datagraphs**|W. J. Meijer et.al.|[2407.10743v1](http://arxiv.org/abs/2407.10743v1)|null|
|**2024-07-14**|**AutoGRAMS: Autonomous Graphical Agent Modeling Software**|Ben Krause et.al.|[2407.10049v1](http://arxiv.org/abs/2407.10049v1)|[link](https://github.com/autograms/autograms)|
|**2024-07-13**|**FarFetched: Entity-centric Reasoning and Claim Validation for the Greek Language based on Textually Represented Environments**|Dimitris Papadopoulos et.al.|[2407.09888v1](http://arxiv.org/abs/2407.09888v1)|[link](https://github.com/lighteternal/farfetched_nlp)|
|**2024-07-12**|**GOFA: A Generative One-For-All Model for Joint Graph Language Modeling**|Lecheng Kong et.al.|[2407.09709v1](http://arxiv.org/abs/2407.09709v1)|[link](https://github.com/jiaruifeng/gofa)|
|**2024-07-12**|**Human-like Episodic Memory for Infinite Context LLMs**|Zafeirios Fountas et.al.|[2407.09450v1](http://arxiv.org/abs/2407.09450v1)|null|
|**2024-07-12**|**The $μ\mathcal{G}$ Language for Programming Graph Neural Networks**|Matteo Belenchia et.al.|[2407.09441v1](http://arxiv.org/abs/2407.09441v1)|null|
|**2024-07-12**|**Towards More Trustworthy and Interpretable LLMs for Code through Syntax-Grounded Explanations**|David N. Palacio et.al.|[2407.08983v1](http://arxiv.org/abs/2407.08983v1)|null|
|**2024-07-12**|**Domain-Hierarchy Adaptation via Chain of Iterative Reasoning for Few-shot Hierarchical Text Classification**|Ke Ji et.al.|[2407.08959v1](http://arxiv.org/abs/2407.08959v1)|null|
|**2024-07-11**|**Cloud Atlas: Efficient Fault Localization for Cloud Systems using Language Models and Causal Insight**|Zhiqiang Xie et.al.|[2407.08694v1](http://arxiv.org/abs/2407.08694v1)|null|
|**2024-07-11**|**Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents**|Haoyi Xiong et.al.|[2407.08516v3](http://arxiv.org/abs/2407.08516v3)|null|
|**2024-07-10**|**A Comprehensive Survey on the Security of Smart Grid: Challenges, Mitigations, and Future Research Opportunities**|Arastoo Zibaeirad et.al.|[2407.07966v1](http://arxiv.org/abs/2407.07966v1)|null|
|**2024-07-10**|**Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs**|Hao-Tien Lewis Chiang et.al.|[2407.07775v2](http://arxiv.org/abs/2407.07775v2)|null|
|**2024-07-10**|**Teaching Transformers Causal Reasoning through Axiomatic Training**|Aniket Vashishtha et.al.|[2407.07612v1](http://arxiv.org/abs/2407.07612v1)|null|
|**2024-07-10**|**STAGE: Simplified Text-Attributed Graph Embeddings Using Pre-trained LLMs**|Aaron Zolnai-Lucas et.al.|[2407.12860v1](http://arxiv.org/abs/2407.12860v1)|[link](https://github.com/aaronzo/STAGE)|
|**2024-07-10**|**GLBench: A Comprehensive Benchmark for Graph with Large Language Models**|Yuhan Li et.al.|[2407.07457v2](http://arxiv.org/abs/2407.07457v2)|[link](https://github.com/nineabyss/glbench)|
|**2024-07-09**|**Decoding Climate Disagreement: A Graph Neural Network-Based Approach to Understanding Social Media Dynamics**|Ruiran Su et.al.|[2407.07038v1](http://arxiv.org/abs/2407.07038v1)|null|
|**2024-07-09**|**Graph-Based Captioning: Enhancing Visual Descriptions by Interconnecting Region Captions**|Yu-Guan Hsieh et.al.|[2407.06723v1](http://arxiv.org/abs/2407.06723v1)|null|
|**2024-07-09**|**Combining Knowledge Graphs and Large Language Models**|Amanda Kau et.al.|[2407.06564v1](http://arxiv.org/abs/2407.06564v1)|null|
|**2024-07-09**|**FuncEvalGMN: Evaluating Functional Correctness of SQL via Graph Matching Network**|Yi Zhan et.al.|[2407.14530v1](http://arxiv.org/abs/2407.14530v1)|null|
|**2024-07-08**|**MST5 -- Multilingual Question Answering over Knowledge Graphs**|Nikit Srivastava et.al.|[2407.06041v1](http://arxiv.org/abs/2407.06041v1)|[link](https://github.com/dice-group/MST5)|
|**2024-07-08**|**Enhancing Vision-Language Models with Scene Graphs for Traffic Accident Understanding**|Aaron Lohner et.al.|[2407.05910v1](http://arxiv.org/abs/2407.05910v1)|null|
|**2024-07-08**|**Affordances-Oriented Planning using Foundation Models for Continuous Vision-Language Navigation**|Jiaqi Chen et.al.|[2407.05890v1](http://arxiv.org/abs/2407.05890v1)|null|
|**2024-07-08**|**KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions**|Yanxu Zhu et.al.|[2407.05868v1](http://arxiv.org/abs/2407.05868v1)|[link](https://github.com/yanxuzhu/kg-fpq)|
|**2024-07-07**|**Language Models Encode Collaborative Signals in Recommendation**|Leheng Sheng et.al.|[2407.05441v1](http://arxiv.org/abs/2407.05441v1)|[link](https://github.com/lehengthu/alpharec)|
|**2024-07-07**|**LTLBench: Towards Benchmarks for Evaluating Temporal Logic Reasoning in Large Language Models**|Weizhi Tang et.al.|[2407.05434v1](http://arxiv.org/abs/2407.05434v1)|[link](https://github.com/rutatang/ltlbench)|
|**2024-07-05**|**Leveraging Graph Structures to Detect Hallucinations in Large Language Models**|Noa Nonkes et.al.|[2407.04485v1](http://arxiv.org/abs/2407.04485v1)|[link](https://github.com/noanonkes/Hallucination-Detection-in-LLMs)|
|**2024-07-05**|**AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents**|Petr Anokhin et.al.|[2407.04363v1](http://arxiv.org/abs/2407.04363v1)|[link](https://github.com/airi-institute/arigraph)|
|**2024-07-04**|**Semantic Graphs for Syntactic Simplification: A Revisit from the Age of LLM**|Peiran Yao et.al.|[2407.04067v1](http://arxiv.org/abs/2407.04067v1)|[link](https://github.com/U-Alberta/AMRS3)|
|**2024-07-04**|**Functional Faithfulness in the Wild: Circuit Discovery with Differentiable Computation Graph Pruning**|Lei Yu et.al.|[2407.03779v1](http://arxiv.org/abs/2407.03779v1)|null|
|**2024-07-03**|**BACON: Supercharge Your VLM with Bag-of-Concept Graph to Mitigate Hallucinations**|Zhantao Yang et.al.|[2407.03314v1](http://arxiv.org/abs/2407.03314v1)|null|
|**2024-07-03**|**Knowledge-based Consistency Testing of Large Language Models**|Sai Sathiesh Rajan et.al.|[2407.12830v1](http://arxiv.org/abs/2407.12830v1)|null|
|**2024-07-03**|**GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models**|Zike Yuan et.al.|[2407.02936v1](http://arxiv.org/abs/2407.02936v1)|[link](https://github.com/zikeyuan/gracore)|
|**2024-07-03**|**Croppable Knowledge Graph Embedding**|Yushan Zhu et.al.|[2407.02779v1](http://arxiv.org/abs/2407.02779v1)|null|
|**2024-07-02**|**Reasoning in Large Language Models: A Geometric Perspective**|Romain Cosentino et.al.|[2407.02678v1](http://arxiv.org/abs/2407.02678v1)|null|
|**2024-07-02**|**LLMs Plagiarize: Ensuring Responsible Sourcing of Large Language Model Training Data Through Knowledge Graph Comparison**|Devam Mondal et.al.|[2407.02659v2](http://arxiv.org/abs/2407.02659v2)|null|
|**2024-07-02**|**Multi-Peptide: Multimodality Leveraged Language-Graph Learning of Peptide Properties**|Srivathsan Badrinarayanan et.al.|[2407.03380v1](http://arxiv.org/abs/2407.03380v1)|[link](https://github.com/srivathsanb14/multipeptide)|
|**2024-07-02**|**Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification**|Pritish Sahu et.al.|[2407.02352v1](http://arxiv.org/abs/2407.02352v1)|null|
|**2024-07-02**|**Is Your Large Language Model Knowledgeable or a Choices-Only Cheater?**|Nishant Balepur et.al.|[2407.01992v1](http://arxiv.org/abs/2407.01992v1)|null|
|**2024-07-01**|**CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents**|Tianqi Xu et.al.|[2407.01511v1](http://arxiv.org/abs/2407.01511v1)|[link](https://github.com/camel-ai/crab)|
|**2024-07-01**|**Dynamic Few-Shot Learning for Knowledge Graph Question Answering**|Jacopo D'Abramo et.al.|[2407.01409v1](http://arxiv.org/abs/2407.01409v1)|null|
|**2024-07-01**|**Adapting Multilingual LLMs to Low-Resource Languages with Knowledge Graphs via Adapters**|Daniil Gurgurov et.al.|[2407.01406v2](http://arxiv.org/abs/2407.01406v2)|[link](https://github.com/d-gurgurov/Injecting-Commonsense-Knowledge-into-LLMs)|
|**2024-07-01**|**SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model**|Lingyue Fu et.al.|[2407.01245v2](http://arxiv.org/abs/2407.01245v2)|null|

#### Abstracts
##### **A Few-Shot Approach for Relation Extraction Domain Adaptation using Large Language Models**
2408.02377v1 by Vanni Zavarella, Juan Carlos Gamero-Salinas, Sergio Consoli

Knowledge graphs (KGs) have been successfully applied to the analysis of
complex scientific and technological domains, with automatic KG generation
methods typically building upon relation extraction models capturing
fine-grained relations between domain entities in text. While these relations
are fully applicable across scientific areas, existing models are trained on
few domain-specific datasets such as SciERC and do not perform well on new
target domains. In this paper, we experiment with leveraging in-context
learning capabilities of Large Language Models to perform schema-constrained
data annotation, collecting in-domain training instances for a
Transformer-based relation extraction model deployed on titles and abstracts of
research papers in the Architecture, Construction, Engineering and Operations
(AECO) domain. By assessing the performance gain with respect to a baseline
Deep Learning architecture trained on off-domain data, we show that by using a
few-shot learning strategy with structured prompts and only minimal expert
annotation the presented approach can potentially support domain adaptation of
a science KG generation model.

摘要：知識圖譜 (KG) 已成功應用於分析複雜的科學技術領域，自動 KG 生成方法通常建構於關係萃取模型上，捕捉文本中領域實體之間的細粒度關係。雖然這些關係完全適用於各科學領域，但現有模型是用 SciERC 等少數特定領域的資料集訓練，而且在新目標領域的表現不佳。在本論文中，我們嘗試利用大型語言模型的脈絡學習能力，執行受架構約束的資料標註，收集領域內訓練實例，用於部署在建築、營造、工程和營運 (AECO) 領域研究論文標題和摘要的基於 Transformer 的關係萃取模型。透過評估相對於在領域外資料上訓練的基準深度學習架構的效能提升，我們展示透過使用帶有結構化提示的少量學習策略，以及僅最少的專家標註，所提出的方法有可能支援科學 KG 生成模型的領域適應。

##### **Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction**
2408.02337v1 by Albert Sawczyn, Katsiaryna Viarenich, Konrad Wojtasik, Aleksandra Domogała, Marcin Oleksy, Maciej Piasecki, Tomasz Kajdanowicz

Advancements in AI and natural language processing have revolutionized
machine-human language interactions, with question answering (QA) systems
playing a pivotal role. The knowledge base question answering (KBQA) task,
utilizing structured knowledge graphs (KG), allows for handling extensive
knowledge-intensive questions. However, a significant gap exists in KBQA
datasets, especially for low-resource languages. Many existing construction
pipelines for these datasets are outdated and inefficient in human labor, and
modern assisting tools like Large Language Models (LLM) are not utilized to
reduce the workload. To address this, we have designed and implemented a
modern, semi-automated approach for creating datasets, encompassing tasks such
as KBQA, Machine Reading Comprehension (MRC), and Information Retrieval (IR),
tailored explicitly for low-resource environments. We executed this pipeline
and introduced the PUGG dataset, the first Polish KBQA dataset, and novel
datasets for MRC and IR. Additionally, we provide a comprehensive
implementation, insightful findings, detailed statistics, and evaluation of
baseline models.

摘要：人工智能和自然語言處理的進展徹底改變了機器與人類的語言互動，其中問答 (QA) 系統扮演了關鍵角色。知識庫問答 (KBQA) 任務利用結構化的知識圖譜 (KG)，可以處理大量的知識密集型問題。然而，KBQA 資料集存在著顯著的差距，特別是對於低資源語言。許多現有的這些資料集建構管道已經過時且在人力上效率低下，而像大型語言模型 (LLM) 這樣的現代輔助工具並未被用於減少工作負載。為了解決這個問題，我們設計並實作了一種現代的半自動化方法來建立資料集，涵蓋了專門針對低資源環境量身打造的任務，例如 KBQA、機器閱讀理解 (MRC) 和資訊檢索 (IR)。我們執行了這個管道並引入了 PUGG 資料集，這是第一個波蘭 KBQA 資料集，以及 MRC 和 IR 的新穎資料集。此外，我們提供了全面的實作、有見地的發現、詳細的統計資料和基準模型的評估。

##### **MedSyn: LLM-based Synthetic Medical Text Generation Framework**
2408.02056v1 by Gleb Kumichev, Pavel Blinov, Yulia Kuzkina, Vasily Goncharov, Galina Zubkova, Nikolai Zenovkin, Aleksei Goncharov, Andrey Savchenko

Generating synthetic text addresses the challenge of data availability in
privacy-sensitive domains such as healthcare. This study explores the
applicability of synthetic data in real-world medical settings. We introduce
MedSyn, a novel medical text generation framework that integrates large
language models with a Medical Knowledge Graph (MKG). We use MKG to sample
prior medical information for the prompt and generate synthetic clinical notes
with GPT-4 and fine-tuned LLaMA models. We assess the benefit of synthetic data
through application in the ICD code prediction task. Our research indicates
that synthetic data can increase the classification accuracy of vital and
challenging codes by up to 17.8% compared to settings without synthetic data.
Furthermore, to provide new data for further research in the healthcare domain,
we present the largest open-source synthetic dataset of clinical notes for the
Russian language, comprising over 41k samples covering 219 ICD-10 codes.

摘要：合成文本的生成解决了隐私敏感领域（如医疗保健）中数据可用性的挑战。本研究探讨了合成数据在实际医疗环境中的适用性。我们引入了 MedSyn，这是一个新颖的医学文本生成框架，它将大型语言模型与医学知识图谱 (MKG) 相结合。我们使用 MKG 为提示采样先验医学信息，并使用 GPT-4 和微调的 LLaMA 模型生成合成临床注释。我们通过在 ICD 代码预测任务中的应用评估了合成数据的优势。我们的研究表明，与没有合成数据的设置相比，合成数据可以将重要且具有挑战性的代码的分类准确性提高多达 17.8%。此外，为了为医疗保健领域的进一步研究提供新数据，我们展示了最大的开放源代码合成数据集，其中包含超过 41k 个涵盖 219 个 ICD-10 代码的临床注释。

##### **DiReCT: Diagnostic Reasoning for Clinical Notes via Large Language Models**
2408.01933v2 by Bowen Wang, Jiuyang Chang, Yiming Qian, Guoxin Chen, Junhao Chen, Zhouqiang Jiang, Jiahao Zhang, Yuta Nakashima, Hajime Nagahara

Large language models (LLMs) have recently showcased remarkable capabilities,
spanning a wide range of tasks and applications, including those in the medical
domain. Models like GPT-4 excel in medical question answering but may face
challenges in the lack of interpretability when handling complex tasks in real
clinical settings. We thus introduce the diagnostic reasoning dataset for
clinical notes (DiReCT), aiming at evaluating the reasoning ability and
interpretability of LLMs compared to human doctors. It contains 511 clinical
notes, each meticulously annotated by physicians, detailing the diagnostic
reasoning process from observations in a clinical note to the final diagnosis.
Additionally, a diagnostic knowledge graph is provided to offer essential
knowledge for reasoning, which may not be covered in the training data of
existing LLMs. Evaluations of leading LLMs on DiReCT bring out a significant
gap between their reasoning ability and that of human doctors, highlighting the
critical need for models that can reason effectively in real-world clinical
scenarios.

摘要：大型語言模型 (LLM) 最近展示了非凡的能力，涵蓋廣泛的任務和應用，包括醫療領域的任務和應用。GPT-4 等模型在醫療問題解答方面表現出色，但在處理實際臨床場景中的複雜任務時，可能會面臨缺乏可解釋性的挑戰。因此，我們引入了臨床筆記診斷推理數據集 (DiReCT)，旨在評估 LLM 與人類醫生相比的推理能力和可解釋性。它包含 511 個臨床筆記，每個筆記都經過醫生仔細註解，詳細說明了從臨床筆記中的觀察結果到最終診斷的診斷推理過程。此外，還提供了診斷知識圖譜，以提供推理所需的基本知識，這可能未涵蓋在現有 LLM 的訓練數據中。在 DiReCT 上對領先的 LLM 進行評估，發現它們的推理能力與人類醫生的推理能力之間存在顯著差距，這突顯了在現實世界的臨床場景中能夠有效推理的模型的關鍵需求。

##### **Integrating Large Language Models and Knowledge Graphs for Extraction and Validation of Textual Test Data**
2408.01700v1 by Antonio De Santis, Marco Balduini, Federico De Santis, Andrea Proia, Arsenio Leo, Marco Brambilla, Emanuele Della Valle

Aerospace manufacturing companies, such as Thales Alenia Space, design,
develop, integrate, verify, and validate products characterized by high
complexity and low volume. They carefully document all phases for each product
but analyses across products are challenging due to the heterogeneity and
unstructured nature of the data in documents. In this paper, we propose a
hybrid methodology that leverages Knowledge Graphs (KGs) in conjunction with
Large Language Models (LLMs) to extract and validate data contained in these
documents. We consider a case study focused on test data related to electronic
boards for satellites. To do so, we extend the Semantic Sensor Network
ontology. We store the metadata of the reports in a KG, while the actual test
results are stored in parquet accessible via a Virtual Knowledge Graph. The
validation process is managed using an LLM-based approach. We also conduct a
benchmarking study to evaluate the performance of state-of-the-art LLMs in
executing this task. Finally, we analyze the costs and benefits of automating
preexisting processes of manual data extraction and validation for subsequent
cross-report analyses.

摘要：航太製造公司，例如泰雷茲阿萊尼亞太空公司，設計、開發、整合、驗證和驗證以高複雜度和低體積為特徵的產品。他們仔細記錄每個產品的所有階段，但由於文件中資料的異質性和非結構化性質，導致跨產品的分析具有挑戰性。在本文中，我們提出了一種混合方法，利用知識圖譜 (KG) 結合大型語言模型 (LLM)，來擷取和驗證這些文件中包含的資料。我們考慮了一個案例研究，重點在於衛星電子電路板的測試資料。為此，我們擴充了語義感測器網路本体。我們將報告的元資料儲存在 KG 中，而實際測試結果儲存在可透過虛擬知識圖譜存取的 Parquet 中。驗證過程使用基於 LLM 的方法管理。我們還進行基準研究，以評估最先進的 LLM 在執行此任務時的效能。最後，我們分析了自動化現有手動資料擷取和驗證程序的成本和好處，以進行後續的跨報告分析。

##### **DERA: Dense Entity Retrieval for Entity Alignment in Knowledge Graphs**
2408.01154v1 by Zhichun Wang, Xuan Chen

Entity Alignment (EA) aims to match equivalent entities in different
Knowledge Graphs (KGs), which is essential for knowledge fusion and
integration. Recently, embedding-based EA has attracted significant attention
and many approaches have been proposed. Early approaches primarily focus on
learning entity embeddings from the structural features of KGs, defined by
relation triples. Later methods incorporated entities' names and attributes as
auxiliary information to enhance embeddings for EA. However, these approaches
often used different techniques to encode structural and attribute information,
limiting their interaction and mutual enhancement. In this work, we propose a
dense entity retrieval framework for EA, leveraging language models to
uniformly encode various features of entities and facilitate nearest entity
search across KGs. Alignment candidates are first generated through entity
retrieval, which are subsequently reranked to determine the final alignments.
We conduct comprehensive experiments on both cross-lingual and monolingual EA
datasets, demonstrating that our approach achieves state-of-the-art performance
compared to existing EA methods.

摘要：實體對齊 (EA) 旨在比對不同知識圖譜 (KG) 中的等效實體，這對於知識融合和整合非常重要。最近，基於嵌入的 EA 已引起相當大的關注，並且已提出許多方法。早期的方法主要專注於從 KG 的結構特徵中學習實體嵌入，這些特徵由關係三元組定義。後續的方法將實體的名稱和屬性作為輔助資訊，以增強 EA 的嵌入。然而，這些方法通常使用不同的技術來編碼結構和屬性資訊，限制了它們的互動和相互增強。在這項工作中，我們提出了一個密集實體擷取架構，用於 EA，利用語言模型來統一編碼實體的各種特徵，並促進跨 KG 的最近實體搜尋。對齊候選者首先透過實體擷取產生，然後重新排序以確定最終對齊。我們對跨語言和單語言 EA 資料集進行了全面的實驗，證明與現有的 EA 方法相比，我們的做法達到了最先進的效能。

##### **Bridging Information Gaps in Dialogues With Grounded Exchanges Using Knowledge Graphs**
2408.01088v1 by Phillip Schneider, Nektarios Machner, Kristiina Jokinen, Florian Matthes

Knowledge models are fundamental to dialogue systems for enabling
conversational interactions, which require handling domain-specific knowledge.
Ensuring effective communication in information-providing conversations entails
aligning user understanding with the knowledge available to the system.
However, dialogue systems often face challenges arising from semantic
inconsistencies in how information is expressed in natural language compared to
how it is represented within the system's internal knowledge. To address this
problem, we study the potential of large language models for conversational
grounding, a mechanism to bridge information gaps by establishing shared
knowledge between dialogue participants. Our approach involves annotating human
conversations across five knowledge domains to create a new dialogue corpus
called BridgeKG. Through a series of experiments on this dataset, we
empirically evaluate the capabilities of large language models in classifying
grounding acts and identifying grounded information items within a knowledge
graph structure. Our findings offer insights into how these models use
in-context learning for conversational grounding tasks and common prediction
errors, which we illustrate with examples from challenging dialogues. We
discuss how the models handle knowledge graphs as a semantic layer between
unstructured dialogue utterances and structured information items.

摘要：知識模型是對話系統的基本要素，用於啟用對話互動，這需要處理特定領域的知識。確保在提供資訊的對話中進行有效的溝通，需要將使用者的理解與系統可用的知識結合起來。然而，對話系統經常面臨語意不一致的挑戰，在自然語言中表達資訊的方式與在系統內部知識中表示資訊的方式不同。為了解決這個問題，我們研究大型語言模型在對話基礎中的潛力，這是一種透過在對話參與者之間建立共享知識來彌合資訊差距的機制。我們的做法包括註解五個知識領域中的人類對話，以建立一個新的對話語料庫，稱為 BridgeKG。透過對此資料集進行一系列實驗，我們實證評估大型語言模型在分類基礎行為和識別知識圖結構中的基礎資訊項目的能力。我們的發現提供了關於這些模型如何使用情境學習來進行對話基礎任務和常見預測錯誤的見解，我們用具有挑戰性的對話範例來說明。我們討論模型如何將知識圖形視為非結構化對話語句和結構化資訊項目之間的語意層。

##### **Automatic Extraction of Relationships among Motivations, Emotions and Actions from Natural Language Texts**
2408.00966v1 by Fei Yang

We propose a new graph-based framework to reveal relationships among
motivations, emotions and actions explicitly given natural language texts. A
directed acyclic graph is designed to describe human's nature. Nurture beliefs
are incorporated to connect outside events and the human's nature graph. No
annotation resources are required due to the power of large language models.
Amazon Fine Foods Reviews dataset is used as corpus and food-related
motivations are focused. Totally 92,990 relationship graphs are generated, of
which 63% make logical sense. We make further analysis to investigate error
types for optimization direction in future research.

摘要：我們提出一個新的基於圖形的架構，用於揭示在自然語言文本中明確給出的動機、情緒和動作之間的關係。有向無環圖被設計用於描述人類的本性。培養信念被納入其中，用於連接外部事件和人類的本性圖。由於大型語言模型的強大功能，不需要註解資源。亞馬遜美食評論數據集被用作語料庫，並且重點關注與食物相關的動機。總共生成了 92,990 個關係圖，其中 63% 具有邏輯意義。我們進一步分析以調查錯誤類型，以便為未來的研究提供優化方向。

##### **DisTrack: a new Tool for Semi-automatic Misinformation Tracking in Online Social Networks**
2408.00633v1 by Guillermo Villar-Rodríguez, Álvaro Huertas-García, Alejandro Martín, Javier Huertas-Tato, David Camacho

Introduction: This article introduces DisTrack, a methodology and a tool
developed for tracking and analyzing misinformation within Online Social
Networks (OSNs). DisTrack is designed to combat the spread of misinformation
through a combination of Natural Language Processing (NLP) Social Network
Analysis (SNA) and graph visualization. The primary goal is to detect
misinformation, track its propagation, identify its sources, and assess the
influence of various actors within the network.
  Methods: DisTrack's architecture incorporates a variety of methodologies
including keyword search, semantic similarity assessments, and graph generation
techniques. These methods collectively facilitate the monitoring of
misinformation, the categorization of content based on alignment with known
false claims, and the visualization of dissemination cascades through detailed
graphs. The tool is tailored to capture and analyze the dynamic nature of
misinformation spread in digital environments.
  Results: The effectiveness of DisTrack is demonstrated through three case
studies focused on different themes: discredit/hate speech, anti-vaccine
misinformation, and false narratives about the Russia-Ukraine conflict. These
studies show DisTrack's capabilities in distinguishing posts that propagate
falsehoods from those that counteract them, and tracing the evolution of
misinformation from its inception.
  Conclusions: The research confirms that DisTrack is a valuable tool in the
field of misinformation analysis. It effectively distinguishes between
different types of misinformation and traces their development over time. By
providing a comprehensive approach to understanding and combating
misinformation in digital spaces, DisTrack proves to be an essential asset for
researchers and practitioners working to mitigate the impact of false
information in online social environments.

摘要：<paragraph>引言：本文介紹 DisTrack，這是一種方法和工具，用於追蹤和分析線上社交網路（OSN）中的錯誤資訊。DisTrack 的設計目的是透過結合自然語言處理（NLP）、社交網路分析（SNA）和圖形視覺化來對抗錯誤資訊的散布。主要目標是偵測錯誤資訊、追蹤其傳播、找出其來源，並評估網路中各個參與者的影響力。
方法：DisTrack 的架構結合了多種方法，包括關鍵字搜尋、語意相似性評估和圖形產生技術。這些方法共同促進了錯誤資訊的監控、基於與已知虛假說法的比對來分類內容，以及透過詳細圖形視覺化傳播層疊。此工具經過量身打造，用於擷取和分析數位環境中錯誤資訊散布的動態特性。
結果：DisTrack 的效能透過三個案例研究獲得驗證，這些研究專注於不同的主題：貶低/仇恨言論、反疫苗錯誤資訊，以及關於俄羅斯-烏克蘭衝突的虛假敘述。這些研究顯示出 DisTrack 在區分傳播虛假資訊和反制虛假資訊的貼文，以及追蹤錯誤資訊從其開端演變的過程中所具備的能力。
結論：研究證實 DisTrack 是錯誤資訊分析領域中一個有價值的工具。它有效區分了不同類型的錯誤資訊，並追蹤其隨著時間推移的發展。透過提供一種全面的方法來理解和對抗數位空間中的錯誤資訊，DisTrack 證明了自己是協助研究人員和實務工作者減輕線上社交環境中虛假資訊影響力的重要資產。</paragraph>

##### **On the Limitations and Prospects of Machine Unlearning for Generative AI**
2408.00376v1 by Shiji Zhou, Lianzhe Wang, Jiangnan Ye, Yongliang Wu, Heng Chang

Generative AI (GenAI), which aims to synthesize realistic and diverse data
samples from latent variables or other data modalities, has achieved remarkable
results in various domains, such as natural language, images, audio, and
graphs. However, they also pose challenges and risks to data privacy, security,
and ethics. Machine unlearning is the process of removing or weakening the
influence of specific data samples or features from a trained model, without
affecting its performance on other data or tasks. While machine unlearning has
shown significant efficacy in traditional machine learning tasks, it is still
unclear if it could help GenAI become safer and aligned with human desire. To
this end, this position paper provides an in-depth discussion of the machine
unlearning approaches for GenAI. Firstly, we formulate the problem of machine
unlearning tasks on GenAI and introduce the background. Subsequently, we
systematically examine the limitations of machine unlearning on GenAI models by
focusing on the two representative branches: LLMs and image generative
(diffusion) models. Finally, we provide our prospects mainly from three
aspects: benchmark, evaluation metrics, and utility-unlearning trade-off, and
conscientiously advocate for the future development of this field.

摘要：生成式 AI (GenAI) 旨在從潛在變數或其他資料模式中合成逼真且多樣化的資料範例，已在自然語言、影像、音訊和圖形等各種領域中取得顯著成果。然而，它們也對資料隱私、安全性與道德構成挑戰和風險。機器遺忘是移除或減弱特定資料範例或特徵對已訓練模型的影響，同時不影響其在其他資料或任務上的效能。雖然機器遺忘已在傳統機器學習任務中展現顯著的功效，但仍不清楚它是否能協助 GenAI 變得更安全且符合人類的期望。為此，本立場文件深入探討了 GenAI 的機器遺忘方法。首先，我們制定 GenAI 上機器遺忘任務的問題，並介紹背景。接著，我們有系統地檢視機器遺忘在 GenAI 模型上的限制，重點放在兩個代表性的分支：LLM 和影像生成（擴散）模型。最後，我們主要從基準、評估指標和效用遺忘權衡三個面向提供我們的展望，並審慎倡議該領域的未來發展。

##### **Multi-Modal Parameter-Efficient Fine-tuning via Graph Neural Network**
2408.00290v1 by Bin Cheng, Jiaxuan Lu

With the advent of the era of foundation models, pre-training and fine-tuning
have become common paradigms. Recently, parameter-efficient fine-tuning has
garnered widespread attention due to its better balance between the number of
learnable parameters and performance. However, some current parameter-efficient
fine-tuning methods only model a single modality and lack the utilization of
structural knowledge in downstream tasks. To address this issue, this paper
proposes a multi-modal parameter-efficient fine-tuning method based on graph
networks. Each image is fed into a multi-modal large language model (MLLM) to
generate a text description. The image and its corresponding text description
are then processed by a frozen image encoder and text encoder to generate image
features and text features, respectively. A graph is constructed based on the
similarity of the multi-modal feature nodes, and knowledge and relationships
relevant to these features are extracted from each node. Additionally, Elastic
Weight Consolidation (EWC) regularization is incorporated into the loss
function to mitigate the problem of forgetting during task learning. The
proposed model achieves test accuracies on the OxfordPets, Flowers102, and
Food101 datasets that improve by 4.45%, 2.92%, and 0.23%, respectively. The
code is available at https://github.com/yunche0/GA-Net/tree/master.

摘要：隨著基礎模型時代的到來，預訓練和微調已成為常見的範例。最近，由於參數有效微調在可學習參數數量和效能之間取得更好的平衡，因此備受關注。然而，一些目前的參數有效微調方法僅建模單一模態，且缺乏在下游任務中利用結構知識。為了解決此問題，本文提出了一種基於圖形網路的多模態參數有效微調方法。每個影像都會輸入到多模態大型語言模型 (MLLM) 中，以產生文字描述。然後，影像及其對應的文字描述會由凍結的影像編碼器和文字編碼器處理，分別產生影像特徵和文字特徵。根據多模態特徵節點的相似性建構一個圖形，並從每個節點中萃取出與這些特徵相關的知識和關係。此外，彈性權重整合 (EWC) 正則化會納入損失函數中，以減輕在任務學習期間遺忘的問題。所提出的模型在 OxfordPets、Flowers102 和 Food101 資料集上達成的測試準確度分別提升了 4.45%、2.92% 和 0.23%。程式碼可在 https://github.com/yunche0/GA-Net/tree/master 取得。

##### **CEAR: Automatic construction of a knowledge graph of chemical entities and roles from scientific literature**
2407.21708v1 by Stefan Langer, Fabian Neuhaus, Andreas Nürnberger

Ontologies are formal representations of knowledge in specific domains that
provide a structured framework for organizing and understanding complex
information. Creating ontologies, however, is a complex and time-consuming
endeavor. ChEBI is a well-known ontology in the field of chemistry, which
provides a comprehensive resource for defining chemical entities and their
properties. However, it covers only a small fraction of the rapidly growing
knowledge in chemistry and does not provide references to the scientific
literature. To address this, we propose a methodology that involves augmenting
existing annotated text corpora with knowledge from Chebi and fine-tuning a
large language model (LLM) to recognize chemical entities and their roles in
scientific text. Our experiments demonstrate the effectiveness of our approach.
By combining ontological knowledge and the language understanding capabilities
of LLMs, we achieve high precision and recall rates in identifying both the
chemical entities and roles in scientific literature. Furthermore, we extract
them from a set of 8,000 ChemRxiv articles, and apply a second LLM to create a
knowledge graph (KG) of chemical entities and roles (CEAR), which provides
complementary information to ChEBI, and can help to extend it.

摘要：本体是特定領域中知識的形式化表示，它提供了一個結構化的框架，用於組織和理解複雜的資訊。然而，建立本体是一項複雜且耗時的努力。ChEBI 是化學領域中一個著名的本体，它提供了一個全面的資源，用於定義化學實體及其屬性。然而，它僅涵蓋了化學領域快速增長的知識中的一小部分，並且沒有提供科學文獻的參考。為了解決這個問題，我們提出了一種方法，它涉及使用來自 Chebi 的知識擴充現有的註釋文本語料庫，並微調大型語言模型 (LLM)，以識別化學實體及其在科學文本中的作用。我們的實驗證明了我們方法的有效性。透過結合本体知識和 LLM 的語言理解能力，我們在識別科學文獻中的化學實體和作用方面達到了很高的準確度和召回率。此外，我們從一組 8,000 篇 ChemRxiv 文章中提取它們，並應用第二個 LLM 來建立一個化學實體和作用 (CEAR) 的知識圖譜 (KG)，它提供補充 ChEBI 的資訊，並有助於擴充它。

##### **eSPARQL: Representing and Reconciling Agnostic and Atheistic Beliefs in RDF-star Knowledge Graphs**
2407.21483v3 by Xinyi Pan, Daniel Hernández, Philipp Seifer, Ralf Lämmel, Steffen Staab

Over the past few years, we have seen the emergence of large knowledge graphs
combining information from multiple sources. Sometimes, this information is
provided in the form of assertions about other assertions, defining contexts
where assertions are valid. A recent extension to RDF which admits statements
over statements, called RDF-star, is in revision to become a W3C standard.
However, there is no proposal for a semantics of these RDF-star statements nor
a built-in facility to operate over them. In this paper, we propose a query
language for epistemic RDF-star metadata based on a four-valued logic, called
eSPARQL. Our proposed query language extends SPARQL-star, the query language
for RDF-star, with a new type of FROM clause to facilitate operating with
multiple and sometimes conflicting beliefs. We show that the proposed query
language can express four use case queries, including the following features:
(i) querying the belief of an individual, (ii) the aggregating of beliefs,
(iii) querying who is conflicting with somebody, and (iv) beliefs about beliefs
(i.e., nesting of beliefs).

摘要：在過去幾年，我們見證了大型知識圖譜的出現，結合來自多個來源的資訊。有時，這些資訊會以對其他斷言的斷言形式提供，定義斷言有效的脈絡。最近對 RDF 的擴充，允許對陳述進行陳述，稱為 RDF-star，正在修訂為 W3C 標準。然而，目前沒有針對這些 RDF-star 陳述的語意建議，也沒有內建的運作功能。在本文中，我們提出了一種基於四值邏輯的知識 RDF-star 元資料查詢語言，稱為 eSPARQL。我們提出的查詢語言擴充了 RDF-star 的查詢語言 SPARQL-star，新增一種 FROM 子句類型，以利於使用多重且有時相互衝突的信念進行運作。我們展示了所提出的查詢語言可以表達四種使用案例查詢，包括以下功能：(i) 查詢個人的信念，(ii) 彙總信念，(iii) 查詢與某人衝突的是誰，以及 (iv) 關於信念的信念（即信念的巢狀）。

##### **Navigating Beyond Instructions: Vision-and-Language Navigation in Obstructed Environments**
2407.21452v1 by Haodong Hong, Sen Wang, Zi Huang, Qi Wu, Jiajun Liu

Real-world navigation often involves dealing with unexpected obstructions
such as closed doors, moved objects, and unpredictable entities. However,
mainstream Vision-and-Language Navigation (VLN) tasks typically assume
instructions perfectly align with the fixed and predefined navigation graphs
without any obstructions. This assumption overlooks potential discrepancies in
actual navigation graphs and given instructions, which can cause major failures
for both indoor and outdoor agents. To address this issue, we integrate diverse
obstructions into the R2R dataset by modifying both the navigation graphs and
visual observations, introducing an innovative dataset and task, R2R with
UNexpected Obstructions (R2R-UNO). R2R-UNO contains various types and numbers
of path obstructions to generate instruction-reality mismatches for VLN
research. Experiments on R2R-UNO reveal that state-of-the-art VLN methods
inevitably encounter significant challenges when facing such mismatches,
indicating that they rigidly follow instructions rather than navigate
adaptively. Therefore, we propose a novel method called ObVLN (Obstructed VLN),
which includes a curriculum training strategy and virtual graph construction to
help agents effectively adapt to obstructed environments. Empirical results
show that ObVLN not only maintains robust performance in unobstructed scenarios
but also achieves a substantial performance advantage with unexpected
obstructions.

摘要：现实世界的导航通常涉及处理意外的障碍，例如关着的门、移动的物体和不可预测的实体。然而，主流的视觉和语言导航 (VLN) 任务通常假设指令与固定的和预定义的导航图完全一致，没有任何障碍。这种假设忽略了实际导航图和给定指令中潜在的差异，这可能会导致室内和室外代理出现重大故障。为了解决这个问题，我们通过修改导航图和视觉观察，将各种障碍整合到 R2R 数据集中，引入了创新数据集和任务，即带有意外障碍的 R2R (R2R-UNO)。R2R-UNO 包含各种类型和数量的路径障碍，以生成 VLN 研究的指令-现实不匹配。在 R2R-UNO 上的实验表明，最先进的 VLN 方法在面对此类不匹配时不可避免地会遇到重大挑战，这表明它们严格遵循指令，而不是自适应地导航。因此，我们提出了一种称为 ObVLN（受阻 VLN）的新方法，其中包括课程训练策略和虚拟图构建，以帮助代理有效地适应受阻环境。经验结果表明，ObVLN 不仅在无障碍场景中保持了稳健的性能，而且在意外障碍中也获得了实质性的性能优势。

##### **Tree-of-Traversals: A Zero-Shot Reasoning Algorithm for Augmenting Black-box Language Models with Knowledge Graphs**
2407.21358v1 by Elan Markowitz, Anil Ramakrishna, Jwala Dhamala, Ninareh Mehrabi, Charith Peris, Rahul Gupta, Kai-Wei Chang, Aram Galstyan

Knowledge graphs (KGs) complement Large Language Models (LLMs) by providing
reliable, structured, domain-specific, and up-to-date external knowledge.
However, KGs and LLMs are often developed separately and must be integrated
after training. We introduce Tree-of-Traversals, a novel zero-shot reasoning
algorithm that enables augmentation of black-box LLMs with one or more KGs. The
algorithm equips a LLM with actions for interfacing a KG and enables the LLM to
perform tree search over possible thoughts and actions to find high confidence
reasoning paths. We evaluate on two popular benchmark datasets. Our results
show that Tree-of-Traversals significantly improves performance on question
answering and KG question answering tasks. Code is available at
\url{https://github.com/amazon-science/tree-of-traversals}

摘要：知識圖譜 (KG) 透過提供可靠、結構化、特定於領域且最新的外部知識，來補充大型語言模型 (LLM)。
然而，KG 和 LLM 通常是分開開發，並且必須在訓練後整合。我們介紹了 Tree-of-Traversals，一種新穎的零次推理演算法，它能讓黑盒 LLM 使用一個或多個 KG。該演算法為 LLM 提供與 KG 介面的動作，並讓 LLM 能在可能的思考和動作上執行樹狀搜尋，以找出高度信心的推理路徑。我們在兩個熱門的基準資料集上進行評估。我們的結果顯示，Tree-of-Traversals 大幅提升了問題解答和 KG 問題解答任務的效能。程式碼可在 \url{https://github.com/amazon-science/tree-of-traversals} 取得

##### **SimpleLLM4AD: An End-to-End Vision-Language Model with Graph Visual Question Answering for Autonomous Driving**
2407.21293v1 by Peiru Zheng, Yun Zhao, Zhan Gong, Hong Zhu, Shaohua Wu

Many fields could benefit from the rapid development of the large language
models (LLMs). The end-to-end autonomous driving (e2eAD) is one of the
typically fields facing new opportunities as the LLMs have supported more and
more modalities. Here, by utilizing vision-language model (VLM), we proposed an
e2eAD method called SimpleLLM4AD. In our method, the e2eAD task are divided
into four stages, which are perception, prediction, planning, and behavior.
Each stage consists of several visual question answering (VQA) pairs and VQA
pairs interconnect with each other constructing a graph called Graph VQA
(GVQA). By reasoning each VQA pair in the GVQA through VLM stage by stage, our
method could achieve e2e driving with language. In our method, vision
transformers (ViT) models are employed to process nuScenes visual data, while
VLM are utilized to interpret and reason about the information extracted from
the visual inputs. In the perception stage, the system identifies and
classifies objects from the driving environment. The prediction stage involves
forecasting the potential movements of these objects. The planning stage
utilizes the gathered information to develop a driving strategy, ensuring the
safety and efficiency of the autonomous vehicle. Finally, the behavior stage
translates the planned actions into executable commands for the vehicle. Our
experiments demonstrate that SimpleLLM4AD achieves competitive performance in
complex driving scenarios.

摘要：大型語言模型 (LLM) 的快速發展可能使許多領域受益。端到端自動駕駛 (e2eAD) 是典型領域之一，因為 LLM 支援越來越多的模式，因此面臨新的機會。在此，透過利用視覺語言模型 (VLM)，我們提出了一個稱為 SimpleLLM4AD 的 e2eAD 方法。在我們的模型中，e2eAD 任務分為四個階段，分別是感知、預測、規劃和行為。每個階段包含多個視覺問答 (VQA) 配對，且 VQA 配對相互連接，構建一個稱為圖形 VQA (GVQA) 的圖形。透過 VLM 分階段推理 GVQA 中的每個 VQA 配對，我們的模型可以透過語言實現端到端駕駛。在我們的模型中，採用視覺Transformer (ViT) 模型來處理 nuScenes 視覺資料，同時利用 VLM 來詮釋和推理從視覺輸入中提取的資訊。在感知階段，系統識別和分類駕駛環境中的物件。預測階段涉及預測這些物件的潛在移動。規劃階段利用收集的資訊來制定駕駛策略，確保自動駕駛汽車的安全性和效率。最後，行為階段將規劃的動作轉換為車輛可執行的命令。我們的實驗證明，SimpleLLM4AD 在複雜的駕駛場景中實現了競爭力。

##### **Be aware of overfitting by hyperparameter optimization!**
2407.20786v1 by Igor V. Tetko, Ruud van Deursen, Guillaume Godin

Hyperparameter optimization is very frequently employed in machine learning.
However, an optimization of a large space of parameters could result in
overfitting of models. In recent studies on solubility prediction the authors
collected seven thermodynamic and kinetic solubility datasets from different
data sources. They used state-of-the-art graph-based methods and compared
models developed for each dataset using different data cleaning protocols and
hyperparameter optimization. In our study we showed that hyperparameter
optimization did not always result in better models, possibly due to
overfitting when using the same statistical measures. Similar results could be
calculated using pre-set hyperparameters, reducing the computational effort by
around 10,000 times. We also extended the previous analysis by adding a
representation learning method based on Natural Language Processing of smiles
called Transformer CNN. We show that across all analyzed sets using exactly the
same protocol, Transformer CNN provided better results than graph-based methods
for 26 out of 28 pairwise comparisons by using only a tiny fraction of time as
compared to other methods. Last but not least we stressed the importance of
comparing calculation results using exactly the same statistical measures.

摘要：機器學習中非常頻繁地使用超參數最佳化。
然而，對大參數空間進行最佳化可能會導致模型過擬合。在最近對溶解度預測的研究中，作者從不同的數據源收集了七個熱力學和動力學溶解度數據集。他們使用了最先進的基於圖形的方法，並比較了使用不同的數據清洗協議和超參數最佳化為每個數據集開發的模型。在我們的研究中，我們表明超參數最佳化並非總是會產生更好的模型，這可能是由於在使用相同的統計測量時發生過擬合。可以使用預設的超參數計算類似的結果，從而將計算工作量減少約 10,000 倍。我們還通過添加基於笑容的自然語言處理的表示學習方法（稱為 Transformer CNN）來擴展先前的分析。我們表明，在使用完全相同的協議對所有分析的集合進行分析時，Transformer CNN 在 28 個成對比較中有 26 個比較比基於圖形的方法提供了更好的結果，而與其他方法相比，所用的時間只是很小的一部分。最後但並非最不重要的是，我們強調了使用完全相同的統計測量來比較計算結果的重要性。

##### **Harvesting Textual and Structured Data from the HAL Publication Repository**
2407.20595v1 by Francis Kulumba, Wissam Antoun, Guillaume Vimont, Laurent Romary

HAL (Hyper Articles en Ligne) is the French national publication repository,
used by most higher education and research organizations for their open science
policy. As a digital library, it is a rich repository of scholarly documents,
but its potential for advanced research has been underutilized. We present
HALvest, a unique dataset that bridges the gap between citation networks and
the full text of papers submitted on HAL. We craft our dataset by filtering HAL
for scholarly publications, resulting in approximately 700,000 documents,
spanning 34 languages across 13 identified domains, suitable for language model
training, and yielding approximately 16.5 billion tokens (with 8 billion in
French and 7 billion in English, the most represented languages). We transform
the metadata of each paper into a citation network, producing a directed
heterogeneous graph. This graph includes uniquely identified authors on HAL, as
well as all open submitted papers, and their citations. We provide a baseline
for authorship attribution using the dataset, implement a range of
state-of-the-art models in graph representation learning for link prediction,
and discuss the usefulness of our generated knowledge graph structure.

摘要：HAL（線上超連結文章）是法國國家出版物資料庫，
大多數高等教育和研究組織都使用它來制定開放科學
政策。作為一個數位圖書館，它是一個豐富的學術文件資料庫，
但它在進階研究的潛力尚未被充分利用。我們提出
HALvest，一個獨特的資料集，它彌補了引文網路和
在 HAL 上提交的論文全文之間的差距。我們透過篩選 HAL
中的學術出版品來建立我們的資料集，最後得到約 70 萬份文件，
涵蓋 13 個已識別領域的 34 種語言，適合語言模型
訓練，並產生約 165 億個詞彙（其中法文有 80 億個，
英文有 70 億個，是最具代表性的語言）。我們將
每篇論文的元資料轉換成引文網路，產生一個有向
異質圖形。此圖形包含在 HAL 上唯一識別的作者，以及
所有公開提交的論文及其引文。我們提供一個基準
使用資料集進行作者歸屬，實作一系列
最先進的圖形表示學習模型進行連結預測，
並討論我們產生的知識圖形結構的實用性。

##### **CLR-Fact: Evaluating the Complex Logical Reasoning Capability of Large Language Models over Factual Knowledge**
2407.20564v1 by Tianshi Zheng, Jiaxin Bai, Yicheng Wang, Tianqing Fang, Yue Guo, Yauwai Yim, Yangqiu Song

While large language models (LLMs) have demonstrated impressive capabilities
across various natural language processing tasks by acquiring rich factual
knowledge from their broad training data, their ability to synthesize and
logically reason with this knowledge in complex ways remains underexplored. In
this work, we present a systematic evaluation of state-of-the-art LLMs' complex
logical reasoning abilities through a novel benchmark of automatically
generated complex reasoning questions over general domain and biomedical
knowledge graphs. Our extensive experiments, employing diverse in-context
learning techniques, reveal that LLMs excel at reasoning over general world
knowledge but face significant challenges with specialized domain-specific
knowledge. We find that prompting with explicit Chain-of-Thought demonstrations
can substantially improve LLM performance on complex logical reasoning tasks
with diverse logical operations. Interestingly, our controlled evaluations
uncover an asymmetry where LLMs display proficiency at set union operations,
but struggle considerably with set intersections - a key building block of
logical reasoning. To foster further work, we will publicly release our
evaluation benchmark and code.

摘要：儘管大型語言模型 (LLM) 已展現出令人印象深刻的能力，可透過從廣泛的訓練資料中獲取豐富的事實知識，執行各種自然語言處理任務，但它們綜合運用並以複雜的方式運用此知識進行邏輯推理的能力仍有待進一步探討。在這項工作中，我們透過一個自動生成的一般領域和生物醫學知識圖表複雜推理問題的新基準，對最先進的 LLM 複雜邏輯推理能力進行系統性評估。我們的廣泛實驗採用多樣化的情境學習技術，揭示出 LLM 擅長對一般世界知識進行推理，但在處理特定領域的專業知識時則面臨重大挑戰。我們發現，使用明確的思考鏈條示範進行提示，可以大幅改善 LLM 在具有多樣化邏輯運算的複雜邏輯推理任務中的表現。有趣的是，我們的受控評估揭露了一個不對稱性，其中 LLM 展現出在集合聯集運算方面的熟練度，但在集合交集方面卻顯得相當吃力，而集合交集正是邏輯推理的關鍵組成部分。為了促進後續研究，我們將公開發布我們的評估基準和程式碼。

##### **Prompt2DeModel: Declarative Neuro-Symbolic Modeling with Natural Language**
2407.20513v1 by Hossein Rajaby Faghihi, Aliakbar Nafar, Andrzej Uszok, Hamid Karimian, Parisa Kordjamshidi

This paper presents a conversational pipeline for crafting domain knowledge
for complex neuro-symbolic models through natural language prompts. It
leverages large language models to generate declarative programs in the
DomiKnowS framework. The programs in this framework express concepts and their
relationships as a graph in addition to logical constraints between them. The
graph, later, can be connected to trainable neural models according to those
specifications. Our proposed pipeline utilizes techniques like dynamic
in-context demonstration retrieval, model refinement based on feedback from a
symbolic parser, visualization, and user interaction to generate the tasks'
structure and formal knowledge representation. This approach empowers domain
experts, even those not well-versed in ML/AI, to formally declare their
knowledge to be incorporated in customized neural models in the DomiKnowS
framework.

摘要：本文提出了一個對話式管道，透過自然語言提示，為複雜的神經符號模型建立領域知識。它利用大型語言模型在 DomiKnowS 框架中產生宣告式程式。此框架中的程式會將概念及其關係表示為圖形，並在它們之間加上邏輯約束。之後，可以根據這些規格將圖形連接到可訓練的神經模型。我們提出的管道利用動態情境中示範檢索、基於符號解析器回饋的模型精煉、視覺化和使用者互動等技術，以產生任務結構和形式知識表示。這種方法讓領域專家，即使是不熟悉機器學習／人工智慧的人，也能正式宣告他們的知識，並將其納入 DomiKnowS 框架中的自訂神經模型。

##### **What if Red Can Talk? Dynamic Dialogue Generation Using Large Language Models**
2407.20382v1 by Navapat Nananukul, Wichayaporn Wongkamjan

Role-playing games (RPGs) provide players with a rich, interactive world to
explore. Dialogue serves as the primary means of communication between
developers and players, manifesting in various forms such as guides, NPC
interactions, and storytelling. While most games rely on written scripts to
define the main story and character personalities, player immersion can be
significantly enhanced through casual interactions between characters. With the
advent of large language models (LLMs), we introduce a dialogue filler
framework that utilizes LLMs enhanced by knowledge graphs to generate dynamic
and contextually appropriate character interactions. We test this framework
within the environments of Final Fantasy VII Remake and Pokemon, providing
qualitative and quantitative evidence that demonstrates GPT-4's capability to
act with defined personalities and generate dialogue. However, some flaws
remain, such as GPT-4 being overly positive or more subtle personalities, such
as maturity, tend to be of lower quality compared to more overt traits like
timidity. This study aims to assist developers in crafting more nuanced filler
dialogues, thereby enriching player immersion and enhancing the overall RPG
experience.

摘要：角色扮演遊戲 (RPG) 為玩家提供一個豐富且互動的世界供其探索。對話作為開發者與玩家之間的主要溝通方式，以指南、NPC 互動和說故事等各種形式呈現。雖然大多數遊戲依賴於書面腳本來定義主線故事和角色個性，但透過角色之間的閒聊互動，可以大幅提升玩家的沉浸感。隨著大型語言模型 (LLM) 的出現，我們引入了一個對話填充框架，利用由知識圖譜增強的 LLM 來產生動態且符合情境的對話互動。我們在 Final Fantasy VII Remake 和寶可夢的環境中測試了這個框架，提供了定性和定量的證據，證明了 GPT-4 具備以定義好的個性行動並產生對話的能力。然而，仍存在一些缺陷，例如 GPT-4 過於正面，或者較為細微的個性，例如成熟度，往往品質低於較明顯的特質，例如膽怯。本研究旨在協助開發者打造更細緻的填充對話，從而豐富玩家的沉浸感並提升整體 RPG 體驗。

##### **MindSearch: Mimicking Human Minds Elicits Deep AI Searcher**
2407.20183v1 by Zehui Chen, Kuikun Liu, Qiuchen Wang, Jiangning Liu, Wenwei Zhang, Kai Chen, Feng Zhao

Information seeking and integration is a complex cognitive task that consumes
enormous time and effort. Inspired by the remarkable progress of Large Language
Models, recent works attempt to solve this task by combining LLMs and search
engines. However, these methods still obtain unsatisfying performance due to
three challenges: (1) complex requests often cannot be accurately and
completely retrieved by the search engine once (2) corresponding information to
be integrated is spread over multiple web pages along with massive noise, and
(3) a large number of web pages with long contents may quickly exceed the
maximum context length of LLMs. Inspired by the cognitive process when humans
solve these problems, we introduce MindSearch to mimic the human minds in web
information seeking and integration, which can be instantiated by a simple yet
effective LLM-based multi-agent framework. The WebPlanner models the human mind
of multi-step information seeking as a dynamic graph construction process: it
decomposes the user query into atomic sub-questions as nodes in the graph and
progressively extends the graph based on the search result from WebSearcher.
Tasked with each sub-question, WebSearcher performs hierarchical information
retrieval with search engines and collects valuable information for WebPlanner.
The multi-agent design of MindSearch enables the whole framework to seek and
integrate information parallelly from larger-scale (e.g., more than 300) web
pages in 3 minutes, which is worth 3 hours of human effort. MindSearch
demonstrates significant improvement in the response quality in terms of depth
and breadth, on both close-set and open-set QA problems. Besides, responses
from MindSearch based on InternLM2.5-7B are preferable by humans to ChatGPT-Web
and Perplexity.ai applications, which implies that MindSearch can already
deliver a competitive solution to the proprietary AI search engine.

摘要：資訊搜尋與整合是一項複雜的認知任務，會耗費大量時間與精力。在大型語言模型顯著進展的啟發下，近期研究嘗試結合大型語言模型與搜尋引擎來解決此任務。然而，這些方法仍因三項挑戰而無法獲得令人滿意的效能：(1) 複雜的查詢通常無法由搜尋引擎一次準確且完整地擷取，(2) 要整合的對應資訊散布在多個網頁中且伴隨著大量雜訊，以及 (3) 大量內容過長的網頁可能會快速超過大型語言模型的最大脈絡長度。在人類解決這些問題的認知過程中獲得靈感，我們引入了 MindSearch 來模擬人類心智在網頁資訊搜尋與整合中的行為，這可以用一個簡單但有效的基於大型語言模型的多代理架構來實例化。WebPlanner 以動態圖形建構過程來建模人類心智的多步驟資訊搜尋：它將使用者查詢分解成圖形中的節點，作為原子化子問題，並根據 WebSearcher 的搜尋結果逐步延伸圖形。WebSearcher 以每個子問題為任務，執行搜尋引擎的分層式資訊擷取，並為 WebPlanner 收集有價值的資訊。MindSearch 的多代理設計讓整個架構可以在 3 分鐘內平行地從更大規模（例如超過 300 個）的網頁中搜尋並整合資訊，這相當於 3 小時的人力。MindSearch 在深度和廣度方面都顯著提升了回應品質，無論是在封閉式或開放式問答問題上。此外，人類更偏好基於 InternLM2.5-7B 的 MindSearch 回應，勝過 ChatGPT-Web 和 Perplexity.ai 應用程式，這表示 MindSearch 已經可以為專有 AI 搜尋引擎提供有競爭力的解決方案。

##### **rLLM: Relational Table Learning with LLMs**
2407.20157v1 by Weichen Li, Xiaotong Huang, Jianwu Zheng, Zheng Wang, Chaokun Wang, Li Pan, Jianhua Li

We introduce rLLM (relationLLM), a PyTorch library designed for Relational
Table Learning (RTL) with Large Language Models (LLMs). The core idea is to
decompose state-of-the-art Graph Neural Networks, LLMs, and Table Neural
Networks into standardized modules, to enable the fast construction of novel
RTL-type models in a simple "combine, align, and co-train" manner. To
illustrate the usage of rLLM, we introduce a simple RTL method named
\textbf{BRIDGE}. Additionally, we present three novel relational tabular
datasets (TML1M, TLF2K, and TACM12K) by enhancing classic datasets. We hope
rLLM can serve as a useful and easy-to-use development framework for
RTL-related tasks. Our code is available at:
https://github.com/rllm-project/rllm.

摘要：我們引入了 rLLM (relationLLM)，一個專為大型語言模型 (LLM) 的關係表學習 (RTL) 所設計的 PyTorch 函式庫。核心概念是將最先進的圖形神經網路、LLM 和表神經網路分解為標準化模組，以便以簡單的「組合、對齊和共同訓練」方式快速建構新型 RTL 類型模型。為了說明 rLLM 的用法，我們引入了名為 \textbf{BRIDGE} 的簡單 RTL 方法。此外，我們透過強化經典資料集來呈現三個新穎的關係表格資料集 (TML1M、TLF2K 和 TACM12K)。我們希望 rLLM 能夠作為 RTL 相關任務有用的且易於使用的開發架構。我們的程式碼可在以下網址取得：
https://github.com/rllm-project/rllm。

##### **Prometheus Chatbot: Knowledge Graph Collaborative Large Language Model for Computer Components Recommendation**
2407.19643v2 by Yunsheng Wang, Songhao Chen, Kevin Jin

Knowledge graphs (KGs) are essential in applications such as network
alignment, question-answering, and recommender systems (RSs) since they offer
structured relational data that facilitate the inference of indirect
relationships. However, the development of KG-based RSs capable of processing
user inputs in natural language faces significant challenges. Firstly, natural
language processing units must effectively handle the ambiguity and variability
in human language to interpret user intents accurately. Secondly, the system
must precisely identify and link entities, like product names, to their
corresponding nodes in KGs. To overcome these challenges, supported by Lenovo,
we developed a novel chatbot called "Prometheus," which integrates a KG with a
large language model (LLM), specifically designed for recommending computer
components. This chatbot can accurately decode user requests and deliver
personalized recommendations derived from KGs, ensuring precise comprehension
and response to their computer setup needs.

摘要：知識圖譜 (KG) 在網路比對、問答和推薦系統 (RS) 等應用中至關重要，因為它們提供結構化的關係資料，有助於推斷間接關係。然而，開發能夠處理自然語言使用者輸入的基於 KG 的 RS 面臨著重大的挑戰。首先，自然語言處理單元必須有效處理人類語言中的模糊性和變異性，才能準確地解釋使用者意圖。其次，系統必須準確識別和連結實體（例如產品名稱）到 KG 中對應的節點。為了克服這些挑戰，在聯想的支援下，我們開發了一款名為「普羅米修斯」的新聊天機器人，它將 KG 與大型語言模型 (LLM) 整合在一起，專門用於推薦電腦組件。此聊天機器人可以準確地解碼使用者要求，並提供從 KG 中衍生的個人化推薦，確保精確理解和回應其電腦設定需求。

##### **TopicTag: Automatic Annotation of NMF Topic Models Using Chain of Thought and Prompt Tuning with LLMs**
2407.19616v1 by Selma Wanna, Ryan Barron, Nick Solovyev, Maksim E. Eren, Manish Bhattarai, Kim Rasmussen, Boian S. Alexandrov

Topic modeling is a technique for organizing and extracting themes from large
collections of unstructured text. Non-negative matrix factorization (NMF) is a
common unsupervised approach that decomposes a term frequency-inverse document
frequency (TF-IDF) matrix to uncover latent topics and segment the dataset
accordingly. While useful for highlighting patterns and clustering documents,
NMF does not provide explicit topic labels, necessitating subject matter
experts (SMEs) to assign labels manually. We present a methodology for
automating topic labeling in documents clustered via NMF with automatic model
determination (NMFk). By leveraging the output of NMFk and employing prompt
engineering, we utilize large language models (LLMs) to generate accurate topic
labels. Our case study on over 34,000 scientific abstracts on Knowledge Graphs
demonstrates the effectiveness of our method in enhancing knowledge management
and document organization.

摘要：主題建模是一種從大量非結構化文本中組織和提取主題的技術。非負矩陣分解 (NMF) 是一種常見的無監督方法，它將詞頻-逆文件頻率 (TF-IDF) 矩陣分解為潛在主題，並據此對數據集進行分段。儘管 NMF 可用於強調模式和群組文件，但它不提供明確的主題標籤，這需要主題專家 (SME) 手動分配標籤。我們提出了一種方法，用於自動標記通過 NMF 進行群組的文件，並自動確定模型 (NMFk)。通過利用 NMFk 的輸出並採用提示工程，我們利用大型語言模型 (LLM) 來生成準確的主題標籤。我們對超過 34,000 篇關於知識圖譜的科學摘要進行的案例研究證明了我們的方法在增強知識管理和文件組織方面的有效性。

##### **Semantic Communication Enhanced by Knowledge Graph Representation Learning**
2407.19338v1 by Nour Hello, Paolo Di Lorenzo, Emilio Calvanese Strinati

This paper investigates the advantages of representing and processing
semantic knowledge extracted into graphs within the emerging paradigm of
semantic communications. The proposed approach leverages semantic and pragmatic
aspects, incorporating recent advances on large language models (LLMs) to
achieve compact representations of knowledge to be processed and exchanged
between intelligent agents. This is accomplished by using the cascade of LLMs
and graph neural networks (GNNs) as semantic encoders, where information to be
shared is selected to be meaningful at the receiver. The embedding vectors
produced by the proposed semantic encoder represent information in the form of
triplets: nodes (semantic concepts entities), edges(relations between
concepts), nodes. Thus, semantic information is associated with the
representation of relationships among elements in the space of semantic concept
abstractions. In this paper, we investigate the potential of achieving high
compression rates in communication by incorporating relations that link
elements within graph embeddings. We propose sending semantic symbols solely
equivalent to node embeddings through the wireless channel and inferring the
complete knowledge graph at the receiver. Numerical simulations illustrate the
effectiveness of leveraging knowledge graphs to semantically compress and
transmit information.

摘要：本文研究了在语义通信的新兴范例中将提取到图中的语义知识表示和处理的优势。所提出的方法利用语义和语用方面，结合了大语言模型 (LLM) 的最新进展，以实现要处理和在智能代理之间交换的知识的紧凑表示。这是通过使用 LLM 和图神经网络 (GNN) 的级联作为语义编码器来完成的，其中要共享的信息被选择为对接收者有意义。由所提出的语义编码器产生的嵌入向量以三元组的形式表示信息：节点（语义概念实体）、边（概念之间的关系）、节点。因此，语义信息与语义概念抽象空间中元素之间关系的表示相关联。在本文中，我们研究了通过合并将图嵌入中的元素联系起来的关联来实现高压缩率的潜力。我们建议仅通过无线信道发送语义符号，这些符号完全等效于节点嵌入，并在接收器处推断出完整的知识图。数值模拟说明了利用知识图语义压缩和传输信息的有效性。

##### **GraphBPE: Molecular Graphs Meet Byte-Pair Encoding**
2407.19039v1 by Yuchen Shen, Barnabás Póczos

With the increasing attention to molecular machine learning, various
innovations have been made in designing better models or proposing more
comprehensive benchmarks. However, less is studied on the data preprocessing
schedule for molecular graphs, where a different view of the molecular graph
could potentially boost the model's performance. Inspired by the Byte-Pair
Encoding (BPE) algorithm, a subword tokenization method popularly adopted in
Natural Language Processing, we propose GraphBPE, which tokenizes a molecular
graph into different substructures and acts as a preprocessing schedule
independent of the model architectures. Our experiments on 3 graph-level
classification and 3 graph-level regression datasets show that data
preprocessing could boost the performance of models for molecular graphs, and
GraphBPE is effective for small classification datasets and it performs on par
with other tokenization methods across different model architectures.

摘要：隨著分子機器學習受到的關注度越來越高，在設計更好的模型或提出更全面的基準方面已經有了各種創新。然而，對於分子圖的數據預處理計畫研究較少，在該計畫中，分子圖的不同視圖可能會提升模型的效能。受到在自然語言處理中廣泛採用的子詞彙標記化方法 Byte-Pair 編碼 (BPE) 演算法的啟發，我們提出了 GraphBPE，它將分子圖標記化為不同的子結構，並作為與模型架構無關的預處理計畫。我們在 3 個圖形層級分類和 3 個圖形層級回歸資料集上的實驗顯示，資料預處理可以提升分子圖模型的效能，而 GraphBPE 對於小型分類資料集有效，並且在不同的模型架構中與其他標記化方法表現相當。

##### **Knowledge Graph Structure as Prompt: Improving Small Language Models Capabilities for Knowledge-based Causal Discovery**
2407.18752v3 by Yuni Susanti, Michael Färber

Causal discovery aims to estimate causal structures among variables based on
observational data. Large Language Models (LLMs) offer a fresh perspective to
tackle the causal discovery problem by reasoning on the metadata associated
with variables rather than their actual data values, an approach referred to as
knowledge-based causal discovery. In this paper, we investigate the
capabilities of Small Language Models (SLMs, defined as LLMs with fewer than 1
billion parameters) with prompt-based learning for knowledge-based causal
discovery. Specifically, we present KG Structure as Prompt, a novel approach
for integrating structural information from a knowledge graph, such as common
neighbor nodes and metapaths, into prompt-based learning to enhance the
capabilities of SLMs. Experimental results on three types of biomedical and
open-domain datasets under few-shot settings demonstrate the effectiveness of
our approach, surpassing most baselines and even conventional fine-tuning
approaches trained on full datasets. Our findings further highlight the strong
capabilities of SLMs: in combination with knowledge graphs and prompt-based
learning, SLMs demonstrate the potential to surpass LLMs with larger number of
parameters. Our code and datasets are available on GitHub.

摘要：因果發現旨在根據觀測數據估計變數之間的因果結構。大型語言模型 (LLM) 提供了一個新的觀點來解決因果發現問題，方法是推論與變數相關的元數據，而不是它們的實際數據值，這種方法稱為基於知識的因果發現。在本文中，我們探討了小語言模型 (SLM，定義為參數少於 10 億的 LLM) 的能力，並採用基於提示的學習進行基於知識的因果發現。具體來說，我們提出了 KG Structure as Prompt，這是一種新穎的方法，用於將來自知識圖譜的結構資訊，例如共同鄰居節點和元路徑，整合到基於提示的學習中，以增強 SLM 的能力。在少次嘗試設定下，針對三種類型的生物醫學和開放領域資料集的實驗結果證明了我們方法的有效性，超越了大多數基準，甚至超越了在完整資料集上訓練的傳統微調方法。我們的發現進一步突出了 SLM 的強大功能：結合知識圖譜和基於提示的學習，SLM 展示了超越具有更多參數的 LLM 的潛力。我們的程式碼和資料集可在 GitHub 上取得。

##### **Using GPT-4 to guide causal machine learning**
2407.18607v1 by Anthony C. Constantinou, Neville K. Kitson, Alessio Zanga

Since its introduction to the public, ChatGPT has had an unprecedented
impact. While some experts praised AI advancements and highlighted their
potential risks, others have been critical about the accuracy and usefulness of
Large Language Models (LLMs). In this paper, we are interested in the ability
of LLMs to identify causal relationships. We focus on the well-established
GPT-4 (Turbo) and evaluate its performance under the most restrictive
conditions, by isolating its ability to infer causal relationships based solely
on the variable labels without being given any context, demonstrating the
minimum level of effectiveness one can expect when it is provided with
label-only information. We show that questionnaire participants judge the GPT-4
graphs as the most accurate in the evaluated categories, closely followed by
knowledge graphs constructed by domain experts, with causal Machine Learning
(ML) far behind. We use these results to highlight the important limitation of
causal ML, which often produces causal graphs that violate common sense,
affecting trust in them. However, we show that pairing GPT-4 with causal ML
overcomes this limitation, resulting in graphical structures learnt from real
data that align more closely with those identified by domain experts, compared
to structures learnt by causal ML alone. Overall, our findings suggest that
despite GPT-4 not being explicitly designed to reason causally, it can still be
a valuable tool for causal representation, as it improves the causal discovery
process of causal ML algorithms that are designed to do just that.

摘要：自 ChatGPT 向公众发布以来，它产生了前所未有的影响。虽然一些专家赞扬了 AI 的进步并强调了其潜在风险，但其他人一直批评大型语言模型 (LLM) 的准确性和有用性。在本文中，我们对 LLM 识别因果关系的能力感兴趣。我们专注于成熟的 GPT-4（Turbo），并在最严格的条件下评估其性能，通过孤立其仅根据变量标签推断因果关系的能力，而不提供任何上下文，展示了当仅提供标签信息时人们可以预期的最低有效性水平。我们表明，问卷参与者认为 GPT-4 图形在评估类别中是最准确的，紧随其后的是由领域专家构建的知识图谱，因果机器学习 (ML) 远远落后。我们使用这些结果来强调因果 ML 的重要局限性，它经常产生违背常识的因果图，影响人们对它们的信任。然而，我们表明将 GPT-4 与因果 ML 配对可以克服这一限制，从而产生从真实数据中学到的图形结构，与领域专家识别的结构相比，更紧密地与之对齐，而不是仅由因果 ML 学到的结构。总体而言，我们的研究结果表明，尽管 GPT-4 并未明确设计为因果推理，但它仍然可以成为因果表示的宝贵工具，因为它改进了旨在执行此操作的因果 ML 算法的因果发现过程。

##### **Multi-turn Response Selection with Commonsense-enhanced Language Models**
2407.18479v1 by Yuandong Wang, Xuhui Ren, Tong Chen, Yuxiao Dong, Nguyen Quoc Viet Hung, Jie Tang

As a branch of advanced artificial intelligence, dialogue systems are
prospering. Multi-turn response selection is a general research problem in
dialogue systems. With the assistance of background information and pre-trained
language models, the performance of state-of-the-art methods on this problem
gains impressive improvement. However, existing studies neglect the importance
of external commonsense knowledge. Hence, we design a Siamese network where a
pre-trained Language model merges with a Graph neural network (SinLG). SinLG
takes advantage of Pre-trained Language Models (PLMs) to catch the word
correlations in the context and response candidates and utilizes a Graph Neural
Network (GNN) to reason helpful common sense from an external knowledge graph.
The GNN aims to assist the PLM in fine-tuning, and arousing its related
memories to attain better performance. Specifically, we first extract related
concepts as nodes from an external knowledge graph to construct a subgraph with
the context response pair as a super node for each sample. Next, we learn two
representations for the context response pair via both the PLM and GNN. A
similarity loss between the two representations is utilized to transfer the
commonsense knowledge from the GNN to the PLM. Then only the PLM is used to
infer online so that efficiency can be guaranteed. Finally, we conduct
extensive experiments on two variants of the PERSONA-CHAT dataset, which proves
that our solution can not only improve the performance of the PLM but also
achieve an efficient inference.

摘要：作為高級人工智慧的一個分支，對話系統正蓬勃發展。多輪回應用戶回應選擇是對話系統中一個通用的研究問題。在背景資訊和預先訓練的語言模型的協助下，最先進的方法在此問題上的表現獲致令人印象深刻的進步。然而，現有的研究忽略了外部常識知識的重要性。因此，我們設計了一個暹羅網路，其中一個預先訓練的語言模型與一個圖神經網路（SinLG）合併。SinLG 利用預先訓練的語言模型（PLM）來捕捉語境和回應候選中的詞彙關聯，並利用圖神經網路（GNN）從外部知識圖譜推理有用的常識。GNN 旨在協助 PLM 進行微調，並喚醒其相關記憶以獲得更好的表現。具體來說，我們首先從外部知識圖譜中提取相關概念作為節點，以構建一個子圖，其中語境回應對作為每個範例的超級節點。接下來，我們透過 PLM 和 GNN 為語境回應對學習兩個表示。兩個表示之間的相似性損失用於將常識知識從 GNN 轉移到 PLM。然後僅使用 PLM 來進行線上推論，以便保證效率。最後，我們對 PERSONA-CHAT 資料集的兩個變體進行了廣泛的實驗，這證明我們的解決方案不僅可以提高 PLM 的效能，還能實現高效的推論。

##### **Gene Regulatory Network Inference from Pre-trained Single-Cell Transcriptomics Transformer with Joint Graph Learning**
2407.18181v1 by Sindhura Kommu, Yizhi Wang, Yue Wang, Xuan Wang

Inferring gene regulatory networks (GRNs) from single-cell RNA sequencing
(scRNA-seq) data is a complex challenge that requires capturing the intricate
relationships between genes and their regulatory interactions. In this study,
we tackle this challenge by leveraging the single-cell BERT-based pre-trained
transformer model (scBERT), trained on extensive unlabeled scRNA-seq data, to
augment structured biological knowledge from existing GRNs. We introduce a
novel joint graph learning approach that combines the rich contextual
representations learned by pre-trained single-cell language models with the
structured knowledge encoded in GRNs using graph neural networks (GNNs). By
integrating these two modalities, our approach effectively reasons over boththe
gene expression level constraints provided by the scRNA-seq data and the
structured biological knowledge inherent in GRNs. We evaluate our method on
human cell benchmark datasets from the BEELINE study with cell type-specific
ground truth networks. The results demonstrate superior performance over
current state-of-the-art baselines, offering a deeper understanding of cellular
regulatory mechanisms.

摘要：從單細胞 RNA 定序 (scRNA-seq) 資料推論基因調控網路 (GRN) 是一項複雜的挑戰，需要掌握基因與其調控交互作用之間的複雜關係。在此研究中，我們透過利用在廣泛的未標記 scRNA-seq 資料上訓練的單細胞 BERT 基於預訓練轉換器模型 (scBERT)，來克服此挑戰，以擴充現有 GRN 中的結構化生物知識。我們引入一種新穎的聯合圖形學習方法，它結合了預訓練單細胞語言模型所學習到的豐富脈絡表徵，以及使用圖形神經網路 (GNN) 對 GRN 中編碼的結構化知識。透過整合這兩種方式，我們的做法有效地對 scRNA-seq 資料提供的基因表現層級約束和 GRN 中固有的結構化生物知識進行推理。我們使用 BEELINE 研究中的人類細胞基準資料集，以及細胞類型特定的基本事實網路，來評估我們的方法。結果證明其效能優於目前最先進的基準，提供了對細胞調控機制的更深入理解。

##### **MathViz-E: A Case-study in Domain-Specialized Tool-Using Agents**
2407.17544v1 by Arya Bulusu, Brandon Man, Ashish Jagmohan, Aditya Vempaty, Jennifer Mari-Wyka, Deepak Akkil

There has been significant recent interest in harnessing LLMs to control
software systems through multi-step reasoning, planning and tool-usage. While
some promising results have been obtained, application to specific domains
raises several general issues including the control of specialized domain
tools, the lack of existing datasets for training and evaluation, and the
non-triviality of automated system evaluation and improvement. In this paper,
we present a case-study where we examine these issues in the context of a
specific domain. Specifically, we present an automated math visualizer and
solver system for mathematical pedagogy. The system orchestrates mathematical
solvers and math graphing tools to produce accurate visualizations from simple
natural language commands. We describe the creation of specialized data-sets,
and also develop an auto-evaluator to easily evaluate the outputs of our system
by comparing them to ground-truth expressions. We have open sourced the
data-sets and code for the proposed system.

摘要：最近，人们对利用大型语言模型 (LLM) 来通过多步骤推理、规划和工具使用来控制软件系统产生了极大的兴趣。虽然已经取得了一些有希望的结果，但应用于特定领域会引发几个普遍性问题，包括对专业领域工具的控制、缺乏用于训练和评估的现有数据集，以及自动化系统评估和改进的非平凡性。在本文中，我们提出了一个案例研究，其中我们研究了特定领域背景下的这些问题。具体来说，我们展示了一个用于数学教育的自动化数学可视化器和求解器系统。该系统协调数学求解器和数学绘图工具，以根据简单的自然语言命令生成准确的可视化效果。我们描述了专门数据集的创建，还开发了一个自动评估器，通过将我们的系统输出与真实表达式进行比较，轻松评估其输出。我们已经开源了所提议系统的代码和数据集。

##### **Ranking protein-protein models with large language models and graph neural networks**
2407.16375v1 by Xiaotong Xu, Alexandre M. J. J. Bonvin

Protein-protein interactions (PPIs) are associated with various diseases,
including cancer, infections, and neurodegenerative disorders. Obtaining
three-dimensional structural information on these PPIs serves as a foundation
to interfere with those or to guide drug design. Various strategies can be
followed to model those complexes, all typically resulting in a large number of
models. A challenging step in this process is the identification of good models
(near-native PPI conformations) from the large pool of generated models. To
address this challenge, we previously developed DeepRank-GNN-esm, a graph-based
deep learning algorithm for ranking modelled PPI structures harnessing the
power of protein language models. Here, we detail the use of our software with
examples. DeepRank-GNN-esm is freely available at
https://github.com/haddocking/DeepRank-GNN-esm

摘要：蛋白-蛋白交互作用 (PPI) 與各種疾病相關，包括癌症、感染和神經退化性疾病。取得這些 PPI 的三維結構資訊，作為干擾它們或引導藥物設計的基礎。可以遵循各種策略來建模這些複合體，所有這些策略通常會產生大量的模型。此過程中的挑戰性步驟，是從大量產生的模型中找出好的模型（接近原生 PPI 構象）。為了應對這個挑戰，我們之前開發了 DeepRank-GNN-esm，這是一種基於圖形的深度學習演算法，用於對建模的 PPI 結構進行排名，利用蛋白質語言模型的力量。在這裡，我們詳細說明了我們軟體的使用範例。DeepRank-GNN-esm 可在 https://github.com/haddocking/DeepRank-GNN-esm 免費取得

##### **PhenoFlow: A Human-LLM Driven Visual Analytics System for Exploring Large and Complex Stroke Datasets**
2407.16329v1 by Jaeyoung Kim, Sihyeon Lee, Hyeon Jeon, Keon-Joo Lee, Hee-Joon Bae, Bohyoung Kim, Jinwook Seo

Acute stroke demands prompt diagnosis and treatment to achieve optimal
patient outcomes. However, the intricate and irregular nature of clinical data
associated with acute stroke, particularly blood pressure (BP) measurements,
presents substantial obstacles to effective visual analytics and
decision-making. Through a year-long collaboration with experienced
neurologists, we developed PhenoFlow, a visual analytics system that leverages
the collaboration between human and Large Language Models (LLMs) to analyze the
extensive and complex data of acute ischemic stroke patients. PhenoFlow
pioneers an innovative workflow, where the LLM serves as a data wrangler while
neurologists explore and supervise the output using visualizations and natural
language interactions. This approach enables neurologists to focus more on
decision-making with reduced cognitive load. To protect sensitive patient
information, PhenoFlow only utilizes metadata to make inferences and synthesize
executable codes, without accessing raw patient data. This ensures that the
results are both reproducible and interpretable while maintaining patient
privacy. The system incorporates a slice-and-wrap design that employs temporal
folding to create an overlaid circular visualization. Combined with a linear
bar graph, this design aids in exploring meaningful patterns within irregularly
measured BP data. Through case studies, PhenoFlow has demonstrated its
capability to support iterative analysis of extensive clinical datasets,
reducing cognitive load and enabling neurologists to make well-informed
decisions. Grounded in long-term collaboration with domain experts, our
research demonstrates the potential of utilizing LLMs to tackle current
challenges in data-driven clinical decision-making for acute ischemic stroke
patients.

摘要：<paragraph>急性中風需要迅速診斷和治療，才能達到最佳的病人治療結果。然而，與急性中風相關的臨床資料複雜且不規則，特別是血壓 (BP) 測量，對有效的視覺分析和決策制定構成重大障礙。透過與經驗豐富的神經科醫師長達一年的合作，我們開發了 PhenoFlow，這是一個視覺分析系統，利用人與大型語言模型 (LLM) 之間的協作來分析急性缺血性中風患者的廣泛且複雜資料。PhenoFlow 開創了一種創新的工作流程，其中 LLM 擔任資料整理員，而神經科醫師則使用視覺化和自然語言互動來探索和監督輸出。這種方法使神經科醫師能夠更專注於決策制定，同時降低認知負擔。為了保護敏感的病人資訊，PhenoFlow 僅利用元資料進行推論並合成可執行程式碼，而不會存取原始病人資料。這確保了結果既可重現又可解釋，同時維護病人的隱私。該系統採用分段和包裝設計，採用時間摺疊來建立疊加的圓形視覺化。結合線性長條圖，此設計有助於探索不規則測量血壓資料中的有意義模式。透過案例研究，PhenoFlow 已證明其支援對廣泛臨床資料集進行反覆分析的能力，降低認知負擔並使神經科醫師能夠做出明智的決策。我們的研究以與領域專家長期合作為基礎，證明了利用 LLM 來應對當前急性缺血性中風患者資料驅動臨床決策制定挑戰的潛力。</paragraph>

##### **Graph-Structured Speculative Decoding**
2407.16207v1 by Zhuocheng Gong, Jiahao Liu, Ziyue Wang, Pengfei Wu, Jingang Wang, Xunliang Cai, Dongyan Zhao, Rui Yan

Speculative decoding has emerged as a promising technique to accelerate the
inference of Large Language Models (LLMs) by employing a small language model
to draft a hypothesis sequence, which is then validated by the LLM. The
effectiveness of this approach heavily relies on the balance between
performance and efficiency of the draft model. In our research, we focus on
enhancing the proportion of draft tokens that are accepted to the final output
by generating multiple hypotheses instead of just one. This allows the LLM more
options to choose from and select the longest sequence that meets its
standards. Our analysis reveals that hypotheses produced by the draft model
share many common token sequences, suggesting a potential for optimizing
computation. Leveraging this observation, we introduce an innovative approach
utilizing a directed acyclic graph (DAG) to manage the drafted hypotheses. This
structure enables us to efficiently predict and merge recurring token
sequences, vastly reducing the computational demands of the draft model. We
term this approach Graph-structured Speculative Decoding (GSD). We apply GSD
across a range of LLMs, including a 70-billion parameter LLaMA-2 model, and
observe a remarkable speedup of 1.73$\times$ to 1.96$\times$, significantly
surpassing standard speculative decoding.

摘要：<paragraph>推測性解碼已成為一種有前途的技術，可通過使用小型語言模型起草假設序列，然後由大型語言模型 (LLM) 驗證該序列，從而加速大型語言模型 (LLM) 的推理。此方法的有效性在很大程度上取決於草稿模型的性能和效率之間的平衡。在我們的研究中，我們專注於通過生成多個假設而不是只生成一個假設來提高被接受為最終輸出的草稿令牌的比例。這允許 LLM 從中選擇更多選項，並選擇符合其標準的最長序列。我們的分析表明，草稿模型產生的假設共享許多公共令牌序列，這表明優化計算的可能性。利用這一觀察結果，我們引入了一種創新的方法，利用有向無環圖 (DAG) 來管理已編制的假設。這種結構使我們能夠有效地預測和合併重複的令牌序列，從而大大降低了草稿模型的計算需求。我們將這種方法稱為圖結構推測性解碼 (GSD)。我們將 GSD 應用於一系列 LLM，包括一個 700 億參數的 LLaMA-2 模型，並觀察到顯著的加速，從 1.73 倍到 1.96 倍，顯著超過標準推測性解碼。</paragraph>

##### **Evaluating Long Range Dependency Handling in Code Generation Models using Multi-Step Key Retrieval**
2407.21049v1 by Yannick Assogba, Donghao Ren

As language models support larger and larger context sizes, evaluating their
ability to make effective use of that context becomes increasingly important.
We analyze the ability of several code generation models to handle long range
dependencies using a suite of multi-step key retrieval tasks in context windows
up to 8k tokens in length. The tasks progressively increase in difficulty and
allow more nuanced evaluation of model capabilities than tests like the popular
needle-in-the-haystack test. We find that performance degrades significantly
(up to 2x) when a function references another function that is defined later in
the prompt. We also observe that models that use sliding window attention
mechanisms have difficulty handling references further than the size of a
single window. We perform simple prompt modifications using call graph
information to improve multi-step retrieval performance up to 3x. Our analysis
highlights different facets of long-context performance and is suggestive of
prompt construction strategies for code completion tools

摘要：隨著語言模型支援的內容大小越來越大，評估其有效利用該內容的能力變得越來越重要。我們分析了幾個程式碼生成模型處理長距離依賴關係的能力，使用一組多步驟關鍵檢索任務，在長達 8k 令牌的內容視窗中。任務逐漸增加難度，並允許對模型功能進行比流行的針頭乾草堆測試更細緻的評估。我們發現，當函式參照稍後在提示中定義的另一個函式時，效能會顯著下降（最多 2 倍）。我們還觀察到，使用滑動視窗注意機制的模型難以處理超出單一視窗大小的參照。我們使用呼叫圖形資訊執行簡單的提示修改，以將多步驟檢索效能提升至 3 倍。我們的分析突顯了長內容效能的不同面向，並暗示了程式碼完成工具的提示建構策略

##### **Finetuning Generative Large Language Models with Discrimination Instructions for Knowledge Graph Completion**
2407.16127v1 by Yang Liu, Xiaobin Tian, Zequn Sun, Wei Hu

Traditional knowledge graph (KG) completion models learn embeddings to
predict missing facts. Recent works attempt to complete KGs in a
text-generation manner with large language models (LLMs). However, they need to
ground the output of LLMs to KG entities, which inevitably brings errors. In
this paper, we present a finetuning framework, DIFT, aiming to unleash the KG
completion ability of LLMs and avoid grounding errors. Given an incomplete
fact, DIFT employs a lightweight model to obtain candidate entities and
finetunes an LLM with discrimination instructions to select the correct one
from the given candidates. To improve performance while reducing instruction
data, DIFT uses a truncated sampling method to select useful facts for
finetuning and injects KG embeddings into the LLM. Extensive experiments on
benchmark datasets demonstrate the effectiveness of our proposed framework.

摘要：傳統知識圖譜（KG）完成功能模型學習嵌入，以預測遺失的事實。最近的工作嘗試以大型語言模型（LLM）以文字生成的方式完成 KG。然而，他們需要將 LLM 的輸出基礎建立在 KG 實體上，這不可避免地會帶來錯誤。在本文中，我們提出了一個微調框架 DIFT，旨在釋放 LLM 的 KG 完成功能，並避免基礎錯誤。給定一個不完整的事實，DIFT 使用一個輕量級模型來獲得候選實體，並微調一個 LLM，並使用辨別指令從給定的候選項中選擇正確的實體。為了在減少指令數據的同時提升效能，DIFT 使用一個截斷抽樣方法來選擇有用的事實以進行微調，並將 KG 嵌入注入到 LLM 中。在基準資料集上的廣泛實驗證明了我們提出的框架的有效性。

##### **Unsupervised Robust Cross-Lingual Entity Alignment via Joint Modeling of Entity and Relation Texts**
2407.15588v1 by Soojin Yoon, Sungho Ko, Tongyoung Kim, SeongKu Kang, Jinyoung Yeo, Dongha Lee

Cross-lingual entity alignment (EA) enables the integration of multiple
knowledge graphs (KGs) across different languages, providing users with
seamless access to diverse and comprehensive knowledge.Existing methods, mostly
supervised, face challenges in obtaining labeled entity pairs. To address this,
recent studies have shifted towards a self-supervised and unsupervised
frameworks. Despite their effectiveness, these approaches have limitations: (1)
they mainly focus on entity features, neglecting the semantic information of
relations, (2) they assume isomorphism between source and target graphs,
leading to noise and reduced alignment accuracy, and (3) they are susceptible
to noise in the textual features, especially when encountering inconsistent
translations or Out-Of-Vocabulary (OOV) problems.
  In this paper, we propose ERAlign, an unsupervised and robust cross-lingual
EA framework that jointly performs Entity-level and Relation-level Alignment
using semantic textual features of relations and entities. Its refinement
process iteratively enhances results by fusing entity-level and relation-level
alignments based on neighbor triple matching. The additional verification
process examines the entities' neighbor triples as the linearized text. This
\textit{Align-and-Verify} pipeline that rigorously assesses alignment results,
achieving near-perfect alignment even in the presence of noisy textual features
of entities. Our extensive experiments demonstrate that robustness and general
applicability of \proposed improved the accuracy and effectiveness of EA tasks,
contributing significantly to knowledge-oriented applications.

摘要：跨語言實體對齊 (EA) 能夠整合不同語言中的多個知識圖譜 (KG)，讓使用者能無縫地存取多元且全面的知識。現有方法大多是有監督的，在取得標記實體對時面臨挑戰。為了解決這個問題，最近的研究已轉向自監督和無監督的架構。儘管這些方法很有效，但它們有以下限制：(1) 它們主要關注實體特徵，忽略關係的語義資訊，(2) 它們假設來源圖譜和目標圖譜之間同構，導致雜訊和對齊準確度降低，(3) 它們容易受到文字特徵中的雜訊影響，特別是在遇到不一致的翻譯或詞彙外問題 (OOV) 時。
在本文中，我們提出 ERAlign，一個無監督且穩健的跨語言 EA 架構，它使用關係和實體的語義文字特徵，同時執行實體層級和關係層級對齊。它的精煉程序透過根據鄰接三元組匹配融合實體層級和關係層級對齊，反覆增強結果。額外的驗證程序將實體的鄰接三元組視為線性化文字進行檢查。這個嚴格評估對齊結果的「對齊和驗證」管線，即使在存在實體的雜訊文字特徵時也能達成近乎完美的對齊。我們廣泛的實驗證明，\proposed 的穩健性和普遍適用性提升了 EA 任務的準確度和有效性，對知識導向應用程式有顯著的貢獻。

##### **Pre-Training and Prompting for Few-Shot Node Classification on Text-Attributed Graphs**
2407.15431v1 by Huanjing Zhao, Beining Yang, Yukuo Cen, Junyu Ren, Chenhui Zhang, Yuxiao Dong, Evgeny Kharlamov, Shu Zhao, Jie Tang

The text-attributed graph (TAG) is one kind of important real-world
graph-structured data with each node associated with raw texts. For TAGs,
traditional few-shot node classification methods directly conduct training on
the pre-processed node features and do not consider the raw texts. The
performance is highly dependent on the choice of the feature pre-processing
method. In this paper, we propose P2TAG, a framework designed for few-shot node
classification on TAGs with graph pre-training and prompting. P2TAG first
pre-trains the language model (LM) and graph neural network (GNN) on TAGs with
self-supervised loss. To fully utilize the ability of language models, we adapt
the masked language modeling objective for our framework. The pre-trained model
is then used for the few-shot node classification with a mixed prompt method,
which simultaneously considers both text and graph information. We conduct
experiments on six real-world TAGs, including paper citation networks and
product co-purchasing networks. Experimental results demonstrate that our
proposed framework outperforms existing graph few-shot learning methods on
these datasets with +18.98% ~ +35.98% improvements.

摘要：文本属性图 (TAG) 是一种重要的真实世界图结构化数据，其中每个节点都与原始文本相关联。对于 TAG，传统的少数镜头节点分类方法直接对预处理的节点特征进行训练，而不考虑原始文本。性能在很大程度上取决于特征预处理方法的选择。在本文中，我们提出了 P2TAG，这是一个专为 TAG 上的少数镜头节点分类设计的框架，具有图预训练和提示。P2TAG 首先使用自我监督损失对 TAG 上的语言模型 (LM) 和图神经网络 (GNN) 进行预训练。为了充分利用语言模型的能力，我们为我们的框架调整了掩码语言建模目标。然后使用预训练模型进行少数镜头节点分类，采用混合提示方法，同时考虑文本和图信息。我们对六个真实世界的 TAG 进行了实验，包括论文引用网络和产品共同购买网络。实验结果表明，我们提出的框架在这些数据集上优于现有的图少数镜头学习方法，改进了 +18.98% ~ +35.98%。

##### **LLMExplainer: Large Language Model based Bayesian Inference for Graph Explanation Generation**
2407.15351v2 by Jiaxing Zhang, Jiayi Liu, Dongsheng Luo, Jennifer Neville, Hua Wei

Recent studies seek to provide Graph Neural Network (GNN) interpretability
via multiple unsupervised learning models. Due to the scarcity of datasets,
current methods easily suffer from learning bias. To solve this problem, we
embed a Large Language Model (LLM) as knowledge into the GNN explanation
network to avoid the learning bias problem. We inject LLM as a Bayesian
Inference (BI) module to mitigate learning bias. The efficacy of the BI module
has been proven both theoretically and experimentally. We conduct experiments
on both synthetic and real-world datasets. The innovation of our work lies in
two parts: 1. We provide a novel view of the possibility of an LLM functioning
as a Bayesian inference to improve the performance of existing algorithms; 2.
We are the first to discuss the learning bias issues in the GNN explanation
problem.

摘要：近期研究試圖透過多種非監督式學習模型來提供圖神經網路 (GNN) 的可解釋性。由於資料集的稀少，目前的演算法容易受到學習偏差的影響。為了解決這個問題，我們將大型語言模型 (LLM) 作為知識嵌入到 GNN 解釋網路中，以避免學習偏差的問題。我們將 LLM 作為貝氏推論 (BI) 模組注入，以減輕學習偏差。BI 模組的效能已在理論上和實驗上得到證實。我們在合成和真實世界資料集上進行實驗。我們工作的創新之處在於兩部分：1. 我們提供 LLM 作為貝氏推論以改善現有演算法效能的可能性之新觀點；2. 我們率先討論 GNN 解釋問題中的學習偏差問題。

##### **Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation**
2407.15141v1 by Yu Zhang, Ruijie Yu, Kaipeng Zeng, Ding Li, Feng Zhu, Xiaokang Yang, Yaohui Jin, Yanyan Xu

High-throughput reaction condition (RC) screening is fundamental to chemical
synthesis. However, current RC screening suffers from laborious and costly
trial-and-error workflows. Traditional computer-aided synthesis planning (CASP)
tools fail to find suitable RCs due to data sparsity and inadequate reaction
representations. Nowadays, large language models (LLMs) are capable of tackling
chemistry-related problems, such as molecule design, and chemical logic Q\&A
tasks. However, LLMs have not yet achieved accurate predictions of chemical
reaction conditions. Here, we present MM-RCR, a text-augmented multimodal LLM
that learns a unified reaction representation from SMILES, reaction graphs, and
textual corpus for chemical reaction recommendation (RCR). To train MM-RCR, we
construct 1.2 million pair-wised Q\&A instruction datasets. Our experimental
results demonstrate that MM-RCR achieves state-of-the-art performance on two
open benchmark datasets and exhibits strong generalization capabilities on
out-of-domain (OOD) and High-Throughput Experimentation (HTE) datasets. MM-RCR
has the potential to accelerate high-throughput condition screening in chemical
synthesis.

摘要：高通量反應條件 (RC) 篩選是化學合成中的基礎。然而，當前的 RC 篩選會遇到繁瑣且昂貴的試錯工作流程。傳統的電腦輔助合成規劃 (CASP) 工具無法找到合適的 RC，這是因為資料稀疏且反應表示不足。如今，大型語言模型 (LLM) 能夠解決與化學相關的問題，例如分子設計和化學邏輯問答任務。然而，LLM 尚未達成化學反應條件的準確預測。在此，我們提出 MM-RCR，一個文本增強的多模態 LLM，它從 SMILES、反應圖和文本語料庫學習統一的反應表示，以進行化學反應推薦 (RCR)。為了訓練 MM-RCR，我們建構了 120 萬對配對的問答指令資料集。我們的實驗結果證明，MM-RCR 在兩個開放基準資料集上達到了最先進的效能，並在領域外 (OOD) 和高通量實驗 (HTE) 資料集上展現出強大的概化能力。MM-RCR 有可能加速化學合成中的高通量條件篩選。

##### **On the Design and Analysis of LLM-Based Algorithms**
2407.14788v1 by Yanxi Chen, Yaliang Li, Bolin Ding, Jingren Zhou

We initiate a formal investigation into the design and analysis of LLM-based
algorithms, i.e. algorithms that contain one or multiple calls of large
language models (LLMs) as sub-routines and critically rely on the capabilities
of LLMs. While LLM-based algorithms, ranging from basic LLM calls with prompt
engineering to complicated LLM-powered agent systems and compound AI systems,
have achieved remarkable empirical success, the design and optimization of them
have mostly relied on heuristics and trial-and-errors, which is largely due to
a lack of formal and analytical study for these algorithms. To fill this gap,
we start by identifying the computational-graph representation of LLM-based
algorithms, the design principle of task decomposition, and some key
abstractions, which then facilitate our formal analysis for the accuracy and
efficiency of LLM-based algorithms, despite the black-box nature of LLMs. We
further consider parallel decomposition for a case study, providing extensive
analytical and empirical study for four concrete examples of this pattern. Our
proposed framework holds promise for advancing LLM-based algorithms, by
revealing the reasons behind curious empirical phenomena, guiding the choices
of hyperparameters, predicting the empirical performance of algorithms, and
inspiring new algorithm design. To promote further study of LLM-based
algorithms, we release our source code at
https://github.com/modelscope/agentscope/tree/main/examples/paper_llm_based_algorithm.

摘要：<paragraph>我們對基於 LLM 的演算法的設計和分析展開正式調查，即包含一個或多個大型語言模型 (LLM) 作為子常式呼叫的演算法，並極度依賴 LLM 的功能。儘管基於 LLM 的演算法，從帶提示工程的基本 LLM 呼叫到複雜的 LLM 驅動的代理系統和複合式 AI 系統，已取得顯著的實證成功，但其設計和最佳化大多依賴試驗法和錯誤，這在很大程度上是因為缺乏對這些演算法的正式和分析研究。為了填補這個空白，我們從識別基於 LLM 的演算法的計算圖表示、任務分解的設計原則，以及一些關鍵抽象化開始，然後促進我們對基於 LLM 的演算法的準確性和效率進行正式分析，儘管 LLM 本身具有黑盒特性。我們進一步考慮並行分解作為案例研究，為此模式的四個具體範例提供廣泛的分析和實證研究。我們提出的架構有望推進基於 LLM 的演算法，方法是揭示奇怪的實證現象背後的原因、指導超參數的選擇、預測演算法的實證效能，並激發新的演算法設計。為了促進對基於 LLM 的演算法的進一步研究，我們在 https://github.com/modelscope/agentscope/tree/main/examples/paper_llm_based_algorithm/ 發布我們的原始碼。</paragraph>

##### **LaMAGIC: Language-Model-based Topology Generation for Analog Integrated Circuits**
2407.18269v1 by Chen-Chia Chang, Yikang Shan, Shaoze Fan, Jing Li, Shun Zhang, Ningyuan Cao, Yiran Chen, Xin Zhang

In the realm of electronic and electrical engineering, automation of analog
circuit is increasingly vital given the complexity and customized requirements
of modern applications. However, existing methods only develop search-based
algorithms that require many simulation iterations to design a custom circuit
topology, which is usually a time-consuming process. To this end, we introduce
LaMAGIC, a pioneering language model-based topology generation model that
leverages supervised finetuning for automated analog circuit design. LaMAGIC
can efficiently generate an optimized circuit design from the custom
specification in a single pass. Our approach involves a meticulous development
and analysis of various input and output formulations for circuit. These
formulations can ensure canonical representations of circuits and align with
the autoregressive nature of LMs to effectively addressing the challenges of
representing analog circuits as graphs. The experimental results show that
LaMAGIC achieves a success rate of up to 96\% under a strict tolerance of 0.01.
We also examine the scalability and adaptability of LaMAGIC, specifically
testing its performance on more complex circuits. Our findings reveal the
enhanced effectiveness of our adjacency matrix-based circuit formulation with
floating-point input, suggesting its suitability for handling intricate circuit
designs. This research not only demonstrates the potential of language models
in graph generation, but also builds a foundational framework for future
explorations in automated analog circuit design.

摘要：在電子和電氣工程領域中，自動化類比電路越來越重要，因為現代應用程式具有複雜且客製化的需求。然而，現有的方法僅開發基於搜尋的演算法，需要許多模擬反覆運算才能設計客製化電路拓撲，這通常是一個耗時的過程。為此，我們引入了 LaMAGIC，一個基於先驅語言模型的拓撲生成模型，它利用監督微調進行自動化類比電路設計。LaMAGIC 可以有效率地從客製化規格中生成最佳化的電路設計，只需一次通過。我們的做法包括仔細開發和分析電路的各種輸入和輸出公式。這些公式可以確保電路的標準表示，並與 LM 的自迴歸性質保持一致，以有效解決將類比電路表示為圖形的挑戰。實驗結果顯示，LaMAGIC 在 0.01 的嚴格容差下實現了高達 96% 的成功率。我們還檢查了 LaMAGIC 的可擴充性和適應性，特別是測試了它在更複雜電路上的效能。我們的研究結果揭示了我們基於鄰接矩陣的電路公式與浮點輸入的增強效能，表明它適用於處理複雜的電路設計。這項研究不僅展示了語言模型在圖形生成中的潛力，也為未來在自動化類比電路設計中的探索建立了基礎框架。

##### **Hierarchical Windowed Graph Attention Network and a Large Scale Dataset for Isolated Indian Sign Language Recognition**
2407.14224v1 by Suvajit Patra, Arkadip Maitra, Megha Tiwari, K. Kumaran, Swathy Prabhu, Swami Punyeshwarananda, Soumitra Samanta

Automatic Sign Language (SL) recognition is an important task in the computer
vision community. To build a robust SL recognition system, we need a
considerable amount of data which is lacking particularly in Indian sign
language (ISL). In this paper, we propose a large-scale isolated ISL dataset
and a novel SL recognition model based on skeleton graph structure. The dataset
covers 2,002 daily used common words in the deaf community recorded by 20 (10
male and 10 female) deaf adult signers (contains 40033 videos). We propose a SL
recognition model namely Hierarchical Windowed Graph Attention Network (HWGAT)
by utilizing the human upper body skeleton graph structure. The HWGAT tries to
capture distinctive motions by giving attention to different body parts induced
by the human skeleton graph structure. The utility of the proposed dataset and
the usefulness of our model are evaluated through extensive experiments. We
pre-trained the proposed model on the proposed dataset and fine-tuned it across
different sign language datasets further boosting the performance of 1.10,
0.46, 0.78, and 6.84 percentage points on INCLUDE, LSA64, AUTSL and WLASL
respectively compared to the existing state-of-the-art skeleton-based models.

摘要：自動手語 (SL) 識別是電腦視覺社群中的重要任務。要建立強健的 SL 識別系統，我們需要大量的資料，而這在印度手語 (ISL) 中特別缺乏。在本文中，我們提出一個大規模的孤立 ISL 資料集，以及一個基於骨架圖結構的新型 SL 識別模型。該資料集涵蓋 2,002 個聾啞社群中常用的日常單字，由 20 位 (10 男 10 女) 聾啞成人手語者錄製（包含 40033 部影片）。我們提出一個 SL 識別模型，即分層視窗圖注意力網路 (HWGAT)，利用人體上半身骨架圖結構。HWGAT 嘗試透過關注由人體骨架圖結構誘導的不同身體部位來捕捉獨特的動作。透過廣泛的實驗評估所提出的資料集的效用和我們模型的有用性。我們在所提出的資料集上預訓練所提出的模型，並在不同的手語資料集上微調它，進一步提升了 INCLUDE、LSA64、AUTSL 和 WLASL 上 1.10、0.46、0.78 和 6.84 個百分點的效能，分別與現有的最先進的基於骨架的模型相比。

##### **Enhancing Data-Limited Graph Neural Networks by Actively Distilling Knowledge from Large Language Models**
2407.13989v1 by Quan Li, Tianxiang Zhao, Lingwei Chen, Junjie Xu, Suhang Wang

Graphs have emerged as critical data structures for content analysis in
various domains, such as social network analysis, bioinformatics, and
recommendation systems. Node classification, a fundamental task in this
context, is typically tackled using graph neural networks (GNNs).
Unfortunately, conventional GNNs still face challenges in scenarios with few
labeled nodes, despite the prevalence of few-shot node classification tasks in
real-world applications. To address this challenge, various approaches have
been proposed, including graph meta-learning, transfer learning, and methods
based on Large Language Models (LLMs). However, traditional meta-learning and
transfer learning methods often require prior knowledge from base classes or
fail to exploit the potential advantages of unlabeled nodes. Meanwhile,
LLM-based methods may overlook the zero-shot capabilities of LLMs and rely
heavily on the quality of generated contexts. In this paper, we propose a novel
approach that integrates LLMs and GNNs, leveraging the zero-shot inference and
reasoning capabilities of LLMs and employing a Graph-LLM-based active learning
paradigm to enhance GNNs' performance. Extensive experiments demonstrate the
effectiveness of our model in improving node classification accuracy with
considerably limited labeled data, surpassing state-of-the-art baselines by
significant margins.

摘要：圖表已成為各種領域中內容分析的關鍵數據結構，例如社交網路分析、生物資訊學和推薦系統。節點分類是此脈絡中的基本任務，通常使用圖形神經網路 (GNN) 來處理。不幸的是，儘管現實世界應用中普遍存在少樣本節點分類任務，但傳統的 GNN 在標記節點很少的情況下仍面臨挑戰。為了應對這一挑戰，已提出各種方法，包括圖形元學習、遷移學習和基於大型語言模型 (LLM) 的方法。然而，傳統的元學習和遷移學習方法通常需要來自基礎類別的先驗知識，或者無法利用未標記節點的潛在優勢。同時，基於 LLM 的方法可能會忽視 LLM 的零樣本能力，並且過度依賴生成語境的品質。在本文中，我們提出了一種新的方法，它整合了 LLM 和 GNN，利用 LLM 的零樣本推論和推理能力，並採用基於 Graph-LLM 的主動學習範例來增強 GNN 的效能。廣泛的實驗證明了我們的模型在改進節點分類準確度方面的有效性，標記數據相當有限，顯著超越了最先進的基準。

##### **A Comprehensive Review of Recommender Systems: Transitioning from Theory to Practice**
2407.13699v1 by Shaina Raza, Mizanur Rahman, Safiullah Kamawal, Armin Toroghi, Ananya Raval, Farshad Navah, Amirmohammad Kazemeini

Recommender Systems (RS) play an integral role in enhancing user experiences
by providing personalized item suggestions. This survey reviews the progress in
RS inclusively from 2017 to 2024, effectively connecting theoretical advances
with practical applications. We explore the development from traditional RS
techniques like content-based and collaborative filtering to advanced methods
involving deep learning, graph-based models, reinforcement learning, and large
language models. We also discuss specialized systems such as context-aware,
review-based, and fairness-aware RS. The primary goal of this survey is to
bridge theory with practice. It addresses challenges across various sectors,
including e-commerce, healthcare, and finance, emphasizing the need for
scalable, real-time, and trustworthy solutions. Through this survey, we promote
stronger partnerships between academic research and industry practices. The
insights offered by this survey aim to guide industry professionals in
optimizing RS deployment and to inspire future research directions, especially
in addressing emerging technological and societal trends

摘要：推薦系統 (RS) 在提升使用者體驗中扮演著不可或缺的角色，透過提供個人化的商品建議。這項調查回顧了 RS 在 2017 年到 2024 年間的進展，有效地將理論進展與實際應用連結起來。我們探討了從傳統的 RS 技術，例如基於內容和協同過濾，到涉及深度學習、基於圖形的模型、強化學習和大語言模型等先進方法的發展。我們也討論了專門的系統，例如情境感知、基於評論和公平感知的 RS。這項調查的主要目標是將理論與實務結合起來。它解決了各個領域的挑戰，包括電子商務、醫療保健和金融，強調了對可擴充、即時和可信賴的解決方案的需求。透過這項調查，我們促進了學術研究和產業實務之間更強大的夥伴關係。這項調查提供的見解旨在引導產業專業人士優化 RS 部署，並激勵未來的研究方向，特別是在解決新興的技術和社會趨勢方面。

##### **MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains**
2407.18961v2 by Guoli Yin, Haoping Bai, Shuang Ma, Feng Nan, Yanchao Sun, Zhaoyang Xu, Shen Ma, Jiarui Lu, Xiang Kong, Aonan Zhang, Dian Ang Yap, Yizhe zhang, Karsten Ahnert, Vik Kamath, Mathias Berglund, Dominic Walsh, Tobias Gindele, Juergen Wiest, Zhengfeng Lai, Xiaoming Wang, Jiulong Shan, Meng Cao, Ruoming Pang, Zirui Wang

Recent advances in large language models (LLMs) have increased the demand for
comprehensive benchmarks to evaluate their capabilities as human-like agents.
Existing benchmarks, while useful, often focus on specific application
scenarios, emphasizing task completion but failing to dissect the underlying
skills that drive these outcomes. This lack of granularity makes it difficult
to deeply discern where failures stem from. Additionally, setting up these
environments requires considerable effort, and issues of unreliability and
reproducibility sometimes arise, especially in interactive tasks. To address
these limitations, we introduce the Massive Multitask Agent Understanding
(MMAU) benchmark, featuring comprehensive offline tasks that eliminate the need
for complex environment setups. It evaluates models across five domains,
including Tool-use, Directed Acyclic Graph (DAG) QA, Data Science and Machine
Learning coding, Contest-level programming and Mathematics, and covers five
essential capabilities: Understanding, Reasoning, Planning, Problem-solving,
and Self-correction. With a total of 20 meticulously designed tasks
encompassing over 3K distinct prompts, MMAU provides a comprehensive framework
for evaluating the strengths and limitations of LLM agents. By testing 18
representative models on MMAU, we provide deep and insightful analyses.
Ultimately, MMAU not only sheds light on the capabilities and limitations of
LLM agents but also enhances the interpretability of their performance.
Datasets and evaluation scripts of MMAU are released at
https://github.com/apple/axlearn/tree/main/docs/research/mmau.

摘要：大型語言模型 (LLM) 的最新進展增加了對全面基準測試的需求，以評估其作為類人代理的能力。現有的基準測試雖然有用，但通常專注於具體的應用場景，強調任務完成，但未能剖析驅動這些結果的底層技能。這種缺乏粒度使得難以深入辨別失敗的根源。此外，設置這些環境需要大量的精力，有時會出現不可靠性和可重複性的問題，特別是在互動任務中。為了解決這些限制，我們引入了大規模多任務代理理解 (MMAU) 基準測試，它具有全面的離線任務，消除了對複雜環境設置的需求。它跨越五個領域評估模型，包括工具使用、有向無環圖 (DAG) 問答、數據科學和機器學習編碼、競賽級編程和數學，並涵蓋五項基本能力：理解、推理、規劃、問題解決和自我糾正。MMAU 總共包含 20 項精心設計的任務，涵蓋超過 3K 個不同的提示，為評估 LLM 代理的優勢和局限性提供了一個全面的框架。通過在 MMAU 上測試 18 個代表性模型，我們提供了深入而有見地的分析。最終，MMAU 不僅闡明了 LLM 代理的能力和局限性，還增強了其性能的可解釋性。MMAU 的數據集和評估腳本已發布在 https://github.com/apple/axlearn/tree/main/docs/research/mmau。

##### **Is Sarcasm Detection A Step-by-Step Reasoning Process in Large Language Models?**
2407.12725v1 by Ben Yao, Yazhou Zhang, Qiuchi Li, Jing Qin

Elaborating a series of intermediate reasoning steps significantly improves
the ability of large language models (LLMs) to solve complex problems, as such
steps would evoke LLMs to think sequentially. However, human sarcasm
understanding is often considered an intuitive and holistic cognitive process,
in which various linguistic, contextual, and emotional cues are integrated to
form a comprehensive understanding of the speaker's true intention, which is
argued not be limited to a step-by-step reasoning process. To verify this
argument, we introduce a new prompting framework called SarcasmCue, which
contains four prompting strategies, $viz.$ chain of contradiction (CoC), graph
of cues (GoC), bagging of cues (BoC) and tensor of cues (ToC), which elicits
LLMs to detect human sarcasm by considering sequential and non-sequential
prompting methods. Through a comprehensive empirical comparison on four
benchmarking datasets, we show that the proposed four prompting methods
outperforms standard IO prompting, CoT and ToT with a considerable margin, and
non-sequential prompting generally outperforms sequential prompting.

摘要：通過闡述一系列中間推理步驟，大幅提升大型語言模型 (LLM) 解決複雜問題的能力，因為這些步驟會促使 LLM 按順序思考。然而，人類的諷刺理解通常被認為是一種直覺且全面的認知過程，其中各種語言、語境和情緒線索整合在一起，以全面了解說話者的真實意圖，這被認為不僅限於循序漸進的推理過程。為了驗證這個論點，我們引入了一個新的提示框架，稱為 SarcasmCue，其中包含四種提示策略，即矛盾鏈 (CoC)、線索圖 (GoC)、線索袋 (BoC) 和線索張量 (ToC)，它引發 LLM 通過考慮順序和非順序提示方法來檢測人類的諷刺。通過對四個基準數據集進行全面的實證比較，我們表明所提出的四種提示方法以相當大的幅度優於標準 IO 提示、CoT 和 ToT，並且非順序提示通常優於順序提示。

##### **Subgraph-Aware Training of Text-based Methods for Knowledge Graph Completion**
2407.12703v3 by Youmin Ko, Hyemin Yang, Taeuk Kim, Hyunjoon Kim

Fine-tuning pre-trained language models (PLMs) has recently shown a potential
to improve knowledge graph completion (KGC). However, most PLM-based methods
encode only textual information, neglecting various topological structures of
knowledge graphs (KGs). In this paper, we empirically validate the significant
relations between the structural properties of KGs and the performance of the
PLM-based methods. To leverage the structural knowledge, we propose a
Subgraph-Aware Training framework for KGC (SATKGC) that combines (i)
subgraph-aware mini-batching to encourage hard negative sampling, and (ii) a
new contrastive learning method to focus more on harder entities and harder
negative triples in terms of the structural properties. To the best of our
knowledge, this is the first study to comprehensively incorporate the
structural inductive bias of the subgraphs into fine-tuning PLMs. Extensive
experiments on four KGC benchmarks demonstrate the superiority of SATKGC. Our
code is available.

摘要：微調預訓練語言模型 (PLM) 近來顯示出改善知識圖譜完成功能 (KGC) 的潛力。然而，大多數基於 PLM 的方法僅編碼文字資訊，忽略了知識圖譜 (KG) 的各種拓撲結構。在本文中，我們透過經驗驗證了 KG 的結構屬性與基於 PLM 的方法效能之間的重要關係。為了利用結構知識，我們提出了一個用於 KGC 的子圖感知訓練架構 (SATKGC)，它結合了：(i) 子圖感知小批次處理以鼓勵困難負面抽樣，以及 (ii) 一種新的對比學習方法，在結構屬性方面更專注於更困難的實體和更困難的負三元組。據我們所知，這是第一個將子圖的結構歸納偏誤全面納入 PLM 微調的研究。在四個 KGC 基準上的廣泛實驗證明了 SATKGC 的優越性。我們的程式碼現已公開。

##### **Abstraction Alignment: Comparing Model and Human Conceptual Relationships**
2407.12543v1 by Angie Boggust, Hyemin Bang, Hendrik Strobelt, Arvind Satyanarayan

Abstraction -- the process of generalizing specific examples into broad
reusable patterns -- is central to how people efficiently process and store
information and apply their knowledge to new data. Promisingly, research has
shown that ML models learn representations that span levels of abstraction,
from specific concepts like "bolo tie" and "car tire" to more general concepts
like "CEO" and "model". However, existing techniques analyze these
representations in isolation, treating learned concepts as independent
artifacts rather than an interconnected web of abstraction. As a result,
although we can identify the concepts a model uses to produce its output, it is
difficult to assess if it has learned a human-aligned abstraction of the
concepts that will generalize to new data. To address this gap, we introduce
abstraction alignment, a methodology to measure the agreement between a model's
learned abstraction and the expected human abstraction. We quantify abstraction
alignment by comparing model outputs against a human abstraction graph, such as
linguistic relationships or medical disease hierarchies. In evaluation tasks
interpreting image models, benchmarking language models, and analyzing medical
datasets, abstraction alignment provides a deeper understanding of model
behavior and dataset content, differentiating errors based on their agreement
with human knowledge, expanding the verbosity of current model quality metrics,
and revealing ways to improve existing human abstractions.

摘要：抽象化——將特定範例概括為廣泛可重複使用的模式的過程——是人們有效處理和儲存資訊，並將其知識應用於新資料的核心。有希望的是，研究顯示 ML 模型學習跨越抽象層級的表徵，從「細領帶」和「汽車輪胎」等具體概念到「執行長」和「模型」等更一般的概念。然而，現有的技術孤立地分析這些表徵，將學習到的概念視為獨立的產物，而不是抽象的相互連結網路。因此，儘管我們可以識別模型用來產生其輸出的概念，但很難評估它是否學習到概念的人類對齊抽象，這些概念將概括到新的資料。為了解決這個差距，我們引入了抽象對齊，一種衡量模型學習的抽象與預期的抽象之間一致性的方法。我們透過將模型輸出與人類抽象圖形（例如語言關係或醫療疾病層級結構）進行比較來量化抽象對齊。在解釋影像模型、基準語言模型和分析醫療資料集的評估任務中，抽象對齊提供了對模型行為和資料集內容更深入的理解，根據與人類知識的一致性區分錯誤，擴展當前模型品質指標的詳細程度，並揭示改善現有人類抽象的方法。

##### **Struct-X: Enhancing Large Language Models Reasoning with Structured Data**
2407.12522v1 by Xiaoyu Tan, Haoyu Wang, Xihe Qiu, Yuan Cheng, Yinghui Xu, Wei Chu, Yuan Qi

Structured data, rich in logical and relational information, has the
potential to enhance the reasoning abilities of large language models (LLMs).
Still, its integration poses a challenge due to the risk of overwhelming LLMs
with excessive tokens and irrelevant context information. To address this, we
propose Struct-X, a novel framework that operates through five key phases:
``read-model-fill-reflect-reason'' efficiently enabling LLMs to utilize
structured data. It begins by encoding structured data into a topological space
using graph embeddings, followed by filling in missing entity information with
knowledge retrieval modules, and filtering out irrelevant tokens via a
self-supervised module. The final phase involves constructing a topological
network with selected tokens to further reduce the total token length for more
effective LLM inference. Additionally, Struct-X includes an Auxiliary Module
trained to generate prompts, aiding LLMs in analyzing structured data.
Extensive experiments on benchmarks, including the knowledge graph
question-answer task and the long document reading comprehension task, show
that Struct-X notably improves LLM reasoning, demonstrating the effectiveness
of structured data augmentation in improving LLM inference with complex input
context.

摘要：結構化資料富含邏輯和關係資訊，有潛力增強大型語言模型 (LLM) 的推理能力。儘管如此，由於過多符號和無關脈絡資訊可能會讓 LLM 不堪負荷，因此整合此類資料構成了一項挑戰。為了解決此問題，我們提出 Struct-X，這是一個透過五個關鍵階段運作的新穎架構：``讀取-建模-填補-反思-推理''，有效地讓 LLM 能夠利用結構化資料。它首先使用圖形嵌入將結構化資料編碼到拓撲空間中，接著利用知識擷取模組填補遺失的實體資訊，並透過自我監督模組篩選出無關符號。最後一個階段涉及建構一個拓撲網路，其中包含選定的符號，以進一步減少總符號長度，以便更有效地進行 LLM 推論。此外，Struct-X 還包括一個輔助模組，經過訓練可以產生提示，協助 LLM 分析結構化資料。在基準上的大量實驗，包括知識圖譜問答任務和長篇文件閱讀理解任務，顯示 Struct-X 明顯改善了 LLM 推理，證明了結構化資料擴充在改善 LLM 推論時的有效性，特別是在輸入脈絡複雜的情況下。

##### **Explainable Biomedical Hypothesis Generation via Retrieval Augmented Generation enabled Large Language Models**
2407.12888v1 by Alexander R. Pelletier, Joseph Ramirez, Irsyad Adam, Simha Sankar, Yu Yan, Ding Wang, Dylan Steinecke, Wei Wang, Peipei Ping

The vast amount of biomedical information available today presents a
significant challenge for investigators seeking to digest, process, and
understand these findings effectively. Large Language Models (LLMs) have
emerged as powerful tools to navigate this complex and challenging data
landscape. However, LLMs may lead to hallucinatory responses, making Retrieval
Augmented Generation (RAG) crucial for achieving accurate information. In this
protocol, we present RUGGED (Retrieval Under Graph-Guided Explainable disease
Distinction), a comprehensive workflow designed to support investigators with
knowledge integration and hypothesis generation, identifying validated paths
forward. Relevant biomedical information from publications and knowledge bases
are reviewed, integrated, and extracted via text-mining association analysis
and explainable graph prediction models on disease nodes, forecasting potential
links among drugs and diseases. These analyses, along with biomedical texts,
are integrated into a framework that facilitates user-directed mechanism
elucidation as well as hypothesis exploration through RAG-enabled LLMs. A
clinical use-case demonstrates RUGGED's ability to evaluate and recommend
therapeutics for Arrhythmogenic Cardiomyopathy (ACM) and Dilated Cardiomyopathy
(DCM), analyzing prescribed drugs for molecular interactions and unexplored
uses. The platform minimizes LLM hallucinations, offers actionable insights,
and improves the investigation of novel therapeutics.

摘要：<paragraph>現今大量的生物醫學資訊對試圖有效消化、處理和理解這些發現的研究人員構成重大挑戰。大型語言模型 (LLM) 已成為在這個複雜且具挑戰性的資料環境中導航的強大工具。然而，LLM 可能會導致幻覺反應，這使得檢索擴增生成 (RAG) 對於獲得準確資訊至關重要。在這個協定中，我們提出 RUGGED（圖形導引可解釋疾病區分的檢索），這是一個全面的工作流程，旨在支援研究人員進行知識整合和假設產生，找出經過驗證的進展路徑。來自出版物和知識庫的相關生物醫學資訊會透過文本探勘關聯分析和疾病節點的可解釋圖形預測模型進行檢閱、整合和萃取，預測藥物和疾病之間的潛在關聯。這些分析連同生物醫學文本會整合到一個架構中，該架構促進使用者導向的機制闡明，以及透過 RAG 啟用的 LLM 進行假設探討。一個臨床使用案例展示了 RUGGED 評估和推薦用於心律失常性心肌病變 (ACM) 和擴張型心肌病變 (DCM) 的治療方法的能力，分析處方藥物的分子交互作用和未探索的用途。這個平台將 LLM 幻覺降到最低，提供可操作的見解，並改善新治療方法的研究。</paragraph>

##### **A Comprehensive Evaluation of Large Language Models on Temporal Event Forecasting**
2407.11638v1 by He Chang, Chenchen Ye, Zhulin Tao, Jie Wu, Zhengmao Yang, Yunshan Ma, Xianglin Huang, Tat-Seng Chua

Recently, Large Language Models (LLMs) have demonstrated great potential in
various data mining tasks, such as knowledge question answering, mathematical
reasoning, and commonsense reasoning. However, the reasoning capability of LLMs
on temporal event forecasting has been under-explored. To systematically
investigate their abilities in temporal event forecasting, we conduct a
comprehensive evaluation of LLM-based methods for temporal event forecasting.
Due to the lack of a high-quality dataset that involves both graph and textual
data, we first construct a benchmark dataset, named MidEast-TE-mini. Based on
this dataset, we design a series of baseline methods, characterized by various
input formats and retrieval augmented generation(RAG) modules. From extensive
experiments, we find that directly integrating raw texts into the input of LLMs
does not enhance zero-shot extrapolation performance. In contrast,
incorporating raw texts in specific complex events and fine-tuning LLMs
significantly improves performance. Moreover, enhanced with retrieval modules,
LLM can effectively capture temporal relational patterns hidden in historical
events. Meanwhile, issues such as popularity bias and the long-tail problem
still persist in LLMs, particularly in the RAG-based method. These findings not
only deepen our understanding of LLM-based event forecasting methods but also
highlight several promising research directions.We consider that this
comprehensive evaluation, along with the identified research opportunities,
will significantly contribute to future research on temporal event forecasting
through LLMs.

摘要：近期，大型语言模型 (LLM) 在各种资料探勘任务中展现出极大的潜力，例如知识问答、数学推理和常识推理。然而，LLM 在时间事件预测方面的推理能力尚未被充分探索。为了系统性地调查其在时间事件预测方面的能力，我们对基于 LLM 的时间事件预测方法进行了全面的评估。由于缺乏同时包含图表和文本资料的高品质数据集，我们首先构建了一个名为 MidEast-TE-mini 的基准数据集。基于此数据集，我们设计了一系列基线方法，其特点是各种输入格式和检索增强生成 (RAG) 模块。从广泛的实验中，我们发现直接将原始文本整合到 LLM 的输入中并不会增强零次学习外推性能。相比之下，在特定复杂事件中纳入原始文本并微调 LLM 会显著提高性能。此外，通过检索模块的增强，LLM 可以有效地捕捉隐藏在历史事件中的时间关系模式。同时，诸如流行度偏差和长尾问题等问题仍然存在于 LLM 中，尤其是在基于 RAG 的方法中。这些发现不仅加深了我们对基于 LLM 的事件预测方法的理解，还突出了几个有前景的研究方向。我们认为，这项全面的评估，连同已确定的研究机会，将极大地促进通过 LLM 进行时间事件预测的未来研究。

##### **Learning on Graphs with Large Language Models(LLMs): A Deep Dive into Model Robustness**
2407.12068v2 by Kai Guo, Zewen Liu, Zhikai Chen, Hongzhi Wen, Wei Jin, Jiliang Tang, Yi Chang

Large Language Models (LLMs) have demonstrated remarkable performance across
various natural language processing tasks. Recently, several LLMs-based
pipelines have been developed to enhance learning on graphs with text
attributes, showcasing promising performance. However, graphs are well-known to
be susceptible to adversarial attacks and it remains unclear whether LLMs
exhibit robustness in learning on graphs. To address this gap, our work aims to
explore the potential of LLMs in the context of adversarial attacks on graphs.
Specifically, we investigate the robustness against graph structural and
textual perturbations in terms of two dimensions: LLMs-as-Enhancers and
LLMs-as-Predictors. Through extensive experiments, we find that, compared to
shallow models, both LLMs-as-Enhancers and LLMs-as-Predictors offer superior
robustness against structural and textual attacks.Based on these findings, we
carried out additional analyses to investigate the underlying causes.
Furthermore, we have made our benchmark library openly available to facilitate
quick and fair evaluations, and to encourage ongoing innovative research in
this field.

摘要：大型語言模型 (LLM) 在各種自然語言處理任務中都展現出卓越的效能。最近，已開發出多個基於 LLM 的管道，以增強具有文字屬性的圖形學習，展現出令人滿意的效能。然而，圖形容易受到對抗性攻擊，而 LLM 在圖形學習中是否展現出穩健性仍不清楚。為了解決這個差距，我們的研究旨在探討 LLM 在圖形對抗性攻擊中的潛力。具體來說，我們針對兩個面向探討其對圖形結構和文字擾動的穩健性：LLM 作為增強器和 LLM 作為預測器。透過廣泛的實驗，我們發現，與淺層模型相比，LLM 作為增強器和 LLM 作為預測器在結構性和文字攻擊中都提供優異的穩健性。根據這些發現，我們進行了額外的分析來探討其根本原因。此外，我們已公開我們的基準庫，以利快速且公平的評估，並鼓勵持續進行這方面的創新研究。

##### **CIC-BART-SSA: Controllable Image Captioning with Structured Semantic Augmentation**
2407.11393v2 by Kalliopi Basioti, Mohamed A. Abdelsalam, Federico Fancellu, Vladimir Pavlovic, Afsaneh Fazly

Controllable Image Captioning (CIC) aims at generating natural language
descriptions for an image, conditioned on information provided by end users,
e.g., regions, entities or events of interest. However, available
image-language datasets mainly contain captions that describe the entirety of
an image, making them ineffective for training CIC models that can potentially
attend to any subset of regions or relationships. To tackle this challenge, we
propose a novel, fully automatic method to sample additional focused and
visually grounded captions using a unified structured semantic representation
built on top of the existing set of captions associated with an image. We
leverage Abstract Meaning Representation (AMR), a cross-lingual graph-based
semantic formalism, to encode all possible spatio-semantic relations between
entities, beyond the typical spatial-relations-only focus of current methods.
We use this Structured Semantic Augmentation (SSA) framework to augment
existing image-caption datasets with the grounded controlled captions,
increasing their spatial and semantic diversity and focal coverage. We then
develop a new model, CIC-BART-SSA, specifically tailored for the CIC task, that
sources its control signals from SSA-diversified datasets. We empirically show
that, compared to SOTA CIC models, CIC-BART-SSA generates captions that are
superior in diversity and text quality, are competitive in controllability,
and, importantly, minimize the gap between broad and highly focused controlled
captioning performance by efficiently generalizing to the challenging highly
focused scenarios. Code is available at
https://github.com/SamsungLabs/CIC-BART-SSA.

摘要：可控图像标注 (CIC) 旨在生成自然语言描述以描述图像，条件是根据最终用户提供的资讯，例如区域、实体或感兴趣的事件。然而，现有的图像语言数据集主要包含描述整个图像的标注，使其无法有效训练 CIC 模型，而这些模型有可能关注任何区域或关系的子集。为了应对这一挑战，我们提出了一种新颖的、全自动的方法，使用建立在与图像关联的现有标注集之上的统一结构化语义表示来抽样其他聚焦且视觉接地的标注。我们利用跨语言图式语义形式化抽象意义表示 (AMR) 来编码实体之间所有可能的空间语义关系，而不仅仅是当前方法中仅关注的空间关系。我们使用这种结构化语义增强 (SSA) 框架来增强现有的图像标注数据集，使其接地且可控的标注，增加它们的空间和语义多样性以及焦点覆盖范围。然后，我们开发了一个新模型 CIC-BART-SSA，专门针对 CIC 任务量身定制，其控制信号来自 SSA 多样化的数据集。我们凭经验表明，与 SOTA CIC 模型相比，CIC-BART-SSA 生成的标注在多样性和文本质量方面更胜一筹，在可控性方面具有竞争力，而且重要的是，通过有效地推广到具有挑战性的高度聚焦场景，最大限度地缩小了广泛和高度聚焦的受控标注性能之间的差距。代码可从 https://github.com/SamsungLabs/CIC-BART-SSA 获得。

##### **Think-on-Graph 2.0: Deep and Interpretable Large Language Model Reasoning with Knowledge Graph-guided Retrieval**
2407.10805v3 by Shengjie Ma, Chengjin Xu, Xuhui Jiang, Muzhi Li, Huaren Qu, Jian Guo

Retrieval-augmented generation (RAG) has significantly advanced large
language models (LLMs) by enabling dynamic information retrieval to mitigate
knowledge gaps and hallucinations in generated content. However, these systems
often falter with complex reasoning and consistency across diverse queries. In
this work, we present Think-on-Graph 2.0, an enhanced RAG framework that aligns
questions with the knowledge graph and uses it as a navigational tool, which
deepens and refines the RAG paradigm for information collection and
integration. The KG-guided navigation fosters deep and long-range associations
to uphold logical consistency and optimize the scope of retrieval for precision
and interoperability. In conjunction, factual consistency can be better ensured
through semantic similarity guided by precise directives. ToG${2.0}$ not only
improves the accuracy and reliability of LLMs' responses but also demonstrates
the potential of hybrid structured knowledge systems to significantly advance
LLM reasoning, aligning it closer to human-like performance. We conducted
extensive experiments on four public datasets to demonstrate the advantages of
our method compared to the baseline.

摘要：檢索增強生成 (RAG) 已大幅提升大型語言模型 (LLM)，藉由啟用動態資訊檢索來減輕產生內容中的知識差距和幻覺。然而，這些系統在複雜推理和不同查詢間的一致性方面經常會出錯。在本文中，我們提出 Think-on-Graph 2.0，一個增強的 RAG 架構，它會將問題與知識圖譜對齊，並將其用作導航工具，這會加深和改善 RAG 典範以進行資訊收集和整合。KG 引導的導航促進深度且長程關聯，以維持邏輯一致性，並最佳化檢索範圍以提升精準度和互操作性。結合使用，事實一致性可透過由精確指示引導的語義相似性獲得更好的確保。ToG${2.0}$ 不僅提升 LLM 回應的準確度和可靠度，也證明混合結構化知識系統有潛力大幅提升 LLM 推理，使其更接近人類般的表現。我們在四個公開資料集上進行廣泛的實驗，以證明我們的方法優於基線。

##### **Graphusion: Leveraging Large Language Models for Scientific Knowledge Graph Fusion and Construction in NLP Education**
2407.10794v1 by Rui Yang, Boming Yang, Sixun Ouyang, Tianwei She, Aosong Feng, Yuang Jiang, Freddy Lecue, Jinghui Lu, Irene Li

Knowledge graphs (KGs) are crucial in the field of artificial intelligence
and are widely applied in downstream tasks, such as enhancing Question
Answering (QA) systems. The construction of KGs typically requires significant
effort from domain experts. Recently, Large Language Models (LLMs) have been
used for knowledge graph construction (KGC), however, most existing approaches
focus on a local perspective, extracting knowledge triplets from individual
sentences or documents. In this work, we introduce Graphusion, a zero-shot KGC
framework from free text. The core fusion module provides a global view of
triplets, incorporating entity merging, conflict resolution, and novel triplet
discovery. We showcase how Graphusion could be applied to the natural language
processing (NLP) domain and validate it in the educational scenario.
Specifically, we introduce TutorQA, a new expert-verified benchmark for graph
reasoning and QA, comprising six tasks and a total of 1,200 QA pairs. Our
evaluation demonstrates that Graphusion surpasses supervised baselines by up to
10% in accuracy on link prediction. Additionally, it achieves average scores of
2.92 and 2.37 out of 3 in human evaluations for concept entity extraction and
relation recognition, respectively.

摘要：<paragraph>知識圖譜 (KG) 在人工智慧領域至關重要，並廣泛應用於下游任務，例如增強問答 (QA) 系統。知識圖譜的建構通常需要領域專家的大量工作。最近，大型語言模型 (LLM) 已被用於知識圖譜建構 (KGC)，然而，現有方法大多關注局部觀點，從個別句子或文件中提取知識三元組。在這項工作中，我們介紹了 Graphusion，一個從自由文本中進行零次學習的 KGC 框架。核心融合模組提供三元組的全局觀點，包含實體合併、衝突解決和新三元組發現。我們展示了如何將 Graphusion 應用於自然語言處理 (NLP) 領域，並在教育場景中驗證它。具體來說，我們介紹了 TutorQA，一個新的由專家驗證的圖譜推理和問答基準，包含六項任務和總計 1,200 個問答對。我們的評估表明，Graphusion 在連結預測的準確度上比監督式基準高出 10%。此外，在概念實體提取和關係識別的人類評估中，它分別獲得了 3 分中的 2.92 分和 2.37 分。</paragraph>

##### **GraphEval: A Knowledge-Graph Based LLM Hallucination Evaluation Framework**
2407.10793v1 by Hannah Sansford, Nicholas Richardson, Hermina Petric Maretic, Juba Nait Saada

Methods to evaluate Large Language Model (LLM) responses and detect
inconsistencies, also known as hallucinations, with respect to the provided
knowledge, are becoming increasingly important for LLM applications. Current
metrics fall short in their ability to provide explainable decisions,
systematically check all pieces of information in the response, and are often
too computationally expensive to be used in practice. We present GraphEval: a
hallucination evaluation framework based on representing information in
Knowledge Graph (KG) structures. Our method identifies the specific triples in
the KG that are prone to hallucinations and hence provides more insight into
where in the response a hallucination has occurred, if at all, than previous
methods. Furthermore, using our approach in conjunction with state-of-the-art
natural language inference (NLI) models leads to an improvement in balanced
accuracy on various hallucination benchmarks, compared to using the raw NLI
models. Lastly, we explore the use of GraphEval for hallucination correction by
leveraging the structure of the KG, a method we name GraphCorrect, and
demonstrate that the majority of hallucinations can indeed be rectified.

摘要：大型語言模型 (LLM) 回應評估方法和不一致性偵測（又稱為幻覺），相對於所提供的知識，對於 LLM 應用正變得越來越重要。目前的指標無法提供可解釋的決策、系統性地檢查回應中的所有資訊，而且在實務上使用時，通常過於耗費運算資源。我們提出 GraphEval：一個基於知識圖 (KG) 結構來表示資訊的幻覺評估架構。我們的技術識別出容易出現幻覺的 KG 中特定三元組，因此比以往的方法更深入地了解回應中幻覺發生在哪裡（如果有的話）。此外，將我們的方法與最先進的自然語言推論 (NLI) 模型結合使用，與使用原始 NLI 模型相比，可以在各種幻覺基準上提高平衡準確度。最後，我們探索使用 GraphEval 來進行幻覺修正，方法是利用 KG 的結構，我們將此方法命名為 GraphCorrect，並證明大多數幻覺確實可以得到糾正。

##### **Scaling 3D Reasoning with LMMs to Large Robot Mission Environments Using Datagraphs**
2407.10743v1 by W. J. Meijer, A. C. Kemmeren, E. H. J. Riemens, J. E. Fransman, M. van Bekkum, G. J. Burghouts, J. D. van Mil

This paper addresses the challenge of scaling Large Multimodal Models (LMMs)
to expansive 3D environments. Solving this open problem is especially relevant
for robot deployment in many first-responder scenarios, such as
search-and-rescue missions that cover vast spaces. The use of LMMs in these
settings is currently hampered by the strict context windows that limit the
LMM's input size. We therefore introduce a novel approach that utilizes a
datagraph structure, which allows the LMM to iteratively query smaller sections
of a large environment. Using the datagraph in conjunction with graph traversal
algorithms, we can prioritize the most relevant locations to the query, thereby
improving the scalability of 3D scene language tasks. We illustrate the
datagraph using 3D scenes, but these can be easily substituted by other dense
modalities that represent the environment, such as pointclouds or Gaussian
splats. We demonstrate the potential to use the datagraph for two 3D scene
language task use cases, in a search-and-rescue mission example.

摘要：本文討論了將大型多模態模型 (LMM) 擴展到廣闊 3D 環境的挑戰。解決這個開放性問題對於機器人在許多第一反應人員場景中的部署特別相關，例如涵蓋廣闊空間的搜救任務。這些設定中使用 LMM 目前受到嚴格的上下文視窗限制，這限制了 LMM 的輸入大小。因此，我們引入了一種新穎的方法，該方法利用資料圖結構，允許 LMM 迭代查詢大型環境的較小部分。透過將資料圖與圖形遍歷演算法結合使用，我們可以優先考慮與查詢最相關的位置，從而提高 3D 場景語言任務的可擴充性。我們使用 3D 場景說明資料圖，但這些場景可以輕鬆地由其他表示環境的密集模式取代，例如點雲或高斯點。我們展示了在搜救任務範例中使用資料圖進行兩個 3D 場景語言任務用例的潛力。

##### **AutoGRAMS: Autonomous Graphical Agent Modeling Software**
2407.10049v1 by Ben Krause, Lucia Chen, Emmanuel Kahembwe

We introduce the AutoGRAMS framework for programming multi-step interactions
with language models. AutoGRAMS represents AI agents as a graph, where each
node can execute either a language modeling instruction or traditional code.
Likewise, transitions in the graph can be governed by either language modeling
decisions or traditional branch logic. AutoGRAMS supports using variables as
memory and allows nodes to call other AutoGRAMS graphs as functions. We show
how AutoGRAMS can be used to design highly sophisticated agents, including
self-referential agents that can modify their own graph. AutoGRAMS's
graph-centric approach aids interpretability, controllability, and safety
during the design, development, and deployment of AI agents. We provide our
framework as open source at https://github.com/autograms/autograms .

摘要：我們介紹 AutoGRAMS 框架，用於編寫與語言模型的多步驟互動。AutoGRAMS 將 AI 代理表示為一個圖形，其中每個節點可以執行語言建模指令或傳統代碼。同樣地，圖形中的轉換可以由語言建模決策或傳統分支邏輯控制。AutoGRAMS 支援使用變數作為記憶體，並允許節點呼叫其他 AutoGRAMS 圖形作為函式。我們展示如何使用 AutoGRAMS 設計高度複雜的代理，包括可以修改自身圖形的自參照代理。AutoGRAMS 以圖形為中心的方法有助於在 AI 代理的設計、開發和部署過程中提高可解釋性、可控性和安全性。我們在 https://github.com/autograms/autograms 提供我們的框架作為開源。

##### **FarFetched: Entity-centric Reasoning and Claim Validation for the Greek Language based on Textually Represented Environments**
2407.09888v1 by Dimitris Papadopoulos, Katerina Metropoulou, Nikolaos Matsatsinis, Nikolaos Papadakis

Our collective attention span is shortened by the flood of online
information. With \textit{FarFetched}, we address the need for automated claim
validation based on the aggregated evidence derived from multiple online news
sources. We introduce an entity-centric reasoning framework in which latent
connections between events, actions, or statements are revealed via entity
mentions and represented in a graph database. Using entity linking and semantic
similarity, we offer a way for collecting and combining information from
diverse sources in order to generate evidence relevant to the user's claim.
Then, we leverage textual entailment recognition to quantitatively determine
whether this assertion is credible, based on the created evidence. Our approach
tries to fill the gap in automated claim validation for less-resourced
languages and is showcased on the Greek language, complemented by the training
of relevant semantic textual similarity (STS) and natural language inference
(NLI) models that are evaluated on translated versions of common benchmarks.

摘要：網路資訊的洪流縮短了我們的集體注意力時間。透過 \textit{FarFetched}，我們解決了根據從多個線上新聞來源彙總的證據進行自動化聲明驗證的需求。我們引入了一個以實體為中心的推理框架，其中事件、動作或陳述之間的潛在關聯透過實體提及被揭露，並在圖形資料庫中表示。使用實體連結和語義相似性，我們提供一種方式來收集和組合來自不同來源的資訊，以產生與使用者聲明相關的證據。然後，我們利用文本蘊涵識別來根據建立的證據量化確定此斷言是否可信。我們的做法試圖填補資源較少的語言的自動化聲明驗證方面的空白，並在希臘語中展示，輔以對相關語義文本相似性 (STS) 和自然語言推論 (NLI) 模型的訓練，這些模型在常見基準的翻譯版本上進行評估。

##### **GOFA: A Generative One-For-All Model for Joint Graph Language Modeling**
2407.09709v1 by Lecheng Kong, Jiarui Feng, Hao Liu, Chengsong Huang, Jiaxin Huang, Yixin Chen, Muhan Zhang

Foundation models, such as Large Language Models (LLMs) or Large Vision
Models (LVMs), have emerged as one of the most powerful tools in the respective
fields. However, unlike text and image data, graph data do not have a
definitive structure, posing great challenges to developing a Graph Foundation
Model (GFM). For example, current attempts at designing general graph models
either transform graph data into a language format for LLM-based prediction or
still train a GNN model with LLM as an assistant. The former can handle
unlimited tasks, while the latter captures graph structure much better -- yet,
no existing work can achieve both simultaneously. In this paper, we identify
three key desirable properties of a GFM: self-supervised pretraining, fluidity
in tasks, and graph awareness. To account for these properties, we extend the
conventional language modeling to the graph domain and propose a novel
generative graph language model GOFA to solve the problem. The model
interleaves randomly initialized GNN layers into a frozen pre-trained LLM so
that the semantic and structural modeling abilities are organically combined.
GOFA is pre-trained on newly proposed graph-level next-word prediction,
question-answering, and structural tasks to obtain the above GFM properties.
The pre-trained model is further fine-tuned on downstream tasks to obtain
task-solving ability. The fine-tuned model is evaluated on various downstream
tasks, demonstrating a strong ability to solve structural and contextual
problems in zero-shot scenarios. The code is available at
https://github.com/JiaruiFeng/GOFA.

摘要：基礎模型，例如大型語言模型 (LLM) 或大型視覺模型 (LVM)，已成為各自領域中最有力的工具之一。然而，與文本和影像資料不同，圖形資料沒有明確的結構，對開發圖形基礎模型 (GFM) 構成極大的挑戰。例如，目前設計通用圖形模型的嘗試，不是將圖形資料轉換為語言格式以供基於 LLM 的預測，就是訓練 GNN 模型，並以 LLM 作為輔助。前者可以處理無限的任務，而後者可以更好地擷取圖形結構，但現有的工作無法同時達成這兩者。在本文中，我們找出 GFM 的三個關鍵理想特性：自我監督預訓練、任務流暢度和圖形感知。為了考量這些特性，我們將傳統的語言建模擴充到圖形領域，並提出一個新穎的生成式圖形語言模型 GOFA 來解決問題。此模型將隨機初始化的 GNN 層交錯插入凍結的預訓練 LLM 中，以便語意和結構建模能力有機結合。GOFA 採用新提出的圖形層級下一個字預測、問答和結構任務進行預訓練，以取得上述 GFM 特性。預訓練模型進一步在下游任務上進行微調，以取得解決任務的能力。微調模型在各種下游任務上進行評估，證明了在零次學習場景中解決結構和上下文問題的強大能力。程式碼可在 https://github.com/JiaruiFeng/GOFA 取得。

##### **Human-like Episodic Memory for Infinite Context LLMs**
2407.09450v1 by Zafeirios Fountas, Martin A Benfeghoul, Adnan Oomerjee, Fenia Christopoulou, Gerasimos Lampouras, Haitham Bou-Ammar, Jun Wang

Large language models (LLMs) have shown remarkable capabilities, but still
struggle with processing extensive contexts, limiting their ability to maintain
coherence and accuracy over long sequences. In contrast, the human brain excels
at organising and retrieving episodic experiences across vast temporal scales,
spanning a lifetime. In this work, we introduce EM-LLM, a novel approach that
integrates key aspects of human episodic memory and event cognition into LLMs,
enabling them to effectively handle practically infinite context lengths while
maintaining computational efficiency. EM-LLM organises sequences of tokens into
coherent episodic events using a combination of Bayesian surprise and
graph-theoretic boundary refinement in an on-line fashion. When needed, these
events are retrieved through a two-stage memory process, combining
similarity-based and temporally contiguous retrieval for efficient and
human-like access to relevant information. Experiments on the LongBench dataset
demonstrate EM-LLM's superior performance, outperforming the state-of-the-art
InfLLM model with an overall relative improvement of 4.3% across various tasks,
including a 33% improvement on the PassageRetrieval task. Furthermore, our
analysis reveals strong correlations between EM-LLM's event segmentation and
human-perceived events, suggesting a bridge between this artificial system and
its biological counterpart. This work not only advances LLM capabilities in
processing extended contexts but also provides a computational framework for
exploring human memory mechanisms, opening new avenues for interdisciplinary
research in AI and cognitive science.

摘要：大型語言模型 (LLM) 已展現出非凡的能力，但仍難以處理廣泛的脈絡，這限制了它們在長序列中維持連貫性和準確性的能力。相較之下，人腦擅長在廣大的時間尺度上組織和提取情節體驗，跨越一生。在這項工作中，我們引入了 EM-LLM，這是一種新穎的方法，它將人類情節記憶和事件認知的關鍵面向整合到 LLM 中，讓它們能夠有效地處理實際上無限的脈絡長度，同時維持運算效率。EM-LLM 使用貝氏驚喜和圖論邊界精煉的組合，以線上方式將序列標記組織成連貫的情節事件。在需要時，這些事件會透過兩階段的記憶過程來提取，結合基於相似性和時間連續性的提取，以有效且類似人類的方式存取相關資訊。在 LongBench 資料集上的實驗證明了 EM-LLM 的卓越效能，在各種任務中優於最先進的 InfLLM 模型，在 PassageRetrieval 任務中改進了 33%。此外，我們的分析揭示了 EM-LLM 的事件分割與人類感知事件之間的強相關性，顯示了這個人工系統與其生物對應物之間的橋樑。這項工作不僅提升了 LLM 在處理延伸脈絡方面的能力，也提供了一個運算架構來探索人類記憶機制，為 AI 和認知科學的跨領域研究開啟了新的途徑。

##### **The $μ\mathcal{G}$ Language for Programming Graph Neural Networks**
2407.09441v1 by Matteo Belenchia, Flavio Corradini, Michela Quadrini, Michele Loreti

Graph neural networks form a class of deep learning architectures
specifically designed to work with graph-structured data. As such, they share
the inherent limitations and problems of deep learning, especially regarding
the issues of explainability and trustworthiness. We propose $\mu\mathcal{G}$,
an original domain-specific language for the specification of graph neural
networks that aims to overcome these issues. The language's syntax is
introduced, and its meaning is rigorously defined by a denotational semantics.
An equivalent characterization in the form of an operational semantics is also
provided and, together with a type system, is used to prove the type soundness
of $\mu\mathcal{G}$. We show how $\mu\mathcal{G}$ programs can be represented
in a more user-friendly graphical visualization, and provide examples of its
generality by showing how it can be used to define some of the most popular
graph neural network models, or to develop any custom graph processing
application.

摘要：圖形神經網路形成一類深度學習架構，特別設計用於處理圖形結構化的資料。因此，它們具有深度學習固有的限制和問題，特別是在可解釋性和可信賴性問題上。我們提出 $\mu\mathcal{G}$，一種用於指定圖形神經網路的原創領域特定語言，旨在克服這些問題。引入了語言的語法，並透過指示語義嚴格定義其含義。還提供了運算語義形式的等效特徵描述，並與類型系統一起用於證明 $\mu\mathcal{G}$ 的類型健全性。我們展示了如何將 $\mu\mathcal{G}$ 程式表示為更友善的圖形視覺化，並透過展示如何使用它定義一些最流行的圖形神經網路模型或開發任何自訂圖形處理應用程式，來提供其通用性的範例。

##### **Towards More Trustworthy and Interpretable LLMs for Code through Syntax-Grounded Explanations**
2407.08983v1 by David N. Palacio, Daniel Rodriguez-Cardenas, Alejandro Velasco, Dipin Khati, Kevin Moran, Denys Poshyvanyk

Trustworthiness and interpretability are inextricably linked concepts for
LLMs. The more interpretable an LLM is, the more trustworthy it becomes.
However, current techniques for interpreting LLMs when applied to code-related
tasks largely focus on accuracy measurements, measures of how models react to
change, or individual task performance instead of the fine-grained explanations
needed at prediction time for greater interpretability, and hence trust. To
improve upon this status quo, this paper introduces ASTrust, an
interpretability method for LLMs of code that generates explanations grounded
in the relationship between model confidence and syntactic structures of
programming languages. ASTrust explains generated code in the context of syntax
categories based on Abstract Syntax Trees and aids practitioners in
understanding model predictions at both local (individual code snippets) and
global (larger datasets of code) levels. By distributing and assigning model
confidence scores to well-known syntactic structures that exist within ASTs,
our approach moves beyond prior techniques that perform token-level confidence
mapping by offering a view of model confidence that directly aligns with
programming language concepts with which developers are familiar. To put
ASTrust into practice, we developed an automated visualization that illustrates
the aggregated model confidence scores superimposed on sequence, heat-map, and
graph-based visuals of syntactic structures from ASTs. We examine both the
practical benefit that ASTrust can provide through a data science study on 12
popular LLMs on a curated set of GitHub repos and the usefulness of ASTrust
through a human study.

摘要：可信度和可解釋性是 LLM 中密不可分的概念。LLM 的可解釋性越高，它的可信度就越高。然而，當應用於與程式碼相關的任務時，目前解釋 LLM 的技術主要集中在準確性測量、模型對變化的反應測量或個別任務表現，而不是在預測時間所需的細粒度解釋，從而提高可解釋性和因此提高信任度。為了改善這種現狀，本文介紹了 ASTrust，這是一種用於程式碼 LLM 的可解釋性方法，它會根據模型信心與程式語言的語法結構之間的關係產生解釋。ASTrust 在基於抽象語法樹的語法類別的上下文中解釋產生的程式碼，並幫助實務人員在局部（個別程式碼片段）和全域（較大的程式碼資料集）層級了解模型預測。透過將模型信心分數分配和指定給 AST 中存在的眾所周知的語法結構，我們的做法超越了先前的技術，這些技術透過提供與開發人員熟悉的程式語言概念直接對齊的模型信心視圖來執行令牌級別的信心對應。為了實踐 ASTrust，我們開發了一個自動化視覺化工具，它說明了疊加在 AST 語法結構的序列、熱圖和基於圖形的視覺效果上的聚合模型信心分數。我們檢查了 ASTrust 可以透過對 12 個流行的 LLM 在一組精選的 GitHub 儲存庫上進行資料科學研究提供的實際好處，以及透過人體研究提供的 ASTrust 的有用性。

##### **Domain-Hierarchy Adaptation via Chain of Iterative Reasoning for Few-shot Hierarchical Text Classification**
2407.08959v1 by Ke Ji, Peng Wang, Wenjun Ke, Guozheng Li, Jiajun Liu, Jingsheng Gao, Ziyu Shang

Recently, various pre-trained language models (PLMs) have been proposed to
prove their impressive performances on a wide range of few-shot tasks. However,
limited by the unstructured prior knowledge in PLMs, it is difficult to
maintain consistent performance on complex structured scenarios, such as
hierarchical text classification (HTC), especially when the downstream data is
extremely scarce. The main challenge is how to transfer the unstructured
semantic space in PLMs to the downstream domain hierarchy. Unlike previous work
on HTC which directly performs multi-label classification or uses graph neural
network (GNN) to inject label hierarchy, in this work, we study the HTC problem
under a few-shot setting to adapt knowledge in PLMs from an unstructured manner
to the downstream hierarchy. Technically, we design a simple yet effective
method named Hierarchical Iterative Conditional Random Field (HierICRF) to
search the most domain-challenging directions and exquisitely crafts
domain-hierarchy adaptation as a hierarchical iterative language modeling
problem, and then it encourages the model to make hierarchical consistency
self-correction during the inference, thereby achieving knowledge transfer with
hierarchical consistency preservation. We perform HierICRF on various
architectures, and extensive experiments on two popular HTC datasets
demonstrate that prompt with HierICRF significantly boosts the few-shot HTC
performance with an average Micro-F1 by 28.80% to 1.50% and Macro-F1 by 36.29%
to 1.5% over the previous state-of-the-art (SOTA) baselines under few-shot
settings, while remaining SOTA hierarchical consistency performance.

摘要：<paragraph>最近，已经提出了多种预训练语言模型 (PLM)，以证明它们在广泛的少量样本任务上具有令人印象深刻的性能。然而，由于 PLM 中非结构化的先验知识受到限制，因此难以在复杂结构化场景（例如层次文本分类 (HTC)）中保持一致的性能，尤其是在下游数据极其稀少的情况下。主要的挑战是如何将 PLM 中非结构化的语义空间转移到下游域层次结构。与以前直接执行多标签分类或使用图神经网络 (GNN) 注入标签层次结构的 HTC 工作不同，在这项工作中，我们在少量样本设置下研究 HTC 问题，以将 PLM 中的知识从非结构化方式适应到下游层次结构。从技术上讲，我们设计了一种简单而有效的方法，称为层次迭代条件随机场 (HierICRF)，以搜索最具领域挑战性的方向，并精细地将领域层次结构适应作为分层迭代语言建模问题，然后它鼓励模型在推理期间进行层次一致性自我校正，从而实现具有层次一致性保留的知识转移。我们在各种架构上执行 HierICRF，在两个流行的 HTC 数据集上的大量实验表明，使用 HierICRF 的提示显着提高了少量样本 HTC 性能，平均 Micro-F1 从 28.80% 提高到 1.50%，Macro-F1 从 36.29% 提高到 1.5% 在少量样本设置下超过了以前最先进 (SOTA) 基准，同时保持 SOTA 层次一致性性能。</paragraph>

##### **Cloud Atlas: Efficient Fault Localization for Cloud Systems using Language Models and Causal Insight**
2407.08694v1 by Zhiqiang Xie, Yujia Zheng, Lizi Ottens, Kun Zhang, Christos Kozyrakis, Jonathan Mace

Runtime failure and performance degradation is commonplace in modern cloud
systems. For cloud providers, automatically determining the root cause of
incidents is paramount to ensuring high reliability and availability as prompt
fault localization can enable faster diagnosis and triage for timely
resolution. A compelling solution explored in recent work is causal reasoning
using causal graphs to capture relationships between varied cloud system
performance metrics. To be effective, however, systems developers must
correctly define the causal graph of their system, which is a time-consuming,
brittle, and challenging task that increases in difficulty for large and
dynamic systems and requires domain expertise. Alternatively, automated
data-driven approaches have limited efficacy for cloud systems due to the
inherent rarity of incidents. In this work, we present Atlas, a novel approach
to automatically synthesizing causal graphs for cloud systems. Atlas leverages
large language models (LLMs) to generate causal graphs using system
documentation, telemetry, and deployment feedback. Atlas is complementary to
data-driven causal discovery techniques, and we further enhance Atlas with a
data-driven validation step. We evaluate Atlas across a range of fault
localization scenarios and demonstrate that Atlas is capable of generating
causal graphs in a scalable and generalizable manner, with performance that far
surpasses that of data-driven algorithms and is commensurate to the
ground-truth baseline.

摘要：在現代雲端系統中，執行時期故障和效能降低是司空見慣的事。對於雲端供應商而言，自動找出事件的根本原因對於確保高可靠性和可用性至關重要，因為及時的故障定位可以讓診斷和分類更快速，以利於及時解決問題。最近的工作中探討了一個引人注目的解決方案，即使用因果圖來擷取各種雲端系統效能指標之間關係的因果推理。然而，系統開發人員必須正確定義其系統的因果圖才能發揮效用，而這項任務耗時、脆弱且具有挑戰性，對於大型且動態的系統而言難度更高，而且需要領域專家知識。或者，由於事件的固有稀少性，自動化資料驅動方法對於雲端系統的效力有限。在這項工作中，我們提出 Atlas，一種自動合成雲端系統因果圖的新方法。Atlas 利用大型語言模型 (LLM) 使用系統文件、遙測和部署回饋來產生因果圖。Atlas 是資料驅動因果發現技術的補充，我們進一步使用資料驅動驗證步驟來增強 Atlas。我們在各種故障定位情境中評估 Atlas，並證明 Atlas 能夠以可擴充且可概化的方式產生因果圖，其效能遠遠超過資料驅動演算法，並且與真實基線相當。

##### **Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents**
2407.08516v3 by Haoyi Xiong, Zhiyuan Wang, Xuhong Li, Jiang Bian, Zeke Xie, Shahid Mumtaz, Laura E. Barnes

This article explores the convergence of connectionist and symbolic
artificial intelligence (AI), from historical debates to contemporary
advancements. Traditionally considered distinct paradigms, connectionist AI
focuses on neural networks, while symbolic AI emphasizes symbolic
representation and logic. Recent advancements in large language models (LLMs),
exemplified by ChatGPT and GPT-4, highlight the potential of connectionist
architectures in handling human language as a form of symbols. The study argues
that LLM-empowered Autonomous Agents (LAAs) embody this paradigm convergence.
By utilizing LLMs for text-based knowledge modeling and representation, LAAs
integrate neuro-symbolic AI principles, showcasing enhanced reasoning and
decision-making capabilities. Comparing LAAs with Knowledge Graphs within the
neuro-symbolic AI theme highlights the unique strengths of LAAs in mimicking
human-like reasoning processes, scaling effectively with large datasets, and
leveraging in-context samples without explicit re-training. The research
underscores promising avenues in neuro-vector-symbolic integration,
instructional encoding, and implicit reasoning, aimed at further enhancing LAA
capabilities. By exploring the progression of neuro-symbolic AI and proposing
future research trajectories, this work advances the understanding and
development of AI technologies.

摘要：本文探討了連線主義與符號人工智慧 (AI) 的融合，從歷史辯論到當代進展。連線主義 AI 傳統上被視為不同的範例，專注於神經網路，而符號 AI 則強調符號表徵和邏輯。大型語言模型 (LLM) 的最新進展，以 ChatGPT 和 GPT-4 為例，突顯了連線主義架構在將人類語言視為符號形式處理方面的潛力。研究認為，由 LLM 賦能的自主代理 (LAA) 體現了這種範例融合。透過利用 LLM 進行基於文字的知識建模和表徵，LAA 整合了神經符號 AI 原則，展示了增強的推理和決策能力。在神經符號 AI 主題中比較 LAA 與知識圖譜，突顯了 LAA 在模擬類人推理過程、有效擴充大型資料集以及利用情境範例而無需明確重新訓練方面的獨特優勢。研究強調了神經向量符號整合、指令編碼和隱式推理中前景看好的途徑，旨在進一步增強 LAA 的能力。透過探討神經符號 AI 的進展並提出未來的研究方向，這項工作推進了對 AI 技術的理解和發展。

##### **A Comprehensive Survey on the Security of Smart Grid: Challenges, Mitigations, and Future Research Opportunities**
2407.07966v1 by Arastoo Zibaeirad, Farnoosh Koleini, Shengping Bi, Tao Hou, Tao Wang

In this study, we conduct a comprehensive review of smart grid security,
exploring system architectures, attack methodologies, defense strategies, and
future research opportunities. We provide an in-depth analysis of various
attack vectors, focusing on new attack surfaces introduced by advanced
components in smart grids. The review particularly includes an extensive
analysis of coordinated attacks that incorporate multiple attack strategies and
exploit vulnerabilities across various smart grid components to increase their
adverse impact, demonstrating the complexity and potential severity of these
threats. Following this, we examine innovative detection and mitigation
strategies, including game theory, graph theory, blockchain, and machine
learning, discussing their advancements in counteracting evolving threats and
associated research challenges. In particular, our review covers a thorough
examination of widely used machine learning-based mitigation strategies,
analyzing their applications and research challenges spanning across
supervised, unsupervised, semi-supervised, ensemble, and reinforcement
learning. Further, we outline future research directions and explore new
techniques and concerns. We first discuss the research opportunities for
existing and emerging strategies, and then explore the potential role of new
techniques, such as large language models (LLMs), and the emerging threat of
adversarial machine learning in the future of smart grid security.

摘要：在這項研究中，我們對智慧電網安全性進行全面檢視，探討系統架構、攻擊方法、防禦策略和未來的研究機會。我們深入分析各種攻擊媒介，專注於智慧電網中先進組件所引入的新攻擊面。本檢視特別包含對協調攻擊的廣泛分析，其中包含多種攻擊策略並利用各種智慧電網組件中的漏洞來增加其負面影響，展示這些威脅的複雜性和潛在嚴重性。在此之後，我們探討創新的偵測和緩解策略，包括博弈論、圖論、區塊鏈和機器學習，討論它們在對抗不斷演變的威脅和相關研究挑戰方面的進展。特別是，我們的檢視涵蓋對廣泛使用的基於機器學習的緩解策略的徹底檢驗，分析它們在監督式、非監督式、半監督式、整體式和強化學習中的應用和研究挑戰。此外，我們概述未來的研究方向並探討新技術和問題。我們首先討論現有和新興策略的研究機會，然後探討新技術的潛在作用，例如大型語言模型 (LLM)，以及對抗式機器學習在智慧電網安全未來的威脅。

##### **Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs**
2407.07775v2 by Hao-Tien Lewis Chiang, Zhuo Xu, Zipeng Fu, Mithun George Jacob, Tingnan Zhang, Tsang-Wei Edward Lee, Wenhao Yu, Connor Schenck, David Rendleman, Dhruv Shah, Fei Xia, Jasmine Hsu, Jonathan Hoech, Pete Florence, Sean Kirmani, Sumeet Singh, Vikas Sindhwani, Carolina Parada, Chelsea Finn, Peng Xu, Sergey Levine, Jie Tan

An elusive goal in navigation research is to build an intelligent agent that
can understand multimodal instructions including natural language and image,
and perform useful navigation. To achieve this, we study a widely useful
category of navigation tasks we call Multimodal Instruction Navigation with
demonstration Tours (MINT), in which the environment prior is provided through
a previously recorded demonstration video. Recent advances in Vision Language
Models (VLMs) have shown a promising path in achieving this goal as it
demonstrates capabilities in perceiving and reasoning about multimodal inputs.
However, VLMs are typically trained to predict textual output and it is an open
research question about how to best utilize them in navigation. To solve MINT,
we present Mobility VLA, a hierarchical Vision-Language-Action (VLA) navigation
policy that combines the environment understanding and common sense reasoning
power of long-context VLMs and a robust low-level navigation policy based on
topological graphs. The high-level policy consists of a long-context VLM that
takes the demonstration tour video and the multimodal user instruction as input
to find the goal frame in the tour video. Next, a low-level policy uses the
goal frame and an offline constructed topological graph to generate robot
actions at every timestep. We evaluated Mobility VLA in a 836m^2 real world
environment and show that Mobility VLA has a high end-to-end success rates on
previously unsolved multimodal instructions such as "Where should I return
this?" while holding a plastic bin. A video demonstrating Mobility VLA can be
found here: https://youtu.be/-Tof__Q8_5s

摘要：<paragraph>導航研究中一個難以捉摸的目標，是建立一個智能代理，它可以理解包括自然語言和影像的多模態指令，並執行有用的導航。為了達成此目標，我們研究了一類廣泛有用的導航任務，我們稱之為示範導覽的多模態指令導航 (MINT)，其中環境先驗是透過先前錄製的示範影片提供的。視覺語言模型 (VLM) 的近期進展，展示了一條實現此目標的有前景路徑，因為它展示了感知和推理多模態輸入的能力。然而，VLM 通常訓練用於預測文字輸出，而如何最佳利用它們進行導航，則是一個開放的研究問題。為了解決 MINT，我們提出了 Mobility VLA，這是一種分層的視覺-語言-動作 (VLA) 導航政策，它結合了長語境 VLM 的環境理解和常識推理能力，以及基於拓撲圖的強健低階導航政策。高階政策包含一個長語境 VLM，它採用示範導覽影片和多模態使用者指令作為輸入，以在導覽影片中找到目標幀。接下來，低階政策使用目標幀和離線建構的拓撲圖，在每個時間步產生機器人動作。我們在 836 平方公尺的真實世界環境中評估了 Mobility VLA，並展示了 Mobility VLA 在先前未解決的多模態指令（例如「我應該把這個塑膠箱歸還到哪裡？」）上具有很高的端到端成功率，同時拿著一個塑膠箱。展示 Mobility VLA 的影片可以在這裡找到：https://youtu.be/-Tof__Q8_5s</paragraph>

##### **Teaching Transformers Causal Reasoning through Axiomatic Training**
2407.07612v1 by Aniket Vashishtha, Abhinav Kumar, Abbavaram Gowtham Reddy, Vineeth N Balasubramanian, Amit Sharma

For text-based AI systems to interact in the real world, causal reasoning is
an essential skill. Since interventional data is costly to generate, we study
to what extent an agent can learn causal reasoning from passive data.
Specifically, we consider an axiomatic training setup where an agent learns
from multiple demonstrations of a causal axiom (or rule), rather than
incorporating the axiom as an inductive bias or inferring it from data values.
A key question is whether the agent would learn to generalize from the axiom
demonstrations to new scenarios. For example, if a transformer model is trained
on demonstrations of the causal transitivity axiom over small graphs, would it
generalize to applying the transitivity axiom over large graphs? Our results,
based on a novel axiomatic training scheme, indicate that such generalization
is possible. We consider the task of inferring whether a variable causes
another variable, given a causal graph structure. We find that a 67 million
parameter transformer model, when trained on linear causal chains (along with
some noisy variations) can generalize well to new kinds of graphs, including
longer causal chains, causal chains with reversed order, and graphs with
branching; even when it is not explicitly trained for such settings. Our model
performs at par (or even better) than many larger language models such as
GPT-4, Gemini Pro, and Phi-3. Overall, our axiomatic training framework
provides a new paradigm of learning causal reasoning from passive data that can
be used to learn arbitrary axioms, as long as sufficient demonstrations can be
generated.

摘要：<paragraph>對於基於文字的人工智慧系統與真實世界互動來說，因果推理是一項必要的技能。由於介入資料的產生成本很高，我們研究一位代理人從被動資料中學習因果推理的程度。具體來說，我們考慮一個公理訓練設置，其中一位代理人從因果公理（或規則）的多個示範中學習，而不是將公理作為歸納偏誤或從資料值中推斷出來。一個關鍵問題是代理人是否會學會從公理示範推廣到新的場景。例如，如果一個Transformer模型在小圖表上因果傳遞性公理的示範中接受訓練，它是否會推廣到在大圖表上應用傳遞性公理？我們的結果基於一個新穎的公理訓練方案，表明這樣的概括是可能的。我們考慮推論一個變數是否導致另一個變數的任務，給定一個因果圖結構。我們發現一個 6700 萬個參數的Transformer模型，在線性因果鏈（以及一些雜訊變化）上訓練時，可以很好地概括到新類型的圖形，包括更長的因果鏈、順序相反的因果鏈和具有分支的圖形；即使它沒有針對此類設置進行明確訓練。我們的模型表現與許多較大的語言模型（例如 GPT-4、Gemini Pro 和 Phi-3）相當（甚至更好）。總體而言，我們的公理訓練框架提供了一個從被動資料中學習因果推理的新範例，只要可以產生足夠的示範，就可以用於學習任意公理。</paragraph>

##### **STAGE: Simplified Text-Attributed Graph Embeddings Using Pre-trained LLMs**
2407.12860v1 by Aaron Zolnai-Lucas, Jack Boylan, Chris Hokamp, Parsa Ghaffari

We present Simplified Text-Attributed Graph Embeddings (STAGE), a
straightforward yet effective method for enhancing node features in Graph
Neural Network (GNN) models that encode Text-Attributed Graphs (TAGs). Our
approach leverages Large-Language Models (LLMs) to generate embeddings for
textual attributes. STAGE achieves competitive results on various node
classification benchmarks while also maintaining a simplicity in implementation
relative to current state-of-the-art (SoTA) techniques. We show that utilizing
pre-trained LLMs as embedding generators provides robust features for ensemble
GNN training, enabling pipelines that are simpler than current SoTA approaches
which require multiple expensive training and prompting stages. We also
implement diffusion-pattern GNNs in an effort to make this pipeline scalable to
graphs beyond academic benchmarks.

摘要：我們提出了簡化文字屬性圖嵌入 (STAGE)，這是一種直接但有效的方法，用於增強圖神經網路 (GNN) 模型中的節點特徵，這些模型會編碼文字屬性圖 (TAG)。我們的做法利用大型語言模型 (LLM) 來為文字屬性產生嵌入。STAGE 在各種節點分類基準上取得了有競爭力的結果，同時在實作上也維持了簡潔性，相較於目前的技術水準 (SoTA)。我們展示了使用預訓練的 LLM 作為嵌入產生器，可為整體 GNN 訓練提供強健的特徵，進而建構比目前 SoTA 做法更簡單的管道，而後者需要多個昂貴的訓練和提示階段。我們也實作了擴散模式 GNN，以期讓這個管道能擴充到學術基準之外的圖形。

##### **GLBench: A Comprehensive Benchmark for Graph with Large Language Models**
2407.07457v2 by Yuhan Li, Peisong Wang, Xiao Zhu, Aochuan Chen, Haiyun Jiang, Deng Cai, Victor Wai Kin Chan, Jia Li

The emergence of large language models (LLMs) has revolutionized the way we
interact with graphs, leading to a new paradigm called GraphLLM. Despite the
rapid development of GraphLLM methods in recent years, the progress and
understanding of this field remain unclear due to the lack of a benchmark with
consistent experimental protocols. To bridge this gap, we introduce GLBench,
the first comprehensive benchmark for evaluating GraphLLM methods in both
supervised and zero-shot scenarios. GLBench provides a fair and thorough
evaluation of different categories of GraphLLM methods, along with traditional
baselines such as graph neural networks. Through extensive experiments on a
collection of real-world datasets with consistent data processing and splitting
strategies, we have uncovered several key findings. Firstly, GraphLLM methods
outperform traditional baselines in supervised settings, with LLM-as-enhancers
showing the most robust performance. However, using LLMs as predictors is less
effective and often leads to uncontrollable output issues. We also notice that
no clear scaling laws exist for current GraphLLM methods. In addition, both
structures and semantics are crucial for effective zero-shot transfer, and our
proposed simple baseline can even outperform several models tailored for
zero-shot scenarios. The data and code of the benchmark can be found at
https://github.com/NineAbyss/GLBench.

摘要：大型語言模型 (LLM) 的出現徹底改變了我們與圖表互動的方式，進而產生一種稱為 GraphLLM 的新典範。儘管近年來 GraphLLM 方法快速發展，但由於缺乏具有一致實驗協定的基準，因此該領域的進展和理解仍不明確。為了彌補這個差距，我們引入了 GLBench，這是第一個用於評估 GraphLLM 方法在監督式和零次學習場景中的綜合基準。GLBench 提供對不同類別的 GraphLLM 方法進行公平且徹底的評估，以及傳統基準，例如圖神經網路。透過對一組真實世界資料集進行廣泛實驗，並採用一致的資料處理和分割策略，我們發現了幾個關鍵發現。首先，GraphLLM 方法在監督式設定中優於傳統基準，其中 LLM 作為增強器顯示出最穩健的效能。然而，使用 LLM 作為預測器較不有效，而且經常導致無法控制的輸出問題。我們還注意到，對於目前的 GraphLLM 方法並不存在明確的縮放定律。此外，結構和語義對於有效的零次學習傳輸至關重要，而我們提出的簡單基準甚至可以優於針對零次學習場景量身打造的幾個模型。基準的資料和程式碼可以在 https://github.com/NineAbyss/GLBench 中找到。

##### **Decoding Climate Disagreement: A Graph Neural Network-Based Approach to Understanding Social Media Dynamics**
2407.07038v1 by Ruiran Su, Janet B. Pierrehumbert

This work introduces the ClimateSent-GAT Model, an innovative method that
integrates Graph Attention Networks (GATs) with techniques from natural
language processing to accurately identify and predict disagreements within
Reddit comment-reply pairs. Our model classifies disagreements into three
categories: agree, disagree, and neutral. Leveraging the inherent graph
structure of Reddit comment-reply pairs, the model significantly outperforms
existing benchmarks by capturing complex interaction patterns and sentiment
dynamics. This research advances graph-based NLP methodologies and provides
actionable insights for policymakers and educators in climate science
communication.

摘要：本研究介紹 ClimateSent-GAT 模型，這是一種創新的方法，它將圖注意力網路 (GAT) 與自然語言處理技術整合，以準確識別並預測 Reddit 留言回覆對中的分歧。我們的模型將分歧分為三類：同意、不同意和中立。透過利用 Reddit 留言回覆對的內在圖形結構，此模型能大幅超越現有基準，捕捉複雜的互動模式和情緒動態。這項研究推動了基於圖形的 NLP 方法，並為氣候科學溝通中的政策制定者和教育工作者提供可行的見解。

##### **Graph-Based Captioning: Enhancing Visual Descriptions by Interconnecting Region Captions**
2407.06723v1 by Yu-Guan Hsieh, Cheng-Yu Hsieh, Shih-Ying Yeh, Louis Béthune, Hadi Pour Ansari, Pavan Kumar Anasosalu Vasu, Chun-Liang Li, Ranjay Krishna, Oncel Tuzel, Marco Cuturi

Humans describe complex scenes with compositionality, using simple text
descriptions enriched with links and relationships. While vision-language
research has aimed to develop models with compositional understanding
capabilities, this is not reflected yet in existing datasets which, for the
most part, still use plain text to describe images. In this work, we propose a
new annotation strategy, graph-based captioning (GBC) that describes an image
using a labelled graph structure, with nodes of various types. The nodes in GBC
are created using, in a first stage, object detection and dense captioning
tools nested recursively to uncover and describe entity nodes, further linked
together in a second stage by highlighting, using new types of nodes,
compositions and relations among entities. Since all GBC nodes hold plain text
descriptions, GBC retains the flexibility found in natural language, but can
also encode hierarchical information in its edges. We demonstrate that GBC can
be produced automatically, using off-the-shelf multimodal LLMs and
open-vocabulary detection models, by building a new dataset, GBC10M, gathering
GBC annotations for about 10M images of the CC12M dataset. We use GBC10M to
showcase the wealth of node captions uncovered by GBC, as measured with CLIP
training. We show that using GBC nodes' annotations -- notably those stored in
composition and relation nodes -- results in significant performance boost on
downstream models when compared to other dataset formats. To further explore
the opportunities provided by GBC, we also propose a new attention mechanism
that can leverage the entire GBC graph, with encouraging experimental results
that show the extra benefits of incorporating the graph structure. Our datasets
are released at \url{https://huggingface.co/graph-based-captions}.

摘要：<paragraph>人類使用簡單的文字描述，豐富的連結和關係，來描述複雜的場景。雖然視覺語言的研究旨在開發具有組合理解能力的模型，但現有的數據集尚未反映這一點，這些數據集在很大程度上仍使用純文本來描述圖像。在這項工作中，我們提出了一種新的註釋策略，基於圖表的標題 (GBC)，它使用標籤圖表結構來描述圖像，其中包含各種類型的節點。GBC 中的節點是使用物體檢測和密集標題工具在第一階段創建的，以遞迴嵌套的方式發現和描述實體節點，並在第二階段使用新類型的節點突出顯示，從而將它們進一步連結在一起，實體之間的組合和關係。由於所有 GBC 節點都包含純文本描述，因此 GBC 保留了自然語言中的靈活性，但也可以在其邊緣編碼分層信息。我們證明了 GBC 可以使用現成的多模態 LLM 和開放詞彙檢測模型自動生成，通過構建一個新的數據集 GBC10M，收集了大約 10M CC12M 數據集圖像的 GBC 註釋。我們使用 GBC10M 來展示 GBC 發現的豐富節點標題，並使用 CLIP 訓練進行測量。我們表明，與其他數據集格式相比，使用 GBC 節點的註釋——特別是存儲在組合和關係節點中的註釋——會顯著提升下游模型的性能。為了進一步探索 GBC 提供的機會，我們還提出了一種新的注意機制，它可以利用整個 GBC 圖表，並通過鼓勵性的實驗結果展示了結合圖表結構的額外好處。我們的數據集發布在 \url{https://huggingface.co/graph-based-captions}。</paragraph>

##### **Combining Knowledge Graphs and Large Language Models**
2407.06564v1 by Amanda Kau, Xuzeng He, Aishwarya Nambissan, Aland Astudillo, Hui Yin, Amir Aryani

In recent years, Natural Language Processing (NLP) has played a significant
role in various Artificial Intelligence (AI) applications such as chatbots,
text generation, and language translation. The emergence of large language
models (LLMs) has greatly improved the performance of these applications,
showing astonishing results in language understanding and generation. However,
they still show some disadvantages, such as hallucinations and lack of
domain-specific knowledge, that affect their performance in real-world tasks.
These issues can be effectively mitigated by incorporating knowledge graphs
(KGs), which organise information in structured formats that capture
relationships between entities in a versatile and interpretable fashion.
Likewise, the construction and validation of KGs present challenges that LLMs
can help resolve. The complementary relationship between LLMs and KGs has led
to a trend that combines these technologies to achieve trustworthy results.
This work collected 28 papers outlining methods for KG-powered LLMs, LLM-based
KGs, and LLM-KG hybrid approaches. We systematically analysed and compared
these approaches to provide a comprehensive overview highlighting key trends,
innovative techniques, and common challenges. This synthesis will benefit
researchers new to the field and those seeking to deepen their understanding of
how KGs and LLMs can be effectively combined to enhance AI applications
capabilities.

摘要：近年来，自然语言处理 (NLP) 在各种人工智能 (AI) 应用中发挥了重要作用，例如聊天机器人、文本生成和语言翻译。大语言模型 (LLM) 的出现极大地提高了这些应用程序的性能，在语言理解和生成方面显示出惊人的结果。然而，它们仍然表现出一些缺点，例如幻觉和缺乏特定领域的知识，这些缺点会影响它们在现实世界中的任务中的表现。通过纳入知识图谱 (KG) 可以有效地减轻这些问题，知识图谱以结构化格式组织信息，以多功能且可解释的方式捕获实体之间的关系。同样，KG 的构建和验证提出了 LLM 可以帮助解决的挑战。LLM 和 KG 之间的互补关系导致了一种将这些技术相结合以实现可信结果的趋势。这项工作收集了 28 篇概述了 KG 驱动的 LLM、基于 LLM 的 KG 和 LLM-KG 混合方法的方法的论文。我们系统地分析和比较了这些方法，以提供一个全面的概述，重点介绍关键趋势、创新技术和共同挑战。这种综合将使该领域的新研究人员和那些寻求加深对如何有效地将 KG 和 LLM 相结合以增强 AI 应用能力的理解的人受益。

##### **FuncEvalGMN: Evaluating Functional Correctness of SQL via Graph Matching Network**
2407.14530v1 by Yi Zhan, Yang Sun, Han Weng, Longjie Cui, Guifeng Wang, Jiajun Xie, Yu Tian, Xiaoming Yin, Boyi Liu, Dongchi Huang

In this paper, we propose a novel graph-based methodology to evaluate the
functional correctness of SQL generation. Conventional metrics for assessing
SQL code generation, such as matching-based and execution-based methods (e.g.,
exact set match and execution accuracy), are subject to two primary
limitations. Firstly, the former fails to effectively assess functional
correctness, as different SQL queries may possess identical functionalities.
Secondly, the latter is susceptible to producing false positive samples in
evaluations. Our proposed evaluation method, \texttt{FuncEvalGMN}, does not
depend on the sufficient preparation of the test data, and it enables precise
testing of the functional correctness of the code. Firstly, we parse SQL using
a relational operator tree (ROT) called \textit{Relnode}, which contains rich
semantic information from the perspective of logical execution.Then, we
introduce a GNN-based approach for predicting the functional correctness of
generated SQL. This approach incorporates global positional embeddings to
address the limitations with the loss of topological information in
conventional graph matching frameworks. As an auxiliary contribution, we
propose a rule-based matching algorithm, Relnode Partial Matching
(\texttt{RelPM}) as a baseline. Finally, we contribute a dataset,
\texttt{Pair-Aug-Spider} with a training set and two testing sets, each
comprising pairs of SQL codes to simulate various SQL code evaluation
scenarios. The training set and one testing dataset focus on code generation
using large language models (LLMs), while the other emphasizes SQL equivalence
rewriting.

摘要：<paragraph>在本文中，我們提出了一種新穎的基於圖的方法來評估 SQL 生成的功能正確性。評估 SQL 程式碼生成的傳統指標，例如基於匹配和基於執行的指標（例如，精確集合匹配和執行準確度），存在兩個主要的限制。首先，前者無法有效評估功能正確性，因為不同的 SQL 查詢可能具有相同的機能。其次，後者在評估中容易產生假陽性樣本。我們提出的評估方法 \texttt{FuncEvalGMN} 不依賴於測試資料的充分準備，並且可以精確測試程式碼的功能正確性。首先，我們使用稱為 \textit{Relnode} 的關係運算元樹 (ROT) 來解析 SQL，其中包含從邏輯執行的角度來看豐富的語義資訊。然後，我們引入一種基於 GNN 的方法來預測生成的 SQL 的功能正確性。這種方法結合了全局位置嵌入，以解決傳統圖形匹配框架中拓撲資訊遺失的限制。作為輔助貢獻，我們提出了一個基於規則的匹配演算法，即 Relnode 部分匹配 (\texttt{RelPM}) 作為基線。最後，我們貢獻了一個資料集 \texttt{Pair-Aug-Spider}，其中包含一個訓練集和兩個測試集，每個測試集都包含成對的 SQL 程式碼來模擬各種 SQL 程式碼評估場景。訓練集和一個測試資料集專注於使用大型語言模型 (LLM) 進行程式碼生成，而另一個則強調 SQL 等價重寫。</paragraph>

##### **MST5 -- Multilingual Question Answering over Knowledge Graphs**
2407.06041v1 by Nikit Srivastava, Mengshi Ma, Daniel Vollmers, Hamada Zahera, Diego Moussallem, Axel-Cyrille Ngonga Ngomo

Knowledge Graph Question Answering (KGQA) simplifies querying vast amounts of
knowledge stored in a graph-based model using natural language. However, the
research has largely concentrated on English, putting non-English speakers at a
disadvantage. Meanwhile, existing multilingual KGQA systems face challenges in
achieving performance comparable to English systems, highlighting the
difficulty of generating SPARQL queries from diverse languages. In this
research, we propose a simplified approach to enhance multilingual KGQA systems
by incorporating linguistic context and entity information directly into the
processing pipeline of a language model. Unlike existing methods that rely on
separate encoders for integrating auxiliary information, our strategy leverages
a single, pretrained multilingual transformer-based language model to manage
both the primary input and the auxiliary data. Our methodology significantly
improves the language model's ability to accurately convert a natural language
query into a relevant SPARQL query. It demonstrates promising results on the
most recent QALD datasets, namely QALD-9-Plus and QALD-10. Furthermore, we
introduce and evaluate our approach on Chinese and Japanese, thereby expanding
the language diversity of the existing datasets.

摘要：知識圖表問答 (KGQA) 簡化了使用自然語言查詢儲存在圖形化模型中的大量知識。然而，研究主要集中在英文上，這對非英語使用者來說是不利的。同時，現有的多語言 KGQA 系統在達成與英文系統相媲美的效能方面面臨挑戰，突顯了從不同語言產生 SPARQL 查詢的困難性。在這項研究中，我們提出了一種簡化的方法，通過將語言學背景和實體資訊直接納入語言模型的處理管道，來增強多語言 KGQA 系統。與依賴於單獨編碼器來整合輔助資訊的現有方法不同，我們的策略利用單一的、預訓練的多語言轉換器語言模型來管理主要輸入和輔助資料。我們的技術顯著提升了語言模型準確地將自然語言查詢轉換為相關 SPARQL 查詢的能力。它在最新的 QALD 資料集，即 QALD-9-Plus 和 QALD-10 上展示了有希望的結果。此外，我們在中文和日文中引入並評估了我們的做法，從而擴展了現有資料集的語言多樣性。

##### **Enhancing Vision-Language Models with Scene Graphs for Traffic Accident Understanding**
2407.05910v1 by Aaron Lohner, Francesco Compagno, Jonathan Francis, Alessandro Oltramari

Recognizing a traffic accident is an essential part of any autonomous driving
or road monitoring system. An accident can appear in a wide variety of forms,
and understanding what type of accident is taking place may be useful to
prevent it from reoccurring. The task of being able to classify a traffic scene
as a specific type of accident is the focus of this work. We approach the
problem by likening a traffic scene to a graph, where objects such as cars can
be represented as nodes, and relative distances and directions between them as
edges. This representation of an accident can be referred to as a scene graph,
and is used as input for an accident classifier. Better results can be obtained
with a classifier that fuses the scene graph input with representations from
vision and language. This work introduces a multi-stage, multimodal pipeline to
pre-process videos of traffic accidents, encode them as scene graphs, and align
this representation with vision and language modalities for accident
classification. When trained on 4 classes, our method achieves a balanced
accuracy score of 57.77% on an (unbalanced) subset of the popular Detection of
Traffic Anomaly (DoTA) benchmark, representing an increase of close to 5
percentage points from the case where scene graph information is not taken into
account.

摘要：辨識交通事故是任何自動駕駛或道路監控系統的必要部分。事故可能以各種形式出現，了解事故類型可能有助於防止再次發生。將交通事故場景分類為特定事故類型的任務是這項工作的重點。我們將交通事故場景比喻為圖形來解決問題，其中汽車等物體可以表示為節點，而它們之間的相對距離和方向則表示為邊緣。這種事故表示可以稱為場景圖，並用作事故分類器的輸入。使用將場景圖輸入與視覺和語言表示融合的分類器可以獲得更好的結果。這項工作引入了一個多階段、多模態管道，用於預處理交通事故影片、將其編碼為場景圖，以及將此表示與視覺和語言模式對齊以進行事故分類。當在 4 個類別上進行訓練時，我們的模型在熱門交通異常檢測 (DoTA) 基準的（不平衡）子集上實現了 57.77% 的平衡準確率，比不考慮場景圖資訊的情況提高了接近 5 個百分點。

##### **Affordances-Oriented Planning using Foundation Models for Continuous Vision-Language Navigation**
2407.05890v1 by Jiaqi Chen, Bingqian Lin, Xinmin Liu, Xiaodan Liang, Kwan-Yee K. Wong

LLM-based agents have demonstrated impressive zero-shot performance in the
vision-language navigation (VLN) task. However, these zero-shot methods focus
only on solving high-level task planning by selecting nodes in predefined
navigation graphs for movements, overlooking low-level control in realistic
navigation scenarios. To bridge this gap, we propose AO-Planner, a novel
affordances-oriented planning framework for continuous VLN task. Our AO-Planner
integrates various foundation models to achieve affordances-oriented motion
planning and action decision-making, both performed in a zero-shot manner.
Specifically, we employ a visual affordances prompting (VAP) approach, where
visible ground is segmented utilizing SAM to provide navigational affordances,
based on which the LLM selects potential next waypoints and generates low-level
path planning towards selected waypoints. We further introduce a high-level
agent, PathAgent, to identify the most probable pixel-based path and convert it
into 3D coordinates to fulfill low-level motion. Experimental results on the
challenging R2R-CE benchmark demonstrate that AO-Planner achieves
state-of-the-art zero-shot performance (5.5% improvement in SPL). Our method
establishes an effective connection between LLM and 3D world to circumvent the
difficulty of directly predicting world coordinates, presenting novel prospects
for employing foundation models in low-level motion control.

摘要：基於 LLM 的代理已在視覺語言導航 (VLN) 任務中展示出令人印象深刻的零次學習效能。然而，這些零次學習方法僅專注於透過選擇預定義導航圖形中的節點來解決高階任務規劃，忽略了實際導航場景中的低階控制。為了彌合此差距，我們提出 AO-Planner，一個用於連續 VLN 任務的新型以可負擔性為導向的規劃架構。我們的 AO-Planner 整合各種基礎模型，以實現以可負擔性為導向的動作規劃和動作決策，兩者都以零次學習的方式執行。具體來說，我們採用視覺可負擔性提示 (VAP) 方法，其中利用 SAM 對可見地面進行分割，以提供導航可負擔性，LLM 根據這些可負擔性選擇潛在的下一個航點，並針對所選航點產生低階路徑規劃。我們進一步引入一個高階代理 PathAgent，以識別最可能的基於像素的路徑，並將其轉換為 3D 座標，以實現低階動作。在具有挑戰性的 R2R-CE 基準測試上的實驗結果表明，AO-Planner 達到了最先進的零次學習效能（SPL 提升 5.5%）。我們的模型在 LLM 和 3D 世界之間建立了一個有效的連結，以規避直接預測世界座標的難題，為在低階動作控制中採用基礎模型提供了新的前景。

##### **KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions**
2407.05868v1 by Yanxu Zhu, Jinlin Xiao, Yuhang Wang, Jitao Sang

Recent studies have demonstrated that large language models (LLMs) are
susceptible to being misled by false premise questions (FPQs), leading to
errors in factual knowledge, know as factuality hallucination. Existing
benchmarks that assess this vulnerability primarily rely on manual
construction, resulting in limited scale and lack of scalability. In this work,
we introduce an automated, scalable pipeline to create FPQs based on knowledge
graphs (KGs). The first step is modifying true triplets extracted from KGs to
create false premises. Subsequently, utilizing the state-of-the-art
capabilities of GPTs, we generate semantically rich FPQs. Based on the proposed
method, we present a comprehensive benchmark, the Knowledge Graph-based False
Premise Questions (KG-FPQ), which contains approximately 178k FPQs across three
knowledge domains, at six levels of confusability, and in two task formats.
Using KG-FPQ, we conduct extensive evaluations on several representative LLMs
and provide valuable insights. The KG-FPQ dataset and code are available
at~https://github.com/yanxuzhu/KG-FPQ.

摘要：最近的研究表明，大型语言模型 (LLM) 容易被错误前提问题 (FPQ) 误导，从而导致事实知识错误，即事实幻觉。用于评估此漏洞的现有基准主要依赖于手动构建，导致规模有限且缺乏可扩展性。在这项工作中，我们引入了一个基于知识图谱 (KG) 创建 FPQ 的自动化可扩展管道。第一步是修改从 KG 中提取的真三元组以创建错误前提。随后，利用 GPT 的最先进功能，我们生成了语义丰富的 FPQ。基于所提出的方法，我们提出了一个综合基准，即基于知识图谱的错误前提问题 (KG-FPQ)，它包含大约 178k 个 FPQ，涵盖三个知识域，六个混淆级别和两种任务格式。使用 KG-FPQ，我们对几个有代表性的 LLM 进行了广泛的评估，并提供了有价值的见解。KG-FPQ 数据集和代码可在~https://github.com/yanxuzhu/KG-FPQ 获得。

##### **Language Models Encode Collaborative Signals in Recommendation**
2407.05441v1 by Leheng Sheng, An Zhang, Yi Zhang, Yuxin Chen, Xiang Wang, Tat-Seng Chua

Recent studies empirically indicate that language models (LMs) encode rich
world knowledge beyond mere semantics, attracting significant attention across
various fields. However, in the recommendation domain, it remains uncertain
whether LMs implicitly encode user preference information. Contrary to the
prevailing understanding that LMs and traditional recommender models learn two
distinct representation spaces due to a huge gap in language and behavior
modeling objectives, this work rethinks such understanding and explores
extracting a recommendation space directly from the language representation
space. Surprisingly, our findings demonstrate that item representations, when
linearly mapped from advanced LM representations, yield superior recommendation
performance. This outcome suggests the homomorphism between the language
representation space and an effective recommendation space, implying that
collaborative signals may indeed be encoded within advanced LMs. Motivated by
these findings, we propose a simple yet effective collaborative filtering (CF)
model named AlphaRec, which utilizes language representations of item textual
metadata (e.g., titles) instead of traditional ID-based embeddings.
Specifically, AlphaRec is comprised of three main components: a multilayer
perceptron (MLP), graph convolution, and contrastive learning (CL) loss
function, making it extremely easy to implement and train. Our empirical
results show that AlphaRec outperforms leading ID-based CF models on multiple
datasets, marking the first instance of such a recommender with text embeddings
achieving this level of performance. Moreover, AlphaRec introduces a new
language-representation-based CF paradigm with several desirable advantages:
being easy to implement, lightweight, rapid convergence, superior zero-shot
recommendation abilities in new domains, and being aware of user intention.

摘要：<paragraph>最近的研究實證表明，語言模型 (LM) 編碼豐富的世界知識，超越了單純的語義，吸引了各個領域的極大關注。然而，在推薦領域中，LM 是否隱含編碼使用者偏好資訊仍不確定。與普遍認知相反，LM 和傳統推薦模型由於語言和行為建模目標的巨大差距而學習兩個不同的表示空間，這項工作重新思考這種理解，並探索直接從語言表示空間中提取推薦空間。令人驚訝的是，我們的研究結果表明，當從先進的 LM 表示中線性映射時，項目表示會產生優異的推薦效能。此結果表明語言表示空間和有效的推薦空間之間存在同態性，這意味著協作訊號確實可能編碼在先進的 LM 中。受這些研究結果的啟發，我們提出了一個簡單但有效的協同過濾 (CF) 模型，名為 AlphaRec，它利用項目文字元資料（例如標題）的語言表示，而不是傳統基於 ID 的嵌入。具體來說，AlphaRec 由三個主要組成部分組成：多層感知器 (MLP)、圖形卷積和對比學習 (CL) 損失函數，使其極易於實作和訓練。我們的實證結果表明，AlphaRec 在多個資料集上優於領先的基於 ID 的 CF 模型，標誌著這種具有文字嵌入的推薦系統首次達到此效能水準。此外，AlphaRec 引入了一個新的基於語言表示的 CF 典範，具有多項理想的優點：易於實作、輕量級、快速收斂、在新的領域中具有優異的零次學習推薦能力，並且可以了解使用者的意圖。</paragraph>

##### **LTLBench: Towards Benchmarks for Evaluating Temporal Logic Reasoning in Large Language Models**
2407.05434v1 by Weizhi Tang, Vaishak Belle

Temporal reasoning (TR) is a critical component of artificial intelligence,
encompassing understanding and processing temporal information and
relationships between events. To discover and study the TR ability in Large
Language Models (LLMs), various datasets have been constructed in different
ways for evaluating various aspects of TR ability. Our work proposes a novel
approach to design and develop a pipeline for constructing datasets to evaluate
the TR ability of LLMs by leveraging random directed graph generation, LTL
formula, and the NuSMV model checker. Based on the pipeline, we have also
constructed a dataset as a benchmark, namely LTLBench, consisting of 2,000 TR
challenges and evaluated six LLMs with it. Furthermore, we have conducted
additional experiments to discover the impact of increasing the number of
events and formula operators on the complexity of TR problems and the
performance of LLMs. We have demonstrated that although LLMs exhibit some
promise in handling TR challenges, they still struggle with complex TR. We
expect this work can offer insights into TR ability in LLMs while also
providing a valuable tool for future TR evaluations.

摘要：時間推理 (TR) 是人工智慧的一項關鍵組成部分，
涵蓋了對時間資訊和事件之間關係的理解和處理。為了發現和研究大型語言模型 (LLM) 中的 TR 能力，已透過各種方式建構各種資料集，用於評估 TR 能力的各個面向。我們的工作提出了一種新穎的方法，用於設計和開發一個建構資料集的管道，以評估 LLM 的 TR 能力，方法是利用隨機有向圖生成、LTL 公式和 NuSMV 模型檢查器。根據這個管道，我們還建構了一個資料集作為基準，即 LTLBench，其中包含 2,000 個 TR 挑戰，並用它評估了六個 LLM。此外，我們還進行了額外的實驗，以發現增加事件數量和公式運算子對 TR 問題複雜性和 LLM 效能的影響。我們已經證明，儘管 LLM 在處理 TR 挑戰方面表現出一些希望，但它們仍然難以處理複雜的 TR。我們預期這項工作可以提供對 LLM 中 TR 能力的見解，同時也為未來的 TR 評估提供一個有價值的工具。

##### **Leveraging Graph Structures to Detect Hallucinations in Large Language Models**
2407.04485v1 by Noa Nonkes, Sergei Agaronian, Evangelos Kanoulas, Roxana Petcu

Large language models are extensively applied across a wide range of tasks,
such as customer support, content creation, educational tutoring, and providing
financial guidance. However, a well-known drawback is their predisposition to
generate hallucinations. This damages the trustworthiness of the information
these models provide, impacting decision-making and user confidence. We propose
a method to detect hallucinations by looking at the structure of the latent
space and finding associations within hallucinated and non-hallucinated
generations. We create a graph structure that connects generations that lie
closely in the embedding space. Moreover, we employ a Graph Attention Network
which utilizes message passing to aggregate information from neighboring nodes
and assigns varying degrees of importance to each neighbor based on their
relevance. Our findings show that 1) there exists a structure in the latent
space that differentiates between hallucinated and non-hallucinated
generations, 2) Graph Attention Networks can learn this structure and
generalize it to unseen generations, and 3) the robustness of our method is
enhanced when incorporating contrastive learning. When evaluated against
evidence-based benchmarks, our model performs similarly without access to
search-based methods.

摘要：大型語言模型廣泛應用於各種任務中，例如客戶支援、內容創作、教育輔導和提供財務指導。然而，一個眾所周知的缺點是它們傾向於產生幻覺。這損害了這些模型所提供資訊的可信度，影響了決策制定和使用者信心。我們提出了一種透過觀察潛在空間的結構並找出幻覺和非幻覺生成中的關聯來偵測幻覺的方法。我們建立了一個圖形結構，連接在嵌入空間中緊密相連的生成。此外，我們採用了一個圖形注意力網路，它利用訊息傳遞來彙總來自相鄰節點的資訊，並根據每個相鄰節點的相關性為其指定不同程度的重要性。我們的研究結果顯示，1) 潛在空間中存在一個結構，可以區分幻覺和非幻覺生成，2) 圖形注意力網路可以學習這個結構並將其概括到未見的生成中，以及 3) 當納入對比學習時，我們方法的穩健性會得到增強。當根據基於證據的基準進行評估時，我們的模型在無法取得基於搜尋的方法的情況下，表現得類似。

##### **AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents**
2407.04363v1 by Petr Anokhin, Nikita Semenov, Artyom Sorokin, Dmitry Evseev, Mikhail Burtsev, Evgeny Burnaev

Advancements in generative AI have broadened the potential applications of
Large Language Models (LLMs) in the development of autonomous agents. Achieving
true autonomy requires accumulating and updating knowledge gained from
interactions with the environment and effectively utilizing it. Current
LLM-based approaches leverage past experiences using a full history of
observations, summarization or retrieval augmentation. However, these
unstructured memory representations do not facilitate the reasoning and
planning essential for complex decision-making. In our study, we introduce
AriGraph, a novel method wherein the agent constructs a memory graph that
integrates semantic and episodic memories while exploring the environment. This
graph structure facilitates efficient associative retrieval of interconnected
concepts, relevant to the agent's current state and goals, thus serving as an
effective environmental model that enhances the agent's exploratory and
planning capabilities. We demonstrate that our Ariadne LLM agent, equipped with
this proposed memory architecture augmented with planning and decision-making,
effectively handles complex tasks on a zero-shot basis in the TextWorld
environment. Our approach markedly outperforms established methods such as
full-history, summarization, and Retrieval-Augmented Generation in various
tasks, including the cooking challenge from the First TextWorld Problems
competition and novel tasks like house cleaning and puzzle Treasure Hunting.

摘要：生成式 AI 的進步擴展了大型語言模型 (LLM) 在自主代理開發中的潛在應用。實現真正的自主性需要累積和更新從與環境互動中獲得的知識，並有效利用它。當前的基於 LLM 的方法利用過去的經驗，使用完整的觀察、摘要或檢索擴充。然而，這些非結構化的記憶表徵並不能促進複雜決策制定中必不可少的推理和規劃。在我們的研究中，我們介紹了 AriGraph，這是一種新方法，其中代理構建了一個記憶圖，該圖在探索環境時整合了語義和情節記憶。這種圖形結構促進了相互聯繫的概念的有效關聯性檢索，與代理的當前狀態和目標相關，從而作為一個有效的環境模型，增強了代理的探索和規劃能力。我們展示了我們的 Ariadne LLM 代理，配備了這種提議的記憶架構，並增強了規劃和決策制定，有效地處理了 TextWorld 環境中零次學習的複雜任務。我們的做法顯著優於已建立的方法，例如完整歷史、摘要和檢索增強生成，在各種任務中，包括來自第一個 TextWorld 問題競賽的烹飪挑戰和房屋清潔和拼圖尋寶等新任務。

##### **Semantic Graphs for Syntactic Simplification: A Revisit from the Age of LLM**
2407.04067v1 by Peiran Yao, Kostyantyn Guzhva, Denilson Barbosa

Symbolic sentence meaning representations, such as AMR (Abstract Meaning
Representation) provide expressive and structured semantic graphs that act as
intermediates that simplify downstream NLP tasks. However, the
instruction-following capability of large language models (LLMs) offers a
shortcut to effectively solve NLP tasks, questioning the utility of semantic
graphs. Meanwhile, recent work has also shown the difficulty of using meaning
representations merely as a helpful auxiliary for LLMs. We revisit the position
of semantic graphs in syntactic simplification, the task of simplifying
sentence structures while preserving their meaning, which requires semantic
understanding, and evaluate it on a new complex and natural dataset. The
AMR-based method that we propose, AMRS$^3$, demonstrates that state-of-the-art
meaning representations can lead to easy-to-implement simplification methods
with competitive performance and unique advantages in cost, interpretability,
and generalization. With AMRS$^3$ as an anchor, we discover that syntactic
simplification is a task where semantic graphs are helpful in LLM prompting. We
propose AMRCoC prompting that guides LLMs to emulate graph algorithms for
explicit symbolic reasoning on AMR graphs, and show its potential for improving
LLM on semantic-centered tasks like syntactic simplification.

摘要：符號句子意義表徵，例如 AMR（抽象意義表徵），提供表達性和結構化的語義圖表，作為簡化下游 NLP 任務的中介。然而，大型語言模型 (LLM) 的指令遵循能力提供了一個捷徑來有效解決 NLP 任務，質疑語義圖表的效用。同時，最近的研究也表明僅將意義表徵用作 LLM 的輔助工具的難度。我們重新審視語義圖表在語法簡化中的位置，語法簡化的任務是在保留句子結構的同時簡化句子結構，這需要語義理解，並在一個新的複雜且自然的數據集上對其進行評估。我們提出的基於 AMR 的方法 AMRS$^3$ 證明了最先進的意義表徵可以導致易於實現的簡化方法，在成本、可解釋性和泛化方面具有競爭優勢和獨特優勢。以 AMRS$^3$ 為錨點，我們發現語法簡化是一項語義圖表有助於 LLM 提示的任務。我們提出 AMRCoC 提示，指導 LLM 模擬圖形演算法，對 AMR 圖形進行明確的符號推理，並展示其在改進 LLM 在以語義為中心的任務（如語法簡化）方面的潛力。

##### **Functional Faithfulness in the Wild: Circuit Discovery with Differentiable Computation Graph Pruning**
2407.03779v1 by Lei Yu, Jingcheng Niu, Zining Zhu, Gerald Penn

In this paper, we introduce a comprehensive reformulation of the task known
as Circuit Discovery, along with DiscoGP, a novel and effective algorithm based
on differentiable masking for discovering circuits. Circuit discovery is the
task of interpreting the computational mechanisms of language models (LMs) by
dissecting their functions and capabilities into sparse subnetworks (circuits).
We identified two major limitations in existing circuit discovery efforts: (1)
a dichotomy between weight-based and connection-edge-based approaches forces
researchers to choose between pruning connections or weights, thereby limiting
the scope of mechanistic interpretation of LMs; (2) algorithms based on
activation patching tend to identify circuits that are neither functionally
faithful nor complete. The performance of these identified circuits is
substantially reduced, often resulting in near-random performance in isolation.
Furthermore, the complement of the circuit -- i.e., the original LM with the
identified circuit removed -- still retains adequate performance, indicating
that essential components of a complete circuits are missed by existing
methods.
  DiscoGP successfully addresses the two aforementioned issues and demonstrates
state-of-the-art faithfulness, completeness, and sparsity. The effectiveness of
the algorithm and its novel structure open up new avenues of gathering new
insights into the internal workings of generative AI.

摘要：<paragraph>在本文中，我們介紹了對稱為電路發現任務的全面重新表述，以及 DiscoGP，一種基於可微遮罩的發現電路的新穎且有效的演算法。電路發現是透過將其功能和能力解剖成稀疏子網路（電路）來詮釋語言模型（LM）的運算機制的任務。我們在現有的電路發現工作中發現了兩個主要的限制：（1）基於權重和基於連接邊緣的方法之間的二分法迫使研究人員在修剪連接或權重之間進行選擇，從而限制了 LM 機制詮釋的範圍；（2）基於啟用修補的演算法傾向於識別在功能上既不忠實也不完整的電路。這些已識別電路的效能大幅降低，通常導致孤立的近乎隨機效能。此外，電路的補數——即移除已識別電路的原始 LM——仍保留了足夠的效能，這表示現有方法錯失了完整電路的基本組成部分。
DiscoGP 成功地解決了上述兩個問題，並展示了最先進的忠實度、完整性和稀疏性。該演算法的有效性和其新穎的結構為深入瞭解生成式 AI 的內部運作開闢了新的途徑。</paragraph>

##### **BACON: Supercharge Your VLM with Bag-of-Concept Graph to Mitigate Hallucinations**
2407.03314v1 by Zhantao Yang, Ruili Feng, Keyu Yan, Huangji Wang, Zhicai Wang, Shangwen Zhu, Han Zhang, Jie Xiao, Pingyu Wu, Kai Zhu, Jixuan Chen, Chen-Wei Xie, Chaojie Mao, Yue Yang, Hongyang Zhang, Yu Liu, Fan Cheng

This paper presents Bag-of-Concept Graph (BACON) to gift models with limited
linguistic abilities to taste the privilege of Vision Language Models (VLMs)
and boost downstream tasks such as detection, visual question answering (VQA),
and image generation. Since the visual scenes in physical worlds are structured
with complex relations between objects, BACON breaks down annotations into
basic minimum elements and presents them in a graph structure. Element-wise
style enables easy understanding, and structural composition liberates
difficult locating. Careful prompt design births the BACON captions with the
help of public-available VLMs and segmentation methods. In this way, we gather
a dataset with 100K annotated images, which endow VLMs with remarkable
capabilities, such as accurately generating BACON, transforming prompts into
BACON format, envisioning scenarios in the style of BACONr, and dynamically
modifying elements within BACON through interactive dialogue and more. Wide
representative experiments, including detection, VQA, and image generation
tasks, tell BACON as a lifeline to achieve previous out-of-reach tasks or excel
in their current cutting-edge solutions.

摘要：本文提出 Bag-of-Concept Graph (BACON)，赋予语言能力有限的模型品尝视觉语言模型 (VLM) 的特权，并提升下游任务，例如检测、视觉问答 (VQA) 和图像生成。由于物理世界中的视觉场景是由对象之间的复杂关系构建而成的，因此 BACON 将注释分解为基本的最小元素，并以图形结构呈现它们。基于元素的风格便于理解，结构化组合解放了困难的定位。在公共可用 VLM 和分割方法的帮助下，精心设计的提示生成了 BACON 标题。通过这种方式，我们收集了一个包含 100K 张注释图像的数据集，该数据集赋予 VLM 显著的能力，例如准确生成 BACON、将提示转换为 BACON 格式、以 BACONr 的风格设想场景，以及通过交互式对话动态修改 BACON 中的元素等等。广泛的代表性实验，包括检测、VQA 和图像生成任务，表明 BACON 作为一条生命线，可以实现以前无法实现的任务，或在当前的尖端解决方案中表现出色。

##### **Knowledge-based Consistency Testing of Large Language Models**
2407.12830v1 by Sai Sathiesh Rajan, Ezekiel Soremekun, Sudipta Chattopadhyay

In this work, we systematically expose and measure the inconsistency and
knowledge gaps of Large Language Models (LLMs). Specifically, we propose an
automated testing framework (called KONTEST) which leverages a knowledge graph
to construct test cases. KONTEST probes and measures the inconsistencies in the
LLM's knowledge of the world via a combination of semantically-equivalent
queries and test oracles (metamorphic or ontological oracle). KONTEST further
mitigates knowledge gaps via a weighted LLM model ensemble. Using four
state-of-the-art LLMs (Falcon, Gemini, GPT3.5, and Llama2), we show that
KONTEST generates 19.2% error inducing inputs (1917 errors from 9983 test
inputs). It also reveals a 16.5% knowledge gap across all tested LLMs.
KONTEST's mitigation method reduces LLM knowledge gap by 32.48%. Our ablation
study further shows that GPT3.5 is not suitable for knowledge-based consistency
testing because it is only 60%-68% effective in knowledge construction.

摘要：在這項工作中，我們系統性地揭露並衡量大型語言模型 (LLM) 的不一致性和知識差距。具體來說，我們提出了一個自動化測試框架 (稱為 KONTEST)，它利用知識圖譜來建構測試案例。KONTEST 通過語義等效查詢和測試預言 (變形或本體論預言) 的組合來探測和衡量 LLM 對世界知識的不一致性。KONTEST 進一步通過加權 LLM 模型集成來緩解知識差距。使用四種最先進的 LLM（Falcon、Gemini、GPT3.5 和 Llama2），我們表明 KONTEST 生成了 19.2% 的錯誤誘發輸入（9983 個測試輸入中的 1917 個錯誤）。它還揭示了所有測試的 LLM 中有 16.5% 的知識差距。KONTEST 的緩解方法將 LLM 知識差距減少了 32.48%。我們的消融研究進一步表明，GPT3.5 不適合用於基於知識的一致性測試，因為它在知識建構中只有 60%-68% 的有效性。

##### **GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models**
2407.02936v1 by Zike Yuan, Ming Liu, Hui Wang, Bing Qin

Evaluating the graph comprehension and reasoning abilities of Large Language
Models (LLMs) is challenging and often incomplete. Existing benchmarks focus
primarily on pure graph understanding, lacking a comprehensive evaluation
across all graph types and detailed capability definitions. This paper presents
GraCoRe, a benchmark for systematically assessing LLMs' graph comprehension and
reasoning. GraCoRe uses a three-tier hierarchical taxonomy to categorize and
test models on pure graph and heterogeneous graphs, subdividing capabilities
into 10 distinct areas tested through 19 tasks. Our benchmark includes 11
datasets with 5,140 graphs of varying complexity. We evaluated three
closed-source and seven open-source LLMs, conducting thorough analyses from
both ability and task perspectives. Key findings reveal that semantic
enrichment enhances reasoning performance, node ordering impacts task success,
and the ability to process longer texts does not necessarily improve graph
comprehension or reasoning. GraCoRe is open-sourced at
https://github.com/ZIKEYUAN/GraCoRe

摘要：評估大型語言模型 (LLM) 的圖形理解和推理能力具有挑戰性，且通常不完整。現有的基準主要著重於純粹的圖形理解，缺乏對所有圖形類型和詳細功能定義的全面評估。本文提出了 GraCoRe，一個用於系統評估 LLM 的圖形理解和推理的基準。GraCoRe 使用三層階層分類法對模型進行分類和測試，將功能細分為 10 個不同的領域，並通過 19 個任務進行測試。我們的基準包含 11 個數據集，其中包含 5,140 個不同複雜度的圖形。我們評估了三個閉源和七個開源 LLM，從能力和任務角度進行了徹底的分析。主要發現表明語義豐富化增強了推理性能，節點排序影響任務成功，而處理較長文本的能力並不一定能改善圖形理解或推理。GraCoRe 在 https://github.com/ZIKEYUAN/GraCoRe 開源

##### **Croppable Knowledge Graph Embedding**
2407.02779v1 by Yushan Zhu, Wen Zhang, Zhiqiang Liu, Mingyang Chen, Lei Liang, Huajun Chen

Knowledge Graph Embedding (KGE) is a common method for Knowledge Graphs (KGs)
to serve various artificial intelligence tasks. The suitable dimensions of the
embeddings depend on the storage and computing conditions of the specific
application scenarios. Once a new dimension is required, a new KGE model needs
to be trained from scratch, which greatly increases the training cost and
limits the efficiency and flexibility of KGE in serving various scenarios. In
this work, we propose a novel KGE training framework MED, through which we
could train once to get a croppable KGE model applicable to multiple scenarios
with different dimensional requirements, sub-models of the required dimensions
can be cropped out of it and used directly without any additional training. In
MED, we propose a mutual learning mechanism to improve the low-dimensional
sub-models performance and make the high-dimensional sub-models retain the
capacity that low-dimensional sub-models have, an evolutionary improvement
mechanism to promote the high-dimensional sub-models to master the knowledge
that the low-dimensional sub-models can not learn, and a dynamic loss weight to
balance the multiple losses adaptively. Experiments on 3 KGE models over 4
standard KG completion datasets, 3 real application scenarios over a real-world
large-scale KG, and the experiments of extending MED to the language model BERT
show the effectiveness, high efficiency, and flexible extensibility of MED.

摘要：知識圖嵌入 (KGE) 是知識圖 (KG) 用於服務各種人工智慧任務的常見方法。嵌入的適當維度取決於特定應用場景的儲存和運算條件。一旦需要新的維度，就需要從頭訓練新的 KGE 模型，這大大增加了訓練成本，並限制了 KGE 在服務各種場景中的效率和靈活性。在這項工作中，我們提出了一種新穎的 KGE 訓練框架 MED，通過它，我們可以訓練一次以獲得適用於具有不同維度需求的多個場景的可裁剪 KGE 模型，可以從中裁剪出所需維度的子模型並直接使用，而無需任何額外訓練。在 MED 中，我們提出了一種相互學習機制，以提高低維子模型的效能，並使高維子模型保留低維子模型具有的能力，一種進化改進機制，以促進高維子模型掌握低維子模型無法學習的知識，以及一種動態損失權重，以自適應地平衡多重損失。在 4 個標準 KG 完成資料集上的 3 個 KGE 模型、一個真實世界大規模 KG 上的 3 個實際應用場景以及將 MED 擴展到語言模型 BERT 的實驗中，展示了 MED 的有效性、高效率和靈活的可擴充性。

##### **Reasoning in Large Language Models: A Geometric Perspective**
2407.02678v1 by Romain Cosentino, Sarath Shekkizhar

The advancement of large language models (LLMs) for real-world applications
hinges critically on enhancing their reasoning capabilities. In this work, we
explore the reasoning abilities of large language models (LLMs) through their
geometrical understanding. We establish a connection between the expressive
power of LLMs and the density of their self-attention graphs. Our analysis
demonstrates that the density of these graphs defines the intrinsic dimension
of the inputs to the MLP blocks. We demonstrate through theoretical analysis
and toy examples that a higher intrinsic dimension implies a greater expressive
capacity of the LLM. We further provide empirical evidence linking this
geometric framework to recent advancements in methods aimed at enhancing the
reasoning capabilities of LLMs.

摘要：大型語言模型 (LLM) 在實際應用中的進展，關鍵在於提升其推理能力。在這項工作中，我們透過大型語言模型 (LLM) 的幾何理解，探討其推理能力。我們建立了 LLM 的表達能力與其自注意力圖密度之間的關聯。我們的分析證明，這些圖的密度定義了 MLP 塊輸入的內在維度。我們透過理論分析和玩具範例證明，較高的內在維度意味著 LLM 具有更大的表達能力。我們進一步提供經驗證據，將這個幾何框架連結到最近在旨在增強 LLM 推理能力的方法中取得的進展。

##### **LLMs Plagiarize: Ensuring Responsible Sourcing of Large Language Model Training Data Through Knowledge Graph Comparison**
2407.02659v2 by Devam Mondal, Carlo Lipizzi

In light of recent legal allegations brought by publishers, newspapers, and
other creators of copyrighted corpora against large language model developers
who use their copyrighted materials for training or fine-tuning purposes, we
propose a novel system, a variant of a plagiarism detection system, that
assesses whether a knowledge source has been used in the training or
fine-tuning of a large language model. Unlike current methods, we utilize an
approach that uses Resource Description Framework (RDF) triples to create
knowledge graphs from both a source document and an LLM continuation of that
document. These graphs are then analyzed with respect to content using cosine
similarity and with respect to structure using a normalized version of graph
edit distance that shows the degree of isomorphism. Unlike traditional
plagiarism systems that focus on content matching and keyword identification
between a source and a target corpus, our approach enables a broader and more
accurate evaluation of similarity between a source document and LLM
continuation by focusing on relationships between ideas and their organization
with regards to others. Additionally, our approach does not require access to
LLM metrics like perplexity that may be unavailable in closed large language
model "black-box" systems, as well as the training corpus. We thus assess
whether an LLM has "plagiarized" a corpus in its continuation through
similarity measures. A prototype of our system will be found on a hyperlinked
GitHub repository.

摘要：鉴于出版商、报纸和其他受版权保护语料库的创作者针对使用其受版权保护资料进行训练或微调的大型语言模型开发者提出的近期法律指控，我们提出了一种新颖的系统，即抄袭检测系统的一个变体，该系统评估知识来源是否已用于大型语言模型的训练或微调。与当前方法不同，我们使用一种方法，该方法利用资源描述框架 (RDF) 三元组从源文档和该文档的 LLM 续篇创建知识图谱。然后使用余弦相似性分析这些图谱的内容，并使用图编辑距离的标准化版本分析其结构，该版本显示同构的程度。与专注于源语料库和目标语料库之间的内容匹配和关键词识别的传统抄袭系统不同，我们的方法通过关注思想之间的关系及其与其他思想的组织方式，对源文档和 LLM 续篇之间的相似性进行更广泛、更准确的评估。此外，我们的方法不需要访问 LLM 指标，例如在封闭的大型语言模型“黑匣子”系统以及训练语料库中可能无法获得的困惑度。因此，我们通过相似性度量评估 LLM 是否在其续篇中“抄袭”了语料库。我们系统的原型将可以在超链接的 GitHub 存储库中找到。

##### **Multi-Peptide: Multimodality Leveraged Language-Graph Learning of Peptide Properties**
2407.03380v1 by Srivathsan Badrinarayanan, Chakradhar Guntuboina, Parisa Mollaei, Amir Barati Farimani

Peptides are essential in biological processes and therapeutics. In this
study, we introduce Multi-Peptide, an innovative approach that combines
transformer-based language models with Graph Neural Networks (GNNs) to predict
peptide properties. We combine PeptideBERT, a transformer model tailored for
peptide property prediction, with a GNN encoder to capture both sequence-based
and structural features. By employing Contrastive Language-Image Pre-training
(CLIP), Multi-Peptide aligns embeddings from both modalities into a shared
latent space, thereby enhancing the model's predictive accuracy. Evaluations on
hemolysis and nonfouling datasets demonstrate Multi-Peptide's robustness,
achieving state-of-the-art 86.185% accuracy in hemolysis prediction. This study
highlights the potential of multimodal learning in bioinformatics, paving the
way for accurate and reliable predictions in peptide-based research and
applications.

摘要：肽在生物過程和治療中至關重要。在此研究中，我們介紹了多肽，這是一種創新的方法，結合了基於轉換器的語言模型和圖神經網絡 (GNN) 來預測肽的性質。我們結合了專門用於肽性質預測的轉換器模型 PeptideBERT 和 GNN 編碼器，以捕獲基於序列和結構的特徵。通過採用對比語言圖像預訓練 (CLIP)，多肽將來自兩種模態的嵌入對齊到一個共享的潛在空間中，從而增強模型的預測準確度。對溶血和抗污數據集的評估證明了多肽的穩健性，在溶血預測中實現了最先進的 86.185% 準確率。本研究強調了生物信息學中多模態學習的潛力，為基於肽的研究和應用中的準確且可靠的預測鋪平了道路。

##### **Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification**
2407.02352v1 by Pritish Sahu, Karan Sikka, Ajay Divakaran

Large Visual Language Models (LVLMs) struggle with hallucinations in visual
instruction following task(s), limiting their trustworthiness and real-world
applicability. We propose Pelican -- a novel framework designed to detect and
mitigate hallucinations through claim verification. Pelican first decomposes
the visual claim into a chain of sub-claims based on first-order predicates.
These sub-claims consist of (predicate, question) pairs and can be
conceptualized as nodes of a computational graph. We then use
Program-of-Thought prompting to generate Python code for answering these
questions through flexible composition of external tools. Pelican improves over
prior work by introducing (1) intermediate variables for precise grounding of
object instances, and (2) shared computation for answering the sub-question to
enable adaptive corrections and inconsistency identification. We finally use
reasoning abilities of LLM to verify the correctness of the the claim by
considering the consistency and confidence of the (question, answer) pairs from
each sub-claim. Our experiments reveal a drop in hallucination rate by
$\sim$8%-32% across various baseline LVLMs and a 27% drop compared to
approaches proposed for hallucination mitigation on MMHal-Bench. Results on two
other benchmarks further corroborate our results.

摘要：大型视觉语言模型 (LVLMs) 在视觉指令遵循任务中会产生幻觉，这限制了它们的可靠性和现实世界的适用性。我们提出了 Pelican——一种旨在通过声明验证来检测和减轻幻觉的新型框架。Pelican 首先根据一阶谓词将视觉声明分解成一个子声明链。这些子声明由 (谓词、问题) 对组成，可以被概念化为计算图的节点。然后，我们使用思想计划提示来生成 Python 代码，通过外部工具的灵活组合来回答这些问题。Pelican 通过引入 (1) 用于对象实例精确接地的中间变量，以及 (2) 用于回答子问题以实现自适应校正和不一致性识别的共享计算，改进了之前的工作。我们最终使用 LLM 的推理能力，通过考虑每个子声明的 (问题、答案) 对的一致性和置信度来验证声明的正确性。我们的实验表明，在各种基线 LVLMs 中，幻觉率下降了约 8%-32%，与 MMHal-Bench 上提出的幻觉缓解方法相比，下降了 27%。在另外两个基准上的结果进一步证实了我们的结果。

##### **Is Your Large Language Model Knowledgeable or a Choices-Only Cheater?**
2407.01992v1 by Nishant Balepur, Rachel Rudinger

Recent work shows that large language models (LLMs) can answer
multiple-choice questions using only the choices, but does this mean that MCQA
leaderboard rankings of LLMs are largely influenced by abilities in
choices-only settings? To answer this, we use a contrast set that probes if
LLMs over-rely on choices-only shortcuts in MCQA. While previous works build
contrast sets via expensive human annotations or model-generated data which can
be biased, we employ graph mining to extract contrast sets from existing MCQA
datasets. We use our method on UnifiedQA, a group of six commonsense reasoning
datasets with high choices-only accuracy, to build an 820-question contrast
set. After validating our contrast set, we test 12 LLMs, finding that these
models do not exhibit reliance on choice-only shortcuts when given both the
question and choices. Thus, despite the susceptibility~of MCQA to high
choices-only accuracy, we argue that LLMs are not obtaining high ranks on MCQA
leaderboards just due to their ability to exploit choices-only shortcuts.

摘要：最近的研究表明，大型语言模型 (LLM) 仅使用选项就能回答多项选择题，但这是否表示多项选择问答 (MCQA) 排行榜上的 LLM 主要受限于仅选项设置中的能力？为了回答这个问题，我们使用对比集来探查 LLM 在 MCQA 中是否过度依赖仅选项捷径。虽然先前的研究通过昂贵的人工注释或可能存在偏差的模型生成数据来构建对比集，但我们采用图挖掘从现有 MCQA 数据集中提取对比集。我们使用我们的方法在 UnifiedQA 上，这是一个由六个具有高仅选项准确率的常识推理数据集组成的组，构建了一个 820 题的对比集。在验证我们的对比集后，我们测试了 12 个 LLM，发现当同时给出问题和选项时，这些模型不会表现出对仅选项捷径的依赖。因此，尽管 MCQA 容易受到高仅选项准确率的影响，但我们认为 LLM 在 MCQA 排行榜上获得高排名并非仅仅因为它们利用仅选项捷径的能力。

##### **CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents**
2407.01511v1 by Tianqi Xu, Linyao Chen, Dai-Jie Wu, Yanjun Chen, Zecheng Zhang, Xiang Yao, Zhiqiang Xie, Yongchao Chen, Shilong Liu, Bochen Qian, Philip Torr, Bernard Ghanem, Guohao Li

The development of autonomous agents increasingly relies on Multimodal
Language Models (MLMs) to perform tasks described in natural language with GUI
environments, such as websites, desktop computers, or mobile phones. Existing
benchmarks for MLM agents in interactive environments are limited by their
focus on a single environment, lack of detailed and generalized evaluation
methods, and the complexities of constructing tasks and evaluators. To overcome
these limitations, we introduce Crab, the first agent benchmark framework
designed to support cross-environment tasks, incorporating a graph-based
fine-grained evaluation method and an efficient mechanism for task and
evaluator construction. Our framework supports multiple devices and can be
easily extended to any environment with a Python interface. Leveraging Crab, we
developed a cross-platform Crab Benchmark-v0 comprising 100 tasks in computer
desktop and mobile phone environments. We evaluated four advanced MLMs using
different single and multi-agent system configurations on this benchmark. The
experimental results demonstrate that the single agent with GPT-4o achieves the
best completion ratio of 35.26%. All framework code, agent code, and task
datasets are publicly available at https://github.com/camel-ai/crab.

摘要：自主代理的開發越來越依賴多模態語言模型 (MLM)，以在具有 GUI 環境（例如網站、桌上型電腦或手機）的自然語言中執行任務。現有的互動環境中 MLM 代理的基準受到以下限制：它們專注於單一環境、缺乏詳細且通用的評估方法，以及建構任務和評估器的複雜性。為了克服這些限制，我們引入了 Crab，這是第一個代理基準架構，旨在支援跨環境任務，並結合了基於圖形的細粒度評估方法和任務與評估器建構的有效機制。我們的架構支援多種裝置，並且可以輕鬆地擴充到任何具有 Python 介面的環境。利用 Crab，我們開發了一個跨平台的 Crab Benchmark-v0，其中包含電腦桌上型電腦和手機環境中的 100 個任務。我們使用不同的單一和多代理系統配置，在這個基準上評估了四種先進的 MLM。實驗結果表明，具有 GPT-4o 的單一代理實現了 35.26% 的最佳完成率。所有架構程式碼、代理程式碼和任務資料集都公開於 https://github.com/camel-ai/crab。

##### **Dynamic Few-Shot Learning for Knowledge Graph Question Answering**
2407.01409v1 by Jacopo D'Abramo, Andrea Zugarini, Paolo Torroni

Large language models present opportunities for innovative Question Answering
over Knowledge Graphs (KGQA). However, they are not inherently designed for
query generation. To bridge this gap, solutions have been proposed that rely on
fine-tuning or ad-hoc architectures, achieving good results but limited
out-of-domain distribution generalization. In this study, we introduce a novel
approach called Dynamic Few-Shot Learning (DFSL). DFSL integrates the
efficiency of in-context learning and semantic similarity and provides a
generally applicable solution for KGQA with state-of-the-art performance. We
run an extensive evaluation across multiple benchmark datasets and architecture
configurations.

摘要：大型語言模型為知識圖譜（KGQA）的創新問答提供了機會。然而，它們並非天生就設計用於查詢生成。為了彌補這一差距，已提出依賴於微調或特定架構的解決方案，取得了良好的結果，但域外分佈泛化能力有限。在本研究中，我們引入了一種稱為動態小樣本學習（DFSL）的新方法。DFSL 集成了語境學習和語義相似性的效率，並為 KGQA 提供了一個普遍適用的解決方案，具有最先進的性能。我們對多個基準資料集和架構配置進行了廣泛的評估。

##### **Adapting Multilingual LLMs to Low-Resource Languages with Knowledge Graphs via Adapters**
2407.01406v2 by Daniil Gurgurov, Mareike Hartmann, Simon Ostermann

This paper explores the integration of graph knowledge from linguistic
ontologies into multilingual Large Language Models (LLMs) using adapters to
improve performance for low-resource languages (LRLs) in sentiment analysis
(SA) and named entity recognition (NER). Building upon successful
parameter-efficient fine-tuning techniques, such as K-ADAPTER and MAD-X, we
propose a similar approach for incorporating knowledge from multilingual
graphs, connecting concepts in various languages with each other through
linguistic relationships, into multilingual LLMs for LRLs. Specifically, we
focus on eight LRLs -- Maltese, Bulgarian, Indonesian, Nepali, Javanese,
Uyghur, Tibetan, and Sinhala -- and employ language-specific adapters
fine-tuned on data extracted from the language-specific section of ConceptNet,
aiming to enable knowledge transfer across the languages covered by the
knowledge graph. We compare various fine-tuning objectives, including standard
Masked Language Modeling (MLM), MLM with full-word masking, and MLM with
targeted masking, to analyse their effectiveness in learning and integrating
the extracted graph data. Through empirical evaluation on language-specific
tasks, we assess how structured graph knowledge affects the performance of
multilingual LLMs for LRLs in SA and NER, providing insights into the potential
benefits of adapting language models for low-resource scenarios.

摘要：這篇論文探討了使用適配器將來自語言學本體的圖形知識整合到多語言大型語言模型 (LLM) 中，以提升低資源語言 (LRL) 在情緒分析 (SA) 和命名實體識別 (NER) 中的效能。我們建立在成功的參數有效微調技術上，例如 K-ADAPTER 和 MAD-X，我們提出了一個類似的做法，將來自多語言圖形、透過語言關係將各種語言中的概念相互連接的知識，納入 LRL 的多語言 LLM 中。具體來說，我們專注於八種 LRL——馬爾他語、保加利亞語、印尼語、尼泊爾語、爪哇語、維吾爾語、藏語和僧伽羅語——並使用在從 ConceptNet 的語言特定部分中提取的資料上微調的語言特定適配器，旨在讓知識轉移到知識圖形涵蓋的語言中。我們比較了各種微調目標，包括標準的遮罩語言模型 (MLM)、具有全詞遮罩的 MLM，以及具有目標遮罩的 MLM，以分析它們在學習和整合提取的圖形資料中的有效性。透過對語言特定任務的實證評估，我們評估結構化圖形知識如何影響多語言 LLM 在 LRL 中的 SA 和 NER 效能，並深入了解為低資源場景調整語言模型的潛在好處。

##### **SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model**
2407.01245v2 by Lingyue Fu, Hao Guan, Kounianhua Du, Jianghao Lin, Wei Xia, Weinan Zhang, Ruiming Tang, Yasheng Wang, Yong Yu

Knowledge Tracing (KT) aims to determine whether students will respond
correctly to the next question, which is a crucial task in intelligent tutoring
systems (ITS). In educational KT scenarios, transductive ID-based methods often
face severe data sparsity and cold start problems, where interactions between
individual students and questions are sparse, and new questions and concepts
consistently arrive in the database. In addition, existing KT models only
implicitly consider the correlation between concepts and questions, lacking
direct modeling of the more complex relationships in the heterogeneous graph of
concepts and questions. In this paper, we propose a Structure-aware Inductive
Knowledge Tracing model with large language model (dubbed SINKT), which, for
the first time, introduces large language models (LLMs) and realizes inductive
knowledge tracing. Firstly, SINKT utilizes LLMs to introduce structural
relationships between concepts and constructs a heterogeneous graph for
concepts and questions. Secondly, by encoding concepts and questions with LLMs,
SINKT incorporates semantic information to aid prediction. Finally, SINKT
predicts the student's response to the target question by interacting with the
student's knowledge state and the question representation. Experiments on four
real-world datasets demonstrate that SINKT achieves state-of-the-art
performance among 12 existing transductive KT models. Additionally, we explore
the performance of SINKT on the inductive KT task and provide insights into
various modules.

摘要：知識追蹤 (KT) 的目的是確定學生是否能正確回答下一個問題，這在智慧型教學系統 (ITS) 中是一項至關重要的任務。在教育 KT 場景中，基於 ID 的轉導方法經常面臨嚴重的資料稀疏性和冷啟動問題，其中個別學生和問題之間的互動很稀疏，而且新的問題和概念會持續出現在資料庫中。此外，現有的 KT 模型只會隱含地考慮概念和問題之間的關聯性，缺乏對概念和問題異質圖中更複雜關係的直接建模。在本文中，我們提出了一個具有大型語言模型的結構感知歸納知識追蹤模型（稱為 SINKT），它首次引入了大型語言模型（LLM），並實現了歸納知識追蹤。首先，SINKT 利用 LLM 引入概念之間的結構關係，並為概念和問題構建了一個異質圖。其次，透過使用 LLM 編碼概念和問題，SINKT 結合了語義資訊，以協助預測。最後，SINKT 透過與學生的知識狀態和問題表徵進行互動，預測學生對目標問題的回應。在四個真實世界資料集上的實驗表明，SINKT 在 12 個現有的轉導 KT 模型中取得了最先進的效能。此外，我們探討了 SINKT 在歸納 KT 任務上的效能，並提供了對各種模組的見解。

