{"2412.13630": {"publish_time": "2024-12-18", "title": "Policy Decorator: Model-Agnostic Online Refinement for Large Policy Model", "paper_summary": "Recent advancements in robot learning have used imitation learning with large\nmodels and extensive demonstrations to develop effective policies. However,\nthese models are often limited by the quantity, quality, and diversity of\ndemonstrations. This paper explores improving offline-trained imitation\nlearning models through online interactions with the environment. We introduce\nPolicy Decorator, which uses a model-agnostic residual policy to refine large\nimitation learning models during online interactions. By implementing\ncontrolled exploration strategies, Policy Decorator enables stable,\nsample-efficient online learning. Our evaluation spans eight tasks across two\nbenchmarks-ManiSkill and Adroit-and involves two state-of-the-art imitation\nlearning models (Behavior Transformer and Diffusion Policy). The results show\nPolicy Decorator effectively improves the offline-trained policies and\npreserves the smooth motion of imitation learning models, avoiding the erratic\nbehaviors of pure RL policies. See our project page\n(https://policydecorator.github.io) for videos.", "paper_summary_zh": "\u6a5f\u5668\u5b78\u7fd2\u7684\u6700\u65b0\u9032\u5c55\u5df2\u4f7f\u7528\u5927\u578b\u6a21\u578b\u548c\u5ee3\u6cdb\u7684\u793a\u7bc4\u9032\u884c\u6a21\u4eff\u5b78\u7fd2\uff0c\u4ee5\u5236\u5b9a\u6709\u6548\u7684\u7b56\u7565\u3002\u7136\u800c\uff0c\u9019\u4e9b\u6a21\u578b\u901a\u5e38\u53d7\u5230\u793a\u7bc4\u6578\u91cf\u3001\u54c1\u8cea\u548c\u591a\u6a23\u6027\u7684\u9650\u5236\u3002\u672c\u6587\u63a2\u8a0e\u4e86\u900f\u904e\u8207\u74b0\u5883\u7684\u7dda\u4e0a\u4e92\u52d5\u4f86\u6539\u5584\u96e2\u7dda\u8a13\u7df4\u7684\u6a21\u4eff\u5b78\u7fd2\u6a21\u578b\u3002\u6211\u5011\u5f15\u5165\u4e86\u7b56\u7565\u88dd\u98fe\u5668\uff0c\u5b83\u4f7f\u7528\u8207\u6a21\u578b\u7121\u95dc\u7684\u6b98\u5dee\u7b56\u7565\u4f86\u5728\u7dda\u4e0a\u4e92\u52d5\u671f\u9593\u512a\u5316\u5927\u578b\u6a21\u4eff\u5b78\u7fd2\u6a21\u578b\u3002\u900f\u904e\u5be6\u65bd\u53d7\u63a7\u63a2\u7d22\u7b56\u7565\uff0c\u7b56\u7565\u88dd\u98fe\u5668\u80fd\u5be6\u73fe\u7a69\u5b9a\u7684\u3001\u6a23\u672c\u6548\u7387\u9ad8\u7684\u7dda\u4e0a\u5b78\u7fd2\u3002\u6211\u5011\u7684\u8a55\u4f30\u6a6b\u8de8\u5169\u500b\u57fa\u6e96\u6e2c\u8a66\u4e2d\u7684\u516b\u9805\u4efb\u52d9\uff08ManiSkill \u548c Adroit\uff09\uff0c\u4e26\u6d89\u53ca\u5169\u500b\u6700\u5148\u9032\u7684\u6a21\u4eff\u5b78\u7fd2\u6a21\u578b\uff08\u884c\u70ba\u8f49\u63db\u5668\u548c\u64f4\u6563\u7b56\u7565\uff09\u3002\u7d50\u679c\u986f\u793a\u7b56\u7565\u88dd\u98fe\u5668\u6709\u6548\u5730\u6539\u5584\u4e86\u96e2\u7dda\u8a13\u7df4\u7684\u7b56\u7565\uff0c\u4e26\u4fdd\u7559\u4e86\u6a21\u4eff\u5b78\u7fd2\u6a21\u578b\u7684\u6d41\u66a2\u52d5\u4f5c\uff0c\u907f\u514d\u4e86\u7d14\u7cb9 RL \u7b56\u7565\u7684\u7570\u5e38\u884c\u70ba\u3002\u8acb\u53c3\u95b1\u6211\u5011\u7684\u5c08\u6848\u9801\u9762 (https://policydecorator.github.io) \u4ee5\u89c0\u770b\u5f71\u7247\u3002", "author": "Xiu Yuan et.al.", "authors": "Xiu Yuan, Tongzhou Mu, Stone Tao, Yunhao Fang, Mengke Zhang, Hao Su", "id": "2412.13630v1", "paper_url": "http://arxiv.org/abs/2412.13630v1", "repo": "null"}}