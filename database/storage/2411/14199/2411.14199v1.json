{"2411.14199": {"publish_time": "2024-11-21", "title": "OpenScholar: Synthesizing Scientific Literature with Retrieval-augmented LMs", "paper_summary": "Scientific progress depends on researchers' ability to synthesize the growing\nbody of literature. Can large language models (LMs) assist scientists in this\ntask? We introduce OpenScholar, a specialized retrieval-augmented LM that\nanswers scientific queries by identifying relevant passages from 45 million\nopen-access papers and synthesizing citation-backed responses. To evaluate\nOpenScholar, we develop ScholarQABench, the first large-scale multi-domain\nbenchmark for literature search, comprising 2,967 expert-written queries and\n208 long-form answers across computer science, physics, neuroscience, and\nbiomedicine. On ScholarQABench, OpenScholar-8B outperforms GPT-4o by 5% and\nPaperQA2 by 7% in correctness, despite being a smaller, open model. While GPT4o\nhallucinates citations 78 to 90% of the time, OpenScholar achieves citation\naccuracy on par with human experts. OpenScholar's datastore, retriever, and\nself-feedback inference loop also improves off-the-shelf LMs: for instance,\nOpenScholar-GPT4o improves GPT-4o's correctness by 12%. In human evaluations,\nexperts preferred OpenScholar-8B and OpenScholar-GPT4o responses over\nexpert-written ones 51% and 70% of the time, respectively, compared to GPT4o's\n32%. We open-source all of our code, models, datastore, data and a public demo.", "paper_summary_zh": "<paragraph>\u79d1\u5b78\u9032\u6b65\u6709\u8cf4\u65bc\u7814\u7a76\u4eba\u54e1\u7d9c\u5408\u65e5\u76ca\u9f90\u5927\u7684\u6587\u737b\u8cc7\u6599\u7684\u80fd\u529b\u3002\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LM) \u80fd\u5426\u5354\u52a9\u79d1\u5b78\u5bb6\u57f7\u884c\u9019\u9805\u4efb\u52d9\uff1f\u6211\u5011\u63a8\u51fa OpenScholar\uff0c\u4e00\u7a2e\u5c08\u9580\u7684\u6aa2\u7d22\u589e\u5f37\u578b LM\uff0c\u5b83\u900f\u904e\u8b58\u5225\u4f86\u81ea 4500 \u842c\u7bc7\u958b\u653e\u53d6\u7528\u8ad6\u6587\u4e2d\u7684\u76f8\u95dc\u6bb5\u843d\u4e26\u7d9c\u5408\u5f15\u7528\u5099\u8a3b\u7684\u56de\u61c9\uff0c\u4f86\u56de\u7b54\u79d1\u5b78\u554f\u984c\u3002\u70ba\u4e86\u8a55\u4f30 OpenScholar\uff0c\u6211\u5011\u958b\u767c\u4e86 ScholarQABench\uff0c\u9019\u662f\u7b2c\u4e00\u500b\u91dd\u5c0d\u6587\u737b\u641c\u5c0b\u7684\u5927\u898f\u6a21\u591a\u9818\u57df\u57fa\u6e96\uff0c\u5305\u542b 2967 \u500b\u5c08\u5bb6\u64b0\u5beb\u7684\u554f\u984c\u548c 208 \u500b\u9577\u7bc7\u7b54\u6848\uff0c\u6db5\u84cb\u96fb\u8166\u79d1\u5b78\u3001\u7269\u7406\u5b78\u3001\u795e\u7d93\u79d1\u5b78\u548c\u751f\u7269\u91ab\u5b78\u3002\u5728 ScholarQABench \u4e0a\uff0cOpenScholar-8B \u5728\u6b63\u78ba\u6027\u65b9\u9762\u6bd4 GPT-4o \u9ad8\u51fa 5%\uff0c\u6bd4 PaperQA2 \u9ad8\u51fa 7%\uff0c\u5118\u7ba1\u5b83\u662f\u4e00\u500b\u8f03\u5c0f\u7684\u958b\u653e\u6a21\u578b\u3002\u96d6\u7136 GPT-4o \u5728 78% \u5230 90% \u7684\u6642\u9593\u5167\u6703\u7522\u751f\u5e7b\u89ba\u5f15\u6587\uff0c\u4f46 OpenScholar \u7684\u5f15\u6587\u6e96\u78ba\u5ea6\u8207\u4eba\u985e\u5c08\u5bb6\u4e0d\u76f8\u4e0a\u4e0b\u3002OpenScholar \u7684\u8cc7\u6599\u5132\u5b58\u5eab\u3001\u6aa2\u7d22\u5668\u548c\u81ea\u6211\u56de\u994b\u63a8\u7406\u8ff4\u5708\u4e5f\u6539\u9032\u4e86\u73fe\u6210\u7684 LM\uff1a\u4f8b\u5982\uff0cOpenScholar-GPT4o \u5c07 GPT-4o \u7684\u6b63\u78ba\u6027\u63d0\u9ad8\u4e86 12%\u3002\u5728\u4eba\u985e\u8a55\u4f30\u4e2d\uff0c\u5c08\u5bb6\u5206\u5225\u6709 51% \u548c 70% \u7684\u6642\u9593\u504f\u597d OpenScholar-8B \u548c OpenScholar-GPT4o \u56de\u61c9\uff0c\u800c GPT-4o \u70ba 32%\u3002\u6211\u5011\u958b\u653e\u539f\u59cb\u78bc\u3001\u6a21\u578b\u3001\u8cc7\u6599\u5132\u5b58\u5eab\u3001\u8cc7\u6599\u548c\u516c\u958b\u793a\u7bc4\u3002</paragraph>", "author": "Akari Asai et.al.", "authors": "Akari Asai, Jacqueline He, Rulin Shao, Weijia Shi, Amanpreet Singh, Joseph Chee Chang, Kyle Lo, Luca Soldaini, Sergey Feldman, Mike D'arcy, David Wadden, Matt Latzke, Minyang Tian, Pan Ji, Shengyan Liu, Hao Tong, Bohao Wu, Yanyu Xiong, Luke Zettlemoyer, Graham Neubig, Dan Weld, Doug Downey, Wen-tau Yih, Pang Wei Koh, Hannaneh Hajishirzi", "id": "2411.14199v1", "paper_url": "http://arxiv.org/abs/2411.14199v1", "repo": "https://github.com/akariasai/scholarbench"}}