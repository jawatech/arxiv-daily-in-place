
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-06-17**|**mDPO: Conditional Preference Optimization for Multimodal Large Language Models**|Fei Wang et.al.|[2406.11839v1](http://arxiv.org/abs/2406.11839v1)|null|
|**2024-06-17**|**MMDU: A Multi-Turn Multi-Image Dialog Understanding Benchmark and Instruction-Tuning Dataset for LVLMs**|Ziyu Liu et.al.|[2406.11833v1](http://arxiv.org/abs/2406.11833v1)|[link](https://github.com/liuziyu77/mmdu)|
|**2024-06-17**|**Language Modeling with Editable External Knowledge**|Belinda Z. Li et.al.|[2406.11830v1](http://arxiv.org/abs/2406.11830v1)|[link](https://github.com/belindal/erase)|
|**2024-06-17**|**WPO: Enhancing RLHF with Weighted Preference Optimization**|Wenxuan Zhou et.al.|[2406.11827v1](http://arxiv.org/abs/2406.11827v1)|[link](https://github.com/wzhouad/wpo)|
|**2024-06-17**|**On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning**|Geewook Kim et.al.|[2406.11823v1](http://arxiv.org/abs/2406.11823v1)|[link](https://github.com/naver-ai/elva)|
|**2024-06-17**|**Embodied Instruction Following in Unknown Environments**|Zhenyu Wu et.al.|[2406.11818v1](http://arxiv.org/abs/2406.11818v1)|null|
|**2024-06-17**|**Iterative Length-Regularized Direct Preference Optimization: A Case Study on Improving 7B Language Models to GPT-4 Level**|Jie Liu et.al.|[2406.11817v1](http://arxiv.org/abs/2406.11817v1)|null|
|**2024-06-17**|**How Do Large Language Models Acquire Factual Knowledge During Pretraining?**|Hoyeon Chang et.al.|[2406.11813v1](http://arxiv.org/abs/2406.11813v1)|null|
|**2024-06-17**|**RepLiQA: A Question-Answering Dataset for Benchmarking LLMs on Unseen Reference Content**|Joao Monteiro et.al.|[2406.11811v1](http://arxiv.org/abs/2406.11811v1)|null|
|**2024-06-17**|**Safety Arithmetic: A Framework for Test-time Safety Alignment of Language Models by Steering Parameters and Activations**|Rima Hazra et.al.|[2406.11801v1](http://arxiv.org/abs/2406.11801v1)|[link](https://github.com/declare-lab/safety-arithmetic)|
|**2024-06-17**|**DataComp-LM: In search of the next generation of training sets for language models**|Jeffrey Li et.al.|[2406.11794v1](http://arxiv.org/abs/2406.11794v1)|null|
|**2024-06-17**|**A Brief Survey on Leveraging Large Scale Vision Models for Enhanced Robot Grasping**|Abhi Kamboj et.al.|[2406.11786v1](http://arxiv.org/abs/2406.11786v1)|null|
|**2024-06-17**|**CELL your Model: Contrastive Explanation Methods for Large Language Models**|Ronny Luss et.al.|[2406.11785v1](http://arxiv.org/abs/2406.11785v1)|null|
|**2024-06-17**|**MDCR: A Dataset for Multi-Document Conditional Reasoning**|Peter Baile Chen et.al.|[2406.11784v1](http://arxiv.org/abs/2406.11784v1)|null|
|**2024-06-17**|**Split, Unlearn, Merge: Leveraging Data Attributes for More Effective Unlearning in LLMs**|Swanand Ravindra Kadhe et.al.|[2406.11780v1](http://arxiv.org/abs/2406.11780v1)|null|
|**2024-06-17**|**Improving Multi-Agent Debate with Sparse Communication Topology**|Yunxuan Li et.al.|[2406.11776v1](http://arxiv.org/abs/2406.11776v1)|null|
|**2024-06-17**|**Task Me Anything**|Jieyu Zhang et.al.|[2406.11775v1](http://arxiv.org/abs/2406.11775v1)|[link](https://github.com/jieyuz2/taskmeanything)|
|**2024-06-17**|**GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities**|Sreyan Ghosh et.al.|[2406.11768v1](http://arxiv.org/abs/2406.11768v1)|null|
|**2024-06-17**|**STAR: SocioTechnical Approach to Red Teaming Language Models**|Laura Weidinger et.al.|[2406.11757v1](http://arxiv.org/abs/2406.11757v1)|null|
|**2024-06-17**|**DustNet: skillful neural network predictions of Saharan dust**|Trish E. Nowak et.al.|[2406.11754v1](http://arxiv.org/abs/2406.11754v1)|null|
|**2024-06-17**|**A Semantic-based Layer Freezing Approach to Efficient Fine-Tuning of Language Models**|Jian Gu et.al.|[2406.11753v1](http://arxiv.org/abs/2406.11753v1)|null|
|**2024-06-17**|**Multi-Layer Ranking with Large Language Models for News Source Recommendation**|Wenjia Zhang et.al.|[2406.11745v1](http://arxiv.org/abs/2406.11745v1)|null|
|**2024-06-17**|**Transcendence: Generative Models Can Outperform The Experts That Train Them**|Edwin Zhang et.al.|[2406.11741v1](http://arxiv.org/abs/2406.11741v1)|null|
|**2024-06-17**|**Imagination Policy: Using Generative Point Cloud Models for Learning Manipulation Policies**|Haojie Huang et.al.|[2406.11740v1](http://arxiv.org/abs/2406.11740v1)|null|
|**2024-06-17**|**Interactive Evolution: A Neural-Symbolic Self-Training Framework For Large Language Models**|Fangzhi Xu et.al.|[2406.11736v1](http://arxiv.org/abs/2406.11736v1)|null|
|**2024-06-17**|**1000 African Voices: Advancing inclusive multi-speaker multi-accent speech synthesis**|Sewade Ogun et.al.|[2406.11727v1](http://arxiv.org/abs/2406.11727v1)|null|
|**2024-06-17**|**Zero-Shot Generalization during Instruction Tuning: Insights from Similarity and Granularity**|Bingxiang He et.al.|[2406.11721v1](http://arxiv.org/abs/2406.11721v1)|[link](https://github.com/hbx-hbx/dynamics_of_zero-shot_generalization)|
|**2024-06-17**|**Refusal in Language Models Is Mediated by a Single Direction**|Andy Arditi et.al.|[2406.11717v1](http://arxiv.org/abs/2406.11717v1)|null|
|**2024-06-17**|**Measuring memorization in RLHF for code completion**|Aneesh Pappu et.al.|[2406.11715v1](http://arxiv.org/abs/2406.11715v1)|null|
|**2024-06-17**|**Instruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical Questioning for Socratic Code Debugging**|Priyanka Kargupta et.al.|[2406.11709v1](http://arxiv.org/abs/2406.11709v1)|null|
|**2024-06-17**|**Prompts as Auto-Optimized Training Hyperparameters: Training Best-in-Class IR Models from Scratch with 10 Gold Labels**|Jasper Xian et.al.|[2406.11706v1](http://arxiv.org/abs/2406.11706v1)|null|
|**2024-06-17**|**Nemotron-4 340B Technical Report**|Nvidia et.al.|[2406.11704v1](http://arxiv.org/abs/2406.11704v1)|null|
|**2024-06-17**|**Meta Reasoning for Large Language Models**|Peizhong Gao et.al.|[2406.11698v1](http://arxiv.org/abs/2406.11698v1)|null|
|**2024-06-17**|**Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs**|Krista Opsahl-Ong et.al.|[2406.11695v1](http://arxiv.org/abs/2406.11695v1)|[link](https://github.com/stanfordnlp/dspy)|
|**2024-06-17**|**Tokenization Falling Short: The Curse of Tokenization**|Yekun Chai et.al.|[2406.11687v1](http://arxiv.org/abs/2406.11687v1)|null|
|**2024-06-17**|**HoLLMwood: Unleashing the Creativity of Large Language Models in Screenwriting via Role Playing**|Jing Chen et.al.|[2406.11683v1](http://arxiv.org/abs/2406.11683v1)|null|
|**2024-06-17**|**Knowledge-to-Jailbreak: One Knowledge Point Worth One Attack**|Shangqing Tu et.al.|[2406.11682v1](http://arxiv.org/abs/2406.11682v1)|[link](https://github.com/thu-keg/knowledge-to-jailbreak)|
|**2024-06-17**|**R-Eval: A Unified Toolkit for Evaluating Domain Knowledge of Retrieval Augmented Large Language Models**|Shangqing Tu et.al.|[2406.11681v1](http://arxiv.org/abs/2406.11681v1)|[link](https://github.com/thu-keg/r-eval)|
|**2024-06-17**|**TourRank: Utilizing Large Language Models for Documents Ranking with a Tournament-Inspired Strategy**|Yiqun Chen et.al.|[2406.11678v1](http://arxiv.org/abs/2406.11678v1)|null|
|**2024-06-17**|**BLoB: Bayesian Low-Rank Adaptation by Backpropagation for Large Language Models**|Yibin Wang et.al.|[2406.11675v1](http://arxiv.org/abs/2406.11675v1)|null|
|**2024-06-17**|**Endor: Hardware-Friendly Sparse Format for Offloaded LLM Inference**|Donghyeon Joo et.al.|[2406.11674v1](http://arxiv.org/abs/2406.11674v1)|null|
|**2024-06-17**|**Benchmarking of LLM Detection: Comparing Two Competing Approaches**|Thorsten Pr√∂hl et.al.|[2406.11670v1](http://arxiv.org/abs/2406.11670v1)|null|
|**2024-06-17**|**"Not Aligned" is Not "Malicious": Being Careful about Hallucinations of Large Language Models' Jailbreak**|Lingrui Mei et.al.|[2406.11668v1](http://arxiv.org/abs/2406.11668v1)|null|
|**2024-06-17**|**See It from My Perspective: Diagnosing the Western Cultural Bias of Large Vision-Language Models in Image Understanding**|Amith Ananthram et.al.|[2406.11665v1](http://arxiv.org/abs/2406.11665v1)|[link](https://github.com/amith-ananthram/see-it-from-my-perspective)|
|**2024-06-17**|**Cultural Conditioning or Placebo? On the Effectiveness of Socio-Demographic Prompting**|Sagnik Mukherjee et.al.|[2406.11661v1](http://arxiv.org/abs/2406.11661v1)|null|
|**2024-06-17**|**Can LLM be a Personalized Judge?**|Yijiang River Dong et.al.|[2406.11657v1](http://arxiv.org/abs/2406.11657v1)|[link](https://github.com/dong-river/personalized-judge)|
|**2024-06-17**|**A Two-dimensional Zero-shot Dialogue State Tracking Evaluation Method using GPT-4**|Ming Gu et.al.|[2406.11651v1](http://arxiv.org/abs/2406.11651v1)|null|
|**2024-06-17**|**YOLO-FEDER FusionNet: A Novel Deep Learning Architecture for Drone Detection**|Tamara R. Lenhard et.al.|[2406.11641v1](http://arxiv.org/abs/2406.11641v1)|null|
|**2024-06-17**|**Linear Bellman Completeness Suffices for Efficient Online Reinforcement Learning with Few Actions**|Noah Golowich et.al.|[2406.11640v1](http://arxiv.org/abs/2406.11640v1)|null|
|**2024-06-17**|**MASAI: Modular Architecture for Software-engineering AI Agents**|Daman Arora et.al.|[2406.11638v1](http://arxiv.org/abs/2406.11638v1)|null|
|**2024-06-17**|**The Base-Rate Effect on LLM Benchmark Performance: Disambiguating Test-Taking Strategies from Benchmark Performance**|Kyle Moore et.al.|[2406.11634v1](http://arxiv.org/abs/2406.11634v1)|null|
|**2024-06-17**|**Unveiling the Power of Source: Source-based Minimum Bayes Risk Decoding for Neural Machine Translation**|Boxuan Lyu et.al.|[2406.11632v1](http://arxiv.org/abs/2406.11632v1)|null|
|**2024-06-17**|**Can Many-Shot In-Context Learning Help Long-Context LLM Judges? See More, Judge Better!**|Mingyang Song et.al.|[2406.11629v1](http://arxiv.org/abs/2406.11629v1)|null|
|**2024-06-17**|**Words in Motion: Representation Engineering for Motion Forecasting**|Omer Sahin Tas et.al.|[2406.11624v1](http://arxiv.org/abs/2406.11624v1)|[link](https://github.com/kit-mrt/future-motion)|
|**2024-06-17**|**Building Knowledge-Guided Lexica to Model Cultural Variation**|Shreya Havaldar et.al.|[2406.11622v1](http://arxiv.org/abs/2406.11622v1)|null|
|**2024-06-17**|**DELLA-Merging: Reducing Interference in Model Merging through Magnitude-Based Sampling**|Pala Tej Deep et.al.|[2406.11617v1](http://arxiv.org/abs/2406.11617v1)|[link](https://github.com/declare-lab/della)|
|**2024-06-17**|**Intrinsic Evaluation of Unlearning Using Parametric Knowledge Traces**|Yihuai Hong et.al.|[2406.11614v1](http://arxiv.org/abs/2406.11614v1)|[link](https://github.com/yihuaihong/conceptvectors)|
|**2024-06-17**|**Long Code Arena: a Set of Benchmarks for Long-Context Code Models**|Egor Bogomolov et.al.|[2406.11612v1](http://arxiv.org/abs/2406.11612v1)|null|
|**2024-06-17**|**Understanding "Democratization" in NLP and ML Research**|Arjun Subramonian et.al.|[2406.11598v1](http://arxiv.org/abs/2406.11598v1)|null|
|**2024-06-17**|**CoSQA+: Enhancing Code Search Dataset with Matching Code**|Jing Gong et.al.|[2406.11589v1](http://arxiv.org/abs/2406.11589v1)|[link](https://github.com/DeepSoftwareAnalytics/CoSQA_Plus)|
|**2024-06-17**|**Style Transfer with Multi-iteration Preference Optimization**|Shuai Liu et.al.|[2406.11581v1](http://arxiv.org/abs/2406.11581v1)|null|
|**2024-06-17**|**Error Span Annotation: A Balanced Approach for Human Evaluation of Machine Translation**|Tom Kocmi et.al.|[2406.11580v1](http://arxiv.org/abs/2406.11580v1)|null|
|**2024-06-17**|**Mathematical Entities: Corpora and Benchmarks**|Jacob Collard et.al.|[2406.11577v1](http://arxiv.org/abs/2406.11577v1)|null|
|**2024-06-17**|**Towards an End-to-End Framework for Invasive Brain Signal Decoding with Large Language Models**|Sheng Feng et.al.|[2406.11568v1](http://arxiv.org/abs/2406.11568v1)|[link](https://github.com/fsfrancis15/brainllm)|
|**2024-06-17**|**Quaternion Generative Adversarial Neural Networks and Applications to Color Image Inpainting**|Duan Wang et.al.|[2406.11567v1](http://arxiv.org/abs/2406.11567v1)|null|
|**2024-06-17**|**MEMLA: Enhancing Multilingual Knowledge Editing with Neuron-Masked Low-Rank Adaptation**|Jiakuan Xie et.al.|[2406.11566v1](http://arxiv.org/abs/2406.11566v1)|null|
|**2024-06-17**|**Extrinsic Evaluation of Cultural Competence in Large Language Models**|Shaily Bhatt et.al.|[2406.11565v1](http://arxiv.org/abs/2406.11565v1)|null|
|**2024-06-17**|**Input Conditioned Graph Generation for Language Agents**|Lukas Vierling et.al.|[2406.11555v1](http://arxiv.org/abs/2406.11555v1)|[link](https://github.com/lukasvierling/dynamicgptswarm)|
|**2024-06-17**|**AIC MLLM: Autonomous Interactive Correction MLLM for Robust Robotic Manipulation**|Chuyan Xiong et.al.|[2406.11548v1](http://arxiv.org/abs/2406.11548v1)|null|
|**2024-06-17**|**GECOBench: A Gender-Controlled Text Dataset and Benchmark for Quantifying Biases in Explanations**|Rick Wilming et.al.|[2406.11547v1](http://arxiv.org/abs/2406.11547v1)|[link](https://github.com/braindatalab/gecobench)|
|**2024-06-17**|**GigaSpeech 2: An Evolving, Large-Scale and Multi-domain ASR Corpus for Low-Resource Languages with Automated Crawling, Transcription and Refinement**|Yifan Yang et.al.|[2406.11546v1](http://arxiv.org/abs/2406.11546v1)|null|
|**2024-06-17**|**Do Parameters Reveal More than Loss for Membership Inference?**|Anshuman Suri et.al.|[2406.11544v1](http://arxiv.org/abs/2406.11544v1)|[link](https://github.com/iamgroot42/iha_hild)|
|**2024-06-17**|**Improving Quality Control of Whole Slide Images by Explicit Artifact Augmentation**|Artur Jurgas et.al.|[2406.11538v1](http://arxiv.org/abs/2406.11538v1)|null|
|**2024-06-17**|**Explainable Artificial Intelligence and Multicollinearity : A Mini Review of Current Approaches**|Ahmed M Salih et.al.|[2406.11524v1](http://arxiv.org/abs/2406.11524v1)|null|
|**2024-06-17**|**FullCert: Deterministic End-to-End Certification for Training and Inference of Neural Networks**|Tobias Lorenz et.al.|[2406.11522v1](http://arxiv.org/abs/2406.11522v1)|null|
|**2024-06-17**|**Revisiting Spurious Correlation in Domain Generalization**|Bin Qin et.al.|[2406.11517v1](http://arxiv.org/abs/2406.11517v1)|null|
|**2024-06-17**|**Counterfactual Debating with Preset Stances for Hallucination Elimination of LLMs**|Yi Fang et.al.|[2406.11514v1](http://arxiv.org/abs/2406.11514v1)|null|
|**2024-06-17**|**On the Feasibility of Fidelity$^-$ for Graph Pruning**|Yong-Min Shin et.al.|[2406.11504v1](http://arxiv.org/abs/2406.11504v1)|null|
|**2024-06-17**|**GeoGPT4V: Towards Geometric Multi-modal Large Language Models with Geometric Image Generation**|Shihao Cai et.al.|[2406.11503v1](http://arxiv.org/abs/2406.11503v1)|null|
|**2024-06-17**|**Teleporter Theory: A General and Simple Approach for Modeling Cross-World Counterfactual Causality**|Jiangmeng Li et.al.|[2406.11501v1](http://arxiv.org/abs/2406.11501v1)|null|
|**2024-06-17**|**CrAM: Credibility-Aware Attention Modification in LLMs for Combating Misinformation in RAG**|Boyi Deng et.al.|[2406.11497v1](http://arxiv.org/abs/2406.11497v1)|null|
|**2024-06-17**|**Analysing zero-shot temporal relation extraction on clinical notes using temporal consistency**|Vasiliki Kougia et.al.|[2406.11486v1](http://arxiv.org/abs/2406.11486v1)|null|
|**2024-06-17**|**Constrained Reinforcement Learning with Average Reward Objective: Model-Based and Model-Free Algorithms**|Vaneet Aggarwal et.al.|[2406.11481v1](http://arxiv.org/abs/2406.11481v1)|null|
|**2024-06-17**|**Vocabulary Expansion for Low-resource Cross-lingual Transfer**|Atsuki Yamaguchi et.al.|[2406.11477v1](http://arxiv.org/abs/2406.11477v1)|null|
|**2024-06-17**|**How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment**|Heyan Huang et.al.|[2406.11474v1](http://arxiv.org/abs/2406.11474v1)|null|
|**2024-06-17**|**Promises, Outlooks and Challenges of Diffusion Language Modeling**|Justin Deschenaux et.al.|[2406.11473v1](http://arxiv.org/abs/2406.11473v1)|null|
|**2024-06-17**|**Automating Easy Read Text Segmentation**|Jes√∫s Calleja et.al.|[2406.11464v1](http://arxiv.org/abs/2406.11464v1)|null|
|**2024-06-17**|**TRACE the Evidence: Constructing Knowledge-Grounded Reasoning Chains for Retrieval-Augmented Generation**|Jinyuan Fang et.al.|[2406.11460v1](http://arxiv.org/abs/2406.11460v1)|[link](https://github.com/jyfang6/trace)|
|**2024-06-17**|**Adaptive Reinforcement Learning Planning: Harnessing Large Language Models for Complex Information Extraction**|Zepeng Ding et.al.|[2406.11455v1](http://arxiv.org/abs/2406.11455v1)|null|
|**2024-06-17**|**GPT-Powered Elicitation Interview Script Generator for Requirements Engineering Training**|Binnur G√∂rer et.al.|[2406.11439v1](http://arxiv.org/abs/2406.11439v1)|null|
|**2024-06-17**|**Analysing the Behaviour of Tree-Based Neural Networks in Regression Tasks**|Peter Samoaa et.al.|[2406.11437v1](http://arxiv.org/abs/2406.11437v1)|[link](https://github.com/petersamoaa/tree_based_nn_error_analysis)|
|**2024-06-17**|**AnyTrans: Translate AnyText in the Image with Large Scale Models**|Zhipeng Qian et.al.|[2406.11432v1](http://arxiv.org/abs/2406.11432v1)|null|
|**2024-06-17**|**Super(ficial)-alignment: Strong Models May Deceive Weak Models in Weak-to-Strong Generalization**|Wenkai Yang et.al.|[2406.11431v1](http://arxiv.org/abs/2406.11431v1)|[link](https://github.com/keven980716/weak-to-strong-deception)|
|**2024-06-17**|**A Simple and Effective $L_2$ Norm-Based Strategy for KV Cache Compression**|Alessio Devoto et.al.|[2406.11430v1](http://arxiv.org/abs/2406.11430v1)|null|
|**2024-06-17**|**DiTTo-TTS: Efficient and Scalable Zero-Shot Text-to-Speech with Diffusion Transformer**|Keon Lee et.al.|[2406.11427v1](http://arxiv.org/abs/2406.11427v1)|null|
|**2024-06-17**|**Evaluating the Efficacy of Open-Source LLMs in Enterprise-Specific RAG Systems: A Comparative Study of Performance and Scalability**|Gautam B et.al.|[2406.11424v1](http://arxiv.org/abs/2406.11424v1)|[link](https://github.com/amaze18/RAGbot-OpenSource-Comparison/blob/main/Hybrid_Topk_similarity_expt.ipynb)|
|**2024-06-17**|**Dredge Word, Social Media, and Webgraph Networks for Unreliable Website Classification and Identification**|Evan M. Williams et.al.|[2406.11423v1](http://arxiv.org/abs/2406.11423v1)|null|
|**2024-06-17**|**BAMBINO-LM: (Bilingual-)Human-Inspired Continual Pretraining of BabyLM**|Zhewen Shen et.al.|[2406.11418v1](http://arxiv.org/abs/2406.11418v1)|null|
|**2024-06-17**|**Formally Certified Approximate Model Counting**|Yong Kiam Tan et.al.|[2406.11414v1](http://arxiv.org/abs/2406.11414v1)|null|
|**2024-06-17**|**HARE: HumAn pRiors, a key to small language model Efficiency**|Lingyun Zhang et.al.|[2406.11410v1](http://arxiv.org/abs/2406.11410v1)|[link](https://github.com/liteai-team/hare)|

#### Abstracts
##### **mDPO: Conditional Preference Optimization for Multimodal Large Language Models**
2406.11839v1 by Fei Wang, Wenxuan Zhou, James Y. Huang, Nan Xu, Sheng Zhang, Hoifung Poon, Muhao Chen

Direct preference optimization (DPO) has shown to be an effective method for
large language model (LLM) alignment. Recent works have attempted to apply DPO
to multimodal scenarios but have found it challenging to achieve consistent
improvement. Through a comparative experiment, we identify the unconditional
preference problem in multimodal preference optimization, where the model
overlooks the image condition. To address this problem, we propose mDPO, a
multimodal DPO objective that prevents the over-prioritization of language-only
preferences by also optimizing image preference. Moreover, we introduce a
reward anchor that forces the reward to be positive for chosen responses,
thereby avoiding the decrease in their likelihood -- an intrinsic problem of
relative preference optimization. Experiments on two multimodal LLMs of
different sizes and three widely used benchmarks demonstrate that mDPO
effectively addresses the unconditional preference problem in multimodal
preference optimization and significantly improves model performance,
particularly in reducing hallucination.

ÊëòË¶ÅÔºöÁõ¥Êé•ÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (DPO) Â∑≤Ë¢´Ë≠âÊòéÊòØÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∞çÈΩäÁöÑÊúâÊïàÊñπÊ≥ï„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Â∑≤ÂòóË©¶Â∞á DPO ÊáâÁî®ÊñºÂ§öÊ®°ÊÖãÂ†¥ÊôØÔºå‰ΩÜÁôºÁèæÈõ£‰ª•ÈÅîÊàê‰∏ÄËá¥ÁöÑÊîπÂñÑ„ÄÇÈÄèÈÅéÊØîËºÉÂØ¶È©óÔºåÊàëÂÄëÊâæÂá∫Â§öÊ®°ÊÖãÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ‰∏≠ÁöÑÁÑ°Ê¢ù‰ª∂ÂÅèÂ•ΩÂïèÈ°åÔºåÂÖ∂‰∏≠Ê®°ÂûãÂøΩÁï•‰∫ÜÂΩ±ÂÉèÊ¢ù‰ª∂„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫ mDPOÔºå‰∏ÄÁ®ÆÂ§öÊ®°ÊÖã DPO ÁõÆÊ®ôÔºåÈÄèÈÅéÊúÄ‰Ω≥ÂåñÂΩ±ÂÉèÂÅèÂ•Ω‰æÜÈò≤Ê≠¢ÈÅéÂ∫¶ÂÑ™ÂÖàËÄÉÊÖÆÂÉÖË™ûË®ÄÁöÑÂÅèÂ•Ω„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÁçéÂãµÈå®ÈªûÔºåÂº∑Âà∂ÁçéÂãµÂ∞çÊâÄÈÅ∏ÂõûÊáâÁÇ∫Ê≠£ÂÄºÔºåÂæûËÄåÈÅøÂÖçÂÖ∂ÂèØËÉΩÊÄßÈôç‰Ωé‚Äî‚ÄîÈÄôÊòØÁõ∏Â∞çÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÁöÑÂÖßÂú®ÂïèÈ°å„ÄÇÂú®‰∏çÂêåÂ§ßÂ∞èÁöÑÂÖ©ÂÄãÂ§öÊ®°ÊÖã LLM Âíå‰∏âÂÄãÂª£Ê≥õ‰ΩøÁî®ÁöÑÂü∫Ê∫ñ‰∏äÁöÑÂØ¶È©óË≠âÊòéÔºåmDPO ÊúâÊïàÂú∞Ëß£Ê±∫‰∫ÜÂ§öÊ®°ÊÖãÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ‰∏≠ÁöÑÁÑ°Ê¢ù‰ª∂ÂÅèÂ•ΩÂïèÈ°åÔºå‰∏¶È°ØËëóÊîπÂñÑ‰∫ÜÊ®°ÂûãÊïàËÉΩÔºåÁâπÂà•ÊòØÂú®Ê∏õÂ∞ëÂπªË¶∫ÊñπÈù¢„ÄÇ

##### **MMDU: A Multi-Turn Multi-Image Dialog Understanding Benchmark and Instruction-Tuning Dataset for LVLMs**
2406.11833v1 by Ziyu Liu, Tao Chu, Yuhang Zang, Xilin Wei, Xiaoyi Dong, Pan Zhang, Zijian Liang, Yuanjun Xiong, Yu Qiao, Dahua Lin, Jiaqi Wang

Generating natural and meaningful responses to communicate with multi-modal
human inputs is a fundamental capability of Large Vision-Language
Models(LVLMs). While current open-source LVLMs demonstrate promising
performance in simplified scenarios such as single-turn single-image input,
they fall short in real-world conversation scenarios such as following
instructions in a long context history with multi-turn and multi-images.
Existing LVLM benchmarks primarily focus on single-choice questions or
short-form responses, which do not adequately assess the capabilities of LVLMs
in real-world human-AI interaction applications. Therefore, we introduce MMDU,
a comprehensive benchmark, and MMDU-45k, a large-scale instruction tuning
dataset, designed to evaluate and improve LVLMs' abilities in multi-turn and
multi-image conversations. We employ the clustering algorithm to ffnd the
relevant images and textual descriptions from the open-source Wikipedia and
construct the question-answer pairs by human annotators with the assistance of
the GPT-4o model. MMDU has a maximum of 18k image+text tokens, 20 images, and
27 turns, which is at least 5x longer than previous benchmarks and poses
challenges to current LVLMs. Our in-depth analysis of 15 representative LVLMs
using MMDU reveals that open-source LVLMs lag behind closed-source counterparts
due to limited conversational instruction tuning data. We demonstrate that
ffne-tuning open-source LVLMs on MMDU-45k signiffcantly address this gap,
generating longer and more accurate conversations, and improving scores on MMDU
and existing benchmarks (MMStar: +1.1%, MathVista: +1.5%, ChartQA:+1.2%). Our
contributions pave the way for bridging the gap between current LVLM models and
real-world application demands. This project is available at
https://github.com/Liuziyu77/MMDU.

ÊëòË¶ÅÔºöÁîüÊàêËá™ÁÑ∂‰∏îÊúâÊÑèÁæ©ÁöÑÂõûÊáâÔºåËàáÂ§öÊ®°ÊÖã‰∫∫È°ûËº∏ÂÖ•ÈÄ≤Ë°åÊ∫ùÈÄöÔºåÊòØÂ§ßÂûãË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (LVLMs) ÁöÑÂü∫Êú¨ËÉΩÂäõ„ÄÇÈõñÁÑ∂ÁõÆÂâçÁöÑÈñãÊ∫ê LVLMs Âú®Á∞°ÂåñÁöÑÂ†¥ÊôØ‰∏≠Â±ïÁèæÂá∫ÊúâÂ∏åÊúõÁöÑË°®ÁèæÔºå‰æãÂ¶ÇÂñÆÊ¨°Ëº™ÊèõÂñÆ‰∏ÄÂΩ±ÂÉèËº∏ÂÖ•Ôºå‰ΩÜÂÆÉÂÄëÂú®ÁèæÂØ¶‰∏ñÁïåÁöÑÂ∞çË©±Â†¥ÊôØ‰∏≠ÂçªË°®Áèæ‰∏ç‰Ω≥Ôºå‰æãÂ¶ÇÂú®ÂÖ∑ÊúâÂ§öËº™ÊèõÂíåÂ§öÂΩ±ÂÉèÁöÑÈï∑Ë™ûÂ¢ÉÊ≠∑Âè≤‰∏≠ÈÅµÂæ™ÊåáÁ§∫„ÄÇÁèæÊúâÁöÑ LVLM Âü∫Ê∫ñ‰∏ªË¶ÅÈóúÊ≥®ÂñÆÈÅ∏È°åÊàñÁü≠ÁØáÂõûÊáâÔºåÈÄô‰∏¶‰∏çËÉΩÂÖÖÂàÜË©ï‰º∞ LVLMs Âú®ÁèæÂØ¶‰∏ñÁïåÁöÑ‰∫∫Â∑•Êô∫ÊÖß‰∫íÂãïÊáâÁî®‰∏≠ÁöÑËÉΩÂäõ„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü MMDUÔºå‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÂü∫Ê∫ñÊ∏¨Ë©¶Ôºå‰ª•Âèä MMDU-45kÔºå‰∏ÄÂÄãÂ§ßË¶èÊ®°ÁöÑÊåá‰ª§Ë™øÊï¥Ë≥áÊñôÈõÜÔºåÊó®Âú®Ë©ï‰º∞ÂíåÊèêÂçá LVLMs Âú®Â§öËº™ÊèõÂíåÂ§öÂΩ±ÂÉèÂ∞çË©±‰∏≠ÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÊé°Áî®Áæ§ÈõÜÊºîÁÆóÊ≥ïÂæûÈñãÊ∫êÁ∂≠Âü∫ÁôæÁßë‰∏≠ÊâæÂá∫Áõ∏ÈóúÁöÑÂΩ±ÂÉèÂíåÊñáÂ≠óÊèèËø∞Ôºå‰∏¶Âú® GPT-4o Ê®°ÂûãÁöÑÂçîÂä©‰∏ãÔºåÁî±‰∫∫Â∑•Ë®ªËß£ËÄÖÂª∫ÊßãÂïèÁ≠îÈÖçÂ∞ç„ÄÇMMDU ÊúÄÂ§öÊúâ 18k ÂÄãÂΩ±ÂÉè + ÊñáÂ≠óÁ¨¶Ëôü„ÄÅ20 ÂÄãÂΩ±ÂÉèÂíå 27 ÂÄãËº™ÊèõÔºåÈÄôËá≥Â∞ëÊØîÂÖàÂâçÁöÑÂü∫Ê∫ñÊ∏¨Ë©¶Èï∑ 5 ÂÄçÔºå‰∏¶Â∞çÁõÆÂâçÁöÑ LVLMs ÊßãÊàêÊåëÊà∞„ÄÇÊàëÂÄë‰ΩøÁî® MMDU Â∞ç 15 ÂÄãÂÖ∑‰ª£Ë°®ÊÄßÁöÑ LVLMs ÈÄ≤Ë°åÊ∑±ÂÖ•ÂàÜÊûêÔºåÁôºÁèæÈñãÊ∫ê LVLMs Áî±ÊñºÂ∞çË©±ÂºèÊåá‰ª§Ë™øÊï¥Ë≥áÊñôÊúâÈôêÔºåËÄåËêΩÂæåÊñºÈñâÊ∫êÂ∞çÊáâÁ®ãÂºè„ÄÇÊàëÂÄëË≠âÊòé‰∫ÜÂú® MMDU-45k ‰∏äÂæÆË™øÈñãÊ∫ê LVLMs ÂèØ‰ª•È°ØËëóËß£Ê±∫Ê≠§Â∑ÆË∑ùÔºåÁî¢ÁîüÊõ¥Èï∑‰∏îÊõ¥Ê∫ñÁ¢∫ÁöÑÂ∞çË©±Ôºå‰∏¶ÊèêÂçá MMDU ÂíåÁèæÊúâÂü∫Ê∫ñÊ∏¨Ë©¶ÁöÑÂàÜÊï∏ (MMStarÔºö+1.1%ÔºåMathVistaÔºö+1.5%ÔºåChartQAÔºö+1.2%)„ÄÇÊàëÂÄëÁöÑË≤¢ÁçªÁÇ∫Á∏ÆÂ∞èÁõÆÂâç LVLM Ê®°ÂûãËàáÁèæÂØ¶‰∏ñÁïåÊáâÁî®ÈúÄÊ±Ç‰πãÈñìÁöÑÂ∑ÆË∑ùÈã™Ë∑Ø„ÄÇÈÄôÂÄãÂ∞àÊ°àÂèØÂú® https://github.com/Liuziyu77/MMDU ÂèñÂæó„ÄÇ

##### **Language Modeling with Editable External Knowledge**
2406.11830v1 by Belinda Z. Li, Emmy Liu, Alexis Ross, Abbas Zeitoun, Graham Neubig, Jacob Andreas

When the world changes, so does the text that humans write about it. How do
we build language models that can be easily updated to reflect these changes?
One popular approach is retrieval-augmented generation, in which new documents
are inserted into a knowledge base and retrieved during prediction for
downstream tasks. Most prior work on these systems have focused on improving
behavior during prediction through better retrieval or reasoning. This paper
introduces ERASE, which instead improves model behavior when new documents are
acquired, by incrementally deleting or rewriting other entries in the knowledge
base each time a document is added. In two new benchmark datasets evaluating
models' ability to answer questions about a stream of news articles or
conversations, ERASE improves accuracy relative to conventional
retrieval-augmented generation by 7-13% (Mixtral-8x7B) and 6-10% (Llama-3-8B)
absolute. Code and data are available at https://github.com/belindal/ERASE

ÊëòË¶ÅÔºöÁï∂‰∏ñÁïåÊîπËÆäÔºå‰∫∫È°ûÂ∞çÂÆÉÁöÑÊñáÂ≠óÊõ∏ÂØ´‰πüË∑üËëóÊîπËÆä„ÄÇÊàëÂÄëÂ¶Ç‰ΩïÂª∫ÊßãÂèØ‰ª•ËºïÊòìÊõ¥Êñ∞‰ª•ÂèçÊò†ÈÄô‰∫õÊîπËÆäÁöÑË™ûË®ÄÊ®°ÂûãÔºü‰∏ÄÁ®ÆÂª£ÂèóÊ≠°ËøéÁöÑÊñπÊ≥ïÊòØÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÔºåÂÖ∂‰∏≠Êñ∞ÁöÑÊñá‰ª∂ÊúÉÊèíÂÖ•Âà∞Áü•Ë≠òÂ∫´‰∏≠Ôºå‰∏¶Âú®È†êÊ∏¨‰∏≠Ê™¢Á¥¢‰ª•ÈÄ≤Ë°å‰∏ãÊ∏∏‰ªªÂãô„ÄÇÈÄô‰∫õÁ≥ªÁµ±ÁöÑÂ§ßÈÉ®ÂàÜÂÖàÂâçÂ∑•‰ΩúÈÉΩÂ∞àÊ≥®ÊñºÈÄèÈÅéÊõ¥Â•ΩÁöÑÊ™¢Á¥¢ÊàñÊé®ÁêÜ‰æÜÊîπÂñÑÈ†êÊ∏¨ÊúüÈñìÁöÑË°åÁÇ∫„ÄÇÊú¨Êñá‰ªãÁ¥π ERASEÔºåÂÆÉÂú®ÂèñÂæóÊñ∞Êñá‰ª∂ÊôÇÊîπÂñÑÊ®°ÂûãË°åÁÇ∫ÔºåÈÄèÈÅéÊØèÊ¨°Êñ∞Â¢ûÊñá‰ª∂ÊôÇÈÅûÂ¢ûÂà™Èô§ÊàñÊîπÂØ´Áü•Ë≠òÂ∫´‰∏≠ÁöÑÂÖ∂‰ªñÊ¢ùÁõÆ„ÄÇÂú®ÂÖ©ÂÄãÊñ∞ÁöÑÂü∫Ê∫ñË≥áÊñôÈõÜË©ï‰º∞Ê®°ÂûãÂõûÁ≠îÊñ∞ËÅûÊñáÁ´†ÊàñÂ∞çË©±‰∏≤ÊµÅÂïèÈ°åÁöÑËÉΩÂäõÔºåERASE Áõ∏ËºÉÊñºÂÇ≥Áµ±ÁöÑÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÔºåÊ∫ñÁ¢∫ÊÄßÊèêÂçá 7-13%ÔºàMixtral-8x7BÔºâÂíå 6-10%ÔºàLlama-3-8BÔºâÁµïÂ∞çÂÄº„ÄÇÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÂèØÊñº https://github.com/belindal/ERASE ÂèñÂæó

##### **WPO: Enhancing RLHF with Weighted Preference Optimization**
2406.11827v1 by Wenxuan Zhou, Ravi Agrawal, Shujian Zhang, Sathish Reddy Indurthi, Sanqiang Zhao, Kaiqiang Song, Silei Xu, Chenguang Zhu

Reinforcement learning from human feedback (RLHF) is a promising solution to
align large language models (LLMs) more closely with human values. Off-policy
preference optimization, where the preference data is obtained from other
models, is widely adopted due to its cost efficiency and scalability. However,
off-policy preference optimization often suffers from a distributional gap
between the policy used for data collection and the target policy, leading to
suboptimal optimization. In this paper, we propose a novel strategy to mitigate
this problem by simulating on-policy learning with off-policy preference data.
Our Weighted Preference Optimization (WPO) method adapts off-policy data to
resemble on-policy data more closely by reweighting preference pairs according
to their probability under the current policy. This method not only addresses
the distributional gap problem but also enhances the optimization process
without incurring additional costs. We validate our method on instruction
following benchmarks including Alpaca Eval 2 and MT-bench. WPO not only
outperforms Direct Preference Optimization (DPO) by up to 5.6% on Alpaca Eval 2
but also establishes a remarkable length-controlled winning rate against
GPT-4-turbo of 48.6% based on Llama-3-8B-Instruct, making it the strongest 8B
model on the leaderboard. We will release the code and models at
https://github.com/wzhouad/WPO.

ÊëòË¶ÅÔºö‰∫∫È°ûÂõûÈ•ãÂº∑ÂåñÂ≠∏Áøí (RLHF) ÊòØËÆìÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Êõ¥Á¨¶Âêà‰∫∫È°ûÂÉπÂÄºËßÄÁöÑÊúâÂâçÈÄîÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÈõ¢Á∑öÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÔºàÂÅèÂ•ΩÊï∏ÊìöÂæûÂÖ∂‰ªñÊ®°ÂûãÂèñÂæóÔºâÂõ†ÂÖ∂ÊàêÊú¨ÊïàÁõäÂíåÂèØÊì¥ÂÖÖÊÄßËÄåÂª£Ê≥õÊé°Áî®„ÄÇÁÑ∂ËÄåÔºåÈõ¢Á∑öÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÁ∂ìÂ∏∏ÊúÉÂõ†Áî®ÊñºÊï∏ÊìöÊî∂ÈõÜÁöÑÊîøÁ≠ñÂíåÁõÆÊ®ôÊîøÁ≠ñ‰πãÈñìÁöÑÂàÜÈÖçÂ∑ÆË∑ùËÄåÂèóËã¶ÔºåÂ∞éËá¥Ê¨°‰Ω≥ÊúÄ‰Ω≥Âåñ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÁ≠ñÁï•ÔºåÈÄèÈÅéÊ®°Êì¨Âú®Á∑öÊîøÁ≠ñÂ≠∏ÁøíËàáÈõ¢Á∑öÂÅèÂ•ΩÊï∏Êìö‰æÜÊ∏õËºïÊ≠§ÂïèÈ°å„ÄÇÊàëÂÄëÁöÑÂä†Ê¨äÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (WPO) ÊñπÊ≥ïÊúÉË™øÊï¥Èõ¢Á∑öÊï∏ÊìöÔºå‰ΩøÂÖ∂Êõ¥Êé•ËøëÂú®Á∑öÊîøÁ≠ñÊï∏ÊìöÔºåÊñπÊ≥ïÊòØÊ†πÊìöÁï∂ÂâçÊîøÁ≠ñÁöÑÊ©üÁéáÈáçÊñ∞Âä†Ê¨äÂÅèÂ•ΩÈÖçÂ∞ç„ÄÇÊ≠§ÊñπÊ≥ï‰∏çÂÉÖËß£Ê±∫‰∫ÜÂàÜÈÖçÂ∑ÆË∑ùÂïèÈ°åÔºåÈÇÑÂ¢ûÂº∑‰∫ÜÊúÄ‰Ω≥ÂåñÊµÅÁ®ãÔºåËÄå‰∏çÊúÉÁî¢ÁîüÈ°çÂ§ñÊàêÊú¨„ÄÇÊàëÂÄëÂú®ÂåÖÊã¨ Alpaca Eval 2 Âíå MT-bench Âú®ÂÖßÁöÑÊåá‰ª§ÈÅµÂæ™Âü∫Ê∫ñ‰∏äÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÊ®°Âûã„ÄÇWPO ‰∏çÂÉÖÂú® Alpaca Eval 2 ‰∏äÊØîÁõ¥Êé•ÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (DPO) È´òÂá∫ 5.6%ÔºåÈÇÑÊ†πÊìö Llama-3-8B-Instruct Âª∫Á´ã‰∫ÜËàá GPT-4-turbo Áõ∏ÊäóË°°ÁöÑ 48.6% Èï∑Â∫¶ÊéßÂà∂Áç≤ÂãùÁéáÔºå‰ΩøÂÖ∂ÊàêÁÇ∫ÊéíË°åÊ¶ú‰∏äÊúÄÂº∑Â§ßÁöÑ 8B Ê®°Âûã„ÄÇÊàëÂÄëÂ∞áÂú® https://github.com/wzhouad/WPO ÈáãÂá∫Á®ãÂºèÁ¢ºÂíåÊ®°Âûã„ÄÇ

##### **On Efficient Language and Vision Assistants for Visually-Situated Natural Language Understanding: What Matters in Reading and Reasoning**
2406.11823v1 by Geewook Kim, Minjoon Seo

Recent advancements in language and vision assistants have showcased
impressive capabilities but suffer from a lack of transparency, limiting
broader research and reproducibility. While open-source models handle general
image tasks effectively, they face challenges with the high computational
demands of complex visually-situated text understanding. Such tasks often
require increased token inputs and large vision modules to harness
high-resolution information. Striking a balance between model size and data
importance remains an open question. This study aims to redefine the design of
vision-language models by identifying key components and creating efficient
models with constrained inference costs. By strategically formulating datasets,
optimizing vision modules, and enhancing supervision techniques, we achieve
significant improvements in inference throughput while maintaining high
performance. Extensive experiments across models ranging from 160M to 13B
parameters offer insights into model optimization. We will fully open-source
our codebase, models, and datasets at https://github.com/naver-ai/elva .

ÊëòË¶ÅÔºöË™ûË®ÄÂíåË¶ñË¶∫Âä©ÁêÜÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂ±ïÁ§∫‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑËÉΩÂäõÔºå‰ΩÜÁº∫‰πèÈÄèÊòéÂ∫¶ÔºåÈôêÂà∂‰∫ÜÊõ¥Âª£Ê≥õÁöÑÁ†îÁ©∂ÂíåÂèØË§áË£ΩÊÄß„ÄÇÈõñÁÑ∂ÈñãÊ∫êÊ®°ÂûãÊúâÊïàÂú∞ËôïÁêÜ‰∏ÄËà¨ÂΩ±ÂÉè‰ªªÂãôÔºå‰ΩÜÂÆÉÂÄëÂú®Ë§áÈõúÁöÑË¶ñË¶∫ÊÉÖÂ¢ÉÊñáÊú¨ÁêÜËß£ÁöÑÈ´òË®àÁÆóÈúÄÊ±ÇÊñπÈù¢Èù¢Ëá®ÊåëÊà∞„ÄÇÊ≠§È°û‰ªªÂãôÈÄöÂ∏∏ÈúÄË¶ÅÂ¢ûÂä†ÁöÑÊ®ôË®òËº∏ÂÖ•ÂíåÂ§ßÂûãË¶ñË¶∫Ê®°ÁµÑÔºå‰ª•Âà©Áî®È´òËß£ÊûêÂ∫¶Ë≥áË®ä„ÄÇÂú®Ê®°ÂûãÂ§ßÂ∞èÂíåË≥áÊñôÈáçË¶ÅÊÄß‰πãÈñìÂèñÂæóÂπ≥Ë°°‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÊú™Ëß£Ê±∫ÁöÑÂïèÈ°å„ÄÇÊú¨Á†îÁ©∂Êó®Âú®ÈÄèÈÅéË≠òÂà•ÈóúÈçµÁµÑÊàêÈÉ®ÂàÜÂíåÂª∫Á´ãÂÖ∑ÊúâÂèóÈôêÊé®Ë´ñÊàêÊú¨ÁöÑÊúâÊïàÁéáÊ®°ÂûãÔºåÈáçÊñ∞ÂÆöÁæ©Ë¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÁöÑË®≠Ë®à„ÄÇÈÄèÈÅéÁ≠ñÁï•ÊÄßÂú∞Âà∂ÂÆöË≥áÊñôÈõÜ„ÄÅÊúÄ‰Ω≥ÂåñË¶ñË¶∫Ê®°ÁµÑÂíåÂ¢ûÂº∑Áõ£Áù£ÊäÄË°ìÔºåÊàëÂÄëÂú®Á∂≠ÊåÅÈ´òÊÄßËÉΩÁöÑÂêåÊôÇÔºåÈ°ØËëóÊîπÂñÑ‰∫ÜÊé®Ë´ñËôïÁêÜÈáè„ÄÇÂæû 160M Âà∞ 13B ÂèÉÊï∏ÁöÑÊ®°ÂûãÁöÑÂª£Ê≥õÂØ¶È©óÊèê‰æõ‰∫ÜÊ®°ÂûãÊúÄ‰Ω≥ÂåñÁöÑË¶ãËß£„ÄÇÊàëÂÄëÂ∞áÂú® https://github.com/naver-ai/elva ÂÆåÂÖ®ÈñãÊîæÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂ∫´„ÄÅÊ®°ÂûãÂíåË≥áÊñôÈõÜ„ÄÇ

##### **Embodied Instruction Following in Unknown Environments**
2406.11818v1 by Zhenyu Wu, Ziwei Wang, Xiuwei Xu, Jiwen Lu, Haibin Yan

Enabling embodied agents to complete complex human instructions from natural
language is crucial to autonomous systems in household services. Conventional
methods can only accomplish human instructions in the known environment where
all interactive objects are provided to the embodied agent, and directly
deploying the existing approaches for the unknown environment usually generates
infeasible plans that manipulate non-existing objects. On the contrary, we
propose an embodied instruction following (EIF) method for complex tasks in the
unknown environment, where the agent efficiently explores the unknown
environment to generate feasible plans with existing objects to accomplish
abstract instructions. Specifically, we build a hierarchical embodied
instruction following framework including the high-level task planner and the
low-level exploration controller with multimodal large language models. We then
construct a semantic representation map of the scene with dynamic region
attention to demonstrate the known visual clues, where the goal of task
planning and scene exploration is aligned for human instruction. For the task
planner, we generate the feasible step-by-step plans for human goal
accomplishment according to the task completion process and the known visual
clues. For the exploration controller, the optimal navigation or object
interaction policy is predicted based on the generated step-wise plans and the
known visual clues. The experimental results demonstrate that our method can
achieve 45.09% success rate in 204 complex human instructions such as making
breakfast and tidying rooms in large house-level scenes.

ÊëòË¶ÅÔºöËÆìÂÖ∑Ë∫´‰ª£ÁêÜ‰∫∫ÂÆåÊàêËá™ÁÑ∂Ë™ûË®Ä‰∏≠ÁöÑË§áÈõú‰∫∫È°ûÊåáÁ§∫Â∞çÊñºÂÆ∂Â∫≠ÊúçÂãô‰∏≠ÁöÑËá™‰∏ªÁ≥ªÁµ±Ëá≥ÈóúÈáçË¶Å„ÄÇÂÇ≥Áµ±ÊñπÊ≥ïÂè™ËÉΩÂú®Â∑≤Áü•Áí∞Â¢É‰∏≠ÂÆåÊàê‰∫∫È°ûÊåáÁ§∫ÔºåÂÖ∂‰∏≠ÊâÄÊúâ‰∫íÂãïÂ∞çË±°ÈÉΩÊèê‰æõÁµ¶ÂÖ∑Ë∫´‰ª£ÁêÜ‰∫∫Ôºå‰∏¶‰∏îÁõ¥Êé•ÈÉ®ÁΩ≤ÁèæÊúâÊñπÊ≥ï‰æÜÊáâÂ∞çÊú™Áü•Áí∞Â¢ÉÈÄöÂ∏∏ÊúÉÁî¢Áîü‰∏çÂèØË°åÁöÑË®àÁï´ÔºåÈÄô‰∫õË®àÁï´ÊúÉÊìç‰Ωú‰∏çÂ≠òÂú®ÁöÑÂ∞çË±°„ÄÇÁõ∏ÂèçÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂú®Êú™Áü•Áí∞Â¢É‰∏≠Âü∑Ë°åË§áÈõú‰ªªÂãôÁöÑÂÖ∑Ë∫´Êåá‰ª§ÈÅµÂæ™ (EIF) ÊñπÊ≥ïÔºåÂÖ∂‰∏≠‰ª£ÁêÜ‰∫∫ÊúâÊïàÂú∞Êé¢Á¥¢Êú™Áü•Áí∞Â¢É‰ª•ÁîüÊàêÂèØË°åÁöÑË®àÁï´Ôºå‰∏¶‰ΩøÁî®ÁèæÊúâÂ∞çË±°‰æÜÂÆåÊàêÊäΩË±°Êåá‰ª§„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊßãÂª∫‰∫Ü‰∏ÄÂÄãÂàÜÂ±§ÂÖ∑Ë∫´Êåá‰ª§ÈÅµÂæ™Êû∂ÊßãÔºåÂåÖÊã¨È´òÁ¥ö‰ªªÂãôË¶èÂäÉÂô®ÂíåÂÖ∑ÊúâÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑ‰ΩéÁ¥öÊé¢Á¥¢ÊéßÂà∂Âô®„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊßãÂª∫‰∏ÄÂÄãÂ†¥ÊôØÁöÑË™ûÁæ©Ë°®Á§∫ÂúñÔºå‰∏¶‰ΩøÁî®ÂãïÊÖãÂçÄÂüüÊ≥®ÊÑè‰æÜÂ±ïÁ§∫Â∑≤Áü•ÁöÑË¶ñË¶∫Á∑öÁ¥¢ÔºåÂÖ∂‰∏≠‰ªªÂãôË¶èÂäÉÂíåÂ†¥ÊôØÊé¢Á¥¢ÁöÑÁõÆÊ®ôËàá‰∫∫È°ûÊåá‰ª§‰øùÊåÅ‰∏ÄËá¥„ÄÇÂ∞çÊñº‰ªªÂãôË¶èÂäÉÂô®ÔºåÊàëÂÄëÊ†πÊìö‰ªªÂãôÂÆåÊàêÈÅéÁ®ãÂíåÂ∑≤Áü•ÁöÑË¶ñË¶∫Á∑öÁ¥¢‰æÜÁîüÊàêÂèØË°åÁöÑÈÄêÊ≠•Ë®àÁï´Ôºå‰ª•ÂÆåÊàê‰∫∫È°ûÁõÆÊ®ô„ÄÇÂ∞çÊñºÊé¢Á¥¢ÊéßÂà∂Âô®ÔºåÊúÄ‰Ω≥Â∞éËà™ÊàñÂ∞çË±°‰∫íÂãïÁ≠ñÁï•ÊòØÊ†πÊìöÁîüÊàêÁöÑÈÄêÊ≠•Ë®àÁï´ÂíåÂ∑≤Áü•ÁöÑË¶ñË¶∫Á∑öÁ¥¢‰æÜÈ†êÊ∏¨ÁöÑ„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂèØ‰ª•Âú® 204 Ê¢ùË§áÈõúÁöÑ‰∫∫È°ûÊåá‰ª§‰∏≠ÂØ¶Áèæ 45.09% ÁöÑÊàêÂäüÁéáÔºå‰æãÂ¶ÇÂú®Â§ßÂûãÊàøÂ±ãÂ†¥ÊôØ‰∏≠Ë£Ω‰ΩúÊó©È§êÂíåÊï¥ÁêÜÊàøÈñì„ÄÇ

##### **Iterative Length-Regularized Direct Preference Optimization: A Case Study on Improving 7B Language Models to GPT-4 Level**
2406.11817v1 by Jie Liu, Zhanhui Zhou, Jiaheng Liu, Xingyuan Bu, Chao Yang, Han-Sen Zhong, Wanli Ouyang

Direct Preference Optimization (DPO), a standard method for aligning language
models with human preferences, is traditionally applied to offline preferences.
Recent studies show that DPO benefits from iterative training with online
preferences labeled by a trained reward model. In this work, we identify a
pitfall of vanilla iterative DPO - improved response quality can lead to
increased verbosity. To address this, we introduce iterative length-regularized
DPO (iLR-DPO) to penalize response length. Our empirical results show that
iLR-DPO can enhance a 7B model to perform on par with GPT-4 without increasing
verbosity. Specifically, our 7B model achieves a $50.5\%$ length-controlled win
rate against $\texttt{GPT-4 Preview}$ on AlpacaEval 2.0, and excels across
standard benchmarks including MT-Bench, Arena-Hard and OpenLLM Leaderboard.
These results demonstrate the effectiveness of iterative DPO in aligning
language models with human feedback.

ÊëòË¶ÅÔºöÁõ¥Êé•ÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÔºàDPOÔºâÊòØ‰∏ÄÁ®ÆÂ∞áË™ûË®ÄÊ®°ÂûãËàá‰∫∫È°ûÂÅèÂ•ΩÂ∞çÈΩäÁöÑÊ®ôÊ∫ñÊñπÊ≥ïÔºåÂÇ≥Áµ±‰∏äÊáâÁî®ÊñºÈõ¢Á∑öÂÅèÂ•Ω„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåDPO ÂèóÁõäÊñº‰ΩøÁî®ÂèóÈÅéË®ìÁ∑¥ÁöÑÁçéÂãµÊ®°ÂûãÊ®ôË®òÁöÑÁ∑ö‰∏äÂÅèÂ•ΩÁöÑÂèçË¶ÜË®ìÁ∑¥„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÁôºÁèæ‰∫ÜÈ¶ôËçâÂèçË¶Ü DPO ÁöÑ‰∏ÄÂÄãÈô∑Èò± - ÊîπÂñÑÁöÑÂõûÊáâÂìÅË≥™ÂèØËÉΩÂ∞éËá¥ÂÜóÈï∑„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂèçË¶ÜÈï∑Â∫¶Ê≠£Ë¶èÂåñÁöÑ DPO (iLR-DPO) ‰æÜÊá≤ÁΩ∞ÂõûÊáâÈï∑Â∫¶„ÄÇÊàëÂÄëÁöÑÂØ¶Ë≠âÁµêÊûúË°®ÊòéÔºåiLR-DPO ÂèØ‰ª•Â¢ûÂº∑ 7B Ê®°ÂûãÔºå‰ΩøÂÖ∂Âú®‰∏çÂ¢ûÂä†ÂÜóÈï∑ÁöÑÊÉÖÊ≥Å‰∏ãËàá GPT-4 Áõ∏Â™≤Áæé„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÁöÑ 7B Ê®°ÂûãÂú® AlpacaEval 2.0 ‰∏äÂØ¶Áèæ‰∫ÜÂ∞ç $\texttt{GPT-4 È†êË¶Ω}$ ÁöÑ $50.5\%$ Èï∑Â∫¶ÊéßÂà∂ÂãùÁéáÔºå‰∏¶Âú®ÂåÖÊã¨ MT-Bench„ÄÅArena-Hard Âíå OpenLLM ÊéíË°åÊ¶úÂú®ÂÖßÁöÑÊ®ôÊ∫ñÂü∫Ê∫ñ‰∏≠Ë°®ÁèæÂá∫Ëâ≤„ÄÇÈÄô‰∫õÁµêÊûúË≠âÊòé‰∫ÜÂèçË¶Ü DPO Âú®Â∞áË™ûË®ÄÊ®°ÂûãËàá‰∫∫È°ûÂõûÈ•ãÂ∞çÈΩäÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **How Do Large Language Models Acquire Factual Knowledge During Pretraining?**
2406.11813v1 by Hoyeon Chang, Jinho Park, Seonghyeon Ye, Sohee Yang, Youngkyung Seo, Du-Seong Chang, Minjoon Seo

Despite the recent observation that large language models (LLMs) can store
substantial factual knowledge, there is a limited understanding of the
mechanisms of how they acquire factual knowledge through pretraining. This work
addresses this gap by studying how LLMs acquire factual knowledge during
pretraining. The findings reveal several important insights into the dynamics
of factual knowledge acquisition during pretraining. First, counterintuitively,
we observe that pretraining on more data shows no significant improvement in
the model's capability to acquire and maintain factual knowledge. Next, there
is a power-law relationship between training steps and forgetting of
memorization and generalization of factual knowledge, and LLMs trained with
duplicated training data exhibit faster forgetting. Third, training LLMs with
larger batch sizes can enhance the models' robustness to forgetting. Overall,
our observations suggest that factual knowledge acquisition in LLM pretraining
occurs by progressively increasing the probability of factual knowledge
presented in the pretraining data at each step. However, this increase is
diluted by subsequent forgetting. Based on this interpretation, we demonstrate
that we can provide plausible explanations for recently observed behaviors of
LLMs, such as the poor performance of LLMs on long-tail knowledge and the
benefits of deduplicating the pretraining corpus.

ÊëòË¶ÅÔºöÂÑòÁÆ°ÊúÄËøëËßÄÂØüÂà∞Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËÉΩÂÑ≤Â≠òÂ§ßÈáèÁöÑÂØ¶ÈöõÁü•Ë≠òÔºå‰ΩÜÂ∞çÊñº LLM Âú®È†êË®ìÁ∑¥ÈÅéÁ®ã‰∏≠Â¶Ç‰ΩïÁç≤ÂèñÂØ¶ÈöõÁü•Ë≠òÁöÑÊ©üÂà∂ÔºåÁêÜËß£‰ªçÁÑ∂ÊúâÈôê„ÄÇÈÄôÈ†ÖÁ†îÁ©∂ÈÄèÈÅéÊé¢Ë®é LLM Âú®È†êË®ìÁ∑¥ÊúüÈñìÂ¶Ç‰ΩïÁç≤ÂèñÂØ¶ÈöõÁü•Ë≠òÔºå‰æÜÊé¢Ë®éÈÄôÂÄãÁü•Ë≠òÁº∫Âè£„ÄÇÁ†îÁ©∂ÁµêÊûúÊè≠Èú≤‰∫ÜÂπæÂÄãÈáçË¶ÅÁöÑË¶ãËß£ÔºåË™™ÊòéÂú®È†êË®ìÁ∑¥ÊúüÈñìÁç≤ÂèñÂØ¶ÈöõÁü•Ë≠òÁöÑÂãïÊÖã„ÄÇÈ¶ñÂÖàÔºåËàáÁõ¥Ë¶∫Áõ∏ÂèçÔºåÊàëÂÄëËßÄÂØüÂà∞‰ΩøÁî®Êõ¥Â§öË≥áÊñôÈÄ≤Ë°åÈ†êË®ìÁ∑¥‰∏¶Êú™È°ØËëóÊèêÂçáÊ®°ÂûãÁç≤ÂèñÂíåÁ∂≠Ë≠∑ÂØ¶ÈöõÁü•Ë≠òÁöÑËÉΩÂäõ„ÄÇÂÖ∂Ê¨°ÔºåË®ìÁ∑¥Ê≠•È©üËàáÈÅ∫Âøò„ÄÅË®òÊÜ∂ÂíåÂØ¶ÈöõÁü•Ë≠òÁöÑÊ¶ÇÂåñ‰πãÈñìÂ≠òÂú®ÂÜ™ÂæãÈóú‰øÇÔºåËÄå‰ΩøÁî®ÈáçË§áË®ìÁ∑¥Ë≥áÊñôË®ìÁ∑¥ÁöÑ LLM ÈÅ∫ÂøòÂæóÊõ¥Âø´„ÄÇÁ¨¨‰∏âÔºå‰ΩøÁî®ËºÉÂ§ßÁöÑÊâπÊ¨°Â§ßÂ∞èË®ìÁ∑¥ LLM ËÉΩÂ§†ÊèêÂçáÊ®°ÂûãÂ∞çÈÅ∫ÂøòÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÁ∏ΩÁöÑ‰æÜË™™ÔºåÊàëÂÄëÁöÑËßÄÂØüÁµêÊûúÈ°ØÁ§∫ÔºåLLM È†êË®ìÁ∑¥‰∏≠ÁöÑÂØ¶ÈöõÁü•Ë≠òÁç≤ÂèñÊòØÈÄèÈÅéÂú®ÊØèÂÄãÊ≠•È©üÈÄêÊ≠•Â¢ûÂä†È†êË®ìÁ∑¥Ë≥áÊñô‰∏≠ÂëàÁèæÁöÑÂØ¶ÈöõÁü•Ë≠òÊ©üÁéáËÄåÁôºÁîüÁöÑ„ÄÇÁÑ∂ËÄåÔºåÈÄôÁ®ÆÂ¢ûÂä†ÊúÉË¢´Èö®ÂæåÁöÑÈÅ∫ÂøòÊâÄÁ®ÄÈáã„ÄÇÊ†πÊìöÈÄôÂÄãËß£ÈáãÔºåÊàëÂÄëË≠âÊòéÊàëÂÄëÂèØ‰ª•Â∞çÊúÄËøëËßÄÂØüÂà∞ÁöÑ LLM Ë°åÁÇ∫Êèê‰æõÂêàÁêÜÁöÑËß£ÈáãÔºå‰æãÂ¶Ç LLM Âú®Èï∑Â∞æÁü•Ë≠ò‰∏äÁöÑË°®Áèæ‰∏ç‰Ω≥Ôºå‰ª•ÂèäÂ∞çÈ†êË®ìÁ∑¥Ë™ûÊñôÂ∫´ÈÄ≤Ë°åÈáçË§áË≥áÊñôÂà™Èô§ÁöÑÂ•ΩËôï„ÄÇ

##### **RepLiQA: A Question-Answering Dataset for Benchmarking LLMs on Unseen Reference Content**
2406.11811v1 by Joao Monteiro, Pierre-Andre Noel, Etienne Marcotte, Sai Rajeswar, Valentina Zantedeschi, David Vazquez, Nicolas Chapados, Christopher Pal, Perouz Taslakian

Large Language Models (LLMs) are trained on vast amounts of data, most of
which is automatically scraped from the internet. This data includes
encyclopedic documents that harbor a vast amount of general knowledge (e.g.,
Wikipedia) but also potentially overlap with benchmark datasets used for
evaluating LLMs. Consequently, evaluating models on test splits that might have
leaked into the training set is prone to misleading conclusions. To foster
sound evaluation of language models, we introduce a new test dataset named
RepLiQA, suited for question-answering and topic retrieval tasks. RepLiQA is a
collection of five splits of test sets, four of which have not been released to
the internet or exposed to LLM APIs prior to this publication. Each sample in
RepLiQA comprises (1) a reference document crafted by a human annotator and
depicting an imaginary scenario (e.g., a news article) absent from the
internet; (2) a question about the document's topic; (3) a ground-truth answer
derived directly from the information in the document; and (4) the paragraph
extracted from the reference document containing the answer. As such, accurate
answers can only be generated if a model can find relevant content within the
provided document. We run a large-scale benchmark comprising several
state-of-the-art LLMs to uncover differences in performance across models of
various types and sizes in a context-conditional language modeling setting.
Released splits of RepLiQA can be found here:
https://huggingface.co/datasets/ServiceNow/repliqa.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊòØÂú®Â§ßÈáèÁöÑË≥áÊñô‰∏äË®ìÁ∑¥ÁöÑÔºåÂÖ∂‰∏≠Â§ßÈÉ®ÂàÜÊòØÂæûÁ∂≤Ë∑Ø‰∏äËá™ÂãïÊäìÂèñÁöÑ„ÄÇÈÄô‰∫õË≥áÊñôÂåÖÊã¨ÂåÖÂê´Â§ßÈáè‰∏ÄËà¨Áü•Ë≠òÁöÑÁôæÁßëÂÖ®Êõ∏Êñá‰ª∂Ôºà‰æãÂ¶ÇÁ∂≠Âü∫ÁôæÁßëÔºâÔºå‰ΩÜ‰πüÂèØËÉΩËàáÁî®ÊñºË©ï‰º∞ LLM ÁöÑÂü∫Ê∫ñË≥áÊñôÈõÜÈáçÁñä„ÄÇÂõ†Ê≠§ÔºåÂú®ÂèØËÉΩÂ∑≤Ê¥©ÊºèÂà∞Ë®ìÁ∑¥ÈõÜ‰∏≠ÁöÑÊ∏¨Ë©¶ÂàÜÂâ≤‰∏äË©ï‰º∞Ê®°ÂûãÂÆπÊòìÂ∞éËá¥Ë™§Â∞éÊÄßÁöÑÁµêË´ñ„ÄÇÁÇ∫‰∫Ü‰øÉÈÄ≤Ë™ûË®ÄÊ®°ÂûãÁöÑÂÅ•ÂÖ®Ë©ï‰º∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂêçÁÇ∫ RepLiQA ÁöÑÊñ∞Ê∏¨Ë©¶Ë≥áÊñôÈõÜÔºåÈÅ©Áî®ÊñºÂïèÁ≠îÂíå‰∏ªÈ°åÊ™¢Á¥¢‰ªªÂãô„ÄÇRepLiQA ÊòØÁî±‰∫îÂÄãÊ∏¨Ë©¶ÈõÜÂàÜÂâ≤ÁµÑÊàêÁöÑÈõÜÂêàÔºåÂÖ∂‰∏≠ÂõõÂÄãÂú®Êú¨Ê¨°ÁôºÂ∏É‰πãÂâçÂ∞öÊú™ÁôºÂ∏ÉÂà∞Á∂≤Ë∑Ø‰∏äÊàñÂÖ¨ÈñãÁµ¶ LLM API„ÄÇRepLiQA ‰∏≠ÁöÑÊØèÂÄãÁØÑ‰æãÂåÖÂê´ (1) Áî±‰∫∫È°ûË®ªËß£ËÄÖÁ∑®ÂØ´ÁöÑÂèÉËÄÉÊñá‰ª∂ÔºåÊèèËø∞‰∏ÄÂÄã‰∏çÂ≠òÂú®ÊñºÁ∂≤Ë∑Ø‰∏ä„ÄÅËôõÊßãÁöÑÊÉÖÂ¢ÉÔºà‰æãÂ¶ÇÊñ∞ËÅûÊñáÁ´†ÔºâÔºõ(2) ÈóúÊñºÊñá‰ª∂‰∏ªÈ°åÁöÑÂïèÈ°åÔºõ(3) Áõ¥Êé•ÂæûÊñá‰ª∂‰∏≠ÁöÑË≥áË®äË°çÁîüÁöÑÂü∫Êú¨‰∫ãÂØ¶Á≠îÊ°àÔºõ‰ª•Âèä (4) ÂæûÂåÖÂê´Á≠îÊ°àÁöÑÂèÉËÄÉÊñá‰ª∂‰∏≠ÊëòÈåÑÁöÑÊÆµËêΩ„ÄÇÂõ†Ê≠§ÔºåÂè™ÊúâÁï∂Ê®°ÂûãÂèØ‰ª•Âú®Êèê‰æõÁöÑÊñá‰ª∂‰∏≠ÊâæÂà∞Áõ∏ÈóúÂÖßÂÆπÊôÇÔºåÊâçËÉΩÁî¢ÁîüÊ∫ñÁ¢∫ÁöÑÁ≠îÊ°à„ÄÇÊàëÂÄëÂü∑Ë°å‰∫Ü‰∏ÄÈ†ÖÂ§ßË¶èÊ®°Âü∫Ê∫ñÊ∏¨Ë©¶ÔºåÂÖ∂‰∏≠ÂåÖÂê´Â§öÂÄãÊúÄÂÖàÈÄ≤ÁöÑ LLMÔºå‰ª•Âú®ÊÉÖÂ¢ÉÊ¢ù‰ª∂Ë™ûË®ÄÂª∫Ê®°Ë®≠ÂÆö‰∏≠Êè≠Á§∫ÂêÑÁ®ÆÈ°ûÂûãÂíåË¶èÊ®°ÁöÑÊ®°Âûã‰πãÈñìÁöÑÊïàËÉΩÂ∑ÆÁï∞„ÄÇRepLiQA ÁöÑÂ∑≤ÁôºÂ∏ÉÂàÜÂâ≤ÂèØ‰ª•Âú®Ê≠§ËôïÊâæÂà∞Ôºöhttps://huggingface.co/datasets/ServiceNow/repliqa„ÄÇ

##### **Safety Arithmetic: A Framework for Test-time Safety Alignment of Language Models by Steering Parameters and Activations**
2406.11801v1 by Rima Hazra, Sayan Layek, Somnath Banerjee, Soujanya Poria

Ensuring the safe alignment of large language models (LLMs) with human values
is critical as they become integral to applications like translation and
question answering. Current alignment methods struggle with dynamic user
intentions and complex objectives, making models vulnerable to generating
harmful content. We propose Safety Arithmetic, a training-free framework
enhancing LLM safety across different scenarios: Base models, Supervised
fine-tuned models (SFT), and Edited models. Safety Arithmetic involves Harm
Direction Removal to avoid harmful content and Safety Alignment to promote safe
responses. Additionally, we present NoIntentEdit, a dataset highlighting edit
instances that could compromise model safety if used unintentionally. Our
experiments show that Safety Arithmetic significantly improves safety measures,
reduces over-safety, and maintains model utility, outperforming existing
methods in ensuring safe content generation.

ÊëòË¶ÅÔºöÁ¢∫‰øùÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Ëàá‰∫∫È°ûÂÉπÂÄºËßÄÂÆâÂÖ®‰∏ÄËá¥ÔºåÂ∞çÊñºÂÆÉÂÄëÊàêÁÇ∫ÁøªË≠ØÂíåÂïèÁ≠îÁ≠âÊáâÁî®Á®ãÂºè‰∏çÂèØÊàñÁº∫ÁöÑ‰∏ÄÈÉ®ÂàÜËá≥ÈóúÈáçË¶Å„ÄÇÁõÆÂâçÁöÑÂ∞çÈΩäÊñπÂºèÊñπÊ≥ïÈõ£‰ª•ÊáâÂ∞çÂãïÊÖã‰ΩøÁî®ËÄÖÊÑèÂúñÂíåË§áÈõúÁõÆÊ®ôÔºå‰ΩøÂæóÊ®°ÂûãÂÆπÊòìÁî¢ÁîüÊúâÂÆ≥ÂÖßÂÆπ„ÄÇÊàëÂÄëÊèêÂá∫ÂÆâÂÖ®ÁÆóË°ìÔºåÈÄôÊòØ‰∏ÄÂÄãÂÖçË®ìÁ∑¥Ê°ÜÊû∂ÔºåÂèØÂ¢ûÂº∑ LLM Âú®‰∏çÂêåÂ†¥ÊôØ‰∏≠ÁöÑÂÆâÂÖ®ÊÄßÔºöÂü∫Á§éÊ®°Âûã„ÄÅÁõ£Áù£ÂæÆË™øÊ®°Âûã (SFT) ÂíåÁ∑®ËºØÊ®°Âûã„ÄÇÂÆâÂÖ®ÁÆóË°ìÊ∂âÂèäÂç±ÂÆ≥ÊñπÂêëÁßªÈô§Ôºå‰ª•ÈÅøÂÖçÊúâÂÆ≥ÂÖßÂÆπÔºå‰ª•ÂèäÂÆâÂÖ®Â∞çÈΩäÔºå‰ª•‰øÉÈÄ≤ÂÆâÂÖ®ÂõûÊáâ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫ NoIntentEditÔºåÈÄôÊòØ‰∏ÄÂÄãË≥áÊñôÈõÜÔºåÈáçÈªûÊ®ôÁ§∫Âá∫Â¶ÇÊûúÁÑ°ÊÑè‰∏≠‰ΩøÁî®ÔºåÂèØËÉΩÊúÉÊêçÂÆ≥Ê®°ÂûãÂÆâÂÖ®ÊÄßÁöÑÁ∑®ËºØÂØ¶‰æã„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåÂÆâÂÖ®ÁÆóË°ìÈ°ØËëóÊîπÂñÑ‰∫ÜÂÆâÂÖ®Êé™ÊñΩÔºåÊ∏õÂ∞ë‰∫ÜÈÅéÂ∫¶ÂÆâÂÖ®ÊÄßÔºå‰∏¶Á∂≠ÊåÅÊ®°ÂûãÊïàÁî®ÔºåÂú®Á¢∫‰øùÂÆâÂÖ®ÂÖßÂÆπÁîüÊàêÊñπÈù¢ÂÑ™ÊñºÁèæÊúâÊñπÊ≥ï„ÄÇ

##### **DataComp-LM: In search of the next generation of training sets for language models**
2406.11794v1 by Jeffrey Li, Alex Fang, Georgios Smyrnis, Maor Ivgi, Matt Jordan, Samir Gadre, Hritik Bansal, Etash Guha, Sedrick Keh, Kushal Arora, Saurabh Garg, Rui Xin, Niklas Muenninghoff, Reinhard Heckel, Jean Mercat, Mayee Chen, Suchin Gururangan, Mitchell Wortsman, Alon Albalak, Yonatan Bitton, Marianna Nezhurina, Amro Abbas, Cheng-Yu Hsieh, Dhruba Ghosh, Josh Gardner, Maciej Kilian, Hanlin Zhang, Rulin Shao, Sarah Pratt, Sunny Sanyal, Gabriel Ilharco, Giannis Daras, Kalyani Marathe, Aaron Gokaslan, Jieyu Zhang, Khyathi Chandu, Thao Nguyen, Igor Vasiljevic, Sham Kakade, Shuran Song, Sujay Sanghavi, Fartash Faghri, Sewoong Oh, Luke Zettlemoyer, Kyle Lo, Alaaeldin El-Nouby, Hadi Pouransari, Alexander Toshev, Stephanie Wang, Dirk Groeneveld, Luca Soldani, Pang Wei Koh, Jenia Jitsev, Thomas Kollar, Alexandros G. Dimakis, Yair Carmon, Achal Dave, Ludwig Schmidt, Vaishaal Shankar

We introduce DataComp for Language Models (DCLM), a testbed for controlled
dataset experiments with the goal of improving language models. As part of
DCLM, we provide a standardized corpus of 240T tokens extracted from Common
Crawl, effective pretraining recipes based on the OpenLM framework, and a broad
suite of 53 downstream evaluations. Participants in the DCLM benchmark can
experiment with data curation strategies such as deduplication, filtering, and
data mixing at model scales ranging from 412M to 7B parameters. As a baseline
for DCLM, we conduct extensive experiments and find that model-based filtering
is key to assembling a high-quality training set. The resulting dataset,
DCLM-Baseline enables training a 7B parameter language model from scratch to
64% 5-shot accuracy on MMLU with 2.6T training tokens. Compared to MAP-Neo, the
previous state-of-the-art in open-data language models, DCLM-Baseline
represents a 6.6 percentage point improvement on MMLU while being trained with
40% less compute. Our baseline model is also comparable to Mistral-7B-v0.3 and
Llama 3 8B on MMLU (63% & 66%), and performs similarly on an average of 53
natural language understanding tasks while being trained with 6.6x less compute
than Llama 3 8B. Our results highlight the importance of dataset design for
training language models and offer a starting point for further research on
data curation.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÁÇ∫Ë™ûË®ÄÊ®°Âûã (DCLM) ÂºïÂÖ• DataCompÔºå‰∏ÄÂÄãÁî®ÊñºÊéßÂà∂Ë≥áÊñôÈõÜÂØ¶È©óÁöÑÊ∏¨Ë©¶Âπ≥Âè∞ÔºåÁõÆÊ®ôÊòØÊîπÈÄ≤Ë™ûË®ÄÊ®°Âûã„ÄÇ‰ΩúÁÇ∫ DCLM ÁöÑ‰∏ÄÈÉ®ÂàÜÔºåÊàëÂÄëÊèê‰æõ‰∏ÄÂÄãÊ®ôÊ∫ñË™ûÊñôÂ∫´ÔºåÂåÖÂê´Âæû Common Crawl ‰∏≠ÊèêÂèñÁöÑ 240T ÂÄãÁ¨¶ËôüÔºåÂü∫Êñº OpenLM Ê°ÜÊû∂ÁöÑÊúâÊïàÈ†êË®ìÁ∑¥ÈÖçÊñπÔºå‰ª•ÂèäÂª£Ê≥õÁöÑ 53 ÂÄã‰∏ãÊ∏∏Ë©ï‰º∞„ÄÇDCLM Âü∫Ê∫ñÊ∏¨Ë©¶ÁöÑÂèÉËàáËÄÖÂèØ‰ª•ÂòóË©¶Ë≥áÊñôÁ≠ñÂ±ïÁ≠ñÁï•Ôºå‰æãÂ¶ÇÂéªÈáç„ÄÅÈÅéÊøæÂíåË≥áÊñôÊ∑∑ÂêàÔºåÊ®°ÂûãË¶èÊ®°Âæû 412M Âà∞ 7B ÂÄãÂèÉÊï∏„ÄÇ‰ΩúÁÇ∫ DCLM ÁöÑÂü∫Ê∫ñÔºåÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºåÁôºÁèæÂü∫ÊñºÊ®°ÂûãÁöÑÈÅéÊøæÊòØÁµÑË£ùÈ´òÂìÅË≥™Ë®ìÁ∑¥ÈõÜÁöÑÈóúÈçµ„ÄÇÁî±Ê≠§Áî¢ÁîüÁöÑË≥áÊñôÈõÜ DCLM-Baseline ËÉΩÂ§†ÂæûÈ†≠ÈñãÂßãË®ìÁ∑¥‰∏ÄÂÄã 7B ÂèÉÊï∏Ë™ûË®ÄÊ®°ÂûãÔºåÂú® MMLU ‰∏ä‰ª• 2.6T ÂÄãË®ìÁ∑¥Á¨¶ËôüÈÅîÂà∞ 64% ÁöÑ 5 Ê¨°Ê∫ñÁ¢∫Â∫¶„ÄÇËàá MAP-Neo Áõ∏ÊØîÔºåDCLM-Baseline ÊòØÈñãÊîæË≥áÊñôË™ûË®ÄÊ®°Âûã‰∏≠ÂÖàÂâçÁöÑÊúÄÊñ∞ÊäÄË°ìÔºåÂú® MMLU ‰∏äÊèêÈ´ò‰∫Ü 6.6 ÂÄãÁôæÂàÜÈªûÔºåÂêåÊôÇË®ìÁ∑¥ÊôÇÈÅãÁÆóÈáèÊ∏õÂ∞ë‰∫Ü 40%„ÄÇÊàëÂÄëÁöÑÂü∫Ê∫ñÊ®°Âûã‰πüËàá MMLU ‰∏äÁöÑ Mistral-7B-v0.3 Âíå Llama 3 8B Áõ∏Áï∂Ôºà63% Âíå 66%ÔºâÔºå‰∏¶‰∏îÂú®Âπ≥Âùá 53 ÂÄãËá™ÁÑ∂Ë™ûË®ÄÁêÜËß£‰ªªÂãô‰∏äÁöÑË°®ÁèæÈ°û‰ººÔºåÂêåÊôÇË®ìÁ∑¥ÊôÇÈÅãÁÆóÈáèÊØî Llama 3 8B Â∞ë 6.6 ÂÄç„ÄÇÊàëÂÄëÁöÑÁµêÊûúÂº∑Ë™ø‰∫ÜË≥áÊñôÈõÜË®≠Ë®àÂ∞çË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÁöÑÈáçË¶ÅÊÄßÔºå‰∏¶ÁÇ∫Ë≥áÊñôÁ≠ñÂ±ïÁöÑÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂Êèê‰æõ‰∫Ü‰∏ÄÂÄãËµ∑Èªû„ÄÇ</paragraph>

##### **A Brief Survey on Leveraging Large Scale Vision Models for Enhanced Robot Grasping**
2406.11786v1 by Abhi Kamboj, Katherine Driggs-Campbell

Robotic grasping presents a difficult motor task in real-world scenarios,
constituting a major hurdle to the deployment of capable robots across various
industries. Notably, the scarcity of data makes grasping particularly
challenging for learned models. Recent advancements in computer vision have
witnessed a growth of successful unsupervised training mechanisms predicated on
massive amounts of data sourced from the Internet, and now nearly all prominent
models leverage pretrained backbone networks. Against this backdrop, we begin
to investigate the potential benefits of large-scale visual pretraining in
enhancing robot grasping performance. This preliminary literature review sheds
light on critical challenges and delineates prospective directions for future
research in visual pretraining for robotic manipulation.

ÊëòË¶ÅÔºöÊ©üÂô®‰∫∫ÊäìÊè°Âú®ÁèæÂØ¶‰∏ñÁïåÂ†¥ÊôØ‰∏≠ÂëàÁèæÂá∫Âõ∞Èõ£ÁöÑÈÅãÂãï‰ªªÂãôÔºå
ÊßãÊàêÊ©üÂô®‰∫∫Âú®ÂêÑÂÄãÁî¢Ê•≠‰∏≠ÈÉ®ÁΩ≤ÁöÑÈáçÂ§ßÈöúÁ§ô„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊï∏ÊìöÁöÑÁ®ÄÁº∫ÊÄß‰ΩøÂæóÊäìÊè°Â∞çÂ≠∏ÁøíÊ®°ÂûãÁâπÂà•ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊúÄËøëÂú®ÈõªËÖ¶Ë¶ñË¶∫ÊñπÈù¢ÁöÑÈÄ≤Â±ïË¶ãË≠â‰∫ÜÊàêÂäüÁÑ°Áõ£Áù£Ë®ìÁ∑¥Ê©üÂà∂ÁöÑÊàêÈï∑ÔºåÈÄô‰∫õÊ©üÂà∂Âª∫Á´ãÂú®ÂæûÁ∂≤ÈöõÁ∂≤Ë∑Ø‰∏äÂèñÂæóÁöÑÂ§ßÈáèÊï∏ÊìöÔºåËÄåÁèæÂú®Âπæ‰πéÊâÄÊúâËëóÂêçÁöÑÊ®°ÂûãÈÉΩÂà©Áî®È†êÂÖàË®ìÁ∑¥Â•ΩÁöÑ‰∏ªÂππÁ∂≤Ë∑Ø„ÄÇÂú®Ê≠§ËÉåÊôØ‰∏ãÔºåÊàëÂÄëÈñãÂßãÊé¢Ë®éÂ§ßË¶èÊ®°Ë¶ñË¶∫È†êË®ìÁ∑¥Âú®ÊèêÂçáÊ©üÂô®‰∫∫ÊäìÊè°ÊïàËÉΩÊñπÈù¢ÁöÑÊΩõÂú®Â•ΩËôï„ÄÇÈÄôÁØáÂàùÊ≠•ÊñáÁçªÂõûÈ°ßÈó°Êòé‰∫ÜÈóúÈçµÊåëÊà∞Ôºå‰∏¶ÂãæÂãíÂá∫Ê©üÂô®‰∫∫Êìç‰ΩúË¶ñË¶∫È†êË®ìÁ∑¥Êú™‰æÜÁ†îÁ©∂ÁöÑÈ†êÊúüÊñπÂêë„ÄÇ

##### **CELL your Model: Contrastive Explanation Methods for Large Language Models**
2406.11785v1 by Ronny Luss, Erik Miehling, Amit Dhurandhar

The advent of black-box deep neural network classification models has sparked
the need to explain their decisions. However, in the case of generative AI such
as large language models (LLMs), there is no class prediction to explain.
Rather, one can ask why an LLM output a particular response to a given prompt.
In this paper, we answer this question by proposing, to the best of our
knowledge, the first contrastive explanation methods requiring simply
black-box/query access. Our explanations suggest that an LLM outputs a reply to
a given prompt because if the prompt was slightly modified, the LLM would have
given a different response that is either less preferable or contradicts the
original response. The key insight is that contrastive explanations simply
require a distance function that has meaning to the user and not necessarily a
real valued representation of a specific response (viz. class label). We offer
two algorithms for finding contrastive explanations: i) A myopic algorithm,
which although effective in creating contrasts, requires many model calls and
ii) A budgeted algorithm, our main algorithmic contribution, which
intelligently creates contrasts adhering to a query budget, necessary for
longer contexts. We show the efficacy of these methods on diverse natural
language tasks such as open-text generation, automated red teaming, and
explaining conversational degradation.

ÊëòË¶ÅÔºöÈö®ËëóÈªëÁÆ±Ê∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÂàÜÈ°ûÊ®°ÂûãÁöÑÂá∫ÁèæÔºåËß£ÈáãÂÖ∂Ê±∫Á≠ñÁöÑÈúÄÊ±Ç‰πüÈö®‰πãÁî¢Áîü„ÄÇÁÑ∂ËÄåÔºåÂú®ÁîüÊàêÂºè AIÔºà‰æãÂ¶ÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºâÁöÑÊÉÖÊ≥Å‰∏ãÔºåÊ≤íÊúâÈ°ûÂà•È†êÊ∏¨ÂèØ‰ª•Ëß£Èáã„ÄÇÁõ∏ÂèçÔºåÂèØ‰ª•Ë©¢Âïè LLM ÁÇ∫‰ΩïÂ∞çÁâπÂÆöÊèêÁ§∫Ëº∏Âá∫ÁâπÂÆöÂõûÊáâ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÈÄèÈÅéÊèêÂá∫ÔºàÊìöÊàëÂÄëÊâÄÁü•ÔºâÁ¨¨‰∏ÄÂÄãÂè™Ë¶ÅÊ±ÇÈªëÁÆ±/Êü•Ë©¢Â≠òÂèñÊ¨äÁöÑÂ∞çÊØîËß£ÈáãÊñπÊ≥ï‰æÜÂõûÁ≠îÈÄôÂÄãÂïèÈ°å„ÄÇÊàëÂÄëÁöÑËß£ÈáãË°®ÊòéÔºåLLM Â∞çÁâπÂÆöÊèêÁ§∫Ëº∏Âá∫ÁöÑÂõûË¶ÜÊòØÂõ†ÁÇ∫ÔºåÂ¶ÇÊûúÊèêÁ§∫Á®ç‰Ωú‰øÆÊîπÔºåLLM ÊúÉÁµ¶Âá∫‰∏çÂêåÁöÑÂõûË¶ÜÔºåËÄåË©≤ÂõûË¶ÜËºÉ‰∏çÁêÜÊÉ≥ÊàñËàáÂéüÂßãÂõûË¶ÜÁõ∏ÁüõÁõæ„ÄÇÈóúÈçµË¶ãËß£Âú®ÊñºÔºåÂ∞çÊØîËß£ÈáãÂÉÖÈúÄË¶ÅÂ∞ç‰ΩøÁî®ËÄÖÊúâÊÑèÁæ©ÁöÑË∑ùÈõ¢ÂáΩÊï∏ÔºåËÄå‰∏ç‰∏ÄÂÆöÈúÄË¶ÅÁâπÂÆöÂõûË¶ÜÁöÑÂØ¶ÂÄºË°®Á§∫ÔºàÂç≥È°ûÂà•Ê®ôÁ±§Ôºâ„ÄÇÊàëÂÄëÊèê‰æõ‰∫ÜÂÖ©Á®ÆÂ∞ãÊâæÂ∞çÊØîËß£ÈáãÁöÑÊºîÁÆóÊ≥ïÔºöi) ‰∏ÄÁ®ÆËøëË¶ñÊºîÁÆóÊ≥ïÔºåÈõñÁÑ∂Âú®Âª∫Á´ãÂ∞çÊØîÊñπÈù¢ÊúâÊïàÔºå‰ΩÜÈúÄË¶ÅË®±Â§öÊ®°ÂûãÂëºÂè´Ôºå‰ª•Âèä ii) ‰∏ÄÁ®ÆÈ†êÁÆóÊºîÁÆóÊ≥ïÔºåÈÄôÊòØÊàëÂÄë‰∏ªË¶ÅÁöÑÊºîÁÆóÊ≥ïË≤¢ÁçªÔºåÂÆÉÂèØ‰ª•Êô∫ÊÖßÂú∞Âª∫Á´ãÁ¨¶ÂêàÊü•Ë©¢È†êÁÆóÁöÑÂ∞çÊØîÔºåÈÄôÂ∞çÊñºËºÉÈï∑ÁöÑËÑàÁµ°ÊòØÂøÖË¶ÅÁöÑ„ÄÇÊàëÂÄëÂú®ÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®Ä‰ªªÂãô‰∏äÂ±ïÁ§∫‰∫ÜÈÄô‰∫õÊñπÊ≥ïÁöÑÊïàËÉΩÔºå‰æãÂ¶ÇÈñãÊîæÊñáÂ≠óÁîüÊàê„ÄÅËá™ÂãïÂåñÁ¥ÖÈöäÊ∏¨Ë©¶Ôºå‰ª•ÂèäËß£ÈáãÂ∞çË©±ÂºèÈÄÄÂåñ„ÄÇ

##### **MDCR: A Dataset for Multi-Document Conditional Reasoning**
2406.11784v1 by Peter Baile Chen, Yi Zhang, Chunwei Liu, Sejal Gupta, Yoon Kim, Michael Cafarella

The same real-life questions posed to different individuals may lead to
different answers based on their unique situations. For instance, whether a
student is eligible for a scholarship depends on eligibility conditions, such
as major or degree required. ConditionalQA was proposed to evaluate models'
capability of reading a document and answering eligibility questions,
considering unmentioned conditions. However, it is limited to questions on
single documents, neglecting harder cases that may require cross-document
reasoning and optimization, for example, "What is the maximum number of
scholarships attainable?" Such questions over multiple documents are not only
more challenging due to more context having to understand, but also because the
model has to (1) explore all possible combinations of unmentioned conditions
and (2) understand the relationship between conditions across documents, to
reason about the optimal outcome. To evaluate models' capability of answering
such questions, we propose a new dataset MDCR, which can reflect real-world
challenges and serve as a new test bed for complex conditional reasoning that
requires optimization. We evaluate this dataset using the most recent LLMs and
demonstrate their limitations in solving this task. We believe this dataset
will facilitate future research in answering optimization questions with
unknown conditions.

ÊëòË¶ÅÔºöÁõ∏ÂêåÁöÑÁúüÂØ¶ÁîüÊ¥ªÂïèÈ°åÂêë‰∏çÂêåÁöÑ‰∫∫ÊèêÂá∫ÊôÇÔºåÂèØËÉΩÊúÉÊ†πÊìö‰ªñÂÄëÁç®ÁâπÁöÑÊÉÖÊ≥ÅËÄåÂ∞éËá¥‰∏çÂêåÁöÑÁ≠îÊ°à„ÄÇ‰æãÂ¶ÇÔºåÂ≠∏ÁîüÊòØÂê¶ÊúâË≥áÊ†ºÁç≤ÂæóÁçéÂ≠∏ÈáëÂèñÊ±∫ÊñºË≥áÊ†ºÊ¢ù‰ª∂Ôºå‰æãÂ¶ÇÊâÄÈúÄÁöÑÂ∞àÊ•≠ÊàñÂ≠∏‰Ωç„ÄÇConditionalQA Ë¢´ÊèêË≠∞Áî®ÊñºË©ï‰º∞Ê®°ÂûãÈñ±ËÆÄÊñá‰ª∂ÂíåÂõûÁ≠îË≥áÊ†ºÂïèÈ°åÁöÑËÉΩÂäõÔºåËÄÉÊÖÆÊú™ÊèêÂà∞ÁöÑÊ¢ù‰ª∂„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÉÖÈôêÊñºÂñÆ‰∏ÄÊñá‰ª∂ÁöÑÂïèÈ°åÔºåÂøΩË¶ñ‰∫ÜÂèØËÉΩÈúÄË¶ÅË∑®Êñá‰ª∂Êé®ÁêÜÂíåÂÑ™ÂåñÁöÑÊõ¥Âõ∞Èõ£ÁöÑÊÉÖÊ≥ÅÔºå‰æãÂ¶ÇÔºå„ÄåÂèØ‰ª•Áç≤ÂæóÁöÑÊúÄÂ§ßÁçéÂ≠∏ÈáëÊï∏ÈáèÊòØÂ§öÂ∞ëÔºü„ÄçÊ≠§È°ûË∑®Â§öÂÄãÊñá‰ª∂ÁöÑÂïèÈ°å‰∏çÂÉÖÁî±ÊñºÂøÖÈ†àÁêÜËß£ÁöÑÂÖßÂÆπÊõ¥Â§öËÄåÊõ¥ÂÖ∑ÊåëÊà∞ÊÄßÔºåÈÇÑÂõ†ÁÇ∫Ê®°ÂûãÂøÖÈ†à (1) Êé¢Á¥¢Êú™ÊèêÂèäÊ¢ù‰ª∂ÁöÑÊâÄÊúâÂèØËÉΩÁµÑÂêàÔºå‰ª•Âèä (2) ‰∫ÜËß£Ë∑®Êñá‰ª∂Ê¢ù‰ª∂‰πãÈñìÁöÑÈóú‰øÇÔºåÊâçËÉΩÂ∞çÊúÄ‰Ω≥ÁµêÊûúÈÄ≤Ë°åÊé®ÁêÜ„ÄÇÁÇ∫‰∫ÜË©ï‰º∞Ê®°ÂûãÂõûÁ≠îÊ≠§È°ûÂïèÈ°åÁöÑËÉΩÂäõÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑË≥áÊñôÈõÜ MDCRÔºåÂÆÉÂèØ‰ª•ÂèçÊò†ÁèæÂØ¶‰∏ñÁïåÁöÑÊåëÊà∞Ôºå‰∏¶‰ΩúÁÇ∫Ë§áÈõúÊ¢ù‰ª∂Êé®ÁêÜÁöÑÊñ∞Ê∏¨Ë©¶Âπ≥Âè∞ÔºåÈúÄË¶ÅÈÄ≤Ë°åÂÑ™Âåñ„ÄÇÊàëÂÄë‰ΩøÁî®ÊúÄÊñ∞ÁöÑ LLM Ë©ï‰º∞Ê≠§Ë≥áÊñôÈõÜÔºå‰∏¶Â±ïÁ§∫ÂÆÉÂÄëÂú®Ëß£Ê±∫Ê≠§‰ªªÂãôÊôÇÁöÑÈôêÂà∂„ÄÇÊàëÂÄëÁõ∏‰ø°Ê≠§Ë≥áÊñôÈõÜÂ∞á‰øÉÈÄ≤Êú™‰æÜÂú®ÂõûÁ≠îÂÖ∑ÊúâÊú™Áü•Ê¢ù‰ª∂ÁöÑÂÑ™ÂåñÂïèÈ°åÊñπÈù¢ÁöÑÁ†îÁ©∂„ÄÇ

##### **Split, Unlearn, Merge: Leveraging Data Attributes for More Effective Unlearning in LLMs**
2406.11780v1 by Swanand Ravindra Kadhe, Farhan Ahmed, Dennis Wei, Nathalie Baracaldo, Inkit Padhi

Large language models (LLMs) have shown to pose social and ethical risks such
as generating toxic language or facilitating malicious use of hazardous
knowledge. Machine unlearning is a promising approach to improve LLM safety by
directly removing harmful behaviors and knowledge. In this paper, we propose
"SPlit, UNlearn, MerGE" (SPUNGE), a framework that can be used with any
unlearning method to amplify its effectiveness. SPUNGE leverages data
attributes during unlearning by splitting unlearning data into subsets based on
specific attribute values, unlearning each subset separately, and merging the
unlearned models. We empirically demonstrate that SPUNGE significantly improves
the performance of two recent unlearning methods on state-of-the-art LLMs while
maintaining their general capabilities on standard academic benchmarks.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤È°ØÁ§∫ÊúÉÈÄ†ÊàêÁ§æÊúÉÂíåÈÅìÂæ∑È¢®Èö™Ôºå‰æãÂ¶ÇÁî¢ÁîüÊúâÊØíË™ûË®ÄÊàñ‰øÉÈÄ≤ÊÉ°ÊÑè‰ΩøÁî®Âç±Èö™Áü•Ë≠ò„ÄÇÊ©üÂô®ÈÅ∫ÂøòÊòØ‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÊñπÊ≥ïÔºåÂèØÈÄèÈÅéÁõ¥Êé•ÁßªÈô§ÊúâÂÆ≥Ë°åÁÇ∫ÂíåÁü•Ë≠ò‰æÜÊîπÂñÑ LLM ÁöÑÂÆâÂÖ®ÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫„ÄåSPlit, UNlearn, MerGE„ÄçÔºàSPUNGEÔºâÔºå‰∏ÄÂÄãÂèØËàá‰ªª‰ΩïÈÅ∫ÂøòÊñπÊ≥ï‰∏ÄËµ∑‰ΩøÁî®‰ª•Êì¥Â§ßÂÖ∂ÊúâÊïàÊÄßÁöÑÊ°ÜÊû∂„ÄÇSPUNGE Âú®ÈÅ∫ÂøòÈÅéÁ®ã‰∏≠Âà©Áî®Ë≥áÊñôÂ±¨ÊÄßÔºåÈÄèÈÅéÊ†πÊìöÁâπÂÆöÂ±¨ÊÄßÂÄºÂ∞áÈÅ∫ÂøòË≥áÊñôÂàÜÂâ≤ÊàêÂ≠êÈõÜ„ÄÅÂÄãÂà•ÈÅ∫ÂøòÊØèÂÄãÂ≠êÈõÜÔºåÁÑ∂ÂæåÂêà‰ΩµÂ∑≤ÈÅ∫ÂøòÁöÑÊ®°Âûã„ÄÇÊàëÂÄëÈÄèÈÅéÂØ¶Ë≠âË≠âÊòéÔºåSPUNGE Âú®ÊúÄÂÖàÈÄ≤ÁöÑ LLM ‰∏äÈ°ØËëóÊîπÂñÑ‰∫ÜÂÖ©Á®ÆÊúÄÊñ∞ÈÅ∫ÂøòÊñπÊ≥ïÁöÑÊïàËÉΩÔºåÂêåÊôÇÂú®Ê®ôÊ∫ñÂ≠∏Ë°ìÂü∫Ê∫ñ‰∏äÁ∂≠ÊåÅÂÖ∂‰∏ÄËà¨ËÉΩÂäõ„ÄÇ

##### **Improving Multi-Agent Debate with Sparse Communication Topology**
2406.11776v1 by Yunxuan Li, Yibing Du, Jiageng Zhang, Le Hou, Peter Grabowski, Yeqing Li, Eugene Ie

Multi-agent debate has proven effective in improving large language models
quality for reasoning and factuality tasks. While various role-playing
strategies in multi-agent debates have been explored, in terms of the
communication among agents, existing approaches adopt a brute force algorithm
-- each agent can communicate with all other agents. In this paper, we
systematically investigate the effect of communication connectivity in
multi-agent systems. Our experiments on GPT and Mistral models reveal that
multi-agent debates leveraging sparse communication topology can achieve
comparable or superior performance while significantly reducing computational
costs. Furthermore, we extend the multi-agent debate framework to multimodal
reasoning and alignment labeling tasks, showcasing its broad applicability and
effectiveness. Our findings underscore the importance of communication
connectivity on enhancing the efficiency and effectiveness of the "society of
minds" approach.

ÊëòË¶ÅÔºöÂ§ö‰∏ªÈ´îËæØË´ñÂ∑≤Ë¢´Ë≠âÂØ¶ËÉΩÊúâÊïàÊèêÂçáÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®Êé®ÁêÜÂíå‰∫ãÂØ¶ÊÄß‰ªªÂãô‰∏≠ÁöÑÂìÅË≥™„ÄÇÂÑòÁÆ°Â∑≤Êé¢Ë®éÈÅéÂ§ö‰∏ªÈ´îËæØË´ñ‰∏≠ÂêÑÁ®ÆËßíËâ≤ÊâÆÊºîÁ≠ñÁï•Ôºå‰ΩÜÂú®‰∏ªÈ´îÈñìÁöÑÊ∫ùÈÄöÊñπÈù¢ÔºåÁèæÊúâÊñπÊ≥ïÊé°Áî®Ë†ªÂäõÊºîÁÆóÊ≥ï‚Äî‚ÄîÊØèÂÄã‰∏ªÈ´îÈÉΩÂèØ‰ª•ËàáÊâÄÊúâÂÖ∂‰ªñ‰∏ªÈ´îÊ∫ùÈÄö„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁ≥ªÁµ±ÊÄßÂú∞Êé¢Ë®é‰∫ÜÊ∫ùÈÄöÈÄ£ÈÄöÊÄßÂú®Â§ö‰∏ªÈ´îÁ≥ªÁµ±‰∏≠ÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÂú® GPT Âíå Mistral Ê®°Âûã‰∏äÁöÑÂØ¶È©óÊè≠Á§∫ÔºåÂà©Áî®Á®ÄÁñèÊ∫ùÈÄöÊãìÊí≤ÁöÑÂ§ö‰∏ªÈ´îËæØË´ñÂèØ‰ª•Âú®Â§ßÂπÖÈôç‰ΩéÈÅãÁÆóÊàêÊú¨ÁöÑÂêåÊôÇÔºåÈÅîÂà∞ÂèØÊØîËºÉÊàñÊõ¥‰Ω≥ÁöÑÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ∞áÂ§ö‰∏ªÈ´îËæØË´ñÊû∂ÊßãÂª∂‰º∏Âà∞Â§öÊ®°ÊÖãÊé®ÁêÜÂíåÊØîÂ∞çÊ®ôË®ò‰ªªÂãôÔºåÂ±ïÁ§∫ÂÖ∂Âª£Ê≥õÁöÑÈÅ©Áî®ÊÄßÂíåÊúâÊïàÊÄß„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÂº∑Ë™ø‰∫ÜÊ∫ùÈÄöÈÄ£ÈÄöÊÄßÂ∞çÊñºÊèêÂçá„ÄåÂøÉÊô∫Á§æÊúÉ„ÄçÊñπÊ≥ïÁöÑÊïàÁéáÂíåÊúâÊïàÊÄßÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **Task Me Anything**
2406.11775v1 by Jieyu Zhang, Weikai Huang, Zixian Ma, Oscar Michel, Dong He, Tanmay Gupta, Wei-Chiu Ma, Ali Farhadi, Aniruddha Kembhavi, Ranjay Krishna

Benchmarks for large multimodal language models (MLMs) now serve to
simultaneously assess the general capabilities of models instead of evaluating
for a specific capability. As a result, when a developer wants to identify
which models to use for their application, they are overwhelmed by the number
of benchmarks and remain uncertain about which benchmark's results are most
reflective of their specific use case. This paper introduces Task-Me-Anything,
a benchmark generation engine which produces a benchmark tailored to a user's
needs. Task-Me-Anything maintains an extendable taxonomy of visual assets and
can programmatically generate a vast number of task instances. Additionally, it
algorithmically addresses user queries regarding MLM performance efficiently
within a computational budget. It contains 113K images, 10K videos, 2K 3D
object assets, over 365 object categories, 655 attributes, and 335
relationships. It can generate 750M image/video question-answering pairs, which
focus on evaluating MLM perceptual capabilities. Task-Me-Anything reveals
critical insights: open-source MLMs excel in object and attribute recognition
but lack spatial and temporal understanding; each model exhibits unique
strengths and weaknesses; larger models generally perform better, though
exceptions exist; and GPT4o demonstrates challenges in recognizing
rotating/moving objects and distinguishing colors.

ÊëòË¶ÅÔºöÂ§ßÂûãÂ§öÊ®°ÊÄÅËØ≠Ë®ÄÊ®°Âûã (MLM) ÁöÑÂü∫ÂáÜÁé∞Âú®ÂèØÁî®‰∫éÂêåÊó∂ËØÑ‰º∞Ê®°ÂûãÁöÑÈÄöÁî®ÂäüËÉΩÔºåËÄå‰∏çÊòØËØÑ‰º∞ÁâπÂÆöÂäüËÉΩ„ÄÇÂõ†Ê≠§ÔºåÂΩìÂºÄÂèë‰∫∫ÂëòÊÉ≥Ë¶ÅÁ°ÆÂÆö‰∏∫ÂÖ∂Â∫îÁî®Á®ãÂ∫è‰ΩøÁî®Âì™‰∫õÊ®°ÂûãÊó∂Ôºå‰ªñ‰ª¨‰ºöË¢´Âü∫ÂáÜÊï∞ÈáèÊâÄÊ∑πÊ≤°ÔºåÂπ∂‰∏î‰ªçÁÑ∂‰∏çÁ°ÆÂÆöÂì™‰∏™Âü∫ÂáÜÁöÑÁªìÊûúÊúÄËÉΩÂèçÊò†ÂÖ∂ÁâπÂÆöÁî®‰æã„ÄÇÊú¨Êñá‰ªãÁªç‰∫Ü Task-Me-AnythingÔºåËøôÊòØ‰∏Ä‰∏™Âü∫ÂáÜÁîüÊàêÂºïÊìéÔºåÂèØ‰ª•Ê†πÊçÆÁî®Êà∑ÁöÑÈúÄÊ±ÇÁîüÊàêÂÆöÂà∂Âü∫ÂáÜ„ÄÇTask-Me-Anything Áª¥Êä§‰∫Ü‰∏Ä‰∏™ÂèØÊâ©Â±ïÁöÑÂèØËßÜËµÑ‰∫ßÂàÜÁ±ªÊ≥ïÔºåÂπ∂‰∏îÂèØ‰ª•‰ª•ÁºñÁ®ãÊñπÂºèÁîüÊàêÂ§ßÈáè‰ªªÂä°ÂÆû‰æã„ÄÇÊ≠§Â§ñÔºåÂÆÉÂú®ËÆ°ÁÆóÈ¢ÑÁÆóÂÜÖÈÄöËøáÁÆóÊ≥ïÈ´òÊïàÂú∞Â§ÑÁêÜÁî®Êà∑ÂÖ≥‰∫é MLM ÊÄßËÉΩÁöÑÊü•ËØ¢„ÄÇÂÆÉÂåÖÂê´ 113K Âº†ÂõæÂÉè„ÄÅ10K ‰∏™ËßÜÈ¢ë„ÄÅ2K ‰∏™ 3D ÂØπË±°ËµÑ‰∫ß„ÄÅË∂ÖËøá 365 ‰∏™ÂØπË±°Á±ªÂà´„ÄÅ655 ‰∏™Â±ûÊÄßÂíå 335 ‰∏™ÂÖ≥Á≥ª„ÄÇÂÆÉÂèØ‰ª•ÁîüÊàê 750M ‰∏™ÂõæÂÉè/ËßÜÈ¢ëÈóÆÁ≠îÂØπÔºåÈáçÁÇπÊòØËØÑ‰º∞ MLM ÊÑüÁü•ËÉΩÂäõ„ÄÇTask-Me-Anything Êè≠Á§∫‰∫ÜÂÖ≥ÈîÆËßÅËß£ÔºöÂºÄÊ∫ê MLM Âú®ÂØπË±°ÂíåÂ±ûÊÄßËØÜÂà´ÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ΩÜÁº∫‰πèÁ©∫Èó¥ÂíåÊó∂Èó¥ÁêÜËß£ÔºõÊØè‰∏™Ê®°ÂûãÈÉΩË°®Áé∞Âá∫Áã¨ÁâπÁöÑ‰ºòÂäøÂíåÂä£ÂäøÔºõËæÉÂ§ßÁöÑÊ®°ÂûãÈÄöÂ∏∏Ë°®Áé∞ÂæóÊõ¥Â•ΩÔºåÂ∞ΩÁÆ°Â≠òÂú®‰æãÂ§ñÔºõGPT4o Âú®ËØÜÂà´ÊóãËΩ¨/ÁßªÂä®Áâ©‰ΩìÂíåÂå∫ÂàÜÈ¢úËâ≤ÊñπÈù¢Ë°®Áé∞Âá∫ÊåëÊàò„ÄÇ

##### **GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities**
2406.11768v1 by Sreyan Ghosh, Sonal Kumar, Ashish Seth, Chandra Kiran Reddy Evuru, Utkarsh Tyagi, S Sakshi, Oriol Nieto, Ramani Duraiswami, Dinesh Manocha

Perceiving and understanding non-speech sounds and non-verbal speech is
essential to making decisions that help us interact with our surroundings. In
this paper, we propose GAMA, a novel General-purpose Large Audio-Language Model
(LALM) with Advanced Audio Understanding and Complex Reasoning Abilities. We
build GAMA by integrating an LLM with multiple types of audio representations,
including features from a custom Audio Q-Former, a multi-layer aggregator that
aggregates features from multiple layers of an audio encoder. We fine-tune GAMA
on a large-scale audio-language dataset, which augments it with audio
understanding capabilities. Next, we propose CompA-R (Instruction-Tuning for
Complex Audio Reasoning), a synthetically generated instruction-tuning (IT)
dataset with instructions that require the model to perform complex reasoning
on the input audio. We instruction-tune GAMA with CompA-R to endow it with
complex reasoning abilities, where we further add a soft prompt as input with
high-level semantic evidence by leveraging event tags of the input audio.
Finally, we also propose CompA-R-test, a human-labeled evaluation dataset for
evaluating the capabilities of LALMs on open-ended audio question-answering
that requires complex reasoning. Through automated and expert human
evaluations, we show that GAMA outperforms all other LALMs in literature on
diverse audio understanding tasks by margins of 1%-84%. Further, GAMA IT-ed on
CompA-R proves to be superior in its complex reasoning and instruction
following capabilities.

ÊëòË¶ÅÔºö<paragraph>ÊÑüÁü•ÂíåÁêÜËß£ÈùûË™ûË®ÄËÅ≤Èü≥ÂíåÈùûË™ûË®ÄË®ÄË™ûÂ∞çÊñºÂÅöÂá∫ÊúâÂä©ÊñºÊàëÂÄëËàáÂë®ÂúçÁí∞Â¢É‰∫íÂãïÁöÑÊ±∫Á≠ñËá≥ÈóúÈáçË¶Å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ GAMAÔºå‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÈÄöÁî®Â§ßÂûãÈü≥Ë®äË™ûË®ÄÊ®°Âûã (LALM)ÔºåÂÖ∑ÂÇôÂÖàÈÄ≤ÁöÑÈü≥Ë®äÁêÜËß£ÂíåË§áÈõúÊé®ÁêÜËÉΩÂäõ„ÄÇÊàëÂÄëÈÄèÈÅéÂ∞á LLM ËàáÂ§öÁ®ÆÈ°ûÂûãÁöÑÈü≥Ë®äË°®ÂæµÊï¥ÂêàÂú®‰∏ÄËµ∑‰æÜÂª∫Êßã GAMAÔºåÂåÖÊã¨‰æÜËá™Ëá™Ë®ÇÈü≥Ë®ä Q-Former ÁöÑÁâπÂæµÔºåÈÄôÊòØ‰∏ÄÂÄãÂ§öÂ±§ËÅöÂêàÂô®ÔºåÂèØ‰ª•ËÅöÂêàÈü≥Ë®äÁ∑®Á¢ºÂô®ÁöÑÂ§öÂ±§ÁâπÂæµ„ÄÇÊàëÂÄëÂú®‰∏ÄÂÄãÂ§ßË¶èÊ®°ÁöÑÈü≥Ë®äË™ûË®ÄË≥áÊñôÈõÜ‰∏äÂæÆË™ø GAMAÔºåÈÄôË≥¶‰∫àÂÆÉÈü≥Ë®äÁêÜËß£ËÉΩÂäõ„ÄÇÊé•‰∏ã‰æÜÔºåÊàëÂÄëÊèêÂá∫ CompA-RÔºàË§áÈõúÈü≥Ë®äÊé®ÁêÜÁöÑÊåá‰ª§ÂæÆË™øÔºâÔºå‰∏ÄÂÄãÂêàÊàêÁî¢ÁîüÁöÑÊåá‰ª§ÂæÆË™ø (IT) Ë≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´ÈúÄË¶ÅÊ®°ÂûãÂ∞çËº∏ÂÖ•Èü≥Ë®äÂü∑Ë°åË§áÈõúÊé®ÁêÜÁöÑÊåá‰ª§„ÄÇÊàëÂÄë‰ΩøÁî® CompA-R Â∞ç GAMA ÈÄ≤Ë°åÊåá‰ª§ÂæÆË™øÔºåË≥¶‰∫àÂÆÉË§áÈõúÁöÑÊé®ÁêÜËÉΩÂäõÔºåÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Ê∑ªÂä†‰∏ÄÂÄãËªüÊèêÁ§∫‰ΩúÁÇ∫Ëº∏ÂÖ•Ôºå‰∏¶ÈÄèÈÅéÂà©Áî®Ëº∏ÂÖ•Èü≥Ë®äÁöÑ‰∫ã‰ª∂Ê®ôÁ±§‰æÜÁç≤ÂèñÈ´òÂ±§Á¥öË™ûÁæ©Ë≠âÊìö„ÄÇÊúÄÂæåÔºåÊàëÂÄëÈÇÑÊèêÂá∫‰∫Ü CompA-R-testÔºå‰∏ÄÂÄã‰∫∫Â∑•Ê®ôË®òÁöÑË©ï‰º∞Ë≥áÊñôÈõÜÔºåÁî®ÊñºË©ï‰º∞ LALM Âú®ÈúÄË¶ÅË§áÈõúÊé®ÁêÜÁöÑÈñãÊîæÂºèÈü≥Ë®äÂïèÁ≠î‰∏äÁöÑËÉΩÂäõ„ÄÇÈÄèÈÅéËá™ÂãïÂåñÂíåÂ∞àÂÆ∂‰∫∫Â∑•Ë©ï‰º∞ÔºåÊàëÂÄëË°®Êòé GAMA Âú®ÂêÑÁ®ÆÈü≥Ë®äÁêÜËß£‰ªªÂãô‰∏äÂÑ™ÊñºÊñáÁçª‰∏≠ÁöÑÊâÄÊúâÂÖ∂‰ªñ LALMÔºåÂπÖÂ∫¶ÁÇ∫ 1%-84%„ÄÇÊ≠§Â§ñÔºåÂú® CompA-R ‰∏äÈÄ≤Ë°å IT ÁöÑ GAMA Ë≠âÊòéÂÖ∂Âú®Ë§áÈõúÊé®ÁêÜÂíåÊåá‰ª§ÈÅµÂæ™ËÉΩÂäõÊñπÈù¢ÂÖ∑ÊúâÂÑ™Ë∂äÊÄß„ÄÇ</paragraph>

##### **STAR: SocioTechnical Approach to Red Teaming Language Models**
2406.11757v1 by Laura Weidinger, John Mellor, Bernat Guillen Pegueroles, Nahema Marchal, Ravin Kumar, Kristian Lum, Canfer Akbulut, Mark Diaz, Stevie Bergman, Mikel Rodriguez, Verena Rieser, William Isaac

This research introduces STAR, a sociotechnical framework that improves on
current best practices for red teaming safety of large language models. STAR
makes two key contributions: it enhances steerability by generating
parameterised instructions for human red teamers, leading to improved coverage
of the risk surface. Parameterised instructions also provide more detailed
insights into model failures at no increased cost. Second, STAR improves signal
quality by matching demographics to assess harms for specific groups, resulting
in more sensitive annotations. STAR further employs a novel step of arbitration
to leverage diverse viewpoints and improve label reliability, treating
disagreement not as noise but as a valuable contribution to signal quality.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫Ü STARÔºå‰∏ÄÁ®ÆÁ§æÊúÉÊäÄË°ìÊ°ÜÊû∂ÔºåÊîπÈÄ≤‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁ¥ÖÈöäÂÆâÂÖ®ÊÄßÁöÑÁèæÊúâÊúÄ‰Ω≥ÂØ¶Âãô„ÄÇSTAR ÂÅöÂá∫ÂÖ©È†Ö‰∏ªË¶ÅË≤¢ÁçªÔºöÂÆÉÈÄèÈÅéÁÇ∫‰∫∫È°ûÁ¥ÖÈöäÂì°Áî¢ÁîüÂèÉÊï∏ÂåñÊåá‰ª§‰æÜÂ¢ûÂº∑ÂèØÂ∞éÂêëÊÄßÔºåÈÄ≤ËÄåÊîπÂñÑÈ¢®Èö™Ë°®Èù¢ÁöÑË¶ÜËìãÁØÑÂúç„ÄÇÂèÉÊï∏ÂåñÊåá‰ª§‰πü‰ª•ÁÑ°Â¢ûÂä†ÊàêÊú¨ÁöÑÊñπÂºèÊèê‰æõÊõ¥Ë©≥Á¥∞ÁöÑÊ®°ÂûãÂ§±ÊïóË¶ãËß£„ÄÇÂÖ∂Ê¨°ÔºåSTAR ÈÄèÈÅéÊØîÂ∞ç‰∫∫Âè£Áµ±Ë®àË≥áÊñô‰æÜË©ï‰º∞ÁâπÂÆöÁæ§È´îÁöÑÂç±ÂÆ≥ÔºåÈÄ≤ËÄåÊîπÂñÑ‰ø°ËôüÂìÅË≥™ÔºåÁî¢ÁîüÊõ¥ÈùàÊïèÁöÑË®ªËß£„ÄÇSTAR ÈÄ≤‰∏ÄÊ≠•Êé°Áî®‰∏ÄÁ®ÆÊñ∞Á©éÁöÑ‰ª≤Ë£ÅÊ≠•È©üÔºå‰ª•Âà©Áî®‰∏çÂêåÁöÑËßÄÈªû‰∏¶ÊîπÂñÑÊ®ôÁ±§ÂèØÈù†ÊÄßÔºåÂ∞áÂàÜÊ≠ßË¶ñÁÇ∫‰ø°ËôüÂìÅË≥™ÁöÑÂØ∂Ë≤¥Ë≤¢ÁçªÔºåËÄå‰∏çÊòØÈõúË®ä„ÄÇ

##### **DustNet: skillful neural network predictions of Saharan dust**
2406.11754v1 by Trish E. Nowak, Andy T. Augousti, Benno I. Simmons, Stefan Siegert

Suspended in the atmosphere are millions of tonnes of mineral dust which
interacts with weather and climate. Accurate representation of mineral dust in
weather models is vital, yet remains challenging. Large scale weather models
use high power supercomputers and take hours to complete the forecast. Such
computational burden allows them to only include monthly climatological means
of mineral dust as input states inhibiting their forecasting accuracy. Here, we
introduce DustNet a simple, accurate and super fast forecasting model for
24-hours ahead predictions of aerosol optical depth AOD. DustNet trains in less
than 8 minutes and creates predictions in 2 seconds on a desktop computer.
Created by DustNet predictions outperform the state-of-the-art physics-based
model on coarse 1 x 1 degree resolution at 95% of grid locations when compared
to ground truth satellite data. Our results show DustNet has a potential for
fast and accurate AOD forecasting which could transform our understanding of
dust impacts on weather patterns.

ÊëòË¶ÅÔºöÊá∏ÊµÆÂú®Â§ßÊ∞£‰∏≠ÁöÑÁ§¶Áâ©Â°µÊúâÊï∏ÁôæËê¨Âô∏ÔºåÊúÉËàáÂ§©Ê∞£ÂíåÊ∞£ÂÄôÁõ∏‰∫í‰ΩúÁî®„ÄÇÂú®Â§©Ê∞£Ê®°Âûã‰∏≠Ê∫ñÁ¢∫ÂëàÁèæÁ§¶Áâ©Â°µËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜ‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂ§ßË¶èÊ®°Â§©Ê∞£Ê®°Âûã‰ΩøÁî®È´òÂäüÁéáË∂ÖÁ¥öÈõªËÖ¶ÔºåÈúÄË¶ÅÊï∏Â∞èÊôÇÊâçËÉΩÂÆåÊàêÈ†êÊ∏¨„ÄÇÈÄôÁ®ÆË®àÁÆóË≤†ÊìîÂè™ËÉΩËÆìÂÆÉÂÄëÂ∞áÁ§¶Áâ©Â°µÁöÑÊØèÊúàÊ∞£ÂÄôÂπ≥ÂùáÂÄº‰ΩúÁÇ∫Ëº∏ÂÖ•ÁãÄÊÖãÔºåÂæûËÄåÊäëÂà∂‰∫ÜÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇÂú®Ê≠§ÔºåÊàëÂÄë‰ªãÁ¥π DustNetÔºåÈÄôÊòØ‰∏ÄÂÄãÁ∞°ÂñÆ„ÄÅÊ∫ñÁ¢∫‰∏îË∂ÖÁ¥öÂø´ÈÄüÁöÑÈ†êÊ∏¨Ê®°ÂûãÔºåÁî®ÊñºÈ†êÊ∏¨ 24 Â∞èÊôÇÂæåÁöÑÊ∞£Ê∫∂ËÜ†ÂÖâÂ≠∏ÂéöÂ∫¶ AOD„ÄÇDustNet ÁöÑË®ìÁ∑¥ÊôÇÈñì‰∏çÂà∞ 8 ÂàÜÈêòÔºå‰∏¶ÂèØ‰ª•Âú®Ê°å‰∏äÂûãÈõªËÖ¶‰∏äÊñº 2 ÁßíÂÖßÂª∫Á´ãÈ†êÊ∏¨„ÄÇËàáÂú∞Èù¢ÁúüÂØ¶Ë°õÊòüÊï∏ÊìöÁõ∏ÊØîÔºåDustNet È†êÊ∏¨Âú®ËàáÊúÄÂÖàÈÄ≤ÁöÑÂü∫ÊñºÁâ©ÁêÜÊ®°ÂûãÁöÑÁ≤óÁï• 1 x 1 Â∫¶Ëß£ÊûêÂ∫¶‰∏≠ÔºåÊñº 95% ÁöÑÁ∂≤Ê†º‰ΩçÁΩÆË°®ÁèæÂÑ™Áï∞„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåDustNet ÂÖ∑ÊúâÂø´ÈÄü‰∏îÊ∫ñÁ¢∫ÁöÑ AOD È†êÊ∏¨ÊΩõÂäõÔºåÈÄôÂèØ‰ª•ÊîπËÆäÊàëÂÄëÂ∞çÁÅ∞Â°µÂ∞çÂ§©Ê∞£Ê®°ÂºèÂΩ±ÈüøÁöÑÁêÜËß£„ÄÇ

##### **A Semantic-based Layer Freezing Approach to Efficient Fine-Tuning of Language Models**
2406.11753v1 by Jian Gu, Aldeida Aleti, Chunyang Chen, Hongyu Zhang

Finetuning language models (LMs) is crucial for adapting the models to
downstream data and tasks. However, full finetuning is usually costly. Existing
work, such as parameter-efficient finetuning (PEFT), often focuses on
\textit{how to finetune} but neglects the issue of \textit{where to finetune}.
As a pioneering work on answering where to finetune (at the layer level), we
conduct a semantic analysis of the LM inference process. We first propose a
virtual transition of the latent representation and then trace its factual
transition. Based on the deviation in transitions, we estimate the gain of
finetuning each model layer, and further, narrow down the scope for finetuning.
We perform extensive experiments across well-known LMs and datasets. The
results show that our approach is effective and efficient, and outperforms the
existing baselines. Our approach is orthogonal to existing efficient
techniques, such as PEFT methods, offering practical values on LM finetuning.

ÊëòË¶ÅÔºöÂæÆË™øË™ûË®ÄÊ®°Âûã (LM) Â∞çÊñºË™øÊï¥Ê®°Âûã‰ª•ÈÅ©Êáâ‰∏ãÊ∏∏Ë≥áÊñôÂíå‰ªªÂãôËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÂÆåÊï¥ÁöÑÂæÆË™øÈÄöÂ∏∏ÊàêÊú¨ÂæàÈ´ò„ÄÇÁèæÊúâÁöÑÂ∑•‰ΩúÔºå‰æãÂ¶ÇÂèÉÊï∏È´òÊïàÂæÆË™ø (PEFT)ÔºåÈÄöÂ∏∏ÂÅ¥ÈáçÊñº„ÄåÂ¶Ç‰ΩïÂæÆË™ø„ÄçÔºå‰ΩÜÂøΩÁï•‰∫Ü„ÄåÂú®Âì™Ë£°ÂæÆË™ø„ÄçÁöÑÂïèÈ°å„ÄÇ‰ΩúÁÇ∫ÂõûÁ≠îÂú®Âì™Ë£°ÂæÆË™øÔºàÂú®Â±§Á¥öÔºâÁöÑÈñãÂâµÊÄßÂ∑•‰ΩúÔºåÊàëÂÄëÂ∞ç LM Êé®Ë´ñÈÅéÁ®ãÈÄ≤Ë°å‰∫ÜË™ûÁæ©ÂàÜÊûê„ÄÇÊàëÂÄëÈ¶ñÂÖàÊèêÂá∫ÊΩõÂú®Ë°®ÂæµÁöÑËôõÊì¨ËΩâÊèõÔºåÁÑ∂ÂæåËøΩËπ§ÂÖ∂‰∫ãÂØ¶ËΩâÊèõ„ÄÇÊ†πÊìöËΩâÊèõ‰∏≠ÁöÑÂÅèÂ∑ÆÔºåÊàëÂÄë‰º∞Ë®àÂæÆË™øÊØèÂÄãÊ®°ÂûãÂ±§ÁöÑÂ¢ûÁõäÔºå‰∏¶ÈÄ≤‰∏ÄÊ≠•Á∏ÆÂ∞èÂæÆË™øÁöÑÁØÑÂúç„ÄÇÊàëÂÄëÂ∞çËëóÂêçÁöÑ LM ÂíåË≥áÊñôÈõÜÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©ó„ÄÇÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÊúâÊïà‰∏îÈ´òÊïàÔºå‰∏¶‰∏îÂÑ™ÊñºÁèæÊúâÁöÑÂü∫Ê∫ñ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïËàáÁèæÊúâÁöÑÈ´òÊïàÊäÄË°ìÔºà‰æãÂ¶Ç PEFT ÊñπÊ≥ïÔºâÊ≠£‰∫§ÔºåÁÇ∫ LM ÂæÆË™øÊèê‰æõ‰∫ÜÂØ¶Áî®ÁöÑÂÉπÂÄº„ÄÇ

##### **Multi-Layer Ranking with Large Language Models for News Source Recommendation**
2406.11745v1 by Wenjia Zhang, Lin Gui, Rob Procter, Yulan He

To seek reliable information sources for news events, we introduce a novel
task of expert recommendation, which aims to identify trustworthy sources based
on their previously quoted statements. To achieve this, we built a novel
dataset, called NewsQuote, consisting of 23,571 quote-speaker pairs sourced
from a collection of news articles. We formulate the recommendation task as the
retrieval of experts based on their likelihood of being associated with a given
query. We also propose a multi-layer ranking framework employing Large Language
Models to improve the recommendation performance. Our results show that
employing an in-context learning based LLM ranker and a multi-layer
ranking-based filter significantly improve both the predictive quality and
behavioural quality of the recommender system.

ÊëòË¶ÅÔºöÁÇ∫‰∫ÜÂ∞ãÊâæÊñ∞ËÅû‰∫ã‰ª∂ÁöÑÂèØÈù†Ë≥áË®ä‰æÜÊ∫êÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÈ†ÖÂ∞àÂÆ∂Êé®Ëñ¶ÁöÑÊñ∞‰ªªÂãôÔºåÁõÆÊ®ôÊòØÊ†πÊìö‰ªñÂÄë‰πãÂâçÂºïÁî®ÁöÑËÅ≤Êòé‰æÜË≠òÂà•ÂèØ‰ø°Ë≥¥ÁöÑ‰æÜÊ∫ê„ÄÇÁÇ∫‰∫ÜÂØ¶ÁèæÊ≠§ÁõÆÁöÑÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ NewsQuote ÁöÑÊñ∞Ë≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂæûÊñ∞ËÅûÊñáÁ´†ÈõÜÂêà‰∏≠ÂèñÂæóÁöÑ 23,571 Â∞çÂºïËø∞-ÁôºË®ÄËÄÖ„ÄÇÊàëÂÄëÂ∞áÊé®Ëñ¶‰ªªÂãôÂà∂ÂÆöÁÇ∫Ê†πÊìöÂ∞àÂÆ∂ËàáÁâπÂÆöÊü•Ë©¢Áõ∏ÈóúÁöÑÂèØËÉΩÊÄß‰æÜÊ™¢Á¥¢Â∞àÂÆ∂„ÄÇÊàëÂÄëÈÇÑÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂ§öÂ±§Á¥öÊéíÂêçÊû∂ÊßãÔºåÊé°Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã‰æÜÊîπÂñÑÊé®Ëñ¶ÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåÊé°Áî®Âü∫ÊñºÊÉÖÂ¢ÉÂ≠∏ÁøíÁöÑ LLM ÊéíÂêçÂô®ÂíåÂü∫ÊñºÂ§öÂ±§Á¥öÊéíÂêçÁöÑÁØ©ÈÅ∏Âô®ÔºåÂèØ‰ª•È°ØËëóÊîπÂñÑÊé®Ëñ¶Á≥ªÁµ±ÁöÑÈ†êÊ∏¨ÂìÅË≥™ÂíåË°åÁÇ∫ÂìÅË≥™„ÄÇ

##### **Transcendence: Generative Models Can Outperform The Experts That Train Them**
2406.11741v1 by Edwin Zhang, Vincent Zhu, Naomi Saphra, Anat Kleiman, Benjamin L. Edelman, Milind Tambe, Sham M. Kakade, Eran Malach

Generative models are trained with the simple objective of imitating the
conditional probability distribution induced by the data they are trained on.
Therefore, when trained on data generated by humans, we may not expect the
artificial model to outperform the humans on their original objectives. In this
work, we study the phenomenon of transcendence: when a generative model
achieves capabilities that surpass the abilities of the experts generating its
data. We demonstrate transcendence by training an autoregressive transformer to
play chess from game transcripts, and show that the trained model can sometimes
achieve better performance than all players in the dataset. We theoretically
prove that transcendence is enabled by low-temperature sampling, and rigorously
assess this experimentally. Finally, we discuss other sources of transcendence,
laying the groundwork for future investigation of this phenomenon in a broader
setting.

ÊëòË¶ÅÔºöÁîüÊàêÊ®°ÂûãÁöÑË®ìÁ∑¥ÁõÆÊ®ôÂæàÁ∞°ÂñÆÔºåÂ∞±ÊòØÊ®°‰ªøË®ìÁ∑¥Ë≥áÊñôÊâÄÂºïÁôºÁöÑÊ¢ù‰ª∂Ê©üÁéáÂàÜ‰Ωà„ÄÇÂõ†Ê≠§ÔºåÁï∂ÊàëÂÄë‰ΩøÁî®‰∫∫È°ûÁî¢ÁîüÁöÑË≥áÊñôÈÄ≤Ë°åË®ìÁ∑¥ÊôÇÔºåÊàëÂÄëÂèØËÉΩ‰∏çÊúÉÊúüÊúõ‰∫∫Â∑•Ê®°ÂûãÂú®ÂéüÊú¨ÁöÑÁõÆÊ®ô‰∏äË∂ÖË∂ä‰∫∫È°û„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éË∂ÖË∂äÁèæË±°ÔºöÁï∂ÁîüÊàêÊ®°ÂûãÈÅîÂà∞ÁöÑËÉΩÂäõË∂ÖË∂äÁî¢ÁîüÂÖ∂Ë≥áÊñôÁöÑÂ∞àÂÆ∂ËÉΩÂäõ„ÄÇÊàëÂÄëÈÄèÈÅéË®ìÁ∑¥‰∏ÄÂÄãËá™Ëø¥Ê≠∏TransformerÂæûÈÅäÊà≤Ë®òÈåÑ‰∏≠‰∏ãÊ£ã‰æÜË≠âÊòéË∂ÖË∂äÔºå‰∏¶È°ØÁ§∫Ë®ìÁ∑¥Âá∫‰æÜÁöÑÊ®°ÂûãÊúâÊôÇÂèØ‰ª•Âú®Ë≥áÊñôÈõÜ‰∏≠ÈÅîÊàêÊØîÊâÄÊúâÁé©ÂÆ∂Êõ¥Â•ΩÁöÑË°®Áèæ„ÄÇÊàëÂÄëÂú®ÁêÜË´ñ‰∏äË≠âÊòé‰∫ÜË∂ÖË∂äÊòØÁî±‰ΩéÊ∫´ÂèñÊ®£ÊâÄ‰øÉÊàêÔºå‰∏¶Âö¥Ê†ºÂú∞‰ª•ÂØ¶È©óË©ï‰º∞ÈÄô‰∏ÄÈªû„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®éË´ñË∂ÖË∂äÁöÑÂÖ∂‰ªñ‰æÜÊ∫êÔºåÁÇ∫Êú™‰æÜÂú®Êõ¥Âª£Ê≥õÁöÑË®≠ÂÆö‰∏≠Êé¢Ë®éÊ≠§ÁèæË±°Â•†ÂÆöÂü∫Á§é„ÄÇ

##### **Imagination Policy: Using Generative Point Cloud Models for Learning Manipulation Policies**
2406.11740v1 by Haojie Huang, Karl Schmeckpeper, Dian Wang, Ondrej Biza, Yaoyao Qian, Haotian Liu, Mingxi Jia, Robert Platt, Robin Walters

Humans can imagine goal states during planning and perform actions to match
those goals. In this work, we propose Imagination Policy, a novel multi-task
key-frame policy network for solving high-precision pick and place tasks.
Instead of learning actions directly, Imagination Policy generates point clouds
to imagine desired states which are then translated to actions using rigid
action estimation. This transforms action inference into a local generative
task. We leverage pick and place symmetries underlying the tasks in the
generation process and achieve extremely high sample efficiency and
generalizability to unseen configurations. Finally, we demonstrate
state-of-the-art performance across various tasks on the RLbench benchmark
compared with several strong baselines.

ÊëòË¶ÅÔºö‰∫∫È°ûÂèØ‰ª•Âú®Ë¶èÂäÉÊúüÈñìÊÉ≥ÂÉèÁõÆÊ®ôÁãÄÊÖãÔºå‰∏¶Âü∑Ë°åÂãï‰Ωú‰ª•Á¨¶ÂêàÈÄô‰∫õÁõÆÊ®ô„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ÊÉ≥ÂÉèÁ≠ñÁï•Ôºå‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂ§ö‰ªªÂãôÈóúÈçµÂΩ±Ê†ºÁ≠ñÁï•Á∂≤Ë∑ØÔºåÁî®ÊñºËß£Ê±∫È´òÁ≤æÂ∫¶ÁöÑÂèñÊîæ‰ªªÂãô„ÄÇÊÉ≥ÂÉèÁ≠ñÁï•‰∏¶ÈùûÁõ¥Êé•Â≠∏ÁøíÂãï‰ΩúÔºåËÄåÊòØÁî¢ÁîüÈªûÈõ≤‰ª•ÊÉ≥ÂÉèÊúüÊúõÁöÑÁãÄÊÖãÔºåÁÑ∂Âæå‰ΩøÁî®ÂâõÊÄßÂãï‰Ωú‰º∞Ë®àÂ∞áÂÖ∂ËΩâÊèõÁÇ∫Âãï‰Ωú„ÄÇÈÄôÂ∞áÂãï‰ΩúÊé®Ë´ñËΩâËÆäÁÇ∫‰∏ÄÂÄãÂ±ÄÈÉ®ÁîüÊàê‰ªªÂãô„ÄÇÊàëÂÄëÂà©Áî®ÂèñÊîæÂ∞çÁ®±ÊÄßÂú®ÁîüÊàêÈÅéÁ®ã‰∏≠‰ΩúÁÇ∫‰ªªÂãôÁöÑÂü∫Á§éÔºå‰∏¶ÂØ¶ÁèæÊ•µÈ´òÁöÑÊ®£Êú¨ÊïàÁéáÂíåÂ∞çÊú™Ë¶ãÈÖçÁΩÆÁöÑ‰∏ÄËà¨ÂåñËÉΩÂäõ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂú® RLbench Âü∫Ê∫ñ‰∏äÂêÑÁ®Æ‰ªªÂãôÁöÑÊúÄÊñ∞ÊïàËÉΩÔºå‰∏¶ËàáÂπæÂÄãÂº∑Â§ßÁöÑÂü∫Ê∫ñÈÄ≤Ë°åÊØîËºÉ„ÄÇ

##### **Interactive Evolution: A Neural-Symbolic Self-Training Framework For Large Language Models**
2406.11736v1 by Fangzhi Xu, Qiushi Sun, Kanzhi Cheng, Jun Liu, Yu Qiao, Zhiyong Wu

One of the primary driving forces contributing to the superior performance of
Large Language Models (LLMs) is the extensive availability of human-annotated
natural language data, which is used for alignment fine-tuning. This inspired
researchers to investigate self-training methods to mitigate the extensive
reliance on human annotations. However, the current success of self-training
has been primarily observed in natural language scenarios, rather than in the
increasingly important neural-symbolic scenarios. To this end, we propose an
environment-guided neural-symbolic self-training framework named ENVISIONS. It
aims to overcome two main challenges: (1) the scarcity of symbolic data, and
(2) the limited proficiency of LLMs in processing symbolic language. Extensive
evaluations conducted on three distinct domains demonstrate the effectiveness
of our approach. Additionally, we have conducted a comprehensive analysis to
uncover the factors contributing to ENVISIONS's success, thereby offering
valuable insights for future research in this area. Code will be available at
\url{https://github.com/xufangzhi/ENVISIONS}.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊïàËÉΩÂçìË∂äÔºåÂÖ∂‰∏≠‰∏ÄÈ†Ö‰∏ªË¶ÅÈ©ÖÂãïÂäõÂú®ÊñºÂ§ßÈáèÂèØ‰æõÂèñÂæóÁöÑ‰∫∫Â∑•Ê®ôË®ªËá™ÁÑ∂Ë™ûË®ÄË≥áÊñôÔºåÈÄô‰∫õË≥áÊñôÁî®ÊñºÊØîÂ∞çÂæÆË™ø„ÄÇÈÄôÂïüÁôºÁ†îÁ©∂‰∫∫Âì°Êé¢Á©∂Ëá™Ë®ìÁ∑¥ÊñπÊ≥ïÔºå‰ª•Ê∏õËºïÂ∞ç‰∫∫Â∑•Ê®ôË®ªÁöÑÂª£Ê≥õ‰æùË≥¥„ÄÇÁÑ∂ËÄåÔºåËá™Ë®ìÁ∑¥ÁõÆÂâçÁöÑÊàêÂäü‰∏ªË¶ÅË¶ãÊñºËá™ÁÑ∂Ë™ûË®ÄÂ†¥ÊôØÔºåËÄåÈùûÊó•ÁõäÈáçË¶ÅÁöÑÁ•ûÁ∂ìÁ¨¶ËôüÂ†¥ÊôØ„ÄÇÊúâÈëëÊñºÊ≠§ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂêçÁÇ∫ ENVISIONS ÁöÑÁí∞Â¢ÉÂºïÂ∞éÁ•ûÁ∂ìÁ¨¶ËôüËá™Ë®ìÁ∑¥Êû∂Êßã„ÄÇÂÖ∂ÁõÆÊ®ôÊòØÂÖãÊúçÂÖ©È†Ö‰∏ªË¶ÅÊåëÊà∞Ôºö(1) Á¨¶ËôüË≥áÊñôÁöÑÁ®ÄÂ∞ëÊÄßÔºå‰ª•Âèä (2) LLM ËôïÁêÜÁ¨¶ËôüË™ûË®ÄÁöÑÁÜüÁ∑¥Â∫¶ÊúâÈôê„ÄÇÂú®‰∏âÂÄã‰∏çÂêåÈ†òÂüüÈÄ≤Ë°åÁöÑÂª£Ê≥õË©ï‰º∞Ë≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÂàÜÊûêÔºå‰ª•ÊâæÂá∫‰øÉÊàê ENVISIONS ÊàêÂäüÁöÑÂéüÂõ†ÔºåÈÄ≤ËÄåÁÇ∫Ê≠§È†òÂüüÁöÑÊú™‰æÜÁ†îÁ©∂Êèê‰æõÂØ∂Ë≤¥Ë¶ãËß£„ÄÇÁ®ãÂºèÁ¢ºÂ∞áÊñº\url{https://github.com/xufangzhi/ENVISIONS} Êèê‰æõ„ÄÇ

##### **1000 African Voices: Advancing inclusive multi-speaker multi-accent speech synthesis**
2406.11727v1 by Sewade Ogun, Abraham T. Owodunni, Tobi Olatunji, Eniola Alese, Babatunde Oladimeji, Tejumade Afonja, Kayode Olaleye, Naome A. Etori, Tosin Adewumi

Recent advances in speech synthesis have enabled many useful applications
like audio directions in Google Maps, screen readers, and automated content
generation on platforms like TikTok. However, these systems are mostly
dominated by voices sourced from data-rich geographies with personas
representative of their source data. Although 3000 of the world's languages are
domiciled in Africa, African voices and personas are under-represented in these
systems. As speech synthesis becomes increasingly democratized, it is desirable
to increase the representation of African English accents. We present Afro-TTS,
the first pan-African accented English speech synthesis system able to generate
speech in 86 African accents, with 1000 personas representing the rich
phonological diversity across the continent for downstream application in
Education, Public Health, and Automated Content Creation. Speaker interpolation
retains naturalness and accentedness, enabling the creation of new voices.

ÊëòË¶ÅÔºöËøëÊúüÂú®Ë™ûÈü≥ÂêàÊàêÊñπÈù¢ÁöÑÈÄ≤Â±ïÂ∑≤ÂïüÁî®Ë®±Â§öÊúâÁî®ÁöÑÊáâÁî®Á®ãÂºèÔºå
‰æãÂ¶Ç Google Âú∞Âúñ‰∏≠ÁöÑË™ûÈü≥ÊåáÁ§∫„ÄÅËû¢ÂπïÈñ±ËÆÄÂô®Ôºå‰ª•Âèä TikTok Á≠âÂπ≥Âè∞‰∏äÁöÑËá™ÂãïÂåñÂÖßÂÆπÁî¢Áîü„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÁ≥ªÁµ±Â§ßÂ§öÁî±‰æÜËá™Ë≥áÊñôË±êÂØåÂú∞ÂçÄÁöÑËÅ≤Èü≥‰∏ªÂ∞éÔºåÈÄô‰∫õËßíËâ≤‰ª£Ë°®ÂÖ∂ÂéüÂßãË≥áÊñô„ÄÇÂÑòÁÆ°‰∏ñÁïå‰∏äÊúâ 3000 Á®ÆË™ûË®ÄÂú®ÈùûÊ¥≤‰ΩøÁî®Ôºå‰ΩÜÈÄô‰∫õÁ≥ªÁµ±‰∏≠ÈùûÊ¥≤ÁöÑËÅ≤Èü≥ÂíåËßíËâ≤ÂçªÈÆÆÂ∞ëË¢´‰ª£Ë°®„ÄÇÈö®ËëóË™ûÈü≥ÂêàÊàêÊó•ÁõäÊ∞ë‰∏ªÂåñÔºåÂ¢ûÂä†ÈùûÊ¥≤Ëã±Ë™ûÂè£Èü≥ÁöÑ‰ª£Ë°®ÊÄßÊòØÂÄºÂæóÊúüÂæÖÁöÑ„ÄÇÊàëÂÄëÊèêÂá∫ Afro-TTSÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÊ≥õÈùûÊ¥≤Âè£Èü≥Ëã±Ë™ûË™ûÈü≥ÂêàÊàêÁ≥ªÁµ±ÔºåËÉΩÂ§†‰ª• 86 Á®ÆÈùûÊ¥≤Âè£Èü≥Áî¢ÁîüË™ûÈü≥Ôºå‰∏¶Êúâ 1000 ÂÄãËßíËâ≤‰ª£Ë°®Êï¥ÂÄãÂ§ßÈô∏Ë±êÂØåÁöÑÈü≥ÈüªÂ§öÊ®£ÊÄßÔºå‰ª•ÊáâÁî®ÊñºÊïôËÇ≤„ÄÅÂÖ¨ÂÖ±Ë°õÁîüÂíåËá™ÂãïÂåñÂÖßÂÆπÂª∫Á´ãÁöÑ‰∏ãÊ∏∏ÊáâÁî®Á®ãÂºè„ÄÇË™™Ë©±ËÄÖÂÖßÊèí‰øùÁïô‰∫ÜËá™ÁÑ∂ÊÄßÂíåÂè£Èü≥ÔºåËÉΩÂ§†ÂâµÈÄ†Âá∫Êñ∞ÁöÑËÅ≤Èü≥„ÄÇ

##### **Zero-Shot Generalization during Instruction Tuning: Insights from Similarity and Granularity**
2406.11721v1 by Bingxiang He, Ning Ding, Cheng Qian, Jia Deng, Ganqu Cui, Lifan Yuan, Huan-ang Gao, Huimin Chen, Zhiyuan Liu, Maosong Sun

Understanding alignment techniques begins with comprehending zero-shot
generalization brought by instruction tuning, but little of the mechanism has
been understood. Existing work has largely been confined to the task level,
without considering that tasks are artificially defined and, to LLMs, merely
consist of tokens and representations. This line of research has been limited
to examining transfer between tasks from a task-pair perspective, with few
studies focusing on understanding zero-shot generalization from the perspective
of the data itself. To bridge this gap, we first demonstrate through multiple
metrics that zero-shot generalization during instruction tuning happens very
early. Next, we investigate the facilitation of zero-shot generalization from
both data similarity and granularity perspectives, confirming that encountering
highly similar and fine-grained training data earlier during instruction
tuning, without the constraints of defined "tasks", enables better
generalization. Finally, we propose a more grounded training data arrangement
method, Test-centric Multi-turn Arrangement, and show its effectiveness in
promoting continual learning and further loss reduction. For the first time, we
show that zero-shot generalization during instruction tuning is a form of
similarity-based generalization between training and test data at the instance
level. We hope our analysis will advance the understanding of zero-shot
generalization during instruction tuning and contribute to the development of
more aligned LLMs. Our code is released at
https://github.com/HBX-hbx/dynamics_of_zero-shot_generalization.

ÊëòË¶ÅÔºöÁêÜËß£Â∞çÈΩäÊäÄË°ìÂßãÊñºÁêÜËß£Êåá‰ª§Ë™øÊï¥Â∏∂‰æÜÁöÑÈõ∂Ê¨°Â≠∏ÁøíÊ≥õÂåñÔºå‰ΩÜÂ∞çÊ©üÂà∂‰∫ÜËß£ÁîöÂ∞ë„ÄÇÁèæÊúâÂ∑•‰ΩúÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂ±ÄÈôêÊñº‰ªªÂãôÂ±§Èù¢ÔºåËÄåÊ≤íÊúâËÄÉÊÖÆÂà∞‰ªªÂãôÊòØ‰∫∫Â∑•ÂÆöÁæ©ÁöÑÔºåËÄå‰∏îÂ∞çÊñº LLM ‰æÜË™™ÔºåÂÉÖÂÉÖÁî±Ê®ôË®òÂíåË°®Á§∫ÁµÑÊàê„ÄÇÈÄôÊ¢ùÁ†îÁ©∂Ë∑ØÁ∑öÂÉÖÈôêÊñºÂæû‰ªªÂãôÂ∞çÁöÑËßíÂ∫¶ÂØ©Ë¶ñ‰ªªÂãô‰πãÈñìÁöÑËΩâÁßªÔºåÂæàÂ∞ëÊúâÁ†îÁ©∂Â∞àÊ≥®ÊñºÂæûÊï∏ÊìöÊú¨Ë∫´ÁöÑËßíÂ∫¶ÁêÜËß£Èõ∂Ê¨°Â≠∏ÁøíÊ≥õÂåñ„ÄÇÁÇ∫‰∫ÜÂΩåË£úÈÄô‰∏ÄÂ∑ÆË∑ùÔºåÊàëÂÄëÈ¶ñÂÖàÈÄöÈÅéÂ§öÈ†ÖÊåáÊ®ôË≠âÊòéÔºåÂú®Êåá‰ª§Ë™øÊï¥ÊúüÈñìÔºåÈõ∂Ê¨°Â≠∏ÁøíÊ≥õÂåñÁôºÁîüÂæóÂæàÊó©„ÄÇÊé•‰∏ã‰æÜÔºåÊàëÂÄëÂæûÊï∏ÊìöÁõ∏‰ººÊÄßÂíåÁ≤íÂ∫¶ËßíÂ∫¶Á†îÁ©∂Èõ∂Ê¨°Â≠∏ÁøíÊ≥õÂåñÁöÑ‰øÉÈÄ≤‰ΩúÁî®ÔºåÁ¢∫Ë™çÂú®Êåá‰ª§Ë™øÊï¥ÊúüÈñìÊõ¥Êó©Âú∞ÈÅáÂà∞È´òÂ∫¶Áõ∏‰ºº‰∏îÁ¥∞Á≤íÂ∫¶ÁöÑË®ìÁ∑¥Êï∏ÊìöÔºå‰∏çÂèóÂÆöÁæ©ÁöÑ„Äå‰ªªÂãô„ÄçÁ¥ÑÊùüÔºåÂèØ‰ª•ÂØ¶ÁèæÊõ¥Â•ΩÁöÑÊ≥õÂåñ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊõ¥Á¥ÆÂØ¶ÁöÑË®ìÁ∑¥Êï∏ÊìöÊéíÂàóÊñπÊ≥ïÔºåÂç≥‰ª•Ê∏¨Ë©¶ÁÇ∫‰∏≠ÂøÉÁöÑÂ§öÊ¨°ÊéíÂàóÔºå‰∏¶Â±ïÁ§∫‰∫ÜÂÖ∂Âú®‰øÉÈÄ≤ÊåÅÁ∫åÂ≠∏ÁøíÂíåÈÄ≤‰∏ÄÊ≠•ÊêçÂ§±Ê∏õÂ∞ëÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëÈ¶ñÊ¨°Ë°®ÊòéÔºåÂú®Êåá‰ª§Ë™øÊï¥ÊúüÈñìÔºåÈõ∂Ê¨°Â≠∏ÁøíÊ≥õÂåñÊòØÂú®ÂØ¶‰æãÂ±§Èù¢‰∏äË®ìÁ∑¥Êï∏ÊìöÂíåÊ∏¨Ë©¶Êï∏Êìö‰πãÈñìÂü∫ÊñºÁõ∏‰ººÊÄßÁöÑÊ≥õÂåñÂΩ¢Âºè„ÄÇÊàëÂÄëÂ∏åÊúõÊàëÂÄëÁöÑÂàÜÊûêÂ∞á‰øÉÈÄ≤Â∞çÊåá‰ª§Ë™øÊï¥ÊúüÈñìÈõ∂Ê¨°Â≠∏ÁøíÊ≥õÂåñÁöÑÁêÜËß£Ôºå‰∏¶ÊúâÂä©ÊñºÈñãÁôºÊõ¥Â§öÂ∞çÈΩäÁöÑ LLM„ÄÇÊàëÂÄëÁöÑ‰ª£Á¢ºÁôºÂ∏ÉÂú® https://github.com/HBX-hbx/dynamics_of_zero-shot_generalization„ÄÇ

##### **Refusal in Language Models Is Mediated by a Single Direction**
2406.11717v1 by Andy Arditi, Oscar Obeso, Aaquib Syed, Daniel Paleka, Nina Rimsky, Wes Gurnee, Neel Nanda

Conversational large language models are fine-tuned for both
instruction-following and safety, resulting in models that obey benign requests
but refuse harmful ones. While this refusal behavior is widespread across chat
models, its underlying mechanisms remain poorly understood. In this work, we
show that refusal is mediated by a one-dimensional subspace, across 13 popular
open-source chat models up to 72B parameters in size. Specifically, for each
model, we find a single direction such that erasing this direction from the
model's residual stream activations prevents it from refusing harmful
instructions, while adding this direction elicits refusal on even harmless
instructions. Leveraging this insight, we propose a novel white-box jailbreak
method that surgically disables refusal with minimal effect on other
capabilities. Finally, we mechanistically analyze how adversarial suffixes
suppress propagation of the refusal-mediating direction. Our findings
underscore the brittleness of current safety fine-tuning methods. More broadly,
our work showcases how an understanding of model internals can be leveraged to
develop practical methods for controlling model behavior.

ÊëòË¶ÅÔºöÂ∞çË©±ÂºèÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁ∂ìÈÅéÂæÆË™øÔºåÂêåÊôÇÂÖ∑ÂÇôÈÅµÂæ™ÊåáÁ§∫ÂíåÂÆâÂÖ®ÊÄßÔºåÂõ†Ê≠§Áî¢ÁîüÁöÑÊ®°ÂûãÊúÉÈÅµÂÆàËâØÊÄßË¶ÅÊ±ÇÔºå‰ΩÜÊãíÁµïÊúâÂÆ≥Ë¶ÅÊ±Ç„ÄÇÈõñÁÑ∂ÈÄôÁ®ÆÊãíÁµïË°åÁÇ∫Âú®ËÅäÂ§©Ê®°Âûã‰∏≠ÂæàÊôÆÈÅçÔºå‰ΩÜÂÖ∂Â∫ïÂ±§Ê©üÂà∂‰ªçÈÆÆÁÇ∫‰∫∫Áü•„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫ÊãíÁµïÊòØÁî±‰∏ÄÁ∂≠Â≠êÁ©∫ÈñìË™øËß£ÁöÑÔºåË∑®Ë∂ä 13 ÂÄãÊµÅË°åÁöÑÈñãÊ∫êËÅäÂ§©Ê®°ÂûãÔºåÂèÉÊï∏Ë¶èÊ®°È´òÈÅî 72B„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÂ∞çÊñºÊØèÂÄãÊ®°ÂûãÔºåÊàëÂÄëÊâæÂà∞‰∏ÄÂÄãÂñÆ‰∏ÄÊñπÂêëÔºåÂæûÊ®°ÂûãÁöÑÊÆòÂ∑ÆÊµÅÊøÄÊ¥ª‰∏≠Êì¶Èô§Ê≠§ÊñπÂêëÂèØÈò≤Ê≠¢ÂÆÉÊãíÁµïÊúâÂÆ≥Êåá‰ª§ÔºåËÄåÊ∑ªÂä†Ê≠§ÊñπÂêëÊúÉÂºïÁôºÊãíÁµïÔºåÂç≥‰ΩøÊòØÁÑ°ÂÆ≥Êåá‰ª§„ÄÇÂà©Áî®Ê≠§Ë¶ãËß£ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÁôΩÁõíË∂äÁçÑÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÈÄöÈÅéÊâãË°ìÁ¶ÅÁî®ÊãíÁµïÔºåÂ∞çÂÖ∂‰ªñÂäüËÉΩÁöÑÂΩ±ÈüøÊúÄÂ∞è„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊ©üÊ¢∞Âú∞ÂàÜÊûê‰∫ÜÂ∞çÊäóÊÄßÂæåÁ∂¥Â¶Ç‰ΩïÊäëÂà∂ÊãíÁµïË™øËß£ÊñπÂêëÁöÑÂÇ≥Êí≠„ÄÇÊàëÂÄëÁöÑÁôºÁèæÂº∑Ë™ø‰∫ÜÁï∂ÂâçÂÆâÂÖ®ÂæÆË™øÊñπÊ≥ïÁöÑËÑÜÂº±ÊÄß„ÄÇÊõ¥Âª£Ê≥õÂú∞Ë™™ÔºåÊàëÂÄëÁöÑÁ†îÁ©∂Â±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÂà©Áî®Â∞çÊ®°ÂûãÂÖßÈÉ®ÁöÑÁêÜËß£‰æÜÈñãÁôºÊéßÂà∂Ê®°ÂûãË°åÁÇ∫ÁöÑÂØ¶Áî®ÊñπÊ≥ï„ÄÇ

##### **Measuring memorization in RLHF for code completion**
2406.11715v1 by Aneesh Pappu, Billy Porter, Ilia Shumailov, Jamie Hayes

Reinforcement learning with human feedback (RLHF) has become the dominant
method to align large models to user preferences. Unlike fine-tuning, for which
there are many studies regarding training data memorization, it is not clear
how memorization is affected by or introduced in the RLHF alignment process.
Understanding this relationship is important as real user data may be collected
and used to align large models; if user data is memorized during RLHF and later
regurgitated, this could raise privacy concerns. In this work, we analyze how
training data memorization can surface and propagate through each phase of
RLHF. We focus our study on code completion models, as code completion is one
of the most popular use cases for large language models. We find that RLHF
significantly decreases the chance that data used for reward modeling and
reinforcement learning is memorized, in comparison to aligning via directly
fine-tuning on this data, but that examples already memorized during the
fine-tuning stage of RLHF, will, in the majority of cases, remain memorized
after RLHF.

ÊëòË¶ÅÔºö‰∫∫È°ûÂõûÈ•ãÂ¢ûÂº∑Â≠∏ÁøíÔºàRLHFÔºâÂ∑≤ÊàêÁÇ∫Ë™øÊï¥Â§ßÂûãÊ®°Âûã‰ª•Á¨¶Âêà‰ΩøÁî®ËÄÖÂÅèÂ•ΩÁöÑ‰∏ªË¶ÅÊñπÊ≥ï„ÄÇËàáÂæÆË™ø‰∏çÂêåÔºåÂ∞çÊñºÂæÆË™øÊúâË®±Â§öÈóúÊñºË®ìÁ∑¥Ë≥áÊñôË®òÊÜ∂ÁöÑÁ†îÁ©∂Ôºå‰ΩÜÂ∞ö‰∏çÊ∏ÖÊ•öË®òÊÜ∂ÊòØÂ¶Ç‰ΩïÂèóÂà∞ RLHF Ë™øÊï¥Á®ãÂ∫èÂΩ±ÈüøÊàñÂºïÂÖ•ÁöÑ„ÄÇ‰∫ÜËß£ÈÄôÁ®ÆÈóú‰øÇÂæàÈáçË¶ÅÔºåÂõ†ÁÇ∫ÂèØËÉΩÊúÉÊî∂ÈõÜÁúüÂØ¶‰ΩøÁî®ËÄÖË≥áÊñô‰∏¶Áî®ÊñºË™øÊï¥Â§ßÂûãÊ®°ÂûãÔºõÂ¶ÇÊûú‰ΩøÁî®ËÄÖË≥áÊñôÂú® RLHF ÊúüÈñìË¢´Ë®òÊÜ∂‰∏ã‰æÜ‰∏¶Á®çÂæåÂÜçÈáçË§áÔºåÈÄôÂèØËÉΩÊúÉÂºïÁôºÈö±ÁßÅÂïèÈ°å„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂàÜÊûêË®ìÁ∑¥Ë≥áÊñôË®òÊÜ∂Â¶Ç‰ΩïÂú® RLHF ÁöÑÊØèÂÄãÈöéÊÆµÊµÆÁèæ‰∏¶ÂÇ≥Êí≠„ÄÇÊàëÂÄëÂ∞áÁ†îÁ©∂ÈáçÈªûÊîæÂú®Á®ãÂºèÁ¢ºÂÆåÊàêÊ®°Âûã‰∏äÔºåÂõ†ÁÇ∫Á®ãÂºèÁ¢ºÂÆåÊàêÊòØÂ§ßË™ûË®ÄÊ®°ÂûãÊúÄÂèóÊ≠°ËøéÁöÑÁî®‰æã‰πã‰∏Ä„ÄÇÊàëÂÄëÁôºÁèæÔºåËàáÁõ¥Êé•Â∞çÊ≠§Ë≥áÊñôÈÄ≤Ë°åÂæÆË™øÁöÑË™øÊï¥ÊñπÂºèÁõ∏ÊØîÔºåRLHF ÊúÉÈ°ØËëóÈôç‰ΩéÁî®ÊñºÁçéÂãµÂª∫Ê®°ÂíåÂ¢ûÂº∑Â≠∏ÁøíÁöÑË≥áÊñôË¢´Ë®òÊÜ∂ÁöÑÊ©üÁéáÔºå‰ΩÜ RLHF ÂæÆË™øÈöéÊÆµ‰∏≠Â∑≤Ë®òÊÜ∂ÁöÑÁØÑ‰æãÂú®Â§ßÈÉ®ÂàÜÊÉÖÊ≥Å‰∏ãÔºåRLHF ‰πãÂæå‰ªçÊúÉ‰øùÊåÅË®òÊÜ∂„ÄÇ

##### **Instruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical Questioning for Socratic Code Debugging**
2406.11709v1 by Priyanka Kargupta, Ishika Agarwal, Dilek Hakkani-Tur, Jiawei Han

Socratic questioning is an effective teaching strategy, encouraging critical
thinking and problem-solving. The conversational capabilities of large language
models (LLMs) show great potential for providing scalable, real-time student
guidance. However, current LLMs often give away solutions directly, making them
ineffective instructors. We tackle this issue in the code debugging domain with
TreeInstruct, an Instructor agent guided by a novel state space-based planning
algorithm. TreeInstruct asks probing questions to help students independently
identify and resolve errors. It estimates a student's conceptual and
syntactical knowledge to dynamically construct a question tree based on their
responses and current knowledge state, effectively addressing both independent
and dependent mistakes concurrently in a multi-turn interaction setting. In
addition to using an existing single-bug debugging benchmark, we construct a
more challenging multi-bug dataset of 150 coding problems, incorrect solutions,
and bug fixes -- all carefully constructed and annotated by experts. Extensive
evaluation shows TreeInstruct's state-of-the-art performance on both datasets,
proving it to be a more effective instructor than baselines. Furthermore, a
real-world case study with five students of varying skill levels further
demonstrates TreeInstruct's ability to guide students to debug their code
efficiently with minimal turns and highly Socratic questioning.

ÊëòË¶ÅÔºöËòáÊ†ºÊãâÂ∫ïÂºèÊèêÂïèÊòØ‰∏ÄÁ®ÆÊúâÊïàÁöÑÊïôÂ≠∏Á≠ñÁï•ÔºåÈºìÂãµÊâπÂà§ÊÄßÊÄùËÄÉÂíåÂïèÈ°åËß£Ê±∫„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂ∞çË©±ËÉΩÂäõÈ°ØÁ§∫Âá∫Êèê‰æõÂèØÊì¥ÂÖÖ„ÄÅÂç≥ÊôÇÁöÑÂ≠∏ÁîüÊåáÂ∞éÁöÑÂ∑®Â§ßÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑ LLM Á∂ìÂ∏∏Áõ¥Êé•Êèê‰æõËß£Ê±∫ÊñπÊ°àÔºåÈÄô‰ΩøÂæóÂÆÉÂÄëÊàêÁÇ∫ÁÑ°ÊïàÁöÑÊåáÂ∞éËÄÖ„ÄÇÊàëÂÄëÂú®Á®ãÂºèÁ¢ºÂÅµÈåØÈ†òÂüü‰∏≠‰ΩøÁî® TreeInstruct ‰æÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåTreeInstruct ÊòØ‰∏ÄÂÄãÊåáÂ∞é‰ª£ÁêÜÔºåÁî±‰∏ÄÂÄãÊñ∞Á©éÁöÑÂü∫ÊñºÁãÄÊÖãÁ©∫ÈñìÁöÑË¶èÂäÉÊºîÁÆóÊ≥ïÊâÄÂºïÂ∞é„ÄÇTreeInstruct ÊúÉÊèêÂá∫Êé¢Ê∏¨ÊÄßÂïèÈ°åÔºå‰ª•Âπ´Âä©Â≠∏ÁîüÁç®Á´ãË≠òÂà•ÂíåËß£Ê±∫ÈåØË™§„ÄÇÂÆÉÊúÉ‰º∞Ë®àÂ≠∏ÁîüÁöÑÊ¶ÇÂøµÊÄßÂíåÂè•Ê≥ïÁü•Ë≠òÔºå‰ª•Ê†πÊìö‰ªñÂÄëÁöÑÂõûÊáâÂíåÁï∂ÂâçÁöÑÁü•Ë≠òÁãÄÊÖãÂãïÊÖãÊßãÂª∫‰∏ÄÂÄãÂïèÈ°åÊ®πÔºåÊúâÊïàÂú∞ÂêåÊôÇÂú®Â§öËº™‰∫íÂãïË®≠ÂÆö‰∏≠Ëß£Ê±∫Áç®Á´ãÂíå‰æùË≥¥ÁöÑÈåØË™§„ÄÇÈô§‰∫Ü‰ΩøÁî®ÁèæÊúâÁöÑÂñÆ‰∏ÄÈåØË™§ÂÅµÈåØÂü∫Ê∫ñ‰πãÂ§ñÔºåÊàëÂÄëÈÇÑÊßãÂª∫‰∫Ü‰∏ÄÂÄãÊõ¥ÂÖ∑ÊåëÊà∞ÊÄßÁöÑ 150 ÂÄãÁ∑®Á¢ºÂïèÈ°å„ÄÅ‰∏çÊ≠£Á¢∫ÁöÑËß£Ê±∫ÊñπÊ°àÂíåÈåØË™§‰øÆÊ≠£ÁöÑÂ§öÈåØË™§Ë≥áÊñôÈõÜÔºåÈÄô‰∫õË≥áÊñôÈõÜÈÉΩÊòØÁî±Â∞àÂÆ∂‰ªîÁ¥∞ÊßãÂª∫ÂíåË®ªËß£ÁöÑ„ÄÇÂª£Ê≥õÁöÑË©ï‰º∞È°ØÁ§∫ TreeInstruct Âú®ÂÖ©ÂÄãË≥áÊñôÈõÜ‰∏äÁöÑÊïàËÉΩÈÉΩÈÅîÂà∞ÊúÄÂÖàÈÄ≤ÁöÑÊ∞¥Âπ≥ÔºåË≠âÊòéÂÆÉÊØîÂü∫Ê∫ñÊõ¥ÊúâÊïàÁöÑÊåáÂ∞éËÄÖ„ÄÇÊ≠§Â§ñÔºå‰∏ÄÂÄãÂåÖÂê´‰∫îÂêç‰∏çÂêåÊäÄËÉΩÁ≠âÁ¥öÂ≠∏ÁîüÁöÑÁúüÂØ¶Ê°à‰æãÁ†îÁ©∂ÈÄ≤‰∏ÄÊ≠•Ë≠âÊòé‰∫Ü TreeInstruct ËÉΩÂ§†ÊåáÂ∞éÂ≠∏Áîü‰ª•ÊúÄÂ∞ëÁöÑËº™Ê¨°ÂíåÈ´òÂ∫¶ËòáÊ†ºÊãâÂ∫ïÂºèÁöÑÊèêÂïèÊúâÊïàÂú∞ÂÅµÈåØ‰ªñÂÄëÁöÑÁ®ãÂºèÁ¢º„ÄÇ

##### **Prompts as Auto-Optimized Training Hyperparameters: Training Best-in-Class IR Models from Scratch with 10 Gold Labels**
2406.11706v1 by Jasper Xian, Saron Samuel, Faraz Khoubsirat, Ronak Pradeep, Md Arafat Sultan, Radu Florian, Salim Roukos, Avirup Sil, Christopher Potts, Omar Khattab

We develop a method for training small-scale (under 100M parameter) neural
information retrieval models with as few as 10 gold relevance labels. The
method depends on generating synthetic queries for documents using a language
model (LM), and the key step is that we automatically optimize the LM prompt
that is used to generate these queries based on training quality. In
experiments with the BIRCO benchmark, we find that models trained with our
method outperform RankZephyr and are competitive with RankLLama, both of which
are 7B parameter models trained on over 100K labels. These findings point to
the power of automatic prompt optimization for synthetic dataset generation.

ÊëòË¶ÅÔºöÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåÂèØ‰ª•Áî®Â∞ëËá≥ 10 ÂÄãÈªÉÈáëÁõ∏ÈóúÊ®ôÁ±§‰æÜË®ìÁ∑¥Â∞èË¶èÊ®°ÔºàÂ∞èÊñº 100M ÂèÉÊï∏ÔºâÁ•ûÁ∂ìË≥áË®äÊ™¢Á¥¢Ê®°Âûã„ÄÇ
Ë©≤ÊñπÊ≥ï‰æùË≥¥Êñº‰ΩøÁî®Ë™ûË®ÄÊ®°Âûã (LM) ÁÇ∫Êñá‰ª∂ÁîüÊàêÂêàÊàêÊü•Ë©¢ÔºåÈóúÈçµÊ≠•È©üÊòØÊàëÂÄëÊ†πÊìöË®ìÁ∑¥ÂìÅË≥™Ëá™ÂãïÊúÄ‰Ω≥ÂåñÁî®ÊñºÁîüÊàêÈÄô‰∫õÊü•Ë©¢ÁöÑ LM ÊèêÁ§∫„ÄÇ
Âú®‰ΩøÁî® BIRCO Âü∫Ê∫ñÈÄ≤Ë°åÁöÑÂØ¶È©ó‰∏≠ÔºåÊàëÂÄëÁôºÁèæ‰ΩøÁî®ÊàëÂÄëÁöÑÊñπÊ≥ïË®ìÁ∑¥ÁöÑÊ®°ÂûãÂÑ™Êñº RankZephyrÔºå‰∏¶‰∏îËàá RankLLama Á´∂Áà≠ÔºåËÄå RankZephyr Âíå RankLLama ÈÉΩÊòØÂü∫ÊñºË∂ÖÈÅé 100K ÂÄãÊ®ôÁ±§Ë®ìÁ∑¥ÁöÑ 7B ÂèÉÊï∏Ê®°Âûã„ÄÇ
ÈÄô‰∫õÁôºÁèæÊåáÂá∫‰∫ÜËá™ÂãïÊèêÁ§∫ÊúÄ‰Ω≥ÂåñÂ∞çÊñºÂêàÊàêË≥áÊñôÈõÜÁîüÊàêÁöÑÂäõÈáè„ÄÇ

##### **Nemotron-4 340B Technical Report**
2406.11704v1 by Nvidia, :, Bo Adler, Niket Agarwal, Ashwath Aithal, Dong H. Anh, Pallab Bhattacharya, Annika Brundyn, Jared Casper, Bryan Catanzaro, Sharon Clay, Jonathan Cohen, Sirshak Das, Ayush Dattagupta, Olivier Delalleau, Leon Derczynski, Yi Dong, Daniel Egert, Ellie Evans, Aleksander Ficek, Denys Fridman, Shaona Ghosh, Boris Ginsburg, Igor Gitman, Tomasz Grzegorzek, Robert Hero, Jining Huang, Vibhu Jawa, Joseph Jennings, Aastha Jhunjhunwala, John Kamalu, Sadaf Khan, Oleksii Kuchaiev, Patrick LeGresley, Hui Li, Jiwei Liu, Zihan Liu, Eileen Long, Ameya Sunil Mahabaleshwarkar, Somshubra Majumdar, James Maki, Miguel Martinez, Maer Rodrigues de Melo, Ivan Moshkov, Deepak Narayanan, Sean Narenthiran, Jesus Navarro, Phong Nguyen, Osvald Nitski, Vahid Noroozi, Guruprasad Nutheti, Christopher Parisien, Jupinder Parmar, Mostofa Patwary, Krzysztof Pawelec, Wei Ping, Shrimai Prabhumoye, Rajarshi Roy, Trisha Saar, Vasanth Rao Naik Sabavat, Sanjeev Satheesh, Jane Polak Scowcroft, Jason Sewall, Pavel Shamis, Gerald Shen, Mohammad Shoeybi, Dave Sizer, Misha Smelyanskiy, Felipe Soares, Makesh Narsimhan Sreedhar, Dan Su, Sandeep Subramanian, Shengyang Sun, Shubham Toshniwal, Hao Wang, Zhilin Wang, Jiaxuan You, Jiaqi Zeng, Jimmy Zhang, Jing Zhang, Vivienne Zhang, Yian Zhang, Chen Zhu

We release the Nemotron-4 340B model family, including Nemotron-4-340B-Base,
Nemotron-4-340B-Instruct, and Nemotron-4-340B-Reward. Our models are open
access under the NVIDIA Open Model License Agreement, a permissive model
license that allows distribution, modification, and use of the models and its
outputs. These models perform competitively to open access models on a wide
range of evaluation benchmarks, and were sized to fit on a single DGX H100 with
8 GPUs when deployed in FP8 precision. We believe that the community can
benefit from these models in various research studies and commercial
applications, especially for generating synthetic data to train smaller
language models. Notably, over 98% of data used in our model alignment process
is synthetically generated, showcasing the effectiveness of these models in
generating synthetic data. To further support open research and facilitate
model development, we are also open-sourcing the synthetic data generation
pipeline used in our model alignment process.

ÊëòË¶ÅÔºöÊàëÂÄëÁôºÂ∏É Nemotron-4 340B Ê®°ÂûãÁ≥ªÂàóÔºåÂåÖÊã¨ Nemotron-4-340B-Base„ÄÅ
Nemotron-4-340B-Instruct Âíå Nemotron-4-340B-Reward„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú® NVIDIA ÈñãÊîæÊ®°ÂûãÊéàÊ¨äÂçîË≠∞‰∏ãÈñãÊîæÂèñÁî®ÔºåÈÄôÊòØ‰∏ÄÂÄãÂØ¨È¨ÜÁöÑÊ®°ÂûãÊéàÊ¨äÔºåÂÖÅË®±ÂàÜÁôº„ÄÅ‰øÆÊîπÂíå‰ΩøÁî®Ê®°ÂûãÂèäÂÖ∂Ëº∏Âá∫„ÄÇÈÄô‰∫õÊ®°ÂûãÂú®Âª£Ê≥õÁöÑË©ï‰º∞Âü∫Ê∫ñ‰∏äÂü∑Ë°åËàáÈñãÊîæÂèñÁî®Ê®°ÂûãÁ´∂Áà≠Ôºå‰∏¶‰∏îÂú®ÈÉ®ÁΩ≤ FP8 Á≤æÂ∫¶ÊôÇÂ§ßÂ∞èÈÅ©ÂêàÂñÆÂÄãÈÖçÂÇô 8 ÂÄã GPU ÁöÑ DGX H100„ÄÇÊàëÂÄëÁõ∏‰ø°Á§æÁæ§ÂèØ‰ª•Âú®ÂêÑÁ®ÆÁ†îÁ©∂ÂíåÂïÜÊ•≠ÊáâÁî®‰∏≠ÂèóÁõäÊñºÈÄô‰∫õÊ®°ÂûãÔºåÁâπÂà•ÊòØÁÇ∫‰∫ÜÁî¢ÁîüÁî®ÊñºË®ìÁ∑¥ËºÉÂ∞èË™ûË®ÄÊ®°ÂûãÁöÑÂêàÊàêË≥áÊñô„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊàëÂÄëÊ®°ÂûãÊØîÂ∞çÈÅéÁ®ã‰∏≠‰ΩøÁî®ÁöÑË≥áÊñôÊúâË∂ÖÈÅé 98% ÊòØÂêàÊàêÁî¢ÁîüÁöÑÔºåÂ±ïÁ§∫‰∫ÜÈÄô‰∫õÊ®°ÂûãÂú®Áî¢ÁîüÂêàÊàêË≥áÊñôÊñπÈù¢ÁöÑÊïàËÉΩ„ÄÇÁÇ∫‰∫ÜÈÄ≤‰∏ÄÊ≠•ÊîØÊè¥ÈñãÊîæÁ†îÁ©∂Âíå‰øÉÈÄ≤Ê®°ÂûãÈñãÁôºÔºåÊàëÂÄë‰πüÈñãÊîæÂéüÂßãÁ¢ºÔºåÂú®ÊàëÂÄëÁöÑÊ®°ÂûãÊØîÂ∞çÈÅéÁ®ã‰∏≠‰ΩøÁî®ÂêàÊàêË≥áÊñôÁî¢ÁîüÁÆ°ÈÅì„ÄÇ

##### **Meta Reasoning for Large Language Models**
2406.11698v1 by Peizhong Gao, Ao Xie, Shaoguang Mao, Wenshan Wu, Yan Xia, Haipeng Mi, Furu Wei

We introduce Meta-Reasoning Prompting (MRP), a novel and efficient system
prompting method for large language models (LLMs) inspired by human
meta-reasoning. Traditional in-context learning-based reasoning techniques,
such as Tree-of-Thoughts, show promise but lack consistent state-of-the-art
performance across diverse tasks due to their specialized nature. MRP addresses
this limitation by guiding LLMs to dynamically select and apply different
reasoning methods based on the specific requirements of each task, optimizing
both performance and computational efficiency. With MRP, LLM reasoning operates
in two phases. Initially, the LLM identifies the most appropriate reasoning
method using task input cues and objective descriptions of available methods.
Subsequently, it applies the chosen method to complete the task. This dynamic
strategy mirrors human meta-reasoning, allowing the model to excel in a wide
range of problem domains. We evaluate the effectiveness of MRP through
comprehensive benchmarks. The results demonstrate that MRP achieves or
approaches state-of-the-art performance across diverse tasks. MRP represents a
significant advancement in enabling LLMs to identify cognitive challenges
across problems and leverage benefits across different reasoning approaches,
enhancing their ability to handle diverse and complex problem domains
efficiently. Every LLM deserves a Meta-Reasoning Prompting to unlock its full
potential and ensure adaptability in an ever-evolving landscape of challenges
and applications.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÂºïÂÖ•‰∫ÜÂÖÉÊé®ÁêÜÊèêÁ§∫ÔºàMRPÔºâÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©é‰∏îÊúâÊïàÁéáÁöÑÁ≥ªÁµ±ÊèêÁ§∫ÊñπÊ≥ïÔºåÈÅ©Áî®ÊñºÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÔºåÂÖ∂ÈùàÊÑü‰æÜËá™‰∫∫È°ûÁöÑÂÖÉÊé®ÁêÜ„ÄÇÂÇ≥Áµ±ÁöÑÂü∫ÊñºÊÉÖÂ¢ÉÂ≠∏ÁøíÁöÑÊé®ÁêÜÊäÄË°ìÔºå‰æãÂ¶ÇÊÄùÊÉ≥Ê®πÔºåÈ°ØÁ§∫Âá∫‰∏ÄÂÆöÁöÑÊΩõÂäõÔºå‰ΩÜÁî±ÊñºÂÖ∂Â∞àÊ•≠ÊÄßË≥™ÔºåÂú®‰∏çÂêåÁöÑ‰ªªÂãô‰∏≠Áº∫‰πè‰∏ÄËá¥ÁöÑÊúÄÊñ∞ÊäÄË°ìÊïàËÉΩ„ÄÇMRP ÈÄèÈÅéÂºïÂ∞é LLM Ê†πÊìöÊØèÂÄã‰ªªÂãôÁöÑÁâπÂÆöÈúÄÊ±ÇÂãïÊÖãÈÅ∏Êìá‰∏¶ÊáâÁî®‰∏çÂêåÁöÑÊé®ÁêÜÊñπÊ≥ï‰æÜËß£Ê±∫ÈÄôÂÄãÈôêÂà∂ÔºåÂêåÊôÇÊúÄ‰Ω≥ÂåñÊïàËÉΩÂíåÈÅãÁÆóÊïàÁéá„ÄÇÈÄèÈÅé MRPÔºåLLM Êé®ÁêÜÂàÜÁÇ∫ÂÖ©ÂÄãÈöéÊÆµ„ÄÇÊúÄÂàùÔºåLLM ‰ΩøÁî®‰ªªÂãôËº∏ÂÖ•ÊèêÁ§∫ÂíåÂèØÁî®ÊñπÊ≥ïÁöÑÂÆ¢ËßÄÊèèËø∞‰æÜË≠òÂà•ÊúÄÂêàÈÅ©ÁöÑÊé®ÁêÜÊñπÊ≥ï„ÄÇÈö®ÂæåÔºåÂÆÉÊáâÁî®ÊâÄÈÅ∏ÊñπÊ≥ï‰æÜÂÆåÊàê‰ªªÂãô„ÄÇÈÄôÁ®ÆÂãïÊÖãÁ≠ñÁï•ÂèçÊò†‰∫Ü‰∫∫È°ûÁöÑÂÖÉÊé®ÁêÜÔºåËÆìÊ®°ÂûãËÉΩÂ§†Âú®Âª£Ê≥õÁöÑÂïèÈ°åÈ†òÂüü‰∏≠Ë°®ÁèæÂá∫Ëâ≤„ÄÇÊàëÂÄëÈÄèÈÅéÂÖ®Èù¢ÁöÑÂü∫Ê∫ñÊ∏¨Ë©¶‰æÜË©ï‰º∞ MRP ÁöÑÊúâÊïàÊÄß„ÄÇÁµêÊûúË°®ÊòéÔºåMRP Âú®‰∏çÂêåÁöÑ‰ªªÂãô‰∏≠ÈÅîÂà∞ÊàñÊé•ËøëÊúÄÊñ∞ÊäÄË°ìÊïàËÉΩ„ÄÇMRP ‰ª£Ë°®‰∫ÜËÆì LLM ËÉΩÂ§†Ë≠òÂà•‰∏çÂêåÂïèÈ°åÁöÑË™çÁü•ÊåëÊà∞Ôºå‰∏¶Âà©Áî®‰∏çÂêåÊé®ÁêÜÊñπÊ≥ïÁöÑÂÑ™ÈªûÁöÑÈáçÂ§ßÈÄ≤Â±ïÔºåÈÄ≤ËÄåÂ¢ûÂº∑ÂÆÉÂÄëÊúâÊïàËôïÁêÜ‰∏çÂêå‰∏îË§áÈõúÂïèÈ°åÈ†òÂüüÁöÑËÉΩÂäõ„ÄÇÊØèÂÄã LLM ÈÉΩÊáâÂÖ∑ÂÇôÂÖÉÊé®ÁêÜÊèêÁ§∫Ôºå‰ª•ÁôºÊèÆÂÖ∂ÂÖ®ÈÉ®ÊΩõÂäõÔºå‰∏¶Á¢∫‰øùÂú®‰∏çÊñ∑ËÆäÂåñÁöÑÊåëÊà∞ÂíåÊáâÁî®Áí∞Â¢É‰∏≠ÈÅ©Êáâ„ÄÇ

##### **Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs**
2406.11695v1 by Krista Opsahl-Ong, Michael J Ryan, Josh Purtell, David Broman, Christopher Potts, Matei Zaharia, Omar Khattab

Language Model Programs, i.e. sophisticated pipelines of modular language
model (LM) calls, are increasingly advancing NLP tasks, but they require
crafting prompts that are jointly effective for all modules. We study prompt
optimization for LM programs, i.e. how to update these prompts to maximize a
downstream metric without access to module-level labels or gradients. To make
this tractable, we factorize our problem into optimizing the free-form
instructions and few-shot demonstrations of every module and introduce several
strategies to craft task-grounded instructions and navigate credit assignment
across modules. Our strategies include (i) program- and data-aware techniques
for proposing effective instructions, (ii) a stochastic mini-batch evaluation
function for learning a surrogate model of our objective, and (iii) a
meta-optimization procedure in which we refine how LMs construct proposals over
time. Using these insights we develop MIPRO, a novel optimizer that outperforms
baselines on five of six diverse LM programs using a best-in-class open-source
model (Llama-3-8B), by as high as 12.9% accuracy. We will release our new
optimizers and benchmark in DSPy at https://github.com/stanfordnlp/dspy

ÊëòË¶ÅÔºöË™ûË®ÄÊ®°ÂûãÁ®ãÂºèÔºåÂç≥Ê®°ÁµÑÂåñË™ûË®ÄÊ®°Âûã (LM) ÂëºÂè´ÁöÑË§áÈõúÁÆ°Á∑öÔºåÊ≠£Êó•ÁõäÊèêÂçá NLP ‰ªªÂãôÔºå‰ΩÜÂÆÉÂÄëÈúÄË¶ÅË£Ω‰ΩúÂ∞çÊâÄÊúâÊ®°ÁµÑÈÉΩÂÖ±ÂêåÊúâÊïàÁöÑÊèêÁ§∫„ÄÇÊàëÂÄëÁ†îÁ©∂ LM Á®ãÂºèÁöÑÊèêÁ§∫ÊúÄ‰Ω≥ÂåñÔºåÂç≥Â¶Ç‰ΩïÂú®Ê≤íÊúâÊ®°ÁµÑÂ±§Á¥öÊ®ôÁ±§ÊàñÊ¢ØÂ∫¶ÁöÑÁãÄÊ≥Å‰∏ãÊõ¥Êñ∞ÈÄô‰∫õÊèêÁ§∫Ôºå‰ª•ÊúÄÂ§ßÂåñ‰∏ãÊ∏∏ÊåáÊ®ô„ÄÇÁÇ∫‰∫Ü‰ΩøÈÄôÂÄãÂïèÈ°åÂèØËôïÁêÜÔºåÊàëÂÄëÂ∞áÂïèÈ°åÂàÜËß£ÁÇ∫ÊúÄ‰Ω≥ÂåñÊØè‰∏ÄÂÄãÊ®°ÁµÑÁöÑËá™Áî±ÂΩ¢ÂºèË™™ÊòéÂíåÂ∞ëÈáèÁ§∫ÁØÑÔºå‰∏¶ÂºïÂÖ•Â§öÁ®ÆÁ≠ñÁï•‰æÜË£Ω‰Ωú‰ª•‰ªªÂãôÁÇ∫Âü∫Á§éÁöÑË™™ÊòéÔºå‰∏¶Âú®Ê®°ÁµÑÈñìÂ∞éËà™‰ø°Áî®ÂàÜÈÖç„ÄÇÊàëÂÄëÁöÑÁ≠ñÁï•ÂåÖÊã¨Ôºö(i) ÊèêÂá∫ÊúâÊïàË™™ÊòéÁöÑÁ®ãÂºèÂíåË≥áÊñôÊÑüÁü•ÊäÄË°ìÔºå(ii) Â≠∏ÁøíÁõÆÊ®ôÊõø‰ª£Ê®°ÂûãÁöÑÈö®Ê©üÂ∞èÊâπÊ¨°Ë©ï‰º∞ÂáΩÊï∏Ôºå‰ª•Âèä (iii) ÊàëÂÄëÂú®ÂÖ∂‰∏≠Á≤æÈÄ≤ LM Èö®ËëóÊôÇÈñìÊé®ÁßªÂª∫ÊßãÊèêÊ°àÊñπÂºèÁöÑÂÖÉÊúÄ‰Ω≥ÂåñÁ®ãÂ∫è„ÄÇÂà©Áî®ÈÄô‰∫õË¶ãËß£ÔºåÊàëÂÄëÈñãÁôº‰∫Ü MIPROÔºå‰∏ÄÁ®ÆÊñ∞ÁöÑÊúÄ‰Ω≥ÂåñÂô®ÔºåÂÆÉÂú®‰ΩøÁî®ÊúÄ‰Ω≥ÈñãÊîæÂéüÂßãÁ¢ºÊ®°Âûã (Llama-3-8B) ÁöÑÂÖ≠ÂÄã‰∏çÂêåÁöÑ LM Á®ãÂºè‰∏≠ÁöÑ‰∫îÂÄãÁ®ãÂºè‰∏≠ÂÑ™ÊñºÂü∫Ê∫ñÔºåÊ∫ñÁ¢∫Â∫¶ÊèêÈ´ò‰∫Ü 12.9%„ÄÇÊàëÂÄëÂ∞áÂú® https://github.com/stanfordnlp/dspy ‰∏äÁôºÂ∏ÉÊàëÂÄëÁöÑÊñ∞ÁöÑÊúÄ‰Ω≥ÂåñÂô®Âíå DSPy Âü∫Ê∫ñ

##### **Tokenization Falling Short: The Curse of Tokenization**
2406.11687v1 by Yekun Chai, Yewei Fang, Qiwei Peng, Xuhong Li

Language models typically tokenize raw text into sequences of subword
identifiers from a predefined vocabulary, a process inherently sensitive to
typographical errors, length variations, and largely oblivious to the internal
structure of tokens-issues we term the curse of tokenization. In this study, we
delve into these drawbacks and demonstrate that large language models (LLMs)
remain susceptible to these problems. This study systematically investigates
these challenges and their impact on LLMs through three critical research
questions: (1) complex problem solving, (2) token structure probing, and (3)
resilience to typographical variation. Our findings reveal that scaling model
parameters can mitigate the issue of tokenization; however, LLMs still suffer
from biases induced by typos and other text format variations. Our experiments
show that subword regularization such as BPE-dropout can mitigate this issue.
We will release our code and data to facilitate further research.

ÊëòË¶ÅÔºöË™ûË®ÄÊ®°ÂûãÈÄöÂ∏∏Â∞áÂéüÂßãÊñáÂ≠óÂàÜË©ûÊàêÈ†êÂÖàÂÆöÁæ©Ë©ûÂΩôË°®‰∏≠Â≠êÂ≠óË©ûÁöÑÂ∫èÂàóÔºåÈÄôÂÄãÈÅéÁ®ãÂ∞çÂç∞Âà∑ÈåØË™§„ÄÅÈï∑Â∫¶ËÆäÂåñÂæàÊïèÊÑüÔºåËÄå‰∏îÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂøΩÁï•‰∫ÜË©ûÂΩôÁöÑÂÖßÈÉ®ÁµêÊßãÔºåÊàëÂÄëÁ®±ÈÄôÂÄãÂïèÈ°åÁÇ∫ÂàÜË©ûÁöÑË©õÂíí„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊ∑±ÂÖ•Êé¢Ë®é‰∫ÜÈÄô‰∫õÁº∫ÈªûÔºå‰∏¶Ë≠âÊòéÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰ªçÁÑ∂ÂÆπÊòìÂèóÂà∞ÈÄô‰∫õÂïèÈ°åÁöÑÂΩ±Èüø„ÄÇÊú¨Á†îÁ©∂Á≥ªÁµ±ÊÄßÂú∞Êé¢Ë®é‰∫ÜÈÄô‰∫õÊåëÊà∞ÂèäÂÖ∂Â∞ç LLM ÁöÑÂΩ±ÈüøÔºåÈÄèÈÅé‰∏âÂÄãÈáçË¶ÅÁöÑÁ†îÁ©∂ÂïèÈ°åÔºö(1) Ë§áÈõúÂïèÈ°åËß£Ê±∫Ôºå(2) Ë©ûÂΩôÁµêÊßãÊé¢Ê∏¨Ôºå‰ª•Âèä (3) Â∞çÂç∞Âà∑ËÆäÁï∞ÁöÑÈüåÊÄß„ÄÇÊàëÂÄëÁöÑÁôºÁèæÈ°ØÁ§∫ÔºåË™øÊï¥Ê®°ÂûãÂèÉÊï∏ÂèØ‰ª•Ê∏õËºïÂàÜË©ûÁöÑÂïèÈ°åÔºõÁÑ∂ËÄåÔºåLLM ‰ªçÁÑ∂ÊúÉÂèóÂà∞Âç∞Âà∑ÈåØË™§ÂíåÂÖ∂‰ªñÊñáÂ≠óÊ†ºÂºèËÆäÁï∞ÊâÄÁî¢ÁîüÁöÑÂÅèÂ∑ÆÂΩ±Èüø„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåÂ≠êÂ≠óË©ûÊ≠£Ë¶èÂåñÔºà‰æãÂ¶Ç BPE-dropoutÔºâÂèØ‰ª•Ê∏õËºïÈÄôÂÄãÂïèÈ°å„ÄÇÊàëÂÄëÂ∞áÈáãÂá∫ÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÔºå‰ª•Âà©ÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂„ÄÇ

##### **HoLLMwood: Unleashing the Creativity of Large Language Models in Screenwriting via Role Playing**
2406.11683v1 by Jing Chen, Xinyu Zhu, Cheng Yang, Chufan Shi, Yadong Xi, Yuxiang Zhang, Junjie Wang, Jiashu Pu, Rongsheng Zhang, Yujiu Yang, Tian Feng

Generative AI has demonstrated unprecedented creativity in the field of
computer vision, yet such phenomena have not been observed in natural language
processing. In particular, large language models (LLMs) can hardly produce
written works at the level of human experts due to the extremely high
complexity of literature writing. In this paper, we present HoLLMwood, an
automated framework for unleashing the creativity of LLMs and exploring their
potential in screenwriting, which is a highly demanding task. Mimicking the
human creative process, we assign LLMs to different roles involved in the
real-world scenario. In addition to the common practice of treating LLMs as
${Writer}$, we also apply LLMs as ${Editor}$, who is responsible for providing
feedback and revision advice to ${Writer}$. Besides, to enrich the characters
and deepen the plots, we introduce a role-playing mechanism and adopt LLMs as
${Actors}$ that can communicate and interact with each other. Evaluations on
automatically generated screenplays show that HoLLMwood substantially
outperforms strong baselines in terms of coherence, relevance, interestingness
and overall quality.

ÊëòË¶ÅÔºöÁîüÊàêÂºè AI Â∑≤Âú®ÈõªËÖ¶Ë¶ñË¶∫È†òÂüüÂ±ïÁèæÂá∫ÂâçÊâÄÊú™ÊúâÁöÑÂâµÈÄ†ÂäõÔºå‰ΩÜËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰∏≠Â∞öÊú™ËßÄÂØüÂà∞ÈÄôÁ®ÆÁèæË±°„ÄÇÁâπÂà•ÊòØÔºåÁî±ÊñºÊñáÂ≠∏ÂØ´‰ΩúÊ•µÈ´òÁöÑË§áÈõúÊÄßÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Èõ£‰ª•Áî¢Áîü‰∫∫È°ûÂ∞àÂÆ∂Á≠âÁ¥öÁöÑÊõ∏Èù¢‰ΩúÂìÅ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ HoLLMwoodÔºå‰∏ÄÂÄãËá™ÂãïÂåñÊ°ÜÊû∂ÔºåÁî®ÊñºÈáãÊîæ LLM ÁöÑÂâµÈÄ†Âäõ‰∏¶Êé¢Á¥¢ÂÆÉÂÄëÂú®Á∑®Âäá‰∏≠ÁöÑÊΩõÂäõÔºåÈÄôÊòØ‰∏ÄÈ†ÖË¶ÅÊ±ÇÂæàÈ´òÁöÑ‰ªªÂãô„ÄÇÊ®°‰ªø‰∫∫È°ûÁöÑÂâµÈÄ†ÈÅéÁ®ãÔºåÊàëÂÄëÂ∞á LLM ÂàÜÈÖçÂà∞ÁèæÂØ¶‰∏ñÁïåÂ†¥ÊôØ‰∏≠Ê∂âÂèäÁöÑ‰∏çÂêåËßíËâ≤„ÄÇÈô§‰∫ÜÂ∞á LLM Ë¶ñÁÇ∫ ${Writer}$ ÁöÑÂ∏∏Ë¶ãÂÅöÊ≥ïÂ§ñÔºåÊàëÂÄëÈÇÑÂ∞á LLM Áî®‰Ωú ${Editor}ÔºåË≤†Ë≤¨Âêë ${Writer}$ Êèê‰æõÂõûÈ•ãÂíå‰øÆÊîπÂª∫Ë≠∞„ÄÇÊ≠§Â§ñÔºåÁÇ∫‰∫ÜË±êÂØåËßíËâ≤‰∏¶Âä†Ê∑±ÂäáÊÉÖÔºåÊàëÂÄëÂºïÂÖ•ËßíËâ≤ÊâÆÊºîÊ©üÂà∂Ôºå‰∏¶Êé°Áî® LLM ‰ΩúÁÇ∫ ${Actors}ÔºåÂÆÉÂÄëÂèØ‰ª•Áõ∏‰∫íÊ∫ùÈÄöÂíå‰∫íÂãï„ÄÇÂ∞çËá™ÂãïÁîüÊàêÁöÑÂäáÊú¨ÈÄ≤Ë°åË©ï‰º∞Ë°®ÊòéÔºåHoLLMwood Âú®ÈÄ£Ë≤´ÊÄß„ÄÅÁõ∏ÈóúÊÄß„ÄÅË∂£Âë≥ÊÄßÂíåÊï¥È´îÂìÅË≥™ÊñπÈù¢ÊòéÈ°ØÂÑ™ÊñºÂº∑Â§ßÁöÑÂü∫Ê∫ñ„ÄÇ

##### **Knowledge-to-Jailbreak: One Knowledge Point Worth One Attack**
2406.11682v1 by Shangqing Tu, Zhuoran Pan, Wenxuan Wang, Zhexin Zhang, Yuliang Sun, Jifan Yu, Hongning Wang, Lei Hou, Juanzi Li

Large language models (LLMs) have been increasingly applied to various
domains, which triggers increasing concerns about LLMs' safety on specialized
domains, e.g. medicine. However, testing the domain-specific safety of LLMs is
challenging due to the lack of domain knowledge-driven attacks in existing
benchmarks. To bridge this gap, we propose a new task, knowledge-to-jailbreak,
which aims to generate jailbreaks from domain knowledge to evaluate the safety
of LLMs when applied to those domains. We collect a large-scale dataset with
12,974 knowledge-jailbreak pairs and fine-tune a large language model as
jailbreak-generator, to produce domain knowledge-specific jailbreaks.
Experiments on 13 domains and 8 target LLMs demonstrate the effectiveness of
jailbreak-generator in generating jailbreaks that are both relevant to the
given knowledge and harmful to the target LLMs. We also apply our method to an
out-of-domain knowledge base, showing that jailbreak-generator can generate
jailbreaks that are comparable in harmfulness to those crafted by human
experts. Data and code: https://github.com/THU-KEG/Knowledge-to-Jailbreak/.

ÊëòË¶ÅÔºöÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÂ∑≤Ë∂äÊù•Ë∂äÂ§öÂú∞Â∫îÁî®‰∫éÂêÑÁßçÈ¢ÜÂüüÔºåËøôÂºïÂèë‰∫Ü‰∫∫‰ª¨ÂØπ LLM Âú®‰∏ì‰∏öÈ¢ÜÂüüÔºà‰æãÂ¶ÇÂåªÂ≠¶Ôºâ‰∏äÁöÑÂÆâÂÖ®ÊÄßÊó•ÁõäÊãÖÂøß„ÄÇÁÑ∂ËÄåÔºåÁî±‰∫éÁé∞ÊúâÂü∫ÂáÜÁº∫‰πèÈ¢ÜÂüüÁü•ËØÜÈ©±Âä®ÁöÑÊîªÂáªÔºåÂõ†Ê≠§ÊµãËØï LLM ÁöÑÁâπÂÆöÈ¢ÜÂüüÂÆâÂÖ®ÊÄßÂÖ∑ÊúâÊåëÊàòÊÄß„ÄÇ‰∏∫‰∫ÜÂº•ÂêàËøô‰∏ÄÂ∑ÆË∑ùÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Êñ∞‰ªªÂä°ÔºåÂç≥Áü•ËØÜÂà∞Ë∂äÁã±ÔºåÂÖ∂ÁõÆÁöÑÊòØ‰ªéÈ¢ÜÂüüÁü•ËØÜ‰∏≠ÁîüÊàêË∂äÁã±Ôºå‰ª•ËØÑ‰º∞ LLM Â∫îÁî®‰∫éËøô‰∫õÈ¢ÜÂüüÊó∂ÁöÑÂÆâÂÖ®ÊÄß„ÄÇÊàë‰ª¨Êî∂ÈõÜ‰∫Ü‰∏Ä‰∏™ÂåÖÂê´ 12,974 ‰∏™Áü•ËØÜË∂äÁã±ÂØπÁöÑÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜÔºåÂπ∂ÂæÆË∞É‰∫Ü‰∏Ä‰∏™Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã‰Ωú‰∏∫Ë∂äÁã±ÁîüÊàêÂô®Ôºå‰ª•‰∫ßÁîüÁâπÂÆö‰∫éÈ¢ÜÂüüÁü•ËØÜÁöÑË∂äÁã±„ÄÇÂú® 13 ‰∏™È¢ÜÂüüÂíå 8 ‰∏™ÁõÆÊ†á LLM ‰∏äÁöÑÂÆûÈ™åË°®Êòé‰∫ÜË∂äÁã±ÁîüÊàêÂô®Âú®ÁîüÊàê‰∏éÁªôÂÆöÁü•ËØÜÁõ∏ÂÖ≥‰∏îÂØπÁõÆÊ†á LLM ÊúâÂÆ≥ÁöÑË∂äÁã±ÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇÊàë‰ª¨ËøòÂ∞ÜÊàë‰ª¨ÁöÑÊñπÊ≥ïÂ∫îÁî®‰∫éÂüüÂ§ñÁü•ËØÜÂ∫ìÔºåË°®ÊòéË∂äÁã±ÁîüÊàêÂô®ÂèØ‰ª•ÁîüÊàê‰∏é‰∫∫Á±ª‰∏ìÂÆ∂Âà∂‰ΩúÁöÑË∂äÁã±Âú®Âç±ÂÆ≥ÊÄßÊñπÈù¢Áõ∏ÂΩìÁöÑË∂äÁã±„ÄÇÊï∞ÊçÆÂíå‰ª£Á†ÅÔºöhttps://github.com/THU-KEG/Knowledge-to-Jailbreak/„ÄÇ

##### **R-Eval: A Unified Toolkit for Evaluating Domain Knowledge of Retrieval Augmented Large Language Models**
2406.11681v1 by Shangqing Tu, Yuanchun Wang, Jifan Yu, Yuyang Xie, Yaran Shi, Xiaozhi Wang, Jing Zhang, Lei Hou, Juanzi Li

Large language models have achieved remarkable success on general NLP tasks,
but they may fall short for domain-specific problems. Recently, various
Retrieval-Augmented Large Language Models (RALLMs) are proposed to address this
shortcoming. However, existing evaluation tools only provide a few baselines
and evaluate them on various domains without mining the depth of domain
knowledge. In this paper, we address the challenges of evaluating RALLMs by
introducing the R-Eval toolkit, a Python toolkit designed to streamline the
evaluation of different RAG workflows in conjunction with LLMs. Our toolkit,
which supports popular built-in RAG workflows and allows for the incorporation
of customized testing data on the specific domain, is designed to be
user-friendly, modular, and extensible. We conduct an evaluation of 21 RALLMs
across three task levels and two representative domains, revealing significant
variations in the effectiveness of RALLMs across different tasks and domains.
Our analysis emphasizes the importance of considering both task and domain
requirements when choosing a RAG workflow and LLM combination. We are committed
to continuously maintaining our platform at https://github.com/THU-KEG/R-Eval
to facilitate both the industry and the researchers.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®ÈÄöÁî®ÁöÑ NLP ‰ªªÂãô‰∏äÂèñÂæó‰∫ÜÈ°ØËëóÁöÑÊàêÂäüÔºå
‰ΩÜÂÆÉÂÄëÂú®ÁâπÂÆöÈ†òÂüüÁöÑÂïèÈ°å‰∏äÂèØËÉΩË°®Áèæ‰∏ç‰Ω≥„ÄÇÊúÄËøëÔºåÊèêÂá∫‰∫ÜÂêÑÁ®Æ
Ê™¢Á¥¢Â¢ûÂº∑Â§ßÂûãË™ûË®ÄÊ®°Âûã (RALLM) ‰æÜËß£Ê±∫ÈÄôÂÄã
Áº∫Èªû„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑË©ï‰º∞Â∑•ÂÖ∑Âè™Êèê‰æõ‰∫Ü‰∏Ä‰∫õÂü∫Ê∫ñÔºå
‰∏¶Âú®ÂêÑÁ®ÆÈ†òÂüüÂ∞çÂÆÉÂÄëÈÄ≤Ë°åË©ï‰º∞ÔºåËÄåÊ≤íÊúâÊåñÊéòÈ†òÂüü
Áü•Ë≠òÁöÑÊ∑±Â∫¶„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëËß£Ê±∫‰∫ÜË©ï‰º∞ RALLM ÁöÑÊåëÊà∞Ôºå
ÂºïÂÖ•‰∫Ü R-Eval Â∑•ÂÖ∑ÂåÖÔºåÈÄôÊòØ‰∏ÄÂÄã Python Â∑•ÂÖ∑ÂåÖÔºåÊó®Âú®Á∞°Âåñ
Ë©ï‰º∞‰∏çÂêåÁöÑ RAG Â∑•‰ΩúÊµÅÁ®ã‰ª•Âèä LLM„ÄÇÊàëÂÄëÁöÑÂ∑•ÂÖ∑ÂåÖÔºå
ÂÆÉÊîØÊåÅÊµÅË°åÁöÑÂÖßÂª∫ RAG Â∑•‰ΩúÊµÅÁ®ãÔºå‰∏¶ÂÖÅË®±Âú®ÁâπÂÆöÈ†òÂüüÊï¥Âêà
Ëá™Ë®ÇÁöÑÊ∏¨Ë©¶Êï∏ÊìöÔºåÊó®Âú®ÊàêÁÇ∫‰ΩøÁî®ËÄÖÂèãÂñÑ„ÄÅÊ®°ÁµÑÂåñÂíåÂèØÊì¥ÂÖÖÁöÑ„ÄÇÊàëÂÄëÂ∞ç 21 ÂÄã RALLM
ÈÄ≤Ë°å‰∫ÜË©ï‰º∞ÔºåÊ∂µËìã‰∏âÂÄã‰ªªÂãôÂ±§Á¥öÂíåÂÖ©ÂÄã‰ª£Ë°®ÊÄßÈ†òÂüüÔºåÊè≠Á§∫‰∫Ü RALLM
Âú®‰∏çÂêå‰ªªÂãôÂíåÈ†òÂüü‰∏≠ÁöÑÊúâÊïàÊÄßÊúâÈ°ØËëóÂ∑ÆÁï∞„ÄÇ
ÊàëÂÄëÁöÑÂàÜÊûêÂº∑Ë™ø‰∫ÜÂú®ÈÅ∏Êìá RAG Â∑•‰ΩúÊµÅÁ®ãÂíå LLM ÁµÑÂêàÊôÇËÄÉÊÖÆ‰ªªÂãôÂíåÈ†òÂüü
ÈúÄÊ±ÇÁöÑÈáçË¶ÅÊÄß„ÄÇÊàëÂÄëËá¥ÂäõÊñºÊåÅÁ∫åÁ∂≠Ë≠∑ÊàëÂÄëÁöÑÂπ≥Âè∞ÔºåÁ∂≤ÂùÄÁÇ∫ https://github.com/THU-KEG/R-EvalÔºå
‰ª•‰øÉÈÄ≤Áî¢Ê•≠ÂíåÁ†îÁ©∂‰∫∫Âì°„ÄÇ

##### **TourRank: Utilizing Large Language Models for Documents Ranking with a Tournament-Inspired Strategy**
2406.11678v1 by Yiqun Chen, Qi Liu, Yi Zhang, Weiwei Sun, Daiting Shi, Jiaxin Mao, Dawei Yin

Large Language Models (LLMs) are increasingly employed in zero-shot documents
ranking, yielding commendable results. However, several significant challenges
still persist in LLMs for ranking: (1) LLMs are constrained by limited input
length, precluding them from processing a large number of documents
simultaneously; (2) The output document sequence is influenced by the input
order of documents, resulting in inconsistent ranking outcomes; (3) Achieving a
balance between cost and ranking performance is quite challenging. To tackle
these issues, we introduce a novel documents ranking method called TourRank,
which is inspired by the tournament mechanism. This approach alleviates the
impact of LLM's limited input length through intelligent grouping, while the
tournament-like points system ensures robust ranking, mitigating the influence
of the document input sequence. We test TourRank with different LLMs on the
TREC DL datasets and the BEIR benchmark. Experimental results show that
TourRank achieves state-of-the-art performance at a reasonable cost.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)  zunehmend in Zero-Shot-Dokumenten eingesetzt
Ranking, was zu lobenswerten Ergebnissen f√ºhrt. Allerdings bestehen bei LLMs f√ºr das Ranking immer noch mehrere erhebliche Herausforderungen: (1) LLMs sind durch eine begrenzte Eingabel√§nge eingeschr√§nkt, was sie daran hindert, eine gro√üe Anzahl von Dokumenten gleichzeitig zu verarbeiten; (2) Die Ausgabe-Dokumentsequenz wird durch die Eingabereihenfolge der Dokumente beeinflusst, was zu inkonsistenten Ranking-Ergebnissen f√ºhrt; (3) Es ist eine ziemliche Herausforderung, ein Gleichgewicht zwischen Kosten und Ranking-Leistung zu erreichen. Um diese Probleme anzugehen, stellen wir eine neuartige Dokumenten-Ranking-Methode namens TourRank vor, die vom Turniermechanismus inspiriert ist. Dieser Ansatz mildert die Auswirkungen der begrenzten Eingabel√§nge von LLM durch intelligente Gruppierung, w√§hrend das turnier√§hnliche Punktesystem ein robustes Ranking gew√§hrleistet und den Einfluss der Dokumenteneingabesequenz abschw√§cht. Wir testen TourRank mit verschiedenen LLMs auf den TREC DL-Datens√§tzen und dem BEIR-Benchmark. Experimentelle Ergebnisse zeigen, dass TourRank zu einem vern√ºnftigen Preis eine hochmoderne Leistung erzielt.

##### **BLoB: Bayesian Low-Rank Adaptation by Backpropagation for Large Language Models**
2406.11675v1 by Yibin Wang, Haizhou Shi, Ligong Han, Dimitris Metaxas, Hao Wang

Large Language Models (LLMs) often suffer from overconfidence during
inference, particularly when adapted to downstream domain-specific tasks with
limited data. Previous work addresses this issue by employing approximate
Bayesian estimation after the LLMs are trained, enabling them to quantify
uncertainty. However, such post-training approaches' performance is severely
limited by the parameters learned during training. In this paper, we go beyond
post-training Bayesianization and propose Bayesian Low-Rank Adaptation by
Backpropagation (BLoB), an algorithm that continuously and jointly adjusts both
the mean and covariance of LLM parameters throughout the whole fine-tuning
process. Our empirical results verify the effectiveness of BLoB in terms of
generalization and uncertainty estimation, when evaluated on both
in-distribution and out-of-distribution data.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Êé®Ë´ñÊúüÈñìÁ∂ìÂ∏∏ÈÅéÊñºËá™‰ø°ÔºåÁâπÂà•ÊòØÂú®ÈÅ©ÊáâÂÖ∑ÊúâÊúâÈôêÊï∏ÊìöÁöÑ‰∏ãÊ∏∏ÁâπÂÆöÈ†òÂüü‰ªªÂãôÊôÇ„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂ÈÄèÈÅéÂú® LLM Ë®ìÁ∑¥ÂæåÊé°Áî®Ëøë‰ººË≤ùÊ∞è‰º∞Ë®à‰æÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºå‰ΩøÂÖ∂ËÉΩÂ§†ÈáèÂåñ‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÁÑ∂ËÄåÔºåÊ≠§È°ûË®ìÁ∑¥ÂæåÊñπÊ≥ïÁöÑÊïàËÉΩÂèóÂà∞Ë®ìÁ∑¥ÊúüÈñìÊâÄÂ≠∏ÁøíÂèÉÊï∏ÁöÑÂö¥ÈáçÈôêÂà∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëË∂ÖË∂ä‰∫ÜË®ìÁ∑¥ÂæåÁöÑË≤ùÊ∞èÂåñÔºå‰∏¶ÊèêÂá∫ÈÄèÈÅéÂèçÂêëÂÇ≥Êí≠ÁöÑË≤ùÊ∞è‰ΩéÈöéÈÅ©Êáâ (BLoB)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊºîÁÆóÊ≥ïÔºåÂèØÂú®Êï¥ÂÄãÂæÆË™øÈÅéÁ®ã‰∏≠ÊåÅÁ∫å‰∏îÂêåÊôÇË™øÊï¥ LLM ÂèÉÊï∏ÁöÑÂπ≥ÂùáÂÄºÂíåÂÖ±ËÆäÁï∞Êï∏„ÄÇÊàëÂÄëÁöÑÂØ¶Ë≠âÁµêÊûúÈ©óË≠â‰∫Ü BLoB Âú®Ê≥õÂåñÂíå‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÊñπÈù¢ÁöÑÊïàËÉΩÔºåÂú®ÂàÜ‰ΩàÂÖßÂíåÂàÜ‰ΩàÂ§ñÊï∏Êìö‰∏äÈÄ≤Ë°åË©ï‰º∞ÊôÇÁöÜËÉΩÈ©óË≠â„ÄÇ

##### **Endor: Hardware-Friendly Sparse Format for Offloaded LLM Inference**
2406.11674v1 by Donghyeon Joo, Ramyad Hadidi, Soheil Feizi, Bahar Asgari

The increasing size of large language models (LLMs) challenges their usage on
resource-constrained platforms. For example, memory on modern GPUs is
insufficient to hold LLMs that are hundreds of Gigabytes in size. Offloading is
a popular method to escape this constraint by storing weights of an LLM model
to host CPU memory and SSD, then loading each weight to GPU before every use.
In our case study of offloaded inference, we found that due to the low
bandwidth between storage devices and GPU, the latency of transferring large
model weights from its offloaded location to GPU memory becomes the critical
bottleneck with actual compute taking nearly 0% of runtime. To effectively
reduce the weight transfer latency, we propose a novel sparse format that
compresses the unstructured sparse pattern of pruned LLM weights to non-zero
values with high compression ratio and low decompression overhead. Endor
achieves this by expressing the positions of non-zero elements with a bitmap.
Compared to offloaded inference using the popular Huggingface Accelerate,
applying Endor accelerates OPT-66B by 1.70x and Llama2-70B by 1.78x. When
direct weight transfer from SSD to GPU is leveraged, Endor achieves 2.25x
speedup on OPT-66B and 2.37x speedup on Llama2-70B.

ÊëòË¶ÅÔºöÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÁöÑÂ∞∫ÂØ∏Ë∂äÊù•Ë∂äÂ§ßÔºåÂØπËµÑÊ∫êÂèóÈôêÂπ≥Âè∞‰∏äÁöÑ‰ΩøÁî®ÊûÑÊàêÊåëÊàò„ÄÇ‰æãÂ¶ÇÔºåÁé∞‰ª£ GPU ‰∏äÁöÑÂÜÖÂ≠ò‰∏çË∂≥‰ª•ÂÆπÁ∫≥Êï∞Áôæ GB Â§ßÂ∞èÁöÑ LLM„ÄÇÂç∏ËΩΩÊòØ‰∏ÄÁßçÊµÅË°åÁöÑÊñπÊ≥ïÔºåÂèØ‰ª•ÈÄöËøáÂ∞Ü LLM Ê®°ÂûãÁöÑÊùÉÈáçÂ≠òÂÇ®Âà∞‰∏ªÊú∫ CPU ÂÜÖÂ≠òÂíå SSD ‰∏≠Êù•ÊëÜËÑ±Ê≠§ÈôêÂà∂ÔºåÁÑ∂ÂêéÂú®ÊØèÊ¨°‰ΩøÁî®‰πãÂâçÂ∞ÜÊØè‰∏™ÊùÉÈáçÂä†ËΩΩÂà∞ GPU ‰∏≠„ÄÇÂú®Êàë‰ª¨ÁöÑÂç∏ËΩΩÊé®ÁêÜÊ°à‰æãÁ†îÁ©∂‰∏≠ÔºåÊàë‰ª¨ÂèëÁé∞Áî±‰∫éÂ≠òÂÇ®ËÆæÂ§áÂíå GPU ‰πãÈó¥ÁöÑÂ∏¶ÂÆΩËæÉ‰ΩéÔºåÂ∞ÜÂ§ßÂûãÊ®°ÂûãÊùÉÈáç‰ªéÂÖ∂Âç∏ËΩΩ‰ΩçÁΩÆ‰º†ËæìÂà∞ GPU ÂÜÖÂ≠òÁöÑÂª∂ËøüÊàê‰∏∫ÂÖ≥ÈîÆÁì∂È¢àÔºåÂÆûÈôÖËÆ°ÁÆó‰ªÖÂç†ËøêË°åÊó∂ÁöÑ 0%„ÄÇ‰∏∫‰∫ÜÊúâÊïàÂáèÂ∞ëÊùÉÈáç‰º†ËæìÂª∂ËøüÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÁ®ÄÁñèÊ†ºÂºèÔºåËØ•Ê†ºÂºèÂ∞Ü‰øÆÂâ™ÁöÑ LLM ÊùÉÈáçÁöÑÈùûÁªìÊûÑÂåñÁ®ÄÁñèÊ®°ÂºèÂéãÁº©‰∏∫ÈùûÈõ∂ÂÄºÔºåÂÖ∑ÊúâÈ´òÂéãÁº©ÊØîÂíå‰ΩéËß£ÂéãÁº©ÂºÄÈîÄ„ÄÇEndor ÈÄöËøá‰ΩøÁî®‰ΩçÂõæË°®Á§∫ÈùûÈõ∂ÂÖÉÁ¥†ÁöÑ‰ΩçÁΩÆÊù•ÂÆûÁé∞Ëøô‰∏ÄÁÇπ„ÄÇ‰∏é‰ΩøÁî®ÊµÅË°åÁöÑ Huggingface Accelerate ËøõË°åÂç∏ËΩΩÊé®ÁêÜÁõ∏ÊØîÔºåÂ∫îÁî® Endor ÂèØÂ∞Ü OPT-66B Âä†ÈÄü 1.70 ÂÄçÔºåÂ∞Ü Llama2-70B Âä†ÈÄü 1.78 ÂÄç„ÄÇÂΩìÂà©Áî®‰ªé SSD Âà∞ GPU ÁöÑÁõ¥Êé•ÊùÉÈáç‰º†ËæìÊó∂ÔºåEndor Âú® OPT-66B ‰∏äÂÆûÁé∞‰∫Ü 2.25 ÂÄçÁöÑÂä†ÈÄüÔºåÂú® Llama2-70B ‰∏äÂÆûÁé∞‰∫Ü 2.37 ÂÄçÁöÑÂä†ÈÄü„ÄÇ

##### **Benchmarking of LLM Detection: Comparing Two Competing Approaches**
2406.11670v1 by Thorsten Pr√∂hl, Erik Putzier, R√ºdiger Zarnekow

This article gives an overview of the field of LLM text recognition.
Different approaches and implemented detectors for the recognition of
LLM-generated text are presented. In addition to discussing the
implementations, the article focuses on benchmarking the detectors. Although
there are numerous software products for the recognition of LLM-generated text,
with a focus on ChatGPT-like LLMs, the quality of the recognition (recognition
rate) is not clear. Furthermore, while it can be seen that scientific
contributions presenting their novel approaches strive for some kind of
comparison with other approaches, the construction and independence of the
evaluation dataset is often not comprehensible. As a result, discrepancies in
the performance evaluation of LLM detectors are often visible due to the
different benchmarking datasets. This article describes the creation of an
evaluation dataset and uses this dataset to investigate the different
detectors. The selected detectors are benchmarked against each other.

ÊëòË¶ÅÔºöÊú¨ÊñáÊ¶ÇËø∞‰∫Ü LLM ÊñáÊú¨ËØÜÂà´ÁöÑÈ¢ÜÂüü„ÄÇ
‰ªãÁªç‰∫ÜÁî®‰∫éËØÜÂà´ LLM ÁîüÊàêÁöÑÊñáÊú¨ÁöÑ‰∏çÂêåÊñπÊ≥ïÂíåÂ∑≤ÂÆûÁé∞ÁöÑÊ£ÄÊµãÂô®„ÄÇÈô§‰∫ÜËÆ®ËÆ∫
ÂÆûÁé∞‰πãÂ§ñÔºåÊú¨ÊñáÈáçÁÇπÂÖ≥Ê≥®Ê£ÄÊµãÂô®ÁöÑÂü∫ÂáÜÊµãËØï„ÄÇËôΩÁÑ∂
ÊúâËÆ∏Â§öÁî®‰∫éËØÜÂà´ LLM ÁîüÊàêÁöÑÊñáÊú¨ÁöÑËΩØ‰ª∂‰∫ßÂìÅÔºå
‰∏ìÊ≥®‰∫éÁ±ª‰ºº ChatGPT ÁöÑ LLMÔºå‰ΩÜËØÜÂà´Ë¥®ÈáèÔºàËØÜÂà´
ÁéáÔºâÂ∞ö‰∏çÊ∏ÖÊ•ö„ÄÇÊ≠§Â§ñÔºåËôΩÁÑ∂ÂèØ‰ª•ÁúãÂá∫ÁßëÂ≠¶
Ë¥°ÁåÆËÄÖÂú®ÊèêÂá∫ÂÖ∂Êñ∞ÊñπÊ≥ïÊó∂Âä™Âäõ‰∏éÂÖ∂‰ªñÊñπÊ≥ïËøõË°åÊüêÁßç
ÊØîËæÉÔºå‰ΩÜËØÑ‰º∞Êï∞ÊçÆÈõÜÁöÑÊûÑÂª∫ÂíåÁã¨Á´ãÊÄßÈÄöÂ∏∏Èöæ‰ª•ÁêÜËß£„ÄÇÂõ†Ê≠§ÔºåÁî±‰∫é
‰∏çÂêåÁöÑÂü∫ÂáÜÊï∞ÊçÆÈõÜÔºåLLM Ê£ÄÊµãÂô®ÁöÑÊÄßËÉΩËØÑ‰º∞‰∏≠ÁªèÂ∏∏‰ºöÂá∫Áé∞Â∑ÆÂºÇ„ÄÇÊú¨Êñá‰ªãÁªç‰∫ÜËØÑ‰º∞Êï∞ÊçÆÈõÜÁöÑÂàõÂª∫ÔºåÂπ∂‰ΩøÁî®Ê≠§Êï∞ÊçÆÈõÜÊù•Ë∞ÉÊü•‰∏çÂêåÁöÑ
Ê£ÄÊµãÂô®„ÄÇÈÄâÂÆöÁöÑÊ£ÄÊµãÂô®Áõ∏‰∫íËøõË°åÂü∫ÂáÜÊµãËØï„ÄÇ

##### **"Not Aligned" is Not "Malicious": Being Careful about Hallucinations of Large Language Models' Jailbreak**
2406.11668v1 by Lingrui Mei, Shenghua Liu, Yiwei Wang, Baolong Bi, Jiayi Mao, Xueqi Cheng

"Jailbreak" is a major safety concern of Large Language Models (LLMs), which
occurs when malicious prompts lead LLMs to produce harmful outputs, raising
issues about the reliability and safety of LLMs. Therefore, an effective
evaluation of jailbreaks is very crucial to develop its mitigation strategies.
However, our research reveals that many jailbreaks identified by current
evaluations may actually be hallucinations-erroneous outputs that are mistaken
for genuine safety breaches. This finding suggests that some perceived
vulnerabilities might not represent actual threats, indicating a need for more
precise red teaming benchmarks. To address this problem, we propose the
$\textbf{B}$enchmark for reli$\textbf{AB}$ilit$\textbf{Y}$ and
jail$\textbf{B}$reak ha$\textbf{L}$l$\textbf{U}$cination $\textbf{E}$valuation
(BabyBLUE). BabyBLUE introduces a specialized validation framework including
various evaluators to enhance existing jailbreak benchmarks, ensuring outputs
are useful malicious instructions. Additionally, BabyBLUE presents a new
dataset as an augmentation to the existing red teaming benchmarks, specifically
addressing hallucinations in jailbreaks, aiming to evaluate the true potential
of jailbroken LLM outputs to cause harm to human society.

ÊëòË¶ÅÔºö„ÄåË∂äÁçÑ„ÄçÊòØÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑ‰∏ªË¶ÅÂÆâÂÖ®ÂïèÈ°åÔºåÂÆÉÁôºÁîüÂú®ÊÉ°ÊÑèÊèêÁ§∫Â∞éËá¥ LLM Áî¢ÁîüÊúâÂÆ≥Ëº∏Âá∫ÊôÇÔºåÂºïÁôº‰∫ÜÈóúÊñº LLM ÁöÑÂèØÈù†ÊÄßÂíåÂÆâÂÖ®ÊÄßÂïèÈ°å„ÄÇÂõ†Ê≠§ÔºåÂ∞çË∂äÁçÑÈÄ≤Ë°åÊúâÊïàÁöÑË©ï‰º∞Â∞çÊñºÂà∂ÂÆöÂÖ∂Á∑©Ëß£Á≠ñÁï•Ëá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÁï∂ÂâçË©ï‰º∞‰∏≠Ë≠òÂà•Âá∫ÁöÑË®±Â§öË∂äÁçÑÂØ¶Èöõ‰∏äÂèØËÉΩÊòØÂπªË¶∫‚Äî‚ÄîÈåØË™§ÁöÑËº∏Âá∫ÔºåË¢´Ë™§Ë™çÁÇ∫ÁúüÊ≠£ÁöÑÂÆâÂÖ®ÊºèÊ¥û„ÄÇÈÄô‰∏ÄÁôºÁèæË°®ÊòéÔºå‰∏Ä‰∫õÊÑüÁü•Âà∞ÁöÑÊºèÊ¥ûÂèØËÉΩ‰∏¶‰∏çËÉΩ‰ª£Ë°®ÂØ¶ÈöõÂ®ÅËÑÖÔºåÈÄôË°®ÊòéÈúÄË¶ÅÊõ¥Á≤æÁ¢∫ÁöÑÁ¥ÖÈöäÂü∫Ê∫ñ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü$\textbf{B}$enchmark for reli$\textbf{AB}$ilit$\textbf{Y}$ and jail$\textbf{B}$reak ha$\textbf{L}$l$\textbf{U}$cination $\textbf{E}$valuationÔºàBabyBLUEÔºâ„ÄÇBabyBLUE ÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂ∞àÈñÄÁöÑÈ©óË≠âÊ°ÜÊû∂ÔºåÂåÖÊã¨ÂêÑÁ®ÆË©ï‰º∞Âô®Ôºå‰ª•Â¢ûÂº∑ÁèæÊúâÁöÑË∂äÁçÑÂü∫Ê∫ñÔºåÁ¢∫‰øùËº∏Âá∫ÊòØÊúâÁî®ÁöÑÊÉ°ÊÑèÊåá‰ª§„ÄÇÊ≠§Â§ñÔºåBabyBLUE ÈÇÑÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊñ∞Êï∏ÊìöÈõÜ‰ΩúÁÇ∫Â∞çÁèæÊúâÁ¥ÖÈöäÂü∫Ê∫ñÁöÑÊì¥ÂÖÖÔºåÁâπÂà•ÈáùÂ∞çË∂äÁçÑ‰∏≠ÁöÑÂπªË¶∫ÔºåÊó®Âú®Ë©ï‰º∞Ë∂äÁçÑ LLM Ëº∏Âá∫Â∞ç‰∫∫È°ûÁ§æÊúÉÈÄ†ÊàêÂÇ∑ÂÆ≥ÁöÑÁúüÊ≠£ÊΩõÂäõ„ÄÇ

##### **See It from My Perspective: Diagnosing the Western Cultural Bias of Large Vision-Language Models in Image Understanding**
2406.11665v1 by Amith Ananthram, Elias Stengel-Eskin, Carl Vondrick, Mohit Bansal, Kathleen McKeown

Vision-language models (VLMs) can respond to queries about images in many
languages. However, beyond language, culture affects how we see things. For
example, individuals from Western cultures focus more on the central figure in
an image while individuals from Eastern cultures attend more to scene context.
In this work, we present a novel investigation that demonstrates and localizes
VLMs' Western bias in image understanding. We evaluate large VLMs across
subjective and objective visual tasks with culturally diverse images and
annotations. We find that VLMs perform better on the Western subset than the
Eastern subset of each task. Controlled experimentation tracing the source of
this bias highlights the importance of a diverse language mix in text-only
pre-training for building equitable VLMs, even when inference is performed in
English. Moreover, while prompting in the language of a target culture can lead
to reductions in bias, it is not a substitute for building AI more
representative of the world's languages.

ÊëòË¶ÅÔºöË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) ËÉΩ‰ª•Â§öÁ®ÆË™ûË®ÄÂõûÁ≠îÈóúÊñºÂΩ±ÂÉèÁöÑÊü•Ë©¢„ÄÇÁÑ∂ËÄåÔºåÈô§‰∫ÜË™ûË®Ä‰πãÂ§ñÔºåÊñáÂåñ‰πüÊúÉÂΩ±ÈüøÊàëÂÄëÁúãÂæÖ‰∫ãÁâ©ÁöÑÊñπÂºè„ÄÇ‰æãÂ¶ÇÔºå‰æÜËá™Ë•øÊñπÊñáÂåñÁöÑ‰∫∫ÊúÉÊõ¥Â∞àÊ≥®ÊñºÂΩ±ÂÉè‰∏≠ÁöÑ‰∏≠Â§Æ‰∫∫Áâ©ÔºåËÄå‰æÜËá™Êù±ÊñπÊñáÂåñÁöÑ‰∫∫ÂâáÊúÉÊõ¥ÈóúÊ≥®Â†¥ÊôØËÉåÊôØ„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÈ†ÖÊñ∞Á©éÁöÑÁ†îÁ©∂ÔºåÂ±ïÁ§∫‰∏¶ÂÆö‰Ωç‰∫Ü VLM Âú®ÂΩ±ÂÉèÁêÜËß£‰∏≠ÁöÑË•øÊñπÂÅèË¶ã„ÄÇÊàëÂÄëÂú®ÂÖ∑ÊúâÊñáÂåñÂ§öÂÖÉÊÄßÂΩ±ÂÉèÂíåË®ªËß£ÁöÑ‰∏ªËßÄÂíåÂÆ¢ËßÄË¶ñË¶∫‰ªªÂãô‰∏≠Ë©ï‰º∞‰∫ÜÂ§ßÂûã VLM„ÄÇÊàëÂÄëÁôºÁèæÔºåVLM Âú®ÊØèÂÄã‰ªªÂãôÁöÑË•øÊñπÂ≠êÈõÜ‰∏äË°®ÁèæÂÑ™ÊñºÊù±ÊñπÂ≠êÈõÜ„ÄÇËøΩËπ§Ê≠§ÂÅèË¶ã‰æÜÊ∫êÁöÑÂèóÊéßÂØ¶È©óÂº∑Ë™ø‰∫ÜÂú®ÂÉÖÊñáÂ≠óÈ†êË®ìÁ∑¥‰∏≠‰ΩøÁî®Â§öÊ®£ÂåñË™ûË®ÄÁµÑÂêàÂ∞çÊñºÂª∫ÊßãÂÖ¨Âπ≥ÁöÑ VLM ÁöÑÈáçË¶ÅÊÄßÔºåÂç≥‰ΩøÊòØÂú®Ëã±Ë™û‰∏≠Âü∑Ë°åÊé®Ë´ñÊôÇ‰πüÊòØÂ¶ÇÊ≠§„ÄÇÊ≠§Â§ñÔºåÂÑòÁÆ°‰ΩøÁî®ÁõÆÊ®ôÊñáÂåñÁöÑË™ûË®ÄÊèêÁ§∫ÂèØ‰ª•Ê∏õÂ∞ëÂÅèË¶ãÔºå‰ΩÜÂÆÉ‰∏¶‰∏çËÉΩÂèñ‰ª£Âª∫ÊßãÊõ¥ËÉΩ‰ª£Ë°®‰∏ñÁïåË™ûË®ÄÁöÑ AI„ÄÇ

##### **Cultural Conditioning or Placebo? On the Effectiveness of Socio-Demographic Prompting**
2406.11661v1 by Sagnik Mukherjee, Muhammad Farid Adilazuarda, Sunayana Sitaram, Kalika Bali, Alham Fikri Aji, Monojit Choudhury

Socio-demographic prompting is a commonly employed approach to study cultural
biases in LLMs as well as for aligning models to certain cultures. In this
paper, we systematically probe four LLMs (Llama 3, Mistral v0.2, GPT-3.5 Turbo
and GPT-4) with prompts that are conditioned on culturally sensitive and
non-sensitive cues, on datasets that are supposed to be culturally sensitive
(EtiCor and CALI) or neutral (MMLU and ETHICS). We observe that all models
except GPT-4 show significant variations in their responses on both kinds of
datasets for both kinds of prompts, casting doubt on the robustness of the
culturally-conditioned prompting as a method for eliciting cultural bias in
models or as an alignment strategy. The work also calls rethinking the control
experiment design to tease apart the cultural conditioning of responses from
"placebo effect", i.e., random perturbations of model responses due to
arbitrary tokens in the prompt.

ÊëòË¶ÅÔºöÁ§æÊúÉ‰∫∫Âè£ÊèêÁ§∫ÊòØ‰∏ÄÁ®ÆÂª£Ê≥õÊé°Áî®ÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÁ†îÁ©∂ LLM ‰∏≠ÁöÑÊñáÂåñÂÅèË¶ãÔºå‰ª•ÂèäÂ∞áÊ®°ÂûãËàáÁâπÂÆöÊñáÂåñÂ∞çÈΩä„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁ≥ªÁµ±ÊÄßÂú∞Êé¢Êü•‰∫ÜÂõõÂÄã LLMÔºàLlama 3„ÄÅMistral v0.2„ÄÅGPT-3.5 Turbo Âíå GPT-4ÔºâÔºåÊèêÁ§∫ÂÆÉÂÄë‰ª•ÊñáÂåñÊïèÊÑüÂíå‰∏çÊïèÊÑüÁöÑÁ∑öÁ¥¢ÁÇ∫Ê¢ù‰ª∂ÔºåÂú®ÂÅáË®≠ÁÇ∫ÊñáÂåñÊïèÊÑüÔºàEtiCor Âíå CALIÔºâÊàñ‰∏≠Á´ãÔºàMMLU Âíå ETHICSÔºâÁöÑÊï∏ÊìöÈõÜ‰∏ä„ÄÇÊàëÂÄëËßÄÂØüÂà∞Èô§‰∫Ü GPT-4 ‰πãÂ§ñÔºåÊâÄÊúâÊ®°ÂûãÂú®ÂÖ©Á®ÆÊèêÁ§∫ÁöÑÂÖ©Á®ÆÊï∏ÊìöÈõÜ‰∏äÁöÑÂõûÊáâÈÉΩÂá∫ÁèæÈ°ØËëóÂ∑ÆÁï∞ÔºåÈÄôÂ∞çÊñáÂåñÊ¢ù‰ª∂ÊèêÁ§∫‰ΩúÁÇ∫ÂºïÁôºÊ®°Âûã‰∏≠ÊñáÂåñÂÅèË¶ãÁöÑÊñπÊ≥ïÊàñ‰ΩúÁÇ∫Â∞çÈΩäÁ≠ñÁï•ÁöÑÁ©©ÂÅ•ÊÄßÊèêÂá∫Ë≥™Áñë„ÄÇÈÄôÈ†ÖÂ∑•‰Ωú‰πüË¶ÅÊ±ÇÈáçÊñ∞ÊÄùËÄÉÂ∞çÁÖßÂØ¶È©óË®≠Ë®àÔºå‰ª•ÂçÄÂàÜÂõûÊáâÁöÑÊñáÂåñÊ¢ù‰ª∂Âíå„ÄåÂÆâÊÖ∞ÂäëÊïàÊáâ„ÄçÔºåÂç≥ÊèêÁ§∫‰∏≠‰ªªÊÑèÁ¨¶ËôüÂ∞éËá¥Ê®°ÂûãÂõûÊáâÁöÑÈö®Ê©üÊìæÂãï„ÄÇ

##### **Can LLM be a Personalized Judge?**
2406.11657v1 by Yijiang River Dong, Tiancheng Hu, Nigel Collier

Ensuring that large language models (LLMs) reflect diverse user values and
preferences is crucial as their user bases expand globally. It is therefore
encouraging to see the growing interest in LLM personalization within the
research community. However, current works often rely on the LLM-as-a-Judge
approach for evaluation without thoroughly examining its validity. In this
paper, we investigate the reliability of LLM-as-a-Personalized-Judge, asking
LLMs to judge user preferences based on personas. Our findings suggest that
directly applying LLM-as-a-Personalized-Judge is less reliable than previously
assumed, showing low and inconsistent agreement with human ground truth. The
personas typically used are often overly simplistic, resulting in low
predictive power. To address these issues, we introduce verbal uncertainty
estimation into the LLM-as-a-Personalized-Judge pipeline, allowing the model to
express low confidence on uncertain judgments. This adjustment leads to much
higher agreement (above 80%) on high-certainty samples for binary tasks.
Through human evaluation, we find that the LLM-as-a-Personalized-Judge achieves
comparable performance to third-party humans evaluation and even surpasses
human performance on high-certainty samples. Our work indicates that
certainty-enhanced LLM-as-a-Personalized-Judge offers a promising direction for
developing more reliable and scalable methods for evaluating LLM
personalization.

ÊëòË¶ÅÔºöÁ¢∫‰øùÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËÉΩÂèçÊò†Â§öÊ®£ÂåñÁöÑ‰ΩøÁî®ËÄÖÂÉπÂÄºËßÄÂíåÂÅèÂ•ΩÔºåÈö®ËëóÂÖ∂‰ΩøÁî®ËÄÖÂü∫Á§éÂú®ÂÖ®ÁêÉÊì¥Â±ïÔºåÈÄôÈªûËá≥ÈóúÈáçË¶Å„ÄÇÂõ†Ê≠§ÔºåÁúãÂà∞Á†îÁ©∂Á§æÁæ§Â∞ç LLM ÂÄã‰∫∫ÂåñË∂ä‰æÜË∂äÊÑüËààË∂£Ôºå‰ª§‰∫∫ÊÑüÂà∞ÊåØÂ•Æ„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑËëó‰ΩúÂ∏∏‰æùË≥¥ LLM ‰ΩúÁÇ∫Ë©ï‰º∞ÁöÑË©ïÂà§ËÄÖÔºåËÄåÊú™ÂæπÂ∫ïÊ™¢Ë¶ñÂÖ∂ÊúâÊïàÊÄß„ÄÇÂú®Êú¨Ë´ñÊñá‰∏≠ÔºåÊàëÂÄëË™øÊü•‰∫Ü LLM ‰ΩúÁÇ∫ÂÄã‰∫∫ÂåñË©ïÂà§ËÄÖÁöÑÂèØÈù†ÊÄßÔºåË¶ÅÊ±Ç LLM Ê†πÊìöËßíËâ≤‰æÜÂà§Êñ∑‰ΩøÁî®ËÄÖÁöÑÂÅèÂ•Ω„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåÁõ¥Êé•ÊáâÁî® LLM ‰ΩúÁÇ∫ÂÄã‰∫∫ÂåñË©ïÂà§ËÄÖÔºåÂÖ∂ÂèØÈù†ÊÄß‰ΩéÊñºÂÖàÂâçÁöÑÂÅáË®≠ÔºåËàá‰∫∫È°ûÁöÑÁúüÂØ¶ÊÉÖÊ≥ÅÈ°ØÁ§∫Âá∫‰Ωé‰∏î‰∏ç‰∏ÄËá¥ÁöÑÁõ∏Á¨¶ÊÄß„ÄÇÈÄöÂ∏∏ÊâÄ‰ΩøÁî®ÁöÑËßíËâ≤ÂæÄÂæÄÈÅéÊñºÁ∞°ÂåñÔºåÂ∞éËá¥È†êÊ∏¨ËÉΩÂäõ‰Ωé„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÂú® LLM ‰ΩúÁÇ∫ÂÄã‰∫∫ÂåñË©ïÂà§ËÄÖÁöÑÁÆ°Á∑ö‰∏≠ÂºïÂÖ•‰∫ÜÂè£È†≠‰∏çÁ¢∫ÂÆöÊÄßË©ï‰º∞ÔºåËÆìÊ®°ÂûãËÉΩÂ§†Â∞ç‰∏çÁ¢∫ÂÆöÁöÑÂà§Êñ∑Ë°®ÈÅî‰Ωé‰ø°ÂøÉ„ÄÇÊ≠§Ë™øÊï¥Â∞éËá¥‰∫åÂÖÉ‰ªªÂãô‰∏≠Â∞çÈ´òÁ¢∫ÂÆöÊÄßÊ®£Êú¨ÁöÑÁõ∏Á¨¶ÊÄßÂ§ßÂπÖÊèêÂçá (Ë∂ÖÈÅé 80%)„ÄÇÈÄèÈÅé‰∫∫ÁÇ∫Ë©ï‰º∞ÔºåÊàëÂÄëÁôºÁèæ LLM ‰ΩúÁÇ∫ÂÄã‰∫∫ÂåñË©ïÂà§ËÄÖÈÅîÂà∞‰∫ÜËàáÁ¨¨‰∏âÊñπ‰∫∫È°ûË©ï‰º∞Áõ∏Áï∂ÁöÑË°®ÁèæÔºåÁîöËá≥Âú®È´òÁ¢∫ÂÆöÊÄßÊ®£Êú¨‰∏äË∂ÖË∂ä‰∫Ü‰∫∫È°ûË°®Áèæ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÊåáÂá∫ÔºåÁ¢∫ÂÆöÊÄßÂ¢ûÂº∑ÁöÑ LLM ‰ΩúÁÇ∫ÂÄã‰∫∫ÂåñË©ïÂà§ËÄÖÁÇ∫ÈñãÁôºÊõ¥ÂèØÈù†‰∏îÂèØÊì¥ÂÖÖÁöÑÊñπÊ≥ï‰æÜË©ï‰º∞ LLM ÂÄã‰∫∫ÂåñÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂâçÈÄîÁöÑÊñπÂêë„ÄÇ

##### **A Two-dimensional Zero-shot Dialogue State Tracking Evaluation Method using GPT-4**
2406.11651v1 by Ming Gu, Yan Yang

Dialogue state tracking (DST) is evaluated by exact matching methods, which
rely on large amounts of labeled data and ignore semantic consistency, leading
to over-evaluation. Currently, leveraging large language models (LLM) in
evaluating natural language processing tasks has achieved promising results.
However, using LLM for DST evaluation is still under explored. In this paper,
we propose a two-dimensional zero-shot evaluation method for DST using GPT-4,
which divides the evaluation into two dimensions: accuracy and completeness.
Furthermore, we also design two manual reasoning paths in prompting to further
improve the accuracy of evaluation. Experimental results show that our method
achieves better performance compared to the baselines, and is consistent with
traditional exact matching based methods.

ÊëòË¶ÅÔºöÂ∞çË©±ÁãÄÊÖãËøΩËπ§ (DST) ÊòØÁî±Á≤æÁ¢∫ÊØîÂ∞çÊñπÊ≥ïË©ï‰º∞ÔºåÂÆÉ‰æùË≥¥Â§ßÈáèÁöÑÊ®ôÁ±§Ë≥áÊñôÔºå‰∏¶ÂøΩÁï•Ë™ûÊÑè‰∏ÄËá¥ÊÄßÔºåÈÄôÂ∞éËá¥Ë©ï‰º∞ÈÅéÈ´ò„ÄÇÁõÆÂâçÔºåÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜË©ï‰º∞Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãôÂ∑≤ÂèñÂæó‰ª§‰∫∫ÊªøÊÑèÁöÑÁµêÊûú„ÄÇÁÑ∂ËÄåÔºå‰ΩøÁî® LLM ÈÄ≤Ë°å DST Ë©ï‰º∞‰ªçËôïÊñºÊé¢Á¥¢ÈöéÊÆµ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄã‰ΩøÁî® GPT-4 ÁöÑ‰∫åÁ∂≠Èõ∂Ê¨°Ë©ï‰º∞ÊñπÊ≥ïÔºåÂ∞áË©ï‰º∞ÂàÜÁÇ∫ÂÖ©ÂÄãÈù¢ÂêëÔºöÊ∫ñÁ¢∫ÊÄßÂíåÂÆåÊï¥ÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÇÑË®≠Ë®à‰∫ÜÂÖ©ÂÄãÊâãÂãïÊé®ÁêÜË∑ØÂæëÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•ÊèêÈ´òË©ï‰º∞ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåËàáÂü∫Á∑öÁõ∏ÊØîÔºåÊàëÂÄëÁöÑË©ï‰º∞ÊñπÊ≥ïË°®ÁèæÊõ¥Â•ΩÔºå‰∏¶‰∏îËàáÂÇ≥Áµ±ÁöÑÂü∫ÊñºÁ≤æÁ¢∫ÊØîÂ∞çÁöÑÊñπÊ≥ï‰∏ÄËá¥„ÄÇ

##### **YOLO-FEDER FusionNet: A Novel Deep Learning Architecture for Drone Detection**
2406.11641v1 by Tamara R. Lenhard, Andreas Weinmann, Stefan J√§ger, Tobias Koch

Predominant methods for image-based drone detection frequently rely on
employing generic object detection algorithms like YOLOv5. While proficient in
identifying drones against homogeneous backgrounds, these algorithms often
struggle in complex, highly textured environments. In such scenarios, drones
seamlessly integrate into the background, creating camouflage effects that
adversely affect the detection quality. To address this issue, we introduce a
novel deep learning architecture called YOLO-FEDER FusionNet. Unlike
conventional approaches, YOLO-FEDER FusionNet combines generic object detection
methods with the specialized strength of camouflage object detection techniques
to enhance drone detection capabilities. Comprehensive evaluations of
YOLO-FEDER FusionNet show the efficiency of the proposed model and demonstrate
substantial improvements in both reducing missed detections and false alarms.

ÊëòË¶ÅÔºöÂü∫ÊñºÂΩ±ÂÉèÁöÑÁÑ°‰∫∫Ê©üÂÅµÊ∏¨ÁöÑÂ∏∏Ë¶ãÊñπÊ≥ïÁ∂ìÂ∏∏‰æùË≥¥‰ΩøÁî® YOLOv5 Á≠âÈÄöÁî®Áâ©‰ª∂ÂÅµÊ∏¨ÊºîÁÆóÊ≥ï„ÄÇÈÄô‰∫õÊºîÁÆóÊ≥ïÈõñÁÑ∂Á≤æÊñºÂú®ÂùáÂãªËÉåÊôØ‰∏≠Ëæ®Ë≠òÁÑ°‰∫∫Ê©üÔºå‰ΩÜÂú®Ë§áÈõú„ÄÅÁ¥ãÁêÜË±êÂØåÁöÑÁí∞Â¢É‰∏≠ÂçªÂ∏∏Â∏∏Âäõ‰∏çÂæûÂøÉ„ÄÇÂú®ÈÄôÁ®ÆÊÉÖÊ≥Å‰∏ãÔºåÁÑ°‰∫∫Ê©üËÉΩÁÑ°Á∏´ËûçÂÖ•ËÉåÊôØÔºåÁî¢ÁîüÂÅΩË£ùÊïàÊûúÔºåÂ∞çÂÅµÊ∏¨ÂìÅË≥™ÈÄ†ÊàêË≤†Èù¢ÂΩ±Èüø„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÈÄ≤‰∏ÄÁ®ÆÁ®±ÁÇ∫ YOLO-FEDER FusionNet ÁöÑÂâµÊñ∞Ê∑±Â∫¶Â≠∏ÁøíÊû∂Êßã„ÄÇËàáÂÇ≥Áµ±ÊñπÊ≥ï‰∏çÂêåÔºåYOLO-FEDER FusionNet ÁµêÂêà‰∫ÜÈÄöÁî®Áâ©‰ª∂ÂÅµÊ∏¨ÊñπÊ≥ïËàáÂÅΩË£ùÁâ©‰ª∂ÂÅµÊ∏¨ÊäÄË°ìÁöÑÂ∞àÈñÄÂÑ™Âã¢Ôºå‰ª•Â¢ûÂº∑ÁÑ°‰∫∫Ê©üÂÅµÊ∏¨ËÉΩÂäõ„ÄÇÂ∞ç YOLO-FEDER FusionNet ÁöÑÂÖ®Èù¢Ë©ï‰º∞È°ØÁ§∫‰∫ÜÊâÄÊèêË≠∞Ê®°ÂûãÁöÑÊïàÁéáÔºå‰∏¶Ë≠âÊòéÂú®Ê∏õÂ∞ëÊºèÂÅµÊ∏¨ÂíåË™§Â†±ÊñπÈù¢ÈÉΩÊúâÈ°ØËëóÁöÑÊîπÂñÑ„ÄÇ

##### **Linear Bellman Completeness Suffices for Efficient Online Reinforcement Learning with Few Actions**
2406.11640v1 by Noah Golowich, Ankur Moitra

One of the most natural approaches to reinforcement learning (RL) with
function approximation is value iteration, which inductively generates
approximations to the optimal value function by solving a sequence of
regression problems. To ensure the success of value iteration, it is typically
assumed that Bellman completeness holds, which ensures that these regression
problems are well-specified. We study the problem of learning an optimal policy
under Bellman completeness in the online model of RL with linear function
approximation. In the linear setting, while statistically efficient algorithms
are known under Bellman completeness (e.g., Jiang et al. (2017); Zanette et al.
(2020)), these algorithms all rely on the principle of global optimism which
requires solving a nonconvex optimization problem. In particular, it has
remained open as to whether computationally efficient algorithms exist. In this
paper we give the first polynomial-time algorithm for RL under linear Bellman
completeness when the number of actions is any constant.

ÊëòË¶ÅÔºöÂú®‰ΩøÁî®ÂáΩÊï∏ÈÄºËøëÈÄ≤Ë°åÂº∑ÂåñÂ≠∏Áøí (RL) ÊôÇÔºåÊúÄËá™ÁÑ∂ÁöÑÂÖ∂‰∏≠‰∏ÄÁ®ÆÊñπÊ≥ïÊòØÂÉπÂÄºËø≠‰ª£ÔºåÂÆÉÈÄèÈÅéËß£‰∏ÄÁ≥ªÂàóÂõûÊ≠∏ÂïèÈ°åÔºå‰ª•Ê≠∏Á¥çÊñπÂºèÁî¢ÁîüÂ∞çÊúÄ‰Ω≥ÂÉπÂÄºÂáΩÊï∏ÁöÑÈÄºËøë„ÄÇÁÇ∫‰∫ÜÁ¢∫‰øùÂÉπÂÄºËø≠‰ª£ÁöÑÊàêÂäüÔºåÈÄöÂ∏∏ÂÅáË®≠Ë≤ùÁàæÊõºÂÆåÂÇôÊÄßÊàêÁ´ãÔºåÈÄôÁ¢∫‰øù‰∫ÜÈÄô‰∫õÂõûÊ≠∏ÂïèÈ°åÊúâÊòéÁ¢∫ÁöÑË¶èÁØÑ„ÄÇÊàëÂÄëÁ†îÁ©∂Âú®Á∑ö RL Ê®°Âûã‰∏≠ÔºåÂú®Ë≤ùÁàæÊõºÂÆåÂÇôÊÄß‰∏ãÂ≠∏ÁøíÊúÄ‰Ω≥Á≠ñÁï•ÁöÑÂïèÈ°åÔºå‰∏¶‰ΩøÁî®Á∑öÊÄßÂáΩÊï∏ÈÄºËøë„ÄÇÂú®Á∑öÊÄßË®≠ÂÆö‰∏≠ÔºåÈõñÁÑ∂Âú®Ë≤ùÁàæÊõºÂÆåÂÇôÊÄß‰∏ãÂ∑≤Áü•Áµ±Ë®à‰∏äÊúâÊïàÁéáÁöÑÊºîÁÆóÊ≥ïÔºà‰æãÂ¶ÇÔºåJiang Á≠â‰∫∫ (2017)ÔºõZanette Á≠â‰∫∫ (2020)ÔºâÔºå‰ΩÜÈÄô‰∫õÊºîÁÆóÊ≥ïÈÉΩ‰æùË≥¥ÊñºÊï¥È´îÊ®ÇËßÄÂéüÂâáÔºåÈÄôÈúÄË¶ÅËß£‰∏ÄÂÄãÈùûÂá∏ÊúÄ‰Ω≥ÂåñÂïèÈ°å„ÄÇÁâπÂà•ÊòØÔºåË®àÁÆó‰∏äÊúâÊïàÁéáÁöÑÊºîÁÆóÊ≥ïÊòØÂê¶Â≠òÂú®Ôºå‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÊú™Ëß£ÁöÑÂïèÈ°å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁµ¶Âá∫‰∫ÜÂú®Á∑öÊÄßË≤ùÁàæÊõºÂÆåÂÇôÊÄß‰∏ã RL ÁöÑÁ¨¨‰∏ÄÂÄãÂ§öÈ†ÖÂºèÊôÇÈñìÊºîÁÆóÊ≥ïÔºåÂÖ∂‰∏≠Âãï‰ΩúÊï∏ÈáèÁÇ∫‰ªªÊÑèÂ∏∏Êï∏„ÄÇ

##### **MASAI: Modular Architecture for Software-engineering AI Agents**
2406.11638v1 by Daman Arora, Atharv Sonwane, Nalin Wadhwa, Abhav Mehrotra, Saiteja Utpala, Ramakrishna Bairi, Aditya Kanade, Nagarajan Natarajan

A common method to solve complex problems in software engineering, is to
divide the problem into multiple sub-problems. Inspired by this, we propose a
Modular Architecture for Software-engineering AI (MASAI) agents, where
different LLM-powered sub-agents are instantiated with well-defined objectives
and strategies tuned to achieve those objectives. Our modular architecture
offers several advantages: (1) employing and tuning different problem-solving
strategies across sub-agents, (2) enabling sub-agents to gather information
from different sources scattered throughout a repository, and (3) avoiding
unnecessarily long trajectories which inflate costs and add extraneous context.
MASAI enabled us to achieve the highest performance (28.33% resolution rate) on
the popular and highly challenging SWE-bench Lite dataset consisting of 300
GitHub issues from 11 Python repositories. We conduct a comprehensive
evaluation of MASAI relative to other agentic methods and analyze the effects
of our design decisions and their contribution to the success of MASAI.

ÊëòË¶ÅÔºöÂú®ËªüÈ´îÂ∑•Á®ã‰∏≠ÔºåËß£Ê±∫Ë§áÈõúÂïèÈ°åÁöÑ‰∏ÄÁ®ÆÂ∏∏Ë¶ãÊñπÊ≥ïÔºåÊòØÂ∞áÂïèÈ°åÂàÜËß£ÊàêÂ§öÂÄãÂ≠êÂïèÈ°å„ÄÇÂèóÂà∞Ê≠§ÂïüÁôºÔºåÊàëÂÄëÊèêÂá∫ËªüÈ´îÂ∑•Á®ã AIÔºàMASAIÔºâ‰ª£ÁêÜÊ®°ÁµÑÂåñÊû∂ÊßãÔºåÂÖ∂‰∏≠‰∏çÂêåÁöÑ LLM È©ÖÂãïÂ≠ê‰ª£ÁêÜÊúÉ‰ª•ÊòéÁ¢∫ÁöÑÁõÆÊ®ôÂíåÁ≠ñÁï•ÂØ¶‰æãÂåñÔºå‰ª•ÈÅîÊàêÈÄô‰∫õÁõÆÊ®ô„ÄÇÊàëÂÄëÁöÑÊ®°ÁµÑÂåñÊû∂ÊßãÊèê‰æõ‰∫ÜÂ§öÈ†ÖÂÑ™ÈªûÔºö(1) Êé°Áî®ÂíåË™øÊï¥Ë∑®Â≠ê‰ª£ÁêÜÁöÑ‰∏çÂêåÂïèÈ°åËß£Ê±∫Á≠ñÁï•Ôºå(2) ËÆìÂ≠ê‰ª£ÁêÜÂæûÊï£‰ΩàÂú®Êï¥ÂÄãÂÑ≤Â≠òÂ∫´ÁöÑ‰∏çÂêå‰æÜÊ∫êÊî∂ÈõÜË≥áË®äÔºå‰ª•Âèä (3) ÈÅøÂÖç‰∏çÂøÖË¶ÅÁöÑÈï∑ËªåË∑°ÔºåÈÄôÊúÉÂ¢ûÂä†ÊàêÊú¨‰∏¶Â¢ûÂä†ÁÑ°ÈóúÁöÑÂÖßÂÆπ„ÄÇMASAI ËÆìÊàëÂÄëÂú®Áî±‰æÜËá™ 11 ÂÄã Python ÂÑ≤Â≠òÂ∫´ÁöÑ 300 ÂÄã GitHub ÂïèÈ°åÁµÑÊàêÁöÑÁÜ±ÈñÄ‰∏îÊ•µÂÖ∑ÊåëÊà∞ÊÄßÁöÑ SWE-bench Lite Ë≥áÊñôÈõÜ‰∏äÔºåÈÅîÂà∞ÊúÄÈ´òÊïàËÉΩÔºà28.33% Ëß£ÊûêÁéáÔºâ„ÄÇÊàëÂÄëÂ∞ç MASAI Áõ∏Â∞çÊñºÂÖ∂‰ªñ‰ª£ÁêÜÊñπÊ≥ïÈÄ≤Ë°åÂÖ®Èù¢Ë©ï‰º∞Ôºå‰∏¶ÂàÜÊûêÊàëÂÄëÁöÑË®≠Ë®àÊ±∫Á≠ñÂèäÂÖ∂Â∞ç MASAI ÊàêÂäüÊâÄÂÅöÁöÑË≤¢Áçª„ÄÇ

##### **The Base-Rate Effect on LLM Benchmark Performance: Disambiguating Test-Taking Strategies from Benchmark Performance**
2406.11634v1 by Kyle Moore, Jesse Roberts, Thao Pham, Oseremhen Ewaleifoh, Doug Fisher

Cloze testing is a common method for measuring the behavior of large language
models on a number of benchmark tasks. Using the MMLU dataset, we show that the
base-rate probability (BRP) differences across answer tokens are significant
and affect task performance ie. guess A if uncertain. We find that
counterfactual prompting does sufficiently mitigate the BRP effect. The BRP
effect is found to have a similar effect to test taking strategies employed by
humans leading to the conflation of task performance and test-taking ability.
We propose the Nvr-X-MMLU task, a variation of MMLU, which helps to
disambiguate test-taking ability from task performance and reports the latter.

ÊëòË¶ÅÔºöÂÆåÂΩ¢Â°´Á©∫Ê∏¨Ë©¶ÊòØ‰∏ÄÁ®ÆÂ∏∏Ë¶ãÁöÑÊñπÊ≥ïÔºåÁî®ÊñºË°°ÈáèÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®Ë®±Â§öÂü∫Ê∫ñ‰ªªÂãô‰∏äÁöÑË°åÁÇ∫„ÄÇ‰ΩøÁî® MMLU Ë≥áÊñôÈõÜÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÁ≠îÊ°àÁ¨¶Ëôü‰πãÈñìÁöÑÂü∫Á§éÊ©üÁéá (BRP) Â∑ÆÁï∞ÂÖ∑ÊúâÈ°ØËëóÊÑèÁæ©Ôºå‰∏¶ÂΩ±Èüø‰ªªÂãôÂü∑Ë°åÔºå‰æãÂ¶ÇÂú®‰∏çÁ¢∫ÂÆöÊôÇÁåúÊ∏¨ A„ÄÇÊàëÂÄëÁôºÁèæÂèç‰∫ãÂØ¶ÊèêÁ§∫Á¢∫ÂØ¶ÂèØ‰ª•ÂÖÖÂàÜÊ∏õËºï BRP ÊïàÊáâ„ÄÇÁôºÁèæ BRP ÊïàÊáâÂ∞ç‰∫∫È°ûÊé°Áî®ÁöÑÊáâË©¶Á≠ñÁï•ÂÖ∑ÊúâÈ°û‰ººÁöÑÊïàÊáâÔºåÂ∞éËá¥‰ªªÂãôÂü∑Ë°åÂíåÊáâË©¶ËÉΩÂäõÊ∑∑Ê∑Ü„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü Nvr-X-MMLU ‰ªªÂãôÔºåÈÄôÊòØ MMLU ÁöÑ‰∏ÄÁ®ÆËÆäÈ´îÔºåÊúâÂä©ÊñºÊ∂àÈô§ÊáâË©¶ËÉΩÂäõËàá‰ªªÂãôÂü∑Ë°å‰πãÈñìÁöÑÊ≠ßÁæ©Ôºå‰∏¶Â†±ÂëäÂæåËÄÖ„ÄÇ

##### **Unveiling the Power of Source: Source-based Minimum Bayes Risk Decoding for Neural Machine Translation**
2406.11632v1 by Boxuan Lyu, Hidetaka Kamigaito, Kotaro Funakoshi, Manabu Okumura

Maximum a posteriori decoding, a commonly used method for neural machine
translation (NMT), aims to maximize the estimated posterior probability.
However, high estimated probability does not always lead to high translation
quality. Minimum Bayes Risk (MBR) decoding offers an alternative by seeking
hypotheses with the highest expected utility.
  In this work, we show that Quality Estimation (QE) reranking, which uses a QE
model as a reranker, can be viewed as a variant of MBR. Inspired by this, we
propose source-based MBR (sMBR) decoding, a novel approach that utilizes
synthetic sources generated by backward translation as ``support hypotheses''
and a reference-free quality estimation metric as the utility function, marking
the first work to solely use sources in MBR decoding. Experiments show that
sMBR significantly outperforms QE reranking and is competitive with standard
MBR decoding. Furthermore, sMBR calls the utility function fewer times compared
to MBR. Our findings suggest that sMBR is a promising approach for high-quality
NMT decoding.

ÊëòË¶ÅÔºöÊúÄÂ§ßÂæåÈ©óËß£Á¢ºÊòØÁ•ûÁ∂ìÊ©üÂô®ÁøªË≠ØÔºàNMTÔºâ‰∏≠Â∏∏Áî®ÁöÑÊñπÊ≥ïÔºåÊó®Âú®ÊúÄÂ§ßÂåñ‰º∞Ë®àÂæåÈ©óÊ©üÁéá„ÄÇ
ÁÑ∂ËÄåÔºåÈ´ò‰º∞Ë®àÊ©üÁéá‰∏¶‰∏çÁ∏ΩÊòØËÉΩÂ∏∂‰æÜÈ´òÁøªË≠ØÂìÅË≥™„ÄÇÊúÄÂ∞èË≤ùÊ∞èÈ¢®Èö™ÔºàMBRÔºâËß£Á¢ºÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊõø‰ª£ÊñπÊ°àÔºåÊñπÊ≥ïÊòØÂ∞ãÊâæÂÖ∑ÊúâÊúÄÈ´òÈ†êÊúüÊïàÁî®ÁöÑÂÅáË®≠„ÄÇ
Âú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëË™™ÊòéÂìÅË≥™Ë©ï‰º∞ÔºàQEÔºâÈáçÊñ∞ÊéíÂ∫èÔºà‰ΩøÁî® QE Ê®°Âûã‰ΩúÁÇ∫ÈáçÊñ∞ÊéíÂ∫èÂô®ÔºâÂèØ‰ª•Ë¶ñÁÇ∫ MBR ÁöÑ‰∏ÄÁ®ÆËÆäÈ´î„ÄÇÂèóÂà∞Ê≠§ÂïüÁôºÔºåÊàëÂÄëÊèêÂá∫Âü∫Êñº‰æÜÊ∫êÁöÑ MBRÔºàsMBRÔºâËß£Á¢ºÔºå‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÂà©Áî®ÂèçÂêëÁøªË≠ØÁî¢ÁîüÁöÑÂêàÊàê‰æÜÊ∫ê‰ΩúÁÇ∫„ÄåÊîØÊè¥ÂÅáË®≠„ÄçÔºå‰∏¶‰ΩøÁî®ÁÑ°ÂèÉËÄÉÂìÅË≥™Ë©ï‰º∞ÊåáÊ®ô‰ΩúÁÇ∫ÊïàÁî®ÂáΩÊï∏ÔºåÊ®ôÁ§∫Âá∫ÂÉÖÂú® MBR Ëß£Á¢º‰∏≠‰ΩøÁî®‰æÜÊ∫êÁöÑÁ¨¨‰∏ÄÈ†ÖÂ∑•‰Ωú„ÄÇÂØ¶È©óÈ°ØÁ§∫ÔºåsMBR ÊòéÈ°ØÂÑ™Êñº QE ÈáçÊñ∞ÊéíÂ∫èÔºå‰∏¶‰∏îËàáÊ®ôÊ∫ñ MBR Ëß£Á¢ºÂÖ∑ÊúâÁ´∂Áà≠Âäõ„ÄÇÊ≠§Â§ñÔºåËàá MBR Áõ∏ÊØîÔºåsMBR ÂëºÂè´ÊïàÁî®ÂáΩÊï∏ÁöÑÊ¨°Êï∏ËºÉÂ∞ë„ÄÇÊàëÂÄëÁöÑÁôºÁèæË°®ÊòéÔºåsMBR ÊòØ‰∏ÄÁ®ÆÊúâÊúõÁî®ÊñºÈ´òÂìÅË≥™ NMT Ëß£Á¢ºÁöÑÊñπÊ≥ï„ÄÇ

##### **Can Many-Shot In-Context Learning Help Long-Context LLM Judges? See More, Judge Better!**
2406.11629v1 by Mingyang Song, Mao Zheng, Xuan Luo

Leveraging Large Language Models (LLMs) as judges for evaluating the
performance of LLMs has recently garnered attention. Nonetheless, this type of
approach concurrently introduces potential biases from LLMs, raising concerns
about the reliability of the evaluation results. To mitigate this issue, we
propose and study two versions of many-shot in-context prompts, Reinforced and
Unsupervised ICL, for helping GPT-4o-as-a-Judge in single answer grading. Based
on the designed prompts, we investigate the impact of scaling the number of
in-context examples on the agreement and quality of the evaluation.
Furthermore, we first reveal the symbol bias in GPT-4o-as-a-Judge for pairwise
comparison and then propose a simple yet effective approach to mitigate it.
Experimental results show that advanced long-context LLMs, such as GPT-4o,
perform better in the many-shot regime than in the zero-shot regime. Meanwhile,
the experimental results further verify the effectiveness of the symbol bias
mitigation approach.

ÊëòË¶ÅÔºöÂà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ‰Ωú‰∏∫ËØÑÂßîÊù•ËØÑ‰º∞ LLM ÁöÑÊÄßËÉΩÊúÄËøëÂºïËµ∑‰∫ÜÂÖ≥Ê≥®„ÄÇÂ∞ΩÁÆ°Â¶ÇÊ≠§ÔºåËøôÁßçÁ±ªÂûãÁöÑËØÑ‰º∞ÂêåÊó∂ÂºïÂÖ•‰∫Ü LLM ÁöÑÊΩúÂú®ÂÅèÂ∑ÆÔºåÂºïËµ∑‰∫Ü‰∫∫‰ª¨ÂØπËØÑ‰º∞ÁªìÊûúÂèØÈù†ÊÄßÁöÑÊãÖÂøß„ÄÇ‰∏∫‰∫ÜÁºìËß£Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏§ÁßçÁâàÊú¨ÁöÑÂ§öÈïúÂ§¥‰∏ä‰∏ãÊñáÊèêÁ§∫ÔºåÂº∫ÂåñÂíåÊó†ÁõëÁù£ ICLÔºå‰ª•Â∏ÆÂä© GPT-4o-as-a-Judge ËøõË°åÂçï‰∏ÄÁ≠îÊ°àËØÑÂàÜ„ÄÇÂü∫‰∫éËÆæËÆ°ÁöÑÊèêÁ§∫ÔºåÊàë‰ª¨Á†îÁ©∂‰∫ÜÊâ©Â±ï‰∏ä‰∏ãÊñáÁ§∫‰æãÊï∞ÈáèÂØπËØÑ‰º∞ÁöÑ‰∏ÄËá¥ÊÄßÂíåË¥®ÈáèÁöÑÂΩ±Âìç„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨È¶ñÂÖàÊè≠Á§∫‰∫Ü GPT-4o-as-a-Judge Âú®ÊàêÂØπÊØîËæÉ‰∏≠ÁöÑÁ¨¶Âè∑ÂÅèÂ∑ÆÔºåÁÑ∂ÂêéÊèêÂá∫‰∫Ü‰∏ÄÁßçÁÆÄÂçï‰ΩÜÊúâÊïàÁöÑÊñπÊ≥ïÊù•ÁºìËß£ÂÆÉ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÂÖàËøõÁöÑÈïø‰∏ä‰∏ãÊñá LLMÔºå‰æãÂ¶Ç GPT-4oÔºåÂú®Â§öÈïúÂ§¥Ê®°Âºè‰∏ãÁöÑË°®Áé∞‰ºò‰∫éÈõ∂ÈïúÂ§¥Ê®°Âºè„ÄÇÂêåÊó∂ÔºåÂÆûÈ™åÁªìÊûúËøõ‰∏ÄÊ≠•È™åËØÅ‰∫ÜÁ¨¶Âè∑ÂÅèÂ∑ÆÁºìËß£ÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Words in Motion: Representation Engineering for Motion Forecasting**
2406.11624v1 by Omer Sahin Tas, Royden Wagner

Motion forecasting transforms sequences of past movements and environment
context into future motion. Recent methods rely on learned representations,
resulting in hidden states that are difficult to interpret. In this work, we
use natural language to quantize motion features in a human-interpretable way,
and measure the degree to which they are embedded in hidden states. Our
experiments reveal that hidden states of motion sequences are arranged with
respect to our discrete sets of motion features. Following these insights, we
fit control vectors to motion features, which allow for controlling motion
forecasts at inference. Consequently, our method enables controlling
transformer-based motion forecasting models with textual inputs, providing a
unique interface to interact with and understand these models. Our
implementation is available at https://github.com/kit-mrt/future-motion

ÊëòË¶ÅÔºöÂãï‰ΩúÈ†êÊ∏¨Â∞áÈÅéÂéªÂãï‰ΩúÂíåÁí∞Â¢ÉËÉåÊôØÂ∫èÂàóËΩâÊèõÁÇ∫Êú™‰æÜÂãï‰Ωú„ÄÇÊúÄËøëÁöÑÊñπÊ≥ï‰æùË≥¥ÊñºÂ≠∏ÁøíË°®ÂæµÔºåÂ∞éËá¥Èõ£‰ª•Ëß£ÈáãÁöÑÈö±ËóèÁãÄÊÖã„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ΩøÁî®Ëá™ÁÑ∂Ë™ûË®Ä‰ª•‰∫∫È°ûÂèØËß£ÈáãÁöÑÊñπÂºèÈáèÂåñÂãï‰ΩúÁâπÂæµÔºå‰∏¶Ë°°ÈáèÂÆÉÂÄëÂµåÂÖ•Èö±ËóèÁãÄÊÖãÁöÑÁ®ãÂ∫¶„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåÂãï‰ΩúÂ∫èÂàóÁöÑÈö±ËóèÁãÄÊÖãÊ†πÊìöÊàëÂÄëÈõ¢Êï£ÁöÑÂãï‰ΩúÁâπÂæµÈõÜÈÄ≤Ë°åÊéíÂàó„ÄÇÊ†πÊìöÈÄô‰∫õË¶ãËß£ÔºåÊàëÂÄëÂ∞áÊéßÂà∂ÂêëÈáèÊì¨ÂêàÂà∞Âãï‰ΩúÁâπÂæµÔºåÈÄôÂÖÅË®±Âú®Êé®ÁêÜÊôÇÊéßÂà∂Âãï‰ΩúÈ†êÊ∏¨„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÁöÑÊñπ‰ΩøÊàëÂÄëËÉΩÂ§†‰ΩøÁî®ÊñáÊú¨Ëº∏ÂÖ•ÊéßÂà∂Âü∫ÊñºËΩâÊèõÂô®ÁöÑÂãï‰ΩúÈ†êÊ∏¨Ê®°ÂûãÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãËàáÈÄô‰∫õÊ®°Âûã‰∫íÂãïÂíåÁêÜËß£ÁöÑÁç®Áâπ‰ªãÈù¢„ÄÇÊàëÂÄëÁöÑÂØ¶‰ΩúÂèØÂú® https://github.com/kit-mrt/future-motion ÂèñÂæó

##### **Building Knowledge-Guided Lexica to Model Cultural Variation**
2406.11622v1 by Shreya Havaldar, Salvatore Giorgi, Sunny Rai, Thomas Talhelm, Sharath Chandra Guntuku, Lyle Ungar

Cultural variation exists between nations (e.g., the United States vs.
China), but also within regions (e.g., California vs. Texas, Los Angeles vs.
San Francisco). Measuring this regional cultural variation can illuminate how
and why people think and behave differently. Historically, it has been
difficult to computationally model cultural variation due to a lack of training
data and scalability constraints. In this work, we introduce a new research
problem for the NLP community: How do we measure variation in cultural
constructs across regions using language? We then provide a scalable solution:
building knowledge-guided lexica to model cultural variation, encouraging
future work at the intersection of NLP and cultural understanding. We also
highlight modern LLMs' failure to measure cultural variation or generate
culturally varied language.

ÊëòË¶ÅÔºöÊñáÂåñÂ∑ÆÁï∞Â≠òÂú®ÊñºÂúãÂÆ∂‰πãÈñìÔºà‰æãÂ¶ÇÁæéÂúãËàá‰∏≠ÂúãÔºâÔºå‰πüÂ≠òÂú®ÊñºÂú∞ÂçÄ‰πãÈñìÔºà‰æãÂ¶ÇÂä†Â∑ûËàáÂæ∑Â∑ûÔºåÊ¥õÊùâÁ£ØËàáËàäÈáëÂ±±Ôºâ„ÄÇË°°ÈáèÈÄôÁ®ÆÂçÄÂüüÊñáÂåñÂ∑ÆÁï∞ÂèØ‰ª•Èó°Êòé‰∫∫ÂÄëÊÄùËÄÉÂíåË°åÁÇ∫ÊñπÂºè‰∏çÂêåÁöÑÂéüÂõ†ÂíåÊñπÂºè„ÄÇÁî±ÊñºÁº∫‰πèË®ìÁ∑¥Êï∏ÊìöÂíåÂèØÊì¥ÂÖÖÊÄßÈôêÂà∂ÔºåÂú®Ê≠∑Âè≤‰∏äÔºåË®àÁÆóÊñáÂåñÂ∑ÆÁï∞‰∏ÄÁõ¥ÂæàÂõ∞Èõ£„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÁÇ∫ NLP Á§æÁæ§ÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÁ†îÁ©∂ÂïèÈ°åÔºöÊàëÂÄëÂ¶Ç‰Ωï‰ΩøÁî®Ë™ûË®Ä‰æÜË°°Èáè‰∏çÂêåÂú∞ÂçÄÊñáÂåñÂª∫ÊßãÁöÑÂ∑ÆÁï∞ÔºüÁÑ∂ÂæåÊàëÂÄëÊèê‰æõ‰∏ÄÂÄãÂèØÊì¥ÂÖÖÁöÑËß£Ê±∫ÊñπÊ°àÔºöÂª∫ÊßãÁü•Ë≠òÂºïÂ∞éÁöÑË©ûÂΩô‰æÜÂª∫Ê®°ÊñáÂåñÂ∑ÆÁï∞ÔºåÈºìÂãµÂú® NLP ÂíåÊñáÂåñÁêÜËß£ÁöÑ‰∫§ÈõÜ‰∏≠ÈÄ≤Ë°åÊú™‰æÜÁöÑÁ†îÁ©∂„ÄÇÊàëÂÄë‰πüÂº∑Ë™øÁèæ‰ª£ LLM ÁÑ°Ê≥ïË°°ÈáèÊñáÂåñÂ∑ÆÁï∞ÊàñÁî¢ÁîüÊñáÂåñÂ§öÊ®£ÂåñÁöÑË™ûË®Ä„ÄÇ

##### **DELLA-Merging: Reducing Interference in Model Merging through Magnitude-Based Sampling**
2406.11617v1 by Pala Tej Deep, Rishabh Bhardwaj, Soujanya Poria

With the proliferation of domain-specific models, model merging has emerged
as a set of techniques that combine the capabilities of multiple models into
one that can multitask without the cost of additional training. In this paper,
we propose a new model merging technique, Drop and rEscaLe via sampLing with
mAgnitude (DELLA-Merging), that employs a novel pruning technique, MAGPRUNE,
which shows significant advantages over DARE and TIES. MAGPRUNE first ranks the
parameters in order of their magnitude and assigns higher dropout probabilities
(p) to parameters with lower ranks corresponding to lower magnitudes. To
approximate the original embeddings, MAGPRUNE employs a rescaling operation on
the parameters that survive the random dropping by 1/(1 - p). On three
different expert models considered for merging (LM, Math, Code) and
corresponding benchmark datasets (AlpacaEval, GSM8K, MBPP), DELLA shows an
average improvement of 2.4 points over baseline methods employing delta
parameter pruning (an improvement of 3.6 points over TIES, 1.2 points over
DARE), and 11.1 points over the no-pruning baseline (TA). We release the source
code at: https://github.com/declare-lab/della.

ÊëòË¶ÅÔºöÈö®ËëóÁâπÂÆöÈ†òÂüüÊ®°ÂûãÁöÑÊøÄÂ¢ûÔºåÊ®°ÂûãÂêà‰ΩµÂ∑≤ÊàêÁÇ∫‰∏ÄÁµÑÊäÄË°ìÔºåÂÆÉÂ∞áÂ§öÂÄãÊ®°ÂûãÁöÑÂäüËÉΩÁµêÂêàÂà∞‰∏ÄÂÄãÊ®°Âûã‰∏≠ÔºåËÄåÁÑ°ÈúÄÈ°çÂ§ñË®ìÁ∑¥ÊàêÊú¨Âç≥ÂèØÂü∑Ë°åÂ§ö‰ªªÂãô„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊ®°ÂûãÂêà‰ΩµÊäÄË°ìÔºåÂç≥ÈÄöÈÅéÂÖ∑ÊúâÂπÖÂ∫¶ÁöÑÊé°Ê®£ÈÄ≤Ë°åÂà™Èô§ÂíåÁ∏ÆÊîæ (DELLA-Merging)ÔºåÂÆÉÊé°Áî®‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂâ™ÊûùÊäÄË°ì MAGPRUNEÔºåËàá DARE Âíå TIES Áõ∏ÊØîÔºåÂÆÉÈ°ØÁ§∫Âá∫È°ØËëóÁöÑÂÑ™Âã¢„ÄÇMAGPRUNE È¶ñÂÖàÊåâÂπÖÂ∫¶Â∞çÂèÉÊï∏ÈÄ≤Ë°åÊéíÂ∫èÔºå‰∏¶Â∞áËºÉÈ´òÁöÑ‰∏≠Êñ∑Ê©üÁéá (p) ÂàÜÈÖçÁµ¶ÂπÖÂ∫¶ËºÉ‰Ωé„ÄÅÂ∞çÊáâÊñºËºÉ‰ΩéÂπÖÂ∫¶ÁöÑÂèÉÊï∏„ÄÇÁÇ∫‰∫ÜËøë‰ººÂéüÂßãÂµåÂÖ•ÔºåMAGPRUNE Â∞çÈÄöÈÅé 1/(1 - p) Èö®Ê©üÂà™Èô§ËÄåÂ≠òÊ¥ªÁöÑÂèÉÊï∏Êé°Áî®Á∏ÆÊîæÊìç‰Ωú„ÄÇÂ∞çÊñºÂêà‰ΩµËÄÉÊÖÆÁöÑ‰∏âÂÄã‰∏çÂêåÁöÑÂ∞àÂÆ∂Ê®°Âûã (LM„ÄÅMath„ÄÅCode) ÂíåÂ∞çÊáâÁöÑÂü∫Ê∫ñË≥áÊñôÈõÜ (AlpacaEval„ÄÅGSM8K„ÄÅMBPP)ÔºåDELLA È°ØÁ§∫ÊØîÊé°Áî® delta ÂèÉÊï∏Ââ™ÊûùÁöÑÂü∫Êú¨ÊñπÊ≥ïÂπ≥ÂùáÊèêÈ´ò 2.4 ÂàÜÔºàÊØî TIES ÊèêÈ´ò 3.6 ÂàÜÔºåÊØî DARE ÊèêÈ´ò 1.2 ÂàÜÔºâÔºå‰∏¶‰∏îÊØî‰∏çÂâ™ÊûùÁöÑÂü∫Êú¨Á∑ö (TA) È´ò 11.1 ÂàÜ„ÄÇÊàëÂÄëÂú®‰ª•‰∏ã‰ΩçÁΩÆÈáãÂá∫ÂéüÂßãÁ¢ºÔºöhttps://github.com/declare-lab/della„ÄÇ

##### **Intrinsic Evaluation of Unlearning Using Parametric Knowledge Traces**
2406.11614v1 by Yihuai Hong, Lei Yu, Shauli Ravfogel, Haiqin Yang, Mor Geva

The task of "unlearning" certain concepts in large language models (LLMs) has
attracted immense attention recently, due to its importance for mitigating
undesirable model behaviours, such as the generation of harmful, private, or
incorrect information. Current protocols to evaluate unlearning methods largely
rely on behavioral tests, without monitoring the presence of unlearned
knowledge within the model's parameters. This residual knowledge can be
adversarially exploited to recover the erased information post-unlearning. We
argue that unlearning should also be evaluated internally, by considering
changes in the parametric knowledge traces of the unlearned concepts. To this
end, we propose a general methodology for eliciting directions in the parameter
space (termed "concept vectors") that encode concrete concepts, and construct
ConceptVectors, a benchmark dataset containing hundreds of common concepts and
their parametric knowledge traces within two open-source LLMs. Evaluation on
ConceptVectors shows that existing unlearning methods minimally impact concept
vectors, while directly ablating these vectors demonstrably removes the
associated knowledge from the LLMs and significantly reduces their
susceptibility to adversarial manipulation. Our results highlight limitations
in behavioral-based unlearning evaluations and call for future work to include
parametric-based evaluations. To support this, we release our code and
benchmark at https://github.com/yihuaihong/ConceptVectors.

ÊëòË¶ÅÔºö„ÄåÂèñÊ∂àÂ≠∏Áøí„ÄçÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠Êüê‰∫õÊ¶ÇÂøµÁöÑ‰ªªÂãôÊúÄËøëÂÇôÂèóÈóúÊ≥®ÔºåÂõ†ÁÇ∫ÈÄôÂ∞çÊñºÊ∏õËºï‰∏çËâØÁöÑÊ®°ÂûãË°åÁÇ∫Ôºà‰æãÂ¶ÇÁî¢ÁîüÊúâÂÆ≥„ÄÅÁßÅ‰∫∫Êàñ‰∏çÊ≠£Á¢∫ÁöÑË≥áË®äÔºâÈùûÂ∏∏ÈáçË¶Å„ÄÇÁõÆÂâçÁî®ÊñºË©ï‰º∞ÂèñÊ∂àÂ≠∏ÁøíÊñπÊ≥ïÁöÑÂçîÂÆö‰∏ªË¶Å‰æùË≥¥Ë°åÁÇ∫Ê∏¨Ë©¶ÔºåËÄå‰∏çÊúÉÁõ£ÊéßÊ®°ÂûãÂèÉÊï∏‰∏≠Êú™Â≠∏ÁøíÁü•Ë≠òÁöÑÂ≠òÂú®„ÄÇÈÄôÁ®ÆÊÆòÁïôÁü•Ë≠òÂèØ‰ª•Ë¢´Â∞çÊâãÂà©Áî®Ôºå‰ª•‰æøÂú®ÂèñÊ∂àÂ≠∏ÁøíÂæåÊÅ¢Âæ©Â∑≤Âà™Èô§ÁöÑË≥áË®ä„ÄÇÊàëÂÄëË™çÁÇ∫ÂèñÊ∂àÂ≠∏Áøí‰πüÊáâË©≤Âú®ÂÖßÈÉ®ÈÄ≤Ë°åË©ï‰º∞ÔºåÊñπÊ≥ïÊòØËÄÉÊÖÆÊú™Â≠∏ÁøíÊ¶ÇÂøµÁöÑÂèÉÊï∏ÂåñÁü•Ë≠òËªåË∑°ÁöÑËÆäÂåñ„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÈÄöÁî®ÊñπÊ≥ïÔºåÁî®ÊñºÂú®ÂèÉÊï∏Á©∫Èñì‰∏≠ÂºïÂá∫Á∑®Á¢ºÂÖ∑È´îÊ¶ÇÂøµÁöÑÊñπÂêëÔºàÁ®±ÁÇ∫„ÄåÊ¶ÇÂøµÂêëÈáè„ÄçÔºâÔºå‰∏¶Âª∫Êßã ConceptVectorsÔºåÈÄôÊòØ‰∏ÄÂÄãÂü∫Ê∫ñË≥áÊñôÈõÜÔºåÂåÖÂê´Êï∏ÁôæÂÄãÂ∏∏Ë¶ãÊ¶ÇÂøµÂèäÂÖ∂Âú®ÂÖ©ÂÄãÈñãÊ∫ê LLM ‰∏≠ÁöÑÂèÉÊï∏ÂåñÁü•Ë≠òËªåË∑°„ÄÇÂ∞ç ConceptVectors ÁöÑË©ï‰º∞È°ØÁ§∫ÔºåÁèæÊúâÁöÑÂèñÊ∂àÂ≠∏ÁøíÊñπÊ≥ïÂ∞çÊ¶ÇÂøµÂêëÈáèÂΩ±ÈüøÊúÄÂ∞èÔºåËÄåÁõ¥Êé•Ê∂àËûçÈÄô‰∫õÂêëÈáèÂâáÊòéÈ°ØÂæû LLM ‰∏≠ÁßªÈô§‰∫ÜÁõ∏ÈóúÁü•Ë≠òÔºå‰∏¶Â§ßÂπÖÈôç‰Ωé‰∫ÜÂÆÉÂÄëÂ∞çÂ∞çÊâãÊìçÁ∏±ÁöÑÊïèÊÑüÊÄß„ÄÇÊàëÂÄëÁöÑÁµêÊûúÁ™ÅÂá∫‰∫ÜÂü∫ÊñºË°åÁÇ∫ÁöÑÂèñÊ∂àÂ≠∏ÁøíË©ï‰º∞ÁöÑÈôêÂà∂Ôºå‰∏¶ÂëºÁ±≤Êú™‰æÜÁöÑÁ†îÁ©∂Á¥çÂÖ•Âü∫ÊñºÂèÉÊï∏ÁöÑË©ï‰º∞„ÄÇÁÇ∫‰∫ÜÊîØÊåÅÈÄô‰∏ÄÈªûÔºåÊàëÂÄëÂú® https://github.com/yihuaihong/ConceptVectors ‰∏äÈáãÂá∫ÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂíåÂü∫Ê∫ñ„ÄÇ

##### **Long Code Arena: a Set of Benchmarks for Long-Context Code Models**
2406.11612v1 by Egor Bogomolov, Aleksandra Eliseeva, Timur Galimzyanov, Evgeniy Glukhov, Anton Shapkin, Maria Tigina, Yaroslav Golubev, Alexander Kovrigin, Arie van Deursen, Maliheh Izadi, Timofey Bryksin

Nowadays, the fields of code and natural language processing are evolving
rapidly. In particular, models become better at processing long context windows
- supported context sizes have increased by orders of magnitude over the last
few years. However, there is a shortage of benchmarks for code processing that
go beyond a single file of context, while the most popular ones are limited to
a single method. With this work, we aim to close this gap by introducing Long
Code Arena, a suite of six benchmarks for code processing tasks that require
project-wide context. These tasks cover different aspects of code processing:
library-based code generation, CI builds repair, project-level code completion,
commit message generation, bug localization, and module summarization. For each
task, we provide a manually verified dataset for testing, an evaluation suite,
and open-source baseline solutions based on popular LLMs to showcase the usage
of the dataset and to simplify adoption by other researchers. We publish the
benchmark page on HuggingFace Spaces with the leaderboard, links to HuggingFace
Hub for all the datasets, and link to the GitHub repository with baselines:
https://huggingface.co/spaces/JetBrains-Research/long-code-arena.

ÊëòË¶ÅÔºöÂ¶Ç‰ªäÔºå‰ª£Á†ÅÂíåËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÈ¢ÜÂüüÊ≠£Âú®Âø´ÈÄüÂèëÂ±ï„ÄÇÂ∞§ÂÖ∂ÊòØÔºåÊ®°ÂûãÂú®Â§ÑÁêÜÈïø‰∏ä‰∏ãÊñáÁ™óÂè£ÊñπÈù¢ÂèòÂæóÊõ¥Â•ΩÔºåÂú®ËøáÂéªÂá†Âπ¥‰∏≠ÔºåÊîØÊåÅÁöÑ‰∏ä‰∏ãÊñáÂ§ßÂ∞èÂ∑≤ÁªèÂ¢ûÂä†‰∫ÜÂá†‰∏™Êï∞ÈáèÁ∫ß„ÄÇÁÑ∂ËÄåÔºåÂØπ‰∫éË∂ÖÂá∫Âçï‰∏™‰∏ä‰∏ãÊñáÊñá‰ª∂ÁöÑ‰ª£Á†ÅÂ§ÑÁêÜÂü∫ÂáÜÂç¥ÂæàÂåÆ‰πèÔºåËÄåÊúÄÊµÅË°åÁöÑÂü∫ÂáÜ‰ªÖÈôê‰∫éÂçï‰∏™ÊñπÊ≥ï„ÄÇÈÄöËøáËøôÈ°πÂ∑•‰ΩúÔºåÊàë‰ª¨Êó®Âú®ÈÄöËøáÂºïÂÖ• Long Code Arena Êù•Âº•Ë°•Ëøô‰∏ÄÂ∑ÆË∑ùÔºåËøôÊòØ‰∏ÄÂ•óÈíàÂØπÈúÄË¶ÅÈ°πÁõÆËåÉÂõ¥‰∏ä‰∏ãÊñáÁöÑ‰ª£Á†ÅÂ§ÑÁêÜ‰ªªÂä°ÁöÑÂÖ≠‰∏™Âü∫ÂáÜ„ÄÇËøô‰∫õ‰ªªÂä°Ê∂µÁõñ‰∫Ü‰ª£Á†ÅÂ§ÑÁêÜÁöÑ‰∏çÂêåÊñπÈù¢ÔºöÂü∫‰∫éÂ∫ìÁöÑ‰ª£Á†ÅÁîüÊàê„ÄÅCI ÊûÑÂª∫‰øÆÂ§ç„ÄÅÈ°πÁõÆÁ∫ß‰ª£Á†ÅÂÆåÊàê„ÄÅÊèê‰∫§Ê∂àÊÅØÁîüÊàê„ÄÅÈîôËØØÂÆö‰ΩçÂíåÊ®°ÂùóÊëòË¶Å„ÄÇÂØπ‰∫éÊØè‰∏™‰ªªÂä°ÔºåÊàë‰ª¨Êèê‰æõ‰∏Ä‰∏™ÊâãÂä®È™åËØÅÁöÑÊï∞ÊçÆÈõÜÁî®‰∫éÊµãËØï„ÄÅ‰∏Ä‰∏™ËØÑ‰º∞Â•ó‰ª∂ÂíåÂü∫‰∫éÊµÅË°å LLM ÁöÑÂºÄÊ∫êÂü∫Á∫øËß£ÂÜ≥ÊñπÊ°àÔºå‰ª•Â±ïÁ§∫Êï∞ÊçÆÈõÜÁöÑ‰ΩøÁî®Âπ∂ÁÆÄÂåñÂÖ∂‰ªñÁ†îÁ©∂‰∫∫ÂëòÁöÑÈááÁî®„ÄÇÊàë‰ª¨Âú® HuggingFace Spaces ‰∏äÂèëÂ∏ÉÂü∫ÂáÜÈ°µÈù¢ÔºåÂÖ∂‰∏≠ÂåÖÂê´ÊéíË°åÊ¶ú„ÄÅÊåáÂêëÊâÄÊúâÊï∞ÊçÆÈõÜÁöÑ HuggingFace Hub ÁöÑÈìæÊé•Ôºå‰ª•ÂèäÊåáÂêëÂ∏¶ÊúâÂü∫Á∫øÁöÑ GitHub Â≠òÂÇ®Â∫ìÁöÑÈìæÊé•Ôºöhttps://huggingface.co/spaces/JetBrains-Research/long-code-arena„ÄÇ

##### **Understanding "Democratization" in NLP and ML Research**
2406.11598v1 by Arjun Subramonian, Vagrant Gautam, Dietrich Klakow, Zeerak Talat

Recent improvements in natural language processing (NLP) and machine learning
(ML) and increased mainstream adoption have led to researchers frequently
discussing the "democratization" of artificial intelligence. In this paper, we
seek to clarify how democratization is understood in NLP and ML publications,
through large-scale mixed-methods analyses of papers using the keyword
"democra*" published in NLP and adjacent venues. We find that democratization
is most frequently used to convey (ease of) access to or use of technologies,
without meaningfully engaging with theories of democratization, while research
using other invocations of "democra*" tends to be grounded in theories of
deliberation and debate. Based on our findings, we call for researchers to
enrich their use of the term democratization with appropriate theory, towards
democratic technologies beyond superficial access.

ÊëòË¶ÅÔºö<paragraph>Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÂíåÊ©üÂô®Â≠∏Áøí (ML) ËøëÊúüÁöÑÈÄ≤Â±ïÔºå‰ª•Âèä‰∏ªÊµÅÊáâÁî®ÁöÑÂ¢ûÂä†ÔºåÂ∑≤Â∞éËá¥Á†îÁ©∂‰∫∫Âì°È†ªÁπÅÂú∞Ë®éË´ñ‰∫∫Â∑•Êô∫ÊÖßÁöÑ„ÄåÊ∞ë‰∏ªÂåñ„Äç„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëË©¶ÂúñÈáêÊ∏ÖÂú® NLP Âíå ML Âá∫ÁâàÁâ©‰∏≠ÔºåÊ∞ë‰∏ªÂåñÊòØÂ¶Ç‰ΩïË¢´ÁêÜËß£ÁöÑÔºåÈÄèÈÅé‰ΩøÁî®ÈóúÈçµÂ≠ó„Äådemocra*„ÄçÂú® NLP ÂíåÁõ∏ÈóúÈ†òÂüüÁôºË°®ÁöÑË´ñÊñáÈÄ≤Ë°åÂ§ßË¶èÊ®°ÁöÑÊ∑∑ÂêàÊñπÊ≥ïÂàÜÊûê„ÄÇÊàëÂÄëÁôºÁèæÊ∞ë‰∏ªÂåñÊúÄÂ∏∏Ë¢´Áî®‰æÜÂÇ≥ÈÅîÔºàÂÆπÊòìÔºâÂèñÂæóÊàñ‰ΩøÁî®ÊäÄË°ìÔºåËÄåÊ≤íÊúâÊúâÊÑèÁæ©Âú∞Êé¢Ë®éÊ∞ë‰∏ªÂåñÁêÜË´ñÔºåËÄå‰ΩøÁî®ÂÖ∂‰ªñ„Äådemocra*„ÄçÁöÑÂëºÁ±≤ÁöÑÁ†îÁ©∂ÂâáÂÇæÂêëÊñº‰ª•ÂØ©Ë≠∞ÂíåËæØË´ñÁöÑÁêÜË´ñÁÇ∫Âü∫Á§é„ÄÇÊ†πÊìöÊàëÂÄëÁöÑÁôºÁèæÔºåÊàëÂÄëÂëºÁ±≤Á†îÁ©∂‰∫∫Âì°‰ª•ÈÅ©Áï∂ÁöÑÁêÜË´ñË±êÂØå‰ªñÂÄëÂ∞çÊ∞ë‰∏ªÂåñ‰∏ÄË©ûÁöÑ‰ΩøÁî®ÔºåÊúùÂêëË∂ÖË∂äË°®Èù¢ÂèñÂæóÁöÑÊ∞ë‰∏ªÊäÄË°ì„ÄÇ</paragraph>

##### **CoSQA+: Enhancing Code Search Dataset with Matching Code**
2406.11589v1 by Jing Gong, Yanghui Wu, Linxi Liang, Zibin Zheng, Yanlin Wang

Semantic code search, retrieving code that matches a given natural language
query, is an important task to improve productivity in software engineering.
Existing code search datasets are problematic: either using unrealistic
queries, or with mismatched codes, and typically using one-to-one query-code
pairing, which fails to reflect the reality that a query might have multiple
valid code matches. This paper introduces CoSQA+, pairing high-quality queries
(reused from CoSQA) with multiple suitable codes. We collect code candidates
from diverse sources and form candidate pairs by pairing queries with these
codes. Utilizing the power of large language models (LLMs), we automate pair
annotation, filtering, and code generation for queries without suitable
matches. Through extensive experiments, CoSQA+ has demonstrated superior
quality over CoSQA. Models trained on CoSQA+ exhibit improved performance.
Furthermore, we propose a new metric Mean Multi-choice Reciprocal Rank (MMRR),
to assess one-to-N code search performance. We provide the code and data at
https://github.com/DeepSoftwareAnalytics/CoSQA_Plus.

ÊëòË¶ÅÔºöË™ûÊÑèÁ®ãÂºèÁ¢ºÊêúÂ∞ãÔºåÊì∑ÂèñËàáÁµ¶ÂÆöÁöÑËá™ÁÑ∂Ë™ûË®ÄÊü•Ë©¢Áõ∏Á¨¶ÁöÑÁ®ãÂºèÁ¢ºÔºåÊòØÊèêÂçáËªüÈ´îÂ∑•Á®ãÁîüÁî¢ÂäõÁöÑÈáçË¶Å‰ªªÂãô„ÄÇ
ÁèæÊúâÁöÑÁ®ãÂºèÁ¢ºÊêúÂ∞ãË≥áÊñôÈõÜÂ≠òÂú®ÂïèÈ°åÔºö‰∏çÊòØ‰ΩøÁî®‰∏çÂàáÂØ¶ÈöõÁöÑÊü•Ë©¢ÔºåÂ∞±ÊòØÁ®ãÂºèÁ¢º‰∏çÂåπÈÖçÔºåËÄå‰∏îÈÄöÂ∏∏‰ΩøÁî®‰∏ÄÂ∞ç‰∏ÄÁöÑÊü•Ë©¢Á®ãÂºèÁ¢ºÈÖçÂ∞çÔºåÁÑ°Ê≥ïÂèçÊò†Êü•Ë©¢ÂèØËÉΩÊúâÂ§öÂÄãÊúâÊïàÁ®ãÂºèÁ¢ºÈÖçÂ∞çÁöÑÁèæÂØ¶„ÄÇÊú¨Êñá‰ªãÁ¥π CoSQA+ÔºåÂ∞áÈ´òÂìÅË≥™Êü•Ë©¢ÔºàÈáçÊñ∞‰ΩøÁî®Ëá™ CoSQAÔºâËàáÂ§öÂÄãÂêàÈÅ©ÁöÑÁ®ãÂºèÁ¢ºÈÖçÂ∞ç„ÄÇÊàëÂÄëÂæû‰∏çÂêåÁöÑ‰æÜÊ∫êÊî∂ÈõÜÁ®ãÂºèÁ¢ºÂÄôÈÅ∏È†ÖÔºå‰∏¶ÈÄèÈÅéÂ∞áÊü•Ë©¢ËàáÈÄô‰∫õÁ®ãÂºèÁ¢ºÈÖçÂ∞ç‰æÜÂΩ¢ÊàêÂÄôÈÅ∏ÈÖçÂ∞ç„ÄÇÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂäüËÉΩÔºåÊàëÂÄëËá™ÂãïÂü∑Ë°åÈÖçÂ∞çË®ªËß£„ÄÅÁØ©ÈÅ∏Ôºå‰ª•ÂèäÁÇ∫Ê≤íÊúâÂêàÈÅ©ÈÖçÂ∞çÁöÑÊü•Ë©¢Áî¢ÁîüÁ®ãÂºèÁ¢º„ÄÇÈÄèÈÅéÂª£Ê≥õÁöÑÂØ¶È©óÔºåCoSQA+ Â∑≤Ë≠âÊòéÂÖ∂ÂìÅË≥™ÂÑ™Êñº CoSQA„ÄÇÂú® CoSQA+ ‰∏äË®ìÁ∑¥ÁöÑÊ®°ÂûãË°®ÁèæÂá∫Êõ¥Â•ΩÁöÑÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÊåáÊ®ôÂπ≥ÂùáÂ§öÈÅ∏ÂÄíÊï∏ÊéíÂêç (MMRR)ÔºåÁî®ÊñºË©ï‰º∞‰∏ÄÂ∞çÂ§öÁ®ãÂºèÁ¢ºÊêúÂ∞ãÊïàËÉΩ„ÄÇÊàëÂÄëÂú® https://github.com/DeepSoftwareAnalytics/CoSQA_Plus Êèê‰æõÁ®ãÂºèÁ¢ºÂíåË≥áÊñô„ÄÇ

##### **Style Transfer with Multi-iteration Preference Optimization**
2406.11581v1 by Shuai Liu, Jonathan May

Numerous recent techniques for text style transfer characterize their
approaches as variants of reinforcement learning and preference optimization.
In this work, we consider the relationship between these approaches and a class
of optimization approaches developed primarily for (non-neural) statistical
machine translation, formerly known as 'tuning'. Inspired by these techniques
from the past, we improve upon established preference optimization approaches,
incorporating multiple iterations of exploration and optimization, and choosing
contrastive examples by following a 'hope' vs 'fear' sampling strategy.
Cognizant of the difference between machine translation and style transfer,
however, we further tailor our framework with a new pseudo-parallel generation
method and a dynamic weighted reward aggregation method to tackle the lack of
parallel data and the need for a multi-objective reward. We evaluate our model
on two commonly used text style transfer datasets. Through automatic and human
evaluation results we show the effectiveness and the superiority of our model
compared to state-of-the-art baselines.

ÊëòË¶ÅÔºöÊúÄËøëË®±Â§öÊñáÊú¨Ê®£ÂºèËΩâÁßªÊäÄË°ìÂ∞áÂÖ∂ÊñπÊ≥ïÊèèËø∞ÁÇ∫Âº∑ÂåñÂ≠∏ÁøíÂíåÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÁöÑËÆäÈ´î„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëËÄÉÊÖÆÈÄô‰∫õÊñπÊ≥ïËàá‰∏ªË¶ÅÁÇ∫ÔºàÈùûÁ•ûÁ∂ìÔºâÁµ±Ë®àÊ©üÂô®ÁøªË≠ØÈñãÁôºÁöÑ‰∏ÄÈ°ûÊúÄ‰Ω≥ÂåñÊñπÊ≥ï‰πãÈñìÁöÑÈóú‰øÇÔºå‰ª•ÂâçÁ®±ÁÇ∫„ÄåË™øÊï¥„Äç„ÄÇÂèóÂà∞ÈÅéÂéªÈÄô‰∫õÊäÄË°ìÁöÑÂïüÁôºÔºåÊàëÂÄëÊîπÈÄ≤Êó¢ÊúâÁöÑÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÊñπÊ≥ïÔºåÁ¥çÂÖ•Â§öÈáçÊé¢Á¥¢ÂíåÊúÄ‰Ω≥ÂåñÁöÑÂèçË¶ÜÈÅãÁÆóÔºå‰∏¶ÈÅµÂæ™„ÄåÂ∏åÊúõ„ÄçËàá„ÄåÊÅêÊáº„ÄçÂèñÊ®£Á≠ñÁï•‰æÜÈÅ∏ÊìáÂ∞çÊØîÁØÑ‰æã„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëË™çÁü•Âà∞Ê©üÂô®ÁøªË≠ØËàáÊ®£ÂºèËΩâÁßª‰πãÈñìÁöÑÂ∑ÆÁï∞ÔºåÈÄ≤‰∏ÄÊ≠•ÈÄèÈÅéÊñ∞ÁöÑÂÅΩÂπ≥Ë°åÁî¢ÁîüÊñπÊ≥ïÂíåÂãïÊÖãÂä†Ê¨äÂõûÈ•ãÂΩôÁ∏ΩÊñπÊ≥ïË™øÊï¥ÊàëÂÄëÁöÑÊû∂ÊßãÔºå‰ª•Ëß£Ê±∫Áº∫‰πèÂπ≥Ë°åË≥áÊñôÂíåÈúÄË¶ÅÂ§öÁõÆÊ®ôÂõûÈ•ãÁöÑÂïèÈ°å„ÄÇÊàëÂÄëÂú®ÂÖ©ÂÄãÂ∏∏Áî®ÁöÑÊñáÊú¨Ê®£ÂºèËΩâÁßªË≥áÊñôÈõÜ‰∏äË©ï‰º∞ÊàëÂÄëÁöÑÊ®°Âûã„ÄÇÈÄèÈÅéËá™ÂãïÂíå‰∫∫Â∑•Ë©ï‰º∞ÁµêÊûúÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑÊ®°ÂûãËàáÊúÄÂÖàÈÄ≤ÁöÑÂü∫Ê∫ñÁõ∏ÊØîÁöÑÊúâÊïàÊÄßÂíåÂÑ™Ë∂äÊÄß„ÄÇ

##### **Error Span Annotation: A Balanced Approach for Human Evaluation of Machine Translation**
2406.11580v1 by Tom Kocmi, Vil√©m Zouhar, Eleftherios Avramidis, Roman Grundkiewicz, Marzena Karpinska, Maja Popoviƒá, Mrinmaya Sachan, Mariya Shmatova

High-quality Machine Translation (MT) evaluation relies heavily on human
judgments. Comprehensive error classification methods, such as Multidimensional
Quality Metrics (MQM), are expensive as they are time-consuming and can only be
done by experts, whose availability may be limited especially for low-resource
languages. On the other hand, just assigning overall scores, like Direct
Assessment (DA), is simpler and faster and can be done by translators of any
level, but are less reliable. In this paper, we introduce Error Span Annotation
(ESA), a human evaluation protocol which combines the continuous rating of DA
with the high-level error severity span marking of MQM. We validate ESA by
comparing it to MQM and DA for 12 MT systems and one human reference
translation (English to German) from WMT23. The results show that ESA offers
faster and cheaper annotations than MQM at the same quality level, without the
requirement of expensive MQM experts.

ÊëòË¶ÅÔºöÈ´òÂìÅË≥™Ê©üÂô®ÁøªË≠Ø (MT) Ë©ïÈáèÈ´òÂ∫¶‰æùË≥¥Êñº‰∫∫È°ûÁöÑÂà§Êñ∑„ÄÇÂÖ®Èù¢ÁöÑÈåØË™§ÂàÜÈ°ûÊñπÊ≥ïÔºà‰æãÂ¶ÇÂ§öÁ∂≠Â∫¶ÂìÅË≥™ÊåáÊ®ô (MQM)ÔºâÊàêÊú¨È´òÊòÇÔºåÂõ†ÁÇ∫ÂÆÉÂÄëËÄóÊôÇ‰∏îÂè™ËÉΩÁî±Â∞àÂÆ∂Âü∑Ë°åÔºåËÄåÂ∞àÂÆ∂ÁöÑÂèØÁî®ÊÄßÂèØËÉΩÊúâÈôêÔºåÁâπÂà•ÊòØÂ∞çÊñº‰ΩéË≥áÊ∫êË™ûË®Ä„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÂÉÖÊåáÂÆöÊï¥È´îÂàÜÊï∏Ôºà‰æãÂ¶ÇÁõ¥Êé•Ë©ïÈáè (DA)ÔºâËºÉÁÇ∫Á∞°ÂñÆ‰∏îÂø´ÈÄüÔºå‰∏îÂèØÁî±‰ªª‰ΩïÂ±§Á¥öÁöÑÁøªË≠Ø‰∫∫Âì°Âü∑Ë°åÔºå‰ΩÜÂèØÈù†ÊÄßËºÉ‰Ωé„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥πÈåØË™§ÁØÑÂúçÊ®ôË®ª (ESA)ÔºåÈÄôÊòØ‰∏ÄÁ®Æ‰∫∫È°ûË©ïÈáèÂçîÂÆöÔºåÁµêÂêà DA ÁöÑÈÄ£Á∫åË©ïÂàÜËàá MQM ÁöÑÈ´òÂ±§Á¥öÈåØË™§Âö¥ÈáçÊÄßÁØÑÂúçÊ®ôË®ò„ÄÇÊàëÂÄëÈÄèÈÅéÊØîËºÉ ESA Ëàá MQM Âíå DA Â∞ç 12 ÂÄãÊ©üÂô®ÁøªË≠ØÁ≥ªÁµ±Âíå‰∏ÄÂÄã‰∫∫È°ûÂèÉËÄÉÁøªË≠ØÔºàËã±Ë≠ØÂæ∑ÔºâÂæû WMT23 È©óË≠â ESA„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåESA Êèê‰æõÊØî MQM Êõ¥Âø´ÈÄü‰∏îÊõ¥‰æøÂÆúÁöÑÊ®ôË®ªÔºåÂìÅË≥™Ê∞¥Ê∫ñÁõ∏ÂêåÔºå‰∏î‰∏çÈúÄË¶ÅÊòÇË≤¥ÁöÑ MQM Â∞àÂÆ∂„ÄÇ

##### **Mathematical Entities: Corpora and Benchmarks**
2406.11577v1 by Jacob Collard, Valeria de Paiva, Eswaran Subrahmanian

Mathematics is a highly specialized domain with its own unique set of
challenges. Despite this, there has been relatively little research on natural
language processing for mathematical texts, and there are few mathematical
language resources aimed at NLP. In this paper, we aim to provide annotated
corpora that can be used to study the language of mathematics in different
contexts, ranging from fundamental concepts found in textbooks to advanced
research mathematics. We preprocess the corpora with a neural parsing model and
some manual intervention to provide part-of-speech tags, lemmas, and dependency
trees. In total, we provide 182397 sentences across three corpora. We then aim
to test and evaluate several noteworthy natural language processing models
using these corpora, to show how well they can adapt to the domain of
mathematics and provide useful tools for exploring mathematical language. We
evaluate several neural and symbolic models against benchmarks that we extract
from the corpus metadata to show that terminology extraction and definition
extraction do not easily generalize to mathematics, and that additional work is
needed to achieve good performance on these metrics. Finally, we provide a
learning assistant that grants access to the content of these corpora in a
context-sensitive manner, utilizing text search and entity linking. Though our
corpora and benchmarks provide useful metrics for evaluating mathematical
language processing, further work is necessary to adapt models to mathematics
in order to provide more effective learning assistants and apply NLP methods to
different mathematical domains.

ÊëòË¶ÅÔºöÊï∏Â≠∏ÊòØ‰∏ÄÂÄãÈ´òÂ∫¶Â∞àÊ•≠ÁöÑÈ†òÂüüÔºåÊúâÂÖ∂Áç®ÁâπÁöÑ‰∏ÄÁµÑÊåëÊà∞„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÈáùÂ∞çÊï∏Â≠∏ÊñáÊú¨ÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁöÑÁ†îÁ©∂Áõ∏Â∞çËºÉÂ∞ëÔºåËÄå‰∏îÈáùÂ∞ç NLP ÁöÑÊï∏Â≠∏Ë™ûË®ÄË≥áÊ∫ê‰πüÂæàÂ∞ë„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊó®Âú®Êèê‰æõË®ªËß£Ë™ûÊñôÂ∫´ÔºåÂèØÁî®‰∫éÁ†îÁ©∂‰∏çÂêåËÑàÁµ°‰∏≠ÁöÑÊï∏Â≠∏Ë™ûË®ÄÔºåÂæûÊïôÁßëÊõ∏‰∏≠ÁôºÁèæÁöÑÂü∫Êú¨Ê¶ÇÂøµÂà∞ÂÖàÈÄ≤ÁöÑÁ†îÁ©∂Êï∏Â≠∏„ÄÇÊàëÂÄë‰ΩøÁî®Á•ûÁ∂ìÂè•Ê≥ïÂàÜÊûêÊ®°ÂûãÂíå‰∏Ä‰∫õÊâãÂãïÂπ≤È†êÂ∞çË™ûÊñôÂ∫´ÈÄ≤Ë°åÈ†êËôïÁêÜÔºå‰ª•Êèê‰æõË©ûÊÄßÊ®ôË®ò„ÄÅË©ûÂππÂíå‰æùË≥¥Ê®π„ÄÇÁ∏ΩÁöÑ‰æÜË™™ÔºåÊàëÂÄëÂú®‰∏âÂÄãË™ûÊñôÂ∫´‰∏≠Êèê‰æõ‰∫Ü 182397 ÂÄãÂè•Â≠ê„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊó®Âú®‰ΩøÁî®ÈÄô‰∫õË™ûÊñôÂ∫´Ê∏¨Ë©¶ÂíåË©ï‰º∞ÂπæÂÄãÂÄºÂæóÊ≥®ÊÑèÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÊ®°ÂûãÔºå‰ª•Â±ïÁ§∫ÂÆÉÂÄëÂ¶Ç‰ΩïÈÅ©ÊáâÊï∏Â≠∏È†òÂüü‰∏¶Êèê‰æõÊé¢Á¥¢Êï∏Â≠∏Ë™ûË®ÄÁöÑÊúâÁî®Â∑•ÂÖ∑„ÄÇÊàëÂÄëÊ†πÊìöÂæûË™ûÊñôÂ∫´ÂÖÉÊï∏Êìö‰∏≠ÊèêÂèñÁöÑÂü∫Ê∫ñË©ï‰º∞‰∫ÜÂπæÂÄãÁ•ûÁ∂ìÂíåÁ¨¶ËôüÊ®°ÂûãÔºå‰ª•Ë°®ÊòéË°ìË™ûÊèêÂèñÂíåÂÆöÁæ©ÊèêÂèñ‰∏çÊòìÊñºÊé®Âª£Âà∞Êï∏Â≠∏Ôºå‰∏¶‰∏îÈúÄË¶ÅÈ°çÂ§ñÁöÑÁ†îÁ©∂ÊâçËÉΩÂú®ÈÄô‰∫õÊåáÊ®ô‰∏äÂèñÂæóËâØÂ•ΩÁöÑË°®Áèæ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂ≠∏ÁøíÂä©ÁêÜÔºåÂÆÉ‰ª•‰∏ä‰∏ãÊñáÊïèÊÑüÁöÑÊñπÂºèÊéà‰∫àË®™ÂïèÈÄô‰∫õË™ûÊñôÂ∫´ÂÖßÂÆπÁöÑÊ¨äÈôêÔºåÂà©Áî®ÊñáÊú¨ÊêúÁ¥¢ÂíåÂØ¶È´îÈÄ£Áµê„ÄÇÂÑòÁÆ°ÊàëÂÄëÁöÑË™ûÊñôÂ∫´ÂíåÂü∫Ê∫ñÁÇ∫Ë©ï‰º∞Êï∏Â≠∏Ë™ûË®ÄËôïÁêÜÊèê‰æõ‰∫ÜÊúâÁî®ÁöÑÊåáÊ®ôÔºå‰ΩÜÈÅ©ÊáâÊ®°Âûã‰ª•ÈÅ©ÊáâÊï∏Â≠∏‰ª•Êèê‰æõÊõ¥ÊúâÊïàÁöÑÂ≠∏ÁøíÂä©ÁêÜ‰∏¶Â∞á NLP ÊñπÊ≥ïÊáâÁî®Êñº‰∏çÂêåÁöÑÊï∏Â≠∏È†òÂüü‰ªçÁÑ∂ÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•ÁöÑÁ†îÁ©∂„ÄÇ

##### **Towards an End-to-End Framework for Invasive Brain Signal Decoding with Large Language Models**
2406.11568v1 by Sheng Feng, Heyang Liu, Yu Wang, Yanfeng Wang

In this paper, we introduce a groundbreaking end-to-end (E2E) framework for
decoding invasive brain signals, marking a significant advancement in the field
of speech neuroprosthesis. Our methodology leverages the comprehensive
reasoning abilities of large language models (LLMs) to facilitate direct
decoding. By fully integrating LLMs, we achieve results comparable to the
state-of-the-art cascade models. Our findings underscore the immense potential
of E2E frameworks in speech neuroprosthesis, particularly as the technology
behind brain-computer interfaces (BCIs) and the availability of relevant
datasets continue to evolve. This work not only showcases the efficacy of
combining LLMs with E2E decoding for enhancing speech neuroprosthesis but also
sets a new direction for future research in BCI applications, underscoring the
impact of LLMs in decoding complex neural signals for communication
restoration. Code will be made available at
https://github.com/FsFrancis15/BrainLLM.

ÊëòË¶ÅÔºöÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÁ™ÅÁ†¥ÊÄßÁöÑÁ´ØÂà∞Á´Ø (E2E) Ê°ÜÊû∂ÔºåÁî®ÊñºËß£Á¢º‰æµÂÖ•ÊÄßËÖ¶‰ø°ËôüÔºåÊ®ôË™åËëóË™ûÈü≥Á•ûÁ∂ìÂÅáÈ´îÈ†òÂüüÁöÑÈáçÂ§ßÈÄ≤Â±ï„ÄÇÊàëÂÄëÁöÑÊäÄË°ìÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂÖ®Èù¢Êé®ÁêÜËÉΩÂäõÔºå‰ª•‰øÉÈÄ≤Áõ¥Êé•Ëß£Á¢º„ÄÇÈÄöÈÅéÂÆåÂÖ®Êï¥Âêà LLMÔºåÊàëÂÄëÂèñÂæó‰∫ÜËàáÊúÄÂÖàÈÄ≤ÁöÑ‰∏≤ËÅØÊ®°ÂûãÁõ∏Áï∂ÁöÑÁµêÊûú„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÂº∑Ë™ø‰∫Ü E2E Ê°ÜÊû∂Âú®Ë™ûÈü≥Á•ûÁ∂ìÂÅáÈ´î‰∏≠ÁöÑÂ∑®Â§ßÊΩõÂäõÔºåÁâπÂà•ÊòØÈö®ËëóËÖ¶Ê©ü‰ªãÈù¢ (BCI) ÊäÄË°ìÂíåÁõ∏ÈóúË≥áÊñôÈõÜÂèØÁî®ÊÄßÁöÑÊåÅÁ∫åÁôºÂ±ï„ÄÇÈÄôÈ†ÖÂ∑•‰Ωú‰∏çÂÉÖÂ±ïÁ§∫‰∫ÜÂ∞á LLM Ëàá E2E Ëß£Á¢ºÁõ∏ÁµêÂêà‰ª•Â¢ûÂº∑Ë™ûÈü≥Á•ûÁ∂ìÂÅáÈ´îÁöÑÂäüÊïàÔºåËÄå‰∏î‰πüÁÇ∫ BCI ÊáâÁî®‰∏≠ÁöÑÊú™‰æÜÁ†îÁ©∂Ë®≠ÂÆö‰∫Ü‰∏ÄÂÄãÊñ∞ÊñπÂêëÔºåÂº∑Ë™ø‰∫Ü LLM Âú®Ëß£Á¢ºË§áÈõúÁ•ûÁ∂ì‰ø°Ëôü‰ª•ÊÅ¢Âæ©Ê∫ùÈÄöÊñπÈù¢ÁöÑÂΩ±ÈüøÂäõ„ÄÇÁ®ãÂºèÁ¢ºÂ∞áÂú® https://github.com/FsFrancis15/BrainLLM ‰∏äÊèê‰æõ„ÄÇ

##### **Quaternion Generative Adversarial Neural Networks and Applications to Color Image Inpainting**
2406.11567v1 by Duan Wang, Dandan Zhu, Meixiang Zhao, Zhigang Jia

Color image inpainting is a challenging task in imaging science. The existing
method is based on real operation, and the red, green and blue channels of the
color image are processed separately, ignoring the correlation between each
channel. In order to make full use of the correlation between each channel,
this paper proposes a Quaternion Generative Adversarial Neural Network (QGAN)
model and related theory, and applies it to solve the problem of color image
inpainting with large area missing. Firstly, the definition of quaternion
deconvolution is given and the quaternion batch normalization is proposed.
Secondly, the above two innovative modules are applied to generate adversarial
networks to improve stability. Finally, QGAN is applied to color image
inpainting and compared with other state-of-the-art algorithms. The
experimental results show that QGAN has superiority in color image inpainting
with large area missing.

ÊëòË¶ÅÔºöÂΩ©Ëâ≤ÂΩ±ÂÉè‰øÆÂæ©Âú®ÂΩ±ÂÉèÁßëÂ≠∏‰∏≠ÊòØ‰∏ÄÈ†ÖÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ‰ªªÂãô„ÄÇÁèæÊúâÁöÑÊñπÊ≥ïÂü∫ÊñºÂØ¶Êï∏ÈÅãÁÆóÔºå‰∏¶‰∏îÂàÜÂà•ËôïÁêÜÂΩ©Ëâ≤ÂΩ±ÂÉèÁöÑÁ¥Ö„ÄÅÁ∂†„ÄÅËóçÈÄöÈÅìÔºåÂøΩÁï•ÂêÑÈÄöÈÅì‰πãÈñìÁöÑÈóúËÅØÊÄß„ÄÇÁÇ∫‰∫ÜÂÖÖÂàÜÂà©Áî®ÂêÑÈÄöÈÅì‰πãÈñìÁöÑÈóúËÅØÊÄßÔºåÊú¨ÊñáÊèêÂá∫ÂõõÂÖÉÊï∏ÁîüÊàêÂ∞çÊäóÁ∂≤Ë∑Ø (QGAN) Ê®°ÂûãÂèäÁõ∏ÈóúÁêÜË´ñÔºå‰∏¶ÊáâÁî®ÊñºËß£Ê±∫Â§ßÈù¢Á©çÁº∫Â§±ÁöÑÂΩ©Ëâ≤ÂΩ±ÂÉè‰øÆÂæ©ÂïèÈ°å„ÄÇÈ¶ñÂÖàÔºåÁµ¶Âá∫ÂõõÂÖÉÊï∏ÂèçÊë∫Á©çÁöÑÂÆöÁæ©Ôºå‰∏¶ÊèêÂá∫ÂõõÂÖÉÊï∏ÊâπÊ¨°Ê≠£Ë¶èÂåñ„ÄÇÂÖ∂Ê¨°ÔºåÂ∞á‰∏äËø∞ÂÖ©ÂÄãÂâµÊñ∞ÁöÑÊ®°ÁµÑÊáâÁî®ÊñºÁîüÊàêÂ∞çÊäóÁ∂≤Ë∑ØÔºå‰ª•ÊèêÂçáÁ©©ÂÆöÊÄß„ÄÇÊúÄÂæåÔºåÂ∞á QGAN ÊáâÁî®ÊñºÂΩ©Ëâ≤ÂΩ±ÂÉè‰øÆÂæ©Ôºå‰∏¶ËàáÂÖ∂‰ªñÊúÄÂÖàÈÄ≤ÁöÑÊºîÁÆóÊ≥ïÈÄ≤Ë°åÊØîËºÉ„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåQGAN Âú®Â§ßÈù¢Á©çÁº∫Â§±ÁöÑÂΩ©Ëâ≤ÂΩ±ÂÉè‰øÆÂæ©‰∏≠ÂÖ∑ÊúâÂÑ™Ë∂äÊÄß„ÄÇ

##### **MEMLA: Enhancing Multilingual Knowledge Editing with Neuron-Masked Low-Rank Adaptation**
2406.11566v1 by Jiakuan Xie, Pengfei Cao, Yuheng Chen, Yubo Chen, Kang Liu, Jun Zhao

Knowledge editing aims to adjust the knowledge within large language models
(LLMs) to prevent their responses from becoming obsolete or inaccurate.
However, existing works on knowledge editing are primarily conducted in a
single language, which is inadequate for multilingual language models. In this
paper, we focus on multilingual knowledge editing (MKE), which requires
propagating updates across multiple languages. This necessity poses a
significant challenge for the task. Furthermore, the limited availability of a
comprehensive dataset for MKE exacerbates this challenge, hindering progress in
this area. Hence, we introduce the Multilingual Knowledge Editing Benchmark
(MKEB), a novel dataset comprising 12 languages and providing a complete
evaluation framework. Additionally, we propose a method that enhances
Multilingual knowledge Editing with neuron-Masked Low-Rank Adaptation (MEMLA).
Specifically, we identify two categories of knowledge neurons to improve
editing precision. Moreover, we perform LoRA-based editing with neuron masks to
efficiently modify parameters and facilitate the propagation of updates across
multiple languages. Experiments demonstrate that our method outperforms
existing baselines and significantly enhances the multi-hop reasoning
capability of the edited model, with minimal impact on its downstream task
performance. The dataset and code will be made publicly available.

ÊëòË¶ÅÔºöÁü•Ë≠òÁ∑®ËºØÊó®Âú®Ë™øÊï¥Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠ÁöÑÁü•Ë≠òÔºå‰ª•Èò≤Ê≠¢ÂÖ∂ÂõûÊáâÈÅéÊôÇÊàñ‰∏çÊ∫ñÁ¢∫„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÁü•Ë≠òÁ∑®ËºØÂ∑•‰Ωú‰∏ªË¶Å‰ª•ÂñÆ‰∏ÄË™ûË®ÄÈÄ≤Ë°åÔºåÈÄôÂ∞çÊñºÂ§öË™ûË®ÄË™ûË®ÄÊ®°Âûã‰æÜË™™ÊòØ‰∏çÂ§†ÁöÑ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÂ§öË™ûË®ÄÁü•Ë≠òÁ∑®ËºØ (MKE)ÔºåÈÄôÈúÄË¶ÅË∑®Â§öÁ®ÆË™ûË®ÄÂÇ≥Êí≠Êõ¥Êñ∞„ÄÇÈÄôÁ®ÆÂøÖË¶ÅÊÄßÂ∞çÈÄôÈ†Ö‰ªªÂãôÊèêÂá∫‰∫ÜÈáçÂ§ßÊåëÊà∞„ÄÇÊ≠§Â§ñÔºåÁ∂úÂêà MKE Êï∏ÊìöÈõÜÁöÑÂèØÁî®ÊÄßÊúâÈôêÔºåÂä†Âäá‰∫ÜÈÄô‰∏ÄÊåëÊà∞ÔºåÈòªÁ§ô‰∫ÜË©≤È†òÂüüÁöÑÈÄ≤Â±ï„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂ§öË™ûË®ÄÁü•Ë≠òÁ∑®ËºØÂü∫Ê∫ñ (MKEB)ÔºåÈÄôÊòØ‰∏ÄÂÄãÂåÖÂê´ 12 Á®ÆË™ûË®ÄÁöÑÊñ∞Á©éÊï∏ÊìöÈõÜÔºå‰∏¶Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂÆåÊï¥ÁöÑË©ï‰º∞Ê°ÜÊû∂„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ï‰ΩøÁî®Á•ûÁ∂ìÂÖÉÊé©Á¢º‰ΩéÁß©ÈÅ©Êáâ (MEMLA) Â¢ûÂº∑‰∫ÜÂ§öË™ûË®ÄÁü•Ë≠òÁ∑®ËºØ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëË≠òÂà•Âá∫ÂÖ©È°ûÁü•Ë≠òÁ•ûÁ∂ìÂÖÉ‰ª•ÊèêÈ´òÁ∑®ËºØÁ≤æÂ∫¶„ÄÇÊ≠§Â§ñÔºåÊàëÂÄë‰ΩøÁî®Á•ûÁ∂ìÂÖÉÊé©Á¢ºÂü∑Ë°åÂü∫Êñº LoRA ÁöÑÁ∑®ËºØÔºå‰ª•ÊúâÊïà‰øÆÊîπÂèÉÊï∏‰∏¶‰øÉÈÄ≤Ë∑®Â§öÁ®ÆË™ûË®ÄÁöÑÊõ¥Êñ∞ÂÇ≥Êí≠„ÄÇÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÂÑ™ÊñºÁèæÊúâÁöÑÂü∫Ê∫ñÔºå‰∏¶È°ØËëóÂ¢ûÂº∑‰∫ÜÂ∑≤Á∑®ËºØÊ®°ÂûãÁöÑÂ§öË∑≥Êé®ÁêÜËÉΩÂäõÔºåÂêåÊôÇÂ∞çÂÖ∂‰∏ãÊ∏∏‰ªªÂãôÊÄßËÉΩÁöÑÂΩ±ÈüøÂæàÂ∞è„ÄÇË©≤Êï∏ÊìöÈõÜÂíå‰ª£Á¢ºÂ∞áÂÖ¨ÈñãÁôºÂ∏É„ÄÇ

##### **Extrinsic Evaluation of Cultural Competence in Large Language Models**
2406.11565v1 by Shaily Bhatt, Fernando Diaz

Productive interactions between diverse users and language technologies
require outputs from the latter to be culturally relevant and sensitive. Prior
works have evaluated models' knowledge of cultural norms, values, and
artifacts, without considering how this knowledge manifests in downstream
applications. In this work, we focus on extrinsic evaluation of cultural
competence in two text generation tasks, open-ended question answering and
story generation. We quantitatively and qualitatively evaluate model outputs
when an explicit cue of culture, specifically nationality, is perturbed in the
prompts. Although we find that model outputs do vary when varying nationalities
and feature culturally relevant words, we also find weak correlations between
text similarity of outputs for different countries and the cultural values of
these countries. Finally, we discuss important considerations in designing
comprehensive evaluation of cultural competence in user-facing tasks.

ÊëòË¶ÅÔºöÁîüÁî¢ÊÄßÁöÑ‰∫íÂãïÔºåÂ≠òÂú®ÊñºÂ§öÂÖÉÁöÑ‰ΩøÁî®ËÄÖÂíåË™ûË®ÄÁßëÊäÄ‰πãÈñìÔºåÈúÄË¶ÅÂæåËÄÖÁöÑËº∏Âá∫Âú®ÊñáÂåñ‰∏äÁõ∏Èóú‰∏îÊïèÊÑü„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂Â∑≤Á∂ìË©ï‰º∞‰∫ÜÊ®°ÂûãÂ∞çÊñáÂåñË¶èÁØÑ„ÄÅÂÉπÂÄºËßÄÂíå‰∫∫Â∑•Ë£ΩÂìÅÁöÑÁü•Ë≠òÔºåËÄåÊ≤íÊúâËÄÉÊÖÆÂà∞ÈÄô‰∫õÁü•Ë≠òÂ¶Ç‰ΩïË°®ÁèæÂú®‰∏ãÊ∏∏ÊáâÁî®Á®ãÂºè‰∏≠„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÊñáÂåñËÉΩÂäõÁöÑÂ§ñÈÉ®Ë©ï‰º∞ÔºåÂú®ÂÖ©ÂÄãÊñáÊú¨ÁîüÊàê‰ªªÂãô‰∏≠ÔºåÈñãÊîæÂºèÂïèÁ≠îÂíåÊïÖ‰∫ãÁîüÊàê„ÄÇÊàëÂÄëÂú®ÊèêÁ§∫‰∏≠ÊìæÂãï‰∫ÜÊñáÂåñÁöÑÊòéÁ¢∫Á∑öÁ¥¢ÔºåÁâπÂà•ÊòØÂúãÁ±çÔºå‰∏¶Â∞çÊ®°ÂûãËº∏Âá∫ÈÄ≤Ë°åÈáèÂåñÂíåË≥™ÂåñË©ï‰º∞„ÄÇÂÑòÁÆ°ÊàëÂÄëÁôºÁèæÔºåÁï∂ÂúãÁ±ç‰∏çÂêå‰∏îÂÖ∑ÊúâÊñáÂåñÁõ∏ÈóúË©ûÂΩôÊôÇÔºåÊ®°ÂûãËº∏Âá∫Á¢∫ÂØ¶ÊúÉÊúâÊâÄ‰∏çÂêåÔºå‰ΩÜÊàëÂÄë‰πüÁôºÁèæ‰∏çÂêåÂúãÂÆ∂ÁöÑËº∏Âá∫ÊñáÊú¨Áõ∏‰ººÂ∫¶ËàáÈÄô‰∫õÂúãÂÆ∂ÁöÑÊñáÂåñÂÉπÂÄºËßÄ‰πãÈñìÁöÑÁõ∏ÈóúÊÄßËºÉÂº±„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®éË´ñ‰∫ÜÂú®‰ΩøÁî®ËÄÖÈù¢Â∞çÁöÑ‰ªªÂãô‰∏≠Ë®≠Ë®àÊñáÂåñËÉΩÂäõÂÖ®Èù¢Ë©ï‰º∞ÊôÇÁöÑÈáçË¶ÅËÄÉÈáèÂõ†Á¥†„ÄÇ

##### **Input Conditioned Graph Generation for Language Agents**
2406.11555v1 by Lukas Vierling, Jie Fu, Kai Chen

Recent progress in Large Language Models (LLMs) and language agents has
demonstrated significant promise for various future applications across
multiple disciplines. While traditional approaches to language agents often
rely on fixed, handcrafted designs, our research aims to develop both learnable
and dynamic agents. Our method uses an existing framework that abstracts
language agents as graphs. Within this graph framework, we aim to learn a model
that can generate edges for every given input to the language agent. This
allows us to generate edges that represent the flow of communication within the
graph based on the given input, thereby adjusting the internal communication of
a language agent. We learn to generate these edges using a pretrained LLM that
is fine-tuned with reinforcement learning. This LLM can be fine-tuned on
several datasets simultaneously, and we hypothesize that the model learns to
adapt to these different domains during training, achieving good overall
performance when encountering data from different domains during deployment. We
demonstrate that our approach surpasses the previous static approach by nearly
6% accuracy on a combined dataset of MMLU and CMMLU, and by more than 10% when
trained with a sparsity-inducing loss. It also performs superior in additional
experiments conducted with the MMLU and Mini Crossword Puzzles datasets. The
code is available at https://github.com/lukasVierling/DynamicGPTSwarm.

ÊëòË¶ÅÔºöÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ÂíåËØ≠Ë®Ä‰ª£ÁêÜÊúÄËøëÁöÑËøõÂ±ïÂ∑≤Â±ïÁ§∫Âá∫ÂØπË∑®Â§ö‰∏™Â≠¶ÁßëÁöÑÂêÑÁßçÊú™Êù•Â∫îÁî®ÁöÑÈáçÂ§ßÂâçÊôØ„ÄÇËôΩÁÑ∂‰º†ÁªüÁöÑËØ≠Ë®Ä‰ª£ÁêÜÊñπÊ≥ïÈÄöÂ∏∏‰æùËµñ‰∫éÂõ∫ÂÆöÁöÑÊâãÂ∑•ËÆæËÆ°Ôºå‰ΩÜÊàë‰ª¨ÁöÑÁ†îÁ©∂Êó®Âú®ÂºÄÂèëÂèØÂ≠¶‰π†ÂíåÂä®ÊÄÅÁöÑ‰ª£ÁêÜ„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ï‰ΩøÁî®‰∫Ü‰∏Ä‰∏™Áé∞ÊúâÁöÑÊ°ÜÊû∂ÔºåÂ∞ÜËØ≠Ë®Ä‰ª£ÁêÜÊäΩË±°‰∏∫Âõæ„ÄÇÂú®Ëøô‰∏™ÂõæÊ°ÜÊû∂ÂÜÖÔºåÊàë‰ª¨Êó®Âú®Â≠¶‰π†‰∏Ä‰∏™Ê®°ÂûãÔºåËØ•Ê®°ÂûãÂèØ‰ª•‰∏∫ËØ≠Ë®Ä‰ª£ÁêÜÁöÑÊØè‰∏™ÁªôÂÆöËæìÂÖ•ÁîüÊàêËæπ„ÄÇËøô‰ΩøÊàë‰ª¨ËÉΩÂ§üÁîüÊàê‰ª£Ë°®Âõæ‰∏≠Âü∫‰∫éÁªôÂÆöËæìÂÖ•ÁöÑÈÄö‰ø°ÊµÅÁöÑËæπÔºå‰ªéËÄåË∞ÉÊï¥ËØ≠Ë®Ä‰ª£ÁêÜÁöÑÂÜÖÈÉ®ÈÄö‰ø°„ÄÇÊàë‰ª¨Â≠¶‰π†‰ΩøÁî®ÁªèËøáÂº∫ÂåñÂ≠¶‰π†ÂæÆË∞ÉÁöÑÈ¢ÑËÆ≠ÁªÉ LLM Êù•ÁîüÊàêËøô‰∫õËæπ„ÄÇËØ• LLM ÂèØ‰ª•ÂêåÊó∂Âú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äËøõË°åÂæÆË∞ÉÔºåÊàë‰ª¨ÂÅáËÆæËØ•Ê®°ÂûãÂú®ËÆ≠ÁªÉÊúüÈó¥Â≠¶‰π†ÈÄÇÂ∫îËøô‰∫õ‰∏çÂêåÁöÑÂüüÔºåÂú®ÈÉ®ÁΩ≤ÊúüÈó¥ÈÅáÂà∞Êù•Ëá™‰∏çÂêåÂüüÁöÑÊï∞ÊçÆÊó∂ÂÆûÁé∞ËâØÂ•ΩÁöÑÊï¥‰ΩìÊÄßËÉΩ„ÄÇÊàë‰ª¨ËØÅÊòéÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú® MMLU Âíå CMMLU ÁöÑÁªÑÂêàÊï∞ÊçÆÈõÜ‰∏äÊØîÂÖàÂâçÁöÑÈùôÊÄÅÊñπÊ≥ïÈ´òÂá∫Ëøë 6% ÁöÑÂáÜÁ°ÆÂ∫¶ÔºåÂπ∂‰∏îÂú®‰ΩøÁî®Á®ÄÁñèÊÄßËØ±ÂØºÊçüÂ§±ËøõË°åËÆ≠ÁªÉÊó∂È´òÂá∫ 10% ‰ª•‰∏ä„ÄÇÂÆÉËøòÂú®‰ΩøÁî® MMLU ÂíåËø∑‰Ω†Â°´Â≠óÊ∏∏ÊàèÊï∞ÊçÆÈõÜËøõË°åÁöÑÂÖ∂‰ªñÂÆûÈ™å‰∏≠Ë°®Áé∞Âá∫Ëâ≤„ÄÇ‰ª£Á†ÅÂèØÂú® https://github.com/lukasVierling/DynamicGPTSwarm Ëé∑Âæó„ÄÇ

##### **AIC MLLM: Autonomous Interactive Correction MLLM for Robust Robotic Manipulation**
2406.11548v1 by Chuyan Xiong, Chengyu Shen, Xiaoqi Li, Kaichen Zhou, Jiaming Liu, Ruiping Wang, Hao Dong

The ability to reflect on and correct failures is crucial for robotic systems
to interact stably with real-life objects.Observing the generalization and
reasoning capabilities of Multimodal Large Language Models (MLLMs), previous
approaches have aimed to utilize these models to enhance robotic systems
accordingly.However, these methods typically focus on high-level planning
corrections using an additional MLLM, with limited utilization of failed
samples to correct low-level contact poses. To address this gap, we propose an
Autonomous Interactive Correction (AIC) MLLM, which makes use of previous
low-level interaction experiences to correct SE(3) pose predictions.
Specifically, AIC MLLM is initially fine-tuned to acquire both pose prediction
and feedback prompt comprehension abilities.We carefully design two types of
prompt instructions through interactions with objects: 1) visual masks to
highlight unmovable parts for position correction, and 2)textual descriptions
to indicate potential directions for rotation correction.During inference, a
Feedback Information Extraction module is introduced to recognize the failure
cause, allowing AIC MLLM to adaptively correct the pose prediction using the
corresponding prompts.To further enhance manipulation stability, we devise a
Test Time Adaptation strategy that enables AIC MLLM to better adapt to the
current scene configuration.Finally, extensive experiments are conducted in
both simulated and real-world environments to evaluate the proposed method. The
results demonstrate that our AIC MLLM can efficiently correct failure samples
by leveraging interaction experience prompts.Real-world demonstration can be
found at https://sites.google.com/view/aic-mllm

ÊëòË¶ÅÔºöÊ©üÂô®‰∫∫Á≥ªÁµ±Ëã•Ë¶ÅËàáÁèæÂØ¶ÁîüÊ¥ª‰∏≠ÁöÑÁâ©È´îÁ©©ÂÆö‰∫íÂãïÔºåÂøÖÈ†àÂÖ∑ÂÇôÂèçÁúÅÂíå‰øÆÊ≠£Â§±ÊïóÁöÑËÉΩÂäõ„ÄÇËßÄÂØüÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) ÁöÑÊ¶ÇÂåñÂíåÊé®ÁêÜËÉΩÂäõÔºåÂÖàÂâçÁöÑÂÅöÊ≥ïÊó®Âú®Âà©Áî®ÈÄô‰∫õÊ®°Âûã‰æÜÁõ∏ÊáâÂú∞Âº∑ÂåñÊ©üÂô®‰∫∫Á≥ªÁµ±„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÈÄöÂ∏∏ËëóÈáçÊñº‰ΩøÁî®È°çÂ§ñÁöÑ MLLM ÈÄ≤Ë°åÈ´òÂ±§Á¥öË¶èÂäÉ‰øÆÊ≠£ÔºåËÄåÂÉÖÊúâÈôêÂú∞Âà©Áî®Â§±ÊïóÊ®£Êú¨‰æÜ‰øÆÊ≠£‰ΩéÂ±§Á¥öÊé•Ëß∏ÂßøÂã¢„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÊèêÂá∫Ëá™Ê≤ª‰∫íÂãï‰øÆÊ≠£ (AIC) MLLMÔºåÂÆÉÂà©Áî®ÂÖàÂâçÁöÑ‰ΩéÂ±§Á¥ö‰∫íÂãïÁ∂ìÈ©ó‰æÜ‰øÆÊ≠£ SE(3) ÂßøÂã¢È†êÊ∏¨„ÄÇÂÖ∑È´î‰æÜË™™ÔºåAIC MLLM ÊúÄÂàùÁ∂ìÈÅéÂæÆË™øÔºå‰ª•Áç≤ÂæóÂßøÂã¢È†êÊ∏¨ÂíåÂõûÈ•ãÊèêÁ§∫ÁêÜËß£ËÉΩÂäõ„ÄÇÊàëÂÄëÈÄèÈÅéËàáÁâ©È´î‰∫íÂãïÔºå‰ªîÁ¥∞Ë®≠Ë®àÂÖ©Á®ÆÈ°ûÂûãÁöÑÊèêÁ§∫Êåá‰ª§Ôºö1) Ë¶ñË¶∫ÈÅÆÁΩ©ÔºåÁî®ÊñºÁ™ÅÂá∫‰∏çÂèØÁßªÂãïÁöÑÈÉ®ÂàÜ‰ª•ÈÄ≤Ë°å‰ΩçÁΩÆ‰øÆÊ≠£Ôºå‰ª•Âèä 2) ÊñáÂ≠óÊèèËø∞ÔºåÁî®ÊñºÊåáÁ§∫ÊóãËΩâ‰øÆÊ≠£ÁöÑÊΩõÂú®ÊñπÂêë„ÄÇÂú®Êé®ÁêÜÊúüÈñìÔºåÂºïÂÖ•‰∫ÜÂõûÈ•ãË≥áË®äÊèêÂèñÊ®°ÁµÑÔºå‰ª•Ë≠òÂà•Â§±ÊïóÂéüÂõ†ÔºåËÆì AIC MLLM ËÉΩÂ§†‰ΩøÁî®Â∞çÊáâÁöÑÊèêÁ§∫Ëá™ÈÅ©ÊáâÂú∞‰øÆÊ≠£ÂßøÂã¢È†êÊ∏¨„ÄÇÁÇ∫‰∫ÜÈÄ≤‰∏ÄÊ≠•Â¢ûÂº∑Êìç‰ΩúÁ©©ÂÆöÊÄßÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÊ∏¨Ë©¶ÊôÇÈñìÈÅ©ÊáâÁ≠ñÁï•ÔºåËÆì AIC MLLM ËÉΩÂ§†Êõ¥Â•ΩÂú∞ÈÅ©ÊáâÁï∂ÂâçÁöÑÂ†¥ÊôØÁµÑÊÖã„ÄÇÊúÄÂæåÔºåÂú®Ê®°Êì¨ÂíåÁúüÂØ¶‰∏ñÁïåÁí∞Â¢É‰∏≠ÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºå‰ª•Ë©ï‰º∞ÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ï„ÄÇÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑ AIC MLLM ËÉΩÂ§†ÈÄèÈÅéÂà©Áî®‰∫íÂãïÁ∂ìÈ©óÊèêÁ§∫ÊúâÊïàÂú∞‰øÆÊ≠£Â§±ÊïóÊ®£Êú¨„ÄÇÂèØ‰ª•Âú® https://sites.google.com/view/aic-mllm ÊâæÂà∞ÂØ¶ÈöõÊìç‰ΩúÁ§∫ÁØÑ

##### **GECOBench: A Gender-Controlled Text Dataset and Benchmark for Quantifying Biases in Explanations**
2406.11547v1 by Rick Wilming, Artur Dox, Hjalmar Schulz, Marta Oliveira, Benedict Clark, Stefan Haufe

Large pre-trained language models have become popular for many applications
and form an important backbone of many downstream tasks in natural language
processing (NLP). Applying 'explainable artificial intelligence' (XAI)
techniques to enrich such models' outputs is considered crucial for assuring
their quality and shedding light on their inner workings. However, large
language models are trained on a plethora of data containing a variety of
biases, such as gender biases, affecting model weights and, potentially,
behavior. Currently, it is unclear to what extent such biases also impact model
explanations in possibly unfavorable ways. We create a gender-controlled text
dataset, GECO, in which otherwise identical sentences appear in male and female
forms. This gives rise to ground-truth 'world explanations' for gender
classification tasks, enabling the objective evaluation of the correctness of
XAI methods. We also provide GECOBench, a rigorous quantitative evaluation
framework benchmarking popular XAI methods, applying them to pre-trained
language models fine-tuned to different degrees. This allows us to investigate
how pre-training induces undesirable bias in model explanations and to what
extent fine-tuning can mitigate such explanation bias. We show a clear
dependency between explanation performance and the number of fine-tuned layers,
where XAI methods are observed to particularly benefit from fine-tuning or
complete retraining of embedding layers. Remarkably, this relationship holds
for models achieving similar classification performance on the same task. With
that, we highlight the utility of the proposed gender-controlled dataset and
novel benchmarking approach for research and development of novel XAI methods.
All code including dataset generation, model training, evaluation and
visualization is available at: https://github.com/braindatalab/gecobench

ÊëòË¶ÅÔºö<paragraph>Â§ßÂûãÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÂ∑≤Âª£Ê≥õÊáâÁî®ÊñºË®±Â§öÊáâÁî®Á®ãÂºè‰∏≠Ôºå‰∏¶ÊßãÊàêËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰∏≠Ë®±Â§ö‰∏ãÊ∏∏‰ªªÂãôÁöÑÈáçË¶ÅÈ™®Âππ„ÄÇÂ∞á„ÄåÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß„Äç(XAI) ÊäÄË°ìÊáâÁî®ÊñºË±êÂØåÊ≠§È°ûÊ®°ÂûãÁöÑËº∏Âá∫ÔºåË¢´Ë™çÁÇ∫Â∞çÊñºÁ¢∫‰øùÂÖ∂ÂìÅË≥™‰∏¶Èó°ÊòéÂÖ∂ÂÖßÈÉ®ÈÅã‰ΩúËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÊòØÂú®ÂåÖÂê´ÂêÑÁ®ÆÂÅèÂ∑ÆÁöÑÈæêÂ§ßË≥áÊñô‰∏äË®ìÁ∑¥ÁöÑÔºå‰æãÂ¶ÇÊÄßÂà•ÂÅèÂ∑ÆÔºåÊúÉÂΩ±ÈüøÊ®°ÂûãÊ¨äÈáçÂíåÊΩõÂú®Ë°åÁÇ∫„ÄÇÁõÆÂâçÂ∞ö‰∏çÊ∏ÖÊ•öÊ≠§È°ûÂÅèÂ∑ÆÂú®‰ΩïÁ®ÆÁ®ãÂ∫¶‰∏ä‰πüÊúÉ‰ª•ÂèØËÉΩ‰∏çÂà©ÁöÑÂΩ±ÈüøÊ®°ÂûãËß£Èáã„ÄÇÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÊÄßÂà•ÊéßÂà∂ÊñáÂ≠óË≥áÊñôÈõÜ GECOÔºåÂÖ∂‰∏≠ÂéüÊú¨Áõ∏ÂêåÁöÑÂè•Â≠ê‰ª•Áî∑ÊÄßÂíåÂ•≥ÊÄßÂΩ¢ÂºèÂá∫Áèæ„ÄÇÈÄôÁî¢Áîü‰∫ÜÊÄßÂà•ÂàÜÈ°û‰ªªÂãôÁöÑÁúüÂØ¶„Äå‰∏ñÁïåËß£Èáã„ÄçÔºå‰ΩøÊàëÂÄëËÉΩÂ§†ÂÆ¢ËßÄË©ï‰º∞ XAI ÊñπÊ≥ïÁöÑÊ≠£Á¢∫ÊÄß„ÄÇÊàëÂÄëÈÇÑÊèê‰æõ‰∫Ü GECOBenchÔºåÈÄôÊòØ‰∏ÄÂÄãÂö¥Ë¨πÁöÑÈáèÂåñË©ï‰º∞Êû∂ÊßãÔºåÁî®ÊñºÂ∞çÊµÅË°åÁöÑ XAI ÊñπÊ≥ïÈÄ≤Ë°åÂü∫Ê∫ñÊ∏¨Ë©¶ÔºåÂ∞áÂÆÉÂÄëÊáâÁî®ÊñºÁ∂ìÈÅé‰∏çÂêåÁ®ãÂ∫¶ÂæÆË™øÁöÑÈ†êË®ìÁ∑¥Ë™ûË®ÄÊ®°Âûã„ÄÇÈÄô‰ΩøÊàëÂÄëËÉΩÂ§†Á†îÁ©∂È†êË®ìÁ∑¥Â¶Ç‰ΩïÂ∞éËá¥Ê®°ÂûãËß£Èáã‰∏≠Âá∫Áèæ‰∏çËâØÂÅèÂ∑ÆÔºå‰ª•ÂèäÂæÆË™øÂèØ‰ª•Âú®Â§öÂ§ßÁ®ãÂ∫¶‰∏äÊ∏õËºïÈÄôÁ®ÆËß£ÈáãÂÅèÂ∑Æ„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜËß£ÈáãÊïàËÉΩËàáÂæÆË™øÂ±§Êï∏‰πãÈñìÁöÑÊòéÈ°Ø‰æùË≥¥Èóú‰øÇÔºåÂÖ∂‰∏≠ËßÄÂØüÂà∞ XAI ÊñπÊ≥ïÁâπÂà•ÂèóÁõäÊñºÂæÆË™øÊàñÂµåÂÖ•Â±§ÁöÑÂÆåÊï¥ÈáçÊñ∞Ë®ìÁ∑¥„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÈÄôÁ®ÆÈóú‰øÇÈÅ©Áî®ÊñºÂú®Âêå‰∏Ä‰ªªÂãô‰∏äÂØ¶ÁèæÈ°û‰ººÂàÜÈ°ûÊïàËÉΩÁöÑÊ®°Âûã„ÄÇÊúâ‰∫ÜÈÄô‰∫õÔºåÊàëÂÄëÂº∑Ë™ø‰∫ÜÊâÄÊèêÂá∫ÁöÑÊÄßÂà•ÊéßÂà∂Ë≥áÊñôÈõÜÂíåÊñ∞Âü∫Ê∫ñÊ∏¨Ë©¶ÊñπÊ≥ïÂ∞çÊñ∞ XAI ÊñπÊ≥ïÁöÑÁ†îÁ©∂ÂíåÈñãÁôºÁöÑÊïàÁî®„ÄÇÊâÄÊúâÁ®ãÂºèÁ¢ºÔºåÂåÖÊã¨Ë≥áÊñôÈõÜÁîüÊàê„ÄÅÊ®°ÂûãË®ìÁ∑¥„ÄÅË©ï‰º∞ÂíåË¶ñË¶∫ÂåñÔºåÈÉΩÂèØ‰ª•Âú®‰ª•‰∏ã‰ΩçÁΩÆÂèñÂæóÔºöhttps://github.com/braindatalab/gecobench</paragraph>

##### **GigaSpeech 2: An Evolving, Large-Scale and Multi-domain ASR Corpus for Low-Resource Languages with Automated Crawling, Transcription and Refinement**
2406.11546v1 by Yifan Yang, Zheshu Song, Jianheng Zhuo, Mingyu Cui, Jinpeng Li, Bo Yang, Yexing Du, Ziyang Ma, Xunying Liu, Ziyuan Wang, Ke Li, Shuai Fan, Kai Yu, Wei-Qiang Zhang, Guoguo Chen, Xie Chen

The evolution of speech technology has been spurred by the rapid increase in
dataset sizes. Traditional speech models generally depend on a large amount of
labeled training data, which is scarce for low-resource languages. This paper
presents GigaSpeech 2, a large-scale, multi-domain, multilingual speech
recognition corpus. It is designed for low-resource languages and does not rely
on paired speech and text data. GigaSpeech 2 comprises about 30,000 hours of
automatically transcribed speech, including Thai, Indonesian, and Vietnamese,
gathered from unlabeled YouTube videos. We also introduce an automated pipeline
for data crawling, transcription, and label refinement. Specifically, this
pipeline uses Whisper for initial transcription and TorchAudio for forced
alignment, combined with multi-dimensional filtering for data quality
assurance. A modified Noisy Student Training is developed to further refine
flawed pseudo labels iteratively, thus enhancing model performance.
Experimental results on our manually transcribed evaluation set and two public
test sets from Common Voice and FLEURS confirm our corpus's high quality and
broad applicability. Notably, ASR models trained on GigaSpeech 2 can reduce the
word error rate for Thai, Indonesian, and Vietnamese on our challenging and
realistic YouTube test set by 25% to 40% compared to the Whisper large-v3
model, with merely 10% model parameters. Furthermore, our ASR models trained on
Gigaspeech 2 yield superior performance compared to commercial services. We
believe that our newly introduced corpus and pipeline will open a new avenue
for low-resource speech recognition and significantly facilitate research in
this area.

ÊëòË¶ÅÔºö<paragraph>Ë™ûÈü≥ÊäÄË°ìÁöÑÊºîÈÄ≤ÂèóÂà∞Ë≥áÊñôÈõÜË¶èÊ®°Âø´ÈÄüÂ¢ûÂä†ÁöÑÂà∫ÊøÄ„ÄÇÂÇ≥Áµ±ÁöÑË™ûÈü≥Ê®°ÂûãÈÄöÂ∏∏‰æùË≥¥ÊñºÂ§ßÈáèÁöÑÊ®ôË®òË®ìÁ∑¥Ë≥áÊñôÔºåËÄåÈÄôÂ∞ç‰ΩéË≥áÊ∫êË™ûË®Ä‰æÜË™™ÂæàÁ®ÄÂ∞ë„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü GigaSpeech 2Ôºå‰∏ÄÂÄãÂ§ßÂûã„ÄÅÂ§öÈ†òÂüü„ÄÅÂ§öË™ûË®ÄÁöÑË™ûÈü≥Ëæ®Ë≠òË™ûÊñôÂ∫´„ÄÇÂÆÉÊòØÁÇ∫‰ΩéË≥áÊ∫êË™ûË®ÄË®≠Ë®àÁöÑÔºå‰∏î‰∏ç‰æùË≥¥ÊàêÂ∞çÁöÑË™ûÈü≥ÂíåÊñáÂ≠óË≥áÊñô„ÄÇGigaSpeech 2 ÂåÖÂê´Á¥Ñ 30,000 Â∞èÊôÇÁöÑËá™ÂãïËΩâÈåÑË™ûÈü≥ÔºåÂåÖÊã¨Ê≥∞Ë™û„ÄÅÂç∞Â∞ºË™ûÂíåË∂äÂçóË™ûÔºåÈÄô‰∫õË™ûÈü≥ÊòØÂæûÊú™Ê®ôË®òÁöÑ YouTube ÂΩ±Áâá‰∏≠Êî∂ÈõÜ‰æÜÁöÑ„ÄÇÊàëÂÄëÈÇÑÂ∞éÂÖ•‰∫Ü‰∏ÄÂÄãÁî®ÊñºË≥áÊñôÁà¨Âèñ„ÄÅËΩâÈåÑÂíåÊ®ôÁ±§Á≤æÁÖâÁöÑËá™ÂãïÂåñÁÆ°ÈÅì„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÈÄôÂÄãÁÆ°ÈÅì‰ΩøÁî® Whisper ÈÄ≤Ë°åÂàùÂßãËΩâÈåÑÔºå‰∏¶‰ΩøÁî® TorchAudio ÈÄ≤Ë°åÂº∑Âà∂ÊØîÂ∞çÔºåÁµêÂêàÂ§öÁ∂≠Â∫¶ÈÅéÊøæ‰æÜÁ¢∫‰øùË≥áÊñôÂìÅË≥™„ÄÇÈñãÁôº‰∫Ü‰∏ÄÂÄãÊîπËâØÁöÑ Noisy Student TrainingÔºåÁî®ÊñºÈÄ≤‰∏ÄÊ≠•ÂèçË¶ÜÁ≤æÁÖâÊúâÁº∫Èô∑ÁöÑÂÅΩÊ®ôÁ±§ÔºåÂæûËÄåÂ¢ûÂº∑Ê®°ÂûãÊïàËÉΩ„ÄÇÊàëÂÄëÊâãÂãïËΩâÈåÑÁöÑË©ï‰º∞ÈõÜÂíå‰æÜËá™ Common Voice Âíå FLEURS ÁöÑÂÖ©ÂÄãÂÖ¨ÈñãÊ∏¨Ë©¶ÈõÜÁöÑÂØ¶È©óÁµêÊûúË≠âÂØ¶‰∫ÜÊàëÂÄëË™ûÊñôÂ∫´ÁöÑÈ´òÂìÅË≥™ÂíåÂª£Ê≥õÁöÑÈÅ©Áî®ÊÄß„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂú® GigaSpeech 2 ‰∏äË®ìÁ∑¥ÁöÑ ASR Ê®°ÂûãÂèØ‰ª•Â∞áÊàëÂÄëÂÖ∑ÊúâÊåëÊà∞ÊÄßÂíåÂØ¶ÈöõÊÄßÁöÑ YouTube Ê∏¨Ë©¶ÈõÜ‰∏äÊ≥∞Ë™û„ÄÅÂç∞Â∞ºË™ûÂíåË∂äÂçóË™ûÁöÑÂ≠óÂÖÉÈåØË™§ÁéáÈôç‰Ωé 25% Âà∞ 40%ÔºåËÄå Whisper large-v3 Ê®°ÂûãÂÉÖÊúâ 10% ÁöÑÊ®°ÂûãÂèÉÊï∏„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂú® Gigaspeech 2 ‰∏äË®ìÁ∑¥ÁöÑ ASR Ê®°ÂûãËàáÂïÜÊ•≠ÊúçÂãôÁõ∏ÊØîÔºåË°®ÁèæÂá∫Êõ¥ÂÑ™Áï∞ÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁõ∏‰ø°ÊàëÂÄëÊñ∞Êé®Âá∫ÁöÑË™ûÊñôÂ∫´ÂíåÁÆ°ÈÅìÂ∞áÁÇ∫‰ΩéË≥áÊ∫êË™ûÈü≥Ëæ®Ë≠òÈñãÂïü‰∏ÄÊ¢ùÊñ∞ÈÄîÂæëÔºå‰∏¶È°ØËëó‰øÉÈÄ≤ÈÄôÊñπÈù¢ÁöÑÁ†îÁ©∂„ÄÇ</paragraph>

##### **Do Parameters Reveal More than Loss for Membership Inference?**
2406.11544v1 by Anshuman Suri, Xiao Zhang, David Evans

Membership inference attacks aim to infer whether an individual record was
used to train a model, serving as a key tool for disclosure auditing. While
such evaluations are useful to demonstrate risk, they are computationally
expensive and often make strong assumptions about potential adversaries' access
to models and training environments, and thus do not provide very tight bounds
on leakage from potential attacks. We show how prior claims around black-box
access being sufficient for optimal membership inference do not hold for most
useful settings such as stochastic gradient descent, and that optimal
membership inference indeed requires white-box access. We validate our findings
with a new white-box inference attack IHA (Inverse Hessian Attack) that
explicitly uses model parameters by taking advantage of computing
inverse-Hessian vector products. Our results show that both audits and
adversaries may be able to benefit from access to model parameters, and we
advocate for further research into white-box methods for membership privacy
auditing.

ÊëòË¶ÅÔºöÊàêÂì°Êé®Ë´ñÊîªÊìäÊó®Âú®Êé®Ë´ñÂÄãÂà•Ë®òÈåÑÊòØÂê¶Áî®ÊñºË®ìÁ∑¥Ê®°ÂûãÔºå‰ΩúÁÇ∫Êè≠Èú≤Á®ΩÊ†∏ÁöÑÈóúÈçµÂ∑•ÂÖ∑„ÄÇÈõñÁÑ∂Ê≠§È°ûË©ï‰º∞ÊúâÂä©ÊñºË≠âÊòéÈ¢®Èö™Ôºå‰ΩÜÂÆÉÂÄëÂú®Ë®àÁÆó‰∏äÂæàÊòÇË≤¥ÔºåËÄå‰∏îÈÄöÂ∏∏Â∞çÊΩõÂú®Â∞çÊâãË®™ÂïèÊ®°ÂûãÂíåË®ìÁ∑¥Áí∞Â¢ÉÂÅöÂá∫Âº∑ÊúâÂäõÁöÑÂÅáË®≠ÔºåÂõ†Ê≠§ÁÑ°Ê≥ïÊèê‰æõÈùûÂ∏∏Âö¥Ê†ºÁöÑÊΩõÂú®ÊîªÊìäÊ¥©ÊºèÁØÑÂúç„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊúâÈóúÈªëÁõíÂ≠òÂèñË∂≥‰ª•ÈÄ≤Ë°åÊúÄ‰Ω≥ÊàêÂì°Êé®Ë´ñÁöÑÂÖàÂâçË™™Ê≥ï‰∏¶‰∏çÈÅ©Áî®ÊñºÂ§ßÂ§öÊï∏ÊúâÁî®ÁöÑË®≠ÂÆöÔºå‰æãÂ¶ÇÈö®Ê©üÊ¢ØÂ∫¶‰∏ãÈôçÔºå‰ª•ÂèäÊúÄ‰Ω≥ÊàêÂì°Êé®Ë´ñÁ¢∫ÂØ¶ÈúÄË¶ÅÁôΩÁõíÂ≠òÂèñ„ÄÇÊàëÂÄë‰ΩøÁî®Êñ∞ÁöÑÁôΩÁõíÊé®Ë´ñÊîªÊìä IHAÔºàÈÄÜÊµ∑Ê£ÆÊîªÊìäÔºâÈ©óË≠âÊàëÂÄëÁöÑÁôºÁèæÔºåË©≤ÊîªÊìäÈÄèÈÅéÂà©Áî®Ë®àÁÆóÈÄÜÊµ∑Ê£ÆÂêëÈáèÁ©çÔºåÊòéÁ¢∫‰ΩøÁî®Ê®°ÂûãÂèÉÊï∏„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåÁ®ΩÊ†∏ÂíåÂ∞çÊâãÈÉΩÂèØ‰ª•ÂæûË®™ÂïèÊ®°ÂûãÂèÉÊï∏‰∏≠ÂèóÁõäÔºåÊàëÂÄë‰∏ªÂºµÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂ÁôΩÁõíÊñπÊ≥ï‰ª•ÈÄ≤Ë°åÊàêÂì°Èö±ÁßÅÁ®ΩÊ†∏„ÄÇ

##### **Improving Quality Control of Whole Slide Images by Explicit Artifact Augmentation**
2406.11538v1 by Artur Jurgas, Marek Wodzinski, Marina D'Amato, Jeroen van der Laak, Manfredo Atzori, Henning M√ºller

The problem of artifacts in whole slide image acquisition, prevalent in both
clinical workflows and research-oriented settings, necessitates human
intervention and re-scanning. Overcoming this challenge requires developing
quality control algorithms, that are hindered by the limited availability of
relevant annotated data in histopathology. The manual annotation of
ground-truth for artifact detection methods is expensive and time-consuming.
This work addresses the issue by proposing a method dedicated to augmenting
whole slide images with artifacts. The tool seamlessly generates and blends
artifacts from an external library to a given histopathology dataset. The
augmented datasets are then utilized to train artifact classification methods.
The evaluation shows their usefulness in classification of the artifacts, where
they show an improvement from 0.10 to 0.01 AUROC depending on the artifact
type. The framework, model, weights, and ground-truth annotations are freely
released to facilitate open science and reproducible research.

ÊëòË¶ÅÔºöÂú®Ëá®Â∫ä‰∏äÊàñÁ†îÁ©∂‰∏≠ÔºåÂÖ®ÂπªÁáàÁâáÂΩ±ÂÉèÊì∑ÂèñÊôÇÁî¢ÁîüÁöÑÂÅΩÂÉèÂïèÈ°åÔºåÈúÄË¶Å‰∫∫ÁÇ∫‰ªãÂÖ•ÂíåÈáçÊñ∞ÊéÉÊèè„ÄÇÂÖãÊúçÈÄôÂÄãÊåëÊà∞ÈúÄË¶ÅÈñãÁôºÂìÅË≥™ÊéßÁÆ°ÊºîÁÆóÊ≥ïÔºå‰ΩÜÁµÑÁπîÁóÖÁêÜÂ≠∏‰∏≠Áõ∏ÈóúË®ªËß£Ë≥áÊñôÊúâÈôêÔºåÈòªÁ§ô‰∫ÜÊºîÁÆóÊ≥ïÁöÑÁôºÂ±ï„ÄÇ‰∫∫Â∑•Ë®ªËß£ÂÅΩÂÉèÂÅµÊ∏¨ÊñπÊ≥ïÁöÑÁúüÂØ¶ÊÉÖÊ≥ÅÊó¢ÊòÇË≤¥ÂèàË≤ªÊôÇ„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÊñπÊ≥ï‰æÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÈÄôÂÄãÊñπÊ≥ïÂ∞àÈñÄÁî®‰æÜÂ¢ûÂä†ÂÖ®ÂπªÁáàÁâáÂΩ±ÂÉè‰∏≠ÁöÑÂÅΩÂÉè„ÄÇÈÄôÂÄãÂ∑•ÂÖ∑ÂèØ‰ª•ÁÑ°Á∏´Âú∞ÂæûÂ§ñÈÉ®Ë≥áÊñôÂ∫´Áî¢Áîü‰∏¶Ê∑∑ÂêàÂÅΩÂÉèÂà∞Áµ¶ÂÆöÁöÑÁµÑÁπîÁóÖÁêÜÂ≠∏Ë≥áÊñôÈõÜ„ÄÇÁÑ∂Âæå‰ΩøÁî®Êì¥ÂÖÖÂæåÁöÑË≥áÊñôÈõÜ‰æÜË®ìÁ∑¥ÂÅΩÂÉèÂàÜÈ°ûÊñπÊ≥ï„ÄÇË©ï‰º∞È°ØÁ§∫Âá∫ÂÆÉÂÄëÂú®ÂÅΩÂÉèÂàÜÈ°û‰∏≠ÁöÑÊïàÁî®ÔºåÂú®‰∏çÂêåÁöÑÂÅΩÂÉèÈ°ûÂûã‰∏≠ÔºåÂÆÉÂÄëÁöÑ AUROC Âæû 0.10 ÈÄ≤Ê≠•Âà∞ 0.01„ÄÇÈÄôÂÄãÊû∂Êßã„ÄÅÊ®°Âûã„ÄÅÊ¨äÈáçÂíåÁúüÂØ¶Ë®ªËß£ÊòØÂÖçË≤ªÈáãÂá∫ÁöÑÔºå‰ª•Âà©ÊñºÈñãÊîæÁßëÂ≠∏ÂíåÂèØÈáçË£ΩÁöÑÁ†îÁ©∂„ÄÇ

##### **Explainable Artificial Intelligence and Multicollinearity : A Mini Review of Current Approaches**
2406.11524v1 by Ahmed M Salih

Explainable Artificial Intelligence (XAI) methods help to understand the
internal mechanism of machine learning models and how they reach a specific
decision or made a specific action. The list of informative features is one of
the most common output of XAI methods. Multicollinearity is one of the big
issue that should be considered when XAI generates the explanation in terms of
the most informative features in an AI system. No review has been dedicated to
investigate the current approaches to handle such significant issue. In this
paper, we provide a review of the current state-of-the-art approaches in
relation to the XAI in the context of recent advances in dealing with the
multicollinearity issue. To do so, we searched in three repositories that are:
Web of Science, Scopus and IEEE Xplore to find pertinent published papers.
After excluding irrelevant papers, seven papers were considered in the review.
In addition, we discuss the current XAI methods and their limitations in
dealing with the multicollinearity and suggest future directions.

ÊëòË¶ÅÔºöÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖßÔºàXAIÔºâÊñπÊ≥ïÊúâÂä©ÊñºÁêÜËß£Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÁöÑÂÖßÈÉ®Ê©üÂà∂Ôºå‰ª•ÂèäÂÆÉÂÄëÂ¶Ç‰ΩïÈÅîÊàêÁâπÂÆöÊ±∫Á≠ñÊàñÊé°ÂèñÁâπÂÆöË°åÂãï„ÄÇË≥áË®äÊÄßÁâπÂæµÊ∏ÖÂñÆÊòØ XAI ÊñπÊ≥ïÊúÄÂ∏∏Ë¶ãÁöÑËº∏Âá∫‰πã‰∏Ä„ÄÇÂ§öÈáçÂÖ±Á∑öÊÄßÊòØ XAI Âú® AI Á≥ªÁµ±‰∏≠Ê†πÊìöË≥áË®äÊÄßÁâπÂæµÁî¢ÁîüËß£ÈáãÊôÇÊáâËÄÉÊÖÆÁöÑ‰∏ªË¶ÅÂïèÈ°å‰πã‰∏Ä„ÄÇÁõÆÂâçÈÇÑÊ≤íÊúâ‰ªª‰ΩïË©ïË´ñÂ∞àÈñÄÊé¢Ë®éËôïÁêÜÊ≠§È°ûÈáçÂ§ßÂïèÈ°åÁöÑÁèæÊúâÊñπÊ≥ï„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂõûÈ°ß‰∫ÜËàá XAI Áõ∏ÈóúÁöÑÁèæÊúâÊúÄÂÖàÈÄ≤ÊñπÊ≥ïÔºå‰ª•ÂèäÂú®ËôïÁêÜÂ§öÈáçÂÖ±Á∑öÊÄßÂïèÈ°åÊñπÈù¢ÂèñÂæóÁöÑÊúÄÊñ∞ÈÄ≤Â±ï„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂú® Web of Science„ÄÅScopus Âíå IEEE Xplore ‰∏âÂÄãË≥áÊñôÂ∫´‰∏≠ÊêúÂ∞ãÁõ∏ÈóúÂ∑≤ÁôºË°®ÁöÑË´ñÊñá„ÄÇÂú®ÊéíÈô§ÁÑ°ÈóúË´ñÊñáÂæåÔºåÊàëÂÄëÂú®Ë©ïË´ñ‰∏≠ËÄÉÊÖÆ‰∫Ü‰∏ÉÁØáË´ñÊñá„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË®éË´ñ‰∫ÜÁèæÊúâÁöÑ XAI ÊñπÊ≥ïÂèäÂÖ∂Âú®ËôïÁêÜÂ§öÈáçÂÖ±Á∑öÊÄßÊñπÈù¢ÁöÑÈôêÂà∂Ôºå‰∏¶ÊèêÂá∫‰∫ÜÊú™‰æÜÁöÑÊñπÂêë„ÄÇ

##### **FullCert: Deterministic End-to-End Certification for Training and Inference of Neural Networks**
2406.11522v1 by Tobias Lorenz, Marta Kwiatkowska, Mario Fritz

Modern machine learning models are sensitive to the manipulation of both the
training data (poisoning attacks) and inference data (adversarial examples).
Recognizing this issue, the community has developed many empirical defenses
against both attacks and, more recently, provable certification methods against
inference-time attacks. However, such guarantees are still largely lacking for
training-time attacks. In this work, we present FullCert, the first end-to-end
certifier with sound, deterministic bounds, which proves robustness against
both training-time and inference-time attacks. We first bound all possible
perturbations an adversary can make to the training data under the considered
threat model. Using these constraints, we bound the perturbations' influence on
the model's parameters. Finally, we bound the impact of these parameter changes
on the model's prediction, resulting in joint robustness guarantees against
poisoning and adversarial examples. To facilitate this novel certification
paradigm, we combine our theoretical work with a new open-source library
BoundFlow, which enables model training on bounded datasets. We experimentally
demonstrate FullCert's feasibility on two different datasets.

ÊëòË¶ÅÔºöÁèæ‰ª£Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÂ∞çÊñºË®ìÁ∑¥Êï∏ÊìöÔºà‰∏≠ÊØíÊîªÊìäÔºâÂíåÊé®Ë´ñÊï∏ÊìöÔºàÂ∞çÊäóÁØÑ‰æãÔºâÁöÑÊìçÁ∏±ÂæàÊïèÊÑü„ÄÇË™çË≠òÂà∞ÈÄôÂÄãÂïèÈ°åÔºåÁ§æÁæ§Â∑≤Á∂ìÈáùÂ∞çÈÄôÂÖ©Á®ÆÊîªÊìäÈñãÁôºÂá∫Ë®±Â§öÁ∂ìÈ©óÈò≤Á¶¶Êé™ÊñΩÔºåËÄå‰∏îÊúÄËøëÈÇÑÈáùÂ∞çÊé®Ë´ñÊôÇÈñìÊîªÊìäÈñãÁôºÂá∫ÂèØË≠âÊòéË™çË≠âÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÂ∞çÊñºË®ìÁ∑¥ÊôÇÈñìÊîªÊìäÔºåÊ≠§È°ûÊìî‰øù‰ªçÁÑ∂Âö¥Èáç‰∏çË∂≥„ÄÇÂú®Ê≠§Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ FullCertÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂÖ∑ÊúâÂÅ•ÂÖ®„ÄÅÁ¢∫ÂÆöÊÄßÁïåÁ∑öÁöÑÁ´ØÂ∞çÁ´ØË™çË≠âÂô®ÔºåÂÆÉË≠âÊòé‰∫ÜÂ∞çË®ìÁ∑¥ÊôÇÈñìÂíåÊé®Ë´ñÊôÇÈñìÊîªÊìäÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÊàëÂÄëÈ¶ñÂÖàÁïåÂÆöÂú®ÊâÄËÄÉÊÖÆÁöÑÂ®ÅËÑÖÊ®°Âûã‰∏ãÔºåÂ∞çÊâãÂ∞çË®ìÁ∑¥Êï∏ÊìöÂèØ‰ª•ÈÄ≤Ë°åÁöÑÊâÄÊúâÊìæÂãï„ÄÇ‰ΩøÁî®ÈÄô‰∫õÁ¥ÑÊùüÊ¢ù‰ª∂ÔºåÊàëÂÄëÁïåÂÆöÊìæÂãïÂ∞çÊ®°ÂûãÂèÉÊï∏ÁöÑÂΩ±Èüø„ÄÇÊúÄÂæåÔºåÊàëÂÄëÁïåÂÆöÈÄô‰∫õÂèÉÊï∏ËÆäÊõ¥Â∞çÊ®°ÂûãÈ†êÊ∏¨ÁöÑÂΩ±ÈüøÔºåÂæûËÄåÈáùÂ∞ç‰∏≠ÊØíÂíåÂ∞çÊäóÁØÑ‰æãÁî¢ÁîüËÅØÂêàÁ©©ÂÅ•ÊÄßÊìî‰øù„ÄÇÁÇ∫‰∫Ü‰øÉÈÄ≤ÈÄôÁ®ÆÊñ∞Á©éÁöÑË™çË≠âÁØÑ‰æãÔºåÊàëÂÄëÂ∞áÊàëÂÄëÁöÑÁêÜË´ñÂ∑•‰ΩúËàá‰∏ÄÂÄãÊñ∞ÁöÑÈñãÊîæÂéüÂßãÁ¢ºÂáΩÂºèÂ∫´ BoundFlow ÁµêÂêàËµ∑‰æÜÔºåÂÆÉÂèØ‰ª•Âú®ÊúâÁïåË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÊ®°ÂûãË®ìÁ∑¥„ÄÇÊàëÂÄëÂú®ÂÖ©ÂÄã‰∏çÂêåÁöÑË≥áÊñôÈõÜ‰∏ä‰ª•ÂØ¶È©óÊñπÂºèË≠âÊòé‰∫Ü FullCert ÁöÑÂèØË°åÊÄß„ÄÇ

##### **Revisiting Spurious Correlation in Domain Generalization**
2406.11517v1 by Bin Qin, Jiangmeng Li, Yi Li, Xuesong Wu, Yupeng Wang, Wenwen Qiang, Jianwen Cao

Without loss of generality, existing machine learning techniques may learn
spurious correlation dependent on the domain, which exacerbates the
generalization of models in out-of-distribution (OOD) scenarios. To address
this issue, recent works build a structural causal model (SCM) to describe the
causality within data generation process, thereby motivating methods to avoid
the learning of spurious correlation by models. However, from the machine
learning viewpoint, such a theoretical analysis omits the nuanced difference
between the data generation process and representation learning process,
resulting in that the causal analysis based on the former cannot well adapt to
the latter. To this end, we explore to build a SCM for representation learning
process and further conduct a thorough analysis of the mechanisms underlying
spurious correlation. We underscore that adjusting erroneous covariates
introduces bias, thus necessitating the correct selection of spurious
correlation mechanisms based on practical application scenarios. In this
regard, we substantiate the correctness of the proposed SCM and further propose
to control confounding bias in OOD generalization by introducing a propensity
score weighted estimator, which can be integrated into any existing OOD method
as a plug-and-play module. The empirical results comprehensively demonstrate
the effectiveness of our method on synthetic and large-scale real OOD datasets.

ÊëòË¶ÅÔºöÂú®‰∏çÂ§±‰∏ÄËà¨ÊÄßÁöÑÂâçÊèê‰∏ãÔºåÁé∞ÊúâÁöÑÊú∫Âô®Â≠¶‰π†ÊäÄÊúØÂèØËÉΩ‰ºöÂ≠¶‰π†
‰æùËµñ‰∫éÈ¢ÜÂüüÁöÑËôöÂÅáÁõ∏ÂÖ≥ÊÄßÔºåËøô‰ºöÂä†ÂâßÊ®°ÂûãÂú®ÂàÜÂ∏ÉÂ§ñ (OOD) Âú∫ÊôØ‰∏≠ÁöÑÊ≥õÂåñ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥
Ëøô‰∏™ÈóÆÈ¢òÔºåÊúÄËøëÁöÑÂ∑•‰ΩúÊûÑÂª∫‰∫Ü‰∏Ä‰∏™ÁªìÊûÑÂõ†ÊûúÊ®°Âûã (SCM) Êù•ÊèèËø∞
Êï∞ÊçÆÁîüÊàêËøáÁ®ã‰∏≠ÁöÑÂõ†ÊûúÂÖ≥Á≥ªÔºå‰ªéËÄåÊøÄÂèëÊñπÊ≥ïÊù•ÈÅøÂÖç
Ê®°ÂûãÂ≠¶‰π†ËôöÂÅáÁõ∏ÂÖ≥ÊÄß„ÄÇÁÑ∂ËÄåÔºå‰ªéÊú∫Âô®ÁöÑËßíÂ∫¶Êù•Áúã
Â≠¶‰π†ËßÇÁÇπÔºåËøôÁßçÁêÜËÆ∫ÂàÜÊûêÂøΩÁï•‰∫ÜÊï∞ÊçÆÁîüÊàêËøáÁ®ãÂíåË°®Á§∫Â≠¶‰π†ËøáÁ®ã‰πãÈó¥ÁöÑÁªÜÂæÆÂ∑ÆÂà´Ôºå
ÂØºËá¥Âü∫‰∫éÂâçËÄÖÁöÑÂõ†ÊûúÂàÜÊûê‰∏çËÉΩÂæàÂ•ΩÂú∞ÈÄÇÂ∫îÂêéËÄÖ„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨Êé¢Á¥¢ÊûÑÂª∫‰∏Ä‰∏™ SCM ‰ª•ËøõË°åË°®Á§∫Â≠¶‰π†
ËøáÁ®ãÂπ∂Ëøõ‰∏ÄÊ≠•ÂØπËôöÂÅáÁõ∏ÂÖ≥ÊÄßËÉåÂêéÁöÑÊú∫Âà∂ËøõË°åÂΩªÂ∫ïÂàÜÊûê„ÄÇÊàë‰ª¨Âº∫Ë∞ÉË∞ÉÊï¥ÈîôËØØÁöÑÂçèÂèòÈáè
‰ºöÂºïÂÖ•ÂÅèÂ∑ÆÔºåÂõ†Ê≠§ÈúÄË¶ÅÊ†πÊçÆÂÆûÈôÖÂ∫îÁî®Âú∫ÊôØÊ≠£Á°ÆÈÄâÊã©ËôöÂÅá
Áõ∏ÂÖ≥Êú∫Âà∂„ÄÇÂú®ËøôÊñπÈù¢ÔºåÊàë‰ª¨ËØÅÂÆû‰∫ÜÊâÄÊèêÂá∫ÁöÑ SCM ÁöÑÊ≠£Á°ÆÊÄßÔºåÂπ∂Ëøõ‰∏ÄÊ≠•ÊèêÂá∫
ÈÄöËøáÂºïÂÖ•ÂÄæÂêëÂæóÂàÜÂä†ÊùÉ‰º∞ËÆ°ÈáèÊù•ÊéßÂà∂ OOD Ê≥õÂåñ‰∏≠ÁöÑÊ∑∑ÊùÇÂÅèÂ∑ÆÔºåËØ•‰º∞ËÆ°ÈáèÂèØ‰ª•ÈõÜÊàêÂà∞‰ªª‰ΩïÁé∞ÊúâÁöÑ OOD ÊñπÊ≥ï‰∏≠
‰Ωú‰∏∫‰∏Ä‰∏™Âç≥ÊèíÂç≥Áî®ÁöÑÊ®°Âùó„ÄÇÁªèÈ™åÁªìÊûúÂÖ®Èù¢ËØÅÊòé‰∫Ü
Êàë‰ª¨ÊñπÊ≥ïÂú®ÂêàÊàêÂíåÂ§ßÂûãÁúüÂÆû OOD Êï∞ÊçÆÈõÜ‰∏äÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Counterfactual Debating with Preset Stances for Hallucination Elimination of LLMs**
2406.11514v1 by Yi Fang, Moxin Li, Wenjie Wang, Hui Lin, Fuli Feng

Large Language Models (LLMs) excel in various natural language processing
tasks but struggle with hallucination issues. Existing solutions have
considered utilizing LLMs' inherent reasoning abilities to alleviate
hallucination, such as self-correction and diverse sampling methods. However,
these methods often overtrust LLMs' initial answers due to inherent biases. The
key to alleviating this issue lies in overriding LLMs' inherent biases for
answer inspection. To this end, we propose a CounterFactual Multi-Agent Debate
(CFMAD) framework. CFMAD presets the stances of LLMs to override their inherent
biases by compelling LLMs to generate justifications for a predetermined
answer's correctness. The LLMs with different predetermined stances are engaged
with a skeptical critic for counterfactual debate on the rationality of
generated justifications. Finally, the debate process is evaluated by a
third-party judge to determine the final answer. Extensive experiments on four
datasets of three tasks demonstrate the superiority of CFMAD over existing
methods.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãô‰∏≠Ë°®ÁèæÂá∫Ëâ≤Ôºå‰ΩÜÂçªÈ£ΩÂèóÂπªË¶∫ÂïèÈ°åÊâÄËã¶„ÄÇÁèæÊúâÁöÑËß£Ê±∫ÊñπÊ°àÂ∑≤ËÄÉÊÖÆÂà©Áî® LLM ÂÖßÂú®ÁöÑÊé®ÁêÜËÉΩÂäõ‰æÜÊ∏õËºïÂπªË¶∫Ôºå‰æãÂ¶ÇËá™Êàë‰øÆÊ≠£ÂíåÂ§öÊ®£ÂåñÊäΩÊ®£ÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÁî±ÊñºÂÖßÂú®ÂÅèË¶ãÔºåÂ∏∏Â∏∏ÈÅéÂ∫¶‰ø°‰ªª LLM ÁöÑÂàùÂßãÁ≠îÊ°à„ÄÇËß£Ê±∫Ê≠§ÂïèÈ°åÁöÑÈóúÈçµÂú®ÊñºË¶ÜÂØ´ LLM Âõ∫ÊúâÁöÑÂÅèË¶ã‰ª•ÈÄ≤Ë°åÁ≠îÊ°àÊ™¢Êü•„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂèç‰∫ãÂØ¶Â§ö‰∏ªÈ´îËæØË´ñ (CFMAD) Ê°ÜÊû∂„ÄÇCFMAD È†êË®≠ LLM ÁöÑÁ´ãÂ†¥‰ª•Ë¶ÜÂØ´ÂÖ∂ÂÖßÂú®ÂÅèË¶ãÔºåÂº∑Ëø´ LLM ÁÇ∫È†êÂÖàÁ¢∫ÂÆöÁöÑÁ≠îÊ°àÊ≠£Á¢∫ÊÄßÁî¢Áîü‰æùÊìö„ÄÇÂÖ∑Êúâ‰∏çÂêåÈ†êÂÖàÁ¢∫ÂÆöÁ´ãÂ†¥ÁöÑ LLM Ëàá‰∏Ä‰ΩçÊá∑ÁñëË´ñËÄÖÈÄ≤Ë°åÂèç‰∫ãÂØ¶ËæØË´ñÔºåÈáùÂ∞çÂ∑≤Áî¢Áîü‰æùÊìöÁöÑÂêàÁêÜÊÄßÈÄ≤Ë°åËæØË´ñ„ÄÇÊúÄÂæåÔºåËæØË´ñÈÅéÁ®ãÁî±Á¨¨‰∏âÊñπË©ïÂØ©ÈÄ≤Ë°åË©ï‰º∞Ôºå‰ª•Á¢∫ÂÆöÊúÄÁµÇÁ≠îÊ°à„ÄÇÂú®‰∏âÂÄã‰ªªÂãôÁöÑÂõõÂÄãË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫Ü CFMAD ÂÑ™ÊñºÁèæÊúâÊñπÊ≥ï„ÄÇ

##### **On the Feasibility of Fidelity$^-$ for Graph Pruning**
2406.11504v1 by Yong-Min Shin, Won-Yong Shin

As one of popular quantitative metrics to assess the quality of explanation
of graph neural networks (GNNs), fidelity measures the output difference after
removing unimportant parts of the input graph. Fidelity has been widely used
due to its straightforward interpretation that the underlying model should
produce similar predictions when features deemed unimportant from the
explanation are removed. This raises a natural question: "Does fidelity induce
a global (soft) mask for graph pruning?" To solve this, we aim to explore the
potential of the fidelity measure to be used for graph pruning, eventually
enhancing the GNN models for better efficiency. To this end, we propose
Fidelity$^-$-inspired Pruning (FiP), an effective framework to construct global
edge masks from local explanations. Our empirical observations using 7 edge
attribution methods demonstrate that, surprisingly, general eXplainable AI
methods outperform methods tailored to GNNs in terms of graph pruning
performance.

ÊëòË¶ÅÔºö‰ΩúÁÇ∫Ë©ï‰º∞ÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) Ëß£ÈáãÂìÅË≥™ÁöÑÁÜ±ÈñÄÂÆöÈáèÊåáÊ®ô‰πã‰∏ÄÔºå‰øùÁúüÂ∫¶Ë°°ÈáèÁßªÈô§Ëº∏ÂÖ•ÂúñÂΩ¢‰∏≠‰∏çÈáçË¶ÅÈÉ®ÂàÜÂæåËº∏Âá∫ÁöÑÂ∑ÆÁï∞„ÄÇ‰øùÁúüÂ∫¶Âª£Ê≥õ‰ΩøÁî®ÔºåÂõ†ÁÇ∫ÂÖ∂Áõ¥ËßÄÁöÑËß£ÈáãÊòØÔºåÁï∂ÂæûËß£Èáã‰∏≠ÁßªÈô§Ë¢´Ë™çÁÇ∫‰∏çÈáçË¶ÅÁöÑÁâπÂæµÊôÇÔºåÂ∫ïÂ±§Ê®°ÂûãÊáâÁî¢ÁîüÈ°û‰ººÁöÑÈ†êÊ∏¨„ÄÇÈÄôÂºïÁôº‰∫Ü‰∏ÄÂÄãËá™ÁÑ∂ÁöÑÂïèÈ°åÔºö„Äå‰øùÁúüÂ∫¶ÊòØÂê¶ÊúÉÁÇ∫ÂúñÂΩ¢Ââ™ÊûùË™òÁôº‰∏ÄÂÄãÂÖ®Â±Ä (Ëªü) Êé©Á¢ºÔºü„ÄçÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊó®Âú®Êé¢Á¥¢‰øùÁúüÂ∫¶Ê∏¨ÈáèÂú®ÂúñÂΩ¢Ââ™Êûù‰∏≠ÁöÑÊΩõÂäõÔºåÊúÄÁµÇÂ¢ûÂº∑ GNN Ê®°Âûã‰ª•ÊèêÈ´òÊïàÁéá„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰øùÁúüÂ∫¶$^-$- ÂïüÁôºÂâ™Êûù (FiP)Ôºå‰∏ÄÂÄãÂæûÂ±ÄÈÉ®Ëß£ÈáãÊßãÈÄ†ÂÖ®Â±ÄÈÇäÁ∑£Êé©Á¢ºÁöÑÊúâÊïàÊ°ÜÊû∂„ÄÇÊàëÂÄë‰ΩøÁî® 7 Á®ÆÈÇäÁ∑£Ê≠∏Âõ†ÊñπÊ≥ïÁöÑÁ∂ìÈ©óËßÄÂØüË°®ÊòéÔºå‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºå‰∏ÄËà¨ÂèØËß£ÈáãÁöÑ AI ÊñπÊ≥ïÂú®ÂúñÂΩ¢Ââ™ÊûùÊïàËÉΩÊñπÈù¢ÂÑ™ÊñºÈáùÂ∞ç GNN ÈáèË∫´ÊâìÈÄ†ÁöÑÊñπÊ≥ï„ÄÇ

##### **GeoGPT4V: Towards Geometric Multi-modal Large Language Models with Geometric Image Generation**
2406.11503v1 by Shihao Cai, Keqin Bao, Hangyu Guo, Jizhi Zhang, Jun Song, Bo Zheng

Large language models have seen widespread adoption in math problem-solving.
However, in geometry problems that usually require visual aids for better
understanding, even the most advanced multi-modal models currently still face
challenges in effectively using image information. High-quality data is crucial
for enhancing the geometric capabilities of multi-modal models, yet existing
open-source datasets and related efforts are either too challenging for direct
model learning or suffer from misalignment between text and images. To overcome
this issue, we introduce a novel pipeline that leverages GPT-4 and GPT-4V to
generate relatively basic geometry problems with aligned text and images,
facilitating model learning. We have produced a dataset of 4.9K geometry
problems and combined it with 19K open-source data to form our GeoGPT4V
dataset. Experimental results demonstrate that the GeoGPT4V dataset
significantly improves the geometry performance of various models on the
MathVista and MathVision benchmarks. The code is available at
https://github.com/Lanyu0303/GeoGPT4V_Project

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂ∑≤Ë¢´Âª£Ê≥õÊé°Áî®ÊñºÊï∏Â≠∏ÂïèÈ°åÊ±ÇËß£„ÄÇ
ÁÑ∂ËÄåÔºåÂú®ÈÄöÂ∏∏ÈúÄË¶ÅË¶ñË¶∫ËºîÂä©Â∑•ÂÖ∑ÊâçËÉΩÊõ¥‰Ω≥ÁêÜËß£ÁöÑÂπæ‰ΩïÂïèÈ°å‰∏≠ÔºåÂç≥‰ΩøÊòØÊúÄÂÖàÈÄ≤ÁöÑÂ§öÊ®°ÊÖãÊ®°ÂûãÁõÆÂâç‰ªçÈù¢Ëá®ÊúâÊïà‰ΩøÁî®ÂΩ±ÂÉèË≥áË®äÁöÑÊåëÊà∞„ÄÇÈ´òÂìÅË≥™Ë≥áÊñôÂ∞çÊñºÊèêÂçáÂ§öÊ®°ÊÖãÊ®°ÂûãÁöÑÂπæ‰ΩïËÉΩÂäõËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÁèæÊúâÁöÑÈñãÊ∫êË≥áÊñôÈõÜÂíåÁõ∏ÈóúÂ∑•‰ΩúÔºåË¶Å‰∏çÂ∞±ÊòØÂ∞çÊ®°ÂûãÂ≠∏ÁøíËÄåË®ÄÈÅéÊñºÂõ∞Èõ£ÔºåË¶Å‰∏çÂ∞±ÊòØÊñáÊú¨ÂíåÂΩ±ÂÉè‰πãÈñìÂ≠òÂú®ÈåØ‰ΩçÂïèÈ°å„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÁÆ°ÈÅìÔºåÂà©Áî® GPT-4 Âíå GPT-4V ‰æÜÁî¢ÁîüÂÖ∑ÊúâÂ∞çÈΩäÊñáÊú¨ÂíåÂΩ±ÂÉèÁöÑÁõ∏Â∞çÂü∫Á§éÁöÑÂπæ‰ΩïÂïèÈ°åÔºå‰øÉÈÄ≤Ê®°ÂûãÂ≠∏Áøí„ÄÇÊàëÂÄëÂ∑≤Á∂ìÁî¢Áîü‰∫Ü‰∏ÄÂÄãÂåÖÂê´ 4.9K ÂÄãÂπæ‰ΩïÂïèÈ°åÁöÑË≥áÊñôÈõÜÔºå‰∏¶Â∞áÂÖ∂Ëàá 19K ÂÄãÈñãÊ∫êË≥áÊñôÁµêÂêàÔºå‰ª•ÂΩ¢ÊàêÊàëÂÄëÁöÑ GeoGPT4V Ë≥áÊñôÈõÜ„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåGeoGPT4V Ë≥áÊñôÈõÜÈ°ØËëóÊèêÂçá‰∫ÜÂêÑÁ®ÆÊ®°ÂûãÂú® MathVista Âíå MathVision Âü∫Ê∫ñ‰∏äÁöÑÂπæ‰ΩïÊïàËÉΩ„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/Lanyu0303/GeoGPT4V_Project ÂèñÂæó

##### **Teleporter Theory: A General and Simple Approach for Modeling Cross-World Counterfactual Causality**
2406.11501v1 by Jiangmeng Li, Bin Qin, Qirui Ji, Yi Li, Wenwen Qiang, Jianwen Cao, Fanjiang Xu

Leveraging the development of structural causal model (SCM), researchers can
establish graphical models for exploring the causal mechanisms behind machine
learning techniques. As the complexity of machine learning applications rises,
single-world interventionism causal analysis encounters theoretical adaptation
limitations. Accordingly, cross-world counterfactual approach extends our
understanding of causality beyond observed data, enabling hypothetical
reasoning about alternative scenarios. However, the joint involvement of
cross-world variables, encompassing counterfactual variables and real-world
variables, challenges the construction of the graphical model. Twin network is
a subtle attempt, establishing a symbiotic relationship, to bridge the gap
between graphical modeling and the introduction of counterfactuals albeit with
room for improvement in generalization. In this regard, we demonstrate the
theoretical breakdowns of twin networks in certain cross-world counterfactual
scenarios. To this end, we propose a novel teleporter theory to establish a
general and simple graphical representation of counterfactuals, which provides
criteria for determining teleporter variables to connect multiple worlds. In
theoretical application, we determine that introducing the proposed teleporter
theory can directly obtain the conditional independence between counterfactual
variables and real-world variables from the cross-world SCM without requiring
complex algebraic derivations. Accordingly, we can further identify
counterfactual causal effects through cross-world symbolic derivation. We
demonstrate the generality of the teleporter theory to the practical
application. Adhering to the proposed theory, we build a plug-and-play module,
and the effectiveness of which are substantiated by experiments on benchmarks.

ÊëòË¶ÅÔºö<paragraph>ËóâÁî±ÁµêÊßãÂõ†ÊûúÊ®°Âûã (SCM) ÁöÑÁôºÂ±ïÔºåÁ†îÁ©∂‰∫∫Âì°ÂèØ‰ª•Âª∫Á´ãÂúñÂΩ¢Ê®°ÂûãÔºå‰ª•Êé¢Á¥¢Ê©üÂô®Â≠∏ÁøíÊäÄË°ìËÉåÂæåÁöÑÂõ†ÊûúÊ©üÂà∂„ÄÇÈö®ËëóÊ©üÂô®Â≠∏ÁøíÊáâÁî®Á®ãÂºèÁöÑË§áÈõúÊÄßÂ¢ûÂä†ÔºåÂñÆ‰∏Ä‰∏ñÁïå‰ªãÂÖ•‰∏ªÁæ©Âõ†ÊûúÂàÜÊûêÈÅ≠ÈÅá‰∫ÜÁêÜË´ñÈÅ©Êáâ‰∏äÁöÑÈôêÂà∂„ÄÇÂõ†Ê≠§ÔºåË∑®‰∏ñÁïåÂèç‰∫ãÂØ¶ÊñπÊ≥ïÊì¥Â±ï‰∫ÜÊàëÂÄëÂ∞çÂõ†ÊûúÈóú‰øÇÁöÑÁêÜËß£ÔºåË∂ÖË∂ä‰∫ÜËßÄÂØüÂà∞ÁöÑË≥áÊñôÔºåËÉΩÂ§†Â∞çÊõø‰ª£ÊÉÖÂ¢ÉÈÄ≤Ë°åÂÅáË®≠ÊÄßÊé®ÁêÜ„ÄÇÁÑ∂ËÄåÔºåË∑®‰∏ñÁïåËÆäÊï∏ÁöÑÂÖ±ÂêåÂèÉËàáÔºåÂåÖÂê´Âèç‰∫ãÂØ¶ËÆäÊï∏ÂíåÁúüÂØ¶‰∏ñÁïåËÆäÊï∏ÔºåÂ∞çÂúñÂΩ¢Ê®°ÂûãÁöÑÂª∫ÊßãÊèêÂá∫‰∫ÜÊåëÊà∞„ÄÇÈõôÁîüÁ∂≤Ë∑ØÊòØ‰∏ÄÂÄãÂæÆÂ¶ôÁöÑÂòóË©¶ÔºåÂª∫Á´ãÂÖ±ÁîüÈóú‰øÇÔºå‰ª•ÂΩåÂêàÂúñÂΩ¢Âª∫Ê®°ÂíåÂèç‰∫ãÂØ¶ÂºïÂÖ•‰πãÈñìÁöÑÂ∑ÆË∑ùÔºåÂÑòÁÆ°Âú®Ê¶ÇÊã¨ÊñπÈù¢‰ªçÊúâÊîπÈÄ≤ÁöÑÁ©∫Èñì„ÄÇÊúâÈëëÊñºÊ≠§ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÈõôÁîüÁ∂≤Ë∑ØÂú®ÁâπÂÆöË∑®‰∏ñÁïåÂèç‰∫ãÂØ¶ÊÉÖÂ¢É‰∏≠ÁöÑÁêÜË´ñÂàÜËß£„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÂÇ≥ÈÄÅÂô®ÁêÜË´ñÔºå‰ª•Âª∫Á´ãÂèç‰∫ãÂØ¶ÁöÑ‰∏ÄËà¨‰∏îÁ∞°ÂñÆÁöÑÂúñÂΩ¢Ë°®Á§∫ÔºåÈÄôÊèê‰æõ‰∫ÜÁ¢∫ÂÆöÂÇ≥ÈÄÅÂô®ËÆäÊï∏‰ª•ÈÄ£Êé•Â§öÂÄã‰∏ñÁïåÁöÑÊ∫ñÂâá„ÄÇÂú®ÁêÜË´ñÊáâÁî®‰∏≠ÔºåÊàëÂÄëÁ¢∫ÂÆöÂºïÂÖ•ÊâÄÊèêÂá∫ÁöÑÂÇ≥ÈÄÅÂô®ÁêÜË´ñÂèØ‰ª•Áõ¥Êé•ÂæûË∑®‰∏ñÁïå SCM ‰∏≠Áç≤ÂæóÂèç‰∫ãÂØ¶ËÆäÊï∏ÂíåÁúüÂØ¶‰∏ñÁïåËÆäÊï∏‰πãÈñìÁöÑÊ¢ù‰ª∂Áç®Á´ãÊÄßÔºåËÄå‰∏çÈúÄË¶ÅË§áÈõúÁöÑ‰ª£Êï∏Êé®Â∞é„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂèØ‰ª•ÈÄ≤‰∏ÄÊ≠•ÈÄèÈÅéË∑®‰∏ñÁïåÁ¨¶ËôüÊé®Â∞é‰æÜË≠òÂà•Âèç‰∫ãÂØ¶Âõ†ÊûúÊïàÊáâ„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂÇ≥ÈÄÅÂô®ÁêÜË´ñÂú®ÂØ¶ÈöõÊáâÁî®‰∏≠ÁöÑÊôÆÈÅçÊÄß„ÄÇÈÅµÂæ™ÊâÄÊèêÂá∫ÁöÑÁêÜË´ñÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÂç≥ÊèíÂç≥Áî®ÁöÑÊ®°ÁµÑÔºåÂÖ∂ÊúâÊïàÊÄßÂ∑≤ÈÄöÈÅéÂü∫Ê∫ñÊ∏¨Ë©¶‰∏≠ÁöÑÂØ¶È©óÂæóÂà∞Ë≠âÂØ¶„ÄÇ</paragraph>

##### **CrAM: Credibility-Aware Attention Modification in LLMs for Combating Misinformation in RAG**
2406.11497v1 by Boyi Deng, Wenjie Wang, Fengbin Zhu, Qifan Wang, Fuli Feng

Retrieval-Augmented Generation (RAG) can alleviate hallucinations of Large
Language Models (LLMs) by referencing external documents. However, the
misinformation in external documents may mislead LLMs' generation. To address
this issue, we explore the task of "credibility-aware RAG", in which LLMs
automatically adjust the influence of retrieved documents based on their
credibility scores to counteract misinformation. To this end, we introduce a
plug-and-play method named $\textbf{Cr}$edibility-aware $\textbf{A}$ttention
$\textbf{M}$odification (CrAM). CrAM identifies influential attention heads in
LLMs and adjusts their attention scores based on the credibility of the
documents, thereby reducing the impact of low-credibility documents.
Experiments on Natual Questions and TriviaQA using Llama2-13B, Llama3-8B, and
Qwen-7B show that CrAM improves the RAG performance of LLMs against
misinformation pollution by over 20%, even surpassing supervised fine-tuning
methods.

ÊëòË¶ÅÔºöÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ËÉΩÈÄèÈÅéÂèÉÁÖßÂ§ñÈÉ®Êñá‰ª∂Ê∏õËºïÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂπªË¶∫„ÄÇÁÑ∂ËÄåÔºåÂ§ñÈÉ®Êñá‰ª∂‰∏≠ÁöÑÈåØË™§Ë≥áË®äÂèØËÉΩÊúÉË™§Â∞é LLM ÁöÑÁîüÊàê„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊé¢Ë®é‰∫Ü„ÄåÂèØ‰ø°Â∫¶ÊÑüÁü• RAG„ÄçÁöÑ‰ªªÂãôÔºåÂÖ∂‰∏≠ LLM ÊúÉÊ†πÊìöÊ™¢Á¥¢Êñá‰ª∂ÁöÑÂèØ‰ø°Â∫¶Ë©ïÂàÜËá™ÂãïË™øÊï¥Ê™¢Á¥¢Êñá‰ª∂ÁöÑÂΩ±ÈüøÂäõÔºå‰ª•Â∞çÊäóÈåØË™§Ë≥áË®ä„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÁ®±ÁÇ∫ $\textbf{Cr}$edibility-aware $\textbf{A}$ttention $\textbf{M}$odification (CrAM) ÁöÑÂç≥ÊèíÂç≥Áî®ÊñπÊ≥ï„ÄÇCrAM ÊúÉÊâæÂá∫ LLM ‰∏≠ÊúâÂΩ±ÈüøÂäõÁöÑÊ≥®ÊÑèÂäõÈ†≠ÈÉ®Ôºå‰∏¶Ê†πÊìöÊñá‰ª∂ÁöÑÂèØ‰ø°Â∫¶Ë™øÊï¥ÂÖ∂Ê≥®ÊÑèÂäõË©ïÂàÜÔºåÂæûËÄåÈôç‰Ωé‰ΩéÂèØ‰ø°Â∫¶Êñá‰ª∂ÁöÑÂΩ±Èüø„ÄÇÂú®‰ΩøÁî® Llama2-13B„ÄÅLlama3-8B Âíå Qwen-7B ÈÄ≤Ë°åÁöÑ Natual Questions Âíå TriviaQA ÂØ¶È©ó‰∏≠ÔºåÁµêÊûúÈ°ØÁ§∫ CrAM Â∞á LLM Âú®Â∞çÊäóÈåØË™§Ë≥áË®äÊ±°ÊüìÊñπÈù¢ÁöÑ RAG ÊïàËÉΩÊèêÂçá‰∫Ü 20% ‰ª•‰∏äÔºåÁîöËá≥Ë∂ÖË∂ä‰∫ÜÁõ£Áù£ÂæÆË™øÊñπÊ≥ï„ÄÇ

##### **Analysing zero-shot temporal relation extraction on clinical notes using temporal consistency**
2406.11486v1 by Vasiliki Kougia, Anastasiia Sedova, Andreas Stephan, Klim Zaporojets, Benjamin Roth

This paper presents the first study for temporal relation extraction in a
zero-shot setting focusing on biomedical text. We employ two types of prompts
and five LLMs (GPT-3.5, Mixtral, Llama 2, Gemma, and PMC-LLaMA) to obtain
responses about the temporal relations between two events. Our experiments
demonstrate that LLMs struggle in the zero-shot setting performing worse than
fine-tuned specialized models in terms of F1 score, showing that this is a
challenging task for LLMs. We further contribute a novel comprehensive temporal
analysis by calculating consistency scores for each LLM. Our findings reveal
that LLMs face challenges in providing responses consistent to the temporal
properties of uniqueness and transitivity. Moreover, we study the relation
between the temporal consistency of an LLM and its accuracy and whether the
latter can be improved by solving temporal inconsistencies. Our analysis shows
that even when temporal consistency is achieved, the predictions can remain
inaccurate.

ÊëòË¶ÅÔºöÊú¨ÊñáÊèêÂá∫Á¨¨‰∏ÄÂÄãÂ∞àÊ≥®ÊñºÁîüÁâ©ÈÜ´Â≠∏ÊñáÊú¨ÁöÑÈõ∂Ê¨°Â≠∏Áøí‰∏≠ÊôÇÈñìÈóú‰øÇËêÉÂèñÁ†îÁ©∂„ÄÇÊàëÂÄëÊé°Áî®ÂÖ©Á®ÆÊèêÁ§∫Âíå‰∫îÁ®Æ LLMÔºàGPT-3.5„ÄÅMixtral„ÄÅLlama 2„ÄÅGemma Âíå PMC-LLaMAÔºâ‰æÜÂèñÂæóÈóúÊñºÂÖ©ÂÄã‰∫ã‰ª∂‰πãÈñìÊôÇÈñìÈóú‰øÇÁöÑÂõûÊáâ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË≠âÊòéÔºåLLM Âú®Èõ∂Ê¨°Â≠∏Áøí‰∏≠Ë°®Áèæ‰∏ç‰Ω≥ÔºåÂú® F1 ÂàÜÊï∏ÊñπÈù¢Ë°®ÁèæÊØîÂæÆË™øÁöÑÂ∞àÊ•≠Ê®°ÂûãÂ∑ÆÔºåÈÄôË°®Á§∫ÈÄôÂ∞ç LLM ‰æÜË™™ÊòØ‰∏ÄÈ†ÖÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ‰ªªÂãô„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Ë≤¢Áçª‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂÖ®Èù¢ÊôÇÈñìÂàÜÊûêÔºåËóâÁî±Ë®àÁÆóÊØèÂÄã LLM ÁöÑ‰∏ÄËá¥ÊÄßÂàÜÊï∏„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåLLM Âú®Êèê‰æõËàáÂîØ‰∏ÄÊÄßÂíåÈÅûÁßªÊÄßÊôÇÈñìÂ±¨ÊÄß‰∏ÄËá¥ÁöÑÂõûÊáâÊôÇÈù¢Ëá®ÊåëÊà∞„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁ†îÁ©∂‰∫Ü LLM ÁöÑÊôÇÈñì‰∏ÄËá¥ÊÄßËàáÂÖ∂Ê∫ñÁ¢∫ÊÄß‰πãÈñìÁöÑÈóú‰øÇÔºå‰ª•ÂèäÂæåËÄÖÊòØÂê¶ËÉΩËóâÁî±Ëß£Ê±∫ÊôÇÈñì‰∏ç‰∏ÄËá¥ÊÄßËÄåÂæóÂà∞ÊîπÂñÑ„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÂç≥‰ΩøÈÅîÂà∞‰∫ÜÊôÇÈñì‰∏ÄËá¥ÊÄßÔºåÈ†êÊ∏¨‰ªçÂèØËÉΩ‰∏çÊ∫ñÁ¢∫„ÄÇ

##### **Constrained Reinforcement Learning with Average Reward Objective: Model-Based and Model-Free Algorithms**
2406.11481v1 by Vaneet Aggarwal, Washim Uddin Mondal, Qinbo Bai

Reinforcement Learning (RL) serves as a versatile framework for sequential
decision-making, finding applications across diverse domains such as robotics,
autonomous driving, recommendation systems, supply chain optimization, biology,
mechanics, and finance. The primary objective in these applications is to
maximize the average reward. Real-world scenarios often necessitate adherence
to specific constraints during the learning process.
  This monograph focuses on the exploration of various model-based and
model-free approaches for Constrained RL within the context of average reward
Markov Decision Processes (MDPs). The investigation commences with an
examination of model-based strategies, delving into two foundational methods -
optimism in the face of uncertainty and posterior sampling. Subsequently, the
discussion transitions to parametrized model-free approaches, where the
primal-dual policy gradient-based algorithm is explored as a solution for
constrained MDPs. The monograph provides regret guarantees and analyzes
constraint violation for each of the discussed setups.
  For the above exploration, we assume the underlying MDP to be ergodic.
Further, this monograph extends its discussion to encompass results tailored
for weakly communicating MDPs, thereby broadening the scope of its findings and
their relevance to a wider range of practical scenarios.

ÊëòË¶ÅÔºöÂº∑ÂåñÂ≠∏Áøí (RL) ÊòØ‰∏ÄÂÄãÈÄöÁî®ÁöÑÊ°ÜÊû∂ÔºåÂèØÁî®ÊñºÈ†ÜÂ∫èÊ±∫Á≠ñÂà∂ÂÆöÔºå‰∏¶Âú®Ê©üÂô®‰∫∫ÊäÄË°ì„ÄÅËá™ÂãïÈßïÈßõ„ÄÅÊé®Ëñ¶Á≥ªÁµ±„ÄÅ‰æõÊáâÈèàÊúÄ‰Ω≥Âåñ„ÄÅÁîüÁâ©Â≠∏„ÄÅÂäõÂ≠∏ÂíåÈáëËûçÁ≠â‰∏çÂêåÈ†òÂüü‰∏≠ÊâæÂà∞ÊáâÁî®„ÄÇÈÄô‰∫õÊáâÁî®‰∏≠ÁöÑ‰∏ªË¶ÅÁõÆÊ®ôÊòØÊúÄÂ§ßÂåñÂπ≥ÂùáÁçéÂãµ„ÄÇÁèæÂØ¶‰∏ñÁïåÁöÑÂ†¥ÊôØÈÄöÂ∏∏ÈúÄË¶ÅÂú®Â≠∏ÁøíÈÅéÁ®ã‰∏≠ÈÅµÂÆàÁâπÂÆöÁöÑÁ¥ÑÊùü„ÄÇ
Êú¨Â∞àÈ°åÂÅ¥ÈáçÊñºÊé¢Á¥¢ÂêÑÁ®ÆÂü∫ÊñºÊ®°ÂûãÂíåÁÑ°Ê®°ÂûãÁöÑÊñπÊ≥ïÔºå‰ª•Âú®Âπ≥ÂùáÁçéÂãµÈ¶¨ÂèØÂ§´Ê±∫Á≠ñÈÅéÁ®ã (MDP) ÁöÑËÉåÊôØ‰∏ãÈÄ≤Ë°åÁ¥ÑÊùü RL„ÄÇË™øÊü•ÂæûÂ∞çÂü∫ÊñºÊ®°ÂûãÁöÑÁ≠ñÁï•ÁöÑÊ™¢Êü•ÈñãÂßãÔºåÊ∑±ÂÖ•Êé¢Ë®éÂÖ©Á®ÆÂü∫Á§éÊñπÊ≥ï‚Äî‚ÄîÈù¢Â∞ç‰∏çÁ¢∫ÂÆöÊÄßÂíåÂæåÈ©óÊäΩÊ®£ÁöÑÊ®ÇËßÄ‰∏ªÁæ©„ÄÇÈö®ÂæåÔºåË®éË´ñÈÅéÊ∏°Âà∞ÂèÉÊï∏ÂåñÁöÑÁÑ°Ê®°ÂûãÊñπÊ≥ïÔºåÂÖ∂‰∏≠Âü∫ÊñºÂéüÂßãÂ∞çÂÅ∂Á≠ñÁï•Ê¢ØÂ∫¶ÁöÑÊºîÁÆóÊ≥ïË¢´Êé¢Á¥¢ÁÇ∫Á¥ÑÊùü MDP ÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÊú¨Â∞àÈ°åÊèê‰æõ‰∫ÜÂæåÊÇî‰øùË≠âÔºå‰∏¶ÂàÜÊûê‰∫ÜÊØèÂÄãË®éË´ñË®≠ÂÆöÁöÑÁ¥ÑÊùüÈÅïË¶è„ÄÇ
Â∞çÊñº‰∏äËø∞Êé¢Á¥¢ÔºåÊàëÂÄëÂÅáË®≠Âü∫Á§é MDP ÊòØ ergodic„ÄÇÊ≠§Â§ñÔºåÊú¨Â∞àÈ°åÂ∞áÂÖ∂Ë®éË´ñÊì¥Â±ïÂà∞ÂåÖÂê´ÈáùÂ∞çÂº±ÈÄö‰ø° MDP ÈáèË∫´ÊâìÈÄ†ÁöÑÁµêÊûúÔºåÂæûËÄåÊì¥Â§ß‰∫ÜÂÖ∂ÁôºÁèæÁöÑÁØÑÂúçÂèäÂÖ∂ËàáÊõ¥Âª£Ê≥õÂØ¶ÈöõÂ†¥ÊôØÁõ∏ÈóúÊÄß„ÄÇ

##### **Vocabulary Expansion for Low-resource Cross-lingual Transfer**
2406.11477v1 by Atsuki Yamaguchi, Aline Villavicencio, Nikolaos Aletras

Large language models (LLMs) have shown remarkable capabilities in many
languages beyond English. Yet, LLMs require more inference steps when
generating non-English text due to their reliance on English-centric
tokenizers, vocabulary, and pre-training data, resulting in higher usage costs
to non-English speakers. Vocabulary expansion with target language tokens is a
widely used cross-lingual vocabulary adaptation approach to remedy this issue.
Despite its effectiveness in inference speedup, the majority of previous work
has focused on high-resource settings assuming access to a substantial amount
of target language data to effectively initialize the embeddings of the new
tokens and adapt the LLM to the target language. However, vocabulary expansion
for LLMs in low-resource settings (i.e. languages and compute) has yet to be
explored. In this paper, we investigate sample-efficient adaptation strategies
from different angles, including target vocabulary size and initialization
methods, and the amount of target data available for adaptation. Extensive
experiments across typologically diverse languages, tasks and models show that
simpler heuristic-based embedding initialization is more efficient and robust
to changes in target vocabulary size and adaptation data in low-resource
settings, outperforming a popular random initialization and a more
sophisticated state-of-the-art approach that relies on external data and model.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âú®Ëã±Ë™û‰ª•Â§ñÁöÑË®±Â§öË™ûË®Ä‰∏≠Â±ïÁèæÂá∫ÂçìË∂äÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÁî±Êñº‰æùË≥¥‰ª•Ëã±Ë™ûÁÇ∫‰∏≠ÂøÉÁöÑÊ®ôË®òÂåñÂô®„ÄÅË©ûÂΩôÂíåÈ†êË®ìÁ∑¥Ë≥áÊñôÔºåLLM Âú®Áî¢ÁîüÈùûËã±Ë™ûÊñáÊú¨ÊôÇÈúÄË¶ÅÊõ¥Â§öÁöÑÊé®Ë´ñÊ≠•È©üÔºåÂ∞éËá¥ÈùûËã±Ë™û‰ΩøÁî®ËÄÖ‰ΩøÁî®ÊàêÊú¨ËºÉÈ´ò„ÄÇ‰ΩøÁî®ÁõÆÊ®ôË™ûË®ÄÊ®ôË®òÊì¥ÂÖÖË©ûÂΩôÊòØ‰∏ÄÁ®ÆÂª£Ê≥õ‰ΩøÁî®ÁöÑË∑®Ë™ûË®ÄË©ûÂΩôÈÅ©ÊáâÊñπÊ≥ïÔºåÁî®‰æÜËß£Ê±∫Ê≠§ÂïèÈ°å„ÄÇÂÑòÁÆ°ÂÖ∂Âú®Êé®Ë´ñÂä†ÈÄüÊñπÈù¢ÂæàÊúâÊïàÔºå‰ΩÜÂ§ßÂ§öÊï∏ÂÖàÂâçÁöÑÁ†îÁ©∂ÈÉΩÈõÜ‰∏≠Âú®ÂÅáË®≠ÂèØ‰ª•Â≠òÂèñÂ§ßÈáèÁõÆÊ®ôË™ûË®ÄË≥áÊñôÁöÑÈ´òË≥áÊ∫êË®≠ÂÆöÔºå‰ª•ÊúâÊïàÂàùÂßãÂåñÊñ∞Ê®ôË®òÁöÑÂµåÂÖ•‰∏¶Â∞á LLM ÈÅ©ÊáâÂà∞ÁõÆÊ®ôË™ûË®Ä„ÄÇÁÑ∂ËÄåÔºåÂú®‰ΩéË≥áÊ∫êË®≠ÂÆöÔºà‰æãÂ¶ÇË™ûË®ÄÂíåÈÅãÁÆóÔºâ‰∏≠ÈáùÂ∞ç LLM Êì¥ÂÖÖË©ûÂΩôÂ∞öÊú™Ë¢´Êé¢Ë®é„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂæû‰∏çÂêåÁöÑËßíÂ∫¶Êé¢Ë®éÊ®£Êú¨ÊúâÊïàÈÅ©ÊáâÁ≠ñÁï•ÔºåÂåÖÊã¨ÁõÆÊ®ôË©ûÂΩôÂ§ßÂ∞èÂíåÂàùÂßãÂåñÊñπÊ≥ïÔºå‰ª•ÂèäÂèØÁî®ÊñºÈÅ©ÊáâÁöÑÁõÆÊ®ôË≥áÊñôÈáè„ÄÇË∑®ÂûãÊÖãÂ§öÊ®£Ë™ûË®Ä„ÄÅ‰ªªÂãôÂíåÊ®°ÂûãÁöÑÂª£Ê≥õÂØ¶È©óÈ°ØÁ§∫ÔºåÂú®‰ΩéË≥áÊ∫êË®≠ÂÆö‰∏≠ÔºåÂü∫ÊñºÂïüÁôºÂºèÁöÑÂµåÂÖ•ÂàùÂßãÂåñËºÉÁÇ∫ÊúâÊïà‰∏îÂº∑ÂÅ•Ôºå‰∏îËÉΩÂõ†ÊáâÁõÆÊ®ôË©ûÂΩôÂ§ßÂ∞èÂíåÈÅ©ÊáâË≥áÊñôÁöÑËÆäÂåñÔºåÂÑ™ÊñºÊµÅË°åÁöÑÈö®Ê©üÂàùÂßãÂåñÂíå‰æùË≥¥Â§ñÈÉ®Ë≥áÊñôÂíåÊ®°ÂûãÁöÑÊõ¥Á≤æÂØÜÁöÑÊúÄÊñ∞ÊñπÊ≥ï„ÄÇ

##### **How Far Can In-Context Alignment Go? Exploring the State of In-Context Alignment**
2406.11474v1 by Heyan Huang, Yinghao Li, Huashan Sun, Yu Bai, Yang Gao

Recent studies have demonstrated that In-Context Learning (ICL), through the
use of specific demonstrations, can align Large Language Models (LLMs) with
human preferences known as In-Context Alignment (ICA), indicating that models
can comprehend human instructions without requiring parameter adjustments.
However, the exploration of the mechanism and applicability of ICA remains
limited. In this paper, we begin by dividing the context text used in ICA into
three categories: format, system prompt, and example. Through ablation
experiments, we investigate the effectiveness of each part in enabling ICA to
function effectively. We then examine how variants in these parts impact the
model's alignment performance. Our findings indicate that the example part is
crucial for enhancing the model's alignment capabilities, with changes in
examples significantly affecting alignment performance. We also conduct a
comprehensive evaluation of ICA's zero-shot capabilities in various alignment
tasks. The results indicate that compared to parameter fine-tuning methods, ICA
demonstrates superior performance in knowledge-based tasks and tool-use tasks.
However, it still exhibits certain limitations in areas such as multi-turn
dialogues and instruction following.

ÊëòË¶ÅÔºöÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÈÄöËøá‰ΩøÁî®ÁâπÂÆöÊºîÁ§∫ÁöÑ‰∏ä‰∏ãÊñáÂ≠¶‰π† (ICL) ÂèØ‰ª•Â∞ÜÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) ‰∏éÁß∞‰∏∫‰∏ä‰∏ãÊñáÂØπÈΩê (ICA) ÁöÑ‰∫∫Á±ªÂÅèÂ•ΩÁõ∏ÁªìÂêàÔºåË°®ÊòéÊ®°ÂûãÂèØ‰ª•ÁêÜËß£‰∫∫Á±ªÊåá‰ª§ËÄåÊó†ÈúÄÂèÇÊï∞Ë∞ÉÊï¥„ÄÇ
ÁÑ∂ËÄåÔºåÂØπ ICA Êú∫Âà∂ÂíåÈÄÇÁî®ÊÄßÁöÑÊé¢Á¥¢‰ªçÁÑ∂ÊúâÈôê„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨È¶ñÂÖàÂ∞Ü ICA ‰∏≠‰ΩøÁî®ÁöÑ‰∏ä‰∏ãÊñáÊñáÊú¨ÂàÜ‰∏∫‰∏âÁ±ªÔºöÊ†ºÂºè„ÄÅÁ≥ªÁªüÊèêÁ§∫ÂíåÁ§∫‰æã„ÄÇÈÄöËøáÊ∂àËûçÂÆûÈ™åÔºåÊàë‰ª¨Á†îÁ©∂‰∫ÜÊØèÈÉ®ÂàÜÂú®‰Ωø ICA ÊúâÊïàËøêË°å‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÁÑ∂ÂêéÊàë‰ª¨Á†îÁ©∂Ëøô‰∫õÈÉ®ÂàÜ‰∏≠ÁöÑÂèò‰ΩìÂ¶Ç‰ΩïÂΩ±ÂìçÊ®°ÂûãÁöÑÂØπÈΩêÊÄßËÉΩ„ÄÇÊàë‰ª¨ÁöÑÁ†îÁ©∂ÁªìÊûúË°®ÊòéÔºåÁ§∫‰æãÈÉ®ÂàÜÂØπ‰∫éÂ¢ûÂº∫Ê®°ÂûãÁöÑÂØπÈΩêËÉΩÂäõËá≥ÂÖ≥ÈáçË¶ÅÔºåÁ§∫‰æã‰∏≠ÁöÑÂèòÂåñ‰ºöÊòæÁùÄÂΩ±ÂìçÂØπÈΩêÊÄßËÉΩ„ÄÇÊàë‰ª¨ËøòÂØπ ICA Âú®ÂêÑÁßçÂØπÈΩê‰ªªÂä°‰∏≠ÁöÑÈõ∂Ê†∑Êú¨ËÉΩÂäõËøõË°å‰∫ÜÂÖ®Èù¢ËØÑ‰º∞„ÄÇÁªìÊûúË°®ÊòéÔºå‰∏éÂèÇÊï∞ÂæÆË∞ÉÊñπÊ≥ïÁõ∏ÊØîÔºåICA Âú®Âü∫‰∫éÁü•ËØÜÁöÑ‰ªªÂä°ÂíåÂ∑•ÂÖ∑‰ΩøÁî®‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫‰ºòÂºÇÁöÑÊÄßËÉΩ„ÄÇ
ÁÑ∂ËÄåÔºåÂÆÉÂú®Â§öËΩÆÂØπËØùÂíåÊåá‰ª§ÈÅµÂæ™Á≠âÈ¢ÜÂüü‰ªçÁÑ∂Ë°®Áé∞Âá∫‰∏ÄÂÆöÁöÑÂ±ÄÈôêÊÄß„ÄÇ

##### **Promises, Outlooks and Challenges of Diffusion Language Modeling**
2406.11473v1 by Justin Deschenaux, Caglar Gulcehre

The modern autoregressive Large Language Models (LLMs) have achieved
outstanding performance on NLP benchmarks, and they are deployed in the real
world. However, they still suffer from limitations of the autoregressive
training paradigm. For example, autoregressive token generation is notably slow
and can be prone to \textit{exposure bias}. The diffusion-based language models
were proposed as an alternative to autoregressive generation to address some of
these limitations. We evaluate the recently proposed Score Entropy Discrete
Diffusion (SEDD) approach and show it is a promising alternative to
autoregressive generation but it has some short-comings too. We empirically
demonstrate the advantages and challenges of SEDD, and observe that SEDD
generally matches autoregressive models in perplexity and on benchmarks such as
HellaSwag, Arc or WinoGrande. Additionally, we show that in terms of inference
latency, SEDD can be up to 4.5$\times$ more efficient than GPT-2. While SEDD
allows conditioning on tokens at abitrary positions, SEDD appears slightly
weaker than GPT-2 for conditional generation given short prompts. Finally, we
reproduced the main results from the original SEDD paper.

ÊëòË¶ÅÔºö<paragraph>Áèæ‰ª£ÁöÑËá™Ëø¥Ê≠∏Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú® NLP Âü∫Ê∫ñ‰∏äÂèñÂæó‰∫ÜÂÇëÂá∫ÁöÑË°®ÁèæÔºå‰∏¶Â∑≤ÈÉ®ÁΩ≤Âú®ÁèæÂØ¶‰∏ñÁïå‰∏≠„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄë‰ªçÁÑ∂ÂèóÂà∞Ëá™Ëø¥Ê≠∏Ë®ìÁ∑¥ÁØÑ‰æãÁöÑÈôêÂà∂„ÄÇ‰æãÂ¶ÇÔºåËá™Ëø¥Ê≠∏Ê¨äÊùñÁîüÊàêÊòéÈ°ØÁ∑©ÊÖ¢Ôºå‰∏îÂèØËÉΩÂÆπÊòìÂá∫Áèæ„ÄåÊõùÂÖâÂÅèÂ∑Æ„Äç„ÄÇÂü∫ÊñºÊì¥Êï£ÁöÑË™ûË®ÄÊ®°ÂûãË¢´ÊèêÂá∫‰ΩúÁÇ∫Ëá™Ëø¥Ê≠∏ÁîüÊàêÁöÑÊõø‰ª£ÊñπÊ°àÔºå‰ª•Ëß£Ê±∫ÂÖ∂‰∏≠‰∏Ä‰∫õÈôêÂà∂„ÄÇÊàëÂÄëË©ï‰º∞‰∫ÜÊúÄËøëÊèêÂá∫ÁöÑÂàÜÊï∏ÁÜµÈõ¢Êï£Êì¥Êï£ (SEDD) ÊñπÊ≥ïÔºå‰∏¶Â±ïÁ§∫ÂÆÉÊòØ‰∏ÄÁ®ÆÂæàÊúâÂâçÈÄîÁöÑËá™Ëø¥Ê≠∏ÁîüÊàêÊõø‰ª£ÊñπÊ°àÔºå‰ΩÜÂÆÉ‰πüÊúâ‰∏Ä‰∫õÁº∫Èªû„ÄÇÊàëÂÄë‰ª•Á∂ìÈ©óÊñπÂºèË≠âÊòé‰∫Ü SEDD ÁöÑÂÑ™ÈªûÂíåÊåëÊà∞Ôºå‰∏¶ËßÄÂØüÂà∞ SEDD ÈÄöÂ∏∏Âú®Âõ∞ÊÉëÂ∫¶Âíå HellaSwag„ÄÅArc Êàñ WinoGrande Á≠âÂü∫Ê∫ñ‰∏äËàáËá™Ëø¥Ê≠∏Ê®°ÂûãÁõ∏ÂåπÈÖç„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË°®ÊòéÂú®Êé®ÁêÜÂª∂ÈÅ≤ÊñπÈù¢ÔºåSEDD ÁöÑÊïàÁéáÂèØ‰ª•ÊØî GPT-2 È´òÈÅî 4.5 ÂÄç„ÄÇÈõñÁÑ∂ SEDD ÂÖÅË®±Âú®‰ªªÊÑè‰ΩçÁΩÆÂ∞çÊ¨äÊùñÈÄ≤Ë°åÊ¢ù‰ª∂Ë®≠ÂÆöÔºå‰ΩÜÂ∞çÊñºÁµ¶ÂÆöÁ∞°Áü≠ÊèêÁ§∫ÁöÑÊ¢ù‰ª∂ÁîüÊàêÔºåSEDD ‰ºº‰πéÊØî GPT-2 Á®çÂº±„ÄÇÊúÄÂæåÔºåÊàëÂÄëÈáçÁèæ‰∫ÜÂéüÂßã SEDD Ë´ñÊñá‰∏≠ÁöÑ‰∏ªË¶ÅÁµêÊûú„ÄÇ</paragraph>

##### **Automating Easy Read Text Segmentation**
2406.11464v1 by Jes√∫s Calleja, Thierry Etchegoyhen, David Ponce

Easy Read text is one of the main forms of access to information for people
with reading difficulties. One of the key characteristics of this type of text
is the requirement to split sentences into smaller grammatical segments, to
facilitate reading. Automated segmentation methods could foster the creation of
Easy Read content, but their viability has yet to be addressed. In this work,
we study novel methods for the task, leveraging masked and generative language
models, along with constituent parsing. We conduct comprehensive automatic and
human evaluations in three languages, analysing the strengths and weaknesses of
the proposed alternatives, under scarce resource limitations. Our results
highlight the viability of automated ER segmentation and remaining deficiencies
compared to expert-driven human segmentation.

ÊëòË¶ÅÔºöÁ∞°ÊòìÈñ±ËÆÄÊñáÊú¨ÊòØÈñ±ËÆÄÂõ∞Èõ£ËÄÖÁç≤ÂèñË≥áË®äÁöÑ‰∏ªË¶ÅÂΩ¢Âºè‰πã‰∏Ä„ÄÇÊ≠§È°ûÊñáÊú¨ÁöÑ‰∏ÄÂÄãÈóúÈçµÁâπÂæµÊòØÂøÖÈ†àÂ∞áÂè•Â≠êÊãÜÂàÜÊàêËºÉÂ∞èÁöÑË™ûÊ≥ïÂçÄÂ°äÔºå‰ª•Âà©Èñ±ËÆÄ„ÄÇËá™ÂãïÂåñÂàÜÊÆµÊñπÊ≥ïÊúâÂä©ÊñºÂª∫Á´ãÁ∞°ÊòìÈñ±ËÆÄÂÖßÂÆπÔºå‰ΩÜÂÖ∂ÂèØË°åÊÄßÂ∞öÊú™Áç≤ÂæóÊé¢Ë®é„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÁ†îÁ©∂Ê≠§‰ªªÂãôÁöÑÊñ∞ÊñπÊ≥ïÔºåÂà©Áî®ÈÅÆËîΩÂºèÂíåÁîüÊàêÂºèË™ûË®ÄÊ®°ÂûãÔºå‰ª•ÂèäÊàêÂàÜÂàÜÊûê„ÄÇÊàëÂÄëÂú®‰∏âÁ®ÆË™ûË®Ä‰∏≠ÈÄ≤Ë°åÂÖ®Èù¢ÁöÑËá™ÂãïÂåñÂíå‰∫∫Â∑•Ë©ï‰º∞ÔºåÂàÜÊûêÊâÄÊèêÂá∫Êõø‰ª£ÊñπÊ°àÂú®Ë≥áÊ∫êÊúâÈôêÊÉÖÊ≥Å‰∏ãÁöÑÂÑ™ÈªûÂíåÁº∫Èªû„ÄÇÊàëÂÄëÁöÑÁµêÊûúÁ™ÅÈ°Ø‰∫ÜËá™ÂãïÂåñ ER ÂàÜÊÆµÁöÑÂèØË°åÊÄßÔºå‰ª•ÂèäËàáÂ∞àÂÆ∂‰∏ªÂ∞éÁöÑ‰∫∫Â∑•ÂàÜÊÆµÁõ∏ÊØî‰ªçÂ≠òÂú®ÁöÑ‰∏çË∂≥„ÄÇ

##### **TRACE the Evidence: Constructing Knowledge-Grounded Reasoning Chains for Retrieval-Augmented Generation**
2406.11460v1 by Jinyuan Fang, Zaiqiao Meng, Craig Macdonald

Retrieval-augmented generation (RAG) offers an effective approach for
addressing question answering (QA) tasks. However, the imperfections of the
retrievers in RAG models often result in the retrieval of irrelevant
information, which could introduce noises and degrade the performance,
especially when handling multi-hop questions that require multiple steps of
reasoning. To enhance the multi-hop reasoning ability of RAG models, we propose
TRACE. TRACE constructs knowledge-grounded reasoning chains, which are a series
of logically connected knowledge triples, to identify and integrate supporting
evidence from the retrieved documents for answering questions. Specifically,
TRACE employs a KG Generator to create a knowledge graph (KG) from the
retrieved documents, and then uses an Autoregressive Reasoning Chain
Constructor to build reasoning chains. Experimental results on three multi-hop
QA datasets show that TRACE achieves an average performance improvement of up
to 14.03% compared to using all the retrieved documents. Moreover, the results
indicate that using reasoning chains as context, rather than the entire
documents, is often sufficient to correctly answer questions.

ÊëòË¶ÅÔºöÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàê (RAG) Êèê‰æõ‰∫Ü‰∏ÄÁßçËß£ÂÜ≥ÈóÆÈ¢òËß£Á≠î (QA) ‰ªªÂä°ÁöÑÊúâÊïàÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåRAG Ê®°Âûã‰∏≠ÁöÑÊ£ÄÁ¥¢Âô®ÁöÑ‰∏çÂÆåÂñÑÈÄöÂ∏∏‰ºöÂØºËá¥Ê£ÄÁ¥¢Âà∞‰∏çÁõ∏ÂÖ≥ÁöÑËÆØÊÅØÔºåËøôÂèØËÉΩ‰ºöÂºïÂÖ•ÊùÇËÆØÂπ∂Èôç‰ΩéÊïàËÉΩÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§ÑÁêÜÈúÄË¶ÅÂ§öÊ≠•È™§Êé®ÁêÜÁöÑÂ§öË∑≥ÈóÆÈ¢òÊó∂„ÄÇ‰∏∫‰∫ÜÂ¢ûÂº∫ RAG Ê®°ÂûãÁöÑÂ§öË∑≥Êé®ÁêÜËÉΩÂäõÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü TRACE„ÄÇTRACE ÊûÑÂª∫‰∫Ü‰ª•Áü•ËØÜ‰∏∫Âü∫Á°ÄÁöÑÊé®ÁêÜÈìæÔºåËøôÊòØ‰∏ÄÁ≥ªÂàóÈÄªËæëËøûÊé•ÁöÑÁü•ËØÜ‰∏âÂÖÉÁªÑÔºå‰ª•ËØÜÂà´ÂíåÊï¥ÂêàÊù•Ëá™Ê£ÄÁ¥¢Âà∞ÁöÑÊñá‰ª∂‰ª•ÂõûÁ≠îÈóÆÈ¢òÁöÑÊîØÊåÅËØÅÊçÆ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåTRACE ‰ΩøÁî® KG ÁîüÊàêÂô®‰ªéÊ£ÄÁ¥¢Âà∞ÁöÑÊñá‰ª∂‰∏≠ÂàõÂª∫Áü•ËØÜÂõæ (KG)ÔºåÁÑ∂Âêé‰ΩøÁî®Ëá™ÂõûÂΩíÊé®ÁêÜÈìæÊûÑÈÄ†Âô®ÊûÑÂª∫Êé®ÁêÜÈìæ„ÄÇÂú®‰∏â‰∏™Â§öË∑≥ QA Êï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åÁªìÊûúË°®ÊòéÔºå‰∏é‰ΩøÁî®ÊâÄÊúâÊ£ÄÁ¥¢Âà∞ÁöÑÊñá‰ª∂Áõ∏ÊØîÔºåTRACE ÁöÑÂπ≥ÂùáÊÄßËÉΩÊèêÂçáÈ´òËææ 14.03%„ÄÇÊ≠§Â§ñÔºåÁªìÊûúË°®ÊòéÔºå‰ΩøÁî®Êé®ÁêÜÈìæ‰Ωú‰∏∫‰∏ä‰∏ãÊñáÔºåËÄå‰∏çÊòØÊï¥‰∏™Êñá‰ª∂ÔºåÈÄöÂ∏∏Ë∂≥‰ª•Ê≠£Á°ÆÂõûÁ≠îÈóÆÈ¢ò„ÄÇ

##### **Adaptive Reinforcement Learning Planning: Harnessing Large Language Models for Complex Information Extraction**
2406.11455v1 by Zepeng Ding, Ruiyang Ke, Wenhao Huang, Guochao Jiang, Yanda Li, Deqing Yang, Yanghua Xiao, Jiaqing Liang

Existing research on large language models (LLMs) shows that they can solve
information extraction tasks through multi-step planning. However, their
extraction behavior on complex sentences and tasks is unstable, emerging issues
such as false positives and missing elements. We observe that decomposing
complex extraction tasks and extracting them step by step can effectively
improve LLMs' performance, and the extraction orders of entities significantly
affect the final results of LLMs. This paper proposes a two-stage multi-step
method for LLM-based information extraction and adopts the RL framework to
execute the multi-step planning. We regard sequential extraction as a Markov
decision process, build an LLM-based extraction environment, design a decision
module to adaptively provide the optimal order for sequential entity extraction
on different sentences, and utilize the DDQN algorithm to train the decision
model. We also design the rewards and evaluation metrics suitable for the
extraction results of LLMs. We conduct extensive experiments on multiple public
datasets to demonstrate the effectiveness of our method in improving the
information extraction capabilities of LLMs.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÂ§ßË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÁ†îÁ©∂Ë°®ÊòéÔºåÂÆÉÂÄëÂèØ‰ª•ÈÄèÈÅéÂ§öÊ≠•È©üË¶èÂäÉ‰æÜËß£Ê±∫Ë≥áË®äËêÉÂèñ‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÂú®Ë§áÈõúÂè•Â≠êÂíå‰ªªÂãô‰∏äÁöÑËêÉÂèñË°åÁÇ∫‰∏¶‰∏çÁ©©ÂÆöÔºåÂá∫Áèæ‰∫ÜË´∏Â¶ÇÂÅáÈôΩÊÄßÂíåÈÅ∫ÊºèÂÖÉÁ¥†Á≠âÂïèÈ°å„ÄÇÊàëÂÄëËßÄÂØüÂà∞ÔºåÂ∞áË§áÈõúÁöÑËêÉÂèñ‰ªªÂãôÂàÜËß£‰∏¶ÈÄêÊ≠•ËêÉÂèñÂèØ‰ª•ÊúâÊïàÂú∞ÊèêÂçá LLM ÁöÑÊïàËÉΩÔºåËÄåÂØ¶È´îÁöÑËêÉÂèñÈ†ÜÂ∫èÊúÉÈ°ØËëóÂΩ±Èüø LLM ÁöÑÊúÄÁµÇÁµêÊûú„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂü∫Êñº LLM ÁöÑË≥áË®äËêÉÂèñÁöÑÂÖ©ÈöéÊÆµÂ§öÊ≠•È©üÊñπÊ≥ïÔºå‰∏¶Êé°Áî® RL Ê°ÜÊû∂‰æÜÂü∑Ë°åÂ§öÊ≠•È©üË¶èÂäÉ„ÄÇÊàëÂÄëÂ∞áÈ†ÜÂ∫èËêÉÂèñË¶ñÁÇ∫‰∏ÄÂÄãÈ¶¨ÂèØÂ§´Ê±∫Á≠ñÈÅéÁ®ãÔºåÂª∫Á´ã‰∏ÄÂÄãÂü∫Êñº LLM ÁöÑËêÉÂèñÁí∞Â¢ÉÔºåË®≠Ë®à‰∏ÄÂÄãÊ±∫Á≠ñÊ®°ÁµÑÔºå‰ª•Ëá™ÈÅ©ÊáâÁöÑÊñπÂºèÊèê‰æõ‰∏çÂêåÂè•Â≠ê‰∏≠È†ÜÂ∫èÂØ¶È´îËêÉÂèñÁöÑÊúÄ‰Ω≥È†ÜÂ∫èÔºå‰∏¶Âà©Áî® DDQN ÊºîÁÆóÊ≥ï‰æÜË®ìÁ∑¥Ê±∫Á≠ñÊ®°Âûã„ÄÇÊàëÂÄëÈÇÑË®≠Ë®à‰∫ÜÈÅ©Âêà LLM ËêÉÂèñÁµêÊûúÁöÑÁçéÂãµÂíåË©ï‰º∞ÊåáÊ®ô„ÄÇÊàëÂÄëÂú®Â§öÂÄãÂÖ¨ÈñãË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºå‰ª•Ë≠âÊòéÊàëÂÄëÁöÑÊñπÊ≥ïÂú®ÊèêÂçá LLM ÁöÑË≥áË®äËêÉÂèñËÉΩÂäõÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **GPT-Powered Elicitation Interview Script Generator for Requirements Engineering Training**
2406.11439v1 by Binnur G√∂rer, Fatma Ba≈üak Aydemir

Elicitation interviews are the most common requirements elicitation
technique, and proficiency in conducting these interviews is crucial for
requirements elicitation. Traditional training methods, typically limited to
textbook learning, may not sufficiently address the practical complexities of
interviewing techniques. Practical training with various interview scenarios is
important for understanding how to apply theoretical knowledge in real-world
contexts. However, there is a shortage of educational interview material, as
creating interview scripts requires both technical expertise and creativity. To
address this issue, we develop a specialized GPT agent for auto-generating
interview scripts. The GPT agent is equipped with a dedicated knowledge base
tailored to the guidelines and best practices of requirements elicitation
interview procedures. We employ a prompt chaining approach to mitigate the
output length constraint of GPT to be able to generate thorough and detailed
interview scripts. This involves dividing the interview into sections and
crafting distinct prompts for each, allowing for the generation of complete
content for each section. The generated scripts are assessed through standard
natural language generation evaluation metrics and an expert judgment study,
confirming their applicability in requirements engineering training.

ÊëòË¶ÅÔºöÂºïÂá∫ÂºèË®™Ë´áÊòØÊúÄÂ∏∏Ë¶ãÁöÑÈúÄÊ±ÇÂºïÂá∫ÊäÄË°ìÔºåËÄåÁ≤æÈÄöÈÄ≤Ë°åÈÄô‰∫õË®™Ë´áÂ∞çÊñºÈúÄÊ±ÇÂºïÂá∫Ëá≥ÈóúÈáçË¶Å„ÄÇÂÇ≥Áµ±ÁöÑÂüπË®ìÊñπÊ≥ïÈÄöÂ∏∏ÂÉÖÈôêÊñºÊïôÁßëÊõ∏Â≠∏ÁøíÔºåÂèØËÉΩÁÑ°Ê≥ïÂÖÖÂàÜËß£Ê±∫Ë®™Ë´áÊäÄÂ∑ßÁöÑÂØ¶ÈöõË§áÈõúÊÄß„ÄÇÈÄèÈÅéÂêÑÁ®ÆË®™Ë´áÂ†¥ÊôØÁöÑÂØ¶ÈöõÂüπË®ìÂ∞çÊñºÁêÜËß£Â¶Ç‰ΩïÂú®ÁèæÂØ¶‰∏ñÁïå‰∏≠ÊáâÁî®ÁêÜË´ñÁü•Ë≠òÈùûÂ∏∏ÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÊïôËÇ≤Ë®™Ë´áË≥áÊñôÂçªÂæàÁº∫‰πèÔºåÂõ†ÁÇ∫Âª∫Á´ãË®™Ë´áËÖ≥Êú¨ÈúÄË¶ÅÊäÄË°ìÂ∞àÊ•≠Áü•Ë≠òÂíåÂâµÈÄ†Âäõ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÂ∞àÈñÄÁöÑ GPT ‰ª£ÁêÜÔºåÁî®ÊñºËá™ÂãïÁî¢ÁîüË®™Ë´áËÖ≥Êú¨„ÄÇGPT ‰ª£ÁêÜÈÖçÂÇô‰∫Ü‰∏ÄÂÄãÂ∞àÈñÄÁöÑÁü•Ë≠òÂ∫´ÔºåÂ∞àÈñÄÈáùÂ∞çÈúÄÊ±ÇÂºïÂá∫Ë®™Ë´áÁ®ãÂ∫èÁöÑÊ∫ñÂâáÂíåÊúÄ‰Ω≥ÂØ¶Âãô„ÄÇÊàëÂÄëÊé°Áî®ÊèêÁ§∫‰∏≤Êé•ÊñπÊ≥ï‰æÜÊ∏õËºï GPT ÁöÑËº∏Âá∫Èï∑Â∫¶ÈôêÂà∂Ôºå‰ª•‰æøËÉΩÂ§†Áî¢ÁîüÂÖ®Èù¢‰∏îË©≥Á¥∞ÁöÑË®™Ë´áËÖ≥Êú¨„ÄÇÈÄôÂåÖÊã¨Â∞áË®™Ë´áÂàÜÁÇ∫ÂπæÂÄãÈÉ®ÂàÜÔºå‰∏¶ÁÇ∫ÊØèÂÄãÈÉ®ÂàÜË£Ω‰Ωú‰∏çÂêåÁöÑÊèêÁ§∫Ôºå‰ª•‰æøÁÇ∫ÊØèÂÄãÈÉ®ÂàÜÁî¢ÁîüÂÆåÊï¥ÁöÑÂÖßÂÆπ„ÄÇÁî¢ÁîüÁöÑËÖ≥Êú¨ÈÄöÈÅéÊ®ôÊ∫ñËá™ÁÑ∂Ë™ûË®ÄÁîüÊàêË©ï‰º∞ÊåáÊ®ôÂíåÂ∞àÂÆ∂Âà§Êñ∑Á†îÁ©∂ÈÄ≤Ë°åË©ï‰º∞ÔºåË≠âÂØ¶‰∫ÜÂÆÉÂÄëÂú®ÈúÄÊ±ÇÂ∑•Á®ãÂüπË®ì‰∏≠ÁöÑÈÅ©Áî®ÊÄß„ÄÇ

##### **Analysing the Behaviour of Tree-Based Neural Networks in Regression Tasks**
2406.11437v1 by Peter Samoaa, Mehrdad Farahani, Antonio Longa, Philipp Leitner, Morteza Haghir Chehreghani

The landscape of deep learning has vastly expanded the frontiers of source
code analysis, particularly through the utilization of structural
representations such as Abstract Syntax Trees (ASTs). While these methodologies
have demonstrated effectiveness in classification tasks, their efficacy in
regression applications, such as execution time prediction from source code,
remains underexplored. This paper endeavours to decode the behaviour of
tree-based neural network models in the context of such regression challenges.
We extend the application of established models--tree-based Convolutional
Neural Networks (CNNs), Code2Vec, and Transformer-based methods--to predict the
execution time of source code by parsing it to an AST. Our comparative analysis
reveals that while these models are benchmarks in code representation, they
exhibit limitations when tasked with regression. To address these deficiencies,
we propose a novel dual-transformer approach that operates on both source code
tokens and AST representations, employing cross-attention mechanisms to enhance
interpretability between the two domains. Furthermore, we explore the
adaptation of Graph Neural Networks (GNNs) to this tree-based problem,
theorizing the inherent compatibility due to the graphical nature of ASTs.
Empirical evaluations on real-world datasets showcase that our dual-transformer
model outperforms all other tree-based neural networks and the GNN-based
models. Moreover, our proposed dual transformer demonstrates remarkable
adaptability and robust performance across diverse datasets.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏ÁøíÁöÑÈ†òÂüüÂ∑≤Á∂ìÂ§ßÂπÖÊì¥Â±ï‰∫ÜÂéüÂßãÁ¢ºÂàÜÊûêÁöÑÁñÜÁïåÔºåÁâπÂà•ÊòØÈÄèÈÅé‰ΩøÁî®ÁµêÊßãÂåñË°®Á§∫Ê≥ïÔºå‰æãÂ¶ÇÊäΩË±°Ë™ûÊ≥ïÊ®π (AST)„ÄÇÂÑòÁÆ°ÈÄô‰∫õÊñπÊ≥ïÂ∑≤Ë≠âÊòéÂú®ÂàÜÈ°û‰ªªÂãô‰∏≠ÊúâÊïàÔºå‰ΩÜÂÆÉÂÄëÂú®ÂõûÊ≠∏ÊáâÁî®‰∏≠ÁöÑÊïàËÉΩÔºå‰æãÂ¶ÇÂæûÂéüÂßãÁ¢º‰∏≠È†êÊ∏¨Âü∑Ë°åÊôÇÈñìÔºå‰ªçÊú™Ë¢´ÂÖÖÂàÜÊé¢Ë®é„ÄÇÊú¨ÊñáË©¶ÂúñËß£Á¢ºÊ®πÁãÄÁ•ûÁ∂ìÁ∂≤Ë∑ØÊ®°ÂûãÂú®ÈÄôÁ®ÆÂõûÊ≠∏ÊåëÊà∞‰∏≠ÁöÑË°åÁÇ∫„ÄÇÊàëÂÄëÊì¥Â±ï‰∫ÜÊó¢ÂÆöÊ®°ÂûãÁöÑÊáâÁî®‚Äî‚ÄîÂü∫ÊñºÊ®πÁãÄÁöÑÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN)„ÄÅCode2Vec ÂíåÂü∫Êñº Transformer ÁöÑÊñπÊ≥ï‚Äî‚ÄîÈÄèÈÅéÂ∞áÂéüÂßãÁ¢ºËß£ÊûêÊàê AST ‰æÜÈ†êÊ∏¨ÂÖ∂Âü∑Ë°åÊôÇÈñì„ÄÇÊàëÂÄëÁöÑÊØîËºÉÂàÜÊûêÈ°ØÁ§∫ÔºåÂÑòÁÆ°ÈÄô‰∫õÊ®°ÂûãÊòØÁ®ãÂºèÁ¢ºË°®Á§∫Ê≥ïÁöÑÂü∫Ê∫ñÔºå‰ΩÜÂÆÉÂÄëÂú®Âü∑Ë°åÂõûÊ≠∏‰ªªÂãôÊôÇË°®ÁèæÂá∫ÈôêÂà∂„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÁº∫Èô∑ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÈõô Transformer ÊñπÊ≥ïÔºåÂÆÉÂêåÊôÇ‰ΩúÁî®ÊñºÂéüÂßãÁ¢º‰ª£Á¢ºÂíå AST Ë°®Á§∫Ê≥ïÔºå‰∏¶Êé°Áî®Ë∑®Ê≥®ÊÑèÂäõÊ©üÂà∂‰æÜÂ¢ûÂº∑ÂÖ©ÂÄãÈ†òÂüü‰πãÈñìÁöÑÂèØËß£ÈáãÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂ∞áÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ÈÅ©ÊáâÂà∞ÈÄôÂÄãÂü∫ÊñºÊ®πÁãÄÁöÑÂïèÈ°åÔºå‰∏¶Ê†πÊìö AST ÁöÑÂúñÂΩ¢ÊÄßË≥™ÔºåÁêÜË´ñÂåñÂÖ∂ÂÖßÂú®Áõ∏ÂÆπÊÄß„ÄÇÂú®ÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏äÁöÑÂØ¶Ë≠âË©ï‰º∞È°ØÁ§∫ÔºåÊàëÂÄëÁöÑÈõô Transformer Ê®°ÂûãÂÑ™ÊñºÊâÄÊúâÂÖ∂‰ªñÂü∫ÊñºÊ®πÁãÄÁöÑÁ•ûÁ∂ìÁ∂≤Ë∑ØÂíåÂü∫Êñº GNN ÁöÑÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫ÁöÑÈõô Transformer Âú®‰∏çÂêåÁöÑË≥áÊñôÈõÜ‰∏äÂ±ïÁèæÂá∫È°ØËëóÁöÑÈÅ©ÊáâÊÄßÂíåÁ©©ÂÅ•ÁöÑÊïàËÉΩ„ÄÇ

##### **AnyTrans: Translate AnyText in the Image with Large Scale Models**
2406.11432v1 by Zhipeng Qian, Pei Zhang, Baosong Yang, Kai Fan, Yiwei Ma, Derek F. Wong, Xiaoshuai Sun, Rongrong Ji

This paper introduces AnyTrans, an all-encompassing framework for the
task-Translate AnyText in the Image (TATI), which includes multilingual text
translation and text fusion within images. Our framework leverages the
strengths of large-scale models, such as Large Language Models (LLMs) and
text-guided diffusion models, to incorporate contextual cues from both textual
and visual elements during translation. The few-shot learning capability of
LLMs allows for the translation of fragmented texts by considering the overall
context. Meanwhile, the advanced inpainting and editing abilities of diffusion
models make it possible to fuse translated text seamlessly into the original
image while preserving its style and realism. Additionally, our framework can
be constructed entirely using open-source models and requires no training,
making it highly accessible and easily expandable. To encourage advancement in
the TATI task, we have meticulously compiled a test dataset called MTIT6, which
consists of multilingual text image translation data from six language pairs.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥π‰∫Ü AnyTransÔºå‰∏ÄÁ®ÆÁî®Êñº„ÄåÂúñÂÉè‰∏≠ÁöÑ‰ªª‰ΩïÊñáÂ≠óÁøªË≠Ø (TATI)„Äç‰ªªÂãôÁöÑÂÖ®Èù¢ÊÄßÊû∂ÊßãÔºåÂÖ∂‰∏≠ÂåÖÊã¨Â§öË™ûË®ÄÊñáÂ≠óÁøªË≠ØÂíåÂúñÂÉè‰∏≠ÁöÑÊñáÂ≠óËûçÂêà„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÂà©Áî®‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÊñáÂ≠óÂºïÂ∞éÊì¥Êï£Ê®°ÂûãÁ≠âÂ§ßË¶èÊ®°Ê®°ÂûãÁöÑÂÑ™Âã¢ÔºåÂú®ÁøªË≠ØÈÅéÁ®ã‰∏≠Á¥çÂÖ•‰∫ÜÊñáÂ≠óÂíåË¶ñË¶∫ÂÖÉÁ¥†ÁöÑËÉåÊôØÁ∑öÁ¥¢„ÄÇLLM ÁöÑÂ∞ëÈáèÂ≠∏ÁøíËÉΩÂäõÂÖÅË®±ÈÄèÈÅéËÄÉÊÖÆÊï¥È´îËÉåÊôØ‰æÜÁøªË≠ØÁâáÊÆµÊñáÂ≠ó„ÄÇÂêåÊôÇÔºåÊì¥Êï£Ê®°ÂûãÁöÑÂÖàÈÄ≤‰øÆÂæ©ÂíåÁ∑®ËºØËÉΩÂäõËÆìÁøªË≠ØÂæåÁöÑÊñáÂ≠óËÉΩÂ§†ÁÑ°Á∏´ËûçÂêàÂà∞ÂéüÂßãÂúñÂÉè‰∏≠ÔºåÂêåÊôÇ‰øùÁïôÂÖ∂È¢®Ê†ºÂíåÁúüÂØ¶ÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÊû∂ÊßãÂèØ‰ª•‰ΩøÁî®ÂÆåÂÖ®ÈñãÊîæÂéüÂßãÁ¢ºÁöÑÊ®°ÂûãÂª∫ÊßãÔºå‰∏¶‰∏î‰∏çÈúÄË¶ÅË®ìÁ∑¥ÔºåÈÄôËÆìÂÆÉÈ´òÂ∫¶ÊòìÊñºÂ≠òÂèñ‰∏îÂÆπÊòìÊì¥ÂÖÖ„ÄÇÁÇ∫‰∫ÜÈºìÂãµ TATI ‰ªªÂãôÁöÑÈÄ≤Â±ïÔºåÊàëÂÄëÁ≤æÂøÉÁ∑®Âà∂‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ MTIT6 ÁöÑÊ∏¨Ë©¶Ë≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´‰æÜËá™ÂÖ≠Á®ÆË™ûË®ÄÈÖçÂ∞çÁöÑÂ§öË™ûË®ÄÊñáÂ≠óÂúñÂÉèÁøªË≠ØË≥áÊñô„ÄÇ

##### **Super(ficial)-alignment: Strong Models May Deceive Weak Models in Weak-to-Strong Generalization**
2406.11431v1 by Wenkai Yang, Shiqi Shen, Guangyao Shen, Zhi Gong, Yankai Lin

Superalignment, where humans are weak supervisors of superhuman models, has
become an important and widely discussed issue in the current era of rapid
development of Large Language Models (LLMs). The recent work preliminarily
studies this problem by using weak models to supervise strong models. It
discovers that weakly supervised strong students can consistently outperform
weak teachers towards the alignment target, leading to a weak-to-strong
generalization phenomenon. However, we are concerned that behind such a
promising phenomenon, whether there exists an issue of weak-to-strong
deception, where strong models may deceive weak models by exhibiting
well-aligned in areas known to weak models but producing misaligned behaviors
in cases weak models do not know. We then take an initial step towards
exploring this security issue in a specific but realistic multi-objective
alignment case, where there may be some alignment targets conflicting with each
other (e.g., helpfulness v.s. harmlessness). Such a conflict is likely to cause
strong models to deceive weak models in one alignment dimension to gain high
reward in other alignment dimension. Our experiments on both the reward
modeling task and the preference optimization scenario indicate: (1) the
weak-to-strong deception exists; (2) the deception phenomenon may intensify as
the capability gap between weak and strong models increases. We also discuss
potential solutions and find bootstrapping with an intermediate model can
mitigate the deception to some extent. Our work highlights the urgent need to
pay more attention to the true reliability of superalignment.

ÊëòË¶ÅÔºöË∂ÖÂ∞çÈΩäÔºà‰∫∫È°ûÊòØË∂Ö‰∫∫È°ûÊ®°ÂûãÁöÑÂº±Áõ£Áù£ËÄÖÔºâÂ∑≤ÊàêÁÇ∫Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âø´ÈÄüÁôºÂ±ïÁöÑÁï∂ÂâçÊôÇ‰ª£‰∏≠‰∏ÄÂÄãÈáçË¶Å‰∏îÂª£Ê≥õË®éË´ñÁöÑÂïèÈ°å„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂ÂàùÊ≠•ÈÄèÈÅé‰ΩøÁî®Âº±Ê®°ÂûãÁõ£Áù£Âº∑Ê®°Âûã‰æÜÊé¢Ë®éÈÄôÂÄãÂïèÈ°å„ÄÇÂÆÉÁôºÁèæÂº±Áõ£Áù£ÁöÑÂº∑Â≠∏ÁîüÂèØ‰ª•ÊåÅÁ∫åÂú®Â∞çÈΩäÁõÆÊ®ô‰∏äÂÑ™ÊñºÂº±ÊïôÂ∏´ÔºåÂ∞éËá¥Âº±Âà∞Âº∑ÁöÑÊ¶ÇÂåñÁèæË±°„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëÊìîÂøÉÂú®ÈÄôÊ®£‰∏ÄÂÄãÊúâÂ∏åÊúõÁöÑÁèæË±°ËÉåÂæåÔºåÊòØÂê¶Â≠òÂú®Âº±Âà∞Âº∑ÁöÑÊ¨∫È®ôÂïèÈ°åÔºåÂÖ∂‰∏≠Âº∑Ê®°ÂûãÂèØËÉΩÈÄèÈÅéÂú®Âº±Ê®°ÂûãÂ∑≤Áü•ÁöÑÈ†òÂüüË°®ÁèæÂá∫ËâØÂ•ΩÂ∞çÈΩäÔºå‰ΩÜÂú®Âº±Ê®°Âûã‰∏çÁü•ÈÅìÁöÑÊÉÖÊ≥Å‰∏ãÁî¢ÁîüÂ§±Ë°°Ë°åÁÇ∫‰æÜÊ¨∫È®ôÂº±Ê®°Âûã„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊé°ÂèñÂàùÊ≠•Ê≠•È©üÂú®ÁâπÂÆö‰ΩÜÂØ¶ÈöõÁöÑÂ§öÁõÆÊ®ôÂ∞çÈΩäÊ°à‰æã‰∏≠Êé¢Ë®éÈÄôÂÄãÂÆâÂÖ®ÂïèÈ°åÔºåÂÖ∂‰∏≠ÂèØËÉΩÊúâ‰∏Ä‰∫õÂ∞çÈΩäÁõÆÊ®ôÁõ∏‰∫íË°ùÁ™ÅÔºà‰æãÂ¶ÇÔºåÊúâÁõäÊÄß v.s. ÁÑ°ÂÆ≥ÊÄßÔºâ„ÄÇÈÄôÁ®ÆË°ùÁ™ÅÂèØËÉΩÊúÉÂ∞éËá¥Âº∑Ê®°ÂûãÂú®‰∏ÄÂÄãÂ∞çÈΩäÁ∂≠Â∫¶Ê¨∫È®ôÂº±Ê®°ÂûãÔºå‰ª•Âú®ÂÖ∂‰ªñÂ∞çÈΩäÁ∂≠Â∫¶Áç≤ÂæóÈ´òÂõûÂ†±„ÄÇÊàëÂÄëÂú®ÂõûÂ†±Âª∫Ê®°‰ªªÂãôÂíåÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÊÉÖÂ¢É‰∏≠ÁöÑÂØ¶È©óË°®ÊòéÔºö(1) Âº±Âà∞Âº∑ÁöÑÊ¨∫È®ôÂ≠òÂú®Ôºõ(2) Èö®ËëóÂº±Ê®°ÂûãÂíåÂº∑Ê®°Âûã‰πãÈñìËÉΩÂäõÂ∑ÆË∑ùÁöÑÂ¢ûÂä†ÔºåÊ¨∫È®ôÁèæË±°ÂèØËÉΩÊúÉÂä†Âäá„ÄÇÊàëÂÄë‰πüË®éË´ñÊΩõÂú®ÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰∏¶ÁôºÁèæ‰ΩøÁî®‰∏≠‰ªãÊ®°ÂûãÈÄ≤Ë°åËá™ËàâÂèØÂú®ÊüêÁ®ÆÁ®ãÂ∫¶‰∏äÊ∏õËºïÊ¨∫È®ô„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Âº∑Ë™øËø´ÂàáÈúÄË¶ÅÊõ¥Ê≥®ÊÑèË∂ÖÂ∞çÈΩäÁöÑÁúüÂØ¶ÂèØÈù†ÊÄß„ÄÇ

##### **A Simple and Effective $L_2$ Norm-Based Strategy for KV Cache Compression**
2406.11430v1 by Alessio Devoto, Yu Zhao, Simone Scardapane, Pasquale Minervini

The deployment of large language models (LLMs) is often hindered by the
extensive memory requirements of the Key-Value (KV) cache, especially as
context lengths increase. Existing approaches to reduce the KV cache size
involve either fine-tuning the model to learn a compression strategy or
leveraging attention scores to reduce the sequence length. We analyse the
attention distributions in decoder-only Transformers-based models and observe
that attention allocation patterns stay consistent across most layers.
Surprisingly, we find a clear correlation between the $L_2$ and the attention
scores over cached KV pairs, where a low $L_2$ of a key embedding usually leads
to a high attention score during decoding. This finding indicates that the
influence of a KV pair is potentially determined by the key embedding itself
before being queried. Based on this observation, we compress the KV cache based
on the $L_2$ of key embeddings. Our experimental results show that this simple
strategy can reduce the KV cache size by 50% on language modelling and
needle-in-a-haystack tasks and 90% on passkey retrieval tasks without losing
accuracy.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈÉ®ÁΩ≤ÈÄöÂ∏∏ÂèóÂà∞ Key-Value (KV) Âø´ÂèñÂª£Ê≥õÁöÑË®òÊÜ∂È´îÈúÄÊ±ÇÊâÄÈòªÁ§ôÔºåÁâπÂà•ÊòØÂú®ËÑàÁµ°Èï∑Â∫¶Â¢ûÂä†ÊôÇ„ÄÇÁèæÊúâÁöÑÊ∏õÂ∞ë KV Âø´ÂèñÂ§ßÂ∞èÁöÑÊñπÊ≥ïÂåÖÊã¨ÂæÆË™øÊ®°Âûã‰ª•Â≠∏ÁøíÂ£ìÁ∏ÆÁ≠ñÁï•ÊàñÂà©Áî®Ê≥®ÊÑèÂäõÂàÜÊï∏‰æÜÊ∏õÂ∞ëÂ∫èÂàóÈï∑Â∫¶„ÄÇÊàëÂÄëÂàÜÊûê‰∫ÜÂÉÖËß£Á¢ºÂô® Transformer Âü∫Á§éÊ®°Âûã‰∏≠ÁöÑÊ≥®ÊÑèÂäõÂàÜ‰ΩàÔºå‰∏¶ËßÄÂØüÂà∞Ê≥®ÊÑèÂäõÂàÜÈÖçÊ®°ÂºèÂú®Â§ßÈÉ®ÂàÜÂ±§‰∏≠‰øùÊåÅ‰∏ÄËá¥„ÄÇ‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºåÊàëÂÄëÁôºÁèæ $L_2$ ÂíåÂø´Âèñ KV Â∞çÁöÑÊ≥®ÊÑèÂäõÂàÜÊï∏‰πãÈñìÂ≠òÂú®ÊòéÈ°ØÁöÑÈóúËÅØÊÄßÔºåÂÖ∂‰∏≠ÈçµÂµåÂÖ•ÁöÑ‰Ωé $L_2$ ÈÄöÂ∏∏ÊúÉÂ∞éËá¥Ëß£Á¢ºÊúüÈñìÁöÑÈ´òÊ≥®ÊÑèÂäõÂàÜÊï∏„ÄÇÈÄô‰∏ÄÁôºÁèæË°®ÊòéÔºåKV Â∞çÁöÑÂΩ±ÈüøÂèØËÉΩÂú®Êü•Ë©¢‰πãÂâçÂ∞±Áî±ÈçµÂµåÂÖ•Êú¨Ë∫´Ê±∫ÂÆö„ÄÇÂü∫ÊñºÈÄô‰∏ÄËßÄÂØüÔºåÊàëÂÄëÊ†πÊìöÈçµÂµåÂÖ•ÁöÑ $L_2$ Â£ìÁ∏Æ KV Âø´Âèñ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÈÄôÁ®ÆÁ∞°ÂñÆÁöÑÁ≠ñÁï•ÂèØ‰ª•Âú®Ë™ûË®ÄÂª∫Ê®°ÂíåÂ§ßÊµ∑ÊíàÈáù‰ªªÂãô‰∏≠Â∞á KV Âø´ÂèñÂ§ßÂ∞èÊ∏õÂ∞ë 50%ÔºåÂú®ÂØÜÈë∞Ê™¢Á¥¢‰ªªÂãô‰∏≠Ê∏õÂ∞ë 90%ÔºåËÄå‰∏çÊúÉÈôç‰ΩéÊ∫ñÁ¢∫Â∫¶„ÄÇ

##### **DiTTo-TTS: Efficient and Scalable Zero-Shot Text-to-Speech with Diffusion Transformer**
2406.11427v1 by Keon Lee, Dong Won Kim, Jaehyeon Kim, Jaewoong Cho

Large-scale diffusion models have shown outstanding generative abilities
across multiple modalities including images, videos, and audio. However,
text-to-speech (TTS) systems typically involve domain-specific modeling factors
(e.g., phonemes and phoneme-level durations) to ensure precise temporal
alignments between text and speech, which hinders the efficiency and
scalability of diffusion models for TTS. In this work, we present an efficient
and scalable Diffusion Transformer (DiT) that utilizes off-the-shelf
pre-trained text and speech encoders. Our approach addresses the challenge of
text-speech alignment via cross-attention mechanisms with the prediction of the
total length of speech representations. To achieve this, we enhance the DiT
architecture to suit TTS and improve the alignment by incorporating semantic
guidance into the latent space of speech. We scale the training dataset and the
model size to 82K hours and 790M parameters, respectively. Our extensive
experiments demonstrate that the large-scale diffusion model for TTS without
domain-specific modeling not only simplifies the training pipeline but also
yields superior or comparable zero-shot performance to state-of-the-art TTS
models in terms of naturalness, intelligibility, and speaker similarity. Our
speech samples are available at https://ditto-tts.github.io.

ÊëòË¶ÅÔºöÂ§ßÂûãÊì¥Êï£Ê®°ÂûãÂ∑≤Â±ïÁèæÂá∫Ë∑®Ë∂äÂ§öÁ®ÆÊ®°ÊÖãÔºàÂåÖÂê´ÂΩ±ÂÉè„ÄÅÂΩ±ÁâáÂíåÈü≥Ë®äÔºâÁöÑÂá∫Ëâ≤ÁîüÊàêËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÊñáÂ≠óËΩâË™ûÈü≥ÔºàTTSÔºâÁ≥ªÁµ±ÈÄöÂ∏∏ÂåÖÂê´ÁâπÂÆöÊñºÈ†òÂüüÁöÑÂª∫Ê®°Âõ†Â≠êÔºà‰æãÂ¶ÇÈü≥Á¥†ÂíåÈü≥Á¥†Â±§Á¥öÁöÑÊåÅÁ∫åÊôÇÈñìÔºâÔºå‰ª•Á¢∫‰øùÊñáÂ≠óËàáË™ûÈü≥‰πãÈñìÁ≤æÁ¢∫ÁöÑÊôÇÈñìÂ∞çÈΩäÔºåÈÄôÊúÉÈòªÁ§ôÊì¥Êï£Ê®°ÂûãÂú® TTS ‰∏≠ÁöÑÊïàÁéáÂíåÂèØÊì¥ÂÖÖÊÄß„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊúâÊïà‰∏îÂèØÊì¥ÂÖÖÁöÑÊì¥Êï£TransformerÔºàDiTÔºâÔºåÂÆÉÂà©Áî®ÁèæÊàêÁöÑÈ†êË®ìÁ∑¥ÊñáÂ≠óÂíåË™ûÈü≥Á∑®Á¢ºÂô®„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÈÄèÈÅé‰∫§ÂèâÊ≥®ÊÑèÂäõÊ©üÂà∂‰ª•ÂèäÈ†êÊ∏¨Ë™ûÈü≥Ë°®ÂæµÁöÑÁ∏ΩÈï∑Â∫¶Ôºå‰æÜËß£Ê±∫ÊñáÂ≠óË™ûÈü≥Â∞çÈΩäÁöÑÊåëÊà∞„ÄÇÁÇ∫ÈÅîÊàêÊ≠§ÁõÆÁöÑÔºåÊàëÂÄëÂ¢ûÂº∑‰∫Ü DiT Êû∂Êßã‰ª•ÈÅ©Áî®Êñº TTSÔºå‰∏¶ÈÄèÈÅéÂ∞áË™ûÊÑèÂºïÂ∞éÁ¥çÂÖ•Ë™ûÈü≥ÁöÑÊΩõÂú®Á©∫Èñì‰∏≠‰æÜÊîπÂñÑÂ∞çÈΩä„ÄÇÊàëÂÄëÂ∞áË®ìÁ∑¥Ë≥áÊñôÈõÜÂíåÊ®°ÂûãÂ§ßÂ∞èÂàÜÂà•Êì¥ÂÖÖÂà∞ 82K Â∞èÊôÇÂíå 790M ÂèÉÊï∏„ÄÇÊàëÂÄëÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòéÔºåÂ§ßÂûãÊì¥Êï£Ê®°ÂûãÁî®Êñº TTSÔºåÂç≥‰ΩøÊ≤íÊúâÁâπÂÆöÊñºÈ†òÂüüÁöÑÂª∫Ê®°Ôºå‰∏çÂÉÖÁ∞°Âåñ‰∫ÜË®ìÁ∑¥ÊµÅÁ®ãÔºåÈÇÑËÉΩÁî¢ÁîüÂÑ™ÊñºÊàñÂ™≤ÁæéÁèæÊúâ TTS Ê®°ÂûãÁöÑÈõ∂Ê¨°Â≠∏ÁøíÊïàËÉΩÔºåÂú®Ëá™ÁÑ∂Â∫¶„ÄÅÊ∏ÖÊô∞Â∫¶ÂíåË™™Ë©±ËÄÖÁõ∏‰ººÊÄßÊñπÈù¢ÁöÜÊòØÂ¶ÇÊ≠§„ÄÇÊàëÂÄëÁöÑË™ûÈü≥ÁØÑ‰æãÂèØÊñº https://ditto-tts.github.io/ ÂèñÂæó„ÄÇ

##### **Evaluating the Efficacy of Open-Source LLMs in Enterprise-Specific RAG Systems: A Comparative Study of Performance and Scalability**
2406.11424v1 by Gautam B, Anupam Purwar

This paper presents an analysis of open-source large language models (LLMs)
and their application in Retrieval-Augmented Generation (RAG) tasks, specific
for enterprise-specific data sets scraped from their websites. With the
increasing reliance on LLMs in natural language processing, it is crucial to
evaluate their performance, accessibility, and integration within specific
organizational contexts. This study examines various open-source LLMs, explores
their integration into RAG frameworks using enterprise-specific data, and
assesses the performance of different open-source embeddings in enhancing the
retrieval and generation process. Our findings indicate that open-source LLMs,
combined with effective embedding techniques, can significantly improve the
accuracy and efficiency of RAG systems, offering a viable alternative to
proprietary solutions for enterprises.

ÊëòË¶ÅÔºöÊú¨ÊñáÂàÜÊûê‰∫ÜÈñãÊ∫êÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂèäÂÖ∂Âú®Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ‰ªªÂãô‰∏≠ÁöÑÊáâÁî®ÔºåÁâπÂà•ÊòØÈáùÂ∞çÂæûÂÖ∂Á∂≤Á´ô‰∏≠Êì∑ÂèñÁöÑÁâπÂÆö‰ºÅÊ•≠Êï∏ÊìöÈõÜ„ÄÇÈö®ËëóËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÂ∞ç LLM ÁöÑ‰æùË≥¥ÊÄßË∂ä‰æÜË∂äÈ´òÔºåË©ï‰º∞ÂÖ∂Âú®ÁâπÂÆöÁµÑÁπîÁí∞Â¢É‰∏≠ÁöÑÊïàËÉΩ„ÄÅÂèØÂèäÊÄßÂíåÊï¥ÂêàËá≥ÈóúÈáçË¶Å„ÄÇÊú¨Á†îÁ©∂Ê™¢Ë¶ñ‰∫ÜÂêÑÁ®ÆÈñãÊ∫ê LLMÔºåÊé¢Ë®éÂÆÉÂÄë‰ΩøÁî®ÁâπÂÆö‰ºÅÊ•≠Êï∏ÊìöÊï¥ÂêàÂà∞ RAG Êû∂Êßã‰∏≠Ôºå‰∏¶Ë©ï‰º∞‰∏çÂêåÈñãÊ∫êÂµåÂÖ•Â∞çÂä†Âº∑Ê™¢Á¥¢ÂíåÁîüÊàêÈÅéÁ®ãÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÈñãÊ∫ê LLM ËàáÊúâÊïàÁöÑÂµåÂÖ•ÊäÄË°ìÁõ∏ÁµêÂêàÔºåÂèØ‰ª•È°ØËëóÊèêÈ´ò RAG Á≥ªÁµ±ÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÊïàÁéáÔºåÁÇ∫‰ºÅÊ•≠Êèê‰æõÂèØË°åÁöÑÂ∞àÊúâËß£Ê±∫ÊñπÊ°àÊõø‰ª£ÊñπÊ°à„ÄÇ

##### **Dredge Word, Social Media, and Webgraph Networks for Unreliable Website Classification and Identification**
2406.11423v1 by Evan M. Williams, Peter Carragher, Kathleen M. Carley

In an attempt to mimic the complex paths through which unreliable content
spreads between search engines and social media, we explore the impact of
incorporating both webgraph and large-scale social media contexts into website
credibility classification and discovery systems. We further explore the usage
of what we define as \textit{dredge words} on social media -- terms or phrases
for which unreliable domains rank highly. Through comprehensive graph neural
network ablations, we demonstrate that curriculum-based heterogeneous graph
models that leverage context from both webgraphs and social media data
outperform homogeneous and single-mode approaches. We further demonstrate that
the incorporation of dredge words into our model strongly associates unreliable
websites with social media and online commerce platforms. Finally, we show our
heterogeneous model greatly outperforms competing systems in the top-k
identification of unlabeled unreliable websites. We demonstrate the strong
unreliability signals present in the diverse paths that users follow to uncover
unreliable content, and we release a novel dataset of dredge words.

ÊëòË¶ÅÔºöÁÇ∫‰∫ÜÊ®°Êì¨‰∏çÂèØÈù†ÂÖßÂÆπÂú®ÊêúÂ∞ãÂºïÊìéÂíåÁ§æÁæ§Â™íÈ´î‰πãÈñìÂÇ≥Êí≠ÁöÑË§áÈõúË∑ØÂæëÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂ∞áÁ∂≤Ë∑ØÂúñÂíåÂ§ßÂûãÁ§æÁæ§Â™íÈ´îËÉåÊôØÁ¥çÂÖ•Á∂≤Á´ôÂèØ‰ø°Â∫¶ÂàÜÈ°ûÂíåÁôºÁèæÁ≥ªÁµ±ÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Êé¢Ë®é‰∫ÜÊàëÂÄëÂÆöÁæ©ÁÇ∫Á§æÁæ§Â™íÈ´î‰∏äÁöÑ„ÄåÊíàËÄôÂ≠êË©ûÂΩô„ÄçÁöÑ‰ΩøÁî®‚Äî‚Äî‰∏çÂèØÈù†Á∂≤ÂüüÊéíÂêçÂæàÈ´òÁöÑË©ûÂΩôÊàñÁâáË™û„ÄÇÈÄèÈÅéÂÖ®Èù¢ÁöÑÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑ØÊ∂àËûçÔºåÊàëÂÄëË≠âÊòé‰∫ÜÂà©Áî®Á∂≤Ë∑ØÂúñÂíåÁ§æÁæ§Â™íÈ´îË≥áÊñôÁöÑËÉåÊôØÁöÑË™≤Á®ãÂºèÁï∞Ë≥™ÂúñÂΩ¢Ê®°ÂûãÔºåÂÑ™ÊñºÂêåË≥™ÂíåÂñÆ‰∏ÄÊ®°ÂºèÊñπÊ≥ï„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Ë≠âÊòéÔºåÂ∞áÊíàËÄôÂ≠êË©ûÂΩôÁ¥çÂÖ•ÊàëÂÄëÁöÑÊ®°ÂûãÔºåÂ∞á‰∏çÂèØÈù†Á∂≤Á´ôËàáÁ§æÁæ§Â™íÈ´îÂíåÁ∑ö‰∏äÂïÜÂãôÂπ≥Âè∞Á∑äÂØÜËÅØÁπ´Âú®‰∏ÄËµ∑„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ±ïÁ§∫ÊàëÂÄëÁöÑÁï∞Ë≥™Ê®°ÂûãÂú®Êú™Ê®ôË®ò‰∏çÂèØÈù†Á∂≤Á´ôÁöÑ top-k Ë≠òÂà•‰∏≠ÔºåÂ§ßÂπÖÂÑ™ÊñºÁ´∂Áà≠Á≥ªÁµ±„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰ΩøÁî®ËÄÖËøΩËπ§‰ª•Êè≠Èú≤‰∏çÂèØÈù†ÂÖßÂÆπÊôÇÔºåÂêÑÁ®ÆË∑ØÂæë‰∏≠Â≠òÂú®Âº∑ÁÉàÁöÑ‰∏çÂèØÈù†‰ø°ËôüÔºå‰∏¶ÈáãÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÊíàËÄôÂ≠êË©ûÂΩôË≥áÊñôÈõÜ„ÄÇ

##### **BAMBINO-LM: (Bilingual-)Human-Inspired Continual Pretraining of BabyLM**
2406.11418v1 by Zhewen Shen, Aditya Joshi, Ruey-Cheng Chen

Children from bilingual backgrounds benefit from interactions with parents
and teachers to re-acquire their heritage language. In this paper, we
investigate how this insight from behavioral study can be incorporated into the
learning of small-scale language models. We introduce BAMBINO-LM, a continual
pretraining strategy for BabyLM that uses a novel combination of alternation
and PPO-based perplexity reward induced from a parent Italian model. Upon
evaluation on zero-shot classification tasks for English and Italian,
BAMBINO-LM improves the Italian language capability of a BabyLM baseline. Our
ablation analysis demonstrates that employing both the alternation strategy and
PPO-based modeling is key to this effectiveness gain. We also show that, as a
side effect, the proposed method leads to similar degradation in L1
effectiveness as human children would have had in an equivalent learning
scenario.

ÊëòË¶ÅÔºö<paragraph>‰æÜËá™ÈõôË™ûËÉåÊôØÁöÑÂÖíÁ´•ÂæûËàáÁà∂ÊØçÂíåËÄÅÂ∏´ÁöÑ‰∫íÂãï‰∏≠ÂèóÁõäÔºå‰ª•ÈáçÊñ∞ÁøíÂæó‰ªñÂÄëÁöÑÂÇ≥Áµ±Ë™ûË®Ä„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éÂ¶Ç‰ΩïÂ∞áË°åÁÇ∫Á†îÁ©∂‰∏≠ÁöÑÈÄô‰∏ÄË¶ãËß£ËûçÂÖ•Â∞èË¶èÊ®°Ë™ûË®ÄÊ®°ÂûãÁöÑÂ≠∏Áøí‰∏≠„ÄÇÊàëÂÄë‰ªãÁ¥π‰∫Ü BAMBINO-LMÔºåÈÄôÊòØ‰∏ÄÁ®ÆÈáùÂ∞ç BabyLM ÁöÑÊåÅÁ∫åÈ†êË®ìÁ∑¥Á≠ñÁï•ÔºåÂÆÉ‰ΩøÁî®‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑ‰∫§ÊõøÁµÑÂêàÂíåÂü∫Êñº PPO ÁöÑÂõ∞ÊÉëÁçéÂãµÔºåÈÄô‰∫õÁçéÂãµ‰æÜËá™Êñº‰∏ÄÂÄãÊÑèÂ§ßÂà©Ë™ûÁà∂‰ª£Ê®°Âûã„ÄÇÂú®Â∞çËã±Ë™ûÂíåÊÑèÂ§ßÂà©Ë™ûÁöÑÈõ∂Ê¨°ÂàÜÈ°û‰ªªÂãôÈÄ≤Ë°åË©ï‰º∞ÂæåÔºåBAMBINO-LM ÊèêÂçá‰∫Ü BabyLM Âü∫Ê∫ñÁöÑÊÑèÂ§ßÂà©Ë™ûËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÊ∂àËûçÂàÜÊûêË°®ÊòéÔºåÊé°Áî®‰∫§ÊõøÁ≠ñÁï•ÂíåÂü∫Êñº PPO ÁöÑÂª∫Ê®°Â∞çÊñºÈÄôÁ®ÆÊúâÊïàÊÄßÊèêÂçáËá≥ÈóúÈáçË¶Å„ÄÇÊàëÂÄëÈÇÑË°®ÊòéÔºå‰ΩúÁÇ∫‰∏ÄÂÄãÂâØ‰ΩúÁî®ÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂ∞éËá¥‰∫ÜËàá‰∫∫È°ûÂÖíÁ´•Âú®Á≠âÊïàÂ≠∏ÁøíÂ†¥ÊôØ‰∏≠ÊúÉÂá∫ÁèæÁöÑÈ°û‰ººÁöÑ L1 ÊúâÊïàÊÄß‰∏ãÈôç„ÄÇ</paragraph>

##### **Formally Certified Approximate Model Counting**
2406.11414v1 by Yong Kiam Tan, Jiong Yang, Mate Soos, Magnus O. Myreen, Kuldeep S. Meel

Approximate model counting is the task of approximating the number of
solutions to an input Boolean formula. The state-of-the-art approximate model
counter for formulas in conjunctive normal form (CNF), ApproxMC, provides a
scalable means of obtaining model counts with probably approximately correct
(PAC)-style guarantees. Nevertheless, the validity of ApproxMC's approximation
relies on a careful theoretical analysis of its randomized algorithm and the
correctness of its highly optimized implementation, especially the latter's
stateful interactions with an incremental CNF satisfiability solver capable of
natively handling parity (XOR) constraints.
  We present the first certification framework for approximate model counting
with formally verified guarantees on the quality of its output approximation.
Our approach combines: (i) a static, once-off, formal proof of the algorithm's
PAC guarantee in the Isabelle/HOL proof assistant; and (ii) dynamic, per-run,
verification of ApproxMC's calls to an external CNF-XOR solver using proof
certificates. We detail our general approach to establish a rigorous connection
between these two parts of the verification, including our blueprint for
turning the formalized, randomized algorithm into a verified proof checker, and
our design of proof certificates for both ApproxMC and its internal CNF-XOR
solving steps. Experimentally, we show that certificate generation adds little
overhead to an approximate counter implementation, and that our certificate
checker is able to fully certify $84.7\%$ of instances with generated
certificates when given the same time and memory limits as the counter.

ÊëòË¶ÅÔºöËøë‰ººÊ®°ÂûãË®àÊï∏ÊòØËøë‰ººËº∏ÂÖ•Â∏ÉÊûóÂÖ¨ÂºèÁöÑËß£ÁöÑÊï∏ÈáèÁöÑÂ∑•‰Ωú„ÄÇËÅØÈõÜÁØÑÂºè (CNF) ‰∏≠ÂÖ¨ÂºèÁöÑÊúÄÊñ∞Ëøë‰ººÊ®°ÂûãË®àÊï∏Âô® ApproxMC Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂèØÊì¥ÂÖÖÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÂèñÂæóÊ®°ÂûãË®àÊï∏Ôºå‰∏¶ÂÖ∑ÊúâÂèØËÉΩËøë‰ººÊ≠£Á¢∫ (PAC) ÂºèÁöÑ‰øùË≠â„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåApproxMC Ëøë‰ººÁöÑÊúâÊïàÊÄß‰æùË≥¥ÊñºÂÖ∂Èö®Ê©üÊºîÁÆóÊ≥ïÁöÑ‰ªîÁ¥∞ÁêÜË´ñÂàÜÊûêÔºå‰ª•ÂèäÂÖ∂È´òÂ∫¶ÊúÄ‰Ω≥ÂåñÂØ¶‰ΩúÁöÑÊ≠£Á¢∫ÊÄßÔºåÁâπÂà•ÊòØÂæåËÄÖËàáÂéüÁîüËôïÁêÜÂ•áÂÅ∂Ê†°È©ó (XOR) Á¥ÑÊùüÁöÑÂ¢ûÈáè CNF ÂèØÊªøË∂≥ÊÄßÊ±ÇËß£Âô®ÁöÑÊúâÁãÄÊÖã‰∫íÂãï„ÄÇ
ÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãËøë‰ººÊ®°ÂûãË®àÊï∏ÁöÑÁ¨¨‰∏ÄÂÄãË™çË≠âÊû∂ÊßãÔºåÂÖ∂Ëº∏Âá∫Ëøë‰ººÁöÑÂìÅË≥™ÂÖ∑ÊúâÊ≠£ÂºèÈ©óË≠âÁöÑ‰øùË≠â„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÁµêÂêàÔºö(i) Âú® Isabelle/HOL Ë≠âÊòéËºîÂä©Â∑•ÂÖ∑‰∏≠ÊºîÁÆóÊ≥ïÁöÑ PAC ‰øùË≠âÁöÑÈùúÊÖã„ÄÅ‰∏ÄÊ¨°ÊÄßÁöÑÊ≠£ÂºèË≠âÊòéÔºõ‰ª•Âèä (ii) ApproxMC Â∞çÂ§ñÈÉ® CNF-XOR Ê±ÇËß£Âô®ÂëºÂè´ÁöÑÂãïÊÖã„ÄÅÊØèÊ¨°Âü∑Ë°åÈ©óË≠âÔºå‰ΩøÁî®Ë≠âÊòéË≠âÊõ∏„ÄÇÊàëÂÄëË©≥Á¥∞Ë™™Êòé‰∫ÜÊàëÂÄëÂª∫Á´ãÈ©óË≠âÈÄôÂÖ©ÂÄãÈÉ®ÂàÜ‰πãÈñìÂö¥Ë¨πÈÄ£Êé•ÁöÑÈÄöÁî®ÂÅöÊ≥ïÔºåÂåÖÊã¨ÊàëÂÄëÂ∞áÂΩ¢ÂºèÂåñÈö®Ê©üÊºîÁÆóÊ≥ïËΩâËÆäÊàêÈ©óË≠âË≠âÊòéÊ™¢Êü•Âô®ÁöÑËóçÂúñÔºå‰ª•ÂèäÊàëÂÄëÁÇ∫ ApproxMC ÂèäÂÖ∂ÂÖßÈÉ® CNF-XOR Ê±ÇËß£Ê≠•È©üË®≠Ë®àÁöÑË≠âÊòéË≠âÊõ∏„ÄÇÂú®ÂØ¶È©ó‰∏≠ÔºåÊàëÂÄëÈ°ØÁ§∫Ë≠âÊõ∏Áî¢ÁîüÁÇ∫Ëøë‰ººË®àÊï∏Âô®ÂØ¶‰ΩúÂ¢ûÂä†ÂæàÂ∞ëÁöÑÈñãÈä∑ÔºåËÄå‰∏îÊàëÂÄëÁöÑË≠âÊõ∏Ê™¢Êü•Âô®ËÉΩÂ§†Âú®ËàáË®àÊï∏Âô®Áµ¶‰∫àÁõ∏ÂêåÊôÇÈñìÂíåË®òÊÜ∂È´îÈôêÂà∂ÊôÇÔºåÂÆåÂÖ®Ë™çË≠â $84.7\%$ ÂÄãÂÖ∑ÊúâÁî¢ÁîüË≠âÊõ∏ÁöÑÂØ¶‰æã„ÄÇ

##### **HARE: HumAn pRiors, a key to small language model Efficiency**
2406.11410v1 by Lingyun Zhang, Bin jin, Gaojian Ge, Lunhui Liu, Xuewen Shen, Mingyong Wu, Houqian Zhang, Yongneng Jiang, Shiqi Chen, Shi Pu

Human priors play a crucial role in efficiently utilizing data in deep
learning. However, with the development of large language models (LLMs), there
is an increasing emphasis on scaling both model size and data volume, which
often diminishes the importance of human priors in data construction.
Influenced by these trends, existing Small Language Models (SLMs) mainly rely
on web-scraped large-scale training data, neglecting the proper incorporation
of human priors. This oversight limits the training efficiency of language
models in resource-constrained settings. In this paper, we propose a principle
to leverage human priors for data construction. This principle emphasizes
achieving high-performance SLMs by training on a concise dataset that
accommodates both semantic diversity and data quality consistency, while
avoiding benchmark data leakage. Following this principle, we train an SLM
named HARE-1.1B. Extensive experiments on large-scale benchmark datasets
demonstrate that HARE-1.1B performs favorably against state-of-the-art SLMs,
validating the effectiveness of the proposed principle. Additionally, this
provides new insights into efficient language model training in
resource-constrained environments from the view of human priors.

ÊëòË¶ÅÔºö‰∫∫È°ûÂÖàÈ©óÂú®ÊúâÊïàÂà©Áî®Ê∑±Â∫¶Â≠∏Áøí‰∏≠ÁöÑË≥áÊñôÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤„ÄÇÁÑ∂ËÄåÔºåÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÁôºÂ±ïÔºåË∂ä‰æÜË∂äÈáçË¶ñÊì¥Â±ïÊ®°ÂûãË¶èÊ®°ÂíåË≥áÊñôÈáèÔºåÈÄôÂ∏∏Â∏∏Èôç‰Ωé‰∫Ü‰∫∫È°ûÂÖàÈ©óÂú®Ë≥áÊñôÂª∫Êßã‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇÂèóÂà∞ÈÄô‰∫õË∂®Âã¢ÁöÑÂΩ±ÈüøÔºåÁèæÊúâÁöÑÂ∞èÂûãË™ûË®ÄÊ®°ÂûãÔºàSLMÔºâ‰∏ªË¶Å‰æùË≥¥Á∂≤Ë∑ØÁà¨ÂèñÁöÑÂ§ßË¶èÊ®°Ë®ìÁ∑¥Ë≥áÊñôÔºåÂøΩÁï•‰∫ÜÈÅ©Áï∂Á¥çÂÖ•‰∫∫È°ûÂÖàÈ©ó„ÄÇÈÄôÁ®ÆÁñèÂøΩÈôêÂà∂‰∫ÜË™ûË®ÄÊ®°ÂûãÂú®Ë≥áÊ∫êÂèóÈôêÁí∞Â¢É‰∏≠ÁöÑË®ìÁ∑¥ÊïàÁéá„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂà©Áî®‰∫∫È°ûÂÖàÈ©óÈÄ≤Ë°åË≥áÊñôÂª∫ÊßãÁöÑÂéüÂâá„ÄÇÊ≠§ÂéüÂâáÂº∑Ë™øÈÄèÈÅéË®ìÁ∑¥‰∏ÄÂÄãÁ∞°ÊΩîÁöÑË≥áÊñôÈõÜ‰æÜÈÅîÊàêÈ´òÊÄßËÉΩ SLMÔºåË©≤Ë≥áÊñôÈõÜÂåÖÂê´Ë™ûÁæ©Â§öÊ®£ÊÄßÂíåË≥áÊñôÂìÅË≥™‰∏ÄËá¥ÊÄßÔºåÂêåÊôÇÈÅøÂÖçÂü∫Ê∫ñË≥áÊñôÂ§ñÊ¥©„ÄÇÈÅµÂæ™Ê≠§ÂéüÂâáÔºåÊàëÂÄëË®ìÁ∑¥‰∫Ü‰∏ÄÂÄãÂêçÁÇ∫ HARE-1.1B ÁöÑ SLM„ÄÇÂú®Â§ßÂûãÂü∫Ê∫ñË≥áÊñôÈõÜ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòéÔºåHARE-1.1B Áõ∏Â∞çÊñºÊúÄÂÖàÈÄ≤ÁöÑ SLM Ë°®ÁèæËâØÂ•ΩÔºåÈ©óË≠â‰∫ÜÊâÄÊèêÂá∫ÂéüÂâáÁöÑÊúâÊïàÊÄß„ÄÇÊ≠§Â§ñÔºåÈÄôÂæû‰∫∫È°ûÂÖàÈ©óÁöÑËßíÂ∫¶Êèê‰æõ‰∫ÜÂ∞çË≥áÊ∫êÂèóÈôêÁí∞Â¢É‰∏≠ÊúâÊïàË™ûË®ÄÊ®°ÂûãË®ìÁ∑¥ÁöÑÊñ∞Ë¶ãËß£„ÄÇ

