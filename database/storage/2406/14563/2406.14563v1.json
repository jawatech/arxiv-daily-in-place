{"2406.14563": {"publish_time": "2024-06-20", "title": "Model Merging and Safety Alignment: One Bad Model Spoils the Bunch", "paper_summary": "Merging Large Language Models (LLMs) is a cost-effective technique for\ncombining multiple expert LLMs into a single versatile model, retaining the\nexpertise of the original ones. However, current approaches often overlook the\nimportance of safety alignment during merging, leading to highly misaligned\nmodels. This work investigates the effects of model merging on alignment. We\nevaluate several popular model merging techniques, demonstrating that existing\nmethods do not only transfer domain expertise but also propagate misalignment.\nWe propose a simple two-step approach to address this problem: (i) generating\nsynthetic safety and domain-specific data, and (ii) incorporating these\ngenerated data into the optimization process of existing data-aware model\nmerging techniques. This allows us to treat alignment as a skill that can be\nmaximized in the resulting merged LLM. Our experiments illustrate the\neffectiveness of integrating alignment-related data during merging, resulting\nin models that excel in both domain expertise and alignment.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5408\u4f75\u662f\u4e00\u7a2e\u7d93\u6fdf\u5be6\u60e0\u7684\u6280\u8853\uff0c\u53ef\u5c07\u591a\u500b\u5c08\u5bb6\u7d1a LLM \u5408\u4f75\u6210\u4e00\u500b\u7528\u9014\u5ee3\u6cdb\u7684\u6a21\u578b\uff0c\u540c\u6642\u4fdd\u7559\u539f\u59cb\u6a21\u578b\u7684\u5c08\u696d\u77e5\u8b58\u3002\u7136\u800c\uff0c\u76ee\u524d\u7684\u505a\u6cd5\u901a\u5e38\u5ffd\u7565\u5408\u4f75\u671f\u9593\u5b89\u5168\u6bd4\u5c0d\u7684\u91cd\u8981\u6027\uff0c\u5c0e\u81f4\u6a21\u578b\u9ad8\u5ea6\u5931\u6e96\u3002\u9019\u9805\u5de5\u4f5c\u63a2\u8a0e\u4e86\u6a21\u578b\u5408\u4f75\u5c0d\u6bd4\u5c0d\u7684\u5f71\u97ff\u3002\u6211\u5011\u8a55\u4f30\u4e86\u5e7e\u7a2e\u6d41\u884c\u7684\u6a21\u578b\u5408\u4f75\u6280\u8853\uff0c\u8b49\u660e\u73fe\u6709\u65b9\u6cd5\u4e0d\u50c5\u6703\u50b3\u905e\u9818\u57df\u5c08\u696d\u77e5\u8b58\uff0c\u9084\u6703\u50b3\u64ad\u5931\u6e96\u3002\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u7c21\u55ae\u7684\u5169\u6b65\u9a5f\u65b9\u6cd5\u4f86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff1a(i) \u751f\u6210\u5408\u6210\u5b89\u5168\u548c\u7279\u5b9a\u9818\u57df\u7684\u6578\u64da\uff0c\u4ee5\u53ca (ii) \u5c07\u9019\u4e9b\u751f\u6210\u7684\u6578\u64da\u7d0d\u5165\u73fe\u6709\u7684\u6578\u64da\u611f\u77e5\u6a21\u578b\u5408\u4f75\u6280\u8853\u7684\u6700\u4f73\u5316\u904e\u7a0b\u4e2d\u3002\u9019\u8b93\u6211\u5011\u53ef\u4ee5\u5c07\u6bd4\u5c0d\u8996\u70ba\u4e00\u7a2e\u53ef\u4ee5\u5728\u5408\u4f75\u5f8c\u7684 LLM \u4e2d\u6700\u5927\u5316\u7684\u6280\u80fd\u3002\u6211\u5011\u7684\u5be6\u9a57\u8aaa\u660e\u4e86\u5728\u5408\u4f75\u904e\u7a0b\u4e2d\u6574\u5408\u8207\u6bd4\u5c0d\u76f8\u95dc\u7684\u6578\u64da\u7684\u6709\u6548\u6027\uff0c\u5f9e\u800c\u7522\u751f\u5728\u9818\u57df\u5c08\u696d\u77e5\u8b58\u548c\u6bd4\u5c0d\u65b9\u9762\u90fd\u8868\u73fe\u51fa\u8272\u7684\u6a21\u578b\u3002", "author": "Hasan Abed Al Kader Hammoud et.al.", "authors": "Hasan Abed Al Kader Hammoud, Umberto Michieli, Fabio Pizzati, Philip Torr, Adel Bibi, Bernard Ghanem, Mete Ozay", "id": "2406.14563v1", "paper_url": "http://arxiv.org/abs/2406.14563v1", "repo": "null"}}