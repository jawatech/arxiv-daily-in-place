
### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-26**|**Is larger always better? Evaluating and prompting large language models for non-generative medical tasks**|Yinghao Zhu et.al.|[2407.18525v1](http://arxiv.org/abs/2407.18525v1)|[link](https://github.com/yhzhu99/ehr-llm-benchmark)|
|**2024-07-26**|**A Role-specific Guided Large Language Model for Ophthalmic Consultation Based on Stylistic Differentiation**|Laiyi Fu et.al.|[2407.18483v1](http://arxiv.org/abs/2407.18483v1)|[link](https://github.com/sperfu/eyedoc)|
|**2024-07-25**|**HDL-GPT: High-Quality HDL is All You Need**|Bhuvnesh Kumar et.al.|[2407.18423v1](http://arxiv.org/abs/2407.18423v1)|null|
|**2024-07-25**|**SCALE: Self-regulated Clustered federAted LEarning in a Homogeneous Environment**|Sai Puppala et.al.|[2407.18387v1](http://arxiv.org/abs/2407.18387v1)|null|
|**2024-07-25**|**Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v1](http://arxiv.org/abs/2407.18343v1)|null|
|**2024-07-25**|**Self-supervised pre-training with diffusion model for few-shot landmark detection in x-ray images**|Roberto Di Via et.al.|[2407.18125v1](http://arxiv.org/abs/2407.18125v1)|null|
|**2024-07-25**|**Multi-Resolution Histopathology Patch Graphs for Ovarian Cancer Subtyping**|Jack Breen et.al.|[2407.18105v1](http://arxiv.org/abs/2407.18105v1)|[link](https://github.com/scjjb/MultiscalePathGraph)|
|**2024-07-25**|**HG-PIPE: Vision Transformer Acceleration with Hybrid-Grained Pipeline**|Qingyu Guo et.al.|[2407.17879v1](http://arxiv.org/abs/2407.17879v1)|null|
|**2024-07-25**|**EEG-SSM: Leveraging State-Space Model for Dementia Detection**|Xuan-The Tran et.al.|[2407.17801v1](http://arxiv.org/abs/2407.17801v1)|null|
|**2024-07-25**|**Mpox Detection Advanced: Rapid Epidemic Response Through Synthetic Data**|Yudara Kularathne et.al.|[2407.17762v1](http://arxiv.org/abs/2407.17762v1)|null|
|**2024-07-25**|**Cost-effective Instruction Learning for Pathology Vision and Language Analysis**|Kaitao Chen et.al.|[2407.17734v1](http://arxiv.org/abs/2407.17734v1)|[link](https://github.com/jlinekai/clover)|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Improving ICD coding using Chapter based Named Entities and Attentional Models**|Abhijith R. Beeravolu et.al.|[2407.17230v1](http://arxiv.org/abs/2407.17230v1)|null|
|**2024-07-24**|**Robust Deep Hawkes Process under Label Noise of Both Event and Occurrence**|Xiaoyu Tan et.al.|[2407.17164v1](http://arxiv.org/abs/2407.17164v1)|null|
|**2024-07-24**|**SDoH-GPT: Using Large Language Models to Extract Social Determinants of Health (SDoH)**|Bernardo Consoli et.al.|[2407.17126v1](http://arxiv.org/abs/2407.17126v1)|null|
|**2024-07-24**|**SepsisLab: Early Sepsis Prediction with Uncertainty Quantification and Active Sensing**|Changchang Yin et.al.|[2407.16999v1](http://arxiv.org/abs/2407.16999v1)|[link](https://github.com/yinchangchang/sepsislab)|
|**2024-07-24**|**Toward an Integrated Decision Making Framework for Optimized Stroke Diagnosis with DSA and Treatment under Uncertainty**|Nur Ahmad Khatim et.al.|[2407.16962v1](http://arxiv.org/abs/2407.16962v1)|[link](https://github.com/inteligensi/dsapomdps.jl)|
|**2024-07-23**|**AI-Enhanced 7-Point Checklist for Melanoma Detection Using Clinical Knowledge Graphs and Data-Driven Quantification**|Yuheng Wang et.al.|[2407.16822v1](http://arxiv.org/abs/2407.16822v1)|[link](https://github.com/ryan315/7pgd)|
|**2024-07-23**|**Multimodal Machine Learning in Mental Health: A Survey of Data, Algorithms, and Challenges**|Zahraa Al Sahili et.al.|[2407.16804v1](http://arxiv.org/abs/2407.16804v1)|null|
|**2024-07-23**|**Deep Bayesian segmentation for colon polyps: Well-calibrated predictions in medical imaging**|Daniela L. Ramos et.al.|[2407.16608v1](http://arxiv.org/abs/2407.16608v1)|null|
|**2024-07-23**|**A Comparative Study on Patient Language across Therapeutic Domains for Effective Patient Voice Classification in Online Health Discussions**|Giorgos Lysandrou et.al.|[2407.16593v1](http://arxiv.org/abs/2407.16593v1)|null|
|**2024-07-23**|**Virtue Ethics For Ethically Tunable Robotic Assistants**|Rajitha Ramanayake et.al.|[2407.16361v1](http://arxiv.org/abs/2407.16361v1)|null|
|**2024-07-23**|**PhenoFlow: A Human-LLM Driven Visual Analytics System for Exploring Large and Complex Stroke Datasets**|Jaeyoung Kim et.al.|[2407.16329v1](http://arxiv.org/abs/2407.16329v1)|null|
|**2024-07-23**|**Research on Adverse Drug Reaction Prediction Model Combining Knowledge Graph Embedding and Deep Learning**|Yufeng Li et.al.|[2407.16715v1](http://arxiv.org/abs/2407.16715v1)|null|
|**2024-07-22**|**Artificial Intelligence-based Decision Support Systems for Precision and Digital Health**|Nina Deliu et.al.|[2407.16062v1](http://arxiv.org/abs/2407.16062v1)|null|
|**2024-07-22**|**GFE-Mamba: Mamba-based AD Multi-modal Progression Assessment via Generative Feature Extraction from MCI**|Zhaojie Fang et.al.|[2407.15719v1](http://arxiv.org/abs/2407.15719v1)|[link](https://github.com/tinysqua/gfe-mamba)|
|**2024-07-22**|**Synthetic Image Learning: Preserving Performance and Preventing Membership Inference Attacks**|Eugenio Lomurno et.al.|[2407.15526v1](http://arxiv.org/abs/2407.15526v1)|null|
|**2024-07-22**|**A Multimodal Knowledge-enhanced Whole-slide Pathology Foundation Model**|Yingxue Xu et.al.|[2407.15362v1](http://arxiv.org/abs/2407.15362v1)|null|
|**2024-07-21**|**Genetic Algorithm to Optimize Design of Micro-Surgical Scissors**|Fatemeh Norouziani et.al.|[2407.15243v1](http://arxiv.org/abs/2407.15243v1)|null|
|**2024-07-21**|**MedSAGa: Few-shot Memory Efficient Medical Image Segmentation using Gradient Low-Rank Projection in SAM**|Navyansh Mahla et.al.|[2407.15042v1](http://arxiv.org/abs/2407.15042v1)|null|
|**2024-07-20**|**Preictal Period Optimization for Deep Learning-Based Epileptic Seizure Prediction**|Petros Koutsouvelis et.al.|[2407.14876v1](http://arxiv.org/abs/2407.14876v1)|null|
|**2024-07-20**|**PASSION: Towards Effective Incomplete Multi-Modal Medical Image Segmentation with Imbalanced Missing Rates**|Junjie Shi et.al.|[2407.14796v1](http://arxiv.org/abs/2407.14796v1)|[link](https://github.com/jun-jie-shi/passion)|
|**2024-07-19**|**Improving Representation of High-frequency Components for Medical Foundation Models**|Yuetan Chu et.al.|[2407.14651v2](http://arxiv.org/abs/2407.14651v2)|[link](https://github.com/Arturia-Pendragon-Iris/Frepa)|
|**2024-07-19**|**CVE-LLM : Automatic vulnerability evaluation in medical device industry using large language models**|Rikhiya Ghosh et.al.|[2407.14640v1](http://arxiv.org/abs/2407.14640v1)|null|
|**2024-07-19**|**Two new feature selection methods based on learn-heuristic techniques for breast cancer prediction: A comprehensive analysis**|Kamyab Karimi et.al.|[2407.14631v1](http://arxiv.org/abs/2407.14631v1)|null|
|**2024-07-19**|**Panoptic Segmentation of Mammograms with Text-To-Image Diffusion Model**|Kun Zhao et.al.|[2407.14326v1](http://arxiv.org/abs/2407.14326v1)|null|
|**2024-07-19**|**Fair Overlap Number of Balls (Fair-ONB): A Data-Morphology-based Undersampling Method for Bias Reduction**|José Daniel Pascual-Triana et.al.|[2407.14210v1](http://arxiv.org/abs/2407.14210v1)|null|
|**2024-07-19**|**Domain-Specific Pretraining of Language Models: A Comparative Study in the Medical Field**|Tobias Kerner et.al.|[2407.14076v1](http://arxiv.org/abs/2407.14076v1)|null|
|**2024-07-19**|**HeCiX: Integrating Knowledge Graphs and Large Language Models for Biomedical Research**|Prerana Sanjay Kulkarni et.al.|[2407.14030v1](http://arxiv.org/abs/2407.14030v1)|null|
|**2024-07-18**|**DuoFormer: Leveraging Hierarchical Visual Representations by Local and Global Attention**|Xiaoya Tang et.al.|[2407.13920v1](http://arxiv.org/abs/2407.13920v1)|null|
|**2024-07-18**|**Data-Algorithm-Architecture Co-Optimization for Fair Neural Networks on Skin Lesion Dataset**|Yi Sheng et.al.|[2407.13896v1](http://arxiv.org/abs/2407.13896v1)|null|
|**2024-07-18**|**APS-USCT: Ultrasound Computed Tomography on Sparse Data via AI-Physic Synergy**|Yi Sheng et.al.|[2407.14564v1](http://arxiv.org/abs/2407.14564v1)|null|
|**2024-07-18**|**Addressing Imbalance for Class Incremental Learning in Medical Image Classification**|Xuze Hao et.al.|[2407.13768v1](http://arxiv.org/abs/2407.13768v1)|null|
|**2024-07-18**|**Shaded Route Planning Using Active Segmentation and Identification of Satellite Images**|Longchao Da et.al.|[2407.13689v1](http://arxiv.org/abs/2407.13689v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-18**|**A review of handcrafted and deep radiomics in neurological diseases: transitioning from oncology to clinical neuroimaging**|Elizaveta Lavrova et.al.|[2407.13813v1](http://arxiv.org/abs/2407.13813v1)|null|
|**2024-07-18**|**End-To-End Clinical Trial Matching with Large Language Models**|Dyke Ferber et.al.|[2407.13463v1](http://arxiv.org/abs/2407.13463v1)|null|
|**2024-07-18**|**CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis**|Junying Chen et.al.|[2407.13301v1](http://arxiv.org/abs/2407.13301v1)|null|
|**2024-07-18**|**NODER: Image Sequence Regression Based on Neural Ordinary Differential Equations**|Hao Bai et.al.|[2407.13241v1](http://arxiv.org/abs/2407.13241v1)|null|
|**2024-07-17**|**Enhancing the Utility of Privacy-Preserving Cancer Classification using Synthetic Data**|Richard Osuala et.al.|[2407.12669v1](http://arxiv.org/abs/2407.12669v1)|null|
|**2024-07-17**|**Abstraction Alignment: Comparing Model and Human Conceptual Relationships**|Angie Boggust et.al.|[2407.12543v1](http://arxiv.org/abs/2407.12543v1)|[link](https://github.com/mitvis/abstraction-alignment)|
|**2024-07-17**|**Maintenance Strategies for Sewer Pipes with Multi-State Degradation and Deep Reinforcement Learning**|Lisandro A. Jimenez-Roa et.al.|[2407.12894v1](http://arxiv.org/abs/2407.12894v1)|null|
|**2024-07-17**|**Search Engines, LLMs or Both? Evaluating Information Seeking Strategies for Answering Health Questions**|Marcos Fernández-Pichel et.al.|[2407.12468v2](http://arxiv.org/abs/2407.12468v2)|null|
|**2024-07-17**|**Explainable Biomedical Hypothesis Generation via Retrieval Augmented Generation enabled Large Language Models**|Alexander R. Pelletier et.al.|[2407.12888v1](http://arxiv.org/abs/2407.12888v1)|[link](https://github.com/pinglab-utils/rugged)|
|**2024-07-17**|**Evaluating graph-based explanations for AI-based recommender systems**|Simon Delarue et.al.|[2407.12357v1](http://arxiv.org/abs/2407.12357v1)|null|
|**2024-07-16**|**GPT-4V Cannot Generate Radiology Reports Yet**|Yuyang Jiang et.al.|[2407.12176v1](http://arxiv.org/abs/2407.12176v1)|[link](https://github.com/yuyangj0/gpt-4v-evaluation-radiology-report)|
|**2024-07-16**|**LLMs-in-the-loop Part-1: Expert Small AI Models for Bio-Medical Text Translation**|Bunyamin Keles et.al.|[2407.12126v2](http://arxiv.org/abs/2407.12126v2)|null|
|**2024-07-16**|**Schema Matching with Large Language Models: an Experimental Study**|Marcel Parciak et.al.|[2407.11852v1](http://arxiv.org/abs/2407.11852v1)|[link](https://github.com/uhasselt-dsi-data-systems-lab/code-schema-matching-llms-artefacs)|
|**2024-07-16**|**GPT Assisted Annotation of Rhetorical and Linguistic Features for Interpretable Propaganda Technique Detection in News Text**|Kyle Hamilton et.al.|[2407.11827v1](http://arxiv.org/abs/2407.11827v1)|null|
|**2024-07-16**|**Characterizing and Understanding HGNN Training on GPUs**|Dengke Han et.al.|[2407.11790v2](http://arxiv.org/abs/2407.11790v2)|null|
|**2024-07-16**|**CCoE: A Compact LLM with Collaboration of Experts**|Shaomang Huang et.al.|[2407.11686v3](http://arxiv.org/abs/2407.11686v3)|null|
|**2024-07-16**|**CCVA-FL: Cross-Client Variations Adaptive Federated Learning for Medical Imaging**|Sunny Gupta et.al.|[2407.11652v2](http://arxiv.org/abs/2407.11652v2)|null|
|**2024-07-16**|**Improving Engagement and Efficacy of mHealth Micro-Interventions for Stress Coping: an In-The-Wild Study**|Chaya Ben Yehuda et.al.|[2407.11612v1](http://arxiv.org/abs/2407.11612v1)|null|
|**2024-07-16**|**DiNO-Diffusion. Scaling Medical Diffusion via Self-Supervised Pre-Training**|Guillermo Jimenez-Perez et.al.|[2407.11594v1](http://arxiv.org/abs/2407.11594v1)|null|
|**2024-07-16**|**Probing the Efficacy of Federated Parameter-Efficient Fine-Tuning of Vision Transformers for Medical Image Classification**|Naif Alkhunaizi et.al.|[2407.11573v1](http://arxiv.org/abs/2407.11573v1)|null|
|**2024-07-16**|**Fine-Tuning Medical Language Models for Enhanced Long-Contextual Understanding and Domain Expertise**|Qimin Yang et.al.|[2407.11536v1](http://arxiv.org/abs/2407.11536v1)|null|
|**2024-07-16**|**Cross-Phase Mutual Learning Framework for Pulmonary Embolism Identification on Non-Contrast CT Scans**|Bizhe Bai et.al.|[2407.11529v1](http://arxiv.org/abs/2407.11529v1)|null|
|**2024-07-16**|**Multi-Channel Masked Autoencoder and Comprehensive Evaluations for Reconstructing 12-Lead ECG from Arbitrary Single-Lead ECG**|Jiarong Chen et.al.|[2407.11481v1](http://arxiv.org/abs/2407.11481v1)|[link](https://github.com/chenjiar3/mcma)|
|**2024-07-16**|**TM-PATHVQA:90000+ Textless Multilingual Questions for Medical Visual Question Answering**|Tonmoy Rajkhowa et.al.|[2407.11383v1](http://arxiv.org/abs/2407.11383v1)|null|
|**2024-07-16**|**Performance Evaluation of Lightweight Open-source Large Language Models in Pediatric Consultations: A Comparative Analysis**|Qiuhong Wei et.al.|[2407.15862v1](http://arxiv.org/abs/2407.15862v1)|null|
|**2024-07-15**|**Leveraging Multimodal CycleGAN for the Generation of Anatomically Accurate Synthetic CT Scans from MRIs**|Leonardo Crespi et.al.|[2407.10888v1](http://arxiv.org/abs/2407.10888v1)|null|
|**2024-07-15**|**Towards Enhanced Classification of Abnormal Lung sound in Multi-breath: A Light Weight Multi-label and Multi-head Attention Classification Method**|Yi-Wei Chua et.al.|[2407.10828v1](http://arxiv.org/abs/2407.10828v1)|null|
|**2024-07-15**|**Classification of Heart Sounds Using Multi-Branch Deep Convolutional Network and LSTM-CNN**|Seyed Amir Latifi et.al.|[2407.10689v1](http://arxiv.org/abs/2407.10689v1)|null|
|**2024-07-15**|**Spatio-temporal neural distance fields for conditional generative modeling of the heart**|Kristine Sørensen et.al.|[2407.10663v1](http://arxiv.org/abs/2407.10663v1)|[link](https://github.com/kristineaajuhl/spatio_temporal_generative_cardiac_model)|
|**2024-07-15**|**TCM-FTP: Fine-Tuning Large Language Models for Herbal Prescription Prediction**|Xingzhi Zhou et.al.|[2407.10510v1](http://arxiv.org/abs/2407.10510v1)|null|
|**2024-07-15**|**A Multi-Stage Framework for 3D Individual Tooth Segmentation in Dental CBCT**|Chunshi Wang et.al.|[2407.10433v1](http://arxiv.org/abs/2407.10433v1)|null|
|**2024-07-15**|**Static and multivariate-temporal attentive fusion transformer for readmission risk prediction**|Zhe Sun et.al.|[2407.11096v1](http://arxiv.org/abs/2407.11096v1)|null|
|**2024-07-14**|**Evolved Developmental Artificial Neural Networks for Multitasking with Advanced Activity Dependence**|Yintong Zhang et.al.|[2407.10359v1](http://arxiv.org/abs/2407.10359v1)|null|
|**2024-07-14**|**Learning Unlabeled Clients Divergence via Anchor Model Aggregation for Federated Semi-supervised Learning**|Marawan Elbatel et.al.|[2407.10327v1](http://arxiv.org/abs/2407.10327v1)|null|
|**2024-07-14**|**Rapid Biomedical Research Classification: The Pandemic PACT Advanced Categorisation Engine**|Omid Rohanian et.al.|[2407.10086v2](http://arxiv.org/abs/2407.10086v2)|null|
|**2024-07-13**|**Document-level Clinical Entity and Relation Extraction via Knowledge Base-Guided Generation**|Kriti Bhattarai et.al.|[2407.10021v1](http://arxiv.org/abs/2407.10021v1)|null|
|**2024-07-13**|**Causality extraction from medical text using Large Language Models (LLMs)**|Seethalakshmi Gopalakrishnan et.al.|[2407.10020v1](http://arxiv.org/abs/2407.10020v1)|null|
|**2024-07-13**|**Pay Less On Clinical Images: Asymmetric Multi-Modal Fusion Method For Efficient Multi-Label Skin Lesion Classification**|Peng Tang et.al.|[2407.09999v1](http://arxiv.org/abs/2407.09999v1)|null|
|**2024-07-13**|**Evaluating the Impact of Different Quantum Kernels on the Classification Performance of Support Vector Machine Algorithm: A Medical Dataset Application**|Emine Akpinar et.al.|[2407.09930v2](http://arxiv.org/abs/2407.09930v2)|null|
|**2024-07-13**|**Enhancing Semantic Segmentation with Adaptive Focal Loss: A Novel Approach**|Md Rakibul Islam et.al.|[2407.09828v1](http://arxiv.org/abs/2407.09828v1)|null|
|**2024-07-12**|**Towards Personalised Patient Risk Prediction Using Temporal Hospital Data Trajectories**|Thea Barnes et.al.|[2407.09373v1](http://arxiv.org/abs/2407.09373v1)|null|
|**2024-07-12**|**Enhancing Depressive Post Detection in Bangla: A Comparative Study of TF-IDF, BERT and FastText Embeddings**|Saad Ahmed Sazan et.al.|[2407.09187v1](http://arxiv.org/abs/2407.09187v1)|null|
|**2024-07-12**|**STD-LLM: Understanding Both Spatial and Temporal Properties of Spatial-Temporal Data with LLMs**|Yiheng Huang et.al.|[2407.09096v1](http://arxiv.org/abs/2407.09096v1)|null|
|**2024-07-12**|**FD-SOS: Vision-Language Open-Set Detectors for Bone Fenestration and Dehiscence Detection from Intraoral Images**|Marawan Elbatel et.al.|[2407.09088v1](http://arxiv.org/abs/2407.09088v1)|null|
|**2024-07-12**|**Heterogeneous Subgraph Network with Prompt Learning for Interpretable Depression Detection on Social Media**|Chen Chen et.al.|[2407.09019v1](http://arxiv.org/abs/2407.09019v1)|null|
|**2024-07-12**|**Application of Artificial Intelligence in Supporting Healthcare Professionals and Caregivers in Treatment of Autistic Children**|Hossein Mohammadi Rouzbahani et.al.|[2407.08902v1](http://arxiv.org/abs/2407.08902v1)|null|
|**2024-07-11**|**SALT: Introducing a Framework for Hierarchical Segmentations in Medical Imaging using Softmax for Arbitrary Label Trees**|Sven Koitka et.al.|[2407.08878v1](http://arxiv.org/abs/2407.08878v1)|[link](https://github.com/umessen/salt)|
|**2024-07-11**|**FedMedICL: Towards Holistic Evaluation of Distribution Shifts in Federated Medical Imaging**|Kumail Alhamoud et.al.|[2407.08822v1](http://arxiv.org/abs/2407.08822v1)|[link](https://github.com/m1k2zoo/fedmedicl)|
|**2024-07-11**|**FairDomain: Achieving Fairness in Cross-Domain Medical Image Segmentation and Classification**|Yu Tian et.al.|[2407.08813v2](http://arxiv.org/abs/2407.08813v2)|[link](https://github.com/harvard-ophthalmology-ai-lab/fairdomain)|
|**2024-07-11**|**Uncertainty Estimation of Large Language Models in Medical Question Answering**|Jiaxin Wu et.al.|[2407.08662v1](http://arxiv.org/abs/2407.08662v1)|null|
|**2024-07-11**|**Establishing Rigorous and Cost-effective Clinical Trials for Artificial Intelligence Models**|Wanling Gao et.al.|[2407.08554v1](http://arxiv.org/abs/2407.08554v1)|[link](https://github.com/benchcouncil/vc-medai)|
|**2024-07-11**|**How Deep is your Guess? A Fresh Perspective on Deep Learning for Medical Time-Series Imputation**|Linglong Qian et.al.|[2407.08442v1](http://arxiv.org/abs/2407.08442v1)|null|
|**2024-07-11**|**Specialist vision-language models for clinical ophthalmology**|Robbie Holland et.al.|[2407.08410v1](http://arxiv.org/abs/2407.08410v1)|[link](https://github.com/robbieholland/specialistvlms)|
|**2024-07-11**|**Unveiling Disparities in Maternity Care: A Topic Modelling Approach to Analysing Maternity Incident Investigation Reports**|Georgina Cosma et.al.|[2407.08328v1](http://arxiv.org/abs/2407.08328v1)|null|
|**2024-07-11**|**Predicting Heart Failure with Attention Learning Techniques Utilizing Cardiovascular Data**|Ershadul Haque et.al.|[2407.08289v1](http://arxiv.org/abs/2407.08289v1)|null|

#### Abstracts
##### **Is larger always better? Evaluating and prompting large language models for non-generative medical tasks**
2407.18525v1 by Yinghao Zhu, Junyi Gao, Zixiang Wang, Weibin Liao, Xiaochen Zheng, Lifang Liang, Yasha Wang, Chengwei Pan, Ewen M. Harrison, Liantao Ma

The use of Large Language Models (LLMs) in medicine is growing, but their
ability to handle both structured Electronic Health Record (EHR) data and
unstructured clinical notes is not well-studied. This study benchmarks various
models, including GPT-based LLMs, BERT-based models, and traditional clinical
predictive models, for non-generative medical tasks utilizing renowned
datasets. We assessed 14 language models (9 GPT-based and 5 BERT-based) and 7
traditional predictive models using the MIMIC dataset (ICU patient records) and
the TJH dataset (early COVID-19 EHR data), focusing on tasks such as mortality
and readmission prediction, disease hierarchy reconstruction, and biomedical
sentence matching, comparing both zero-shot and finetuned performance. Results
indicated that LLMs exhibited robust zero-shot predictive capabilities on
structured EHR data when using well-designed prompting strategies, frequently
surpassing traditional models. However, for unstructured medical texts, LLMs
did not outperform finetuned BERT models, which excelled in both supervised and
unsupervised tasks. Consequently, while LLMs are effective for zero-shot
learning on structured data, finetuned BERT models are more suitable for
unstructured texts, underscoring the importance of selecting models based on
specific task requirements and data characteristics to optimize the application
of NLP technology in healthcare.

摘要：大型語言模型 (LLM) 在醫學中的應用日益廣泛，但它們同時處理結構化電子病歷 (EHR) 資料和非結構化臨床註記的能力尚未得到充分研究。本研究針對各種模型進行基準測試，包括基於 GPT 的 LLM、基於 BERT 的模型，以及傳統的臨床預測模型，用於利用著名資料集的非生成性醫療任務。我們使用 MIMIC 資料集（ICU 病人記錄）和 TJH 資料集（早期 COVID-19 EHR 資料）評估了 14 個語言模型（9 個基於 GPT，5 個基於 BERT）和 7 個傳統預測模型，重點關注死亡率和再入院預測、疾病層級重建和生物醫學句子配對等任務，並比較了零次學習和微調後的效能。結果表明，LLM 在使用設計良好的提示策略時，對結構化 EHR 資料展現出強大的零次學習預測能力，經常超越傳統模型。然而，對於非結構化的醫療文本，LLM 的表現不如微調後的 BERT 模型，後者在監督式和非監督式任務中都表現出色。因此，儘管 LLM 對於結構化資料的零次學習很有用，但微調後的 BERT 模型更適合非結構化文本，這強調了根據特定任務需求和資料特性選擇模型以優化醫療保健中 NLP 技術應用之重要性。

##### **A Role-specific Guided Large Language Model for Ophthalmic Consultation Based on Stylistic Differentiation**
2407.18483v1 by Laiyi Fu, Binbin Fan, Hongkai Du, Yanxiang Feng, Chunhua Li, Huping Song

Ophthalmology consultations are crucial for diagnosing, treating, and
preventing eye diseases. However, the growing demand for consultations exceeds
the availability of ophthalmologists. By leveraging large pre-trained language
models, we can design effective dialogues for specific scenarios, aiding in
consultations. Traditional fine-tuning strategies for question-answering tasks
are impractical due to increasing model size and often ignoring patient-doctor
role function during consultations. In this paper, we propose EyeDoctor, an
ophthalmic medical questioning large language model that enhances accuracy
through doctor-patient role perception guided and an augmented knowledge base
with external disease information. Experimental results show EyeDoctor achieves
higher question-answering precision in ophthalmology consultations. Notably,
EyeDoctor demonstrated a 7.25% improvement in Rouge-1 scores and a 10.16%
improvement in F1 scores on multi-round datasets compared to second best model
ChatGPT, highlighting the importance of doctor-patient role differentiation and
dynamic knowledge base expansion for intelligent medical consultations. EyeDoc
also serves as a free available web based service and souce code is available
at https://github.com/sperfu/EyeDoc.

摘要：眼科諮詢對於診斷、治療和預防眼疾至關重要。然而，諮詢需求不斷增加，超過眼科醫師所能提供的服務。透過利用大型預先訓練語言模型，我們可以針對特定場景設計有效的對話，協助諮詢。由於模型尺寸越來越大，且在諮詢過程中常常忽略患者與醫師的角色功能，因此傳統針對問答任務的微調策略並不切實際。在本文中，我們提出 EyeDoctor，一種眼科醫療問答大型語言模型，透過引導醫師與患者的角色認知以及擴充外部疾病資訊的知識庫來提升準確性。實驗結果顯示，EyeDoctor 在眼科諮詢中達到了更高的問答精準度。值得注意的是，與第二好的模型 ChatGPT 相比，EyeDoctor 在多輪數據集上，Rouge-1 分數提升了 7.25%，F1 分數提升了 10.16%，突顯了醫師與患者角色區分以及動態知識庫擴充對於智慧醫療諮詢的重要性。EyeDoc 也作為一個免費的網路服務，其原始碼可於 https://github.com/sperfu/EyeDoc 取得。

##### **HDL-GPT: High-Quality HDL is All You Need**
2407.18423v1 by Bhuvnesh Kumar, Saurav Nanda, Ganapathy Parthasarathy, Pawan Patil, Austin Tsai, Parivesh Choudhary

This paper presents Hardware Description Language Generative Pre-trained
Transformers (HDL-GPT), a novel approach that leverages the vast repository of
open-source High Definition Language (HDL) codes to train superior quality
large code models. The core premise of this paper is the hypothesis that
high-quality HDL is all you need to create models with exceptional performance
and broad zero-shot generalization abilities. The paper elucidates the methods
employed for the curation and augmentation of large corpora from open-source
HDL code, transforming highly variable quality data into high-quality data
through careful prompting and context maintenance. We demonstrate that the
careful selection, filtering, and augmentation of data across HDLs can yield
powerful models that surpass current state-of-the-art models. We also explore
the impact of different fine-tuning methods on the quality of results. We
describe experimental results across a range of fine-tuned SOTA LLMs,
substantiating our claims. We demonstrate improvements of 50% to 200% over SOTA
HDL models on current benchmarks in tasks ranging from HDL circuit
explanations, code generation, formal and simulation testbench creation,
triaging bugs, and fixing them. HDL-GPT opens new avenues for the development
of advanced model training techniques for circuit design tasks.

摘要：本文提出硬體描述語言生成式預訓練轉換器 (HDL-GPT)，這是一種新方法，利用大量開源高定義語言 (HDL) 程式碼來訓練優質的大型程式碼模型。本文的核心前提是高品質的 HDL 是建立具有卓越效能和廣泛零次學習概化能力模型的唯一要素。本文闡明了從開源 HDL 程式碼策展和擴充大型語料庫所使用的方法，透過仔細提示和脈絡維護，將品質高度變異的資料轉換成高品質資料。我們證明了仔細選擇、篩選和擴充 HDL 中的資料可以產生強大的模型，超越現有的最先進模型。我們也探討了不同微調方法對結果品質的影響。我們描述了針對一系列微調過的 SOTA LLM 的實驗結果，以證實我們的說法。我們證明了在從 HDL 電路說明、程式碼產生、正式和模擬測試平台建立、分類錯誤到修正錯誤等任務的現有基準中，HDL-GPT 比 SOTA HDL 模型進步了 50% 至 200%。HDL-GPT 為電路設計任務的進階模型訓練技術開發開啟了新途徑。

##### **SCALE: Self-regulated Clustered federAted LEarning in a Homogeneous Environment**
2407.18387v1 by Sai Puppala, Ismail Hossain, Md Jahangir Alam, Sajedul Talukder, Zahidur Talukder, Syed Bahauddin

Federated Learning (FL) has emerged as a transformative approach for enabling
distributed machine learning while preserving user privacy, yet it faces
challenges like communication inefficiencies and reliance on centralized
infrastructures, leading to increased latency and costs. This paper presents a
novel FL methodology that overcomes these limitations by eliminating the
dependency on edge servers, employing a server-assisted Proximity Evaluation
for dynamic cluster formation based on data similarity, performance indices,
and geographical proximity. Our integrated approach enhances operational
efficiency and scalability through a Hybrid Decentralized Aggregation Protocol,
which merges local model training with peer-to-peer weight exchange and a
centralized final aggregation managed by a dynamically elected driver node,
significantly curtailing global communication overhead. Additionally, the
methodology includes Decentralized Driver Selection, Check-pointing to reduce
network traffic, and a Health Status Verification Mechanism for system
robustness. Validated using the breast cancer dataset, our architecture not
only demonstrates a nearly tenfold reduction in communication overhead but also
shows remarkable improvements in reducing training latency and energy
consumption while maintaining high learning performance, offering a scalable,
efficient, and privacy-preserving solution for the future of federated learning
ecosystems.

摘要：聯邦學習 (FL) 已成為一種變革性方法，用於在保護使用者隱私的同時啟用分散式機器學習，但它面臨著諸如通訊效率低和依賴於集中式基礎設施等挑戰，導致延遲和成本增加。本文提出了一種新穎的 FL 方法，通過消除對邊緣伺服器的依賴，採用伺服器輔助的接近度評估來根據資料相似性、效能指標和地理接近度進行動態叢集形成，從而克服了這些限制。我們的整合方法透過混合式分散式聚合協定來增強運作效率和可擴充性，該協定將本地模型訓練與點對點權重交換以及由動態選出的驅動程式節點管理的集中式最終聚合合併在一起，大幅減少了整體通訊開銷。此外，該方法包括分散式驅動程式選擇、檢查點以減少網路流量，以及用於系統穩健性的健康狀態驗證機制。我們的架構使用乳癌資料集進行驗證，不僅證明通訊開銷減少了近十倍，而且還顯示出在降低訓練延遲和能源消耗的同時，學習效能仍保持很高的顯著改進，為聯邦學習生態系統的未來提供了一個可擴充性、高效且保護隱私的解決方案。

##### **Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v1 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

摘要：可解釋人工智慧 (XAI) 是整合人工智慧 (AI) 和機器學習 (ML) 演算法進入臨床實務的辯論核心。高性能的 AI/ML 模型，例如整合學習器和深度神經網路，通常缺乏可解釋性，阻礙臨床醫師對其預測的信任。為了解決此問題，XAI 技術正在開發中，用人類可理解的術語描述 AI/ML 預測。一個有希望的方向是採用敏感度分析 (SA) 和全局敏感度分析 (GSA)，它們本質上按模型輸入對預測的影響對其進行排序。在此，我們介紹了一種新的 delta-XAI 方法，它通過擴展 GSA 指標 delta 指數，提供了 ML 模型預測的局部解釋。delta-XAI 指數評估了每個特徵值對迴歸和分類問題中個別實例的預測輸出之影響。我們將 delta-XAI 指數形式化並提供其實作程式碼。delta-XAI 方法使用線性迴歸模型在模擬場景中進行評估，其中 Shapley 值作為基準。結果表明，delta-XAI 指數通常與 Shapley 值一致，在具有高度影響力或極端特徵值的模型中存在顯著差異。delta-XAI 指數在檢測主要特徵和處理極端特徵值方面表現出更高的敏感性。定性地說，delta-XAI 透過利用機率密度函數提供直觀的解釋，使特徵排名更清晰、更易於從業人員理解。總體而言，delta-XAI 方法對於穩健地獲得 ML 模型預測的局部解釋似乎很有希望。將在真實世界的臨床環境中進行進一步調查，以評估其對 AI 輔助臨床工作流程的影響。

##### **Self-supervised pre-training with diffusion model for few-shot landmark detection in x-ray images**
2407.18125v1 by Roberto Di Via, Francesca Odone, Vito Paolo Pastore

In the last few years, deep neural networks have been extensively applied in
the medical domain for different tasks, ranging from image classification and
segmentation to landmark detection. However, the application of these
technologies in the medical domain is often hindered by data scarcity, both in
terms of available annotations and images. This study introduces a new
self-supervised pre-training protocol based on diffusion models for landmark
detection in x-ray images. Our results show that the proposed self-supervised
framework can provide accurate landmark detection with a minimal number of
available annotated training images (up to 50), outperforming ImageNet
supervised pre-training and state-of-the-art self-supervised pre-trainings for
three popular x-ray benchmark datasets. To our knowledge, this is the first
exploration of diffusion models for self-supervised learning in landmark
detection, which may offer a valuable pre-training approach in few-shot
regimes, for mitigating data scarcity.

摘要：在過去幾年中，深度神經網路已廣泛應用於醫療領域的不同任務，從影像分類和分割到地標偵測。然而，這些技術在醫療領域的應用常常受到資料稀少的阻礙，無論是在可用的註解或影像方面。本研究介紹了一個新的自監督預訓練協定，它是基於擴散模型，用於 X 光影像中的地標偵測。我們的結果顯示，所提出的自監督架構可以在最少數量的可用註解訓練影像（最多 50 個）下提供準確的地標偵測，優於 ImageNet 監督式預訓練以及三個熱門 X 光基準資料集的最新自監督式預訓練。據我們所知，這是首次探討擴散模型用於地標偵測中的自監督式學習，它可能在小樣本訓練模式中提供有價值的預訓練方法，以減輕資料稀少的問題。

##### **Multi-Resolution Histopathology Patch Graphs for Ovarian Cancer Subtyping**
2407.18105v1 by Jack Breen, Katie Allen, Kieran Zucker, Nicolas M. Orsi, Nishant Ravikumar

Computer vision models are increasingly capable of classifying ovarian
epithelial cancer subtypes, but they differ from pathologists by processing
small tissue patches at a single resolution. Multi-resolution graph models
leverage the spatial relationships of patches at multiple magnifications,
learning the context for each patch. In this study, we conduct the most
thorough validation of a graph model for ovarian cancer subtyping to date.
Seven models were tuned and trained using five-fold cross-validation on a set
of 1864 whole slide images (WSIs) from 434 patients treated at Leeds Teaching
Hospitals NHS Trust. The cross-validation models were ensembled and evaluated
using a balanced hold-out test set of 100 WSIs from 30 patients, and an
external validation set of 80 WSIs from 80 patients in the Transcanadian Study.
The best-performing model, a graph model using 10x+20x magnification data, gave
balanced accuracies of 73%, 88%, and 99% in cross-validation, hold-out testing,
and external validation, respectively. However, this only exceeded the
performance of attention-based multiple instance learning in external
validation, with a 93% balanced accuracy. Graph models benefitted greatly from
using the UNI foundation model rather than an ImageNet-pretrained ResNet50 for
feature extraction, with this having a much greater effect on performance than
changing the subsequent classification approach. The accuracy of the combined
foundation model and multi-resolution graph network offers a step towards the
clinical applicability of these models, with a new highest-reported performance
for this task, though further validations are still required to ensure the
robustness and usability of the models.

摘要：電腦視覺模型越來越能夠分類卵巢上皮癌的亞型，但它們與病理學家不同，它們以單一解析度處理小組織貼片。多解析度圖形模型利用多個放大倍率下貼片的空間關係，學習每個貼片的背景。在這項研究中，我們對圖形模型進行了迄今為止最徹底的卵巢癌亞型驗證。使用 434 名在利茲教學醫院 NHS 信託基金接受治療的患者的 1864 張全幻燈片影像 (WSI) 進行五倍交叉驗證，調整並訓練了七個模型。將交叉驗證模型集成並使用來自 30 名患者的 100 張 WSI 的平衡留出測試集和來自 Transcanadian 研究中 80 名患者的 80 張 WSI 的外部驗證集進行評估。表現最佳的模型，一個使用 10 倍+20 倍放大倍率資料的圖形模型，在交叉驗證、留出測試和外部驗證中分別給出 73%、88% 和 99% 的平衡準確度。然而，這僅超過了外部驗證中基於注意力的多實例學習的表現，平衡準確度為 93%。圖形模型從使用 UNI 基礎模型而不是 ImageNet 預訓練的 ResNet50 進行特徵提取中受益匪淺，與改變後續分類方法相比，這對效能有更大的影響。結合基礎模型和多解析度圖形網路的準確度為這些模型的臨床應用邁出了一步，對於這項任務來說，這是新的最高報告表現，儘管仍需要進一步的驗證來確保模型的穩健性和可用性。

##### **HG-PIPE: Vision Transformer Acceleration with Hybrid-Grained Pipeline**
2407.17879v1 by Qingyu Guo, Jiayong Wan, Songqiang Xu, Meng Li, Yuan Wang

Vision Transformer (ViT) acceleration with field programmable gate array
(FPGA) is promising but challenging. Existing FPGA-based ViT accelerators
mainly rely on temporal architectures, which process different operators by
reusing the same hardware blocks and suffer from extensive memory access
overhead. Pipelined architectures, either coarse-grained or fine-grained,
unroll the ViT computation spatially for memory access efficiency. However,
they usually suffer from significant hardware resource constraints and pipeline
bubbles induced by the global computation dependency of ViT. In this paper, we
introduce HG-PIPE, a pipelined FPGA accelerator for high-throughput and
low-latency ViT processing. HG-PIPE features a hybrid-grained pipeline
architecture to reduce on-chip buffer cost and couples the computation dataflow
and parallelism design to eliminate the pipeline bubbles. HG-PIPE further
introduces careful approximations to implement both linear and non-linear
operators with abundant Lookup Tables (LUTs), thus alleviating resource
constraints. On a ZCU102 FPGA, HG-PIPE achieves 2.78 times better throughput
and 2.52 times better resource efficiency than the prior-art accelerators,
e.g., AutoViTAcc. With a VCK190 FPGA, HG-PIPE realizes end-to-end ViT
acceleration on a single device and achieves 7118 images/s, which is 2.81 times
faster than a V100 GPU.

摘要：視覺轉換器 (ViT) 與現場可編程閘陣列 (FPGA) 的加速很有前景，但也充滿挑戰。現有的基於 FPGA 的 ViT 加速器主要依賴於暫態架構，它透過重複使用相同的硬體區塊來處理不同的運算子，並承受大量的記憶體存取開銷。管線架構（無論是粗粒度或細粒度）在空間上展開 ViT 計算以提高記憶體存取效率。然而，它們通常會受到顯著的硬體資源限制和由 ViT 的全局計算依賴性所引發的管線氣泡。在本文中，我們介紹了 HG-PIPE，這是一種用於高通量和低延遲 ViT 處理的管線式 FPGA 加速器。HG-PIPE 採用混合粒度管線架構來降低晶片緩衝成本，並結合計算資料流和並行設計以消除管線氣泡。HG-PIPE 進一步引入了仔細的近似值，以使用豐富的查找表 (LUT) 來實作線性和非線性運算子，從而減輕資源限制。在 ZCU102 FPGA 上，HG-PIPE 的吞吐量比先進的加速器（例如 AutoViTAcc）高出 2.78 倍，資源效率高出 2.52 倍。使用 VCK190 FPGA，HG-PIPE 在單一裝置上實現端到端的 ViT 加速，並達到每秒 7118 張影像，比 V100 GPU 快 2.81 倍。

##### **EEG-SSM: Leveraging State-Space Model for Dementia Detection**
2407.17801v1 by Xuan-The Tran, Linh Le, Quoc Toan Nguyen, Thomas Do, Chin-Teng Lin

State-space models (SSMs) have garnered attention for effectively processing
long data sequences, reducing the need to segment time series into shorter
intervals for model training and inference. Traditionally, SSMs capture only
the temporal dynamics of time series data, omitting the equally critical
spectral features. This study introduces EEG-SSM, a novel state-space
model-based approach for dementia classification using EEG data. Our model
features two primary innovations: EEG-SSM temporal and EEG-SSM spectral
components. The temporal component is designed to efficiently process EEG
sequences of varying lengths, while the spectral component enhances the model
by integrating frequency-domain information from EEG signals. The synergy of
these components allows EEG-SSM to adeptly manage the complexities of
multivariate EEG data, significantly improving accuracy and stability across
different temporal resolutions. Demonstrating a remarkable 91.0 percent
accuracy in classifying Healthy Control (HC), Frontotemporal Dementia (FTD),
and Alzheimer's Disease (AD) groups, EEG-SSM outperforms existing models on the
same dataset. The development of EEG-SSM represents an improvement in the use
of state-space models for screening dementia, offering more precise and
cost-effective tools for clinical neuroscience.

摘要：狀態空間模型 (SSM) 因有效處理長資料序列而備受關注，減少將時間序列區隔成較短區間以進行模型訓練和推論的需要。傳統上，SSM 只擷取時間序列資料的時間動態，省略同樣重要的頻譜特徵。本研究提出 EEG-SSM，一種新的基於狀態空間模型的方法，用於使用 EEG 資料進行失智症分類。我們的模型具有兩項主要的創新：EEG-SSM 時間和 EEG-SSM 頻譜組成部分。時間組成部分旨在有效率地處理長度不同的 EEG 序列，而頻譜組成部分透過整合 EEG 訊號的頻域資訊來增強模型。這些組成部分的協同作用讓 EEG-SSM 能靈活地管理多變量 EEG 資料的複雜性，大幅改善不同時間解析度下的準確性和穩定性。EEG-SSM 在分類健康對照組 (HC)、額顳葉型失智症 (FTD) 和阿茲海默症 (AD) 組別時展現出驚人的 91.0% 準確度，在相同的資料集上優於現有模型。EEG-SSM 的開發代表了使用狀態空間模型進行失智症篩檢的進步，為臨床神經科學提供更精確且更具成本效益的工具。

##### **Mpox Detection Advanced: Rapid Epidemic Response Through Synthetic Data**
2407.17762v1 by Yudara Kularathne, Prathapa Janitha, Sithira Ambepitiya, Prarththanan Sothyrajah, Thanveer Ahamed, Dinuka Wijesundara

Rapid development of disease detection models using computer vision is
crucial in responding to medical emergencies, such as epidemics or bioterrorism
events. Traditional data collection methods are often too slow in these
scenarios, requiring innovative approaches for quick, reliable model generation
from minimal data. Our study introduces a novel approach by constructing a
comprehensive computer vision model to detect Mpox lesions using only synthetic
data. Initially, these models generated a diverse set of synthetic images
representing Mpox lesions on various body parts (face, back, chest, leg, neck,
arm) across different skin tones as defined by the Fitzpatrick scale (fair,
brown, dark skin). Subsequently, we trained and tested a vision model with this
synthetic dataset to evaluate the diffusion models' efficacy in producing
high-quality training data and its impact on the vision model's medical image
recognition performance. The results were promising; the vision model achieved
a 97% accuracy rate, with 96% precision and recall for Mpox cases, and
similarly high metrics for normal and other skin disorder cases, demonstrating
its ability to correctly identify true positives and minimize false positives.
The model achieved an F1-Score of 96% for Mpox cases and 98% for normal and
other skin disorders, reflecting a balanced precision-recall relationship, thus
ensuring reliability and robustness in its predictions. Our proposed
SynthVision methodology indicates the potential to develop accurate computer
vision models with minimal data input for future medical emergencies.

摘要：<paragraph>利用電腦視覺快速開發疾病檢測模型對於因應醫療緊急事件（例如流行病或生物恐怖主義事件）至關重要。傳統的資料收集方法在這些情況下通常太慢，需要創新的方法才能從最少資料中快速、可靠地產生模型。我們的研究介紹了一種新穎的方法，透過建構一個全面的電腦視覺模型，僅使用合成資料來檢測猴痘病灶。最初，這些模型產生了一組多樣化的合成影像，代表了不同膚色（根據 Fitzpatrick 量表定義為白皙、棕色、深色皮膚）上不同身體部位（臉部、背部、胸部、腿部、頸部、手臂）的猴痘病灶。隨後，我們使用這個合成資料集訓練和測試一個視覺模型，以評估擴散模型產生高品質訓練資料的效能，以及其對視覺模型醫學影像辨識效能的影響。結果令人滿意；視覺模型達到了 97% 的準確率，猴痘病例的準確度和召回率為 96%，正常和其它皮膚疾病病例的指標也同樣高，證明了它正確辨識真陽性並將假陽性降至最低的能力。該模型在猴痘病例中達到了 96% 的 F1 分數，在正常和其它皮膚疾病中達到了 98%，反映出平衡的準確度召回率關係，從而確保其預測的可靠性和穩健性。我們提出的 SynthVision 方法表明，有可能為未來的醫療緊急事件開發出準確的電腦視覺模型，且資料輸入量最少。</paragraph>

##### **Cost-effective Instruction Learning for Pathology Vision and Language Analysis**
2407.17734v1 by Kaitao Chen, Mianxin Liu, Fang Yan, Lei Ma, Xiaoming Shi, Lilong Wang, Xiaosong Wang, Lifeng Zhu, Zhe Wang, Mu Zhou, Shaoting Zhang

The advent of vision-language models fosters the interactive conversations
between AI-enabled models and humans. Yet applying these models into clinics
must deal with daunting challenges around large-scale training data, financial,
and computational resources. Here we propose a cost-effective instruction
learning framework for conversational pathology named as CLOVER. CLOVER only
trains a lightweight module and uses instruction tuning while freezing the
parameters of the large language model. Instead of using costly GPT-4, we
propose well-designed prompts on GPT-3.5 for building generation-based
instructions, emphasizing the utility of pathological knowledge derived from
the Internet source. To augment the use of instructions, we construct a
high-quality set of template-based instructions in the context of digital
pathology. From two benchmark datasets, our findings reveal the strength of
hybrid-form instructions in the visual question-answer in pathology. Extensive
results show the cost-effectiveness of CLOVER in answering both open-ended and
closed-ended questions, where CLOVER outperforms strong baselines that possess
37 times more training parameters and use instruction data generated from
GPT-4. Through the instruction tuning, CLOVER exhibits robustness of few-shot
learning in the external clinical dataset. These findings demonstrate that
cost-effective modeling of CLOVER could accelerate the adoption of rapid
conversational applications in the landscape of digital pathology.

摘要：視覺語言模型的出現促進了 AI 啟用模型與人類之間的互動對話。然而，將這些模型應用於臨床必須應對大規模訓練數據、財務和計算資源等嚴峻挑戰。在此，我們提出了一個名為 CLOVER 的經濟高效的會話病理學指令學習架構。CLOVER 僅訓練一個輕量級模組，並在凍結大型語言模型參數的同時使用指令微調。我們沒有使用昂貴的 GPT-4，而是針對 GPT-3.5 提出設計良好的提示，以建立基於生成的指令，強調從網際網路來源衍生的病理知識的效用。為了擴展指令的使用，我們在數位病理學的背景下構建了一組高品質的基於範本的指令。從兩個基準資料集，我們的研究結果揭示了混合形式指令在病理學視覺問答中的優勢。廣泛的結果顯示了 CLOVER 在回答開放式和封閉式問題方面的經濟效益，其中 CLOVER 優於擁有多 37 倍訓練參數並使用從 GPT-4 生成的指令資料的強大基準。透過指令微調，CLOVER 在外部臨床資料集中展現了小樣本學習的穩健性。這些發現證明了 CLOVER 的經濟高效建模可以加速在數位病理領域採用快速對話式應用程式。

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

摘要：失智症是一種影響全球數百萬人的衰弱性神經疾病，在診斷上具有重大挑戰。在這項工作中，我們提出了一種新的方法，用於對失智和非失智老年患者進行分類，使用 3D 大腦磁振造影 (MRI) 掃描。我們的做法採用了一種獨特技術，用於選擇性處理 MRI 切片，重點關注最相關的大腦區域，並排除信息量較少的部分。這種方法由一個基於信心的分類委員會補充，該委員會由三個自定義深度學習模型組成：Dem3D ResNet、Dem3D CNN 和 Dem3D EfficientNet。這些模型協同工作以增強決策的準確性，利用它們的集體優勢。在影像研究開放存取系列 (OASIS) 資料集上進行測試，我們的模型達到了 94.12% 的驚人準確度，超過了現有方法。此外，在阿茲海默症神經影像倡議 (ADNI) 資料集上的驗證證實了我們方法的穩健性和普遍性。可解釋 AI (XAI) 技術和全面的消融研究進一步證實了我們技術的有效性，提供了對決策過程和我們方法重要性的見解。這項研究為失智症診斷提供了重大進展，為臨床應用提供了一個高度準確且高效的工具。

##### **Improving ICD coding using Chapter based Named Entities and Attentional Models**
2407.17230v1 by Abhijith R. Beeravolu, Mirjam Jonkman, Sami Azam, Friso De Boer

Recent advancements in natural language processing (NLP) have led to
automation in various domains. However, clinical NLP often relies on benchmark
datasets that may not reflect real-world scenarios accurately. Automatic ICD
coding, a vital NLP task, typically uses outdated and imbalanced datasets like
MIMIC-III, with existing methods yielding micro-averaged F1 scores between 0.4
and 0.7 due to many false positives. Our research introduces an enhanced
approach to ICD coding that improves F1 scores by using chapter-based named
entities and attentional models. This method categorizes discharge summaries
into ICD-9 Chapters and develops attentional models with chapter-specific data,
eliminating the need to consider external data for code identification. For
categorization, we use Chapter-IV to de-bias and influence key entities and
weights without neural networks, creating accurate thresholds and providing
interpretability for human validation. Post-validation, we develop attentional
models for three frequent and three non-frequent codes from Chapter-IV using
Bidirectional-Gated Recurrent Units (GRUs) with Attention and Transformer with
Multi-head Attention architectures. The average Micro-F1 scores of 0.79 and
0.81 from these models demonstrate significant performance improvements in ICD
coding.

摘要：自然語言處理 (NLP) 的最新進展已導致各種領域的自動化。然而，臨床 NLP 通常依賴於基準資料集，這些資料集可能無法準確反映真實世界的場景。自動 ICD 編碼是一項重要的 NLP 任務，通常使用過時且不平衡的資料集，例如 MIMIC-III，由於許多假陽性，現有方法產生的微平均 F1 分數介於 0.4 和 0.7 之間。我們的研究引入了一種增強的 ICD 編碼方法，通過使用基於章節的命名實體和注意力模型來提高 F1 分數。此方法將出院摘要分類為 ICD-9 章節，並使用章節特定資料開發注意力模型，消除了考慮外部資料以進行代碼識別的需要。對於分類，我們使用 Chapter-IV 來消除偏差並影響關鍵實體和權重，而無需神經網路，從而建立準確的閾值並提供人類驗證的可解釋性。在驗證之後，我們使用帶有注意力和多頭注意架構的雙向門控遞迴單元 (GRU) 和 Transformer，為 Chapter-IV 中的三個頻繁和三個非頻繁代碼開發注意力模型。這些模型的平均微 F1 分數為 0.79 和 0.81，表明 ICD 編碼的效能有了顯著的提升。

##### **Robust Deep Hawkes Process under Label Noise of Both Event and Occurrence**
2407.17164v1 by Xiaoyu Tan, Bin Li, Xihe Qiu, Jingjing Huang, Yinghui Xu, Wei Chu

Integrating deep neural networks with the Hawkes process has significantly
improved predictive capabilities in finance, health informatics, and
information technology. Nevertheless, these models often face challenges in
real-world settings, particularly due to substantial label noise. This issue is
of significant concern in the medical field, where label noise can arise from
delayed updates in electronic medical records or misdiagnoses, leading to
increased prediction risks. Our research indicates that deep Hawkes process
models exhibit reduced robustness when dealing with label noise, particularly
when it affects both event types and timing. To address these challenges, we
first investigate the influence of label noise in approximated intensity
functions and present a novel framework, the Robust Deep Hawkes Process (RDHP),
to overcome the impact of label noise on the intensity function of Hawkes
models, considering both the events and their occurrences. We tested RDHP using
multiple open-source benchmarks with synthetic noise and conducted a case study
on obstructive sleep apnea-hypopnea syndrome (OSAHS) in a real-world setting
with inherent label noise. The results demonstrate that RDHP can effectively
perform classification and regression tasks, even in the presence of noise
related to events and their timing. To the best of our knowledge, this is the
first study to successfully address both event and time label noise in deep
Hawkes process models, offering a promising solution for medical applications,
specifically in diagnosing OSAHS.

摘要：將深度神經網路與霍克斯過程整合，大幅提升了金融、健康資訊學和資訊科技的預測能力。然而，這些模型在現實世界中經常面臨挑戰，特別是因為標籤雜訊過大。這個問題在醫療領域特別令人擔憂，因為標籤雜訊可能來自電子病歷的更新延誤或誤診，導致預測風險增加。我們的研究表明，深度霍克斯過程模型在處理標籤雜訊時表現出較低的穩健性，特別是在標籤雜訊同時影響事件類型和時間點時。為了應對這些挑戰，我們首先研究標籤雜訊對近似強度函數的影響，並提出了一個新的框架，即穩健深度霍克斯過程 (RDHP)，以克服標籤雜訊對霍克斯模型強度函數的影響，同時考慮事件及其發生。我們使用多個具有合成雜訊的開源基準測試 RDHP，並對現實世界中具有內在標籤雜訊的阻塞性睡眠呼吸中止低通氣綜合症 (OSAHS) 進行案例研究。結果表明，即使在存在與事件及其時間點相關的雜訊的情況下，RDHP 仍能有效執行分類和回歸任務。據我們所知，這是第一個成功解決深度霍克斯過程模型中事件和時間標籤雜訊的研究，為醫療應用（特別是診斷 OSAHS）提供了一個有前景的解決方案。

##### **SDoH-GPT: Using Large Language Models to Extract Social Determinants of Health (SDoH)**
2407.17126v1 by Bernardo Consoli, Xizhi Wu, Song Wang, Xinyu Zhao, Yanshan Wang, Justin Rousseau, Tom Hartvigsen, Li Shen, Huanmei Wu, Yifan Peng, Qi Long, Tianlong Chen, Ying Ding

Extracting social determinants of health (SDoH) from unstructured medical
notes depends heavily on labor-intensive annotations, which are typically
task-specific, hampering reusability and limiting sharing. In this study we
introduced SDoH-GPT, a simple and effective few-shot Large Language Model (LLM)
method leveraging contrastive examples and concise instructions to extract SDoH
without relying on extensive medical annotations or costly human intervention.
It achieved tenfold and twentyfold reductions in time and cost respectively,
and superior consistency with human annotators measured by Cohen's kappa of up
to 0.92. The innovative combination of SDoH-GPT and XGBoost leverages the
strengths of both, ensuring high accuracy and computational efficiency while
consistently maintaining 0.90+ AUROC scores. Testing across three distinct
datasets has confirmed its robustness and accuracy. This study highlights the
potential of leveraging LLMs to revolutionize medical note classification,
demonstrating their capability to achieve highly accurate classifications with
significantly reduced time and cost.

摘要：從非結構化的醫療筆記中萃取健康的社會決定因素 (SDoH) 仰賴大量的人工標註，而這些標註通常是針對特定任務，這會阻礙可重複使用性並限制分享。在這項研究中，我們引入了 SDoH-GPT，一種簡單且有效的方法，它利用對比範例和簡潔的指示來萃取 SDoH，而不需要仰賴大量的醫療標註或昂貴的人工介入。它分別在時間和成本上達到了十倍和二十倍的降低，並且與人類標註者的優異一致性，由 Cohen's kappa 測量高達 0.92。SDoH-GPT 和 XGBoost 的創新結合利用了兩者的優點，確保了高準確度和運算效率，同時始終維持 0.90+ 的 AUROC 分數。在三個不同的資料集上進行測試已經確認了它的穩健性和準確性。這項研究突顯了利用 LLM 來革新醫療筆記分類的潛力，展示了它們在顯著減少時間和成本的情況下實現高度準確分類的能力。

##### **SepsisLab: Early Sepsis Prediction with Uncertainty Quantification and Active Sensing**
2407.16999v1 by Changchang Yin, Pin-Yu Chen, Bingsheng Yao, Dakuo Wang, Jeffrey Caterino, Ping Zhang

Sepsis is the leading cause of in-hospital mortality in the USA. Early sepsis
onset prediction and diagnosis could significantly improve the survival of
sepsis patients. Existing predictive models are usually trained on high-quality
data with few missing information, while missing values widely exist in
real-world clinical scenarios (especially in the first hours of admissions to
the hospital), which causes a significant decrease in accuracy and an increase
in uncertainty for the predictive models. The common method to handle missing
values is imputation, which replaces the unavailable variables with estimates
from the observed data. The uncertainty of imputation results can be propagated
to the sepsis prediction outputs, which have not been studied in existing works
on either sepsis prediction or uncertainty quantification. In this study, we
first define such propagated uncertainty as the variance of prediction output
and then introduce uncertainty propagation methods to quantify the propagated
uncertainty. Moreover, for the potential high-risk patients with low confidence
due to limited observations, we propose a robust active sensing algorithm to
increase confidence by actively recommending clinicians to observe the most
informative variables. We validate the proposed models in both publicly
available data (i.e., MIMIC-III and AmsterdamUMCdb) and proprietary data in The
Ohio State University Wexner Medical Center (OSUWMC). The experimental results
show that the propagated uncertainty is dominant at the beginning of admissions
to hospitals and the proposed algorithm outperforms state-of-the-art active
sensing methods. Finally, we implement a SepsisLab system for early sepsis
prediction and active sensing based on our pre-trained models. Clinicians and
potential sepsis patients can benefit from the system in early prediction and
diagnosis of sepsis.

摘要：敗血症是美國醫院中死亡的主要原因。敗血症的早期發作預測和診斷可以顯著提高敗血症患者的存活率。現有的預測模型通常在資料品質高且遺失資訊較少的情況下進行訓練，而遺失值在實際臨床情境中普遍存在（尤其是在入院的前幾個小時），這會導致預測模型的準確度顯著下降，並增加不確定性。處理遺失值的常見方法是內插，它使用從觀測資料中估計的數值取代不可用的變數。內插結果的不確定性可能會傳播到敗血症預測輸出，這在現有的敗血症預測或不確定性量化研究中尚未被探討。在這項研究中，我們首先將這種傳播的不確定性定義為預測輸出的變異，然後引入不確定性傳播方法來量化傳播的不確定性。此外，對於由於觀察有限而導致信心較低的潛在高風險患者，我們提出了一種強大的主動感測演算法，透過主動建議臨床醫生觀察最有資訊性的變數來增加信心。我們在公開資料（例如 MIMIC-III 和 AmsterdamUMCdb）和俄亥俄州立大學韋克斯納醫學中心 (OSUWMC) 的專有資料中驗證了所提出的模型。實驗結果表明，傳播的不確定性在入院初期佔主導地位，而所提出的演算法優於最先進的主動感測方法。最後，我們根據預先訓練的模型實作了一個敗血症實驗室系統，用於早期敗血症預測和主動感測。臨床醫生和潛在的敗血症患者可以在敗血症的早期預測和診斷中受益於該系統。

##### **Toward an Integrated Decision Making Framework for Optimized Stroke Diagnosis with DSA and Treatment under Uncertainty**
2407.16962v1 by Nur Ahmad Khatim, Ahmad Azmul Asmar Irfan, Amaliya Mata'ul Hayah, Mansur M. Arief

This study addresses the challenge of stroke diagnosis and treatment under
uncertainty, a critical issue given the rapid progression and severe
consequences of stroke conditions such as aneurysms, arteriovenous
malformations (AVM), and occlusions. Current diagnostic methods, including
Digital Subtraction Angiography (DSA), face limitations due to high costs and
its invasive nature. To overcome these challenges, we propose a novel approach
using a Partially Observable Markov Decision Process (POMDP) framework. Our
model integrates advanced diagnostic tools and treatment approaches with a
decision-making algorithm that accounts for the inherent uncertainties in
stroke diagnosis. Our approach combines noisy observations from CT scans,
Siriraj scores, and DSA reports to inform the subsequent treatment options. We
utilize the online solver DESPOT, which employs tree-search methods and
particle filters, to simulate potential future scenarios and guide our
strategies. The results indicate that our POMDP framework balances diagnostic
and treatment objectives, striking a tradeoff between the need for precise
stroke identification via invasive procedures like DSA and the constraints of
limited healthcare resources that necessitate more cost-effective strategies,
such as in-hospital or at-home observation, by relying only relying on
simulation rollouts and not imposing any prior knowledge. Our study offers a
significant contribution by presenting a systematic framework that optimally
integrates diagnostic and treatment processes for stroke and accounting for
various uncertainties, thereby improving care and outcomes in stroke
management.

摘要：本研究探討在不確定性下中風的診斷和治療的挑戰，這是考量到中風狀況（例如動脈瘤、動靜脈畸形 (AVM) 和阻塞）的快速進展和嚴重後果而出現的關鍵問題。目前的診斷方法（包括數位減影血管攝影 (DSA)）由於成本高昂和侵入性而面臨限制。為了克服這些挑戰，我們提出了一種使用部分可觀察馬可夫決策過程 (POMDP) 架構的新穎方法。我們的模型整合了先進的診斷工具和治療方法，以及一個決策演算法，該演算法考量了中風診斷中固有的不確定性。我們的做法結合了來自電腦斷層掃描、Siriraj 評分和 DSA 報告的雜訊觀測值，以告知後續的治療選項。我們利用線上求解器 DESPOT，它採用樹狀搜尋方法和粒子濾波器，模擬潛在的未來情境並指導我們的策略。結果表明，我們的 POMDP 架構平衡了診斷和治療目標，在透過 DSA 等侵入性程序精確識別中風的需求與需要更具成本效益的策略（例如住院或居家觀察）的醫療資源限制之間取得平衡，僅依賴模擬推出且不施加任何先驗知識。我們的研究透過提出一個系統性架構，最佳化整合中風的診斷和治療過程並考量各種不確定性，從而改善中風管理的照護和結果，做出了重大貢獻。

##### **AI-Enhanced 7-Point Checklist for Melanoma Detection Using Clinical Knowledge Graphs and Data-Driven Quantification**
2407.16822v1 by Yuheng Wang, Tianze Yu, Jiayue Cai, Sunil Kalia, Harvey Lui, Z. Jane Wang, Tim K. Lee

The 7-point checklist (7PCL) is widely used in dermoscopy to identify
malignant melanoma lesions needing urgent medical attention. It assigns point
values to seven attributes: major attributes are worth two points each, and
minor ones are worth one point each. A total score of three or higher prompts
further evaluation, often including a biopsy. However, a significant limitation
of current methods is the uniform weighting of attributes, which leads to
imprecision and neglects their interconnections. Previous deep learning studies
have treated the prediction of each attribute with the same importance as
predicting melanoma, which fails to recognize the clinical significance of the
attributes for melanoma. To address these limitations, we introduce a novel
diagnostic method that integrates two innovative elements: a Clinical
Knowledge-Based Topological Graph (CKTG) and a Gradient Diagnostic Strategy
with Data-Driven Weighting Standards (GD-DDW). The CKTG integrates 7PCL
attributes with diagnostic information, revealing both internal and external
associations. By employing adaptive receptive domains and weighted edges, we
establish connections among melanoma's relevant features. Concurrently, GD-DDW
emulates dermatologists' diagnostic processes, who first observe the visual
characteristics associated with melanoma and then make predictions. Our model
uses two imaging modalities for the same lesion, ensuring comprehensive feature
acquisition. Our method shows outstanding performance in predicting malignant
melanoma and its features, achieving an average AUC value of 85%. This was
validated on the EDRA dataset, the largest publicly available dataset for the
7-point checklist algorithm. Specifically, the integrated weighting system can
provide clinicians with valuable data-driven benchmarks for their evaluations.

摘要：7 點檢查表 (7PCL) 廣泛用於皮膚鏡檢查，以識別需要緊急醫療照護的惡性黑色素瘤病灶。它為七個屬性分配分數：主要屬性各值兩分，次要屬性各值一分。總分為三或以上表示需要進一步評估，通常包括活檢。然而，目前方法的一個重大限制是屬性的統一加權，導致不精確且忽略它們之間的相互關聯。先前的深度學習研究將每個屬性的預測視為與預測黑色素瘤同等重要，這未能認識到屬性對黑色素瘤的臨床意義。為了解決這些限制，我們引入一種新的診斷方法，結合了兩個創新元素：基於臨床知識的拓撲圖 (CKTG) 和具有數據驅動加權標準的梯度診斷策略 (GD-DDW)。CKTG 將 7PCL 屬性與診斷信息整合在一起，揭示了內部和外部關聯。通過採用自適應感受域和加權邊緣，我們建立了黑色素瘤相關特徵之間的聯繫。同時，GD-DDW 模仿皮膚科醫生的診斷過程，他們首先觀察與黑色素瘤相關的視覺特徵，然後做出預測。我們的模型對同一個病灶使用兩種成像方式，確保全面獲取特徵。我們的這種方法在預測惡性黑色素瘤及其特徵方面表現出色，平均 AUC 值達到 85%。這已在 EDRA 數據集上得到驗證，該數據集是 7 點檢查表算法最大的公開可用數據集。具體來說，集成的加權系統可以為臨床醫生提供有價值的數據驅動基準，供他們評估。

##### **Multimodal Machine Learning in Mental Health: A Survey of Data, Algorithms, and Challenges**
2407.16804v1 by Zahraa Al Sahili, Ioannis Patras, Matthew Purver

The application of machine learning (ML) in detecting, diagnosing, and
treating mental health disorders is garnering increasing attention.
Traditionally, research has focused on single modalities, such as text from
clinical notes, audio from speech samples, or video of interaction patterns.
Recently, multimodal ML, which combines information from multiple modalities,
has demonstrated significant promise in offering novel insights into human
behavior patterns and recognizing mental health symptoms and risk factors.
Despite its potential, multimodal ML in mental health remains an emerging
field, facing several complex challenges before practical applications can be
effectively developed. This survey provides a comprehensive overview of the
data availability and current state-of-the-art multimodal ML applications for
mental health. It discusses key challenges that must be addressed to advance
the field. The insights from this survey aim to deepen the understanding of the
potential and limitations of multimodal ML in mental health, guiding future
research and development in this evolving domain.

摘要：機器學習（ML）在偵測、診斷和治療心理健康疾病中的應用正越來越受到重視。傳統上，研究著重於單一模式，例如臨床筆記中的文字、語音樣本中的音訊或互動模式的影片。最近，結合多模式資訊的多模態 ML 已展現出顯著的潛力，可提供對人類行為模式的新見解，並識別心理健康症狀和風險因子。儘管具有潛力，心理健康中的多模態 ML 仍是一個新興領域，在實際應用可以有效開發之前，面臨數項複雜挑戰。本調查提供了心理健康中資料可用性和當前最先進的多模態 ML 應用之全面概觀。它討論了必須解決的關鍵挑戰，以推動該領域的進步。本調查的見解旨在加深對多模態 ML 在心理健康中的潛力和限制的理解，引導這個不斷演變領域未來的研究和發展。

##### **Deep Bayesian segmentation for colon polyps: Well-calibrated predictions in medical imaging**
2407.16608v1 by Daniela L. Ramos, Hector J. Hortua

Colorectal polyps are generally benign alterations that, if not identified
promptly and managed successfully, can progress to cancer and cause
affectations on the colon mucosa, known as adenocarcinoma. Today advances in
Deep Learning have demonstrated the ability to achieve significant performance
in image classification and detection in medical diagnosis applications.
Nevertheless, these models are prone to overfitting, and making decisions based
only on point estimations may provide incorrect predictions. Thus, to obtain a
more informed decision, we must consider point estimations along with their
reliable uncertainty quantification. In this paper, we built different Bayesian
neural network approaches based on the flexibility of posterior distribution to
develop semantic segmentation of colorectal polyp images. We found that these
models not only provide state-of-the-art performance on the segmentation of
this medical dataset but also, yield accurate uncertainty estimates. We applied
multiplicative normalized flows(MNF) and reparameterization trick on the UNET,
FPN, and LINKNET architectures tested with multiple backbones in deterministic
and Bayesian versions. We report that the FPN + EfficientnetB7 architecture
with MNF is the most promising option given its IOU of 0.94 and Expected
Calibration Error (ECE) of 0.004, combined with its superiority in identifying
difficult-to-detect colorectal polyps, which is effective in clinical areas
where early detection prevents the development of colon cancer.

摘要：大腸息肉通常是良性病變，如果不及時發現並成功處理，可能會演變成癌症並導致大腸粘膜受累，即腺癌。如今，深度學習的進展已證明有能力在醫療診斷應用中實現圖像分類和檢測的顯著性能。儘管如此，這些模型容易過度擬合，並且僅基於點估計做出決策可能會提供不正確的預測。因此，為了獲得更明智的決策，我們必須考慮點估計及其可靠的不確定性量化。在本文中，我們基於後驗分佈的靈活性構建了不同的貝葉斯神經網絡方法，以開發大腸息肉圖像的語義分割。我們發現這些模型不僅在這個醫療數據集的分割上提供了最先進的性能，而且還產生了準確的不確定性估計。我們在確定性和貝葉斯版本中使用多個主幹測試的 UNET、FPN 和 LINKNET 架構上應用乘法歸一化流 (MNF) 和重新參數化技巧。我們報告說，具有 MNF 的 FPN + EfficientnetB7 架構是最有希望的選擇，因為它的 IOU 為 0.94，預期的校準誤差 (ECE) 為 0.004，並且在識別難以檢測的大腸息肉方面具有優越性，這在早期檢測可以防止結腸癌發展的臨床領域是有效的。

##### **A Comparative Study on Patient Language across Therapeutic Domains for Effective Patient Voice Classification in Online Health Discussions**
2407.16593v1 by Giorgos Lysandrou, Roma English Owen, Vanja Popovic, Grant Le Brun, Aryo Pradipta Gema, Beatrice Alex, Elizabeth A. L. Fairley

There exists an invisible barrier between healthcare professionals'
perception of a patient's clinical experience and the reality. This barrier may
be induced by the environment that hinders patients from sharing their
experiences openly with healthcare professionals. As patients are observed to
discuss and exchange knowledge more candidly on social media, valuable insights
can be leveraged from these platforms. However, the abundance of non-patient
posts on social media necessitates filtering out such irrelevant content to
distinguish the genuine voices of patients, a task we refer to as patient voice
classification. In this study, we analyse the importance of linguistic
characteristics in accurately classifying patient voices. Our findings
underscore the essential role of linguistic and statistical text similarity
analysis in identifying common patterns among patient groups. These results
allude to even starker differences in the way patients express themselves at a
disease level and across various therapeutic domains. Additionally, we
fine-tuned a pre-trained Language Model on the combined datasets with similar
linguistic patterns, resulting in a highly accurate automatic patient voice
classification. Being the pioneering study on the topic, our focus on
extracting authentic patient experiences from social media stands as a crucial
step towards advancing healthcare standards and fostering a patient-centric
approach.

摘要：醫療保健專業人員對於患者臨床經驗的認知與實際情況之間存在著一道無形的障礙。此障礙可能是由環境所造成，阻礙患者與醫療保健專業人員公開分享他們的經驗。由於觀察到患者在社群媒體上更坦率地討論和交換知識，因此可以從這些平台獲得有價值的見解。然而，社群媒體上充斥著非患者貼文，因此有必要過濾掉這些不相關的內容，以區分患者的真實聲音，我們將此任務稱為患者聲音分類。在本研究中，我們分析了語言特徵在準確分類患者聲音中的重要性。我們的研究結果強調了語言和統計文字相似性分析在識別患者群組之間共同模式中的重要角色。這些結果暗示了患者在疾病層級和各種治療領域中表達自己的方式存在著更明顯的差異。此外，我們根據具有類似語言模式的合併資料集微調了預先訓練好的語言模型，進而產生高度準確的自動患者聲音分類。作為這項主題的開創性研究，我們專注於從社群媒體中提取真實的患者經驗，這是邁向提升醫療保健標準和培養以患者為中心的途徑的關鍵一步。

##### **Virtue Ethics For Ethically Tunable Robotic Assistants**
2407.16361v1 by Rajitha Ramanayake, Vivek Nallur

The common consensus is that robots designed to work alongside or serve
humans must adhere to the ethical standards of their operational environment.
To achieve this, several methods based on established ethical theories have
been suggested. Nonetheless, numerous empirical studies show that the ethical
requirements of the real world are very diverse and can change rapidly from
region to region. This eliminates the idea of a universal robot that can fit
into any ethical context. However, creating customised robots for each
deployment, using existing techniques is challenging. This paper presents a way
to overcome this challenge by introducing a virtue ethics inspired
computational method that enables character-based tuning of robots to
accommodate the specific ethical needs of an environment. Using a simulated
elder-care environment, we illustrate how tuning can be used to change the
behaviour of a robot that interacts with an elderly resident in an
ambient-assisted environment. Further, we assess the robot's responses by
consulting ethicists to identify potential shortcomings.

摘要：一般共識是，設計用於與人類並肩工作或服務人類的機器人必須遵守其運作環境的道德標準。為達成此目的，已提出幾種基於既定倫理理論的方法。儘管如此，許多實證研究顯示，現實世界的道德要求非常多元，且可能因地區而異而快速改變。這消除了通用機器人的概念，而通用機器人可以融入任何道德脈絡。然而，使用現有技術為每個部署建立客製化機器人具有挑戰性。本文提出了一種克服此挑戰的方法，方法是引入一種美德倫理啟發的運算方法，使機器人能夠基於特質進行調整，以適應環境的特定道德需求。使用模擬的長者照護環境，我們說明如何使用調整來改變機器人在環境輔助環境中與年長住民互動的行為。此外，我們諮詢倫理學家來評估機器人的反應，以找出潛在的缺點。

##### **PhenoFlow: A Human-LLM Driven Visual Analytics System for Exploring Large and Complex Stroke Datasets**
2407.16329v1 by Jaeyoung Kim, Sihyeon Lee, Hyeon Jeon, Keon-Joo Lee, Hee-Joon Bae, Bohyoung Kim, Jinwook Seo

Acute stroke demands prompt diagnosis and treatment to achieve optimal
patient outcomes. However, the intricate and irregular nature of clinical data
associated with acute stroke, particularly blood pressure (BP) measurements,
presents substantial obstacles to effective visual analytics and
decision-making. Through a year-long collaboration with experienced
neurologists, we developed PhenoFlow, a visual analytics system that leverages
the collaboration between human and Large Language Models (LLMs) to analyze the
extensive and complex data of acute ischemic stroke patients. PhenoFlow
pioneers an innovative workflow, where the LLM serves as a data wrangler while
neurologists explore and supervise the output using visualizations and natural
language interactions. This approach enables neurologists to focus more on
decision-making with reduced cognitive load. To protect sensitive patient
information, PhenoFlow only utilizes metadata to make inferences and synthesize
executable codes, without accessing raw patient data. This ensures that the
results are both reproducible and interpretable while maintaining patient
privacy. The system incorporates a slice-and-wrap design that employs temporal
folding to create an overlaid circular visualization. Combined with a linear
bar graph, this design aids in exploring meaningful patterns within irregularly
measured BP data. Through case studies, PhenoFlow has demonstrated its
capability to support iterative analysis of extensive clinical datasets,
reducing cognitive load and enabling neurologists to make well-informed
decisions. Grounded in long-term collaboration with domain experts, our
research demonstrates the potential of utilizing LLMs to tackle current
challenges in data-driven clinical decision-making for acute ischemic stroke
patients.

摘要：<paragraph>急性中風需要迅速診斷和治療，才能達到最佳的病人治療結果。然而，與急性中風相關的臨床資料複雜且不規則，特別是血壓 (BP) 測量，對有效的視覺分析和決策制定構成重大障礙。透過與經驗豐富的神經科醫師長達一年的合作，我們開發了 PhenoFlow，這是一個視覺分析系統，利用人與大型語言模型 (LLM) 之間的協作來分析急性缺血性中風患者的廣泛且複雜資料。PhenoFlow 開創了一種創新的工作流程，其中 LLM 擔任資料整理員，而神經科醫師則使用視覺化和自然語言互動來探索和監督輸出。這種方法使神經科醫師能夠更專注於決策制定，同時降低認知負擔。為了保護敏感的病人資訊，PhenoFlow 僅利用元資料進行推論並合成可執行程式碼，而不會存取原始病人資料。這確保了結果既可重現又可解釋，同時維護病人的隱私。該系統採用分段和包裝設計，採用時間摺疊來建立疊加的圓形視覺化。結合線性長條圖，此設計有助於探索不規則測量血壓資料中的有意義模式。透過案例研究，PhenoFlow 已證明其支援對廣泛臨床資料集進行反覆分析的能力，降低認知負擔並使神經科醫師能夠做出明智的決策。我們的研究以與領域專家長期合作為基礎，證明了利用 LLM 來應對當前急性缺血性中風患者資料驅動臨床決策制定挑戰的潛力。</paragraph>

##### **Research on Adverse Drug Reaction Prediction Model Combining Knowledge Graph Embedding and Deep Learning**
2407.16715v1 by Yufeng Li, Wenchao Zhao, Bo Dang, Xu Yan, Weimin Wang, Min Gao, Mingxuan Xiao

In clinical treatment, identifying potential adverse reactions of drugs can
help assist doctors in making medication decisions. In response to the problems
in previous studies that features are high-dimensional and sparse, independent
prediction models need to be constructed for each adverse reaction of drugs,
and the prediction accuracy is low, this paper develops an adverse drug
reaction prediction model based on knowledge graph embedding and deep learning,
which can predict experimental results. Unified prediction of adverse drug
reactions covered. Knowledge graph embedding technology can fuse the associated
information between drugs and alleviate the shortcomings of high-dimensional
sparsity in feature matrices, and the efficient training capabilities of deep
learning can improve the prediction accuracy of the model. This article builds
an adverse drug reaction knowledge graph based on drug feature data; by
analyzing the embedding effect of the knowledge graph under different embedding
strategies, the best embedding strategy is selected to obtain sample vectors;
and then a convolutional neural network model is constructed to predict adverse
reactions. The results show that under the DistMult embedding model and
400-dimensional embedding strategy, the convolutional neural network model has
the best prediction effect; the average accuracy, F_1 score, recall rate and
area under the curve of repeated experiments are better than the methods
reported in the literature. The obtained prediction model has good prediction
accuracy and stability, and can provide an effective reference for later safe
medication guidance.

摘要：在臨床治療中，識別藥物的潛在不良反應有助於協助醫生做出用藥決策。針對以往研究中特徵高維稀疏、需要為每種藥物的不同不良反應建構獨立預測模型、且預測準確率低的問題，本文開發基於知識圖譜嵌入與深度學習的不良藥物反應預測模型，可預測實驗結果。涵蓋不良藥物反應的統一預測。知識圖譜嵌入技術能融合藥物間的關聯資訊，緩解特徵矩陣高維稀疏的缺點，而深度學習的強大訓練能力能提升模型預測準確率。本文建構基於藥物特徵資料的不良藥物反應知識圖譜；透過分析知識圖譜在不同嵌入策略下的嵌入效果，選取最佳嵌入策略獲得樣本向量；再建構卷積神經網路模型預測不良反應。結果顯示，在 DistMult 嵌入模型與 400 維嵌入策略下，卷積神經網路模型有最佳預測效果；重複實驗的平均準確率、F_1 值、召回率與曲線下面積均優於文獻所報導的方法。所獲得的預測模型具備良好的預測準確率與穩定性，可為後續安全用藥指導提供有效的參考依據。

##### **Artificial Intelligence-based Decision Support Systems for Precision and Digital Health**
2407.16062v1 by Nina Deliu, Bibhas Chakraborty

Precision health, increasingly supported by digital technologies, is a domain
of research that broadens the paradigm of precision medicine, advancing
everyday healthcare. This vision goes hand in hand with the groundbreaking
advent of artificial intelligence (AI), which is reshaping the way we diagnose,
treat, and monitor both clinical subjects and the general population. AI tools
powered by machine learning have shown considerable improvements in a variety
of healthcare domains. In particular, reinforcement learning (RL) holds great
promise for sequential and dynamic problems such as dynamic treatment regimes
and just-in-time adaptive interventions in digital health. In this work, we
discuss the opportunity offered by AI, more specifically RL, to current trends
in healthcare, providing a methodological survey of RL methods in the context
of precision and digital health. Focusing on the area of adaptive
interventions, we expand the methodological survey with illustrative case
studies that used RL in real practice.
  This invited article has undergone anonymous review and is intended as a book
chapter for the volume "Frontiers of Statistics and Data Science" edited by
Subhashis Ghoshal and Anindya Roy for the International Indian Statistical
Association Series on Statistics and Data Science, published by Springer. It
covers the material from a short course titled "Artificial Intelligence in
Precision and Digital Health" taught by the author Bibhas Chakraborty at the
IISA 2022 Conference, December 26-30 2022, at the Indian Institute of Science,
Bengaluru.

摘要：<paragraph>精準健康在數位科技的支撐下日益普及，是擴展精準醫療典範的研究領域，促進日常保健。這個願景與人工智慧 (AI) 的突破性進展息息相關，它正在重塑我們診斷、治療和監控臨床受試者和一般民眾的方式。由機器學習支援的 AI 工具已在各種醫療保健領域展現顯著的進步。特別是，強化學習 (RL) 對序貫和動態問題（例如動態治療方案和即時適應性干預）極具發展前景。在這項工作中，我們探討 AI（更具體地說，RL）為當前醫療保健趨勢帶來的契機，並提供 RL 方法在精準和數位健康領域的方法論調查。我們專注於適應性干預領域，並透過在實際應用中使用 RL 的說明性案例研究擴展方法論調查。這篇受邀文章已經過匿名審查，並作為 Subhashis Ghoshal 和 Anindya Roy 編輯的「統計學與資料科學前沿」一書的章節，由 Springer 出版的國際印度統計協會統計學與資料科學系列叢書發行。它涵蓋了由作者 Bibhas Chakraborty 在印度統計協會 2022 年會議（2022 年 12 月 26 日至 30 日，於印度科學院 Bengaluru 舉行）教授的「精準與數位健康中的人工智慧」短期課程的教材。</paragraph>

##### **GFE-Mamba: Mamba-based AD Multi-modal Progression Assessment via Generative Feature Extraction from MCI**
2407.15719v1 by Zhaojie Fang, Shenghao Zhu, Yifei Chen, Binfeng Zou, Fan Jia, Linwei Qiu, Chang Liu, Yiyu Huang, Xiang Feng, Feiwei Qin, Changmiao Wang, Yeru Wang, Jin Fan, Changbiao Chu, Wan-Zhen Wu, Hu Zhao

Alzheimer's Disease (AD) is an irreversible neurodegenerative disorder that
often progresses from Mild Cognitive Impairment (MCI), leading to memory loss
and significantly impacting patients' lives. Clinical trials indicate that
early targeted interventions for MCI patients can potentially slow or halt the
development and progression of AD. Previous research has shown that accurate
medical classification requires the inclusion of extensive multimodal data,
such as assessment scales and various neuroimaging techniques like Magnetic
Resonance Imaging (MRI) and Positron Emission Tomography (PET). However,
consistently tracking the diagnosis of the same individual over time and
simultaneously collecting multimodal data poses significant challenges. To
address this issue, we introduce GFE-Mamba, a classifier based on Generative
Feature Extraction (GFE). This classifier effectively integrates data from
assessment scales, MRI, and PET, enabling deeper multimodal fusion. It
efficiently extracts both long and short sequence information and incorporates
additional information beyond the pixel space. This approach not only improves
classification accuracy but also enhances the interpretability and stability of
the model. We constructed datasets of over 3000 samples based on the
Alzheimer's Disease Neuroimaging Initiative (ADNI) for a two-step training
process. Our experimental results demonstrate that the GFE-Mamba model is
effective in predicting the conversion from MCI to AD and outperforms several
state-of-the-art methods. Our source code and ADNI dataset processing code are
available at https://github.com/Tinysqua/GFE-Mamba.

摘要：阿茲海默症 (AD) 是一種不可逆的神經退化性疾病，
通常會從輕度認知障礙 (MCI) 惡化，導致記憶力減退
並對病患的生活產生重大影響。臨床試驗顯示，
針對 MCI 病患的早期目標性干預措施，有可能減緩或停止
AD 的發展和惡化。先前的研究顯示，精確的
醫療分類需要納入廣泛的多模式數據，
例如評估量表和各種神經影像技術，如磁振造影 (MRI) 和正子斷層掃描 (PET)。然而，
持續追蹤同一位個體的診斷結果，並同時收集多模式數據，會造成重大的挑戰。為了
解決這個問題，我們引入了 GFE-Mamba，一種基於生成特徵萃取 (GFE) 的分類器。此分類器有效整合來自
評估量表、MRI 和 PET 的數據，實現更深入的多模式融合。它
有效率地萃取出長序列和短序列資訊，並納入像素空間以外的額外資訊。這種方法不僅提升了
分類準確度，也增強了模型的可解釋性和穩定性。我們根據
阿茲海默症神經影像倡議組織 (ADNI) 建立了超過 3000 個樣本的資料集，用於兩階段訓練
過程。我們的實驗結果證明，GFE-Mamba 模型在預測從 MCI 轉變為 AD 上是有效的，並且優於多種
最先進的方法。我們的原始程式碼和 ADNI 資料集處理程式碼可於 https://github.com/Tinysqua/GFE-Mamba 取得。

##### **Synthetic Image Learning: Preserving Performance and Preventing Membership Inference Attacks**
2407.15526v1 by Eugenio Lomurno, Matteo Matteucci

Generative artificial intelligence has transformed the generation of
synthetic data, providing innovative solutions to challenges like data scarcity
and privacy, which are particularly critical in fields such as medicine.
However, the effective use of this synthetic data to train high-performance
models remains a significant challenge. This paper addresses this issue by
introducing Knowledge Recycling (KR), a pipeline designed to optimise the
generation and use of synthetic data for training downstream classifiers. At
the heart of this pipeline is Generative Knowledge Distillation (GKD), the
proposed technique that significantly improves the quality and usefulness of
the information provided to classifiers through a synthetic dataset
regeneration and soft labelling mechanism. The KR pipeline has been tested on a
variety of datasets, with a focus on six highly heterogeneous medical image
datasets, ranging from retinal images to organ scans. The results show a
significant reduction in the performance gap between models trained on real and
synthetic data, with models based on synthetic data outperforming those trained
on real data in some cases. Furthermore, the resulting models show almost
complete immunity to Membership Inference Attacks, manifesting privacy
properties missing in models trained with conventional techniques.

摘要：生成式人工智慧已經轉變了合成資料的生成，提供了創新的解決方案來應對資料稀少和隱私等挑戰，這在醫學等領域特別重要。
然而，有效使用這些合成資料來訓練高性能模型仍然是一個重大的挑戰。本文通過引入知識循環 (KR) 來解決這個問題，這是一個旨在優化合成資料的生成和使用以訓練下游分類器的管道。這個管道的核心是生成式知識蒸餾 (GKD)，這是一種提出的技術，它通過合成資料集再生和軟標籤機制顯著提高了提供給分類器的資訊的品質和有用性。KR 管道已經在各種資料集上進行了測試，重點是六個高度異質的醫學影像資料集，範圍從視網膜影像到器官掃描。結果顯示，在真實資料和合成資料上訓練的模型之間的效能差距顯著縮小，在某些情況下，基於合成資料的模型優於在真實資料上訓練的模型。此外，產生的模型顯示出對成員推論攻擊幾乎完全免疫，表現出傳統技術訓練的模型中缺少的隱私屬性。

##### **A Multimodal Knowledge-enhanced Whole-slide Pathology Foundation Model**
2407.15362v1 by Yingxue Xu, Yihui Wang, Fengtao Zhou, Jiabo Ma, Shu Yang, Huangjing Lin, Xin Wang, Jiguang Wang, Li Liang, Anjia Han, Ronald Cheong Kin Chan, Hao Chen

Remarkable strides in computational pathology have been made in the
task-agnostic foundation model that advances the performance of a wide array of
downstream clinical tasks. Despite the promising performance, there are still
several challenges. First, prior works have resorted to either vision-only or
vision-captions data, disregarding invaluable pathology reports and gene
expression profiles which respectively offer distinct knowledge for versatile
clinical applications. Second, the current progress in pathology FMs
predominantly concentrates on the patch level, where the restricted context of
patch-level pretraining fails to capture whole-slide patterns. Here we curated
the largest multimodal dataset consisting of H\&E diagnostic whole slide images
and their associated pathology reports and RNA-Seq data, resulting in 26,169
slide-level modality pairs from 10,275 patients across 32 cancer types. To
leverage these data for CPath, we propose a novel whole-slide pretraining
paradigm which injects multimodal knowledge at the whole-slide context into the
pathology FM, called Multimodal Self-TAught PRetraining (mSTAR). The proposed
paradigm revolutionizes the workflow of pretraining for CPath, which enables
the pathology FM to acquire the whole-slide context. To our knowledge, this is
the first attempt to incorporate multimodal knowledge at the slide level for
enhancing pathology FMs, expanding the modelling context from unimodal to
multimodal knowledge and from patch-level to slide-level. To systematically
evaluate the capabilities of mSTAR, extensive experiments including slide-level
unimodal and multimodal applications, are conducted across 7 diverse types of
tasks on 43 subtasks, resulting in the largest spectrum of downstream tasks.
The average performance in various slide-level applications consistently
demonstrates significant performance enhancements for mSTAR compared to SOTA
FMs.

摘要：<paragraph>在計算病理學中，任務不可知基礎模型已取得顯著進展，可提升廣泛下游臨床任務的效能。儘管效能令人滿意，但仍有幾個挑戰。首先，先前的研究僅採用僅限影像或影像標題資料，忽略了寶貴的病理報告和基因表現特徵，而這些特徵分別為多功能臨床應用提供了不同的知識。其次，病理 FM 的當前進度主要集中在區塊層級，區塊層級預訓練的受限背景無法擷取全切片模式。在此，我們策劃了最大的多模態資料集，包含 H&E 診斷全切片影像及其相關病理報告和 RNA-Seq 資料，共產生來自 32 種癌症類型的 10,275 名患者的 26,169 個切片層級模態配對。為了將這些資料用於 CPath，我們提出了一種創新的全切片預訓練範例，將全切片背景的多模態知識注入病理 FM，稱為多模態自教預訓練 (mSTAR)。所提出的範例徹底改變了 CPath 的預訓練工作流程，使病理 FM 能夠獲取全切片背景。據我們所知，這是首次嘗試在切片層級納入多模態知識以增強病理 FM，將建模背景從單一模態知識擴展到多模態知識，以及從區塊層級擴展到切片層級。為了系統性地評估 mSTAR 的功能，我們在 43 個子任務中對 7 種不同類型的任務進行了廣泛的實驗，包括切片層級的單一模態和多模態應用，產生了最大的下游任務範圍。在各種切片層級應用中，平均效能持續顯示 mSTAR 與 SOTA FM 相比有顯著的效能提升。</paragraph>

##### **Genetic Algorithm to Optimize Design of Micro-Surgical Scissors**
2407.15243v1 by Fatemeh Norouziani, Veerash Palanichamy, Shivam Gupta, Onaizah Onaizah

Microrobotics is an attractive area of research as small-scale robots have
the potential to improve the precision and dexterity offered by minimally
invasive surgeries. One example of such a tool is a pair of micro-surgical
scissors that was developed for cutting of tumors or cancerous tissues present
deep inside the body such as in the brain. This task is often deemed difficult
or impossible with conventional robotic tools due to their size and dexterity.
The scissors are designed with two magnets placed a specific distance apart to
maximize deflection and generate cutting forces. However, remote actuation and
size requirements of the micro-surgical scissors limits the force that can be
generated to puncture the tissue. To address the limitation of small output
forces, we use an evolutionary algorithm to further optimize the performance of
the scissors. In this study, the design of the previously developed untethered
micro-surgical scissors has been modified and their performance is enhanced by
determining the optimal position of the magnets as well as the direction of
each magnetic moment. The developed algorithm is successfully applied to a
4-magnet configuration which results in increased net torque. This improvement
in net torque is directly translated into higher cutting forces. The new
configuration generates a cutting force of 58 mN from 80 generations of the
evolutionary algorithm which is a 1.65 times improvement from the original
design. Furthermore, the developed algorithm has the advantage that it can be
deployed with minor modifications to other microrobotic tools and systems,
opening up new possibilities for various medical procedures and applications.

摘要：微型機器人是一個有吸引力的研究領域，因為小型機器人具有提高微創手術的精確度和靈活性。此類工具的一個範例是一對微型手術剪刀，其開發用於切除深藏於體內（例如大腦）的腫瘤或癌組織。由於傳統機器人工具的尺寸和靈活性，此任務通常被認為困難或不可能。此剪刀的設計採用兩個磁鐵，它們之間的距離設定為特定值，以最大化偏轉並產生切削力。然而，微型手術剪刀的遠程致動和尺寸要求限制了可產生的穿刺組織力。為了解決小輸出力的限制，我們使用演化演算法進一步最佳化剪刀的效能。在本研究中，先前開發的無繫繩微型手術剪刀的設計已修改，並且透過確定磁鐵的最佳位置以及每個磁矩的方向來提升其效能。已將開發的演算法成功應用於 4 磁鐵組態，這會導致淨扭力增加。淨扭力的此項改善直接轉化為更高的切削力。新的組態從演化演算法的 80 個世代產生 58 mN 的切削力，這是相較於原始設計改善了 1.65 倍。此外，已開發的演算法具有可透過輕微修改部署至其他微型機器人工具和系統的優點，為各種醫療程序和應用開啟了新的可能性。

##### **MedSAGa: Few-shot Memory Efficient Medical Image Segmentation using Gradient Low-Rank Projection in SAM**
2407.15042v1 by Navyansh Mahla, Annie D'souza, Shubh Gupta, Bhavik Kanekar, Kshitij Sharad Jadhav

The application of large-scale models in medical image segmentation demands
substantial quantities of meticulously annotated data curated by experts along
with high computational resources, both of which are challenges in
resource-poor settings. In this study, we present the Medical Segment Anything
Model with Galore MedSAGa where we adopt the Segment Anything Model (SAM) to
achieve memory-efficient, few-shot medical image segmentation by applying
Gradient Low-Rank Projection GaLore to the parameters of the image encoder of
SAM. Meanwhile, the weights of the prompt encoder and mask decoder undergo full
parameter fine-tuning using standard optimizers. We further assess MedSAGa's
few-shot learning capabilities, reporting on its memory efficiency and
segmentation performance across multiple standard medical image segmentation
datasets. We compare it with several baseline models, including LoRA fine-tuned
SAM (SAMed) and DAE-Former. Experiments across multiple datasets and these
baseline models with different number of images for fine tuning demonstrated
that the GPU memory consumption of MedSAGa is significantly less than that of
the baseline models, achieving an average memory efficiency of 66% more than
current state-of-the-art (SOTA) models for medical image segmentation. The
combination of substantially lower memory requirements and comparable to SOTA
results in few-shot learning for medical image segmentation positions MedSAGa
as an optimal solution for deployment in resource-constrained settings.

摘要：大型模型在醫學影像分割中的應用需要大量由專家精心註解的資料，以及大量的計算資源，這兩者在資源貧乏的環境中都是挑戰。在本研究中，我們提出了具有豐富醫學影像分割的醫學分割任何模型 (MedSAGa)，其中我們採用分割任何模型 (SAM) 來通過將梯度低秩投影 GaLore 應用於 SAM 的影像編碼器參數來實現記憶體效率高的少量醫學影像分割。同時，提示編碼器和遮罩解碼器的權重使用標準最佳化器進行完整的參數微調。我們進一步評估了 MedSAGa 的少量學習能力，報告了其在多個標準醫學影像分割資料集中的記憶體效率和分割效能。我們將其與幾個基準模型進行比較，包括微調 SAM (SAMed) 的 LoRA 和 DAE-Former。跨多個資料集和這些基準模型的實驗，使用不同數量的影像進行微調，證明 MedSAGa 的 GPU 記憶體消耗明顯低於基準模型，比目前最先進 (SOTA) 的醫學影像分割模型平均記憶體效率高出 66%。在少量學習中，大幅降低記憶體需求與 SOTA 相當的結果，使得 MedSAGa 成為在資源受限環境中部署的最佳解決方案。

##### **Preictal Period Optimization for Deep Learning-Based Epileptic Seizure Prediction**
2407.14876v1 by Petros Koutsouvelis, Bartlomiej Chybowski, Alfredo Gonzalez-Sulser, Shima Abdullateef, Javier Escudero

Accurate prediction of epileptic seizures could prove critical for improving
patient safety and quality of life in drug-resistant epilepsy. Although deep
learning-based approaches have shown promising seizure prediction performance
using scalp electroencephalogram (EEG) signals, substantial limitations still
impede their clinical adoption. Furthermore, identifying the optimal preictal
period (OPP) for labeling EEG segments remains a challenge. Here, we not only
develop a competitive deep learning model for seizure prediction but, more
importantly, leverage it to demonstrate a methodology to comprehensively
evaluate the predictive performance in the seizure prediction task. For this,
we introduce a CNN-Transformer deep learning model to detect preictal
spatiotemporal dynamics, alongside a novel Continuous Input-Output Performance
Ratio (CIOPR) metric to determine the OPP. We trained and evaluated our model
on 19 pediatric patients of the open-access CHB-MIT dataset in a
subject-specific manner. Using the OPP of each patient, preictal and interictal
segments were correctly identified with an average sensitivity of 99.31%,
specificity of 95.34%, AUC of 99.35%, and F1- score of 97.46%, while prediction
time averaged 76.8 minutes before onset. Notably, our novel CIOPR metric
allowed outlining the impact of different preictal period definitions on
prediction time, accuracy, output stability, and transition time between
interictal and preictal states in a comprehensive and quantitative way and
highlighted the importance of considering both inter- and intra-patient
variability in seizure prediction.

摘要：準確預測癲癇發作對於改善藥物抗性癲癇患者的安全性與生活品質至關重要。儘管基於深度學習的方法已展現出使用頭皮腦電圖 (EEG) 信號進行癲癇發作預測的出色表現，但仍有實質限制阻礙其臨床應用。此外，找出標記 EEG 片段的最佳發作前 (OPP) 時期仍然是一項挑戰。在此，我們不僅開發了一種用於癲癇發作預測的競爭性深度學習模型，更重要的是，利用它來展示一種方法，以全面評估癲癇發作預測任務中的預測性能。為此，我們引入了一個 CNN-Transformer 深度學習模型來偵測發作前的時空動力學，以及一個新的連續輸入輸出效能比 (CIOPR) 指標來確定 OPP。我們以主題特定的方式，在開放取用的 CHB-MIT 資料集的 19 位小兒患者上訓練並評估我們的模型。使用每位患者的 OPP，以平均敏感度 99.31%、特異度 95.34%、AUC 99.35% 和 F1 分數 97.46% 正確識別發作前和發作間期，而預測時間平均在發作前 76.8 分鐘。值得注意的是，我們新穎的 CIOPR 指標可以全面且量化地概述不同發作前時期定義對預測時間、準確度、輸出穩定性以及發作間期和發作前狀態之間的轉換時間的影響，並強調在癲癇發作預測中考慮患者間和患者內變異性的重要性。

##### **PASSION: Towards Effective Incomplete Multi-Modal Medical Image Segmentation with Imbalanced Missing Rates**
2407.14796v1 by Junjie Shi, Caozhi Shang, Zhaobin Sun, Li Yu, Xin Yang, Zengqiang Yan

Incomplete multi-modal image segmentation is a fundamental task in medical
imaging to refine deployment efficiency when only partial modalities are
available. However, the common practice that complete-modality data is visible
during model training is far from realistic, as modalities can have imbalanced
missing rates in clinical scenarios. In this paper, we, for the first time,
formulate such a challenging setting and propose Preference-Aware
Self-diStillatION (PASSION) for incomplete multi-modal medical image
segmentation under imbalanced missing rates. Specifically, we first construct
pixel-wise and semantic-wise self-distillation to balance the optimization
objective of each modality. Then, we define relative preference to evaluate the
dominance of each modality during training, based on which to design task-wise
and gradient-wise regularization to balance the convergence rates of different
modalities. Experimental results on two publicly available multi-modal datasets
demonstrate the superiority of PASSION against existing approaches for modality
balancing. More importantly, PASSION is validated to work as a plug-and-play
module for consistent performance improvement across different backbones. Code
is available at https://github.com/Jun-Jie-Shi/PASSION.

摘要：不完整的多模態影像分割是醫學影像中的一項基本任務，用於在只有部分模態可用時精進部署效率。然而，在模型訓練期間可見完整模態資料的常見做法並不切實際，因為在臨床場景中，模態可能會有不平衡的遺漏率。在本文中，我們首次制定了這樣一個具有挑戰性的設定，並提出了不平衡遺漏率下不完整多模態醫學影像分割的偏好感知自蒸餾 (PASSION)。具體來說，我們首先建構像素級和語義級自蒸餾，以平衡每個模態的最佳化目標。然後，我們定義相對偏好來評估訓練期間每個模態的主導地位，並根據此設計任務級和梯度級正則化，以平衡不同模態的收斂率。在兩個公開的多模態資料集上的實驗結果證明了 PASSION 優於現有模態平衡方法。更重要的是，PASSION 被驗證為即插即用模組，可在不同的主幹中持續提升效能。程式碼可在 https://github.com/Jun-Jie-Shi/PASSION 取得。

##### **Improving Representation of High-frequency Components for Medical Foundation Models**
2407.14651v2 by Yuetan Chu, Yilan Zhang, Zhongyi Han, Changchun Yang, Longxi Zhou, Gongning Luo, Xin Gao

Foundation models have recently attracted significant attention for their
impressive generalizability across diverse downstream tasks. However, these
models are demonstrated to exhibit great limitations in representing
high-frequency components and fine-grained details. In many medical imaging
tasks, the precise representation of such information is crucial due to the
inherently intricate anatomical structures, sub-visual features, and complex
boundaries involved. Consequently, the limited representation of prevalent
foundation models can result in significant performance degradation or even
failure in these tasks. To address these challenges, we propose a novel
pretraining strategy, named Frequency-advanced Representation Autoencoder
(Frepa). Through high-frequency masking and low-frequency perturbation combined
with adversarial learning, Frepa encourages the encoder to effectively
represent and preserve high-frequency components in the image embeddings.
Additionally, we introduce an innovative histogram-equalized image masking
strategy, extending the Masked Autoencoder approach beyond ViT to other
architectures such as Swin Transformer and convolutional networks. We develop
Frepa across nine medical modalities and validate it on 32 downstream tasks for
both 2D images and 3D volume data. Without fine-tuning, Frepa can outperform
other self-supervised pretraining methods and, in some cases, even surpasses
task-specific trained models. This improvement is particularly significant for
tasks involving fine-grained details, such as achieving up to a +15% increase
in DSC for retina vessel segmentation and a +7% increase in IoU for lung nodule
detection. Further experiments quantitatively reveal that Frepa enables
superior high-frequency representations and preservation in the embeddings,
underscoring its potential for developing more generalized and universal
medical image foundation models.

摘要：<paragraph>基礎模型最近因其在各種下游任務中令人印象深刻的泛化能力而備受關注。然而，這些模型已證明在表示高頻率組成和細粒度細節方面表現出很大的局限性。在許多醫學影像任務中，由於涉及固有的複雜解剖結構、次視覺特徵和複雜邊界，因此準確表示此類信息至關重要。因此，流行基礎模型的有限表示可能會導致這些任務的顯著性能下降甚至失敗。為了應對這些挑戰，我們提出了一種名為頻率先進表示自動編碼器 (Frepa) 的新穎預訓練策略。通過高頻掩蔽和低頻擾動與對抗學習相結合，Frepa 鼓勵編碼器有效表示和保留圖像嵌入中的高頻組成。此外，我們引入了一種創新的直方圖均衡圖像掩蔽策略，將掩蔽自動編碼器方法從 ViT 擴展到其他架構，例如 Swin Transformer 和卷積網路。我們在九種醫學模式下開發了 Frepa，並在 32 個下游任務中對其進行了驗證，包括 2D 圖像和 3D 體積數據。在不進行微調的情況下，Frepa 可以優於其他自我監督預訓練方法，並且在某些情況下，甚至超過了特定任務訓練的模型。這種改進對於涉及細粒度細節的任務尤其顯著，例如在視網膜血管分割中將 DSC 提高了 15%，在肺結節檢測中將 IoU 提高了 7%。進一步的實驗定量地表明，Frepa 能夠在嵌入中實現優越的高頻表示和保留，這突顯了其開發更通用和通用的醫學影像基礎模型的潛力。</paragraph>

##### **CVE-LLM : Automatic vulnerability evaluation in medical device industry using large language models**
2407.14640v1 by Rikhiya Ghosh, Oladimeji Farri, Hans-Martin von Stockhausen, Martin Schmitt, George Marica Vasile

The healthcare industry is currently experiencing an unprecedented wave of
cybersecurity attacks, impacting millions of individuals. With the discovery of
thousands of vulnerabilities each month, there is a pressing need to drive the
automation of vulnerability assessment processes for medical devices,
facilitating rapid mitigation efforts. Generative AI systems have
revolutionized various industries, offering unparalleled opportunities for
automation and increased efficiency. This paper presents a solution leveraging
Large Language Models (LLMs) to learn from historical evaluations of
vulnerabilities for the automatic assessment of vulnerabilities in the medical
devices industry. This approach is applied within the portfolio of a single
manufacturer, taking into account device characteristics, including existing
security posture and controls. The primary contributions of this paper are
threefold. Firstly, it provides a detailed examination of the best practices
for training a vulnerability Language Model (LM) in an industrial context.
Secondly, it presents a comprehensive comparison and insightful analysis of the
effectiveness of Language Models in vulnerability assessment. Finally, it
proposes a new human-in-the-loop framework to expedite vulnerability evaluation
processes.

摘要：醫療保健產業目前正經歷一前所未有的網路安全攻擊浪潮，影響了數百萬人。隨著每月發現數千個漏洞，迫切需要推動醫療器材漏洞評估程序的自動化，以利於快速採取緩解措施。生成式 AI 系統已經徹底改變了各產業，為自動化和提高效率提供了無與倫比的機會。本文提出了一種解決方案，利用大型語言模型 (LLM) 從漏洞的歷史評估中學習，以自動評估醫療器材產業中的漏洞。此方法應用於單一製造商的產品組合中，考量了裝置特性，包括現有的安全態勢和控制措施。本文的主要貢獻有三方面。首先，它提供了在產業背景下訓練漏洞語言模型 (LM) 的最佳實務詳細說明。其次，它提出了語言模型在漏洞評估中的有效性之全面比較和深入分析。最後，它提出了一個新的「人機協作」架構，以加速漏洞評估程序。

##### **Two new feature selection methods based on learn-heuristic techniques for breast cancer prediction: A comprehensive analysis**
2407.14631v1 by Kamyab Karimi, Ali Ghodratnama, Reza Tavakkoli-Moghaddam

Breast cancer is not preventable because of its unknown causes. However, its
early diagnosis increases patients' recovery chances. Machine learning (ML) can
be utilized to improve treatment outcomes in healthcare operations while
diminishing costs and time. In this research, we suggest two novel feature
selection (FS) methods based upon an imperialist competitive algorithm (ICA)
and a bat algorithm (BA) and their combination with ML algorithms. This study
aims to enhance diagnostic models' efficiency and present a comprehensive
analysis to help clinical physicians make much more precise and reliable
decisions than before. K-nearest neighbors, support vector machine, decision
tree, Naive Bayes, AdaBoost, linear discriminant analysis, random forest,
logistic regression, and artificial neural network are some of the methods
employed. This paper applied a distinctive integration of evaluation measures
and ML algorithms using the wrapper feature selection based on ICA (WFSIC) and
BA (WFSB) separately. We compared two proposed approaches for the performance
of the classifiers. Also, we compared our best diagnostic model with previous
works reported in the literature survey. Experimentations were performed on the
Wisconsin diagnostic breast cancer dataset. Results reveal that the proposed
framework that uses the BA with an accuracy of 99.12\%, surpasses the framework
using the ICA and most previous works. Additionally, the RF classifier in the
approach of FS based on BA emerges as the best model and outperforms others
regarding its criteria. Besides, the results illustrate the role of our
techniques in reducing the dataset dimensions up to 90\% and increasing the
performance of diagnostic models by over 99\%. Moreover, the result
demonstrates that there are more critical features than the optimum dataset
obtained by proposed FS approaches that have been selected by most ML models.

摘要：<paragraph>由於乳癌的成因不明，因此無法預防。然而，早期診斷可增加患者的康復機會。機器學習 (ML) 可用於改善醫療保健作業中的治療成果，同時降低成本和時間。在本研究中，我們提出兩種基於帝國主義競爭演算法 (ICA) 和蝙蝠演算法 (BA) 的新特徵選擇 (FS) 方法，以及它們與 ML 演算法的組合。本研究旨在提高診斷模型的效率，並提供全面的分析，以幫助臨床醫師做出比以往更精確且可靠的決策。K 最近鄰、支援向量機、決策樹、樸素貝氏、AdaBoost、線性判別分析、隨機森林、邏輯迴歸和人工神經網路是一些所採用的方法。本文使用基於 ICA (WFSIC) 和 BA (WFSB) 的包裝特徵選擇，應用評估措施和 ML 演算法的獨特整合。我們比較了兩種提出的方法以評估分類器的效能。此外，我們將我們最好的診斷模型與文獻調查中報導的先前研究進行比較。實驗是在威斯康辛診斷乳癌資料集上進行的。結果顯示，使用 BA 的擬議架構準確率為 99.12%，優於使用 ICA 和大多數先前研究的架構。此外，基於 BA 的 FS 方法中的 RF 分類器成為最佳模型，並在標準方面優於其他模型。此外，結果說明了我們的技術在將資料集維度減少多達 90% 以及將診斷模型的效能提高超過 99% 中所扮演的角色。此外，結果表明，由大多數 ML 模型所選取的，比由提出的 FS 方法所獲得的最佳資料集更重要的特徵還更多。</paragraph>

##### **Panoptic Segmentation of Mammograms with Text-To-Image Diffusion Model**
2407.14326v1 by Kun Zhao, Jakub Prokop, Javier Montalt Tordera, Sadegh Mohammadi

Mammography is crucial for breast cancer surveillance and early diagnosis.
However, analyzing mammography images is a demanding task for radiologists, who
often review hundreds of mammograms daily, leading to overdiagnosis and
overtreatment. Computer-Aided Diagnosis (CAD) systems have been developed to
assist in this process, but their capabilities, particularly in lesion
segmentation, remained limited. With the contemporary advances in deep learning
their performance may be improved. Recently, vision-language diffusion models
emerged, demonstrating outstanding performance in image generation and
transferability to various downstream tasks. We aim to harness their
capabilities for breast lesion segmentation in a panoptic setting, which
encompasses both semantic and instance-level predictions. Specifically, we
propose leveraging pretrained features from a Stable Diffusion model as inputs
to a state-of-the-art panoptic segmentation architecture, resulting in accurate
delineation of individual breast lesions. To bridge the gap between natural and
medical imaging domains, we incorporated a mammography-specific MAM-E diffusion
model and BiomedCLIP image and text encoders into this framework. We evaluated
our approach on two recently published mammography datasets, CDD-CESM and
VinDr-Mammo. For the instance segmentation task, we noted 40.25 AP0.1 and 46.82
AP0.05, as well as 25.44 PQ0.1 and 26.92 PQ0.05. For the semantic segmentation
task, we achieved Dice scores of 38.86 and 40.92, respectively.

摘要：乳房攝影對於乳癌監控和早期診斷至關重要。
然而，分析乳房攝影影像對放射科醫師來說是一項艱鉅的任務，他們
每天經常檢閱數百張乳房攝影影像，導致過度診斷和
過度治療。電腦輔助診斷 (CAD) 系統已開發出來以
協助此流程，但其功能，特別是在病灶
分割方面，仍然有限。隨著深度學習的當代進展
其性能可能會得到改善。最近，視覺語言擴散模型
出現，在影像生成和
可轉移到各種下游任務中展現出傑出的性能。我們旨在利用其
功能在全景設置中進行乳房病灶分割，其中
包含語義和實例級別預測。具體來說，我們
建議利用預先訓練的 Stable Diffusion 模型中的特徵作為輸入
到最先進的全景分割架構，從而精確地描繪個別乳房病灶。為了彌合自然和
醫學影像領域之間的差距，我們將乳房攝影專用的 MAM-E 擴散
模型和 BiomedCLIP 影像和文字編碼器納入這個架構中。我們評估
我們的方法在兩個最近發布的乳房攝影資料集 CDD-CESM 和
VinDr-Mammo。對於實例分割任務，我們注意到 40.25 AP0.1 和 46.82
AP0.05，以及 25.44 PQ0.1 和 26.92 PQ0.05。對於語義分割
任務，我們分別達到了 38.86 和 40.92 的 Dice 分數。

##### **Fair Overlap Number of Balls (Fair-ONB): A Data-Morphology-based Undersampling Method for Bias Reduction**
2407.14210v1 by José Daniel Pascual-Triana, Alberto Fernández, Paulo Novais, Francisco Herrera

Given the magnitude of data generation currently, both in quantity and speed,
the use of machine learning is increasingly important. When data include
protected features that might give rise to discrimination, special care must be
taken. Data quality is critical in these cases, as biases in training data can
be reflected in classification models. This has devastating consequences and
fails to comply with current regulations. Data-Centric Artificial Intelligence
proposes dataset modifications to improve its quality. Instance selection via
undersampling can foster balanced learning of classes and protected feature
values in the classifier. When such undersampling is done close to the decision
boundary, the effect on the classifier would be bolstered. This work proposes
Fair Overlap Number of Balls (Fair-ONB), an undersampling method that harnesses
the data morphology of the different data groups (obtained from the combination
of classes and protected feature values) to perform guided undersampling in the
areas where they overlap. It employs attributes of the ball coverage of the
groups, such as the radius, number of covered instances and density, to select
the most suitable areas for undersampling and reduce bias. Results show that
the Fair-ONB method reduces bias with low impact on the classifier's predictive
performance.

摘要：<paragraph>鉴于当前数据生成的规模，无论是在数量还是速度上，机器学习的使用变得越来越重要。当数据包含可能导致歧视的受保护特征时，必须特别小心。在这些情况下，数据质量至关重要，因为训练数据中的偏差可能会反映在分类模型中。这会产生毁灭性的后果，并且不符合当前法规。以数据为中心的 AI 提出了数据集修改以提高其质量。通过欠采样进行实例选择可以促进分类器中类和受保护特征值的平衡学习。当此类欠采样接近决策边界时，对分类器的影响将得到加强。这项工作提出了公平重叠球数 (Fair-ONB)，这是一种欠采样方法，利用不同数据组（从类和受保护特征值的组合中获得）的数据形态，在它们重叠的区域执行引导欠采样。它采用球覆盖的属性，例如半径、覆盖实例数和密度，以选择最适合欠采样的区域并减少偏差。结果表明，Fair-ONB 方法减少了偏差，对分类器的预测性能影响很小。</paragraph>

##### **Domain-Specific Pretraining of Language Models: A Comparative Study in the Medical Field**
2407.14076v1 by Tobias Kerner

There are many cases where LLMs are used for specific tasks in a single
domain. These usually require less general, but more domain-specific knowledge.
Highly capable, general-purpose state-of-the-art language models like GPT-4 or
Claude-3-opus can often be used for such tasks, but they are very large and
cannot be run locally, even if they were not proprietary. This can be a problem
when working with sensitive data. This paper focuses on domain-specific and
mixed-domain pretraining as potentially more efficient methods than general
pretraining for specialized language models. We will take a look at work
related to domain-specific pretraining, specifically in the medical area, and
compare benchmark results of specialized language models to general-purpose
language models.

摘要：在許多情況下，LLM 被用於單一領域中的特定任務。這些任務通常需要較少的通用知識，但需要更多特定領域的知識。功能強大、用途廣泛的最新語言模型，例如 GPT-4 或 Claude-3-opus，通常可用於此類任務，但它們非常龐大，即使不是專有軟體，也無法在本地執行。在處理敏感資料時，這可能會造成問題。本文重點探討特定領域和混合領域的預訓練，作為比一般預訓練更有效率的專業語言模型潛在方法。我們將探討與特定領域預訓練相關的工作，特別是在醫療領域，並比較專業語言模型與通用語言模型的基準測試結果。

##### **HeCiX: Integrating Knowledge Graphs and Large Language Models for Biomedical Research**
2407.14030v1 by Prerana Sanjay Kulkarni, Muskaan Jain, Disha Sheshanarayana, Srinivasan Parthiban

Despite advancements in drug development strategies, 90% of clinical trials
fail. This suggests overlooked aspects in target validation and drug
optimization. In order to address this, we introduce HeCiX-KG,
Hetionet-Clinicaltrials neXus Knowledge Graph, a novel fusion of data from
ClinicalTrials.gov and Hetionet in a single knowledge graph. HeCiX-KG combines
data on previously conducted clinical trials from ClinicalTrials.gov, and
domain expertise on diseases and genes from Hetionet. This offers a thorough
resource for clinical researchers. Further, we introduce HeCiX, a system that
uses LangChain to integrate HeCiX-KG with GPT-4, and increase its usability.
HeCiX shows high performance during evaluation against a range of clinically
relevant issues, proving this model to be promising for enhancing the
effectiveness of clinical research. Thus, this approach provides a more
holistic view of clinical trials and existing biological data.

摘要：儘管藥物開發策略有進展，90% 的臨床試驗都失敗了。這表示在目標驗證和藥物最佳化方面有被忽略的層面。為了解決這個問題，我們引進了 HeCiX-KG，Hetionet-Clinicaltrials neXus 知識圖譜，這是一個將 ClinicalTrials.gov 和 Hetionet 的資料融合在單一知識圖譜中的新穎融合。HeCiX-KG 結合了來自 ClinicalTrials.gov 的先前執行臨床試驗資料，以及來自 Hetionet 的疾病和基因領域專業知識。這為臨床研究人員提供了豐富的資源。此外，我們引進了 HeCiX，一個使用 LangChain 將 HeCiX-KG 與 GPT-4 整合，並提高其可用性的系統。HeCiX 在針對一系列臨床相關問題的評估中表現出高性能，證明了這個模型有望提高臨床研究的有效性。因此，這種方法提供了對臨床試驗和現有生物資料更全面的看法。

##### **DuoFormer: Leveraging Hierarchical Visual Representations by Local and Global Attention**
2407.13920v1 by Xiaoya Tang, Bodong Zhang, Beatrice S. Knudsen, Tolga Tasdizen

We here propose a novel hierarchical transformer model that adeptly
integrates the feature extraction capabilities of Convolutional Neural Networks
(CNNs) with the advanced representational potential of Vision Transformers
(ViTs). Addressing the lack of inductive biases and dependence on extensive
training datasets in ViTs, our model employs a CNN backbone to generate
hierarchical visual representations. These representations are then adapted for
transformer input through an innovative patch tokenization. We also introduce a
'scale attention' mechanism that captures cross-scale dependencies,
complementing patch attention to enhance spatial understanding and preserve
global perception. Our approach significantly outperforms baseline models on
small and medium-sized medical datasets, demonstrating its efficiency and
generalizability. The components are designed as plug-and-play for different
CNN architectures and can be adapted for multiple applications. The code is
available at https://github.com/xiaoyatang/DuoFormer.git.

摘要：我們在此提出一個新穎的分層Transformer模型，它巧妙地整合了卷積神經網路 (CNN) 的特徵擷取能力，以及視覺Transformer (ViT) 的先進表示潛力。針對 ViT 中缺乏歸納偏誤和依賴於廣泛訓練資料集的問題，我們的模型採用 CNN 主幹來產生分層視覺表示。這些表示接著透過創新的區塊標記化，調整為Transformer輸入。我們也引入「尺度注意力」機制，它捕捉跨尺度依賴性，補充區塊注意力以增強空間理解並保留全局感知。我們的做法在小型和中型的醫學資料集上，明顯優於基線模型，證明了它的效率和可概化性。這些組件被設計成即插即用，適用於不同的 CNN 架構，並且可以調整為多種應用程式。程式碼可在 https://github.com/xiaoyatang/DuoFormer.git 取得。

##### **Data-Algorithm-Architecture Co-Optimization for Fair Neural Networks on Skin Lesion Dataset**
2407.13896v1 by Yi Sheng, Junhuan Yang, Jinyang Li, James Alaina, Xiaowei Xu, Yiyu Shi, Jingtong Hu, Weiwen Jiang, Lei Yang

As Artificial Intelligence (AI) increasingly integrates into our daily lives,
fairness has emerged as a critical concern, particularly in medical AI, where
datasets often reflect inherent biases due to social factors like the
underrepresentation of marginalized communities and socioeconomic barriers to
data collection. Traditional approaches to mitigating these biases have focused
on data augmentation and the development of fairness-aware training algorithms.
However, this paper argues that the architecture of neural networks, a core
component of Machine Learning (ML), plays a crucial role in ensuring fairness.
We demonstrate that addressing fairness effectively requires a holistic
approach that simultaneously considers data, algorithms, and architecture.
Utilizing Automated ML (AutoML) technology, specifically Neural Architecture
Search (NAS), we introduce a novel framework, BiaslessNAS, designed to achieve
fair outcomes in analyzing skin lesion datasets. BiaslessNAS incorporates
fairness considerations at every stage of the NAS process, leading to the
identification of neural networks that are not only more accurate but also
significantly fairer. Our experiments show that BiaslessNAS achieves a 2.55%
increase in accuracy and a 65.50% improvement in fairness compared to
traditional NAS methods, underscoring the importance of integrating fairness
into neural network architecture for better outcomes in medical AI
applications.

摘要：隨著人工智慧（AI）日益融入我們的日常生活，公平性已成為一項至關重要的考量，特別是在醫療 AI 領域，其中由於社會因素（例如邊緣化社群的代表性不足和資料收集的社會經濟障礙），資料集往往反映出固有的偏見。減輕這些偏見的傳統方法著重於資料擴充和開發注重公平性的訓練演算法。然而，本文論證神經網路的架構（機器學習（ML）的核心組成部分）在確保公平性方面發揮著至關重要的作用。我們證明，有效解決公平性問題需要一種全面的方法，該方法同時考慮資料、演算法和架構。利用自動化 ML（AutoML）技術，特別是神經架構搜尋（NAS），我們引入了一個新穎的框架 BiaslessNAS，旨在分析皮膚病變資料集時獲得公平的結果。BiaslessNAS 在 NAS 程序的每個階段都納入了公平性考量，從而識別出不僅更準確，而且也顯著更公平的神經網路。我們的實驗表明，與傳統的 NAS 方法相比，BiaslessNAS 的準確度提高了 2.55%，公平性提高了 65.50%，這凸顯了將公平性整合到神經網路架構中對於改善醫療 AI 應用中的結果的重要性。

##### **APS-USCT: Ultrasound Computed Tomography on Sparse Data via AI-Physic Synergy**
2407.14564v1 by Yi Sheng, Hanchen Wang, Yipei Liu, Junhuan Yang, Weiwen Jiang, Youzuo Lin, Lei Yang

Ultrasound computed tomography (USCT) is a promising technique that achieves
superior medical imaging reconstruction resolution by fully leveraging waveform
information, outperforming conventional ultrasound methods. Despite its
advantages, high-quality USCT reconstruction relies on extensive data
acquisition by a large number of transducers, leading to increased costs,
computational demands, extended patient scanning times, and manufacturing
complexities. To mitigate these issues, we propose a new USCT method called
APS-USCT, which facilitates imaging with sparse data, substantially reducing
dependence on high-cost dense data acquisition. Our APS-USCT method consists of
two primary components: APS-wave and APS-FWI. The APS-wave component, an
encoder-decoder system, preprocesses the waveform data, converting sparse data
into dense waveforms to augment sample density prior to reconstruction. The
APS-FWI component, utilizing the InversionNet, directly reconstructs the speed
of sound (SOS) from the ultrasound waveform data. We further improve the
model's performance by incorporating Squeeze-and-Excitation (SE) Blocks and
source encoding techniques. Testing our method on a breast cancer dataset
yielded promising results. It demonstrated outstanding performance with an
average Structural Similarity Index (SSIM) of 0.8431. Notably, over 82% of
samples achieved an SSIM above 0.8, with nearly 61% exceeding 0.85,
highlighting the significant potential of our approach in improving USCT image
reconstruction by efficiently utilizing sparse data.

摘要：超音波電腦斷層攝影 (USCT) 是一種很有前景的技術，它能透過充分利用波形資訊，達成優異的醫學影像重建解析度，表現優於傳統超音波方法。儘管有其優點，高品質的 USCT 重建依賴於大量換能器廣泛的資料擷取，導致成本增加、運算需求、病患掃描時間延長，以及製造複雜度。為了減輕這些問題，我們提出了一種名為 APS-USCT 的新型 USCT 方法，它促進使用稀疏資料進行影像處理，大幅降低對高成本密集資料擷取的依賴。我們的 APS-USCT 方法包含兩個主要組成部分：APS-wave 和 APS-FWI。APS-wave 組件是一個編碼器解碼器系統，它預先處理波形資料，將稀疏資料轉換為密集波形，以在重建之前增加取樣密度。APS-FWI 組件利用 InversionNet，直接從超音波波形資料重建音速 (SOS)。我們進一步透過結合 Squeeze-and-Excitation (SE) 區塊和原始編碼技術來提升模型效能。在乳癌資料集上測試我們的這個方法，得到了有前景的結果。它展現了傑出的效能，結構相似性指標 (SSIM) 平均為 0.8431。值得注意的是，超過 82% 的樣本達成 SSIM 高於 0.8，近 61% 超過 0.85，突顯了我們的方法在透過有效利用稀疏資料來改善 USCT 影像重建方面的顯著潛力。

##### **Addressing Imbalance for Class Incremental Learning in Medical Image Classification**
2407.13768v1 by Xuze Hao, Wenqian Ni, Xuhao Jiang, Weimin Tan, Bo Yan

Deep convolutional neural networks have made significant breakthroughs in
medical image classification, under the assumption that training samples from
all classes are simultaneously available. However, in real-world medical
scenarios, there's a common need to continuously learn about new diseases,
leading to the emerging field of class incremental learning (CIL) in the
medical domain. Typically, CIL suffers from catastrophic forgetting when
trained on new classes. This phenomenon is mainly caused by the imbalance
between old and new classes, and it becomes even more challenging with
imbalanced medical datasets. In this work, we introduce two simple yet
effective plug-in methods to mitigate the adverse effects of the imbalance.
First, we propose a CIL-balanced classification loss to mitigate the classifier
bias toward majority classes via logit adjustment. Second, we propose a
distribution margin loss that not only alleviates the inter-class overlap in
embedding space but also enforces the intra-class compactness. We evaluate the
effectiveness of our method with extensive experiments on three benchmark
datasets (CCH5000, HAM10000, and EyePACS). The results demonstrate that our
approach outperforms state-of-the-art methods.

摘要：深度卷積神經網路在醫學影像分類方面取得了重大突破，假設所有類別的訓練樣本都能同時取得。然而，在現實世界的醫療場景中，通常需要持續學習新的疾病，導致醫療領域中類別增量學習 (CIL) 的新興領域。通常，CIL 在訓練新類別時會遭受災難性遺忘。這種現象主要是由於舊類別和新類別之間的不平衡造成的，而在不平衡的醫療資料集上，這會變得更具挑戰性。在這項工作中，我們介紹了兩種簡單但有效的外掛方法來減輕不平衡的負面影響。首先，我們提出一個 CIL 平衡分類損失，透過 logit 調整來減輕分類器對多數類別的偏見。其次，我們提出一個分佈邊際損失，它不僅可以減輕嵌入空間中的類間重疊，還可以加強類內緊密性。我們在三個基準資料集（CCH5000、HAM10000 和 EyePACS）上進行了廣泛的實驗，評估了我們方法的有效性。結果表明，我們的做法優於最先進的方法。

##### **Shaded Route Planning Using Active Segmentation and Identification of Satellite Images**
2407.13689v1 by Longchao Da, Rohan Chhibba, Rushabh Jaiswal, Ariane Middel, Hua Wei

Heatwaves pose significant health risks, particularly due to prolonged
exposure to high summer temperatures. Vulnerable groups, especially pedestrians
and cyclists on sun-exposed sidewalks, motivate the development of a route
planning method that incorporates somatosensory temperature effects through
shade ratio consideration. This paper is the first to introduce a pipeline that
utilizes segmentation foundation models to extract shaded areas from
high-resolution satellite images. These areas are then integrated into a
multi-layered road map, enabling users to customize routes based on a balance
between distance and shade exposure, thereby enhancing comfort and health
during outdoor activities. Specifically, we construct a graph-based
representation of the road map, where links indicate connectivity and are
updated with shade ratio data for dynamic route planning. This system is
already implemented online, with a video demonstration, and will be
specifically adapted to assist travelers during the 2024 Olympic Games in
Paris.

摘要：熱浪造成顯著的健康風險，特別是長時間暴露在夏季的高溫下。容易受傷害的族群，尤其是行走在陽光直射人行道上的行人和自行車騎士，促成了規劃路線方法的發展，其中納入了透過遮陽率考量來產生的體感溫度影響。本文首次介紹一個利用分割基礎模型從高解析度衛星影像中擷取陰影區域的管線。這些區域接著整合到多層道路地圖中，使用戶能夠根據距離和遮陽曝曬之間的平衡來自訂路線，進而提升戶外活動時的舒適度和健康。具體來說，我們建構了一個以圖形為基礎的道路地圖表徵，其中連結表示連通性，並透過遮陽率資料更新以進行動態路線規劃。此系統已線上實作，並附有影片示範，且將特別調整以協助旅客參加 2024 年巴黎奧運。

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

摘要：本研究旨在探討將自然語言處理 (NLP) 和機器學習 (ML) 技術實作於醫療信函編碼自動化，並具備視覺化說明能力和輕量化的本地電腦設定。目前在臨床環境中，編碼是一種手動流程，涉及為病患文件中的每項病症、程序和藥物指派代碼 (例如，使用 SNOMED CT 代碼 56265001 表示心臟病)。此領域有使用最新 ML 模型進行自動編碼的初步研究；然而，由於模型的複雜性和大小，並未實現實際部署。為了進一步促進自動編碼實務的可能性，我們在本地電腦設定中探討了一些解決方案；此外，我們探討了說明功能在 AI 模型透明度中的功能。我們使用公開的 MIMIC-III 資料庫和 HAN/HLAN 網路模型進行 ICD 代碼預測。我們還試驗了 ICD 和 SNOMED CT 知識庫之間的對應。在我們的實驗中，這些模型提供了 97.98% 代碼的有用資訊。這項調查結果可以為實務中的自動臨床編碼實作提供一些見解，例如在醫院環境中，由臨床醫生使用的本地電腦，專案頁面 \url{https://github.com/Glenj01/Medical-Coding}。

##### **A review of handcrafted and deep radiomics in neurological diseases: transitioning from oncology to clinical neuroimaging**
2407.13813v1 by Elizaveta Lavrova, Henry C. Woodruff, Hamza Khan, Eric Salmon, Philippe Lambin, Christophe Phillips

Medical imaging technologies have undergone extensive development, enabling
non-invasive visualization of clinical information. The traditional review of
medical images by clinicians remains subjective, time-consuming, and prone to
human error. With the recent availability of medical imaging data,
quantification have become important goals in the field. Radiomics, a
methodology aimed at extracting quantitative information from imaging data, has
emerged as a promising approach to uncover hidden biological information and
support decision-making in clinical practice. This paper presents a review of
the radiomic pipeline from the clinical neuroimaging perspective, providing a
detailed overview of each step with practical advice. It discusses the
application of handcrafted and deep radiomics in neuroimaging, stratified by
neurological diagnosis. Although radiomics shows great potential for increasing
diagnostic precision and improving treatment quality in neurology, several
limitations hinder its clinical implementation. Addressing these challenges
requires collaborative efforts, advancements in image harmonization methods,
and the establishment of reproducible and standardized pipelines with
transparent reporting. By overcoming these obstacles, radiomics can
significantly impact clinical neurology and enhance patient care.

摘要：醫學影像技術已歷經廣泛發展，能以非侵入性方式視覺化臨床資訊。臨床醫師傳統上對醫學影像的檢視仍主觀、耗時，且容易發生人為錯誤。隨著醫學影像資料近期變得容易取得，量化已成為該領域的重要目標。放射特徵組學是一種旨在從影像資料中萃取量化資訊的方法，已成為一種有望揭露隱藏生物資訊並支援臨床實務決策制定的方法。本文回顧了放射特徵組學管線在臨床神經影像的觀點，並提供各步驟的詳細概觀和實用建議。本文討論了人工製作和深度放射特徵組學在神經影像中的應用，並依神經診斷分層。儘管放射特徵組學在提高神經科診斷精準度和改善治療品質方面顯示出極大的潛力，但仍有若干限制阻礙其臨床應用。要解決這些挑戰，需要合作努力、影像調和方法的進展，以及建立具有透明報告的可複製且標準化的管線。透過克服這些障礙，放射特徵組學將能顯著影響臨床神經科並提升病患照護。

##### **End-To-End Clinical Trial Matching with Large Language Models**
2407.13463v1 by Dyke Ferber, Lars Hilgers, Isabella C. Wiest, Marie-Elisabeth Leßmann, Jan Clusmann, Peter Neidlinger, Jiefu Zhu, Georg Wölflein, Jacqueline Lammert, Maximilian Tschochohei, Heiko Böhme, Dirk Jäger, Mihaela Aldea, Daniel Truhn, Christiane Höper, Jakob Nikolas Kather

Matching cancer patients to clinical trials is essential for advancing
treatment and patient care. However, the inconsistent format of medical free
text documents and complex trial eligibility criteria make this process
extremely challenging and time-consuming for physicians. We investigated
whether the entire trial matching process - from identifying relevant trials
among 105,600 oncology-related clinical trials on clinicaltrials.gov to
generating criterion-level eligibility matches - could be automated using Large
Language Models (LLMs). Using GPT-4o and a set of 51 synthetic Electronic
Health Records (EHRs), we demonstrate that our approach identifies relevant
candidate trials in 93.3% of cases and achieves a preliminary accuracy of 88.0%
when matching patient-level information at the criterion level against a
baseline defined by human experts. Utilizing LLM feedback reveals that 39.3%
criteria that were initially considered incorrect are either ambiguous or
inaccurately annotated, leading to a total model accuracy of 92.7% after
refining our human baseline. In summary, we present an end-to-end pipeline for
clinical trial matching using LLMs, demonstrating high precision in screening
and matching trials to individual patients, even outperforming the performance
of qualified medical doctors. Our fully end-to-end pipeline can operate
autonomously or with human supervision and is not restricted to oncology,
offering a scalable solution for enhancing patient-trial matching in real-world
settings.

摘要：配對癌症患者與臨床試驗對於推進治療和患者照護至關重要。然而，醫療自由文本文件格式不一致以及複雜的試驗資格標準，使得這個過程對醫師來說極具挑戰性且耗時。我們調查了整個試驗配對過程——從在 clinicaltrials.gov 上 105,600 個與腫瘤學相關的臨床試驗中找出相關試驗，到產生標準層級資格配對——是否可以使用大型語言模型 (LLM) 自動化。我們使用 GPT-4o 和一套 51 個合成的電子健康紀錄 (EHR)，證明我們的做法在 93.3% 的案例中找出相關候選試驗，並且在針對人類專家定義的基準，比對標準層級的患者層級資訊時，達到 88.0% 的初步準確度。利用 LLM 回饋顯示，最初被認為不正確的 39.3% 標準，不是模稜兩可就是註解不準確，在我們改善人類基準後，導致模型總準確度為 92.7%。總之，我們提出一個使用 LLM 的臨床試驗配對端到端管線，證明在篩選和比對試驗到個別患者時具有高精準度，甚至優於合格醫生的表現。我們完全的端到端管線可以自主運作或在人類監督下運作，且不限於腫瘤學，提供一個可擴充的解決方案，用於提升現實世界中的患者試驗配對。

##### **CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis**
2407.13301v1 by Junying Chen, Chi Gui, Anningzhe Gao, Ke Ji, Xidong Wang, Xiang Wan, Benyou Wang

The field of medical diagnosis has undergone a significant transformation
with the advent of large language models (LLMs), yet the challenges of
interpretability within these models remain largely unaddressed. This study
introduces Chain-of-Diagnosis (CoD) to enhance the interpretability of
LLM-based medical diagnostics. CoD transforms the diagnostic process into a
diagnostic chain that mirrors a physician's thought process, providing a
transparent reasoning pathway. Additionally, CoD outputs the disease confidence
distribution to ensure transparency in decision-making. This interpretability
makes model diagnostics controllable and aids in identifying critical symptoms
for inquiry through the entropy reduction of confidences. With CoD, we
developed DiagnosisGPT, capable of diagnosing 9604 diseases. Experimental
results demonstrate that DiagnosisGPT outperforms other LLMs on diagnostic
benchmarks. Moreover, DiagnosisGPT provides interpretability while ensuring
controllability in diagnostic rigor.

摘要：隨著大型語言模型 (LLM) 的出現，醫療診斷領域經歷了一場重大轉型，但這些模型的可解釋性挑戰在很大程度上仍未得到解決。本研究引入了診斷鏈 (CoD) 來增強基於 LLM 的醫療診斷的可解釋性。CoD 將診斷過程轉換為一個診斷鏈，反映了醫生的思考過程，提供了一條透明的推理路徑。此外，CoD 輸出了疾病置信度分佈，以確保決策透明度。這種可解釋性使模型診斷可控，並有助於通過置信度的熵減來識別需要詢問的關鍵症狀。使用 CoD，我們開發了 DiagnosisGPT，它能夠診斷 9604 種疾病。實驗結果表明，DiagnosisGPT 在診斷基準上優於其他 LLM。此外，DiagnosisGPT 在確保診斷嚴謹性可控性的同時提供了可解釋性。

##### **NODER: Image Sequence Regression Based on Neural Ordinary Differential Equations**
2407.13241v1 by Hao Bai, Yi Hong

Regression on medical image sequences can capture temporal image pattern
changes and predict images at missing or future time points. However, existing
geodesic regression methods limit their regression performance by a strong
underlying assumption of linear dynamics, while diffusion-based methods have
high computational costs and lack constraints to preserve image topology. In
this paper, we propose an optimization-based new framework called NODER, which
leverages neural ordinary differential equations to capture complex underlying
dynamics and reduces its high computational cost of handling high-dimensional
image volumes by introducing the latent space. We compare our NODER with two
recent regression methods, and the experimental results on ADNI and ACDC
datasets demonstrate that our method achieves the state-of-the-art performance
in 3D image regression. Our model needs only a couple of images in a sequence
for prediction, which is practical, especially for clinical situations where
extremely limited image time series are available for analysis. Our source code
is available at https://github.com/ZedKing12138/NODER-pytorch.

摘要：回歸醫療影像序列可以捕捉時間影像模式變化，並預測遺失或未來時間點的影像。然而，現有的測地線迴歸方法限制其迴歸效能，因為其強烈依賴線性動態的基本假設，而基於擴散的方法則具有很高的運算成本，而且缺乏保留影像拓撲的約束。在本文中，我們提出一個稱為 NODER 的基於最佳化的全新架構，它利用神經常微分方程式來捕捉複雜的底層動態，並透過引入潛在空間來降低處理高維度影像體積的高運算成本。我們將 NODER 與兩種最近的迴歸方法進行比較，在 ADNI 和 ACDC 資料集上的實驗結果證明，我們的模型在 3D 影像迴歸中取得了最先進的效能。我們的模型只需要序列中幾個影像即可進行預測，這很實用，特別是在臨床情況下，極其有限的影像時間序列可供分析。我們的原始程式碼可在 https://github.com/ZedKing12138/NODER-pytorch 取得。

##### **Enhancing the Utility of Privacy-Preserving Cancer Classification using Synthetic Data**
2407.12669v1 by Richard Osuala, Daniel M. Lang, Anneliese Riess, Georgios Kaissis, Zuzanna Szafranowska, Grzegorz Skorupko, Oliver Diaz, Julia A. Schnabel, Karim Lekadir

Deep learning holds immense promise for aiding radiologists in breast cancer
detection. However, achieving optimal model performance is hampered by
limitations in availability and sharing of data commonly associated to patient
privacy concerns. Such concerns are further exacerbated, as traditional deep
learning models can inadvertently leak sensitive training information. This
work addresses these challenges exploring and quantifying the utility of
privacy-preserving deep learning techniques, concretely, (i) differentially
private stochastic gradient descent (DP-SGD) and (ii) fully synthetic training
data generated by our proposed malignancy-conditioned generative adversarial
network. We assess these methods via downstream malignancy classification of
mammography masses using a transformer model. Our experimental results depict
that synthetic data augmentation can improve privacy-utility tradeoffs in
differentially private model training. Further, model pretraining on synthetic
data achieves remarkable performance, which can be further increased with
DP-SGD fine-tuning across all privacy guarantees. With this first in-depth
exploration of privacy-preserving deep learning in breast imaging, we address
current and emerging clinical privacy requirements and pave the way towards the
adoption of private high-utility deep diagnostic models. Our reproducible
codebase is publicly available at https://github.com/RichardObi/mammo_dp.

摘要：深度學習在協助放射科醫師進行乳癌偵測方面具有巨大的潛力。然而，由於與病患隱私相關的疑慮，資料的取得與分享受到限制，這阻礙了模型達到最佳效能。由於傳統的深度學習模型可能會無意間洩漏敏感的訓練資訊，這些疑慮進一步加劇。這項研究探討並量化隱私保護深度學習技術的效用，具體來說，(i) 差分隱私隨機梯度下降法 (DP-SGD) 和 (ii) 由我們提出的惡性腫瘤條件生成對抗網路所產生的完全合成訓練資料，以解決這些挑戰。我們透過使用轉換器模型對乳房攝影腫塊進行下游惡性腫瘤分類來評估這些方法。我們的實驗結果顯示，合成資料擴充可以改善差分隱私模型訓練中的隱私效用權衡。此外，在合成資料上進行模型預訓練可獲得顯著的效能，並可透過在所有隱私保證下進行 DP-SGD 微調進一步提升。透過首次深入探討乳房影像中的隱私保護深度學習，我們解決了當前和新興的臨床隱私需求，並為採用私有高實用性深度診斷模型鋪路。我們的可複製程式碼庫已公開於 https://github.com/RichardObi/mammo_dp。

##### **Abstraction Alignment: Comparing Model and Human Conceptual Relationships**
2407.12543v1 by Angie Boggust, Hyemin Bang, Hendrik Strobelt, Arvind Satyanarayan

Abstraction -- the process of generalizing specific examples into broad
reusable patterns -- is central to how people efficiently process and store
information and apply their knowledge to new data. Promisingly, research has
shown that ML models learn representations that span levels of abstraction,
from specific concepts like "bolo tie" and "car tire" to more general concepts
like "CEO" and "model". However, existing techniques analyze these
representations in isolation, treating learned concepts as independent
artifacts rather than an interconnected web of abstraction. As a result,
although we can identify the concepts a model uses to produce its output, it is
difficult to assess if it has learned a human-aligned abstraction of the
concepts that will generalize to new data. To address this gap, we introduce
abstraction alignment, a methodology to measure the agreement between a model's
learned abstraction and the expected human abstraction. We quantify abstraction
alignment by comparing model outputs against a human abstraction graph, such as
linguistic relationships or medical disease hierarchies. In evaluation tasks
interpreting image models, benchmarking language models, and analyzing medical
datasets, abstraction alignment provides a deeper understanding of model
behavior and dataset content, differentiating errors based on their agreement
with human knowledge, expanding the verbosity of current model quality metrics,
and revealing ways to improve existing human abstractions.

摘要：抽象化——將特定範例概括為廣泛可重複使用的模式的過程——是人們有效處理和儲存資訊，並將其知識應用於新資料的核心。有希望的是，研究顯示 ML 模型學習跨越抽象層級的表徵，從「細領帶」和「汽車輪胎」等具體概念到「執行長」和「模型」等更一般的概念。然而，現有的技術孤立地分析這些表徵，將學習到的概念視為獨立的產物，而不是抽象的相互連結網路。因此，儘管我們可以識別模型用來產生其輸出的概念，但很難評估它是否學習到概念的人類對齊抽象，這些概念將概括到新的資料。為了解決這個差距，我們引入了抽象對齊，一種衡量模型學習的抽象與預期的抽象之間一致性的方法。我們透過將模型輸出與人類抽象圖形（例如語言關係或醫療疾病層級結構）進行比較來量化抽象對齊。在解釋影像模型、基準語言模型和分析醫療資料集的評估任務中，抽象對齊提供了對模型行為和資料集內容更深入的理解，根據與人類知識的一致性區分錯誤，擴展當前模型品質指標的詳細程度，並揭示改善現有人類抽象的方法。

##### **Maintenance Strategies for Sewer Pipes with Multi-State Degradation and Deep Reinforcement Learning**
2407.12894v1 by Lisandro A. Jimenez-Roa, Thiago D. Simão, Zaharah Bukhsh, Tiedo Tinga, Hajo Molegraaf, Nils Jansen, Marielle Stoelinga

Large-scale infrastructure systems are crucial for societal welfare, and
their effective management requires strategic forecasting and intervention
methods that account for various complexities. Our study addresses two
challenges within the Prognostics and Health Management (PHM) framework applied
to sewer assets: modeling pipe degradation across severity levels and
developing effective maintenance policies. We employ Multi-State Degradation
Models (MSDM) to represent the stochastic degradation process in sewer pipes
and use Deep Reinforcement Learning (DRL) to devise maintenance strategies. A
case study of a Dutch sewer network exemplifies our methodology. Our findings
demonstrate the model's effectiveness in generating intelligent, cost-saving
maintenance strategies that surpass heuristics. It adapts its management
strategy based on the pipe's age, opting for a passive approach for newer pipes
and transitioning to active strategies for older ones to prevent failures and
reduce costs. This research highlights DRL's potential in optimizing
maintenance policies. Future research will aim improve the model by
incorporating partial observability, exploring various reinforcement learning
algorithms, and extending this methodology to comprehensive infrastructure
management.

摘要：大型基礎設施系統對社會福利至關重要，有效管理這些系統需要策略性預測和干預方法，並考量各種複雜性。我們的研究針對應用於下水道資產的預測和健康管理 (PHM) 框架中的兩個挑戰：對不同嚴重程度的管道劣化進行建模，並制定有效的維護政策。我們採用多狀態劣化模型 (MSDM) 來表示下水道管道中的隨機劣化過程，並使用深度強化學習 (DRL) 來設計維護策略。荷蘭下水道網路的案例研究說明了我們的做法。我們的研究結果證明了該模型在產生超越啟發法的智慧型節省成本維護策略方面的有效性。它根據管道的年齡調整其管理策略，選擇較新的管道採用被動方式，並轉變為較舊管道的積極策略，以防止故障並降低成本。這項研究強調了 DRL 在最佳化維護政策方面的潛力。未來的研究將旨在透過納入部分可觀察性、探索各種強化學習演算法，並將此方法擴展到全面的基礎設施管理，來改善模型。

##### **Search Engines, LLMs or Both? Evaluating Information Seeking Strategies for Answering Health Questions**
2407.12468v2 by Marcos Fernández-Pichel, Juan C. Pichel, David E. Losada

Search engines have traditionally served as primary tools for information
seeking. However, the new Large Language Models (LLMs) have recently
demonstrated remarkable capabilities in multiple tasks and, specifically, their
adoption as question answering systems is becoming increasingly prevalent. It
is expected that LLM-based conversational systems and traditional web engines
will continue to coexist in the future, supporting end users in various ways.
But there is a need for more scientific research on the effectiveness of both
types of systems in facilitating accurate information seeking. In this study,
we focus on their merits in answering health questions. We conducted an
extensive study comparing different web search engines, LLMs and
retrieval-augmented (RAG) approaches. Our research reveals intriguing
conclusions. For example, we observed that the quality of webpages potentially
responding to a health question does not decline as we navigate further down
the ranked lists. However, according to our evaluation, web engines are less
accurate than LLMs in finding correct answers to health questions. On the other
hand, LLMs are quite sensitive to the input prompts, and we also found out that
RAG leads to highly effective information seeking methods.

摘要：搜尋引擎傳統上一直作為尋找資訊的主要工具。然而，新的大型語言模型 (LLM) 近期已在多項任務中展現出卓越的能力，特別是其被採用為問題解答系統正變得越來越普遍。預計未來基於 LLM 的對話系統和傳統網路引擎將持續共存，以各種方式支援最終使用者。但需要更多科學研究來探討這兩種系統在促進準確資訊搜尋方面的效能。在這項研究中，我們專注於它們在回答健康問題方面的優點。我們進行了一項廣泛的研究，比較了不同的網路搜尋引擎、LLM 和檢索增強 (RAG) 方法。我們的研究揭示了有趣的結論。例如，我們觀察到，隨著我們在排名清單中向下瀏覽，可能會回答健康問題的網頁品質並不會下降。然而，根據我們的評估，網路引擎在尋找健康問題的正確答案方面不如 LLM 準確。另一方面，LLM 對輸入提示非常敏感，我們還發現 RAG 導致高度有效的資訊搜尋方法。

##### **Explainable Biomedical Hypothesis Generation via Retrieval Augmented Generation enabled Large Language Models**
2407.12888v1 by Alexander R. Pelletier, Joseph Ramirez, Irsyad Adam, Simha Sankar, Yu Yan, Ding Wang, Dylan Steinecke, Wei Wang, Peipei Ping

The vast amount of biomedical information available today presents a
significant challenge for investigators seeking to digest, process, and
understand these findings effectively. Large Language Models (LLMs) have
emerged as powerful tools to navigate this complex and challenging data
landscape. However, LLMs may lead to hallucinatory responses, making Retrieval
Augmented Generation (RAG) crucial for achieving accurate information. In this
protocol, we present RUGGED (Retrieval Under Graph-Guided Explainable disease
Distinction), a comprehensive workflow designed to support investigators with
knowledge integration and hypothesis generation, identifying validated paths
forward. Relevant biomedical information from publications and knowledge bases
are reviewed, integrated, and extracted via text-mining association analysis
and explainable graph prediction models on disease nodes, forecasting potential
links among drugs and diseases. These analyses, along with biomedical texts,
are integrated into a framework that facilitates user-directed mechanism
elucidation as well as hypothesis exploration through RAG-enabled LLMs. A
clinical use-case demonstrates RUGGED's ability to evaluate and recommend
therapeutics for Arrhythmogenic Cardiomyopathy (ACM) and Dilated Cardiomyopathy
(DCM), analyzing prescribed drugs for molecular interactions and unexplored
uses. The platform minimizes LLM hallucinations, offers actionable insights,
and improves the investigation of novel therapeutics.

摘要：<paragraph>現今大量的生物醫學資訊對試圖有效消化、處理和理解這些發現的研究人員構成重大挑戰。大型語言模型 (LLM) 已成為在這個複雜且具挑戰性的資料環境中導航的強大工具。然而，LLM 可能會導致幻覺反應，這使得檢索擴增生成 (RAG) 對於獲得準確資訊至關重要。在這個協定中，我們提出 RUGGED（圖形導引可解釋疾病區分的檢索），這是一個全面的工作流程，旨在支援研究人員進行知識整合和假設產生，找出經過驗證的進展路徑。來自出版物和知識庫的相關生物醫學資訊會透過文本探勘關聯分析和疾病節點的可解釋圖形預測模型進行檢閱、整合和萃取，預測藥物和疾病之間的潛在關聯。這些分析連同生物醫學文本會整合到一個架構中，該架構促進使用者導向的機制闡明，以及透過 RAG 啟用的 LLM 進行假設探討。一個臨床使用案例展示了 RUGGED 評估和推薦用於心律失常性心肌病變 (ACM) 和擴張型心肌病變 (DCM) 的治療方法的能力，分析處方藥物的分子交互作用和未探索的用途。這個平台將 LLM 幻覺降到最低，提供可操作的見解，並改善新治療方法的研究。</paragraph>

##### **Evaluating graph-based explanations for AI-based recommender systems**
2407.12357v1 by Simon Delarue, Astrid Bertrand, Tiphaine Viard

Recent years have witnessed a rapid growth of recommender systems, providing
suggestions in numerous applications with potentially high social impact, such
as health or justice. Meanwhile, in Europe, the upcoming AI Act mentions
\emph{transparency} as a requirement for critical AI systems in order to
``mitigate the risks to fundamental rights''. Post-hoc explanations seamlessly
align with this goal and extensive literature on the subject produced several
forms of such objects, graphs being one of them. Early studies in visualization
demonstrated the graphs' ability to improve user understanding, positioning
them as potentially ideal explanations. However, it remains unclear how
graph-based explanations compare to other explanation designs. In this work, we
aim to determine the effectiveness of graph-based explanations in improving
users' perception of AI-based recommendations using a mixed-methods approach.
We first conduct a qualitative study to collect users' requirements for graph
explanations. We then run a larger quantitative study in which we evaluate the
influence of various explanation designs, including enhanced graph-based ones,
on aspects such as understanding, usability and curiosity toward the AI system.
We find that users perceive graph-based explanations as more usable than
designs involving feature importance. However, we also reveal that textual
explanations lead to higher objective understanding than graph-based designs.
Most importantly, we highlight the strong contrast between participants'
expressed preferences for graph design and their actual ratings using it, which
are lower compared to textual design. These findings imply that meeting
stakeholders' expressed preferences might not alone guarantee ``good''
explanations. Therefore, crafting hybrid designs successfully balancing social
expectations with downstream performance emerges as a significant challenge.

摘要：<paragraph>近年來推薦系統快速成長，提供各種應用程式建議，具有潛在的高社會影響力，例如健康或司法。同時，在歐洲，即將出台的人工智慧法案提到，關鍵人工智慧系統需要「透明度」，才能「降低對基本權利的風險」。事後解釋與此目標無縫對齊，且該主題的廣泛文獻產生了多種此類物件，其中一種就是圖形。視覺化的早期研究證明了圖形能夠提升使用者理解力，將其定位為潛在的理想解釋。然而，基於圖形的解釋與其他解釋設計相比如何，目前仍不清楚。在這項工作中，我們旨在使用混合方法，來確定基於圖形的解釋在提升使用者對基於人工智慧的建議的感知上的有效性。我們首先進行一項定性研究，以收集使用者對圖形解釋的需求。然後，我們執行一項規模更大的定量研究，評估各種解釋設計的影響，包括增強的基於圖形的設計，對人工智慧系統的理解、可用性和好奇心等面向。我們發現，使用者認為基於圖形的解釋比涉及特徵重要性的設計更可用。然而，我們也發現，文字解釋比基於圖形的設計帶來更高的客觀理解。最重要的是，我們強調了參與者對圖形設計表達的偏好與實際使用圖形設計時的評分之間的強烈對比，與文字設計相比，使用圖形設計的評分較低。這些發現暗示，滿足利害關係人表達的偏好，可能無法單獨保證「良好」的解釋。因此，巧妙設計混合設計，成功平衡社會期望與下游效能，成為一項重大的挑戰。</paragraph>

##### **GPT-4V Cannot Generate Radiology Reports Yet**
2407.12176v1 by Yuyang Jiang, Chacha Chen, Dang Nguyen, Benjamin M. Mervak, Chenhao Tan

GPT-4V's purported strong multimodal abilities raise interests in using it to
automate radiology report writing, but there lacks thorough evaluations. In
this work, we perform a systematic evaluation of GPT-4V in generating radiology
reports on two chest X-ray report datasets: MIMIC-CXR and IU X-Ray. We attempt
to directly generate reports using GPT-4V through different prompting
strategies and find that it fails terribly in both lexical metrics and clinical
efficacy metrics. To understand the low performance, we decompose the task into
two steps: 1) the medical image reasoning step of predicting medical condition
labels from images; and 2) the report synthesis step of generating reports from
(groundtruth) conditions. We show that GPT-4V's performance in image reasoning
is consistently low across different prompts. In fact, the distributions of
model-predicted labels remain constant regardless of which groundtruth
conditions are present on the image, suggesting that the model is not
interpreting chest X-rays meaningfully. Even when given groundtruth conditions
in report synthesis, its generated reports are less correct and less
natural-sounding than a finetuned LLaMA-2. Altogether, our findings cast doubt
on the viability of using GPT-4V in a radiology workflow.

摘要：GPT-4V 所謂強大的多模態能力引起了人們對使用它來自動化放射報告編寫的興趣，但卻缺乏徹底的評估。在這項工作中，我們對 GPT-4V 在兩個胸部 X 光報告數據集：MIMIC-CXR 和 IU X-Ray 上生成放射報告進行了系統評估。我們嘗試通過不同的提示策略直接使用 GPT-4V 生成報告，並發現它在詞彙指標和臨床療效指標上都表現得很糟糕。為了了解低性能，我們將任務分解為兩個步驟：1) 從圖像預測醫療狀況標籤的醫學影像推理步驟；以及 2) 從（真實）條件生成報告的報告合成步驟。我們表明，GPT-4V 在圖像推理中的表現始終低於不同的提示。事實上，模型預測標籤的分布保持不變，無論圖像上存在哪些真實條件，這表明該模型沒有有意義地解釋胸部 X 光。即使在報告合成中給出真實條件，其生成的報告也不如微調後的 LLaMA-2 正確和自然。總之，我們的發現對在放射工作流程中使用 GPT-4V 的可行性提出了質疑。

##### **LLMs-in-the-loop Part-1: Expert Small AI Models for Bio-Medical Text Translation**
2407.12126v2 by Bunyamin Keles, Murat Gunay, Serdar I. Caglar

Machine translation is indispensable in healthcare for enabling the global
dissemination of medical knowledge across languages. However, complex medical
terminology poses unique challenges to achieving adequate translation quality
and accuracy. This study introduces a novel "LLMs-in-the-loop" approach to
develop supervised neural machine translation models optimized specifically for
medical texts. While large language models (LLMs) have demonstrated powerful
capabilities, this research shows that small, specialized models trained on
high-quality in-domain (mostly synthetic) data can outperform even vastly
larger LLMs.
  Custom parallel corpora in six languages were compiled from scientific
articles, synthetically generated clinical documents, and medical texts. Our
LLMs-in-the-loop methodology employs synthetic data generation, rigorous
evaluation, and agent orchestration to enhance performance. We developed small
medical translation models using the MarianMT base model. We introduce a new
medical translation test dataset to standardize evaluation in this domain.
Assessed using BLEU, METEOR, ROUGE, and BERT scores on this test set, our
MarianMT-based models outperform Google Translate, DeepL, and GPT-4-Turbo.
  Results demonstrate that our LLMs-in-the-loop approach, combined with
fine-tuning high-quality, domain-specific data, enables specialized models to
outperform general-purpose and some larger systems. This research, part of a
broader series on expert small models, paves the way for future
healthcare-related AI developments, including deidentification and bio-medical
entity extraction models. Our study underscores the potential of tailored
neural translation models and the LLMs-in-the-loop methodology to advance the
field through improved data generation, evaluation, agent, and modeling
techniques.

摘要：<paragraph>機器翻譯在醫療保健中不可或缺，因為它能讓醫療知識跨語言在全球傳播。然而，複雜的醫療術語對達成適當的翻譯品質和精確度提出了獨特挑戰。本研究介紹了一種新穎的「迴圈中的大型語言模型」方法，用於開發專門針對醫療文本進行最佳化的監督式神經機器翻譯模型。儘管大型語言模型 (LLM) 已展現強大的能力，但本研究顯示，根據高品質領域內 (大多為合成) 資料訓練的小型專門模型，其表現甚至能超越規模龐大的 LLM。
  從科學文章、合成產生的臨床文件和醫療文本中編譯了六種語言的客製化平行語料庫。我們的迴圈中 LLM 方法採用合成資料產生、嚴格評估和代理程式編排來提升效能。我們使用 MarianMT 基礎模型開發了小型醫療翻譯模型。我們引進新的醫療翻譯測試資料集，以標準化此領域的評估。使用此測試集上的 BLEU、METEOR、ROUGE 和 BERT 分數進行評估，我們的 MarianMT 基礎模型表現優於 Google Translate、DeepL 和 GPT-4-Turbo。
  結果顯示，我們的迴圈中 LLM 方法結合微調高品質特定領域資料，能讓專門模型的表現優於一般用途和一些規模較大的系統。本研究是專家小型模型廣泛系列的一部分，為未來的醫療保健相關 AI 發展鋪路，包括去識別化和生物醫學實體萃取模型。我們的研究強調了客製化神經翻譯模型和迴圈中 LLM 方法的潛力，它們能透過改善資料產生、評估、代理程式和建模技術，讓這個領域進步。</paragraph>

##### **Schema Matching with Large Language Models: an Experimental Study**
2407.11852v1 by Marcel Parciak, Brecht Vandevoort, Frank Neven, Liesbet M. Peeters, Stijn Vansummeren

Large Language Models (LLMs) have shown useful applications in a variety of
tasks, including data wrangling. In this paper, we investigate the use of an
off-the-shelf LLM for schema matching. Our objective is to identify semantic
correspondences between elements of two relational schemas using only names and
descriptions. Using a newly created benchmark from the health domain, we
propose different so-called task scopes. These are methods for prompting the
LLM to do schema matching, which vary in the amount of context information
contained in the prompt. Using these task scopes we compare LLM-based schema
matching against a string similarity baseline, investigating matching quality,
verification effort, decisiveness, and complementarity of the approaches. We
find that matching quality suffers from a lack of context information, but also
from providing too much context information. In general, using newer LLM
versions increases decisiveness. We identify task scopes that have acceptable
verification effort and succeed in identifying a significant number of true
semantic matches. Our study shows that LLMs have potential in bootstrapping the
schema matching process and are able to assist data engineers in speeding up
this task solely based on schema element names and descriptions without the
need for data instances.

摘要：大型語言模型 (LLM) 已在各種任務中展現出有用的應用，包括資料整理。在本文中，我們探討現成 LLM 在架構比對中的用途。我們的目標是僅使用名稱和描述，找出兩個關聯式架構的元素之間的語意對應。使用從健康領域新建立的基準，我們提出不同的所謂任務範圍。這些方法是用於提示 LLM 進行架構比對，其包含在提示中的脈絡資訊量有所不同。使用這些任務範圍，我們將基於 LLM 的架構比對與字串相似性基準進行比較，探討比對品質、驗證工作、果斷性，以及方法的互補性。我們發現比對品質會受到脈絡資訊不足以及提供過多脈絡資訊的影響。一般來說，使用較新的 LLM 版本會增加果斷性。我們找出具有可接受驗證工作，並成功找出大量真實語意比對的任務範圍。我們的研究顯示，LLM 有助於引導架構比對流程，並且能夠協助資料工程師僅根據架構元素名稱和描述加速此任務，而不需要資料實例。

##### **GPT Assisted Annotation of Rhetorical and Linguistic Features for Interpretable Propaganda Technique Detection in News Text**
2407.11827v1 by Kyle Hamilton, Luca Longo, Bojan Bozic

While the use of machine learning for the detection of propaganda techniques
in text has garnered considerable attention, most approaches focus on
"black-box" solutions with opaque inner workings. Interpretable approaches
provide a solution, however, they depend on careful feature engineering and
costly expert annotated data. Additionally, language features specific to
propagandistic text are generally the focus of rhetoricians or linguists, and
there is no data set labeled with such features suitable for machine learning.
This study codifies 22 rhetorical and linguistic features identified in
literature related to the language of persuasion for the purpose of annotating
an existing data set labeled with propaganda techniques. To help human experts
annotate natural language sentences with these features, RhetAnn, a web
application, was specifically designed to minimize an otherwise considerable
mental effort. Finally, a small set of annotated data was used to fine-tune
GPT-3.5, a generative large language model (LLM), to annotate the remaining
data while optimizing for financial cost and classification accuracy. This
study demonstrates how combining a small number of human annotated examples
with GPT can be an effective strategy for scaling the annotation process at a
fraction of the cost of traditional annotation relying solely on human experts.
The results are on par with the best performing model at the time of writing,
namely GPT-4, at 10x less the cost. Our contribution is a set of features,
their properties, definitions, and examples in a machine-readable format, along
with the code for RhetAnn and the GPT prompts and fine-tuning procedures for
advancing state-of-the-art interpretable propaganda technique detection.

摘要：<paragraph>儘管使用機器學習來偵測宣傳技巧在文本中已獲得相當的關注，但大多數方法都專注於具有不透明內部運作的「黑盒子」解決方案。可解釋的方法提供了解決方案，然而，它們依賴於仔細的特徵工程和昂貴的專家註釋資料。此外，宣傳性文本的特定語言特徵通常是修辭學家或語言學家的關注焦點，並且沒有標記有此類特徵的資料集適合機器學習。本研究將出現在與說服語言相關的文獻中識別出的 22 個修辭和語言特徵編纂成法典，目的是為標記有宣傳技巧的現有資料集。為了幫助人類專家使用這些特徵註釋自然語言句子，專門設計了網路應用程式 RhetAnn，以最大程度地減少原本相當大的心智負擔。最後，使用一小組註釋資料微調了生成式大型語言模型 (LLM) GPT-3.5，以註釋剩餘資料，同時針對財務成本和分類準確度進行最佳化。本研究展示了將少數人類註釋範例與 GPT 結合如何成為以傳統僅依賴人類專家的註釋成本的一小部分來擴展註釋程序的有效策略。在撰寫本文時，結果與當時表現最佳的模型 GPT-4 相當，成本卻低了 10 倍。我們的貢獻是一組特徵、它們的屬性、定義和範例，採用機器可讀格式，以及 RhetAnn 的程式碼和 GPT 提示和微調程序，用於推進最先進的可解釋宣傳技巧偵測。</paragraph>

##### **Characterizing and Understanding HGNN Training on GPUs**
2407.11790v2 by Dengke Han, Mingyu Yan, Xiaochun Ye, Dongrui Fan, Ninghui Sun

Owing to their remarkable representation capabilities for heterogeneous graph
data, Heterogeneous Graph Neural Networks (HGNNs) have been widely adopted in
many critical real-world domains such as recommendation systems and medical
analysis. Prior to their practical application, identifying the optimal HGNN
model parameters tailored to specific tasks through extensive training is a
time-consuming and costly process. To enhance the efficiency of HGNN training,
it is essential to characterize and analyze the execution semantics and
patterns within the training process to identify performance bottlenecks. In
this study, we conduct an in-depth quantification and analysis of two
mainstream HGNN training scenarios, including single-GPU and multi-GPU
distributed training. Based on the characterization results, we disclose the
performance bottlenecks and their underlying causes in different HGNN training
scenarios and provide optimization guidelines from both software and hardware
perspectives.

摘要：由於異質圖形神經網路 (HGNN) 對異質圖形資料有卓越的表示能力，因此已廣泛用於許多重要的真實世界領域，例如推薦系統和醫療分析。在實際應用之前，透過廣泛的訓練來找出針對特定任務量身打造的最佳 HGNN 模型參數，是一個耗時且昂貴的過程。為了提高 HGNN 訓練的效率，必須對訓練過程中執行語義和模式進行特徵化和分析，以找出效能瓶頸。在本研究中，我們對兩個主流 HGNN 訓練場景進行深入的量化和分析，包括單一 GPU 和多 GPU 分散式訓練。根據特徵化結果，我們揭露了不同 HGNN 訓練場景中的效能瓶頸及其根本原因，並從軟體和硬體角度提供最佳化準則。

##### **CCoE: A Compact LLM with Collaboration of Experts**
2407.11686v3 by Shaomang Huang, Jianfeng Pan, Hanzhong Zheng

In the domain of Large Language Model (LLM), LLMs demonstrate significant
capabilities in natural language understanding and generation. With the growing
needs of applying LLMs on various domains, it is a research question that how
to efficiently train and build a model that has expertise in different domains
but with a low training cost. We propose CCoE architecture, a framework of
easily coupling multiple strong domain experts together to fuse into a big LLM,
provides a collective way of utilizing the different domain expert LLMs.
Besides, training a large collaborative of multiple expert LLMs requires a high
requirements on training sources. CCoE bypasses this problem through isolating
other experts and train each expert separately. The design of CCoE assembles
multiple expert LLMs through the CoE (Collaboration of Experts) layer. Each CoE
layer could have one or more expert LLMs. Expert LLMs have different number of
layers and have been well-trained for different domain tasks. Each expert is
fine-tuned to be able to achieve the comparable results with SOTA domain LLMs.
We start from 5 experts in the domain of Code, Math, Law, text-to-SQL and
Medical. The results indicate that our CCoE framework can easily and
efficiently boost nearly 10%-20% performance on original base model in
different domains but using less resources on training, as well as inference.

摘要：在大語言模型（LLM）領域中，LLM 在自然語言理解和生成方面展現出顯著的能力。隨著 LLM 在各種領域應用的需求日益增長，如何有效訓練和建立一個在不同領域具有專業知識但訓練成本低的模型，是一個研究問題。我們提出 CCoE 架構，一個將多個強大的領域專家輕鬆結合在一起以融合成一個大型 LLM 的框架，提供了一種利用不同領域專家 LLM 的集合方式。此外，訓練多個專家 LLM 的大型協作需要對訓練來源提出很高的要求。CCoE 通過隔離其他專家並分別訓練每個專家來繞過這個問題。CCoE 的設計通過 CoE（專家協作）層組裝多個專家 LLM。每個 CoE 層可以有一個或多個專家 LLM。專家 LLM 具有不同的層數，並且已經針對不同的領域任務接受過良好的訓練。每個專家都經過微調，能夠達到與 SOTA 領域 LLM 相當的結果。我們從程式碼、數學、法律、文字轉 SQL 和醫學領域的 5 位專家開始。結果表明，我們的 CCoE 框架可以輕鬆有效地提升不同領域中原始基礎模型的性能近 10%-20%，但訓練和推理使用的資源更少。

##### **CCVA-FL: Cross-Client Variations Adaptive Federated Learning for Medical Imaging**
2407.11652v2 by Sunny Gupta, Amit Sethi

Federated Learning (FL) offers a privacy-preserving approach to train models
on decentralized data. Its potential in healthcare is significant, but
challenges arise due to cross-client variations in medical image data,
exacerbated by limited annotations. This paper introduces Cross-Client
Variations Adaptive Federated Learning (CCVA-FL) to address these issues.
CCVA-FL aims to minimize cross-client variations by transforming images into a
common feature space. It involves expert annotation of a subset of images from
each client, followed by the selection of a client with the least data
complexity as the target. Synthetic medical images are then generated using
Scalable Diffusion Models with Transformers (DiT) based on the target client's
annotated images. These synthetic images, capturing diversity and representing
the original data, are shared with other clients. Each client then translates
its local images into the target image space using image-to-image translation.
The translated images are subsequently used in a federated learning setting to
develop a server model. Our results demonstrate that CCVA-FL outperforms
Vanilla Federated Averaging by effectively addressing data distribution
differences across clients without compromising privacy.

摘要：聯邦學習 (FL) 提供一種保護隱私的方法，可以在分散式數據上訓練模型。其在醫療保健中的潛力很大，但由於醫療影像數據中的跨客戶差異，加上註釋有限，因此產生了挑戰。本文介紹跨客戶差異自適應聯邦學習 (CCVA-FL) 來解決這些問題。CCVA-FL 旨在透過將影像轉換到一個共同特徵空間來最小化跨客戶差異。它涉及從每個客戶端中的一個影像子集進行專家註釋，然後選擇數據複雜性最低的客戶端作為目標。然後使用基於目標客戶端註釋影像的可擴充擴散模型與 Transformer (DiT) 來產生合成醫療影像。這些合成影像擷取多樣性並代表原始數據，並與其他客戶端共享。然後，每個客戶端使用影像到影像翻譯，將其本地影像轉換到目標影像空間。翻譯後的影像隨後用於聯邦學習設定，以開發伺服器模型。我們的結果證明，CCVA-FL 透過有效解決客戶端之間的數據分佈差異，在不損害隱私的情況下，優於香草聯邦平均。

##### **Improving Engagement and Efficacy of mHealth Micro-Interventions for Stress Coping: an In-The-Wild Study**
2407.11612v1 by Chaya Ben Yehuda, Ran Gilad-Bachrach, Yarin Udi

Sustaining long-term user engagement with mobile health (mHealth)
interventions while preserving their high efficacy remains an ongoing challenge
in real-world well-being applications. To address this issue, we introduce a
new algorithm, the Personalized, Context-Aware Recommender (PCAR), for
intervention selection and evaluate its performance in a field experiment. In a
four-week, in-the-wild experiment involving 29 parents of young children, we
delivered personalized stress-reducing micro-interventions through a mobile
chatbot. We assessed their impact on stress reduction using momentary stress
level ecological momentary assessments (EMAs) before and after each
intervention. Our findings demonstrate the superiority of PCAR intervention
selection in enhancing the engagement and efficacy of mHealth
micro-interventions to stress coping compared to random intervention selection
and a control group that did not receive any intervention. Furthermore, we show
that even brief, one-minute interventions can significantly reduce perceived
stress levels (p=0.001). We observe that individuals are most receptive to
one-minute interventions during transitional periods between activities, such
as transitioning from afternoon activities to bedtime routines. Our study
contributes to the literature by introducing a personalized context-aware
intervention selection algorithm that improves engagement and efficacy of
mHealth interventions, identifying key timing for stress interventions, and
offering insights into mechanisms to improve stress coping.

摘要：<paragraph>在維持行動健康 (mHealth) 干預措施的長期使用者參與度，同時維持其高功效，在現實世界的健康應用中仍是一個持續的挑戰。為了解決這個問題，我們引入了一種新的演算法，稱為個人化、情境感知推薦器 (PCAR)，用於干預選擇，並在實地實驗中評估其效能。在為期四週的野外實驗中，涉及 29 位幼兒的父母，我們透過行動聊天機器人傳遞個人化的減壓微型干預措施。我們透過在每次干預措施前後進行的瞬間壓力等級生態瞬時評估 (EMA)，評估它們對減壓的影響。我們的研究結果證明了 PCAR 干預選擇在增強 mHealth 微型干預措施對壓力應對的參與度和效能方面的優越性，相較於隨機干預選擇和未接受任何干預措施的對照組。此外，我們證明了即使簡短的一分鐘干預措施也能顯著降低感知壓力等級 (p=0.001)。我們觀察到，個人在活動之間的過渡期（例如從下午活動過渡到就寢時間）對一分鐘的干預措施最具接受度。我們的研究透過引入一種個人化情境感知干預選擇演算法，改善 mHealth 干預措施的參與度和效能，找出壓力干預措施的關鍵時機，並提供改善壓力應對機制的見解，為文獻做出貢獻。</paragraph>

##### **DiNO-Diffusion. Scaling Medical Diffusion via Self-Supervised Pre-Training**
2407.11594v1 by Guillermo Jimenez-Perez, Pedro Osorio, Josef Cersovsky, Javier Montalt-Tordera, Jens Hooge, Steffen Vogler, Sadegh Mohammadi

Diffusion models (DMs) have emerged as powerful foundation models for a
variety of tasks, with a large focus in synthetic image generation. However,
their requirement of large annotated datasets for training limits their
applicability in medical imaging, where datasets are typically smaller and
sparsely annotated. We introduce DiNO-Diffusion, a self-supervised method for
training latent diffusion models (LDMs) that conditions the generation process
on image embeddings extracted from DiNO. By eliminating the reliance on
annotations, our training leverages over 868k unlabelled images from public
chest X-Ray (CXR) datasets. Despite being self-supervised, DiNO-Diffusion shows
comprehensive manifold coverage, with FID scores as low as 4.7, and emerging
properties when evaluated in downstream tasks. It can be used to generate
semantically-diverse synthetic datasets even from small data pools,
demonstrating up to 20% AUC increase in classification performance when used
for data augmentation. Images were generated with different sampling strategies
over the DiNO embedding manifold and using real images as a starting point.
Results suggest, DiNO-Diffusion could facilitate the creation of large datasets
for flexible training of downstream AI models from limited amount of real data,
while also holding potential for privacy preservation. Additionally,
DiNO-Diffusion demonstrates zero-shot segmentation performance of up to 84.4%
Dice score when evaluating lung lobe segmentation. This evidences good CXR
image-anatomy alignment, akin to segmenting using textual descriptors on
vanilla DMs. Finally, DiNO-Diffusion can be easily adapted to other medical
imaging modalities or state-of-the-art diffusion models, opening the door for
large-scale, multi-domain image generation pipelines for medical imaging.

摘要：擴散模型 (DM) 已成為各種任務中強大的基礎模型，特別是合成影像生成。然而，它們在訓練中對大型標註資料集的要求限制了它們在醫療影像中的應用，而醫療影像的資料集通常較小且標註稀疏。我們引入了 DiNO-Diffusion，這是一種用於訓練條件生成過程的潛在擴散模型 (LDM) 的自監督方法，該過程基於從 DiNO 中提取的影像嵌入。透過消除對標註的依賴，我們的訓練利用了來自公共胸部 X 光 (CXR) 資料集的超過 868k 張未標註影像。儘管是自監督的，但 DiNO-Diffusion 顯示出全面的流形覆蓋，FID 分數低至 4.7，並且在評估下游任務時出現了新興的屬性。它可用於從小型資料庫生成語義多樣的合成資料集，在用於資料擴充時，分類效能提升幅度高達 20% AUC。影像是在 DiNO 嵌入流形上使用不同的取樣策略生成的，並使用真實影像作為起點。結果顯示，DiNO-Diffusion 可以促進從有限的真實資料中靈活訓練下游 AI 模型的大型資料集的建立，同時也具有隱私保護的潛力。此外，DiNO-Diffusion 在評估肺葉分割時展示了高達 84.4% 的 Dice 分數的零次學習分割效能。這證明了良好的 CXR 影像解剖對齊，類似於在香草 DM 上使用文字描述符進行分割。最後，DiNO-Diffusion 可以輕鬆適應其他醫療影像方式或最先進的擴散模型，為醫療影像的大規模、多領域影像生成管道開啟了大門。

##### **Probing the Efficacy of Federated Parameter-Efficient Fine-Tuning of Vision Transformers for Medical Image Classification**
2407.11573v1 by Naif Alkhunaizi, Faris Almalik, Rouqaiah Al-Refai, Muzammal Naseer, Karthik Nandakumar

With the advent of large pre-trained transformer models, fine-tuning these
models for various downstream tasks is a critical problem. Paucity of training
data, the existence of data silos, and stringent privacy constraints exacerbate
this fine-tuning problem in the medical imaging domain, creating a strong need
for algorithms that enable collaborative fine-tuning of pre-trained models.
Moreover, the large size of these models necessitates the use of
parameter-efficient fine-tuning (PEFT) to reduce the communication burden in
federated learning. In this work, we systematically investigate various
federated PEFT strategies for adapting a Vision Transformer (ViT) model
(pre-trained on a large natural image dataset) for medical image
classification. Apart from evaluating known PEFT techniques, we introduce new
federated variants of PEFT algorithms such as visual prompt tuning (VPT),
low-rank decomposition of visual prompts, stochastic block attention
fine-tuning, and hybrid PEFT methods like low-rank adaptation (LoRA)+VPT.
Moreover, we perform a thorough empirical analysis to identify the optimal PEFT
method for the federated setting and understand the impact of data distribution
on federated PEFT, especially for out-of-domain (OOD) and non-IID data. The key
insight of this study is that while most federated PEFT methods work well for
in-domain transfer, there is a substantial accuracy vs. efficiency trade-off
when dealing with OOD and non-IID scenarios, which is commonly the case in
medical imaging. Specifically, every order of magnitude reduction in
fine-tuned/exchanged parameters can lead to a 4% drop in accuracy. Thus, the
initial model choice is crucial for federated PEFT. It is preferable to use
medical foundation models learned from in-domain medical image data (if
available) rather than general vision models.

摘要：<paragraph>隨著大型預訓練轉換器模型的出現，針對各種下游任務微調這些模型是一個關鍵問題。訓練資料的稀缺性、資料孤島的存在以及嚴格的隱私限制會加劇醫療影像領域中的微調問題，這對能讓預訓練模型進行協作微調的演算法產生了強烈需求。此外，這些模型的龐大規模需要使用參數有效微調 (PEFT) 來降低聯合學習中的通訊負擔。在這項工作中，我們系統性地探討了各種聯合 PEFT 策略，以調整視覺轉換器 (ViT) 模型（在大型自然影像資料集上預先訓練）以進行醫療影像分類。除了評估已知的 PEFT 技術外，我們還引入了 PEFT 演算法的新聯合變體，例如視覺提示調整 (VPT)、視覺提示的低秩分解、隨機區塊注意力微調，以及低秩適應 (LoRA)+VPT 等混合 PEFT 方法。此外，我們進行了徹底的經驗分析，以找出聯合設定的最佳 PEFT 方法，並了解資料分佈對聯合 PEFT 的影響，特別是對於領域外 (OOD) 和非獨立同分佈 (non-IID) 資料。這項研究的主要見解是，儘管大多數聯合 PEFT 方法都適用於領域內轉移，但在處理 OOD 和非獨立同分佈場景時，會有大幅的準確度與效率折衷，這通常是醫療影像中的情況。具體來說，微調/交換參數的每個數量級減少都可能導致準確度下降 4%。因此，初始模型的選擇對於聯合 PEFT 至關重要。最好使用從領域內醫學影像資料（如果有的話）學習的醫學基礎模型，而不是一般視覺模型。</paragraph>

##### **Fine-Tuning Medical Language Models for Enhanced Long-Contextual Understanding and Domain Expertise**
2407.11536v1 by Qimin Yang, Rongsheng Wang, Jiexin Chen, Runqi Su, Tao Tan

Large Language Models (LLMs) have been widely applied in various professional
fields. By fine-tuning the models using domain specific question and answer
datasets, the professional domain knowledge and Q\&A abilities of these models
have significantly improved, for example, medical professional LLMs that use
fine-tuning of doctor-patient Q\&A data exhibit extraordinary disease
diagnostic abilities. However, we observed that despite improvements in
specific domain knowledge, the performance of medical LLM in long-context
understanding has significantly declined, especially compared to general
language models with similar parameters. The purpose of this study is to
investigate the phenomenon of reduced performance in understanding long-context
in medical LLM. We designed a series of experiments to conduct open-book
professional knowledge exams on all models to evaluate their ability to read
long-context. By adjusting the proportion and quantity of general data and
medical data in the process of fine-tuning, we can determine the best data
composition to optimize the professional model and achieve a balance between
long-context performance and specific domain knowledge.

摘要：大型語言模型 (LLM) 已廣泛應用於各種專業領域。通過使用特定領域的問答資料集微調模型，這些模型的專業領域知識和問答能力已顯著提升，例如，使用醫生-患者問答資料進行微調的醫療專業 LLM 展現出非凡的疾病診斷能力。然而，我們觀察到，儘管特定領域知識有所提升，但醫療 LLM 在長語境理解方面的表現卻大幅下降，尤其是與具有類似參數的一般語言模型相比。本研究的目的是探討醫療 LLM 在理解長語境方面的表現下降現象。我們設計了一系列實驗，對所有模型進行開放式專業知識考試，以評估它們閱讀長語境的理解能力。通過調整微調過程中一般資料和醫療資料的比例和數量，我們可以確定最佳資料組合，以優化專業模型，並在長語境表現和特定領域知識之間取得平衡。

##### **Cross-Phase Mutual Learning Framework for Pulmonary Embolism Identification on Non-Contrast CT Scans**
2407.11529v1 by Bizhe Bai, Yan-Jie Zhou, Yujian Hu, Tony C. W. Mok, Yilang Xiang, Le Lu, Hongkun Zhang, Minfeng Xu

Pulmonary embolism (PE) is a life-threatening condition where rapid and
accurate diagnosis is imperative yet difficult due to predominantly atypical
symptomatology. Computed tomography pulmonary angiography (CTPA) is
acknowledged as the gold standard imaging tool in clinics, yet it can be
contraindicated for emergency department (ED) patients and represents an
onerous procedure, thus necessitating PE identification through non-contrast CT
(NCT) scans. In this work, we explore the feasibility of applying a
deep-learning approach to NCT scans for PE identification. We propose a novel
Cross-Phase Mutual learNing framework (CPMN) that fosters knowledge transfer
from CTPA to NCT, while concurrently conducting embolism segmentation and
abnormality classification in a multi-task manner. The proposed CPMN leverages
the Inter-Feature Alignment (IFA) strategy that enhances spatial contiguity and
mutual learning between the dual-pathway network, while the Intra-Feature
Discrepancy (IFD) strategy can facilitate precise segmentation of PE against
complex backgrounds for single-pathway networks. For a comprehensive assessment
of the proposed approach, a large-scale dual-phase dataset containing 334 PE
patients and 1,105 normal subjects has been established. Experimental results
demonstrate that CPMN achieves the leading identification performance, which is
95.4\% and 99.6\% in patient-level sensitivity and specificity on NCT scans,
indicating the potential of our approach as an economical, accessible, and
precise tool for PE identification in clinical practice.

摘要：肺栓塞 (PE) 是一種危及生命的疾病，快速且準確的診斷至關重要，但由於症狀主要是非典型的，因此很難診斷。電腦斷層肺血管攝影 (CTPA) 被公認為診所中的黃金標準影像工具，但它可能會對急診部門 (ED) 的患者禁忌，並且代表著繁重的程序，因此需要透過非對比 CT (NCT) 掃描來識別 PE。在這項工作中，我們探討了將深度學習方法應用於 NCT 掃描以識別 PE 的可行性。我們提出了一個新穎的跨相位互學習框架 (CPMN)，它促進了從 CTPA 到 NCT 的知識轉移，同時以多任務的方式進行栓塞分割和異常分類。所提出的 CPMN 採用了特徵間對齊 (IFA) 策略，它增強了雙路徑網路之間的空間連續性和相互學習，而特徵內差異 (IFD) 策略可以促進單路徑網路對複雜背景中的 PE 進行精確分割。為了對所提出的方法進行全面評估，已經建立了一個包含 334 名 PE 患者和 1,105 名正常受試者的、大規模雙相位數據集。實驗結果表明，CPMN 達到了領先的識別效能，在 NCT 掃描中，患者層級的敏感性和特異性分別為 95.4% 和 99.6%，這表明我們的做法有可能成為一種經濟、易於取得且精確的 PE 識別工具，可應用於臨床實務。

##### **Multi-Channel Masked Autoencoder and Comprehensive Evaluations for Reconstructing 12-Lead ECG from Arbitrary Single-Lead ECG**
2407.11481v1 by Jiarong Chen, Wanqing Wu, Tong Liu, Shenda Hong

In the context of cardiovascular diseases (CVD) that exhibit an elevated
prevalence and mortality, the electrocardiogram (ECG) is a popular and standard
diagnostic tool for doctors, commonly utilizing a 12-lead configuration in
clinical practice. However, the 10 electrodes placed on the surface would cause
a lot of inconvenience and discomfort, while the rapidly advancing wearable
devices adopt the reduced-lead or single-lead ECG to reduce discomfort as a
solution in long-term monitoring. Since the single-lead ECG is a subset of
12-lead ECG, it provides insufficient cardiac health information and plays a
substandard role in real-world healthcare applications. Hence, it is necessary
to utilize signal generation technologies to reduce their clinical importance
gap by reconstructing 12-lead ECG from the real single-lead ECG. Specifically,
this study proposes a multi-channel masked autoencoder (MCMA) for this goal. In
the experimental results, the visualized results between the generated and real
signals can demonstrate the effectiveness of the proposed framework. At the
same time, this study introduces a comprehensive evaluation benchmark named
ECGGenEval, encompassing the signal-level, feature-level, and diagnostic-level
evaluations, providing a holistic assessment of 12-lead ECG signals and
generative model. Further, the quantitative experimental results are as
follows, the mean square errors of 0.0178 and 0.0658, correlation coefficients
of 0.7698 and 0.7237 in the signal-level evaluation, the average F1-score with
two generated 12-lead ECG is 0.8319 and 0.7824 in the diagnostic-level
evaluation, achieving the state-of-the-art performance. The open-source code is
publicly available at \url{https://github.com/CHENJIAR3/MCMA}.

摘要：<paragraph>在表現出高盛行率和死亡率的心血管疾病 (CVD) 的情況下，心電圖 (ECG) 是一種醫生常用的標準診斷工具，在臨床實務中通常使用 12 導程組態。然而，放置在表面的 10 個電極會造成許多不便和不適，而快速進步的可穿戴式裝置採用減少導程或單導程 ECG 來降低不適，作為長期監測的解決方案。由於單導程 ECG 是 12 導程 ECG 的子集，它提供的健康資訊不足，在真實世界的醫療保健應用中扮演著次標準的角色。因此，有必要利用訊號產生技術來縮小其臨床重要性差距，方法是從真實的單導程 ECG 重建 12 導程 ECG。具體來說，本研究提出了一個多通道遮罩自動編碼器 (MCMA) 來達成此目標。在實驗結果中，生成的訊號與真實訊號之間的可視化結果可以證明所提出架構的有效性。同時，本研究引入了稱為 ECGGenEval 的綜合評估基準，涵蓋訊號層級、特徵層級和診斷層級評估，提供 12 導程 ECG 訊號和生成模型的整體評估。此外，定量的實驗結果如下，在訊號層級評估中，均方誤差為 0.0178 和 0.0658，相關係數為 0.7698 和 0.7237，在診斷層級評估中，兩個生成的 12 導程 ECG 的平均 F1 分數為 0.8319 和 0.7824，達到了最先進的效能。開放原始碼可以在 \url{https://github.com/CHENJIAR3/MCMA} 公開取得。</paragraph>

##### **TM-PATHVQA:90000+ Textless Multilingual Questions for Medical Visual Question Answering**
2407.11383v1 by Tonmoy Rajkhowa, Amartya Roy Chowdhury, Sankalp Nagaonkar, Achyut Mani Tripathi

In healthcare and medical diagnostics, Visual Question Answering (VQA)
mayemergeasapivotal tool in scenarios where analysis of intricate medical
images becomes critical for accurate diagnoses. Current text-based VQA systems
limit their utility in scenarios where hands-free interaction and accessibility
are crucial while performing tasks. A speech-based VQA system may provide a
better means of interaction where information can be accessed while performing
tasks simultaneously. To this end, this work implements a speech-based VQA
system by introducing a Textless Multilingual Pathological VQA (TMPathVQA)
dataset, an expansion of the PathVQA dataset, containing spoken questions in
English, German & French. This dataset comprises 98,397 multilingual spoken
questions and answers based on 5,004 pathological images along with 70 hours of
audio. Finally, this work benchmarks and compares TMPathVQA systems implemented
using various combinations of acoustic and visual features.

摘要：在醫療保健和醫療診斷中，視覺問答（VQA）可能成為關鍵工具，在分析複雜的醫療影像對於準確診斷至關重要的場景中。目前的基於文字的 VQA 系統限制了它們在執行任務時免持互動和可及性至關重要的場景中的效用。基於語音的 VQA 系統可能提供更好的互動方式，可以在執行任務的同時存取資訊。為此，本研究透過導入無文字多語言病理 VQA（TMPathVQA）資料集，擴充了 PathVQA 資料集，包含英語、德語和法語的口說問題，實作了一個基於語音的 VQA 系統。此資料集包含 98,397 個多語言的口說問題和答案，基於 5,004 個病理影像以及 70 小時的音訊。最後，本研究使用各種音訊和視覺特徵的組合來實作 TMPathVQA 系統，並進行基準測試和比較。

##### **Performance Evaluation of Lightweight Open-source Large Language Models in Pediatric Consultations: A Comparative Analysis**
2407.15862v1 by Qiuhong Wei, Ying Cui, Mengwei Ding, Yanqin Wang, Lingling Xiang, Zhengxiong Yao, Ceran Chen, Ying Long, Zhezhen Jin, Ximing Xu

Large language models (LLMs) have demonstrated potential applications in
medicine, yet data privacy and computational burden limit their deployment in
healthcare institutions. Open-source and lightweight versions of LLMs emerge as
potential solutions, but their performance, particularly in pediatric settings
remains underexplored. In this cross-sectional study, 250 patient consultation
questions were randomly selected from a public online medical forum, with 10
questions from each of 25 pediatric departments, spanning from December 1,
2022, to October 30, 2023. Two lightweight open-source LLMs, ChatGLM3-6B and
Vicuna-7B, along with a larger-scale model, Vicuna-13B, and the widely-used
proprietary ChatGPT-3.5, independently answered these questions in Chinese
between November 1, 2023, and November 7, 2023. To assess reproducibility, each
inquiry was replicated once. We found that ChatGLM3-6B demonstrated higher
accuracy and completeness than Vicuna-13B and Vicuna-7B (P < .001), but all
were outperformed by ChatGPT-3.5. ChatGPT-3.5 received the highest ratings in
accuracy (65.2%) compared to ChatGLM3-6B (41.2%), Vicuna-13B (11.2%), and
Vicuna-7B (4.4%). Similarly, in completeness, ChatGPT-3.5 led (78.4%), followed
by ChatGLM3-6B (76.0%), Vicuna-13B (34.8%), and Vicuna-7B (22.0%) in highest
ratings. ChatGLM3-6B matched ChatGPT-3.5 in readability, both outperforming
Vicuna models (P < .001). In terms of empathy, ChatGPT-3.5 outperformed the
lightweight LLMs (P < .001). In safety, all models performed comparably well (P
> .05), with over 98.4% of responses being rated as safe. Repetition of
inquiries confirmed these findings. In conclusion, Lightweight LLMs demonstrate
promising application in pediatric healthcare. However, the observed gap
between lightweight and large-scale proprietary LLMs underscores the need for
continued development efforts.

摘要：大型語言模型 (LLM) 已展現出在醫療保健領域的潛在應用，但資料隱私和運算負擔限制了它們在醫療保健機構中的部署。開放原始碼和輕量級版本的 LLM 成為潛在的解決方案，但它們的效能，特別是在兒科領域的效能，仍未被充分探討。在這項橫斷面研究中，從一個公開的線上醫療論壇中隨機選取了 250 個患者諮詢問題，每個兒科部門各 10 個問題，時間跨度從 2022 年 12 月 1 日到 2023 年 10 月 30 日。兩個輕量級的開放原始碼 LLM，ChatGLM3-6B 和 Vicuna-7B，以及一個更大規模的模型 Vicuna-13B，還有廣泛使用的專有 ChatGPT-3.5，在 2023 年 11 月 1 日到 2023 年 11 月 7 日期間獨立用中文回答了這些問題。為了評估可複製性，每個查詢都複製了一次。我們發現 ChatGLM3-6B 的準確性和完整性高於 Vicuna-13B 和 Vicuna-7B (P < .001)，但所有這些都低於 ChatGPT-3.5。ChatGPT-3.5 在準確性方面獲得了最高評分 (65.2%)，而 ChatGLM3-6B (41.2%)、Vicuna-13B (11.2%) 和 Vicuna-7B (4.4%) 的評分較低。同樣地，在完整性方面，ChatGPT-3.5 領先 (78.4%)，其次是 ChatGLM3-6B (76.0%)、Vicuna-13B (34.8%) 和 Vicuna-7B (22.0%) 的評分最高。ChatGLM3-6B 在可讀性方面與 ChatGPT-3.5 相匹配，兩者都優於 Vicuna 模型 (P < .001)。在同理心方面，ChatGPT-3.5 優於輕量級 LLM (P < .001)。在安全性方面，所有模型的表現都相當好 (P > .05)，超過 98.4% 的回應被評為安全。查詢的重複確認了這些發現。結論是，輕量級 LLM 展示了在兒科醫療保健中的應用前景。然而，在輕量級和大型專有 LLM 之間觀察到的差距強調了持續開發工作的重要性。

##### **Leveraging Multimodal CycleGAN for the Generation of Anatomically Accurate Synthetic CT Scans from MRIs**
2407.10888v1 by Leonardo Crespi, Samuele Camnasio, Damiano Dei, Nicola Lambri, Pietro Mancosu, Marta Scorsetti, Daniele Loiacono

In many clinical settings, the use of both Computed Tomography (CT) and
Magnetic Resonance (MRI) is necessary to pursue a thorough understanding of the
patient's anatomy and to plan a suitable therapeutical strategy; this is often
the case in MRI-based radiotherapy, where CT is always necessary to prepare the
dose delivery, as it provides the essential information about the radiation
absorption properties of the tissues. Sometimes, MRI is preferred to contour
the target volumes. However, this approach is often not the most efficient, as
it is more expensive, time-consuming and, most importantly, stressful for the
patients. To overcome this issue, in this work, we analyse the capabilities of
different configurations of Deep Learning models to generate synthetic CT scans
from MRI, leveraging the power of Generative Adversarial Networks (GANs) and,
in particular, the CycleGAN architecture, capable of working in an unsupervised
manner and without paired images, which were not available. Several CycleGAN
models were trained unsupervised to generate CT scans from different MRI
modalities with and without contrast agents. To overcome the problem of not
having a ground truth, distribution-based metrics were used to assess the
model's performance quantitatively, together with a qualitative evaluation
where physicians were asked to differentiate between real and synthetic images
to understand how realistic the generated images were. The results show how,
depending on the input modalities, the models can have very different
performances; however, models with the best quantitative results, according to
the distribution-based metrics used, can generate very difficult images to
distinguish from the real ones, even for physicians, demonstrating the
approach's potential.

摘要：在許多臨床環境中，需要使用電腦斷層掃描 (CT) 和磁振造影 (MRI) 來徹底了解患者的解剖結構，並規劃適當的治療策略；這通常發生在基於 MRI 的放射治療中，其中 CT 對於準備劑量傳遞總是必要的，因為它提供了有關組織輻射吸收特性的基本資訊。有時，MRI 優先於勾勒目標體積。然而，這種方法通常不是最有效率的，因為它更昂貴、耗時，最重要的是會讓患者感到壓力。為了克服這個問題，在這項工作中，我們分析了深度學習模型的不同配置，以從 MRI 生成合成 CT 掃描的能力，利用生成對抗網路 (GAN) 的功能，特別是 CycleGAN 架構，能夠以無監督的方式工作，而且不需要成對的影像，而這些影像並不可用。幾個 CycleGAN 模型經過無監督訓練，以從不同 MRI 模式生成 CT 掃描，無論是否使用對比劑。為了克服沒有基本事實的問題，基於分佈的指標被用於定量評估模型的效能，以及定性評估，其中要求醫生區分真實和合成影像，以了解生成的影像有多逼真。結果顯示，根據輸入模式，模型的效能可能大不相同；然而，根據所使用的基於分佈的指標，具有最佳定量結果的模型可以產生非常難以與真實影像區分的影像，即使對於醫生來說也是如此，這證明了這種方法的潛力。

##### **Towards Enhanced Classification of Abnormal Lung sound in Multi-breath: A Light Weight Multi-label and Multi-head Attention Classification Method**
2407.10828v1 by Yi-Wei Chua, Yun-Chien Cheng

This study aims to develop an auxiliary diagnostic system for classifying
abnormal lung respiratory sounds, enhancing the accuracy of automatic abnormal
breath sound classification through an innovative multi-label learning approach
and multi-head attention mechanism. Addressing the issue of class imbalance and
lack of diversity in existing respiratory sound datasets, our study employs a
lightweight and highly accurate model, using a two-dimensional label set to
represent multiple respiratory sound characteristics. Our method achieved a
59.2% ICBHI score in the four-category task on the ICBHI2017 dataset,
demonstrating its advantages in terms of lightweight and high accuracy. This
study not only improves the accuracy of automatic diagnosis of lung respiratory
sound abnormalities but also opens new possibilities for clinical applications.

摘要：本研究旨在開發一個輔助診斷系統，用於分類異常的肺部呼吸音，透過創新的多標籤學習方法和多頭注意力機制，提升自動異常呼吸音分類的準確度。針對現有呼吸音資料集中類別不平衡和缺乏多樣性的問題，本研究採用輕量且高精確度的模型，使用二維標籤組來表示多重呼吸音特徵。我們的模型在 ICBHI2017 資料集的四類別任務中，獲得了 59.2% 的 ICBHI 分數，證明了其在輕量化和高準確度方面的優勢。本研究不僅提升了肺部呼吸音異常自動診斷的準確度，也為臨床應用開啟了新的可能性。

##### **Classification of Heart Sounds Using Multi-Branch Deep Convolutional Network and LSTM-CNN**
2407.10689v1 by Seyed Amir Latifi, Hassan Ghassemian, Maryam Imani

This paper presents a fast and cost-effective method for diagnosing cardiac
abnormalities with high accuracy and reliability using low-cost systems in
clinics. The primary limitation of automatic diagnosing of cardiac diseases is
the rarity of correct and acceptable labeled samples, which can be expensive to
prepare. To address this issue, two methods are proposed in this work. The
first method is a unique Multi-Branch Deep Convolutional Neural Network (MBDCN)
architecture inspired by human auditory processing, specifically designed to
optimize feature extraction by employing various sizes of convolutional filters
and audio signal power spectrum as input. In the second method, called as Long
short-term memory-Convolutional Neural (LSCN) model, Additionally, the network
architecture includes Long Short-Term Memory (LSTM) network blocks to improve
feature extraction in the time domain. The innovative approach of combining
multiple parallel branches consisting of the one-dimensional convolutional
layers along with LSTM blocks helps in achieving superior results in audio
signal processing tasks. The experimental results demonstrate superiority of
the proposed methods over the state-of-the-art techniques. The overall
classification accuracy of heart sounds with the LSCN network is more than 96%.
The efficiency of this network is significant compared to common feature
extraction methods such as Mel Frequency Cepstral Coefficients (MFCC) and
wavelet transform. Therefore, the proposed method shows promising results in
the automatic analysis of heart sounds and has potential applications in the
diagnosis and early detection of cardiovascular diseases.

摘要：本文提出了一種快速且經濟有效的方法，使用低成本的系統在診所診斷心臟異常，且具有高準確度和可靠性。自動診斷心臟疾病的主要限制是正確且可接受的標籤樣本稀少，而且準備起來可能很昂貴。為了解決這個問題，這項工作提出了兩種方法。第一種方法是一種獨特的多分支深度卷積神經網路 (MBDCN) 架構，靈感來自人類聽覺處理，特別設計為透過採用各種大小的卷積濾波器和音訊訊號功率譜作為輸入，來最佳化特徵提取。在第二種方法中，稱為長短期記憶 - 卷積神經 (LSCN) 模型，此外，網路架構包括長短期記憶 (LSTM) 網路區塊，以改善時域中的特徵提取。結合由一維卷積層和 LSTM 區塊組成的多個並行分支的創新方法，有助於在音訊訊號處理任務中達成優異的結果。實驗結果證明了所提出的方法優於最先進的技術。LSCN 網路對心音的整體分類準確度超過 96%。與常見的特徵提取方法（例如梅爾頻率倒譜係數 (MFCC) 和小波轉換）相比，此網路的效率顯著。因此，所提出的方法在心音的自動分析中顯示出有希望的結果，並且在心血管疾病的診斷和早期檢測中具有潛在應用。

##### **Spatio-temporal neural distance fields for conditional generative modeling of the heart**
2407.10663v1 by Kristine Sørensen, Paula Diez, Jan Margeta, Yasmin El Youssef, Michael Pham, Jonas Jalili Pedersen, Tobias Kühl, Ole de Backer, Klaus Kofoed, Oscar Camara, Rasmus Paulsen

The rhythmic pumping motion of the heart stands as a cornerstone in life, as
it circulates blood to the entire human body through a series of carefully
timed contractions of the individual chambers. Changes in the size, shape and
movement of the chambers can be important markers for cardiac disease and
modeling this in relation to clinical demography or disease is therefore of
interest. Existing methods for spatio-temporal modeling of the human heart
require shape correspondence over time or suffer from large memory
requirements, making it difficult to use for complex anatomies. We introduce a
novel conditional generative model, where the shape and movement is modeled
implicitly in the form of a spatio-temporal neural distance field and
conditioned on clinical demography. The model is based on an auto-decoder
architecture and aims to disentangle the individual variations from that
related to the clinical demography. It is tested on the left atrium (including
the left atrial appendage), where it outperforms current state-of-the-art
methods for anatomical sequence completion and generates synthetic sequences
that realistically mimics the shape and motion of the real left atrium. In
practice, this means we can infer functional measurements from a static image,
generate synthetic populations with specified demography or disease and
investigate how non-imaging clinical data effect the shape and motion of
cardiac anatomies.

摘要：心臟有節奏的跳動動作是生命中的基石，因為它透過一系列仔細計時的單獨心室收縮，將血液循環到整個身體。心室的大小、形狀和運動的變化可能是心臟疾病的重要標記，因此對此進行建模以關聯臨床人口統計或疾病，因此具有意義。現有的時空建模方法需要隨著時間推移進行形狀對應，或需要大量的記憶體需求，這使得難以用於複雜的解剖結構。我們引入了一個新穎的條件生成模型，其中形狀和運動以時空神經距離場的形式隱含建模，並根據臨床人口統計進行條件設定。該模型基於自動編碼器架構，旨在解開與臨床人口統計相關的個別變異。它在左心房（包括左心耳）上進行測試，在解剖序列完成方面優於當前最先進的方法，並生成逼真地模擬真實左心房形狀和運動的合成序列。實際上，這意味著我們可以從靜態影像推斷功能性測量，生成具有特定人口統計或疾病的合成族群，並調查非影像臨床資料如何影響心臟解剖結構的形狀和運動。

##### **TCM-FTP: Fine-Tuning Large Language Models for Herbal Prescription Prediction**
2407.10510v1 by Xingzhi Zhou, Xin Dong, Chunhao Li, Yuning Bai, Yulong Xu, Ka Chun Cheung, Simon See, Xinpeng Song, Runshun Zhang, Xuezhong Zhou, Nevin L. Zhang

Traditional Chinese medicine (TCM) relies on specific combinations of herbs
in prescriptions to treat symptoms and signs, a practice that spans thousands
of years. Predicting TCM prescriptions presents a fascinating technical
challenge with practical implications. However, this task faces limitations due
to the scarcity of high-quality clinical datasets and the intricate
relationship between symptoms and herbs. To address these issues, we introduce
DigestDS, a new dataset containing practical medical records from experienced
experts in digestive system diseases. We also propose a method, TCM-FTP (TCM
Fine-Tuning Pre-trained), to leverage pre-trained large language models (LLMs)
through supervised fine-tuning on DigestDS. Additionally, we enhance
computational efficiency using a low-rank adaptation technique. TCM-FTP also
incorporates data augmentation by permuting herbs within prescriptions,
capitalizing on their order-agnostic properties. Impressively, TCM-FTP achieves
an F1-score of 0.8031, surpassing previous methods significantly. Furthermore,
it demonstrates remarkable accuracy in dosage prediction, achieving a
normalized mean square error of 0.0604. In contrast, LLMs without fine-tuning
perform poorly. Although LLMs have shown capabilities on a wide range of tasks,
this work illustrates the importance of fine-tuning for TCM prescription
prediction, and we have proposed an effective way to do that.

摘要：中醫依賴特定中草藥組合來治療症狀和徵兆，這項做法已有數千年的歷史。預測中醫處方是一個引人入勝的技術挑戰，具有實際意義。然而，由於缺乏高品質的臨床數據集以及症狀與中草藥之間的複雜關係，這項任務面臨限制。為了解決這些問題，我們引入了 DigestDS，一個包含消化系統疾病經驗豐富專家實際病歷的新數據集。我們還提出了一種方法，TCM-FTP（中醫微調預訓練），通過在 DigestDS 上進行監督微調來利用預訓練的大語言模型 (LLM)。此外，我們使用低秩適應技術來提高計算效率。TCM-FTP 還通過置換處方中的中草藥來納入數據擴充，利用它們與順序無關的特性。令人印象深刻的是，TCM-FTP 達到了 0.8031 的 F1 分數，顯著超越了以前的方法。此外，它在劑量預測中表現出顯著的準確性，實現了 0.0604 的歸一化均方誤差。相比之下，未經微調的 LLM 表現不佳。儘管 LLM 已在廣泛的任務中展現出能力，但這項工作說明了微調對於中醫處方預測的重要性，而且我們提出了一個有效的方法來做到這一點。

##### **A Multi-Stage Framework for 3D Individual Tooth Segmentation in Dental CBCT**
2407.10433v1 by Chunshi Wang, Bin Zhao, Shuxue Ding

Cone beam computed tomography (CBCT) is a common way of diagnosing dental
related diseases. Accurate segmentation of 3D tooth is of importance for the
treatment. Although deep learning based methods have achieved convincing
results in medical image processing, they need a large of annotated data for
network training, making it very time-consuming in data collection and
annotation. Besides, domain shift widely existing in the distribution of data
acquired by different devices impacts severely the model generalization. To
resolve the problem, we propose a multi-stage framework for 3D tooth
segmentation in dental CBCT, which achieves the third place in the
"Semi-supervised Teeth Segmentation" 3D (STS-3D) challenge. The experiments on
validation set compared with other semi-supervised segmentation methods further
indicate the validity of our approach.

摘要：錐狀光束電腦斷層掃描 (CBCT) 是一種常見的牙科相關疾病診斷方式。3D 牙齒的精確分割對於治療至關重要。儘管基於深度學習的方法在醫學影像處理中已取得令人信服的成果，但它們需要大量的註解資料進行網路訓練，這使得資料收集和註解非常耗時。此外，在不同裝置取得的資料分佈中廣泛存在的領域轉移會嚴重影響模型的泛化能力。為了解決這個問題，我們提出了一個多階段架構，用於牙科 CBCT 中的 3D 牙齒分割，在「半監督牙齒分割」3D (STS-3D) 挑戰中獲得第三名。與其他半監督分割方法相比，在驗證集上的實驗進一步證明了我們方法的有效性。

##### **Static and multivariate-temporal attentive fusion transformer for readmission risk prediction**
2407.11096v1 by Zhe Sun, Runzhi Li, Jing Wang, Gang Chen, Siyu Yan, Lihong Ma

Background: Accurate short-term readmission prediction of ICU patients is
significant in improving the efficiency of resource assignment by assisting
physicians in making discharge decisions. Clinically, both individual static
static and multivariate temporal data collected from ICU monitors play critical
roles in short-term readmission prediction. Informative static and multivariate
temporal feature representation capturing and fusion present challenges for
accurate readmission prediction. Methods:We propose a novel static and
multivariate-temporal attentive fusion transformer (SMTAFormer) to predict
short-term readmission of ICU patients by fully leveraging the potential of
demographic and dynamic temporal data. In SMTAFormer, we first apply an MLP
network and a temporal transformer network to learn useful static and temporal
feature representations, respectively. Then, the well-designed static and
multivariate temporal feature fusion module is applied to fuse static and
temporal feature representations by modeling intra-correlation among
multivariate temporal features and constructing inter-correlation between
static and multivariate temporal features. Results: We construct a readmission
risk assessment (RRA) dataset based on the MIMIC-III dataset. The extensive
experiments show that SMTAFormer outperforms advanced methods, in which the
accuracy of our proposed method is up to 86.6%, and the area under the receiver
operating characteristic curve (AUC) is up to 0.717. Conclusion: Our proposed
SMTAFormer can efficiently capture and fuse static and multivariate temporal
feature representations. The results show that SMTAFormer significantly
improves the short-term readmission prediction performance of ICU patients
through comparisons to strong baselines.

摘要：<paragraph>背景：精準短期重返預測重症加護病房（ICU）病人對於提升資源分配效率至關重要，能協助醫師做出出院決策。臨床上，從 ICU 監測器收集到的個別靜態資料和多變量時間資料在短期重返預測中扮演關鍵角色。擷取和融合有意義的靜態和多變量時間特徵表徵對於精準重返預測構成挑戰。方法：我們提出一個新穎的靜態和多變量時間注意力融合Transformer（SMTAFormer），藉由充分利用人口統計和動態時間資料的潛力，來預測 ICU 病人的短期重返。在 SMTAFormer 中，我們首先應用一個 MLP 網路和一個時間Transformer網路，分別學習有用的靜態和時間特徵表徵。然後，應用精心設計的靜態和多變量時間特徵融合模組，藉由建模多變量時間特徵之間的內部相關性，以及建構靜態和多變量時間特徵之間的相互關聯性，來融合靜態和時間特徵表徵。結果：我們根據 MIMIC-III 資料集建構一個重返風險評估（RRA）資料集。廣泛的實驗顯示，SMTAFormer 優於進階方法，其中我們提出的方法的準確度高達 86.6%，而受試者工作特性曲線（AUC）下的面積高達 0.717。結論：我們提出的 SMTAFormer 能有效擷取和融合靜態和多變量時間特徵表徵。結果顯示，SMTAFormer 藉由與強大的基線比較，顯著提升 ICU 病人的短期重返預測效能。</paragraph>

##### **Evolved Developmental Artificial Neural Networks for Multitasking with Advanced Activity Dependence**
2407.10359v1 by Yintong Zhang, Jason A. Yoder

Recently, Cartesian Genetic Programming has been used to evolve developmental
programs to guide the formation of artificial neural networks (ANNs). This
approach has demonstrated success in enabling ANNs to perform multiple tasks
while avoiding catastrophic forgetting. One unique aspect of this approach is
the use of separate developmental programs evolved to regulate the development
of separate soma and dendrite units. An opportunity afforded by this approach
is the ability to incorporate Activity Dependence (AD) into the model such that
environmental feedback can help to regulate the behavior of each type of unit.
Previous work has shown a limited version of AD (influencing neural bias) to
provide marginal improvements over non-AD ANNs. In this work, we present
promising results from new extensions to AD. Specifically, we demonstrate a
more significant improvement via AD on new neural parameters including health
and position, as well as a combination of all of these along with bias. We
report on the implications of this work and suggest several promising
directions for future work.

摘要：最近，笛卡尔遗传规划已被用于进化发育程序，以指导人工神经网络 (ANN) 的形成。这种方法已证明能够让 ANN 执行多项任务，同时避免灾难性遗忘。这种方法的一个独特方面是使用单独的发展程序来调节单独的躯体和树突单元的发展。这种方法提供了一个机会，即能够将活动依赖性 (AD) 纳入模型，以便环境反馈可以帮助调节每种类型的单元的行为。以前的工作已经展示了 AD 的一个有限版本（影响神经偏置），以提供对非 AD ANN 的边际改进。在这项工作中，我们展示了 AD 新扩展的令人鼓舞的结果。具体来说，我们通过 AD 在新的神经参数（包括健康和位置）以及所有这些参数与偏置的组合上展示了更显着的改进。我们报告了这项工作的影响，并为未来的工作提出了几个有希望的方向。

##### **Learning Unlabeled Clients Divergence via Anchor Model Aggregation for Federated Semi-supervised Learning**
2407.10327v1 by Marawan Elbatel, Hualiang Wang, Jixiang Chen, Hao Wang, Xiaomeng Li

Federated semi-supervised learning (FedSemi) refers to scenarios where there
may be clients with fully labeled data, clients with partially labeled, and
even fully unlabeled clients while preserving data privacy. However, challenges
arise from client drift due to undefined heterogeneous class distributions and
erroneous pseudo-labels. Existing FedSemi methods typically fail to aggregate
models from unlabeled clients due to their inherent unreliability, thus
overlooking unique information from their heterogeneous data distribution,
leading to sub-optimal results. In this paper, we enable unlabeled client
aggregation through SemiAnAgg, a novel Semi-supervised Anchor-Based federated
Aggregation. SemiAnAgg learns unlabeled client contributions via an anchor
model, effectively harnessing their informative value. Our key idea is that by
feeding local client data to the same global model and the same consistently
initialized anchor model (i.e., random model), we can measure the importance of
each unlabeled client accordingly. Extensive experiments demonstrate that
SemiAnAgg achieves new state-of-the-art results on four widely used FedSemi
benchmarks, leading to substantial performance improvements: a 9% increase in
accuracy on CIFAR-100 and a 7.6% improvement in recall on the medical dataset
ISIC-18, compared with prior state-of-the-art. Code is available at:
https://github.com/xmed-lab/SemiAnAgg.

摘要：聯邦半監督學習 (FedSemi) 指的是在保護資料隱私的同時，可能存在具有完全標籤資料的客戶端、具有部分標籤的客戶端，甚至完全沒有標籤的客戶端的情況。然而，由於未定義的異質類別分佈和錯誤的偽標籤，客戶端漂移帶來了挑戰。現有的 FedSemi 方法通常無法彙總來自未標籤客戶端的模型，因為它們本質上不可靠，因此忽略了其異質資料分佈中的獨特資訊，導致次佳結果。在本文中，我們透過 SemiAnAgg（一種新穎的半監督錨定式聯邦聚合）啟用未標籤客戶端聚合。SemiAnAgg 透過錨定模型學習未標籤客戶端貢獻，有效利用其資訊價值。我們的關鍵構想是，透過將本地客戶端資料提供給相同的全球模型和相同一致初始化的錨定模型（即隨機模型），我們可以相應地衡量每個未標籤客戶端的重要性。廣泛的實驗證明 SemiAnAgg 在四個廣泛使用的 FedSemi 基準上獲得了新的最先進結果，帶來了顯著的效能提升：與先前的最先進技術相比，CIFAR-100 的準確度提高了 9%，醫療資料集 ISIC-18 的召回率提高了 7.6%。程式碼可在 https://github.com/xmed-lab/SemiAnAgg 取得。

##### **Rapid Biomedical Research Classification: The Pandemic PACT Advanced Categorisation Engine**
2407.10086v2 by Omid Rohanian, Mohammadmahdi Nouriborji, Olena Seminog, Rodrigo Furst, Thomas Mendy, Shanthi Levanita, Zaharat Kadri-Alabi, Nusrat Jabin, Daniela Toale, Georgina Humphreys, Emilia Antonio, Adrian Bucher, Alice Norton, David A. Clifton

This paper introduces the Pandemic PACT Advanced Categorisation Engine
(PPACE) along with its associated dataset. PPACE is a fine-tuned model
developed to automatically classify research abstracts from funded biomedical
projects according to WHO-aligned research priorities. This task is crucial for
monitoring research trends and identifying gaps in global health preparedness
and response. Our approach builds on human-annotated projects, which are
allocated one or more categories from a predefined list. A large language model
is then used to generate `rationales' explaining the reasoning behind these
annotations. This augmented data, comprising expert annotations and rationales,
is subsequently used to fine-tune a smaller, more efficient model. Developed as
part of the Pandemic PACT project, which aims to track and analyse research
funding and clinical evidence for a wide range of diseases with outbreak
potential, PPACE supports informed decision-making by research funders,
policymakers, and independent researchers. We introduce and release both the
trained model and the instruction-based dataset used for its training. Our
evaluation shows that PPACE significantly outperforms its baselines. The
release of PPACE and its associated dataset offers valuable resources for
researchers in multilabel biomedical document classification and supports
advancements in aligning biomedical research with key global health priorities.

摘要：本文介紹了流行病 PACT 高級分類引擎 (PPACE) 及其相關的資料集。PPACE 是一個微調模型，用於根據 WHO 對齊的研究優先事項自動分類獲得資助的生物醫學專案研究摘要。這項任務對於監控研究趨勢和找出全球衛生準備和應變的缺口至關重要。我們的做法建立在人工標註的專案上，這些專案從預先定義的清單中分配一個或多個類別。然後使用大型語言模型產生「依據」來解釋這些標註背後的推理。此擴充資料包含專家標註和依據，隨後用於微調較小、更有效率的模型。PPACE 作為流行病 PACT 專案的一部分而開發，旨在追蹤和分析各種具有爆發潛力的疾病的研究資金和臨床證據，透過研究資金提供者、政策制定者和獨立研究人員的明智決策制定提供支援。我們介紹並釋出了受訓模型和用於其訓練的基於說明的資料集。我們的評估顯示 PPACE 明顯優於其基準。PPACE 及其相關資料集的釋出為多標籤生物醫學文件分類的研究人員提供了寶貴的資源，並支援將生物醫學研究與關鍵全球衛生優先事項對齊的進展。

##### **Document-level Clinical Entity and Relation Extraction via Knowledge Base-Guided Generation**
2407.10021v1 by Kriti Bhattarai, Inez Y. Oh, Zachary B. Abrams, Albert M. Lai

Generative pre-trained transformer (GPT) models have shown promise in
clinical entity and relation extraction tasks because of their precise
extraction and contextual understanding capability. In this work, we further
leverage the Unified Medical Language System (UMLS) knowledge base to
accurately identify medical concepts and improve clinical entity and relation
extraction at the document level. Our framework selects UMLS concepts relevant
to the text and combines them with prompts to guide language models in
extracting entities. Our experiments demonstrate that this initial concept
mapping and the inclusion of these mapped concepts in the prompts improves
extraction results compared to few-shot extraction tasks on generic language
models that do not leverage UMLS. Further, our results show that this approach
is more effective than the standard Retrieval Augmented Generation (RAG)
technique, where retrieved data is compared with prompt embeddings to generate
results. Overall, we find that integrating UMLS concepts with GPT models
significantly improves entity and relation identification, outperforming the
baseline and RAG models. By combining the precise concept mapping capability of
knowledge-based approaches like UMLS with the contextual understanding
capability of GPT, our method highlights the potential of these approaches in
specialized domains like healthcare.

摘要：生成式预训练转换器 (GPT) 模型在临床实体和关系抽取任务中展现出潜力，因为它们具有精确抽取和上下文理解能力。在这项工作中，我们进一步利用统一医学语言系统 (UMLS) 知识库来准确识别医学概念，并在文档级别改进临床实体和关系抽取。我们的框架选择与文本相关的 UMLS 概念，并将它们与提示相结合，以指导语言模型抽取实体。我们的实验表明，与不利用 UMLS 的通用语言模型上的少量抽取任务相比，这种初始概念映射和在提示中包含这些映射概念改进了抽取结果。此外，我们的结果表明，这种方法比标准的检索增强生成 (RAG) 技术更有效，其中检索到的数据与提示嵌入进行比较以生成结果。总体而言，我们发现将 UMLS 概念与 GPT 模型集成可以显著改善实体和关系识别，优于基线和 RAG 模型。通过将 UMLS 等基于知识的方法的精确概念映射能力与 GPT 的上下文理解能力相结合，我们的方法突出了这些方法在医疗保健等专业领域的潜力。

##### **Causality extraction from medical text using Large Language Models (LLMs)**
2407.10020v1 by Seethalakshmi Gopalakrishnan, Luciana Garbayo, Wlodek Zadrozny

This study explores the potential of natural language models, including large
language models, to extract causal relations from medical texts, specifically
from Clinical Practice Guidelines (CPGs). The outcomes causality extraction
from Clinical Practice Guidelines for gestational diabetes are presented,
marking a first in the field. We report on a set of experiments using variants
of BERT (BioBERT, DistilBERT, and BERT) and using Large Language Models (LLMs),
namely GPT-4 and LLAMA2. Our experiments show that BioBERT performed better
than other models, including the Large Language Models, with an average
F1-score of 0.72. GPT-4 and LLAMA2 results show similar performance but less
consistency. We also release the code and an annotated a corpus of causal
statements within the Clinical Practice Guidelines for gestational diabetes.

摘要：本研究探討自然語言模型，包括大型語言模型，從醫學文本中萃取因果關係的可能性，特別是從臨床實務指南 (CPG) 中。研究成果為妊娠糖尿病的臨床實務指南中因果關係萃取，為該領域首例。我們報告了一組使用 BERT 變體 (BioBERT、DistilBERT 和 BERT) 和使用大型語言模型 (LLM) 的實驗，即 GPT-4 和 LLAMA2。我們的實驗顯示，BioBERT 的表現優於其他模型，包括大型語言模型，平均 F1 分數為 0.72。GPT-4 和 LLAMA2 的結果顯示出類似的表現，但一致性較低。我們也釋出了程式碼和妊娠糖尿病臨床實務指南中因果陳述的標註語料庫。

##### **Pay Less On Clinical Images: Asymmetric Multi-Modal Fusion Method For Efficient Multi-Label Skin Lesion Classification**
2407.09999v1 by Peng Tang, Tobias Lasser

Existing multi-modal approaches primarily focus on enhancing multi-label skin
lesion classification performance through advanced fusion modules, often
neglecting the associated rise in parameters. In clinical settings, both
clinical and dermoscopy images are captured for diagnosis; however, dermoscopy
images exhibit more crucial visual features for multi-label skin lesion
classification. Motivated by this observation, we introduce a novel asymmetric
multi-modal fusion method in this paper for efficient multi-label skin lesion
classification. Our fusion method incorporates two innovative schemes. Firstly,
we validate the effectiveness of our asymmetric fusion structure. It employs a
light and simple network for clinical images and a heavier, more complex one
for dermoscopy images, resulting in significant parameter savings compared to
the symmetric fusion structure using two identical networks for both
modalities. Secondly, in contrast to previous approaches using mutual attention
modules for interaction between image modalities, we propose an asymmetric
attention module. This module solely leverages clinical image information to
enhance dermoscopy image features, considering clinical images as supplementary
information in our pipeline. We conduct the extensive experiments on the
seven-point checklist dataset. Results demonstrate the generality of our
proposed method for both networks and Transformer structures, showcasing its
superiority over existing methods We will make our code publicly available.

摘要：現有的多模式方法主要專注於透過先進的融合模組來增強多標籤皮膚病變分類效能，往往忽略了相關參數的增加。在臨床環境中，臨床上和皮膚鏡影像都會被擷取用於診斷；然而，皮膚鏡影像展現出更重要的視覺特徵，用於多標籤皮膚病變分類。受此觀察結果啟發，我們在本文中介紹一種新穎的不對稱多模式融合方法，用於有效的多標籤皮膚病變分類。我們的融合方法包含兩個創新的方案。首先，我們驗證了我們的不對稱融合結構的有效性。它採用一個輕量且簡單的網路用於臨床影像，以及一個較重且複雜的網路用於皮膚鏡影像，與使用兩個相同的網路用於兩種模式的對稱融合結構相比，這會節省大量的參數。其次，與先前使用相互注意力模組用於影像模式之間互動的方法相反，我們提出了一個不對稱注意力模組。這個模組僅利用臨床影像資訊來增強皮膚鏡影像特徵，將臨床影像視為我們流程中的補充資訊。我們在七點核對清單資料集上進行了廣泛的實驗。結果證明了我們提出的方法對網路和 Transformer 結構的普遍性，展示了它優於現有方法的優越性。我們將公開我們的程式碼。

##### **Evaluating the Impact of Different Quantum Kernels on the Classification Performance of Support Vector Machine Algorithm: A Medical Dataset Application**
2407.09930v2 by Emine Akpinar, Sardar M. N. Islam, Murat Oduncuoglu

The support vector machine algorithm with a quantum kernel estimator
(QSVM-Kernel), as a leading example of a quantum machine learning technique,
has undergone significant advancements. Nevertheless, its integration with
classical data presents unique challenges. While quantum computers primarily
interact with data in quantum states, embedding classical data into quantum
states using feature mapping techniques is essential for leveraging quantum
algorithms Despite the recognized importance of feature mapping, its specific
impact on data classification outcomes remains largely unexplored. This study
addresses this gap by comprehensively assessing the effects of various feature
mapping methods on classification results, taking medical data analysis as a
case study. In this study, the QSVM-Kernel method was applied to classification
problems in two different and publicly available medical datasets, namely, the
Wisconsin Breast Cancer (original) and The Cancer Genome Atlas (TCGA) Glioma
datasets. In the QSVM-Kernel algorithm, quantum kernel matrices obtained from 9
different quantum feature maps were used. Thus, the effects of these quantum
feature maps on the classification results of the QSVM-Kernel algorithm were
examined in terms of both classifier performance and total execution time. As a
result, in the Wisconsin Breast Cancer (original) and TCGA Glioma datasets,
when Rx and Ry rotational gates were used, respectively, as feature maps in the
QSVM-Kernel algorithm, the best classification performances were achieved both
in terms of classification performance and total execution time. The
contributions of this study are that (1) it highlights the significant impact
of feature mapping techniques on medical data classification outcomes using the
QSVM-Kernel algorithm, and (2) it also guides undertaking research for improved
QSVM classification performance.

摘要：<paragraph>作為量子機器學習技術的領先範例，具有量子核估計器的支持向量機演算法 (QSVM-Kernel) 已經歷重大的進展。儘管如此，它與經典資料的整合提出了獨特的挑戰。雖然量子電腦主要與量子狀態中的資料互動，但使用特徵對應技術將經典資料嵌入量子狀態對於利用量子演算法至關重要。儘管特徵對應的重要性獲得認可，但其對資料分類結果的具體影響仍未得到充分探討。本研究透過全面評估各種特徵對應方法對分類結果的影響來解決這個差距，並將醫學資料分析作為案例研究。在本研究中，QSVM-Kernel 方法被應用於兩個不同且公開可用的醫學資料集中的分類問題，即威斯康辛乳癌 (原始) 和癌症基因組圖譜 (TCGA) 神經膠質瘤資料集。在 QSVM-Kernel 演算法中，使用了從 9 個不同的量子特徵對應中獲得的量子核矩陣。因此，這些量子特徵對應對 QSVM-Kernel 演算法分類結果的影響在分類器效能和總執行時間方面都得到了檢驗。結果，在威斯康辛乳癌 (原始) 和 TCGA 神經膠質瘤資料集中，當 Rx 和 Ry 旋轉閘分別用作 QSVM-Kernel 演算法中的特徵對應時，在分類效能和總執行時間方面都達到了最佳的分類效能。本研究的貢獻在於：(1) 它強調了特徵對應技術對使用 QSVM-Kernel 演算法的醫學資料分類結果的重大影響，以及 (2) 它也指導進行研究以改善 QSVM 分類效能。</paragraph>

##### **Enhancing Semantic Segmentation with Adaptive Focal Loss: A Novel Approach**
2407.09828v1 by Md Rakibul Islam, Riad Hassan, Abdullah Nazib, Kien Nguyen, Clinton Fookes, Md Zahidul Islam

Deep learning has achieved outstanding accuracy in medical image
segmentation, particularly for objects like organs or tumors with smooth
boundaries or large sizes. Whereas, it encounters significant difficulties with
objects that have zigzag boundaries or are small in size, leading to a notable
decrease in segmentation effectiveness. In this context, using a loss function
that incorporates smoothness and volume information into a model's predictions
offers a promising solution to these shortcomings. In this work, we introduce
an Adaptive Focal Loss (A-FL) function designed to mitigate class imbalance by
down-weighting the loss for easy examples that results in up-weighting the loss
for hard examples and giving greater emphasis to challenging examples, such as
small and irregularly shaped objects. The proposed A-FL involves dynamically
adjusting a focusing parameter based on an object's surface smoothness, size
information, and adjusting the class balancing parameter based on the ratio of
targeted area to total area in an image. We evaluated the performance of the
A-FL using ResNet50-encoded U-Net architecture on the Picai 2022 and BraTS 2018
datasets. On the Picai 2022 dataset, the A-FL achieved an Intersection over
Union (IoU) of 0.696 and a Dice Similarity Coefficient (DSC) of 0.769,
outperforming the regular Focal Loss (FL) by 5.5% and 5.4% respectively. It
also surpassed the best baseline Dice-Focal by 2.0% and 1.2%. On the BraTS 2018
dataset, A-FL achieved an IoU of 0.883 and a DSC of 0.931. The comparative
studies show that the proposed A-FL function surpasses conventional methods,
including Dice Loss, Focal Loss, and their hybrid variants, in IoU, DSC,
Sensitivity, and Specificity metrics. This work highlights A-FL's potential to
improve deep learning models for segmenting clinically significant regions in
medical images, leading to more precise and reliable diagnostic tools.

摘要：深度學習在醫學影像分割方面取得了傑出的準確性，特別是對於具有平滑邊界或大尺寸的器官或腫瘤等物體。然而，對於具有曲折邊界或尺寸小的物體，它會遇到很大的困難，導致分割效果顯著下降。在此背景下，使用將平滑度和體積資訊納入模型預測的損失函數為這些缺點提供了一個有希望的解決方案。在這項工作中，我們引入了一個自適應焦點損失 (A-FL) 函數，旨在通過降低易於範例的損失來減輕類別失衡，從而增加困難範例的損失，並更加強調具有挑戰性的範例，例如小且形狀不規則的物體。所提出的 A-FL 涉及根據物體的表面平滑度、尺寸資訊動態調整聚焦參數，並根據圖像中目標區域與總區域的比率調整類別平衡參數。我們使用 ResNet50 編碼的 U-Net 架構在 Picai 2022 和 BraTS 2018 資料集上評估了 A-FL 的效能。在 Picai 2022 資料集上，A-FL 的交集比聯集 (IoU) 為 0.696，骰子相似性係數 (DSC) 為 0.769，分別優於常規焦點損失 (FL) 5.5% 和 5.4%。它還超越了最佳基準 Dice-Focal 2.0% 和 1.2%。在 BraTS 2018 資料集上，A-FL 的 IoU 為 0.883，DSC 為 0.931。比較研究表明，所提出的 A-FL 函數在 IoU、DSC、敏感性和特異性指標上優於傳統方法，包括 Dice 損失、焦點損失及其混合變體。這項工作突出了 A-FL 在分割醫學影像中具有臨床意義的區域以改善深度學習模型的潛力，從而產生更精確、更可靠的診斷工具。

##### **Towards Personalised Patient Risk Prediction Using Temporal Hospital Data Trajectories**
2407.09373v1 by Thea Barnes, Enrico Werner, Jeffrey N. Clark, Raul Santos-Rodriguez

Quantifying a patient's health status provides clinicians with insight into
patient risk, and the ability to better triage and manage resources. Early
Warning Scores (EWS) are widely deployed to measure overall health status, and
risk of adverse outcomes, in hospital patients. However, current EWS are
limited both by their lack of personalisation and use of static observations.
We propose a pipeline that groups intensive care unit patients by the
trajectories of observations data throughout their stay as a basis for the
development of personalised risk predictions. Feature importance is considered
to provide model explainability. Using the MIMIC-IV dataset, six clusters were
identified, capturing differences in disease codes, observations, lengths of
admissions and outcomes. Applying the pipeline to data from just the first four
hours of each ICU stay assigns the majority of patients to the same cluster as
when the entire stay duration is considered. In-hospital mortality prediction
models trained on individual clusters had higher F1 score performance in five
of the six clusters when compared against the unclustered patient cohort. The
pipeline could form the basis of a clinical decision support tool, working to
improve the clinical characterisation of risk groups and the early detection of
patient deterioration.

摘要：量化患者的健康状况可让临床医生深入了解患者风险，并能更好地对资源进行分类和管理。早期预警评分 (EWS) 被广泛用于衡量整体健康状况和住院患者的不良后果风险。然而，当前的 EWS 受限于其缺乏个性化和使用静态观察。我们提出了一个管道，该管道根据患者在整个住院期间的观察数据轨迹对重症监护病房患者进行分组，作为制定个性化风险预测的基础。特征重要性被考虑为提供模型可解释性。使用 MIMIC-IV 数据集，识别出六个集群，捕捉疾病代码、观察、入院时间和结果的差异。将管道应用于每个 ICU 住院的前四个小时的数据时，将大多数患者分配到与考虑整个住院时间时相同的集群。在五个集群中，针对各个集群训练的院内死亡率预测模型与未分组患者队列相比具有更高的 F1 分数表现。该管道可以形成临床决策支持工具的基础，用于改善风险组的临床表征和患者恶化的早期检测。

##### **Enhancing Depressive Post Detection in Bangla: A Comparative Study of TF-IDF, BERT and FastText Embeddings**
2407.09187v1 by Saad Ahmed Sazan, Mahdi H. Miraz, A B M Muntasir Rahman

Due to massive adoption of social media, detection of users' depression
through social media analytics bears significant importance, particularly for
underrepresented languages, such as Bangla. This study introduces a
well-grounded approach to identify depressive social media posts in Bangla, by
employing advanced natural language processing techniques. The dataset used in
this work, annotated by domain experts, includes both depressive and
non-depressive posts, ensuring high-quality data for model training and
evaluation. To address the prevalent issue of class imbalance, we utilised
random oversampling for the minority class, thereby enhancing the model's
ability to accurately detect depressive posts. We explored various numerical
representation techniques, including Term Frequency-Inverse Document Frequency
(TF-IDF), Bidirectional Encoder Representations from Transformers (BERT)
embedding and FastText embedding, by integrating them with a deep
learning-based Convolutional Neural Network-Bidirectional Long Short-Term
Memory (CNN-BiLSTM) model. The results obtained through extensive
experimentation, indicate that the BERT approach performed better the others,
achieving a F1-score of 84%. This indicates that BERT, in combination with the
CNN-BiLSTM architecture, effectively recognises the nuances of Bangla texts
relevant to depressive contents. Comparative analysis with the existing
state-of-the-art methods demonstrates that our approach with BERT embedding
performs better than others in terms of evaluation metrics and the reliability
of dataset annotations. Our research significantly contribution to the
development of reliable tools for detecting depressive posts in the Bangla
language. By highlighting the efficacy of different embedding techniques and
deep learning models, this study paves the way for improved mental health
monitoring through social media platforms.

摘要：<paragraph>由於社群媒體的廣泛採用，透過社群媒體分析來偵測使用者的憂鬱症具有重要的意義，特別是對於孟加拉語等代表性不足的語言。本研究介紹了一種有根據的方法來識別孟加拉語中的憂鬱社群媒體貼文，方法是採用先進的自然語言處理技術。本研究中所使用的資料集由領域專家註解，包括憂鬱和非憂鬱貼文，確保模型訓練和評估資料的高品質。為了解決類別不平衡的普遍問題，我們對少數類別採用隨機過度取樣，從而增強模型準確偵測憂鬱貼文的能力。我們探討了各種數值表示技術，包括詞頻-逆文件頻率 (TF-IDF)、Transformer (BERT) 嵌入的雙向編碼器表示和 FastText 嵌入，並將它們與基於深度學習的卷積神經網路-雙向長短期記憶 (CNN-BiLSTM) 模型整合在一起。透過廣泛的實驗所獲得的結果顯示，BERT 方法的表現優於其他方法，達到了 84% 的 F1 分數。這表示 BERT 與 CNN-BiLSTM 架構相結合，可以有效識別與憂鬱內容相關的孟加拉語文本的細微差別。與現有的最先進方法進行比較分析，證明我們採用 BERT 嵌入的方法在評估指標和資料集註解的可靠性方面優於其他方法。我們的研究為開發用於偵測孟加拉語中憂鬱貼文的可靠工具做出了重大貢獻。透過強調不同嵌入技術和深度學習模型的效能，本研究為透過社群媒體平台改善心理健康監控鋪平了道路。</paragraph>

##### **STD-LLM: Understanding Both Spatial and Temporal Properties of Spatial-Temporal Data with LLMs**
2407.09096v1 by Yiheng Huang, Xiaowei Mao, Shengnan Guo, Yubin Chen, Youfang Lin, Huaiyu Wan

Spatial-temporal forecasting and imputation are important for real-world
dynamic systems such as intelligent transportation, urban planning, and public
health. Most existing methods are tailored for individual forecasting or
imputation tasks but are not designed for both. Additionally, they are less
effective for zero-shot and few-shot learning. While large language models
(LLMs) have exhibited strong pattern recognition and reasoning abilities across
various tasks, including few-shot and zero-shot learning, their development in
understanding spatial-temporal data has been constrained by insufficient
modeling of complex correlations such as the temporal correlations, spatial
connectivity, non-pairwise and high-order spatial-temporal correlations within
data. In this paper, we propose STD-LLM for understanding both spatial and
temporal properties of \underline{S}patial-\underline{T}emporal
\underline{D}ata with \underline{LLM}s, which is capable of implementing both
spatial-temporal forecasting and imputation tasks. STD-LLM understands
spatial-temporal correlations via explicitly designed spatial and temporal
tokenizers as well as virtual nodes. Topology-aware node embeddings are
designed for LLMs to comprehend and exploit the topology structure of data.
Additionally, to capture the non-pairwise and higher-order correlations, we
design a hypergraph learning module for LLMs, which can enhance the overall
performance and improve efficiency. Extensive experiments demonstrate that
STD-LLM exhibits strong performance and generalization capabilities across the
forecasting and imputation tasks on various datasets. Moreover, STD-LLM
achieves promising results on both few-shot and zero-shot learning tasks.

摘要：時空預測和填補對於智慧交通、都市計畫和公共衛生等真實世界動態系統來說很重要。現有方法大多是針對個別預測或填補任務量身打造，但並非針對兩者設計。此外，它們對於零次學習和少次學習的效果較差。儘管大型語言模型 (LLM) 已在各種任務中展現強大的模式識別和推理能力，包括少次學習和零次學習，但它們在理解時空資料方面的發展受到限制，原因是對複雜關聯性的建模不足，例如資料中的時間關聯性、空間連通性、非成對和高階時空關聯性。在本文中，我們提出 STD-LLM，用於了解時空資料的空間和時間屬性，並具備執行時空預測和填補任務的能力。STD-LLM 透過明確設計的空間和時間標記化器以及虛擬節點來了解時空關聯性。拓撲感知節點嵌入是為 LLM 設計的，用於理解和利用資料的拓撲結構。此外，為了捕捉非成對和高階關聯性，我們為 LLM 設計了一個超圖學習模組，可以提升整體效能並改善效率。大量的實驗證明 STD-LLM 在各種資料集的預測和填補任務中展現出強大的效能和泛化能力。此外，STD-LLM 在少次學習和零次學習任務中都取得了令人滿意的成果。

##### **FD-SOS: Vision-Language Open-Set Detectors for Bone Fenestration and Dehiscence Detection from Intraoral Images**
2407.09088v1 by Marawan Elbatel, Keyuan Liu, Yanqi Yang, Xiaomeng Li

Accurate detection of bone fenestration and dehiscence (FD) is crucial for
effective treatment planning in dentistry. While cone-beam computed tomography
(CBCT) is the gold standard for evaluating FD, it comes with limitations such
as radiation exposure, limited accessibility, and higher cost compared to
intraoral images. In intraoral images, dentists face challenges in the
differential diagnosis of FD. This paper presents a novel and clinically
significant application of FD detection solely from intraoral images. To
achieve this, we propose FD-SOS, a novel open-set object detector for FD
detection from intraoral images. FD-SOS has two novel components: conditional
contrastive denoising (CCDN) and teeth-specific matching assignment (TMA).
These modules enable FD-SOS to effectively leverage external dental semantics.
Experimental results showed that our method outperformed existing detection
methods and surpassed dental professionals by 35% recall under the same level
of precision. Code is available at: https://github.com/xmed-lab/FD-SOS.

摘要：骨骼穿孔和骨缺損 (FD) 的準確偵測對於牙科的有效治療計畫至關重要。錐形束電腦斷層掃描 (CBCT) 雖然是評估 FD 的黃金標準，但它存在著諸如輻射曝露、取得不易和與口腔內影像相比成本較高等限制。在口腔內影像中，牙醫師在 FD 的鑑別診斷中面臨挑戰。本文提出了一個創新且臨床上重要的應用，可僅從口腔內影像中偵測 FD。為達成此目標，我們提出 FD-SOS，這是一種用於從口腔內影像中偵測 FD 的新型開放式物件偵測器。FD-SOS 有兩個新穎的組成部分：條件對比去噪 (CCDN) 和特定於牙齒的匹配指定 (TMA)。這些模組使 FD-SOS 能有效利用外部牙科語義。實驗結果顯示，我們的技術優於現有的偵測技術，且在相同的準確度下，比牙科專業人員高出 35% 的召回率。程式碼可在 https://github.com/xmed-lab/FD-SOS 取得。

##### **Heterogeneous Subgraph Network with Prompt Learning for Interpretable Depression Detection on Social Media**
2407.09019v1 by Chen Chen, Mingwei Li, Fenghuan Li, Haopeng Chen, Yuankun Lin

Massive social media data can reflect people's authentic thoughts, emotions,
communication, etc., and therefore can be analyzed for early detection of
mental health problems such as depression. Existing works about early
depression detection on social media lacked interpretability and neglected the
heterogeneity of social media data. Furthermore, they overlooked the global
interaction among users. To address these issues, we develop a novel method
that leverages a Heterogeneous Subgraph Network with Prompt Learning(HSNPL) and
contrastive learning mechanisms. Specifically, prompt learning is employed to
map users' implicit psychological symbols with excellent interpretability while
deep semantic and diverse behavioral features are incorporated by a
heterogeneous information network. Then, the heterogeneous graph network with a
dual attention mechanism is constructed to model the relationships among
heterogeneous social information at the feature level. Furthermore, the
heterogeneous subgraph network integrating subgraph attention and
self-supervised contrastive learning is developed to explore complicated
interactions among users and groups at the user level. Extensive experimental
results demonstrate that our proposed method significantly outperforms
state-of-the-art methods for depression detection on social media.

摘要：龐大的社群媒體資料可以反映人們真實的想法、情緒、溝通等，因此可以分析這些資料，以早期偵測憂鬱症等心理健康問題。現有關於社群媒體上早期憂鬱症偵測的研究缺乏可解釋性，且忽略了社群媒體資料的異質性。此外，這些研究忽視了使用者之間的整體互動。為了解決這些問題，我們開發了一種新穎的方法，這種方法利用帶有提示學習（HSNPL）的異質子圖網路和對比學習機制。具體而言，提示學習被用於繪製使用者具有出色可解釋性的隱含心理符號，同時通過異質資訊網路整合了深層語義和多樣化的行為特徵。然後，構建具有雙重注意機制的異質圖網路，以在特徵層級建模異質社群資訊之間的關係。此外，開發了整合子圖注意和自我監督對比學習的異質子圖網路，以探索使用者和群組之間在使用者層級的複雜互動。大量的實驗結果表明，我們提出的方法在社群媒體上的憂鬱症偵測方面顯著優於最先進的方法。

##### **Application of Artificial Intelligence in Supporting Healthcare Professionals and Caregivers in Treatment of Autistic Children**
2407.08902v1 by Hossein Mohammadi Rouzbahani, Hadis Karimipour

Autism Spectrum Disorder (ASD) represents a multifaceted neurodevelopmental
condition marked by difficulties in social interaction, communication
impediments, and repetitive behaviors. Despite progress in understanding ASD,
its diagnosis and treatment continue to pose significant challenges due to the
variability in symptomatology and the necessity for multidisciplinary care
approaches. This paper investigates the potential of Artificial Intelligence
(AI) to augment the capabilities of healthcare professionals and caregivers in
managing ASD. We have developed a sophisticated algorithm designed to analyze
facial and bodily expressions during daily activities of both autistic and
non-autistic children, leading to the development of a powerful deep
learning-based autism detection system. Our study demonstrated that AI models,
specifically the Xception and ResNet50V2 architectures, achieved high accuracy
in diagnosing Autism Spectrum Disorder (ASD). This research highlights the
transformative potential of AI in improving the diagnosis, treatment, and
comprehensive management of ASD. Our study revealed that AI models, notably the
Xception and ResNet50V2 architectures, demonstrated high accuracy in diagnosing
ASD.

摘要：自閉症譜系障礙 (ASD) 是一種多面向的神經發展狀況，其特徵在於社交互動困難、溝通障礙和重複性行為。儘管在了解 ASD 方面取得進展，但由於症狀的多變性和對跨領域照護方法的必要性，其診斷和治療仍然構成重大挑戰。本文探討人工智慧 (AI) 在擴增醫療保健專業人員和照護者管理 ASD 能力方面的潛力。我們開發了一種精密演算法，旨在分析自閉症和非自閉症兒童在日常活動中的面部和身體表情，進而開發出功能強大的深度學習自閉症偵測系統。我們的研究表明，AI 模型，特別是 Xception 和 ResNet50V2 架構，在診斷自閉症譜系障礙 (ASD) 方面取得高準確度。這項研究突顯了 AI 在改善 ASD 診斷、治療和全面管理方面的變革潛力。我們的研究揭示，AI 模型，特別是 Xception 和 ResNet50V2 架構，在診斷 ASD 方面表現出高準確度。

##### **SALT: Introducing a Framework for Hierarchical Segmentations in Medical Imaging using Softmax for Arbitrary Label Trees**
2407.08878v1 by Sven Koitka, Giulia Baldini, Cynthia S. Schmidt, Olivia B. Pollok, Obioma Pelka, Judith Kohnke, Katarzyna Borys, Christoph M. Friedrich, Benedikt M. Schaarschmidt, Michael Forsting, Lale Umutlu, Johannes Haubold, Felix Nensa, René Hosch

Traditional segmentation networks approach anatomical structures as
standalone elements, overlooking the intrinsic hierarchical connections among
them. This study introduces Softmax for Arbitrary Label Trees (SALT), a novel
approach designed to leverage the hierarchical relationships between labels,
improving the efficiency and interpretability of the segmentations.
  This study introduces a novel segmentation technique for CT imaging, which
leverages conditional probabilities to map the hierarchical structure of
anatomical landmarks, such as the spine's division into lumbar, thoracic, and
cervical regions and further into individual vertebrae. The model was developed
using the SAROS dataset from The Cancer Imaging Archive (TCIA), comprising 900
body region segmentations from 883 patients. The dataset was further enhanced
by generating additional segmentations with the TotalSegmentator, for a total
of 113 labels. The model was trained on 600 scans, while validation and testing
were conducted on 150 CT scans. Performance was assessed using the Dice score
across various datasets, including SAROS, CT-ORG, FLARE22, LCTSC, LUNA16, and
WORD.
  Among the evaluated datasets, SALT achieved its best results on the LUNA16
and SAROS datasets, with Dice scores of 0.93 and 0.929 respectively. The model
demonstrated reliable accuracy across other datasets, scoring 0.891 on CT-ORG
and 0.849 on FLARE22. The LCTSC dataset showed a score of 0.908 and the WORD
dataset also showed good performance with a score of 0.844.
  SALT used the hierarchical structures inherent in the human body to achieve
whole-body segmentations with an average of 35 seconds for 100 slices. This
rapid processing underscores its potential for integration into clinical
workflows, facilitating the automatic and efficient computation of full-body
segmentations with each CT scan, thus enhancing diagnostic processes and
patient care.

摘要：<paragraph>傳統的分割網路將解剖結構視為獨立元素，忽略了它們之間固有的層級連接。本研究引入了任意標籤樹的 Softmax (SALT)，這是一種新穎的方法，旨在利用標籤之間的層級關係，提高分割的效率和可解釋性。
本研究引入了一種新的 CT 影像分割技術，它利用條件機率來對解剖標誌的層級結構進行對應，例如將脊椎分為腰椎、胸椎和頸椎區域，並進一步分為個別椎骨。該模型是使用癌症影像檔案館 (TCIA) 中的 SAROS 資料集開發的，其中包含來自 883 位患者的 900 個身體區域分割。該資料集進一步透過 TotalSegmentator 生成了額外的分割，總共 113 個標籤。該模型在 600 次掃描中接受了訓練，而驗證和測試則在 150 次 CT 掃描中進行。效能使用 Dice 分數在各種資料集上進行評估，包括 SAROS、CT-ORG、FLARE22、LCTSC、LUNA16 和 WORD。
在評估的資料集中，SALT 在 LUNA16 和 SAROS 資料集上取得了最佳結果，Dice 分數分別為 0.93 和 0.929。該模型在其他資料集上表現出可靠的準確性，在 CT-ORG 上得分為 0.891，在 FLARE22 上得分為 0.849。LCTSC 資料集的得分為 0.908，WORD 資料集的表現也很好，得分為 0.844。
SALT 利用人體固有的層級結構，以平均 35 秒的時間對 100 個切片進行全身分割。這種快速處理突顯了它整合到臨床工作流程中的潛力，促進了每次 CT 掃描的全身分割的自動化和高效計算，從而增強了診斷過程和患者護理。</paragraph>

##### **FedMedICL: Towards Holistic Evaluation of Distribution Shifts in Federated Medical Imaging**
2407.08822v1 by Kumail Alhamoud, Yasir Ghunaim, Motasem Alfarra, Thomas Hartvigsen, Philip Torr, Bernard Ghanem, Adel Bibi, Marzyeh Ghassemi

For medical imaging AI models to be clinically impactful, they must
generalize. However, this goal is hindered by (i) diverse types of distribution
shifts, such as temporal, demographic, and label shifts, and (ii) limited
diversity in datasets that are siloed within single medical institutions. While
these limitations have spurred interest in federated learning, current
evaluation benchmarks fail to evaluate different shifts simultaneously.
However, in real healthcare settings, multiple types of shifts co-exist, yet
their impact on medical imaging performance remains unstudied. In response, we
introduce FedMedICL, a unified framework and benchmark to holistically evaluate
federated medical imaging challenges, simultaneously capturing label,
demographic, and temporal distribution shifts. We comprehensively evaluate
several popular methods on six diverse medical imaging datasets (totaling 550
GPU hours). Furthermore, we use FedMedICL to simulate COVID-19 propagation
across hospitals and evaluate whether methods can adapt to pandemic changes in
disease prevalence. We find that a simple batch balancing technique surpasses
advanced methods in average performance across FedMedICL experiments. This
finding questions the applicability of results from previous, narrow benchmarks
in real-world medical settings.

摘要：為了讓醫學影像 AI 模型在臨床上產生影響，它們必須具備泛化性。然而，此目標受到 (i) 分佈轉移的不同類型（例如時間、人口統計和標籤轉移）以及 (ii) 侷限於單一醫療機構內資料集的多樣性所阻礙。儘管這些限制激發了對聯合學習的興趣，但目前的評估基準無法同時評估不同的轉移。然而，在實際的醫療保健環境中，多種類型的轉移同時存在，但它們對醫學影像效能的影響仍未得到研究。為了解決這個問題，我們引入了 FedMedICL，一個統一的架構和基準，以全面評估聯合醫學影像挑戰，同時捕捉標籤、人口統計和時間分佈轉移。我們在六個不同的醫學影像資料集（總計 550 個 GPU 小時）上全面評估了幾種流行的方法。此外，我們使用 FedMedICL 模擬了 COVID-19 在醫院間的傳播，並評估方法是否能適應疾病盛行率的流行病變化。我們發現，一個簡單的批次平衡技術在 FedMedICL 實驗中超越了先進的方法的平均效能。此發現質疑了先前狹隘基準在現實世界醫療環境中結果的適用性。

##### **FairDomain: Achieving Fairness in Cross-Domain Medical Image Segmentation and Classification**
2407.08813v2 by Yu Tian, Congcong Wen, Min Shi, Muhammad Muneeb Afzal, Hao Huang, Muhammad Osama Khan, Yan Luo, Yi Fang, Mengyu Wang

Addressing fairness in artificial intelligence (AI), particularly in medical
AI, is crucial for ensuring equitable healthcare outcomes. Recent efforts to
enhance fairness have introduced new methodologies and datasets in medical AI.
However, the fairness issue under the setting of domain transfer is almost
unexplored, while it is common that clinics rely on different imaging
technologies (e.g., different retinal imaging modalities) for patient
diagnosis. This paper presents FairDomain, a pioneering systemic study into
algorithmic fairness under domain shifts, employing state-of-the-art domain
adaptation (DA) and generalization (DG) algorithms for both medical
segmentation and classification tasks to understand how biases are transferred
between different domains. We also introduce a novel plug-and-play fair
identity attention (FIA) module that adapts to various DA and DG algorithms to
improve fairness by using self-attention to adjust feature importance based on
demographic attributes. Additionally, we curate the first fairness-focused
dataset with two paired imaging modalities for the same patient cohort on
medical segmentation and classification tasks, to rigorously assess fairness in
domain-shift scenarios. Excluding the confounding impact of demographic
distribution variation between source and target domains will allow clearer
quantification of the performance of domain transfer models. Our extensive
evaluations reveal that the proposed FIA significantly enhances both model
performance accounted for fairness across all domain shift settings (i.e., DA
and DG) with respect to different demographics, which outperforms existing
methods on both segmentation and classification. The code and data can be
accessed at https://ophai.hms.harvard.edu/datasets/harvard-fairdomain20k.

摘要：<paragraph>在人工智慧（AI）中，特別是在醫療 AI 中，解決公平性對於確保公平的醫療保健結果至關重要。最近為提高公平性所做的努力，在醫療 AI 中引入了新的方法和數據集。然而，在領域轉移的設定下，公平性問題幾乎未被探討，而診所依賴不同的影像技術（例如，不同的視網膜影像方式）來進行患者診斷是很常見的。本文提出了 FairDomain，這是一項關於領域轉移下演算法公平性的開創性系統性研究，採用最先進的領域適應（DA）和概化（DG）演算法，用於醫療分割和分類任務，以了解偏差如何在不同領域之間轉移。我們還引入了一個新穎的即插即用公平身分注意力（FIA）模組，它適用於各種 DA 和 DG 演算法，透過使用自我注意力根據人口屬性調整特徵重要性來改善公平性。此外，我們策劃了第一個以公平性為重點的數據集，其中包含針對相同患者群體的兩種配對影像方式，用於醫療分割和分類任務，以嚴格評估領域轉移情境中的公平性。排除來源和目標領域之間人口分佈差異的混淆影響，將允許更清楚地量化領域轉移模型的效能。我們廣泛的評估顯示，所提出的 FIA 大幅提升了模型效能，在所有領域轉移設定（即 DA 和 DG）中，針對不同人口統計資料都考慮了公平性，在分割和分類方面都優於現有方法。程式碼和資料可於 https://ophai.hms.harvard.edu/datasets/harvard-fairdomain20k 取得。</paragraph>

##### **Uncertainty Estimation of Large Language Models in Medical Question Answering**
2407.08662v1 by Jiaxin Wu, Yizhou Yu, Hong-Yu Zhou

Large Language Models (LLMs) show promise for natural language generation in
healthcare, but risk hallucinating factually incorrect information. Deploying
LLMs for medical question answering necessitates reliable uncertainty
estimation (UE) methods to detect hallucinations. In this work, we benchmark
popular UE methods with different model sizes on medical question-answering
datasets. Our results show that current approaches generally perform poorly in
this domain, highlighting the challenge of UE for medical applications. We also
observe that larger models tend to yield better results, suggesting a
correlation between model size and the reliability of UE. To address these
challenges, we propose Two-phase Verification, a probability-free Uncertainty
Estimation approach. First, an LLM generates a step-by-step explanation
alongside its initial answer, followed by formulating verification questions to
check the factual claims in the explanation. The model then answers these
questions twice: first independently, and then referencing the explanation.
Inconsistencies between the two sets of answers measure the uncertainty in the
original response. We evaluate our approach on three biomedical
question-answering datasets using Llama 2 Chat models and compare it against
the benchmarked baseline methods. The results show that our Two-phase
Verification method achieves the best overall accuracy and stability across
various datasets and model sizes, and its performance scales as the model size
increases.

摘要：大型語言模型 (LLM) 在醫療保健領域的自然語言生成方面顯示出前景，但存在虛構事實不正確資訊的風險。部署 LLM 來回答醫療問題需要可靠的不確定性估計 (UE) 方法來偵測虛構。在這項工作中，我們使用不同模型大小對熱門 UE 方法進行基準測試，針對醫療問題回答資料集。我們的結果顯示，目前的作法在這方面通常表現不佳，突顯了 UE 在醫療應用中的挑戰。我們還觀察到，較大的模型往往會產生更好的結果，這表明模型大小與 UE 的可靠性之間存在相關性。為了應對這些挑戰，我們提出了兩階段驗證，一種無機率的不確定性估計方法。首先，LLM 會在其初始答案旁邊產生逐步說明，然後制定驗證問題來檢查說明中的事實聲明。然後，模型回答這些問題兩次：第一次獨立回答，然後參考說明。兩組答案之間的不一致性衡量原始回應中的不確定性。我們使用 Llama 2 Chat 模型在三個生物醫學問題回答資料集上評估我們的作法，並將其與基準基準方法進行比較。結果顯示，我們的兩階段驗證方法在各種資料集和模型大小中實現了最佳的整體準確性和穩定性，並且其效能隨著模型大小的增加而擴展。

##### **Establishing Rigorous and Cost-effective Clinical Trials for Artificial Intelligence Models**
2407.08554v1 by Wanling Gao, Yunyou Huang, Dandan Cui, Zhuoming Yu, Wenjing Liu, Xiaoshuang Liang, Jiahui Zhao, Jiyue Xie, Hao Li, Li Ma, Ning Ye, Yumiao Kang, Dingfeng Luo, Peng Pan, Wei Huang, Zhongmou Liu, Jizhong Hu, Gangyuan Zhao, Chongrong Jiang, Fan Huang, Tianyi Wei, Suqin Tang, Bingjie Xia, Zhifei Zhang, Jianfeng Zhan

A profound gap persists between artificial intelligence (AI) and clinical
practice in medicine, primarily due to the lack of rigorous and cost-effective
evaluation methodologies. State-of-the-art and state-of-the-practice AI model
evaluations are limited to laboratory studies on medical datasets or direct
clinical trials with no or solely patient-centered controls. Moreover, the
crucial role of clinicians in collaborating with AI, pivotal for determining
its impact on clinical practice, is often overlooked. For the first time, we
emphasize the critical necessity for rigorous and cost-effective evaluation
methodologies for AI models in clinical practice, featuring
patient/clinician-centered (dual-centered) AI randomized controlled trials
(DC-AI RCTs) and virtual clinician-based in-silico trials (VC-MedAI) as an
effective proxy for DC-AI RCTs. Leveraging 7500 diagnosis records from
two-phase inaugural DC-AI RCTs across 14 medical centers with 125 clinicians,
our results demonstrate the necessity of DC-AI RCTs and the effectiveness of
VC-MedAI. Notably, VC-MedAI performs comparably to human clinicians,
replicating insights and conclusions from prospective DC-AI RCTs. We envision
DC-AI RCTs and VC-MedAI as pivotal advancements, presenting innovative and
transformative evaluation methodologies for AI models in clinical practice,
offering a preclinical-like setting mirroring conventional medicine, and
reshaping development paradigms in a cost-effective and fast-iterative manner.
Chinese Clinical Trial Registration: ChiCTR2400086816.

摘要：<paragraph>人工智慧（AI）與臨床醫療實務之間存在著巨大的鴻溝，其主要原因在於缺乏嚴謹且具成本效益的評估方法。最先進且符合實務的 AI 模型評估僅限於針對醫學資料集進行的實驗室研究，或僅有患者為中心的對照組的直接臨床試驗。此外，臨床醫師在與 AI 合作中所扮演的關鍵角色，對於決定其對臨床實務的影響至關重要，卻經常被忽視。我們首度強調在臨床實務中採用嚴謹且具成本效益的 AI 模型評估方法至關重要，其特色在於以患者／臨床醫師為中心的（雙中心）AI 隨機對照試驗（DC-AI RCT）和虛擬臨床醫師為基礎的電腦模擬試驗（VC-MedAI），做為 DC-AI RCT 的有效替代方案。利用來自 14 個醫療中心、125 位臨床醫師的兩階段首次 DC-AI RCT 中的 7500 筆診斷紀錄，我們的結果證明了 DC-AI RCT 的必要性與 VC-MedAI 的有效性。值得注意的是，VC-MedAI 的表現與人類臨床醫師相當，複製了前瞻性 DC-AI RCT 的見解和結論。我們將 DC-AI RCT 和 VC-MedAI 視為關鍵的進展，它們提出了創新且具有變革性的 AI 模型評估方法，在臨床實務中提供類似於臨床前設定的環境，反映傳統醫學，並以具成本效益且快速反覆運算的方式重新塑造開發模式。中國臨床試驗註冊：ChiCTR2400086816。</paragraph>

##### **How Deep is your Guess? A Fresh Perspective on Deep Learning for Medical Time-Series Imputation**
2407.08442v1 by Linglong Qian, Tao Wang, Jun Wang, Hugh Logan Ellis, Robin Mitra, Richard Dobson, Zina Ibrahim

We introduce a novel classification framework for time-series imputation
using deep learning, with a particular focus on clinical data. By identifying
conceptual gaps in the literature and existing reviews, we devise a taxonomy
grounded on the inductive bias of neural imputation frameworks, resulting in a
classification of existing deep imputation strategies based on their
suitability for specific imputation scenarios and data-specific properties. Our
review further examines the existing methodologies employed to benchmark deep
imputation models, evaluating their effectiveness in capturing the missingness
scenarios found in clinical data and emphasising the importance of reconciling
mathematical abstraction with clinical insights. Our classification aims to
serve as a guide for researchers to facilitate the selection of appropriate
deep learning imputation techniques tailored to their specific clinical data.
Our novel perspective also highlights the significance of bridging the gap
between computational methodologies and medical insights to achieve clinically
sound imputation models.

摘要：我們提出了一個新的時間序列插補分類架構，使用深度學習，特別關注臨床數據。通過找出文獻和現有評論中的概念差距，我們設計了一個分類法，該分類法基於神經插補框架的歸納偏誤，從而對現有的深度插補策略進行分類，基於它們對特定插補場景和數據特定屬性的適用性。我們的回顧進一步檢驗了用於對深度插補模型進行基準測試的現有方法，評估了它們在捕捉臨床數據中發現的缺失場景方面的有效性，並強調了調和數學抽象與臨床見解的重要性。我們的分類旨在作為研究人員的指南，以促進根據其特定臨床數據選擇適當的深度學習插補技術。我們的新觀點還強調了彌合計算方法和醫學見解之間差距以實現臨床合理插補模型的重要性。

##### **Specialist vision-language models for clinical ophthalmology**
2407.08410v1 by Robbie Holland, Thomas R. P. Taylor, Christopher Holmes, Sophie Riedl, Julia Mai, Maria Patsiamanidi, Dimitra Mitsopoulou, Paul Hager, Philip Müller, Hendrik P. N. Scholl, Hrvoje Bogunović, Ursula Schmidt-Erfurth, Daniel Rueckert, Sobha Sivaprasad, Andrew J. Lotery, Martin J. Menten

Clinicians spend a significant amount of time reviewing medical images and
transcribing their findings regarding patient diagnosis, referral and treatment
in text form. Vision-language models (VLMs), which automatically interpret
images and summarize their findings as text, have enormous potential to
alleviate clinical workloads and increase patient access to high-quality
medical care. While foundational models have stirred considerable interest in
the medical community, it is unclear whether their general capabilities
translate to real-world clinical utility. In this work, we show that foundation
VLMs markedly underperform compared to practicing ophthalmologists on
specialist tasks crucial to the care of patients with age-related macular
degeneration (AMD). To address this, we initially identified the essential
capabilities required for image-based clinical decision-making, and then
developed a curriculum to selectively train VLMs in these skills. The resulting
model, RetinaVLM, can be instructed to write reports that significantly
outperform those written by leading foundation medical VLMs in disease staging
(F1 score of 0.63 vs. 0.11) and patient referral (0.67 vs. 0.39), and
approaches the diagnostic performance of junior ophthalmologists (who achieve
0.77 and 0.78 on the respective tasks). Furthermore, in a reader study
involving two senior ophthalmologists with up to 32 years of experience,
RetinaVLM's reports were found to be similarly correct (78.6% vs. 82.1%) and
complete (both 78.6%) as reports written by junior ophthalmologists with up to
10 years of experience. These results demonstrate that our curriculum-based
approach provides a blueprint for specializing generalist foundation medical
VLMs to handle real-world clinical tasks.

摘要：<paragraph>臨床醫生花費大量時間檢閱醫療影像，並以文字形式記錄他們關於患者診斷、轉診和治療的發現。視覺語言模型 (VLM) 會自動解讀影像並將其發現摘要成文字，具有減輕臨床工作負載和增加患者獲得優質醫療保健的機會的巨大潛力。雖然基礎模型在醫療界引起了相當大的興趣，但尚不清楚它們的一般能力是否能轉化為實際的臨床效用。在這項工作中，我們表明基礎 VLM 在與年齡相關性黃斑部病變 (AMD) 患者照護至關重要的專門任務上，表現明顯不如執業眼科醫生。為了解決這個問題，我們最初找出影像式臨床決策所需的必要能力，然後制定課程來選擇性地訓練 VLM 這些技能。所產生的模型 RetinaVLM 可以被指示撰寫報告，其在疾病分期（F1 分數為 0.63 對 0.11）和患者轉診（0.67 對 0.39）方面明顯優於領先的基礎醫療 VLM 所撰寫的報告，並接近初級眼科醫生的診斷表現（在各項任務中分別達到 0.77 和 0.78）。此外，在涉及兩位擁有長達 32 年經驗的高級眼科醫生的讀者研究中，發現 RetinaVLM 的報告正確性（78.6% 對 82.1%）和完整性（均為 78.6%）與擁有長達 10 年經驗的初級眼科醫生所撰寫的報告相似。這些結果表明，我們基於課程的方法提供了將通才基礎醫療 VLM 專門化以處理實際臨床任務的藍圖。</paragraph>

##### **Unveiling Disparities in Maternity Care: A Topic Modelling Approach to Analysing Maternity Incident Investigation Reports**
2407.08328v1 by Georgina Cosma, Mohit Kumar Singh, Patrick Waterson, Gyuchan Thomas Jun, Jonathan Back

This study applies Natural Language Processing techniques, including Latent
Dirichlet Allocation, to analyse anonymised maternity incident investigation
reports from the Healthcare Safety Investigation Branch. The reports underwent
preprocessing, annotation using the Safety Intelligence Research taxonomy, and
topic modelling to uncover prevalent topics and detect differences in maternity
care across ethnic groups. A combination of offline and online methods was
utilised to ensure data protection whilst enabling advanced analysis, with
offline processing for sensitive data and online processing for non-sensitive
data using the `Claude 3 Opus' language model. Interactive topic analysis and
semantic network visualisation were employed to extract and display thematic
topics and visualise semantic relationships among keywords. The analysis
revealed disparities in care among different ethnic groups, with distinct focus
areas for the Black, Asian, and White British ethnic groups. The study
demonstrates the effectiveness of topic modelling and NLP techniques in
analysing maternity incident investigation reports and highlighting disparities
in care. The findings emphasise the crucial role of advanced data analysis in
improving maternity care quality and equity.

摘要：本研究應用自然語言處理技術，包括潛在狄利克雷分配，分析醫療保健安全調查局的匿名產婦事件調查報告。這些報告經過預處理、使用安全情報研究分類法註解，以及主題建模，以找出普遍的主題並找出不同族群在產前照護的差異。結合離線和線上方法，以確保資料保護，同時進行進階分析，使用 Claude 3 Opus 語言模型對敏感資料進行離線處理，對非敏感資料進行線上處理。採用互動主題分析和語意網路視覺化，以萃取和顯示主題主題，並視覺化關鍵字之間的語意關係。分析顯示不同族群之間的照護差異，黑人、亞洲人和白人英國人族群的關注領域不同。本研究證明了主題建模和自然語言處理技術在分析產婦事件調查報告和強調照護差異方面的有效性。研究結果強調了進階資料分析在提升產前照護品質和公平性方面的關鍵角色。

##### **Predicting Heart Failure with Attention Learning Techniques Utilizing Cardiovascular Data**
2407.08289v1 by Ershadul Haque, Manoranjan Paul, Faranak Tohidi

Cardiovascular diseases (CVDs) encompass a group of disorders affecting the
heart and blood vessels, including conditions such as coronary artery disease,
heart failure, stroke, and hypertension. In cardiovascular diseases, heart
failure is one of the main causes of death and also long-term suffering in
patients worldwide. Prediction is one of the risk factors that is highly
valuable for treatment and intervention to minimize heart failure. In this
work, an attention learning-based heart failure prediction approach is proposed
on EHR(electronic health record) cardiovascular data such as ejection fraction
and serum creatinine. Moreover, different optimizers with various learning rate
approaches are applied to fine-tune the proposed approach. Serum creatinine and
ejection fraction are the two most important features to predict the patient's
heart failure. The computational result shows that the RMSProp optimizer with
0.001 learning rate has a better prediction based on serum creatinine. On the
other hand, the combination of SGD optimizer with 0.01 learning rate exhibits
optimum performance based on ejection fraction features. Overall, the proposed
attention learning-based approach performs very efficiently in predicting heart
failure compared to the existing state-of-the-art such as LSTM approach.

摘要：心血管疾病 (CVD) 包含一組影響心臟和血管的疾病，包括冠狀動脈疾病、心衰竭、中風和高血壓等疾病。在心血管疾病中，心衰竭是全球患者死亡的主要原因之一，也是長期痛苦的來源。預測是對治療和干預以最大程度減少心衰竭極有價值的風險因素之一。在這項工作中，提出了一種基於注意力學習的心衰竭預測方法，該方法基於 EHR（電子健康記錄）心血管數據，例如射血分數和血清肌酐。此外，應用具有各種學習率方法的不同優化器對所提出的方法進行微調。血清肌酐和射血分數是預測患者心衰竭的兩個最重要的特徵。計算結果表明，學習率為 0.001 的 RMSProp 優化器基於血清肌酐具有更好的預測。另一方面，學習率為 0.01 的 SGD 優化器與射血分數特徵相結合，表現出最佳性能。總體而言，與 LSTM 方法等現有技術相比，所提出的基於注意力學習的方法在預測心衰竭方面表現得非常有效。

