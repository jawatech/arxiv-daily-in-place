{"2409.00084": {"publish_time": "2024-08-25", "title": "Vision-Language and Large Language Model Performance in Gastroenterology: GPT, Claude, Llama, Phi, Mistral, Gemma, and Quantized Models", "paper_summary": "Background and Aims: This study evaluates the medical reasoning performance\nof large language models (LLMs) and vision language models (VLMs) in\ngastroenterology.\n  Methods: We used 300 gastroenterology board exam-style multiple-choice\nquestions, 138 of which contain images to systematically assess the impact of\nmodel configurations and parameters and prompt engineering strategies utilizing\nGPT-3.5. Next, we assessed the performance of proprietary and open-source LLMs\n(versions), including GPT (3.5, 4, 4o, 4omini), Claude (3, 3.5), Gemini (1.0),\nMistral, Llama (2, 3, 3.1), Mixtral, and Phi (3), across different interfaces\n(web and API), computing environments (cloud and local), and model precisions\n(with and without quantization). Finally, we assessed accuracy using a\nsemiautomated pipeline.\n  Results: Among the proprietary models, GPT-4o (73.7%) and Claude3.5-Sonnet\n(74.0%) achieved the highest accuracy, outperforming the top open-source\nmodels: Llama3.1-405b (64%), Llama3.1-70b (58.3%), and Mixtral-8x7b (54.3%).\nAmong the quantized open-source models, the 6-bit quantized Phi3-14b (48.7%)\nperformed best. The scores of the quantized models were comparable to those of\nthe full-precision models Llama2-7b, Llama2--13b, and Gemma2-9b. Notably, VLM\nperformance on image-containing questions did not improve when the images were\nprovided and worsened when LLM-generated captions were provided. In contrast, a\n10% increase in accuracy was observed when images were accompanied by\nhuman-crafted image descriptions.\n  Conclusion: In conclusion, while LLMs exhibit robust zero-shot performance in\nmedical reasoning, the integration of visual data remains a challenge for VLMs.\nEffective deployment involves carefully determining optimal model\nconfigurations, encouraging users to consider either the high performance of\nproprietary models or the flexible adaptability of open-source models.", "paper_summary_zh": "<paragraph>\u80cc\u666f\u8207\u76ee\u6a19\uff1a\u672c\u7814\u7a76\u8a55\u4f30\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u548c\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM) \u5728\u8178\u80c3\u75c5\u5b78\u4e2d\u7684\u91ab\u7642\u63a8\u7406\u8868\u73fe\u3002\n\u65b9\u6cd5\uff1a\u6211\u5011\u4f7f\u7528 300 \u500b\u8178\u80c3\u75c5\u5b78\u5c08\u79d1\u8003\u8a66\u98a8\u683c\u7684\u591a\u9078\u984c\uff0c\u5176\u4e2d 138 \u500b\u5305\u542b\u5f71\u50cf\uff0c\u4ee5\u7cfb\u7d71\u6027\u5730\u8a55\u4f30\u6a21\u578b\u914d\u7f6e\u548c\u53c3\u6578\u4ee5\u53ca\u5229\u7528 GPT-3.5 \u7684\u63d0\u793a\u5de5\u7a0b\u7b56\u7565\u7684\u5f71\u97ff\u3002\u63a5\u4e0b\u4f86\uff0c\u6211\u5011\u8a55\u4f30\u5c08\u6709\u548c\u958b\u6e90 LLM\uff08\u7248\u672c\uff09\u7684\u8868\u73fe\uff0c\u5305\u62ec GPT\uff083.5\u30014\u30014o\u30014omini\uff09\u3001Claude\uff083\u30013.5\uff09\u3001Gemini\uff081.0\uff09\u3001Mistral\u3001Llama\uff082\u30013\u30013.1\uff09\u3001Mixtral \u548c Phi\uff083\uff09\uff0c\u8de8\u4e0d\u540c\u4ecb\u9762\uff08\u7db2\u8def\u548c API\uff09\u3001\u904b\u7b97\u74b0\u5883\uff08\u96f2\u7aef\u548c\u672c\u5730\uff09\u548c\u6a21\u578b\u7cbe\u78ba\u5ea6\uff08\u6709\u548c\u6c92\u6709\u91cf\u5316\uff09\u3002\u6700\u5f8c\uff0c\u6211\u5011\u4f7f\u7528\u534a\u81ea\u52d5\u5316\u7ba1\u9053\u8a55\u4f30\u6e96\u78ba\u5ea6\u3002\n\u7d50\u679c\uff1a\u5728\u5c08\u6709\u6a21\u578b\u4e2d\uff0cGPT-4o\uff0873.7%\uff09\u548c Claude3.5-Sonnet\uff0874.0%\uff09\u9054\u5230\u6700\u9ad8\u6e96\u78ba\u5ea6\uff0c\u512a\u65bc\u9802\u5c16\u7684\u958b\u6e90\u6a21\u578b\uff1aLlama3.1-405b\uff0864%\uff09\u3001Llama3.1-70b\uff0858.3%\uff09\u548c Mixtral-8x7b\uff0854.3%\uff09\u3002\u5728\u91cf\u5316\u7684\u958b\u6e90\u6a21\u578b\u4e2d\uff0c6 \u4f4d\u5143\u91cf\u5316\u7684 Phi3-14b\uff0848.7%\uff09\u8868\u73fe\u6700\u4f73\u3002\u91cf\u5316\u6a21\u578b\u7684\u5206\u6578\u8207\u5168\u7cbe\u5ea6\u6a21\u578b Llama2-7b\u3001Llama2--13b \u548c Gemma2-9b \u76f8\u7576\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u7576\u63d0\u4f9b\u5f71\u50cf\u6642\uff0cVLM \u5728\u5305\u542b\u5f71\u50cf\u7684\u554f\u984c\u4e0a\u7684\u8868\u73fe\u4e26\u672a\u6539\u5584\uff0c\u800c\u5728\u63d0\u4f9b LLM \u751f\u6210\u7684\u6a19\u984c\u6642\u8868\u73fe\u60e1\u5316\u3002\u76f8\u53cd\u5730\uff0c\u7576\u5f71\u50cf\u9644\u6709\u4eba\u5de5\u88fd\u4f5c\u7684\u5f71\u50cf\u63cf\u8ff0\u6642\uff0c\u6e96\u78ba\u5ea6\u89c0\u5bdf\u5230\u589e\u52a0\u4e86 10%\u3002\n\u7d50\u8ad6\uff1a\u7d50\u8ad6\u800c\u8a00\uff0c\u96d6\u7136 LLM \u5728\u91ab\u7642\u63a8\u7406\u4e2d\u8868\u73fe\u51fa\u5f37\u5065\u7684\u96f6\u6b21\u5b78\u7fd2\u8868\u73fe\uff0c\u4f46\u8996\u89ba\u8cc7\u6599\u7684\u6574\u5408\u4ecd\u7136\u662f VLM \u7684\u4e00\u9805\u6311\u6230\u3002\u6709\u6548\u7684\u90e8\u7f72\u6d89\u53ca\u4ed4\u7d30\u78ba\u5b9a\u6700\u4f73\u6a21\u578b\u914d\u7f6e\uff0c\u9f13\u52f5\u4f7f\u7528\u8005\u8003\u616e\u5c08\u6709\u6a21\u578b\u7684\u9ad8\u6548\u80fd\u6216\u958b\u6e90\u6a21\u578b\u7684\u9748\u6d3b\u9069\u61c9\u6027\u3002</paragraph>", "author": "Seyed Amir Ahmad Safavi-Naini et.al.", "authors": "Seyed Amir Ahmad Safavi-Naini, Shuhaib Ali, Omer Shahab, Zahra Shahhoseini, Thomas Savage, Sara Rafiee, Jamil S Samaan, Reem Al Shabeeb, Farah Ladak, Jamie O Yang, Juan Echavarria, Sumbal Babar, Aasma Shaukat, Samuel Margolis, Nicholas P Tatonetti, Girish Nadkarni, Bara El Kurdi, Ali Soroush", "id": "2409.00084v2", "paper_url": "http://arxiv.org/abs/2409.00084v2", "repo": "https://github.com/sdamirsa/llm-vlm-in-gastroenterology"}}