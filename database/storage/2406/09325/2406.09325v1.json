{"2406.09325": {"publish_time": "2024-06-13", "title": "REVS: Unlearning Sensitive Information in Language Models via Rank Editing in the Vocabulary Space", "paper_summary": "Large language models (LLMs) risk inadvertently memorizing and divulging\nsensitive or personally identifiable information (PII) seen in training data,\ncausing privacy concerns. Current approaches to address this issue involve\ncostly dataset scrubbing, or model filtering through unlearning and model\nediting, which can be bypassed through extraction attacks. We propose REVS, a\nnovel model editing method for unlearning sensitive information from LLMs. REVS\nidentifies and modifies a small subset of neurons relevant for each piece of\nsensitive information. By projecting these neurons to the vocabulary space\n(unembedding), we pinpoint the components driving its generation. We then\ncompute a model edit based on the pseudo-inverse of the unembedding matrix, and\napply it to de-promote generation of the targeted sensitive data. To adequately\nevaluate our method on truly sensitive information, we curate two datasets: an\nemail dataset inherently memorized by GPT-J, and a synthetic social security\nnumber dataset that we tune the model to memorize. Compared to other\nstate-of-the-art model editing methods, REVS demonstrates superior performance\nin both eliminating sensitive information and robustness to extraction attacks,\nwhile retaining integrity of the underlying model. The code and a demo notebook\nare available at https://technion-cs-nlp.github.io/REVS.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6709\u98a8\u96aa\u6703\u4e0d\u7d93\u610f\u5730\u8a18\u61b6\u548c\u6d29\u9732\u5728\u8a13\u7df4\u8cc7\u6599\u4e2d\u770b\u5230\u7684\u654f\u611f\u6216\u500b\u4eba\u53ef\u8b58\u5225\u8cc7\u8a0a (PII)\uff0c\u9020\u6210\u96b1\u79c1\u554f\u984c\u3002\u76ee\u524d\u89e3\u6c7a\u6b64\u554f\u984c\u7684\u65b9\u6cd5\u5305\u62ec\u4ee3\u50f9\u9ad8\u6602\u7684\u8cc7\u6599\u96c6\u6e05\u9664\uff0c\u6216\u900f\u904e\u5fd8\u8a18\u548c\u6a21\u578b\u7de8\u8f2f\u4f86\u9032\u884c\u6a21\u578b\u7be9\u9078\uff0c\u4f46\u9019\u53ef\u80fd\u6703\u88ab\u64f7\u53d6\u653b\u64ca\u7e5e\u904e\u3002\u6211\u5011\u63d0\u51fa REVS\uff0c\u4e00\u7a2e\u7528\u65bc\u5f9e LLM \u4e2d\u5fd8\u8a18\u654f\u611f\u8cc7\u8a0a\u7684\u65b0\u7a4e\u6a21\u578b\u7de8\u8f2f\u65b9\u6cd5\u3002REVS \u6703\u8b58\u5225\u4e26\u4fee\u6539\u8207\u6bcf\u4e00\u6bb5\u654f\u611f\u8cc7\u8a0a\u76f8\u95dc\u7684\u5c0f\u90e8\u5206\u795e\u7d93\u5143\u3002\u900f\u904e\u5c07\u9019\u4e9b\u795e\u7d93\u5143\u6295\u5f71\u5230\u8a5e\u5f59\u7a7a\u9593\uff08\u53d6\u6d88\u5d4c\u5165\uff09\uff0c\u6211\u5011\u53ef\u4ee5\u7cbe\u78ba\u627e\u51fa\u9a45\u52d5\u5176\u7522\u751f\u7684\u7d44\u6210\u90e8\u5206\u3002\u63a5\u8457\uff0c\u6211\u5011\u6839\u64da\u53d6\u6d88\u5d4c\u5165\u77e9\u9663\u7684\u507d\u9006\u4f86\u8a08\u7b97\u6a21\u578b\u7de8\u8f2f\uff0c\u4e26\u5957\u7528\u5b83\u4f86\u964d\u4f4e\u76ee\u6a19\u654f\u611f\u8cc7\u6599\u7522\u751f\u7684\u512a\u5148\u9806\u5e8f\u3002\u70ba\u4e86\u9069\u7576\u5730\u8a55\u4f30\u6211\u5011\u7684\u65b9\u6cd5\u5c0d\u771f\u6b63\u654f\u611f\u8cc7\u8a0a\u7684\u5f71\u97ff\uff0c\u6211\u5011\u7b56\u5283\u4e86\u5169\u500b\u8cc7\u6599\u96c6\uff1a\u4e00\u500b\u7531 GPT-J \u5167\u5efa\u8a18\u61b6\u7684\u96fb\u5b50\u90f5\u4ef6\u8cc7\u6599\u96c6\uff0c\u4ee5\u53ca\u4e00\u500b\u6211\u5011\u8abf\u6574\u6a21\u578b\u4ee5\u8a18\u61b6\u7684\u5408\u6210\u793e\u6703\u5b89\u5168\u865f\u78bc\u8cc7\u6599\u96c6\u3002\u8207\u5176\u4ed6\u6700\u5148\u9032\u7684\u6a21\u578b\u7de8\u8f2f\u65b9\u6cd5\u76f8\u6bd4\uff0cREVS \u5728\u6d88\u9664\u654f\u611f\u8cc7\u8a0a\u548c\u5c0d\u6297\u64f7\u53d6\u653b\u64ca\u7684\u5f37\u5065\u6027\u65b9\u9762\u90fd\u5c55\u73fe\u51fa\u5353\u8d8a\u7684\u6548\u80fd\uff0c\u540c\u6642\u4fdd\u7559\u57fa\u790e\u6a21\u578b\u7684\u5b8c\u6574\u6027\u3002\u7a0b\u5f0f\u78bc\u548c\u793a\u7bc4\u7b46\u8a18\u672c\u53ef\u4ee5\u5728 https://technion-cs-nlp.github.io/REVS \u53d6\u5f97\u3002", "author": "Tomer Ashuach et.al.", "authors": "Tomer Ashuach, Martin Tutek, Yonatan Belinkov", "id": "2406.09325v1", "paper_url": "http://arxiv.org/abs/2406.09325v1", "repo": "null"}}