
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-10**|**SAT: Spatial Aptitude Training for Multimodal Language Models**|Arijit Ray et.al.|[2412.07755v1](http://arxiv.org/abs/2412.07755v1)|null|
|**2024-12-10**|**PortraitTalk: Towards Customizable One-Shot Audio-to-Talking Face Generation**|Fatemeh Nazarieh et.al.|[2412.07754v1](http://arxiv.org/abs/2412.07754v1)|null|
|**2024-12-10**|**FlashRNN: Optimizing Traditional RNNs on Modern Hardware**|Korbinian Pöppel et.al.|[2412.07752v1](http://arxiv.org/abs/2412.07752v1)|null|
|**2024-12-10**|**Predictive Modeling of Homeless Service Assignment: A Representation Learning Approach**|Khandker Sadia Rahman et.al.|[2412.07747v1](http://arxiv.org/abs/2412.07747v1)|null|
|**2024-12-10**|**Zero-Shot ATC Coding with Large Language Models for Clinical Assessments**|Zijian Chen et.al.|[2412.07743v1](http://arxiv.org/abs/2412.07743v1)|null|
|**2024-12-10**|**GASP: Gaussian Avatars with Synthetic Priors**|Jack Saunders et.al.|[2412.07739v1](http://arxiv.org/abs/2412.07739v1)|null|
|**2024-12-10**|**STIV: Scalable Text and Image Conditioned Video Generation**|Zongyu Lin et.al.|[2412.07730v1](http://arxiv.org/abs/2412.07730v1)|null|
|**2024-12-10**|**Granite Guardian**|Inkit Padhi et.al.|[2412.07724v1](http://arxiv.org/abs/2412.07724v1)|[link](https://github.com/ibm-granite/granite-guardian)|
|**2024-12-10**|**Benchmark for Evaluation and Analysis of Citation Recommendation Models**|Puja Maharjan et.al.|[2412.07713v1](http://arxiv.org/abs/2412.07713v1)|null|
|**2024-12-10**|**SimVS: Simulating World Inconsistencies for Robust View Synthesis**|Alex Trevithick et.al.|[2412.07696v1](http://arxiv.org/abs/2412.07696v1)|null|
|**2024-12-10**|**The Pitfalls of Memorization: When Memorization Hurts Generalization**|Reza Bayat et.al.|[2412.07684v1](http://arxiv.org/abs/2412.07684v1)|null|
|**2024-12-10**|**TRIM: Token Reduction and Inference Modeling for Cost-Effective Language Generation**|Alfredo Garrachón Ruiz et.al.|[2412.07682v1](http://arxiv.org/abs/2412.07682v1)|null|
|**2024-12-10**|**RADIO Amplified: Improved Baselines for Agglomerative Vision Foundation Models**|Greg Heinrich et.al.|[2412.07679v1](http://arxiv.org/abs/2412.07679v1)|null|
|**2024-12-10**|**Can linguists better understand DNA?**|Wang Liang et.al.|[2412.07678v1](http://arxiv.org/abs/2412.07678v1)|null|
|**2024-12-10**|**RAZOR: Sharpening Knowledge by Cutting Bias with Unsupervised Text Rewriting**|Shuo Yang et.al.|[2412.07675v1](http://arxiv.org/abs/2412.07675v1)|null|
|**2024-12-10**|**FlexLLM: Exploring LLM Customization for Moving Target Defense on Black-Box LLMs Against Jailbreak Attacks**|Bocheng Chen et.al.|[2412.07672v1](http://arxiv.org/abs/2412.07672v1)|null|
|**2024-12-10**|**TraSCE: Trajectory Steering for Concept Erasure**|Anubhav Jain et.al.|[2412.07658v1](http://arxiv.org/abs/2412.07658v1)|null|
|**2024-12-10**|**Searching for Structure: Investigating Emergent Communication with Large Language Models**|Tom Kouwenhoven et.al.|[2412.07646v1](http://arxiv.org/abs/2412.07646v1)|null|
|**2024-12-10**|**TrojanWhisper: Evaluating Pre-trained LLMs to Detect and Localize Hardware Trojans**|Md Omar Faruque et.al.|[2412.07636v1](http://arxiv.org/abs/2412.07636v1)|null|
|**2024-12-10**|**ChocoLlama: Lessons Learned From Teaching Llamas Dutch**|Matthieu Meeus et.al.|[2412.07633v1](http://arxiv.org/abs/2412.07633v1)|null|
|**2024-12-10**|**Piece of Table: A Divide-and-Conquer Approach for Selecting Sub-Tables in Table Question Answering**|Wonjin Lee et.al.|[2412.07629v1](http://arxiv.org/abs/2412.07629v1)|null|
|**2024-12-10**|**OmniDocBench: Benchmarking Diverse PDF Document Parsing with Comprehensive Annotations**|Linke Ouyang et.al.|[2412.07626v1](http://arxiv.org/abs/2412.07626v1)|[link](https://github.com/opendatalab/OmniDocBench)|
|**2024-12-10**|**DRUM: Learning Demonstration Retriever for Large MUlti-modal Models**|Ellen Yi-Ge et.al.|[2412.07619v1](http://arxiv.org/abs/2412.07619v1)|null|
|**2024-12-10**|**Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs**|Xiaqiang Tang et.al.|[2412.07618v1](http://arxiv.org/abs/2412.07618v1)|[link](https://github.com/futureeeeee/dynamic-rag)|
|**2024-12-10**|**Swarm Behavior Cloning**|Jonas Nüßlein et.al.|[2412.07617v1](http://arxiv.org/abs/2412.07617v1)|null|
|**2024-12-10**|**Scaling Sequential Recommendation Models with Transformers**|Pablo Zivic et.al.|[2412.07585v1](http://arxiv.org/abs/2412.07585v1)|[link](https://github.com/mercadolibre/srt)|
|**2024-12-10**|**Multimodal Contextualized Support for Enhancing Video Retrieval System**|Quoc-Bao Nguyen-Le et.al.|[2412.07584v1](http://arxiv.org/abs/2412.07584v1)|null|
|**2024-12-10**|**Mobile Video Diffusion**|Haitam Ben Yahia et.al.|[2412.07583v1](http://arxiv.org/abs/2412.07583v1)|null|
|**2024-12-10**|**SST framework for Document Matching**|Youchao Zhou et.al.|[2412.07573v1](http://arxiv.org/abs/2412.07573v1)|null|
|**2024-12-10**|**A data-driven learned discretization approach in finite volume schemes for hyperbolic conservation laws and varying boundary conditions**|Guillaume de Romémont et.al.|[2412.07541v1](http://arxiv.org/abs/2412.07541v1)|[link](https://github.com/guigzair/burgers_1d)|
|**2024-12-10**|**CoPrUS: Consistency Preserving Utterance Synthesis towards more realistic benchmark dialogues**|Sebastian Steindl et.al.|[2412.07515v1](http://arxiv.org/abs/2412.07515v1)|null|
|**2024-12-10**|**Ontology-driven Prompt Tuning for LLM-based Task and Motion Planning**|Muhayy Ud Din et.al.|[2412.07493v1](http://arxiv.org/abs/2412.07493v1)|null|
|**2024-12-10**|**SmartAgent: Chain-of-User-Thought for Embodied Personalized Agent in Cyber World**|Jiaqi Zhang et.al.|[2412.07472v1](http://arxiv.org/abs/2412.07472v1)|[link](https://github.com/tsinghua-fib-lab/smartagent)|
|**2024-12-10**|**Bilingual BSARD: Extending Statutory Article Retrieval to Dutch**|Ehsan Lotfi et.al.|[2412.07462v1](http://arxiv.org/abs/2412.07462v1)|null|
|**2024-12-10**|**Tazza: Shuffling Neural Network Parameters for Secure and Private Federated Learning**|Kichang Lee et.al.|[2412.07454v1](http://arxiv.org/abs/2412.07454v1)|null|
|**2024-12-10**|**Dynamic Ensemble Reasoning for LLM Experts**|Jinwu Hu et.al.|[2412.07448v1](http://arxiv.org/abs/2412.07448v1)|null|
|**2024-12-10**|**Causal World Representation in the GPT Model**|Raanan Y. Rohekar et.al.|[2412.07446v1](http://arxiv.org/abs/2412.07446v1)|null|
|**2024-12-10**|**Knowledge Graph Guided Evaluation of Abstention Techniques**|Kinshuk Vasisht et.al.|[2412.07430v1](http://arxiv.org/abs/2412.07430v1)|null|
|**2024-12-10**|**Optimizing Alignment with Less: Leveraging Data Augmentation for Personalized Evaluation**|Javad Seraj et.al.|[2412.07429v1](http://arxiv.org/abs/2412.07429v1)|null|
|**2024-12-10**|**RAG-based Question Answering over Heterogeneous Data and Text**|Philipp Christmann et.al.|[2412.07420v1](http://arxiv.org/abs/2412.07420v1)|null|
|**2024-12-10**|**Composing or Not Composing? Towards Distributional Construction Grammars**|Philippe Blache et.al.|[2412.07419v1](http://arxiv.org/abs/2412.07419v1)|null|
|**2024-12-10**|**Generating Knowledge Graphs from Large Language Models: A Comparative Study of GPT-4, LLaMA 2, and BERT**|Ahan Bhatt et.al.|[2412.07412v1](http://arxiv.org/abs/2412.07412v1)|null|
|**2024-12-10**|**DSFEC: Efficient and Deployable Deep Radar Object Detection**|Gayathri Dandugula et.al.|[2412.07411v1](http://arxiv.org/abs/2412.07411v1)|null|
|**2024-12-10**|**Explainability of Deep Learning-Based Plant Disease Classifiers Through Automated Concept Identification**|Jihen Amara et.al.|[2412.07408v1](http://arxiv.org/abs/2412.07408v1)|null|
|**2024-12-10**|**MoDULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning**|Yufei Ma et.al.|[2412.07405v1](http://arxiv.org/abs/2412.07405v1)|null|
|**2024-12-10**|**Non-Progressive Influence Maximization in Dynamic Social Networks**|Yunming Hui et.al.|[2412.07402v1](http://arxiv.org/abs/2412.07402v1)|null|
|**2024-12-10**|**CMT: A Memory Compression Method for Continual Knowledge Learning of Large Language Models**|Dongfang Li et.al.|[2412.07393v1](http://arxiv.org/abs/2412.07393v1)|null|
|**2024-12-10**|**A Review of Challenges in Speech-based Conversational AI for Elderly Care**|Willemijn Klaassen et.al.|[2412.07388v1](http://arxiv.org/abs/2412.07388v1)|null|
|**2024-12-10**|**Enhanced MRI Representation via Cross-series Masking**|Churan Wang et.al.|[2412.07387v1](http://arxiv.org/abs/2412.07387v1)|null|
|**2024-12-10**|**Algorithmic Phase Transitions in Language Models: A Mechanistic Case Study of Arithmetic**|Alan Sun et.al.|[2412.07386v1](http://arxiv.org/abs/2412.07386v1)|null|
|**2024-12-10**|**SpecFuse: Ensembling Large Language Models via Next-Segment Prediction**|Bo Lv et.al.|[2412.07380v1](http://arxiv.org/abs/2412.07380v1)|null|
|**2024-12-10**|**My Words Imply Your Opinion: Reader Agent-Based Propagation Enhancement for Personalized Implicit Emotion Analysis**|Jian Liao et.al.|[2412.07367v1](http://arxiv.org/abs/2412.07367v1)|null|
|**2024-12-10**|**Towards Predictive Communication with Brain-Computer Interfaces integrating Large Language Models**|Andrea Caria et.al.|[2412.07355v1](http://arxiv.org/abs/2412.07355v1)|null|
|**2024-12-10**|**Contextualized Counterspeech: Strategies for Adaptation, Personalization, and Evaluation**|Lorenzo Cima et.al.|[2412.07338v1](http://arxiv.org/abs/2412.07338v1)|null|
|**2024-12-10**|**Frame Representation Hypothesis: Multi-Token LLM Interpretability and Concept-Guided Text Generation**|Pedro H. V. Valois et.al.|[2412.07334v1](http://arxiv.org/abs/2412.07334v1)|[link](https://github.com/phvv-me/frame-representation-hypothesis)|
|**2024-12-10**|**Fusion Embedding for Pose-Guided Person Image Synthesis with Diffusion Model**|Donghwna Lee et.al.|[2412.07333v1](http://arxiv.org/abs/2412.07333v1)|null|
|**2024-12-10**|**Filipino Benchmarks for Measuring Sexist and Homophobic Bias in Multilingual Language Models from Southeast Asia**|Lance Calvin Lim Gamboa et.al.|[2412.07303v1](http://arxiv.org/abs/2412.07303v1)|null|
|**2024-12-10**|**The Rise and Down of Babel Tower: Investigating the Evolution Process of Multilingual Code Large Language Model**|Jiawei Chen et.al.|[2412.07298v1](http://arxiv.org/abs/2412.07298v1)|null|
|**2024-12-10**|**Enhancing Relation Extraction via Supervised Rationale Verification and Feedback**|Yongqi Li et.al.|[2412.07289v1](http://arxiv.org/abs/2412.07289v1)|[link](https://github.com/nlpgm/srvf)|
|**2024-12-10**|**HARP: Hesitation-Aware Reframing in Transformer Inference Pass**|Romain Storaï et.al.|[2412.07282v1](http://arxiv.org/abs/2412.07282v1)|[link](https://github.com/romsto/harp)|
|**2024-12-10**|**Superficial Consciousness Hypothesis for Autoregressive Transformers**|Yosuke Miyanishi et.al.|[2412.07278v1](http://arxiv.org/abs/2412.07278v1)|null|
|**2024-12-10**|**Temporal-Aware Evaluation and Learning for Temporal Graph Neural Networks**|Junwei Su et.al.|[2412.07273v1](http://arxiv.org/abs/2412.07273v1)|null|
|**2024-12-10**|**Goal-Driven Reasoning in DatalogMTL with Magic Sets**|Shaoyu Wang et.al.|[2412.07259v1](http://arxiv.org/abs/2412.07259v1)|null|
|**2024-12-10**|**Label-Confidence-Aware Uncertainty Estimation in Natural Language Generation**|Qinhong Lin et.al.|[2412.07255v1](http://arxiv.org/abs/2412.07255v1)|null|
|**2024-12-10**|**KULTURE Bench: A Benchmark for Assessing Language Model in Korean Cultural Context**|Xiaonan Wang et.al.|[2412.07251v1](http://arxiv.org/abs/2412.07251v1)|null|
|**2024-12-10**|**Buster: Incorporating Backdoor Attacks into Text Encoder to Mitigate NSFW Content Generation**|Xin Zhao et.al.|[2412.07249v1](http://arxiv.org/abs/2412.07249v1)|null|
|**2024-12-10**|**Filling Memory Gaps: Enhancing Continual Semantic Parsing via SQL Syntax Variance-Guided LLMs without Real Data Replay**|Ruiheng Liu et.al.|[2412.07246v1](http://arxiv.org/abs/2412.07246v1)|null|
|**2024-12-10**|**Speaker effects in spoken language comprehension**|Hanlin Wu et.al.|[2412.07238v1](http://arxiv.org/abs/2412.07238v1)|null|
|**2024-12-10**|**ArtFormer: Controllable Generation of Diverse 3D Articulated Objects**|Jiayi Su et.al.|[2412.07237v1](http://arxiv.org/abs/2412.07237v1)|[link](https://github.com/shuyumo2003/artformer)|
|**2024-12-10**|**CBraMod: A Criss-Cross Brain Foundation Model for EEG Decoding**|Jiquan Wang et.al.|[2412.07236v1](http://arxiv.org/abs/2412.07236v1)|[link](https://github.com/wjq-learning/cbramod)|
|**2024-12-10**|**MPSI: Mamba enhancement model for pixel-wise sequential interaction Image Super-Resolution**|Yuchun He et.al.|[2412.07222v1](http://arxiv.org/abs/2412.07222v1)|null|
|**2024-12-10**|**Comateformer: Combined Attention Transformer for Semantic Sentence Matching**|Bo Li et.al.|[2412.07220v1](http://arxiv.org/abs/2412.07220v1)|null|
|**2024-12-10**|**Towards Automated Cross-domain Exploratory Data Analysis through Large Language Models**|Jun-Peng Zhu et.al.|[2412.07214v1](http://arxiv.org/abs/2412.07214v1)|[link](https://github.com/tidbcloud/tiinsight)|
|**2024-12-10**|**IntellectSeeker: A Personalized Literature Management System with the Probabilistic Model and Large Language Model**|Weizhen Bian et.al.|[2412.07213v1](http://arxiv.org/abs/2412.07213v1)|[link](https://github.com/luckybian/isy5001)|
|**2024-12-10**|**EDiT: A Local-SGD-Based Efficient Distributed Training Method for Large Language Models**|Jialiang Cheng et.al.|[2412.07210v1](http://arxiv.org/abs/2412.07210v1)|null|
|**2024-12-10**|**MAPLE: A Framework for Active Preference Learning Guided by Large Language Models**|Saaduddin Mahmud et.al.|[2412.07207v1](http://arxiv.org/abs/2412.07207v1)|null|
|**2024-12-10**|**A Review on the Applications of Transformer-based language models for Nucleotide Sequence Analysis**|Nimisha Ghosh et.al.|[2412.07201v1](http://arxiv.org/abs/2412.07201v1)|null|
|**2024-12-10**|**Hierarchical Split Federated Learning: Convergence Analysis and System Optimization**|Zheng Lin et.al.|[2412.07197v1](http://arxiv.org/abs/2412.07197v1)|null|
|**2024-12-10**|**PrisonBreak: Jailbreaking Large Language Models with Fewer Than Twenty-Five Targeted Bit-flips**|Zachary Coalson et.al.|[2412.07192v1](http://arxiv.org/abs/2412.07192v1)|null|
|**2024-12-10**|**Exploring What Why and How: A Multifaceted Benchmark for Causation Understanding of Video Anomaly**|Hang Du et.al.|[2412.07183v1](http://arxiv.org/abs/2412.07183v1)|null|
|**2024-12-10**|**An Enhancement of CNN Algorithm for Rice Leaf Disease Image Classification in Mobile Applications**|Kayne Uriel K. Rodrigo et.al.|[2412.07182v1](http://arxiv.org/abs/2412.07182v1)|null|
|**2024-12-10**|**Post-Training Statistical Calibration for Higher Activation Sparsity**|Vui Seng Chua et.al.|[2412.07174v1](http://arxiv.org/abs/2412.07174v1)|[link](https://github.com/intellabs/scap)|
|**2024-12-10**|**Breaking the Stage Barrier: A Novel Single-Stage Approach to Long Context Extension for Large Language Models**|Haoran Lian et.al.|[2412.07171v1](http://arxiv.org/abs/2412.07171v1)|null|
|**2024-12-10**|**Fast Occupancy Network**|Mingjie Lu et.al.|[2412.07163v1](http://arxiv.org/abs/2412.07163v1)|null|
|**2024-12-10**|**MM-PoE: Multiple Choice Reasoning via. Process of Elimination using Multi-Modal Models**|Sayak Chakrabarty et.al.|[2412.07148v1](http://arxiv.org/abs/2412.07148v1)|[link](https://github.com/souradipp76/mm-poe)|
|**2024-12-10**|**MIT-10M: A Large Scale Parallel Corpus of Multilingual Image Translation**|Bo Li et.al.|[2412.07147v1](http://arxiv.org/abs/2412.07147v1)|null|
|**2024-12-10**|**Political Actor Agent: Simulating Legislative System for Roll Call Votes Prediction with Large Language Models**|Hao Li et.al.|[2412.07144v1](http://arxiv.org/abs/2412.07144v1)|null|
|**2024-12-10**|**Bridging the Gap for Test-Time Multimodal Sentiment Analysis**|Zirun Guo et.al.|[2412.07121v1](http://arxiv.org/abs/2412.07121v1)|[link](https://github.com/zrguo/casp)|
|**2024-12-10**|**A Review of Human Emotion Synthesis Based on Generative Technology**|Fei Ma et.al.|[2412.07116v1](http://arxiv.org/abs/2412.07116v1)|null|
|**2024-12-10**|**Exploring Coding Spot: Understanding Parametric Contributions to LLM Coding Performance**|Dongjun Kim et.al.|[2412.07113v1](http://arxiv.org/abs/2412.07113v1)|null|
|**2024-12-10**|**Maya: An Instruction Finetuned Multilingual Multimodal Model**|Nahid Alam et.al.|[2412.07112v1](http://arxiv.org/abs/2412.07112v1)|[link](https://github.com/nahidalam/maya)|
|**2024-12-10**|**Predictable Emergent Abilities of LLMs: Proxy Tasks Are All You Need**|Bo-Wen Zhang et.al.|[2412.07111v1](http://arxiv.org/abs/2412.07111v1)|null|
|**2024-12-10**|**Improving the Natural Language Inference robustness to hard dataset by data augmentation and preprocessing**|Zijiang Yang et.al.|[2412.07108v1](http://arxiv.org/abs/2412.07108v1)|null|
|**2024-12-10**|**On Evaluating the Durability of Safeguards for Open-Weight LLMs**|Xiangyu Qi et.al.|[2412.07097v1](http://arxiv.org/abs/2412.07097v1)|null|
|**2024-12-10**|**EvRepSL: Event-Stream Representation via Self-Supervised Learning for Event-Based Vision**|Qiang Qu et.al.|[2412.07080v1](http://arxiv.org/abs/2412.07080v1)|[link](https://github.com/vincentqqu/evrepsl)|
|**2024-12-10**|**Defensive Dual Masking for Robust Adversarial Defense**|Wangli Yang et.al.|[2412.07078v1](http://arxiv.org/abs/2412.07078v1)|null|
|**2024-12-10**|**The Mirage of Artificial Intelligence Terms of Use Restrictions**|Peter Henderson et.al.|[2412.07066v1](http://arxiv.org/abs/2412.07066v1)|null|
|**2024-12-09**|**Generative AI Impact on Labor Market: Analyzing ChatGPT's Demand in Job Advertisements**|Mahdi Ahmadi et.al.|[2412.07042v1](http://arxiv.org/abs/2412.07042v1)|null|
|**2024-12-09**|**Large Language Models: An Applied Econometric Framework**|Jens Ludwig et.al.|[2412.07031v1](http://arxiv.org/abs/2412.07031v1)|null|
|**2024-12-09**|**FM2DS: Few-Shot Multimodal Multihop Data Synthesis with Knowledge Distillation for Question Answering**|Amirhossein Abaskohi et.al.|[2412.07030v1](http://arxiv.org/abs/2412.07030v1)|null|

#### Abstracts
##### **SAT: Spatial Aptitude Training for Multimodal Language Models**
2412.07755v1 by Arijit Ray, Jiafei Duan, Reuben Tan, Dina Bashkirova, Rose Hendrix, Kiana Ehsani, Aniruddha Kembhavi, Bryan A. Plummer, Ranjay Krishna, Kuo-Hao Zeng, Kate Saenko

Spatial perception is a fundamental component of intelligence. While many
studies highlight that large multimodal language models (MLMs) struggle to
reason about space, they only test for static spatial reasoning, such as
categorizing the relative positions of objects. Meanwhile, real-world
deployment requires dynamic capabilities like perspective-taking and egocentric
action recognition. As a roadmap to improving spatial intelligence, we
introduce SAT, Spatial Aptitude Training, which goes beyond static relative
object position questions to the more dynamic tasks. SAT contains 218K
question-answer pairs for 22K synthetic scenes across a training and testing
set. Generated using a photo-realistic physics engine, our dataset can be
arbitrarily scaled and easily extended to new actions, scenes, and 3D assets.
We find that even MLMs that perform relatively well on static questions
struggle to accurately answer dynamic spatial questions. Further, we show that
SAT instruction-tuning data improves not only dynamic spatial reasoning on SAT,
but also zero-shot performance on existing real-image spatial benchmarks:
$23\%$ on CVBench, $8\%$ on the harder BLINK benchmark, and $18\%$ on VSR. When
instruction-tuned on SAT, our 13B model matches larger proprietary MLMs like
GPT4-V and Gemini-3-1.0 in spatial reasoning. Our data/code is available at
http://arijitray1993.github.io/SAT/ .

摘要：空間感知是智慧的基本組成部分。雖然許多研究強調大型多模態語言模型 (MLM) 難以推論空間，但它們僅測試靜態空間推理，例如分類物體的相對位置。同時，現實世界的部署需要動態能力，例如觀點採取和自我中心動作識別。作為改善空間智慧的路線圖，我們引入了 SAT（空間能力訓練），它超越了靜態相對物體位置問題，轉向更動態的任務。SAT 包含 218K 個問題解答對，適用於訓練和測試集中 22K 個合成場景。我們的數據集使用逼真的物理引擎生成，可以任意縮放，並輕鬆擴展到新的動作、場景和 3D 資產。我們發現，即使在靜態問題上表現相對良好的 MLM 也難以準確回答動態空間問題。此外，我們表明 SAT 指令調整數據不僅改善了 SAT 上的動態空間推理，還改善了現有真實圖像空間基準上的零次學習效能：CVBench 上的 23%，較困難的 BLINK 基準上的 8%，以及 VSR 上的 18%。當在 SAT 上進行指令調整後，我們的 13B 模型在空間推理中與 GPT4-V 和 Gemini-3-1.0 等較大的專有 MLM 相匹配。我們的數據/程式碼可在 http://arijitray1993.github.io/SAT/ 取得。

##### **PortraitTalk: Towards Customizable One-Shot Audio-to-Talking Face Generation**
2412.07754v1 by Fatemeh Nazarieh, Zhenhua Feng, Diptesh Kanojia, Muhammad Awais, Josef Kittler

Audio-driven talking face generation is a challenging task in digital
communication. Despite significant progress in the area, most existing methods
concentrate on audio-lip synchronization, often overlooking aspects such as
visual quality, customization, and generalization that are crucial to producing
realistic talking faces. To address these limitations, we introduce a novel,
customizable one-shot audio-driven talking face generation framework, named
PortraitTalk. Our proposed method utilizes a latent diffusion framework
consisting of two main components: IdentityNet and AnimateNet. IdentityNet is
designed to preserve identity features consistently across the generated video
frames, while AnimateNet aims to enhance temporal coherence and motion
consistency. This framework also integrates an audio input with the reference
images, thereby reducing the reliance on reference-style videos prevalent in
existing approaches. A key innovation of PortraitTalk is the incorporation of
text prompts through decoupled cross-attention mechanisms, which significantly
expands creative control over the generated videos. Through extensive
experiments, including a newly developed evaluation metric, our model
demonstrates superior performance over the state-of-the-art methods, setting a
new standard for the generation of customizable realistic talking faces
suitable for real-world applications.

摘要：語音驅動對話人臉生成是數位溝通中的一項艱鉅任務。儘管該領域已取得顯著進展，但現有方法大多集中在音訊唇形同步，往往忽略了視覺品質、自訂化和泛化等對於產生逼真對話人臉至關重要的面向。為了解決這些限制，我們提出了一個新穎、可自訂的單次音訊驅動對話人臉生成架構，名為 PortraitTalk。我們提出的方法利用一個潛在擴散架構，該架構包含兩個主要元件：IdentityNet 和 AnimateNet。IdentityNet 旨在在生成的影片畫格中持續保留身分特徵，而 AnimateNet 則旨在增強時間相干性和動作一致性。此架構還將音訊輸入與參考影像整合，從而減少現有方法中普遍依賴參考風格影片的情況。PortraitTalk 的一項關鍵創新是透過解耦交叉注意力機制納入文字提示，這顯著擴展了對生成影片的創意控制。透過廣泛的實驗，包括一個新開發的評估指標，我們的模型證明了其優於最先進方法的效能，為可自訂的逼真對話人臉生成樹立了新標準，適用於真實世界的應用。

##### **FlashRNN: Optimizing Traditional RNNs on Modern Hardware**
2412.07752v1 by Korbinian Pöppel, Maximilian Beck, Sepp Hochreiter

While Transformers and other sequence-parallelizable neural network
architectures seem like the current state of the art in sequence modeling, they
specifically lack state-tracking capabilities. These are important for
time-series tasks and logical reasoning. Traditional RNNs like LSTMs and GRUs,
as well as modern variants like sLSTM do have these capabilities at the cost of
strictly sequential processing. While this is often seen as a strong
limitation, we show how fast these networks can get with our
hardware-optimization FlashRNN in Triton and CUDA, optimizing kernels to the
register level on modern GPUs. We extend traditional RNNs with a
parallelization variant that processes multiple RNNs of smaller hidden state in
parallel, similar to the head-wise processing in Transformers. To enable
flexibility on different GPU variants, we introduce a new optimization
framework for hardware-internal cache sizes, memory and compute handling. It
models the hardware in a setting using polyhedral-like constraints, including
the notion of divisibility. This speeds up the solution process in our
ConstrINT library for general integer constraint satisfaction problems (integer
CSPs). We show that our kernels can achieve 50x speed-ups over a vanilla
PyTorch implementation and allow 40x larger hidden sizes compared to our Triton
implementation. Our open-source kernels and the optimization library are
released here to boost research in the direction of state-tracking enabled RNNs
and sequence modeling: \url{https://github.com/NX-AI/flashrnn}

摘要：儘管 Transformer 和其他可平行處理序列的神經網路架構看起來像是序列建模的現今技術水準，但它們特別缺乏狀態追蹤功能。這些功能對於時間序列任務和邏輯推理非常重要。傳統的 RNN，例如 LSTM 和 GRU，以及現代變體，例如 sLSTM，確實具有這些功能，但代價是嚴格的順序處理。儘管這通常被視為一個嚴重的限制，但我們展示了這些網路透過我們在 Triton 和 CUDA 中的硬體最佳化 FlashRNN，如何使用現代 GPU 將核心最佳化到暫存器層級，進而變得有多快。我們以並行化變體擴充傳統的 RNN，該變體處理多個隱藏狀態較小的 RNN，類似於 Transformer 中的頭部處理。為了在不同的 GPU 變體上啟用彈性，我們引進了一個新的最佳化架構，用於硬體內部快取大小、記憶體和運算處理。它使用類多面體的約束來模擬硬體設定，包括可除性的概念。這加速了我們 ConstrINT 函式庫中的一般整數約束滿足問題 (整數 CSP) 的解決程序。我們展示了我們的核心可以比香草 PyTorch 實作快 50 倍，並允許比我們的 Triton 實作大 40 倍的隱藏大小。我們的開源核心和最佳化函式庫在此釋出，以促進狀態追蹤啟用 RNN 和序列建模的研究：\url{https://github.com/NX-AI/flashrnn}

##### **Predictive Modeling of Homeless Service Assignment: A Representation Learning Approach**
2412.07747v1 by Khandker Sadia Rahman, Charalampos Chelmis

In recent years, there has been growing interest in leveraging machine
learning for homeless service assignment. However, the categorical nature of
administrative data recorded for homeless individuals hinders the development
of accurate machine learning methods for this task. This work asserts that
deriving latent representations of such features, while at the same time
leveraging underlying relationships between instances is crucial in
algorithmically enhancing the existing assignment decision-making process. Our
proposed approach learns temporal and functional relationships between services
from historical data, as well as unobserved but relevant relationships between
individuals to generate features that significantly improve the prediction of
the next service assignment compared to the state-of-the-art.

摘要：近年來，利用機器學習來分配遊民服務的興趣日增。然而，為遊民個人所記錄的行政資料的分類性質，阻礙了為此任務開發精確的機器學習方法。本研究斷言，推導此類特徵的潛在表示，同時利用實例之間的底層關係，對於演算法式增強現有的分配決策制定流程至關重要。我們提出的方法從歷史資料中學習服務之間的時間和功能關係，以及個人之間未觀察到但相關的關係，以生成特徵，與目前最先進的方法相比，這些特徵顯著改善了下一個服務分配的預測。

##### **Zero-Shot ATC Coding with Large Language Models for Clinical Assessments**
2412.07743v1 by Zijian Chen, John-Michael Gamble, Micaela Jantzi, John P. Hirdes, Jimmy Lin

Manual assignment of Anatomical Therapeutic Chemical (ATC) codes to
prescription records is a significant bottleneck in healthcare research and
operations at Ontario Health and InterRAI Canada, requiring extensive expert
time and effort. To automate this process while maintaining data privacy, we
develop a practical approach using locally deployable large language models
(LLMs). Inspired by recent advances in automatic International Classification
of Diseases (ICD) coding, our method frames ATC coding as a hierarchical
information extraction task, guiding LLMs through the ATC ontology level by
level. We evaluate our approach using GPT-4o as an accuracy ceiling and focus
development on open-source Llama models suitable for privacy-sensitive
deployment. Testing across Health Canada drug product data, the RABBITS
benchmark, and real clinical notes from Ontario Health, our method achieves 78%
exact match accuracy with GPT-4o and 60% with Llama 3.1 70B. We investigate
knowledge grounding through drug definitions, finding modest improvements in
accuracy. Further, we show that fine-tuned Llama 3.1 8B matches zero-shot Llama
3.1 70B accuracy, suggesting that effective ATC coding is feasible with smaller
models. Our results demonstrate the feasibility of automatic ATC coding in
privacy-sensitive healthcare environments, providing a foundation for future
deployments.

摘要：手動分配解剖學治療化學（ATC）代碼至處方紀錄是安大略省衛生廳和 InterRAI 加拿大在醫療保健研究和作業中的一大瓶頸，需要大量的專家時間和精力。為了在維護資料隱私的同時自動化此流程，我們開發了一種使用可本地部署的大型語言模型（LLM）的實用方法。受到國際疾病分類（ICD）自動編碼的最新進展啟發，我們的編碼方法將 ATC 編碼設定為一項層級式資訊萃取任務，引導 LLM 逐層通過 ATC ontology。我們使用 GPT-4o 作為準確度上限，評估我們的做法並專注於開發適用於隱私敏感部署的開源 Llama 模型。在加拿大衛生部藥物產品資料、RABBITS 基準和安大略省衛生廳的真實臨床筆記中進行測試，我們的編碼方法使用 GPT-4o 達到 78% 的完全匹配準確度，使用 Llama 3.1 70B 達到 60%。我們透過藥物定義調查知識基礎，發現準確度有小幅提升。此外，我們展示微調後的 Llama 3.1 8B 匹配零次學習的 Llama 3.1 70B 準確度，這表示使用較小的模型也能有效進行 ATC 編碼。我們的結果證明了在注重隱私的醫療保健環境中自動進行 ATC 編碼的可行性，為未來的部署奠定基礎。

##### **GASP: Gaussian Avatars with Synthetic Priors**
2412.07739v1 by Jack Saunders, Charlie Hewitt, Yanan Jian, Marek Kowalski, Tadas Baltrusaitis, Yiye Chen, Darren Cosker, Virginia Estellers, Nicholas Gyde, Vinay P. Namboodiri, Benjamin E Lundell

Gaussian Splatting has changed the game for real-time photo-realistic
rendering. One of the most popular applications of Gaussian Splatting is to
create animatable avatars, known as Gaussian Avatars. Recent works have pushed
the boundaries of quality and rendering efficiency but suffer from two main
limitations. Either they require expensive multi-camera rigs to produce avatars
with free-view rendering, or they can be trained with a single camera but only
rendered at high quality from this fixed viewpoint. An ideal model would be
trained using a short monocular video or image from available hardware, such as
a webcam, and rendered from any view. To this end, we propose GASP: Gaussian
Avatars with Synthetic Priors. To overcome the limitations of existing
datasets, we exploit the pixel-perfect nature of synthetic data to train a
Gaussian Avatar prior. By fitting this prior model to a single photo or video
and fine-tuning it, we get a high-quality Gaussian Avatar, which supports
360$^\circ$ rendering. Our prior is only required for fitting, not inference,
enabling real-time application. Through our method, we obtain high-quality,
animatable Avatars from limited data which can be animated and rendered at
70fps on commercial hardware. See our project page
(https://microsoft.github.io/GASP/) for results.

摘要：高斯散射改變了即時寫實渲染的遊戲規則。高斯散射最熱門的應用之一，就是建立可動態化的頭像，稱為高斯頭像。最近的研究已突破品質和渲染效率的界線，但仍有兩個主要的限制。他們需要昂貴的多相機裝置，才能產生可自由視角渲染的頭像；或者他們可以使用單一相機訓練，但只能從這個固定視角渲染出高品質的影像。理想的模型應使用短的單眼視訊或來自現有硬體（例如網路攝影機）的影像進行訓練，並能從任何視角渲染。為此，我們提出 GASP：具有合成先驗的高斯頭像。為了克服現有資料集的限制，我們利用合成資料的像素完美特性，訓練高斯頭像先驗。透過將此先驗模型套用至單一照片或視訊，並進行微調，我們得到一個高品質的高斯頭像，支援 360 度渲染。我們的先驗僅需用於擬合，而非推論，因而能進行即時應用。透過我們的方法，我們從有限的資料中取得高品質、可動態化的頭像，可以在市售硬體上以 70fps 動畫化和渲染。請參閱我們的專案頁面 (https://microsoft.github.io/GASP/) 以取得結果。

##### **STIV: Scalable Text and Image Conditioned Video Generation**
2412.07730v1 by Zongyu Lin, Wei Liu, Chen Chen, Jiasen Lu, Wenze Hu, Tsu-Jui Fu, Jesse Allardice, Zhengfeng Lai, Liangchen Song, Bowen Zhang, Cha Chen, Yiran Fei, Yifan Jiang, Lezhi Li, Yizhou Sun, Kai-Wei Chang, Yinfei Yang

The field of video generation has made remarkable advancements, yet there
remains a pressing need for a clear, systematic recipe that can guide the
development of robust and scalable models. In this work, we present a
comprehensive study that systematically explores the interplay of model
architectures, training recipes, and data curation strategies, culminating in a
simple and scalable text-image-conditioned video generation method, named STIV.
Our framework integrates image condition into a Diffusion Transformer (DiT)
through frame replacement, while incorporating text conditioning via a joint
image-text conditional classifier-free guidance. This design enables STIV to
perform both text-to-video (T2V) and text-image-to-video (TI2V) tasks
simultaneously. Additionally, STIV can be easily extended to various
applications, such as video prediction, frame interpolation, multi-view
generation, and long video generation, etc. With comprehensive ablation studies
on T2I, T2V, and TI2V, STIV demonstrate strong performance, despite its simple
design. An 8.7B model with 512 resolution achieves 83.1 on VBench T2V,
surpassing both leading open and closed-source models like CogVideoX-5B, Pika,
Kling, and Gen-3. The same-sized model also achieves a state-of-the-art result
of 90.1 on VBench I2V task at 512 resolution. By providing a transparent and
extensible recipe for building cutting-edge video generation models, we aim to
empower future research and accelerate progress toward more versatile and
reliable video generation solutions.

摘要：影片生成領域已取得顯著進展，但仍迫切需要一個清晰且系統化的配方，以引導穩健且可擴充模型的開發。在這項工作中，我們提出了一項全面性的研究，系統性地探討模型架構、訓練配方和資料策展策略的交互作用，最終形成一種簡單且可擴充的文字影像條件影片生成方法，稱為 STIV。我們的架構透過畫面替換將影像條件整合到擴散轉換器 (DiT) 中，同時透過聯合影像文字條件分類器自由引導來納入文字條件。此設計讓 STIV 能夠同時執行文字轉影片 (T2V) 和文字影像轉影片 (TI2V) 任務。此外，STIV 可以輕鬆延伸至各種應用，例如影片預測、畫面內插、多視圖生成和長影片生成等。透過對 T2I、T2V 和 TI2V 進行全面的消融研究，STIV 展現出強大的效能，儘管其設計簡單。一個解析度為 512 的 8.7B 模型在 VBench T2V 上達到 83.1，超越了 CogVideoX-5B、Pika、Kling 和 Gen-3 等領先的開放和閉源模型。相同大小的模型在解析度為 512 的 VBench I2V 任務上也達到了 90.1 的最新技術成果。透過提供一個透明且可擴充的配方來建構尖端的影片生成模型，我們旨在賦能未來的研究，並加速朝向更通用且可靠的影片生成解決方案邁進。

##### **Granite Guardian**
2412.07724v1 by Inkit Padhi, Manish Nagireddy, Giandomenico Cornacchia, Subhajit Chaudhury, Tejaswini Pedapati, Pierre Dognin, Keerthiram Murugesan, Erik Miehling, Martín Santillán Cooper, Kieran Fraser, Giulio Zizzo, Muhammad Zaid Hameed, Mark Purcell, Michael Desmond, Qian Pan, Inge Vejsbjerg, Elizabeth M. Daly, Michael Hind, Werner Geyer, Ambrish Rawat, Kush R. Varshney, Prasanna Sattigeri

We introduce the Granite Guardian models, a suite of safeguards designed to
provide risk detection for prompts and responses, enabling safe and responsible
use in combination with any large language model (LLM). These models offer
comprehensive coverage across multiple risk dimensions, including social bias,
profanity, violence, sexual content, unethical behavior, jailbreaking, and
hallucination-related risks such as context relevance, groundedness, and answer
relevance for retrieval-augmented generation (RAG). Trained on a unique dataset
combining human annotations from diverse sources and synthetic data, Granite
Guardian models address risks typically overlooked by traditional risk
detection models, such as jailbreaks and RAG-specific issues. With AUC scores
of 0.871 and 0.854 on harmful content and RAG-hallucination-related benchmarks
respectively, Granite Guardian is the most generalizable and competitive model
available in the space. Released as open-source, Granite Guardian aims to
promote responsible AI development across the community.
  https://github.com/ibm-granite/granite-guardian

摘要：我們推出 Granite Guardian 模型，這是一套旨在提供提示和回應風險偵測的安全防護措施，讓使用者能夠安全且負責任地與任何大型語言模型 (LLM) 結合使用。這些模型提供跨多個風險面向的全面覆蓋，包括社會偏見、褻瀆、暴力、性內容、不道德行為、越獄，以及與幻覺相關的風險，例如脈絡相關性、紮實性，以及用於檢索增強生成 (RAG) 的答案相關性。Granite Guardian 模型採用結合來自不同來源的人工標註和合成資料的獨特資料集進行訓練，可解決傳統風險偵測模型通常會忽略的風險，例如越獄和 RAG 特定的問題。Granite Guardian 在有害內容和 RAG 幻覺相關基準上的 AUC 分數分別為 0.871 和 0.854，是此領域中通用性最高且競爭力最強的模型。Granite Guardian 以開源形式發布，旨在促進整個社群負責任的 AI 開發。
https://github.com/ibm-granite/granite-guardian

##### **Benchmark for Evaluation and Analysis of Citation Recommendation Models**
2412.07713v1 by Puja Maharjan

Citation recommendation systems have attracted much academic interest,
resulting in many studies and implementations. These systems help authors
automatically generate proper citations by suggesting relevant references based
on the text they have written. However, the methods used in citation
recommendation differ across various studies and implementations. Some
approaches focus on the overall content of papers, while others consider the
context of the citation text. Additionally, the datasets used in these studies
include different aspects of papers, such as metadata, citation context, or
even the full text of the paper in various formats and structures. The
diversity in models, datasets, and evaluation metrics makes it challenging to
assess and compare citation recommendation methods effectively. To address this
issue, a standardized dataset and evaluation metrics are needed to evaluate
these models consistently. Therefore, we propose developing a benchmark
specifically designed to analyze and compare citation recommendation models.
This benchmark will evaluate the performance of models on different features of
the citation context and provide a comprehensive evaluation of the models
across all these tasks, presenting the results in a standardized way. By
creating a benchmark with standardized evaluation metrics, researchers and
practitioners in the field of citation recommendation will have a common
platform to assess and compare different models. This will enable meaningful
comparisons and help identify promising approaches for further research and
development in the field.

摘要：引用推薦系統吸引了許多學術興趣，
導致許多研究和實作。這些系統協助作者
自動產生適當的引用，透過建議相關的參考書目來根據
他們撰寫的文字。然而，在引用
推薦中所使用的這些方法在各種研究和實作中有所不同。一些
方法著重於論文的整體內容，而其他方法則考量引用文字的
脈絡。此外，這些研究中所使用的資料集
包含論文的不同面向，例如元資料、引用脈絡，
或甚至各種格式和結構的論文全文。模型、資料集，
和評量指標的多樣性使得評估和比較引用推薦方法
變得具有挑戰性。為了解決這個
問題，需要標準化的資料集和評量指標來評估
這些模型的一致性。因此，我們建議開發一個基準
特別用來分析和比較引用推薦模型。
這個基準將評量模型在引用脈絡的不同特徵上的表現，並提供
一個對所有這些任務的模型全面評量，以標準化的方式呈現
結果。透過建立一個具有標準化評量指標的基準，研究人員和
引用推薦領域的實務工作者將有一個共同
的平台來評估和比較不同的模型。這將能進行有意義的
比較，並協助找出有前途的方法，以進行該領域進一步的研究和
發展。

##### **SimVS: Simulating World Inconsistencies for Robust View Synthesis**
2412.07696v1 by Alex Trevithick, Roni Paiss, Philipp Henzler, Dor Verbin, Rundi Wu, Hadi Alzayer, Ruiqi Gao, Ben Poole, Jonathan T. Barron, Aleksander Holynski, Ravi Ramamoorthi, Pratul P. Srinivasan

Novel-view synthesis techniques achieve impressive results for static scenes
but struggle when faced with the inconsistencies inherent to casual capture
settings: varying illumination, scene motion, and other unintended effects that
are difficult to model explicitly. We present an approach for leveraging
generative video models to simulate the inconsistencies in the world that can
occur during capture. We use this process, along with existing multi-view
datasets, to create synthetic data for training a multi-view harmonization
network that is able to reconcile inconsistent observations into a consistent
3D scene. We demonstrate that our world-simulation strategy significantly
outperforms traditional augmentation methods in handling real-world scene
variations, thereby enabling highly accurate static 3D reconstructions in the
presence of a variety of challenging inconsistencies. Project page:
https://alextrevithick.github.io/simvs

摘要：新穎視圖合成技術在靜態場景中取得令人印象深刻的成果，
但面對隨意擷取設定中固有的不一致性時卻力不從心：
變化的光照、場景動作和其他難以明確建模的意外效果。
我們提出了一種利用生成影片模型來模擬擷取過程中可能發生的世界不一致性的方法。
我們使用這個過程，以及現有的多視圖資料集，來建立用於訓練多視圖調和網路的合成資料，
該網路能夠將不一致的觀測值調和到一致的 3D 場景中。
我們證明了我們的世界模擬策略在處理真實世界場景變化方面顯著優於傳統的擴充方法，
從而能夠在各種具有挑戰性的不一致性存在的情況下實現高度準確的靜態 3D 重建。
專案頁面：
https://alextrevithick.github.io/simvs

##### **The Pitfalls of Memorization: When Memorization Hurts Generalization**
2412.07684v1 by Reza Bayat, Mohammad Pezeshki, Elvis Dohmatob, David Lopez-Paz, Pascal Vincent

Neural networks often learn simple explanations that fit the majority of the
data while memorizing exceptions that deviate from these explanations.This
behavior leads to poor generalization when the learned explanations rely on
spurious correlations. In this work, we formalize the interplay between
memorization and generalization, showing that spurious correlations would
particularly lead to poor generalization when are combined with memorization.
Memorization can reduce training loss to zero, leaving no incentive to learn
robust, generalizable patterns. To address this, we propose memorization-aware
training (MAT), which uses held-out predictions as a signal of memorization to
shift a model's logits. MAT encourages learning robust patterns invariant
across distributions, improving generalization under distribution shifts.

摘要：神经網路經常學習適合大多數資料的簡單解釋，同時記憶偏離這些解釋的例外情況。當學習到的解釋依賴於虛假的相關性時，這種行為會導致概化不良。在這項工作中，我們將記憶和概化之間的相互作用形式化，表明虛假的相關性特別會在與記憶結合時導致概化不良。記憶可以將訓練損失減少到零，沒有誘因去學習穩健、可概化的模式。為了解決這個問題，我們提出了記憶感知訓練 (MAT)，它使用保留的預測作為記憶信號來轉移模型的對數機率。MAT 鼓勵學習對分佈不變的穩健模式，改善在分佈轉移下的概化。

##### **TRIM: Token Reduction and Inference Modeling for Cost-Effective Language Generation**
2412.07682v1 by Alfredo Garrachón Ruiz, Tomás de la Rosa, Daniel Borrajo

The inference cost of Large Language Models (LLMs) is a significant challenge
due to their computational demands, specially on tasks requiring long outputs.
However, natural language often contains redundancy, which presents an
opportunity for optimization. We have observed that LLMs can generate distilled
language-concise outputs that retain essential meaning, when prompted
appropriately. We propose a framework for saving computational cost, in which a
shorter distilled output from the LLM is reconstructed into a full narrative by
a smaller model with lower inference costs. Our experiments show promising
results, particularly in general knowledge domains with 20.58% saved tokens on
average with tiny decrease in evaluation metrics, hinting that this approach
can effectively balance efficiency and accuracy in language processing tasks.

摘要：由於大型語言模型 (LLM) 的運算需求，特別是在需要長輸出時，其推論成本是一項重大的挑戰。
然而，自然語言通常包含冗餘，這提供了最佳化的機會。我們觀察到，LLM 在適當地提示時，可以產生保留基本含義的精煉語言簡潔輸出。我們提出了一個用於節省運算成本的框架，其中 LLM 的較短精煉輸出由具有較低推論成本的較小模型重建成一個完整的敘述。我們的實驗顯示出有希望的結果，特別是在一般知識領域中，評估指標平均節省了 20.58% 的代幣，這暗示了這種方法可以有效地在語言處理任務中平衡效率和準確性。

##### **RADIO Amplified: Improved Baselines for Agglomerative Vision Foundation Models**
2412.07679v1 by Greg Heinrich, Mike Ranzinger, Hongxu, Yin, Yao Lu, Jan Kautz, Andrew Tao, Bryan Catanzaro, Pavlo Molchanov

Agglomerative models have recently emerged as a powerful approach to training
vision foundation models, leveraging multi-teacher distillation from existing
models such as CLIP, DINO, and SAM. This strategy enables the efficient
creation of robust models, combining the strengths of individual teachers while
significantly reducing computational and resource demands. In this paper, we
thoroughly analyze state-of-the-art agglomerative models, identifying critical
challenges including resolution mode shifts, teacher imbalance, idiosyncratic
teacher artifacts, and an excessive number of output tokens. To address these
issues, we propose several novel solutions: multi-resolution training, mosaic
augmentation, and improved balancing of teacher loss functions. Specifically,
in the context of Vision Language Models, we introduce a token compression
technique to maintain high-resolution information within a fixed token count.
We release our top-performing models, available in multiple scales (-B, -L, -H,
and -g), alongside inference code and pretrained weights.

摘要：聚合模型最近已成为训练視覺基礎模型的一種強大方法，利用現有模型（例如 CLIP、DINO 和 SAM）的多教師蒸餾。此策略可有效建立穩健的模型，結合個別教師的優勢，同時大幅降低運算和資源需求。在本文中，我們徹底分析了最先進的聚合模型，找出關鍵挑戰，包括解析度模式轉移、教師失衡、特殊教師人工製品和過多的輸出符號。為了解決這些問題，我們提出了幾種創新的解決方案：多解析度訓練、馬賽克擴充，以及改進教師損失函數的平衡。具體來說，在視覺語言模型的背景下，我們引入了一種符號壓縮技術，以在固定的符號數中維護高解析度資訊。我們發布了我們效能最佳的模型，提供多種規模（-B、-L、-H 和 -g），以及推理程式碼和預訓練權重。

##### **Can linguists better understand DNA?**
2412.07678v1 by Wang Liang

Multilingual transfer ability, which reflects how well models fine-tuned on
one source language can be applied to other languages, has been well studied in
multilingual pre-trained models. However, the existence of such capability
transfer between natural language and gene sequences/languages remains
underexplored.This study addresses this gap by drawing inspiration from the
sentence-pair classification task used for evaluating sentence similarity in
natural language. We constructed two analogous tasks: DNA-pair
classification(DNA sequence similarity) and DNA-protein-pair
classification(gene coding determination). These tasks were designed to
validate the transferability of capabilities from natural language to gene
sequences. Even a small-scale pre-trained model like GPT-2-small, which was
pre-trained on English, achieved an accuracy of 78% on the DNA-pair
classification task after being fine-tuned on English sentence-pair
classification data(XTREME PAWS-X). While training a BERT model on multilingual
text, the precision reached 82%.On the more complex DNA-protein-pair
classification task, however, the model's output was barely distinguishable
from random output.Experiments suggest that there may be a capability transfer
from natural language to genetic language, but further task testing is needed
to confirm this.

摘要：多語言轉移能力反映了針對一種原始語言進行微調的模型在多大程度上可以應用於其他語言，這在多語言預訓練模型中得到了很好的研究。然而，自然語言與基因序列/語言之間這種能力轉移的存在仍然未得到充分探索。本研究從用於評估自然語言中句子相似性的句子對分類任務中汲取靈感，來解決這一差距。我們構建了兩個類似的任務：DNA 對分類（DNA 序列相似性）和 DNA 蛋白質對分類（基因編碼確定）。這些任務旨在驗證從自然語言到基因序列的能力可轉移性。即使像 GPT-2-small 這樣的小規模預訓練模型（經過英語預訓練）在針對英語句子對分類數據（XTREME PAWS-X）進行微調後，在 DNA 對分類任務上也達到了 78% 的準確度。在多語言文本上訓練 BERT 模型時，準確率達到了 82%。然而，在更複雜的 DNA 蛋白質對分類任務上，模型的輸出幾乎與隨機輸出沒有區別。實驗表明，自然語言到遺傳語言的能力轉移可能是存在的，但需要進一步的任務測試來確認這一點。

##### **RAZOR: Sharpening Knowledge by Cutting Bias with Unsupervised Text Rewriting**
2412.07675v1 by Shuo Yang, Bardh Prenkaj, Gjergji Kasneci

Despite the widespread use of LLMs due to their superior performance in
various tasks, their high computational costs often lead potential users to opt
for the pretraining-finetuning pipeline. However, biases prevalent in manually
constructed datasets can introduce spurious correlations between tokens and
labels, creating so-called shortcuts and hindering the generalizability of
fine-tuned models. Existing debiasing methods often rely on prior knowledge of
specific dataset biases, which is challenging to acquire a priori. We propose
RAZOR (Rewriting And Zero-bias Optimization Refinement), a novel, unsupervised,
and data-focused debiasing approach based on text rewriting for shortcut
mitigation. RAZOR leverages LLMs to iteratively rewrite potentially biased text
segments by replacing them with heuristically selected alternatives in a
shortcut space defined by token statistics and positional information. This
process aims to align surface-level text features more closely with diverse
label distributions, thereby promoting the learning of genuine linguistic
patterns. Compared with unsupervised SoTA models, RAZOR improves by 3.5% on the
FEVER and 6.5% on MNLI and SNLI datasets according to the F1 score.
Additionally, RAZOR effectively mitigates specific known biases, reducing
bias-related terms by x2 without requiring prior bias information, a result
that is on par with SoTA models that leverage prior information. Our work
prioritizes data manipulation over architectural modifications, emphasizing the
pivotal role of data quality in enhancing model performance and fairness. This
research contributes to developing more robust evaluation benchmarks for
debiasing methods by incorporating metrics for bias reduction and overall model
efficacy.

摘要：儘管 LLM 因其在各種任務中表現優異而廣泛使用，但其高昂的運算成本通常導致潛在使用者選擇預訓練微調管線。然而，手動建構的資料集中普遍存在的偏差會導致標記和詞彙之間產生虛假的相關性，造成所謂的捷徑，並阻礙微調模型的泛化能力。現有的去偏差方法通常依賴於特定資料集偏差的先驗知識，這在先驗上很難獲得。我們提出 RAZOR（重寫和零偏差最佳化優化），一種基於文字重寫的新穎、無監督和以資料為中心的去偏差方法，用於捷徑緩解。RAZR 利用 LLM 迭代重寫潛在有偏差的文字片段，藉由在由標記統計和位置資訊定義的捷徑空間中以啟發式選擇的替代方案取代它們。此程序旨在使表面文字特徵更緊密地與多樣化的標籤分佈保持一致，從而促進真正語言模式的學習。與無監督的 SoTA 模型相比，根據 F1 分數，RAZR 在 FEVER 上提高了 3.5%，在 MNLI 和 SNLI 資料集上提高了 6.5%。此外，RAZR 有效地減輕了已知的特定偏差，將與偏差相關的術語減少了 x2，而不需要先前的偏差資訊，這項結果與利用先驗資訊的 SoTA 模型相當。我們的研究優先考慮資料處理而非架構修改，強調資料品質在提升模型效能和公平性方面的關鍵作用。這項研究有助於開發更穩健的去偏差方法評估基準，方法是納入偏差減少和整體模型效能的指標。

##### **FlexLLM: Exploring LLM Customization for Moving Target Defense on Black-Box LLMs Against Jailbreak Attacks**
2412.07672v1 by Bocheng Chen, Hanqing Guo, Qiben Yan

Defense in large language models (LLMs) is crucial to counter the numerous
attackers exploiting these systems to generate harmful content through
manipulated prompts, known as jailbreak attacks. Although many defense
strategies have been proposed, they often require access to the model's
internal structure or need additional training, which is impractical for
service providers using LLM APIs, such as OpenAI APIs or Claude APIs. In this
paper, we propose a moving target defense approach that alters decoding
hyperparameters to enhance model robustness against various jailbreak attacks.
Our approach does not require access to the model's internal structure and
incurs no additional training costs. The proposed defense includes two key
components: (1) optimizing the decoding strategy by identifying and adjusting
decoding hyperparameters that influence token generation probabilities, and (2)
transforming the decoding hyperparameters and model system prompts into dynamic
targets, which are continuously altered during each runtime. By continuously
modifying decoding strategies and prompts, the defense effectively mitigates
the existing attacks. Our results demonstrate that our defense is the most
effective against jailbreak attacks in three of the models tested when using
LLMs as black-box APIs. Moreover, our defense offers lower inference costs and
maintains comparable response quality, making it a potential layer of
protection when used alongside other defense methods.

摘要：在大型語言模型 (LLM) 中，防禦對於對抗眾多攻擊者利用這些系統透過已操縱的提示產生有害內容（稱為越獄攻擊）至關重要。儘管已提出許多防禦策略，但它們通常需要存取模型的內部結構或需要額外訓練，這對於使用 LLM API（例如 OpenAI API 或 Claude API）的服務提供者而言並不實際。在本文中，我們提出了一種移動目標防禦方法，它會改變解碼超參數以增強模型對各種越獄攻擊的穩健性。我們的做法不需要存取模型的內部結構，也不會產生額外的訓練成本。所提出的防禦包括兩個關鍵組成部分：(1) 透過識別和調整影響代碼產生機率的解碼超參數，來優化解碼策略，以及 (2) 將解碼超參數和模型系統提示轉換為動態目標，這些目標會在每次執行期間持續變更。透過持續修改解碼策略和提示，防禦措施有效減輕了現有的攻擊。我們的結果表明，在將 LLM 作為黑盒 API 使用時，我們的防禦措施對三個受測模型中的越獄攻擊最有效。此外，我們的防禦措施提供了較低的推論成本，並維持了可比較的回應品質，使其成為與其他防禦方法並用時的一層潛在防護。

##### **TraSCE: Trajectory Steering for Concept Erasure**
2412.07658v1 by Anubhav Jain, Yuya Kobayashi, Takashi Shibuya, Yuhta Takida, Nasir Memon, Julian Togelius, Yuki Mitsufuji

Recent advancements in text-to-image diffusion models have brought them to
the public spotlight, becoming widely accessible and embraced by everyday
users. However, these models have been shown to generate harmful content such
as not-safe-for-work (NSFW) images. While approaches have been proposed to
erase such abstract concepts from the models, jail-breaking techniques have
succeeded in bypassing such safety measures. In this paper, we propose TraSCE,
an approach to guide the diffusion trajectory away from generating harmful
content. Our approach is based on negative prompting, but as we show in this
paper, conventional negative prompting is not a complete solution and can
easily be bypassed in some corner cases. To address this issue, we first
propose a modification of conventional negative prompting. Furthermore, we
introduce a localized loss-based guidance that enhances the modified negative
prompting technique by steering the diffusion trajectory. We demonstrate that
our proposed method achieves state-of-the-art results on various benchmarks in
removing harmful content including ones proposed by red teams; and erasing
artistic styles and objects. Our proposed approach does not require any
training, weight modifications, or training data (both image or prompt), making
it easier for model owners to erase new concepts.

摘要：最近文本到图像扩散模型的进步使其成为公众关注的焦点，被广泛使用并被日常用户接受。然而，这些模型已被证明会生成有害内容，例如不适合工作的（NSFW）图像。虽然已经提出了从模型中抹去此类抽象概念的方法，但越狱技术已经成功绕过了此类安全措施。在本文中，我们提出了 TraSCE，这是一种引导扩散轨迹远离生成有害内容的方法。我们的方法基于负面提示，但正如我们在本文中所示，传统的负面提示并不是一个完整的解决方案，并且在某些极端情况下很容易被绕过。为了解决这个问题，我们首先提出了对传统负面提示的修改。此外，我们引入了一种基于局部损失的指导，通过控制扩散轨迹来增强修改后的负面提示技术。我们证明了我们提出的方法在消除有害内容（包括红队提出的内容）的各种基准测试中取得了最先进的结果；并擦除了艺术风格和物体。我们提出的方法不需要任何训练、权重修改或训练数据（图像或提示），这使得模型所有者更容易擦除新概念。

##### **Searching for Structure: Investigating Emergent Communication with Large Language Models**
2412.07646v1 by Tom Kouwenhoven, Max Peeperkorn, Tessa Verhoef

Human languages have evolved to be structured through repeated language
learning and use. These processes introduce biases that operate during language
acquisition and shape linguistic systems toward communicative efficiency. In
this paper, we investigate whether the same happens if artificial languages are
optimised for implicit biases of Large Language Models (LLMs). To this end, we
simulate a classical referential game in which LLMs learn and use artificial
languages. Our results show that initially unstructured holistic languages are
indeed shaped to have some structural properties that allow two LLM agents to
communicate successfully. Similar to observations in human experiments,
generational transmission increases the learnability of languages, but can at
the same time result in non-humanlike degenerate vocabularies. Taken together,
this work extends experimental findings, shows that LLMs can be used as tools
in simulations of language evolution, and opens possibilities for future
human-machine experiments in this field.

摘要：人類語言在經過重複的語言學習和使用後，演化出結構。這些過程在語言習得過程中引入了偏差，並將語言系統塑造成具有溝通效率。在本文中，我們探討了如果人工語言針對大型語言模型 (LLM) 的隱性偏差進行最佳化，是否也會發生同樣的情況。為此，我們模擬了一個經典的指稱遊戲，其中 LLM 學習並使用人工語言。我們的結果顯示，最初沒有結構的整體語言確實會形成一些結構屬性，讓兩個 LLM 代理人能夠成功溝通。與人類實驗中的觀察結果類似，世代傳遞會增加語言的可學習性，但同時也可能導致非人類的退化詞彙。綜合來說，這項工作擴展了實驗發現，顯示 LLM 可用作語言演化模擬的工具，並開啟了未來在此領域進行人機實驗的可能性。

##### **TrojanWhisper: Evaluating Pre-trained LLMs to Detect and Localize Hardware Trojans**
2412.07636v1 by Md Omar Faruque, Peter Jamieson, Ahmad Patooghy, Abdel-Hameed A. Badawy

Existing Hardware Trojans (HT) detection methods face several critical
limitations: logic testing struggles with scalability and coverage for large
designs, side-channel analysis requires golden reference chips, and formal
verification methods suffer from state-space explosion. The emergence of Large
Language Models (LLMs) offers a promising new direction for HT detection by
leveraging their natural language understanding and reasoning capabilities. For
the first time, this paper explores the potential of general-purpose LLMs in
detecting various HTs inserted in Register Transfer Level (RTL) designs,
including SRAM, AES, and UART modules. We propose a novel tool for this goal
that systematically assesses state-of-the-art LLMs (GPT-4o, Gemini 1.5 pro, and
Llama 3.1) in detecting HTs without prior fine-tuning. To address potential
training data bias, the tool implements perturbation techniques, i.e., variable
name obfuscation, and design restructuring, that make the cases more
sophisticated for the used LLMs. Our experimental evaluation demonstrates
perfect detection rates by GPT-4o and Gemini 1.5 pro in baseline scenarios
(100%/100% precision/recall), with both models achieving better trigger line
coverage (TLC: 0.82-0.98) than payload line coverage (PLC: 0.32-0.46). Under
code perturbation, while Gemini 1.5 pro maintains perfect detection performance
(100%/100%), GPT-4o (100%/85.7%) and Llama 3.1 (66.7%/85.7%) show some
degradation in detection rates, and all models experience decreased accuracy in
localizing both triggers and payloads. This paper validates the potential of
LLM approaches for hardware security applications, highlighting areas for
future improvement.

摘要：現有的硬體木馬 (HT) 偵測方法面臨幾個關鍵的限制：邏輯測試在可擴充性和對大型設計的涵蓋範圍上遇到困難，側通道分析需要黃金參考晶片，而形式驗證方法則會受到狀態空間爆炸的影響。大型語言模型 (LLM) 的出現為 HT 偵測提供了一個有前景的新方向，方法是利用它們的自然語言理解和推理能力。這篇論文首次探討了通用 LLM 在偵測插入暫存器傳輸層級 (RTL) 設計中的各種 HT（包括 SRAM、AES 和 UART 模組）的潛力。我們提出了一個新穎的工具來達成此目標，這個工具系統性地評估了最先進的 LLM（GPT-4o、Gemini 1.5 pro 和 Llama 3.1）在未經事先微調的情況下偵測 HT 的能力。為了解決潛在的訓練資料偏差，該工具實作了擾動技術，例如變數名稱混淆和設計重組，讓案例對所使用的 LLM 來說更複雜。我們的實驗評估顯示，在基準情境中，GPT-4o 和 Gemini 1.5 pro 的偵測率完美（100%/100% 精確度/召回率），這兩個模型達到的觸發線涵蓋率 (TLC：0.82-0.98) 都優於酬載線涵蓋率 (PLC：0.32-0.46)。在程式碼擾動下，雖然 Gemini 1.5 pro 維持了完美的偵測效能 (100%/100%)，但 GPT-4o (100%/85.7%) 和 Llama 3.1 (66.7%/85.7%) 的偵測率出現了一些下降，而且所有模型在定位觸發器和酬載的準確度都下降了。這篇論文驗證了 LLM 方法在硬體安全應用中的潛力，並突出了未來改進的領域。

##### **ChocoLlama: Lessons Learned From Teaching Llamas Dutch**
2412.07633v1 by Matthieu Meeus, Anthony Rathé, François Remy, Pieter Delobelle, Jens-Joris Decorte, Thomas Demeester

While Large Language Models (LLMs) have shown remarkable capabilities in
natural language understanding and generation, their performance often lags in
lower-resource, non-English languages due to biases in the training data. In
this work, we explore strategies for adapting the primarily English LLMs
(Llama-2 and Llama-3) to Dutch, a language spoken by 30 million people
worldwide yet often underrepresented in LLM development. We collect 104GB of
Dutch text ($32$B tokens) from various sources to first apply continued
pretraining using low-rank adaptation (LoRA), complemented with Dutch
posttraining strategies provided by prior work. For Llama-2, we consider using
(i) the tokenizer of the original model, and (ii) training a new,
Dutch-specific tokenizer combined with embedding reinitialization. We evaluate
our adapted models, ChocoLlama-2, both on standard benchmarks and a novel Dutch
benchmark, ChocoLlama-Bench. Our results demonstrate that LoRA can effectively
scale for language adaptation, and that tokenizer modification with careful
weight reinitialization can improve performance. Notably, Llama-3 was released
during the course of this project and, upon evaluation, demonstrated superior
Dutch capabilities compared to our Dutch-adapted versions of Llama-2. We hence
apply the same adaptation technique to Llama-3, using its original tokenizer.
While our adaptation methods enhanced Llama-2's Dutch capabilities, we found
limited gains when applying the same techniques to Llama-3. This suggests that
for ever improving, multilingual foundation models, language adaptation
techniques may benefit more from focusing on language-specific posttraining
rather than on continued pretraining. We hope this work contributes to the
broader understanding of adapting LLMs to lower-resource languages, and to the
development of Dutch LLMs in particular.

摘要：儘管大型語言模型 (LLM) 在自然語言理解和生成方面展現了非凡的能力，但由於訓練資料的偏差，它們在低資源、非英語語言中的表現往往落後。在這項工作中，我們探討了將以英語為主的 LLM（Llama-2 和 Llama-3）適應到荷蘭語的策略，荷蘭語是全球 3000 萬人使用的語言，但在 LLM 的開發中卻經常被低估。我們從各種來源收集了 104GB 的荷蘭語文字（320 億個詞彙），首先使用低秩適應 (LoRA) 進行持續預訓練，並補充先前工作提供的荷蘭語後訓練策略。對於 Llama-2，我們考慮使用 (i) 原始模型的 tokenization 器，以及 (ii) 訓練一個新的、特定於荷蘭語的 tokenization 器，並結合嵌入式重新初始化。我們在標準基準測試和一個新的荷蘭語基準測試 ChocoLlama-Bench 上評估我們的適應模型 ChocoLlama-2。我們的結果表明，LoRA 可以有效地擴展語言適應，並且 tokenization 器修改與謹慎的權重重新初始化可以改善效能。值得注意的是，Llama-3 是在這個專案進行期間發布的，並且在評估後，與我們適應荷蘭語版本的 Llama-2 相比，展現了優越的荷蘭語能力。因此，我們使用其原始 tokenization 器，對 Llama-3 應用相同的適應技術。儘管我們的適應方法增強了 Llama-2 的荷蘭語能力，但我們發現將相同的技術應用於 Llama-3 時，增益有限。這表明，對於持續改進的多語言基礎模型而言，語言適應技術可能更受益於專注於特定語言的後訓練，而不是持續預訓練。我們希望這項工作有助於更廣泛地了解如何將 LLM 適應到低資源語言，並有助於開發荷蘭語 LLM。

##### **Piece of Table: A Divide-and-Conquer Approach for Selecting Sub-Tables in Table Question Answering**
2412.07629v1 by Wonjin Lee, Kyumin Kim, Sungjae Lee, Jihun Lee, Kwang In KIm

Applying language models (LMs) to tables is challenging due to the inherent
structural differences between two-dimensional tables and one-dimensional text
for which the LMs were originally designed. Furthermore, when applying
linearized tables to LMs, the maximum token lengths often imposed in
self-attention calculations make it difficult to comprehensively understand the
context spread across large tables. To address these challenges, we present
PieTa (Piece of Table), a new framework for sub-table-based question answering
(QA). PieTa operates through an iterative process of dividing tables into
smaller windows, using LMs to select relevant cells within each window, and
merging these cells into a sub-table. This multi-resolution approach captures
dependencies across multiple rows and columns while avoiding the limitations
caused by long context inputs. Instantiated as a simple iterative sub-table
union algorithm, PieTa demonstrates improved performance over previous
sub-table-based QA approaches.

摘要：將語言模型 (LM) 應用於表格具有挑戰性，因為二維表格與原本為 LM 設計的一維文字之間存在固有的結構差異。此外，在將線性化的表格應用於 LM 時，自我注意計算中經常施加的最大權杖長度使得難以全面理解散佈在大型表格中的上下文。為了應對這些挑戰，我們提出了 PieTa（表格片段），一個新的基於子表格的問答 (QA) 框架。PieTa 通過一個反覆的過程運作，將表格分成較小的視窗，使用 LM 在每個視窗中選擇相關的儲存格，然後將這些儲存格合併成一個子表格。這種多解析度方法捕獲了跨多行和多列的依賴關係，同時避免了長上下文輸入造成的限制。作為一個簡單的反覆子表格聯合演算法實例化，PieTa 展示了比先前的基於子表格的 QA 方法更好的效能。

##### **OmniDocBench: Benchmarking Diverse PDF Document Parsing with Comprehensive Annotations**
2412.07626v1 by Linke Ouyang, Yuan Qu, Hongbin Zhou, Jiawei Zhu, Rui Zhang, Qunshu Lin, Bin Wang, Zhiyuan Zhao, Man Jiang, Xiaomeng Zhao, Jin Shi, Fan Wu, Pei Chu, Minghao Liu, Zhenxiang Li, Chao Xu, Bo Zhang, Botian Shi, Zhongying Tu, Conghui He

Document content extraction is crucial in computer vision, especially for
meeting the high-quality data needs of large language models (LLMs) and
retrieval-augmented generation (RAG) technologies. However, current document
parsing methods suffer from significant limitations in terms of diversity and
comprehensive evaluation. To address these challenges, we introduce
OmniDocBench, a novel multi-source benchmark designed to advance automated
document content extraction. OmniDocBench includes a meticulously curated and
annotated high-quality evaluation dataset comprising nine diverse document
types, such as academic papers, textbooks, slides, among others. Our benchmark
provides a flexible and comprehensive evaluation framework with 19 layout
category labels and 14 attribute labels, enabling multi-level assessments
across entire datasets, individual modules, or specific data types. Using
OmniDocBench, we perform an exhaustive comparative analysis of existing modular
pipelines and multimodal end-to-end methods, highlighting their limitations in
handling document diversity and ensuring fair evaluation. OmniDocBench
establishes a robust, diverse, and fair evaluation standard for the document
content extraction field, offering crucial insights for future advancements and
fostering the development of document parsing technologies. The codes and
dataset is available in https://github.com/opendatalab/OmniDocBench.

摘要：文件內容萃取在電腦視覺中至關重要，特別是為了滿足大型語言模型 (LLM) 和檢索增強生成 (RAG) 技術的高品質資料需求。然而，目前的的文件解析方法在多樣性和全面評估方面存在重大限制。為了應對這些挑戰，我們引入了 OmniDocBench，這是一個新穎的多來源基準測試，旨在推進自動化文件內容萃取。OmniDocBench 包含一個精心策劃和註解的高品質評估資料集，包含九種多樣的文件類型，例如學術論文、教科書、投影片等。我們的基準測試提供了一個靈活且全面的評估架構，包含 19 個版面類別標籤和 14 個屬性標籤，可以在整個資料集、個別模組或特定資料類型中進行多層級評估。使用 OmniDocBench，我們對現有的模組化管線和多模態端到端方法進行了詳盡的比較分析，突顯了它們在處理文件多樣性和確保公平評估方面的限制。OmniDocBench 為文件內容萃取領域建立了一個強大、多樣且公平的評估標準，為未來的進步提供了重要的見解，並促進了文件解析技術的發展。程式碼和資料集可在 https://github.com/opendatalab/OmniDocBench 中取得。

##### **DRUM: Learning Demonstration Retriever for Large MUlti-modal Models**
2412.07619v1 by Ellen Yi-Ge, Jiechao Gao, Wei Han, Wei Zhu

Recently, large language models (LLMs) have demonstrated impressive
capabilities in dealing with new tasks with the help of in-context learning
(ICL). In the study of Large Vision-Language Models (LVLMs), when implementing
ICL, researchers usually adopts the naive strategies like fixed demonstrations
across different samples, or selecting demonstrations directly via a
visual-language embedding model. These methods does not guarantee the
configured demonstrations fit the need of the LVLMs. To address this issue, we
now propose a novel framework, \underline{d}emonstration \underline{r}etriever
for large m\underline{u}lti-modal \underline{m}odel (DRUM), which fine-tunes
the visual-language embedding model to better meet the LVLM's needs. First, we
discuss the retrieval strategies for a visual-language task, assuming an
embedding model is given. And we propose to concate the image and text
embeddings to enhance the retrieval performance. Second, we propose to re-rank
the demonstrations retrieved by the embedding model via the LVLM's feedbacks,
and calculate a list-wise ranking loss for training the embedding model. Third,
we propose an iterative demonstration mining strategy to improve the training
of the embedding model. Through extensive experiments on 3 types of
visual-language tasks, 7 benchmark datasets, our DRUM framework is proven to be
effective in boosting the LVLM's in-context learning performance via retrieving
more proper demonstrations.

摘要：<paragraph>最近，大型语言模型（LLM）在处理新任务时表现出令人印象深刻的能力，这得益于上下文学习 (ICL) 的帮助。在大型视觉语言模型 (LVLMs) 的研究中，研究人员在实施 ICL 时通常采用朴素的策略，例如跨不同样本的固定演示，或直接通过视觉语言嵌入模型选择演示。这些方法不能保证配置的演示符合 LVLMs 的需求。为了解决这个问题，我们现在提出一个新框架，即大型多模态模型的演示检索器 (DRUM)，它微调视觉语言嵌入模型以更好地满足 LVLM 的需求。首先，我们讨论视觉语言任务的检索策略，假设给定了一个嵌入模型。我们提出将图像和文本嵌入连接起来以增强检索性能。其次，我们提出通过 LVLM 的反馈重新对嵌入模型检索到的演示进行排名，并计算一个列表级排名损失以训练嵌入模型。第三，我们提出了一种迭代演示挖掘策略来改进嵌入模型的训练。通过对 3 种类型的视觉语言任务、7 个基准数据集进行广泛的实验，我们的 DRUM 框架被证明可以有效地通过检索更合适的演示来提升 LVLM 的上下文学习性能。</paragraph>

##### **Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs**
2412.07618v1 by Xiaqiang Tang, Jian Li, Nan Du, Sihong Xie

Despite the superior performance of Large language models on many NLP tasks,
they still face significant limitations in memorizing extensive world
knowledge. Recent studies have demonstrated that leveraging the
Retrieval-Augmented Generation (RAG) framework, combined with Knowledge Graphs
that encapsulate extensive factual data in a structured format, robustly
enhances the reasoning capabilities of LLMs. However, deploying such systems in
real-world scenarios presents challenges: the continuous evolution of
non-stationary environments may lead to performance degradation and user
satisfaction requires a careful balance of performance and responsiveness. To
address these challenges, we introduce a Multi-objective Multi-Armed Bandit
enhanced RAG framework, supported by multiple retrieval methods with diverse
capabilities under rich and evolving retrieval contexts in practice. Within
this framework, each retrieval method is treated as a distinct ``arm''. The
system utilizes real-time user feedback to adapt to dynamic environments, by
selecting the appropriate retrieval method based on input queries and the
historical multi-objective performance of each arm. Extensive experiments
conducted on two benchmark KGQA datasets demonstrate that our method
significantly outperforms baseline methods in non-stationary settings while
achieving state-of-the-art performance in stationary environments. Code and
data are available at https://github.com/FUTUREEEEEE/Dynamic-RAG.git

摘要：儘管大型語言模型在許多 NLP 任務上表現優異，
它們在記憶廣泛的世界知識方面仍面臨重大限制。最近的研究表明，
利用檢索增強生成 (RAG) 框架，結合以結構化格式封裝廣泛事實資料的知識圖譜，
能穩健地增強 LLM 的推理能力。然而，在現實世界場景中部署此類系統會產生挑戰：
非平穩環境的持續演變可能導致效能下降，而使用者的滿意度需要在效能和回應性之間取得仔細的平衡。
為了應對這些挑戰，我們引入了多目標多臂老虎機增強的 RAG 框架，
並在實務中採用具備多元能力的各種檢索方法，以應對豐富且不斷演變的檢索情境。
在此框架中，每個檢索方法都被視為一個不同的「手臂」。
該系統利用即時使用者回饋來適應動態環境，
根據輸入查詢和每個手臂的歷史多目標效能來選擇適當的檢索方法。
在兩個基準 KGQA 資料集上進行的廣泛實驗表明，
我們的模型在非平穩設定中顯著優於基線模型，同時在平穩環境中達到最先進的效能。
程式碼和資料可於 https://github.com/FUTUREEEEEE/Dynamic-RAG.git 取得

##### **Swarm Behavior Cloning**
2412.07617v1 by Jonas Nüßlein, Maximilian Zorn, Philipp Altmann, Claudia Linnhoff-Popien

In sequential decision-making environments, the primary approaches for
training agents are Reinforcement Learning (RL) and Imitation Learning (IL).
Unlike RL, which relies on modeling a reward function, IL leverages expert
demonstrations, where an expert policy $\pi_e$ (e.g., a human) provides the
desired behavior. Formally, a dataset $D$ of state-action pairs is provided: $D
= {(s, a = \pi_e(s))}$. A common technique within IL is Behavior Cloning (BC),
where a policy $\pi(s) = a$ is learned through supervised learning on $D$.
Further improvements can be achieved by using an ensemble of $N$ individually
trained BC policies, denoted as $E = {\pi_i(s)}{1 \leq i \leq N}$. The
ensemble's action $a$ for a given state $s$ is the aggregated output of the $N$
actions: $a = \frac{1}{N} \sum{i} \pi_i(s)$. This paper addresses the issue of
increasing action differences -- the observation that discrepancies between the
$N$ predicted actions grow in states that are underrepresented in the training
data. Large action differences can result in suboptimal aggregated actions. To
address this, we propose a method that fosters greater alignment among the
policies while preserving the diversity of their computations. This approach
reduces action differences and ensures that the ensemble retains its inherent
strengths, such as robustness and varied decision-making. We evaluate our
approach across eight diverse environments, demonstrating a notable decrease in
action differences and significant improvements in overall performance, as
measured by mean episode returns.

摘要：在顺序決策環境中，訓練代理的主要方法是強化學習 (RL) 和模仿學習 (IL)。與依賴於建模獎勵函數的 RL 不同，IL 利用專家示範，其中專家策略 $\pi_e$（例如，人類）提供所需的行為。正式地，提供了一個狀態動作對的資料集 $D$：$D = {(s, a = \pi_e(s))}$。IL 中的一種常見技術是行為複製 (BC)，其中通過在 $D$ 上進行監督式學習來學習策略 $\pi(s) = a$。通過使用一組 $N$ 個個別訓練的 BC 策略（表示為 $E = {\pi_i(s)}{1 \leq i \leq N}$）可以進一步提高。集合體對於給定狀態 $s$ 的動作 $a$ 是 $N$ 個動作的聚合輸出：$a = \frac{1}{N} \sum{i} \pi_i(s)$。本文探討了增加動作差異的問題——觀察到在訓練資料中代表性不足的狀態中，$N$ 個預測動作之間的差異會增長。大的動作差異可能導致次優的聚合動作。為了解決這個問題，我們提出了一種方法，它在保留其計算多樣性的同時，促進策略之間更大的對齊。這種方法減少了動作差異，並確保集合體保留其固有的優勢，例如穩健性和多樣化的決策制定。我們在八個不同的環境中評估了我們的做法，展示了動作差異的顯著減少和整體性能的顯著提升，如平均情節回報率所測量的那樣。

##### **Scaling Sequential Recommendation Models with Transformers**
2412.07585v1 by Pablo Zivic, Hernan Vazquez, Jorge Sanchez

Modeling user preferences has been mainly addressed by looking at users'
interaction history with the different elements available in the system.
Tailoring content to individual preferences based on historical data is the
main goal of sequential recommendation.
  The nature of the problem, as well as the good performance observed across
various domains, has motivated the use of the transformer architecture, which
has proven effective in leveraging increasingly larger amounts of training data
when accompanied by an increase in the number of model parameters. This scaling
behavior has brought a great deal of attention, as it provides valuable
guidance in the design and training of even larger models.
  Taking inspiration from the scaling laws observed in training large language
models, we explore similar principles for sequential recommendation.
  We use the full Amazon Product Data dataset, which has only been partially
explored in other studies, and reveal scaling behaviors similar to those found
in language models. Compute-optimal training is possible but requires a careful
analysis of the compute-performance trade-offs specific to the application.
  We also show that performance scaling translates to downstream tasks by
fine-tuning larger pre-trained models on smaller task-specific domains. Our
approach and findings provide a strategic roadmap for model training and
deployment in real high-dimensional preference spaces, facilitating better
training and inference efficiency.
  We hope this paper bridges the gap between the potential of transformers and
the intrinsic complexities of high-dimensional sequential recommendation in
real-world recommender systems.
  Code and models can be found at https://github.com/mercadolibre/srt

摘要：<paragraph>建模使用者偏好主要透過觀察使用者與系統中不同元素的互動記錄。
根據歷史資料調整個人偏好的內容是連續推薦的主要目標。
問題的本質，以及在各個領域觀察到的良好效能，激勵了Transformer架構的使用，在增加模型參數數量時，已證明能有效利用越來越多訓練資料。這種規模行為引起了極大的關注，因為它在設計和訓練更大模型時提供了有價值的指導。
從訓練大型語言模型中觀察到的規模法則中汲取靈感，我們探討了連續推薦的類似原則。
我們使用了完整的 Amazon 產品資料集，其他研究僅部分探討過，並揭示了與在語言模型中發現的類似的規模行為。計算最佳訓練是可能的，但需要仔細分析特定於應用程式的計算效能折衷。
我們還展示了效能規模轉化為下游任務，透過對較小的特定任務領域微調較大的預訓練模型。我們的做法和發現為模型訓練和在實際高維度偏好空間中部署提供了策略性路線圖，促進更好的訓練和推理效率。
我們希望這篇論文能彌合Transformer潛力與實際推薦系統中高維度連續推薦的內在複雜性之間的差距。
程式碼和模型可以在 https://github.com/mercadolibre/srt 找到</paragraph>

##### **Multimodal Contextualized Support for Enhancing Video Retrieval System**
2412.07584v1 by Quoc-Bao Nguyen-Le, Thanh-Huy Le-Nguyen

Current video retrieval systems, especially those used in competitions,
primarily focus on querying individual keyframes or images rather than encoding
an entire clip or video segment. However, queries often describe an action or
event over a series of frames, not a specific image. This results in
insufficient information when analyzing a single frame, leading to less
accurate query results. Moreover, extracting embeddings solely from images
(keyframes) does not provide enough information for models to encode
higher-level, more abstract insights inferred from the video. These models tend
to only describe the objects present in the frame, lacking a deeper
understanding. In this work, we propose a system that integrates the latest
methodologies, introducing a novel pipeline that extracts multimodal data, and
incorporate information from multiple frames within a video, enabling the model
to abstract higher-level information that captures latent meanings, focusing on
what can be inferred from the video clip, rather than just focusing on object
detection in one single image.

摘要：目前的影片擷取系統，特別是競賽中使用的系統，
主要專注於查詢個別關鍵影格或影像，而非編碼整個影片片段或影片區段。然而，查詢通常會描述一系列影格中的動作或事件，而非特定影像。這會導致分析單一影格時資訊不足，進而產生較不準確的查詢結果。此外，僅從影像（關鍵影格）中擷取嵌入式資訊並無法提供足夠的資訊，讓模型編碼從影片推論出的更高層次、更抽象的見解。這些模型往往僅描述影格中存在的物體，缺乏更深入的理解。在這項工作中，我們提出一個整合最新方法的系統，引入一個新穎的管線，用以擷取多模態資料，並整合影片中多個影格的資訊，讓模型能夠抽象出捕捉潛在意義的更高層次資訊，專注於從影片片段中可以推論出的內容，而非僅專注於單一影像中的物體偵測。

##### **Mobile Video Diffusion**
2412.07583v1 by Haitam Ben Yahia, Denis Korzhenkov, Ioannis Lelekas, Amir Ghodrati, Amirhossein Habibian

Video diffusion models have achieved impressive realism and controllability
but are limited by high computational demands, restricting their use on mobile
devices. This paper introduces the first mobile-optimized video diffusion
model. Starting from a spatio-temporal UNet from Stable Video Diffusion (SVD),
we reduce memory and computational cost by reducing the frame resolution,
incorporating multi-scale temporal representations, and introducing two novel
pruning schema to reduce the number of channels and temporal blocks.
Furthermore, we employ adversarial finetuning to reduce the denoising to a
single step. Our model, coined as MobileVD, is 523x more efficient (1817.2 vs.
4.34 TFLOPs) with a slight quality drop (FVD 149 vs. 171), generating latents
for a 14x512x256 px clip in 1.7 seconds on a Xiaomi-14 Pro. Our results are
available at https://qualcomm-ai-research.github.io/mobile-video-diffusion/

摘要：影片擴散模型已達到令人印象深刻的真實感和可控性，但受到高運算需求的限制，限制了它們在行動裝置上的使用。本文介紹了第一個針對行動裝置最佳化的影片擴散模型。從 Stable Video Diffusion (SVD) 的時空 UNet 開始，我們透過降低影格解析度、整合多尺度時間表示，以及引入兩個創新的修剪架構來減少通道和時間區塊的數量，以減少記憶體和運算成本。此外，我們採用對抗式微調，將去噪步驟減少為單一步驟。我們的模型稱為 MobileVD，效率提高了 523 倍（1817.2 與 4.34 TFLOP），品質略有下降（FVD 149 與 171），在小米 14 Pro 上為 14x512x256 像素的剪輯產生潛在變數，耗時 1.7 秒。我們的結果可在 https://qualcomm-ai-research.github.io/mobile-video-diffusion/ 取得。

##### **SST framework for Document Matching**
2412.07573v1 by Youchao Zhou, Heyan Huang, Zhijing Wu, Yuhang Liu, Xinglin Wang

Long-form document matching aims to judge the relevance between two documents
and has been applied to various scenarios. Most existing works utilize
hierarchical or long context models to process documents, which achieve coarse
understanding but may ignore details. Some researchers construct a document
view with similar sentences about aligned document subtopics to focus on
detailed matching signals. However, a long document generally contains multiple
subtopics. The matching signals are heterogeneous from multiple topics.
Considering only the homologous aligned subtopics may not be representative
enough and may cause biased modeling. In this paper, we introduce a new
framework to model representative matching signals. First, we propose to
capture various matching signals through subtopics of document pairs. Next, We
construct multiple document views based on subtopics to cover heterogeneous and
valuable details. However, existing spatial aggregation methods like attention,
which integrate all these views simultaneously, are hard to integrate
heterogeneous information. Instead, we propose temporal aggregation, which
effectively integrates different views gradually as the training progresses.
Experimental results show that our learning framework is effective on several
document-matching tasks, including news duplication and legal case retrieval.

摘要：長文件文件配對旨在判斷兩個文件之間的關聯性，並已應用於各種場景。現有的大多數作品利用階層式或長上下文模型來處理文件，這實現了粗略的理解，但可能會忽略細節。一些研究人員構建了一個包含有關對齊文件子主題的相似句子的文件檢視，以專注於詳細的匹配訊號。然而，長文件通常包含多個子主題。匹配訊號來自多個主題，是異質的。僅考慮同源對齊子主題可能不夠具代表性，並且可能導致偏頗的建模。在本文中，我們引入了一個新的框架來建模具有代表性的匹配訊號。首先，我們建議透過文件對的子主題擷取各種匹配訊號。接下來，我們基於子主題構建多個文件檢視，以涵蓋異質且有價值的細節。然而，現有的空間聚合方法（例如注意力），同時整合所有這些檢視，很難整合異質資訊。相反，我們提出時間聚合，隨著訓練的進行，它會逐漸有效地整合不同的檢視。實驗結果表明，我們的學習框架在多項文件匹配任務中是有效的，包括新聞重複和法律案例檢索。

##### **A data-driven learned discretization approach in finite volume schemes for hyperbolic conservation laws and varying boundary conditions**
2412.07541v1 by Guillaume de Romémont, Florent Renac, Jorge Nunez, Francisco Chinesta

This paper presents a data-driven finite volume method for solving 1D and 2D
hyperbolic partial differential equations. This work builds upon the prior
research incorporating a data-driven finite-difference approximation of smooth
solutions of scalar conservation laws, where optimal coefficients of neural
networks approximating space derivatives are learned based on accurate, but
cumbersome solutions to these equations. We extend this approach to
flux-limited finite volume schemes for hyperbolic scalar and systems of
conservation laws. We also train the discretization to efficiently capture
discontinuous solutions with shock and contact waves, as well as to the
application of boundary conditions. The learning procedure of the data-driven
model is extended through the definition of a new loss, paddings and adequate
database. These new ingredients guarantee computational stability, preserve the
accuracy of fine-grid solutions, and enhance overall performance. Numerical
experiments using test cases from the literature in both one- and
two-dimensional spaces demonstrate that the learned model accurately reproduces
fine-grid results on very coarse meshes.

摘要：本文提出了一個資料驅動的有限體積法，用於求解 1D 和 2D 雙曲型偏微分方程式。這項工作建立在先前的研究上，結合了平滑解的資料驅動有限差分近似值，其中近似空間導數的神經網路最佳係數是根據這些方程式的準確但繁瑣的解而學習的。我們將此方法擴展到雙曲型標量和守恆律系統的通量限制有限體積方案。我們還訓練離散化以有效捕捉具有激波和接觸波的不連續解，以及邊界條件的應用。資料驅動模型的學習過程透過定義新的損失、填充和適當的資料庫而得到擴展。這些新成分保證了計算穩定性，保留了精細網格解的準確性，並增強了整體效能。使用來自文獻中一維和二維空間的測試案例進行的數值實驗表明，學習到的模型在非常粗糙的網格上準確地重現了精細網格結果。

##### **CoPrUS: Consistency Preserving Utterance Synthesis towards more realistic benchmark dialogues**
2412.07515v1 by Sebastian Steindl, Ulrich Schäfer, Bernd Ludwig

Large-scale Wizard-Of-Oz dialogue datasets have enabled the training of deep
learning-based dialogue systems. While they are successful as benchmark
datasets, they lack certain types of utterances, which would make them more
realistic. In this work, we investigate the creation of synthetic communication
errors in an automatic pipeline. Based on linguistic theory, we propose and
follow a simple error taxonomy. We focus on three types of miscommunications
that could happen in real-world dialogues but are underrepresented in the
benchmark dataset: misunderstandings, non-understandings and vaguely related
questions. Our two-step approach uses a state-of-the-art Large Language Model
(LLM) to first create the error and secondly the repairing utterance. We
perform Language Model-based evaluation to ensure the quality of the generated
utterances. We apply the method to the MultiWOZ dataset and evaluate it both
qualitatively and empirically as well as with human judges. Our results
indicate that current LLMs can aid in adding post-hoc miscommunications to
benchmark datasets as a form of data augmentation. We publish the resulting
dataset, in which nearly 1900 dialogues have been modified, as CoPrUS-MultiWOZ
to facilitate future work on dialogue systems.

摘要：大型绿野仙踪对话数据集已能训练基于深度学习的对话系统。虽然它们作为基准数据集很成功，但它们缺乏某些类型的言论，这会使它们更真实。在这项工作中，我们研究了在自动管道中创建合成通信错误。基于语言理论，我们提出并遵循简单的错误分类法。我们专注于现实世界对话中可能发生但在基准数据集中代表性不足的三种类型的误传：误解、不理解和含糊相关的问题。我们的两步法使用最先进的大语言模型 (LLM) 首先创建错误，然后修复言论。我们执行基于语言模型的评估以确保生成言论的质量。我们将该方法应用于 MultiWOZ 数据集，并对其进行定性和经验评估以及人类评判。我们的结果表明，当前的 LLM 可以帮助将事后误传添加到基准数据集作为数据扩充的一种形式。我们发布了结果数据集，其中近 1900 个对话已被修改，作为 CoPrUS-MultiWOZ，以促进对话系统未来的工作。

##### **Ontology-driven Prompt Tuning for LLM-based Task and Motion Planning**
2412.07493v1 by Muhayy Ud Din, Jan Rosell, Waseem Akram, Isiah Zaplana, Maximo A Roa, Lakmal Seneviratne, Irfan Hussain

Performing complex manipulation tasks in dynamic environments requires
efficient Task and Motion Planning (TAMP) approaches, which combine high-level
symbolic plan with low-level motion planning. Advances in Large Language Models
(LLMs), such as GPT-4, are transforming task planning by offering natural
language as an intuitive and flexible way to describe tasks, generate symbolic
plans, and reason. However, the effectiveness of LLM-based TAMP approaches is
limited due to static and template-based prompting, which struggles in adapting
to dynamic environments and complex task contexts. To address these
limitations, this work proposes a novel ontology-driven prompt-tuning framework
that employs knowledge-based reasoning to refine and expand user prompts with
task contextual reasoning and knowledge-based environment state descriptions.
Integrating domain-specific knowledge into the prompt ensures semantically
accurate and context-aware task plans. The proposed framework demonstrates its
effectiveness by resolving semantic errors in symbolic plan generation, such as
maintaining logical temporal goal ordering in scenarios involving hierarchical
object placement. The proposed framework is validated through both simulation
and real-world scenarios, demonstrating significant improvements over the
baseline approach in terms of adaptability to dynamic environments, and the
generation of semantically correct task plans.

摘要：在動態環境中執行複雜操作任務需要有效率的任務和動作規劃 (TAMP) 方法，它結合了高階符號計畫和低階動作規劃。大型語言模型 (LLM) 的進展，例如 GPT-4，透過提供自然語言作為一種直觀且彈性的方式來描述任務、產生符號計畫和推理，進而轉變了任務規劃。然而，基於 LLM 的 TAMP 方法的有效性受到靜態和基於範本的提示的限制，這在適應動態環境和複雜任務情境方面有困難。為了解決這些限制，這項工作提出了一個新穎的本體驅動提示調整架構，它採用基於知識的推理來使用任務情境推理和基於知識的環境狀態描述來精煉和擴充使用者的提示。將特定領域的知識整合到提示中，可確保語義準確且具備情境感知的任務計畫。所提出的架構透過解決符號計畫產生中的語義錯誤來證明其有效性，例如在涉及階層式物件放置的情境中維持邏輯時間目標順序。所提出的架構透過模擬和真實世界情境進行驗證，證明在適應動態環境以及產生語義正確的任務計畫方面，都比基線方法有顯著的進步。

##### **SmartAgent: Chain-of-User-Thought for Embodied Personalized Agent in Cyber World**
2412.07472v1 by Jiaqi Zhang, Chen Gao, Liyuan Zhang, Yong Li, Hongzhi Yin

Recent advances in embodied agents with multimodal perception and reasoning
capabilities based on large vision-language models (LVLMs), excel in
autonomously interacting either real or cyber worlds, helping people make
intelligent decisions in complex environments. However, the current works are
normally optimized by golden action trajectories or ideal task-oriented
solutions toward a definitive goal. This paradigm considers limited
user-oriented factors, which could be the reason for their performance
reduction in a wide range of personal assistant applications. To address this,
we propose Chain-of-User-Thought (COUT), a novel embodied reasoning paradigm
that takes a chain of thought from basic action thinking to explicit and
implicit personalized preference thought to incorporate personalized factors
into autonomous agent learning. To target COUT, we introduce SmartAgent, an
agent framework perceiving cyber environments and reasoning personalized
requirements as 1) interacting with GUI to access an item pool, 2) generating
users' explicit requirements implied by previous actions, and 3) recommending
items to fulfill users' implicit requirements. To demonstrate SmartAgent's
capabilities, we also create a brand-new dataset SmartSpot that offers a
full-stage personalized action-involved environment. To our best knowledge, our
work is the first to formulate the COUT process, serving as a preliminary
attempt towards embodied personalized agent learning. Our extensive experiments
on SmartSpot illuminate SmartAgent's functionality among a series of embodied
and personalized sub-tasks. We will release code and data upon paper
notification at \url{https://github.com/tsinghua-fib-lab/SmartAgent}.

摘要：<paragraph>最近多模态感知和推理能力的具身代理取得了进展，基于大型视觉语言模型 (LVLMs)，在自动交互真实或网络世界方面表现出色，帮助人们在复杂环境中做出明智的决策。然而，当前的工作通常通过黄金动作轨迹或理想的任务导向解决方案针对明确的目标进行优化。这种范例考虑了有限的用户导向因素，这可能是其在广泛的个人助理应用程序中性能降低的原因。为了解决这个问题，我们提出了用户思想链 (COUT)，一种新颖的具身推理范例，它从基本动作思维到显性和隐式个性化偏好思维，将个性化因素纳入自主代理学习中。为了针对 COUT，我们引入了 SmartAgent，一个代理框架，它可以感知网络环境并推理个性化需求，包括 1) 与 GUI 交互以访问项目池，2) 生成由先前操作暗示的用户显式需求，以及 3) 推荐项目以满足用户的隐式需求。为了展示 SmartAgent 的能力，我们还创建了一个全新的数据集 SmartSpot，它提供了一个全阶段的个性化动作参与环境。据我们所知，我们的工作是第一个制定 COUT 流程，作为面向具身个性化代理学习的初步尝试。我们在 SmartSpot 上进行的广泛实验阐明了 SmartAgent 在一系列具身和个性化子任务中的功能。我们将在 \url{https://github.com/tsinghua-fib-lab/SmartAgent} 上发布论文通知后的代码和数据。</paragraph>

##### **Bilingual BSARD: Extending Statutory Article Retrieval to Dutch**
2412.07462v1 by Ehsan Lotfi, Nikolay Banar, Nerses Yuzbashyan, Walter Daelemans

Statutory article retrieval plays a crucial role in making legal information
more accessible to both laypeople and legal professionals. Multilingual
countries like Belgium present unique challenges for retrieval models due to
the need for handling legal issues in multiple languages. Building on the
Belgian Statutory Article Retrieval Dataset (BSARD) in French, we introduce the
bilingual version of this dataset, bBSARD. The dataset contains parallel
Belgian statutory articles in both French and Dutch, along with legal questions
from BSARD and their Dutch translation. Using bBSARD, we conduct extensive
benchmarking of retrieval models available for Dutch and French. Our
benchmarking setup includes lexical models, zero-shot dense models, and
fine-tuned small foundation models. Our experiments show that BM25 remains a
competitive baseline compared to many zero-shot dense models in both languages.
We also observe that while proprietary models outperform open alternatives in
the zero-shot setting, they can be matched or surpassed by fine-tuning small
language-specific models. Our dataset and evaluation code are publicly
available.

摘要：法定條文檢索在讓法律資訊更易於讓一般民眾和法律專業人士取得方面扮演著至關重要的角色。像比利時等多語國家由於需要處理多種語言的法律問題，因此對檢索模型提出了獨特的挑戰。我們在法語的比利時法定條文檢索資料集 (BSARD) 的基礎上，推出了這個資料集的雙語版本 bBSARD。這個資料集包含法語和荷蘭語的比利時法定條文平行語料，以及 BSARD 中的法律問題及其荷蘭語翻譯。使用 bBSARD，我們對荷蘭語和法語可用的檢索模型進行了廣泛的基準測試。我們的基準測試設定包括詞彙模型、零次學習稠密模型和微調小型基礎模型。我們的實驗表明，與兩種語言中的許多零次學習稠密模型相比，BM25 仍然是一個有競爭力的基線。我們還觀察到，雖然專有模型在零次學習設定中優於開放式替代方案，但它們可以通過微調特定於語言的小型模型來匹配或超越。我們的資料集和評估程式碼已公開。

##### **Tazza: Shuffling Neural Network Parameters for Secure and Private Federated Learning**
2412.07454v1 by Kichang Lee, Jaeho Jin, JaeYeon Park, JeongGil Ko

Federated learning enables decentralized model training without sharing raw
data, preserving data privacy. However, its vulnerability towards critical
security threats, such as gradient inversion and model poisoning by malicious
clients, remain unresolved. Existing solutions often address these issues
separately, sacrificing either system robustness or model accuracy. This work
introduces Tazza, a secure and efficient federated learning framework that
simultaneously addresses both challenges. By leveraging the permutation
equivariance and invariance properties of neural networks via weight shuffling
and shuffled model validation, Tazza enhances resilience against diverse
poisoning attacks, while ensuring data confidentiality and high model accuracy.
Comprehensive evaluations on various datasets and embedded platforms show that
Tazza achieves robust defense with up to 6.7x improved computational efficiency
compared to alternative schemes, without compromising performance.

摘要：聯邦學習可進行分散式模型訓練，而不需分享原始資料，進而保護資料隱私。然而，其對於重大安全威脅的脆弱性，例如惡意用戶的梯度反轉和模型中毒，仍未獲得解決。現有解決方案通常會個別處理這些問題，犧牲系統穩健性或模型準確性。本研究引入了 Tazza，一個安全且有效的聯邦學習架構，能同時解決這兩個挑戰。Tazza 透過權重洗牌和洗牌模型驗證，利用神經網路的置換等變性和不變性屬性，增強對各種中毒攻擊的復原力，同時確保資料機密性和高模型準確性。在各種資料集和嵌入式平台上的全面評估顯示，與替代方案相比，Tazza 達到了穩健的防禦能力，運算效率提高了 6.7 倍，且不影響效能。

##### **Dynamic Ensemble Reasoning for LLM Experts**
2412.07448v1 by Jinwu Hu, Yufeng Wang, Shuhai Zhang, Kai Zhou, Guohao Chen, Yu Hu, Bin Xiao, Mingkui Tan

Ensemble reasoning for the strengths of different LLM experts is critical to
achieving consistent and satisfactory performance on diverse inputs across a
wide range of tasks. However, existing LLM ensemble methods are either
computationally intensive or incapable of leveraging complementary knowledge
among LLM experts for various inputs. In this paper, we propose a Dynamic
Ensemble Reasoning paradigm, called DER to integrate the strengths of multiple
LLM experts conditioned on dynamic inputs. Specifically, we model the LLM
ensemble reasoning problem as a Markov Decision Process (MDP), wherein an agent
sequentially takes inputs to request knowledge from an LLM candidate and passes
the output to a subsequent LLM candidate. Moreover, we devise a reward function
to train a DER-Agent to dynamically select an optimal answering route given the
input questions, aiming to achieve the highest performance with as few
computational resources as possible. Last, to fully transfer the expert
knowledge from the prior LLMs, we develop a Knowledge Transfer Prompt (KTP)
that enables the subsequent LLM candidates to transfer complementary knowledge
effectively. Experiments demonstrate that our method uses fewer computational
resources to achieve better performance compared to state-of-the-art baselines.

摘要：針對不同 LLM 專家的優勢進行整體推理，對於在各種任務的各種輸入中達成一致且令人滿意的效能至關重要。然而，現有的 LLM 整合方法不是計算密集，就是無法針對各種輸入利用 LLM 專家之間的互補知識。在本文中，我們提出一個名為 DER 的動態整體推理範例，以整合多位 LLM 專家的優勢，並以動態輸入為條件。具體而言，我們將 LLM 整合推理問題建模為馬可夫決策過程 (MDP)，其中一個代理會依序取得輸入，以要求 LLM 候選者提供知識，並將輸出傳遞給後續的 LLM 候選者。此外，我們設計了一個獎勵函數來訓練 DER 代理，以動態選擇最佳回答路徑，並以最少的計算資源達成最高的效能。最後，為了完全傳遞先前 LLM 的專家知識，我們開發了一個知識傳遞提示 (KTP)，讓後續的 LLM 候選者能夠有效傳遞互補知識。實驗證明，與最先進的基準線相比，我們的模型使用較少的計算資源就能達成更好的效能。

##### **Causal World Representation in the GPT Model**
2412.07446v1 by Raanan Y. Rohekar, Yaniv Gurwicz, Sungduk Yu, Vasudev Lal

Are generative pre-trained transformer (GPT) models only trained to predict
the next token, or do they implicitly learn a world model from which a sequence
is generated one token at a time? We examine this question by deriving a causal
interpretation of the attention mechanism in GPT, and suggesting a causal world
model that arises from this interpretation. Furthermore, we propose that
GPT-models, at inference time, can be utilized for zero-shot causal structure
learning for in-distribution sequences. Empirical evaluation is conducted in a
controlled synthetic environment using the setup and rules of the Othello board
game. A GPT, pre-trained on real-world games played with the intention of
winning, is tested on synthetic data that only adheres to the game rules. We
find that the GPT model tends to generate next moves that adhere to the game
rules for sequences for which the attention mechanism encodes a causal
structure with high confidence. In general, in cases for which the GPT model
generates moves that do not adhere to the game rules, it also fails to capture
any causal structure.

摘要：生成式预训练转换器 (GPT) 模型是否仅接受过预测下一个标记的训练，还是它们隐式地学习了一个世界模型，从中一次生成一个标记的序列？我们通过推导 GPT 中注意力机制的因果解释来检验这个问题，并提出了由此解释产生的因果世界模型。此外，我们提出 GPT 模型在推理时可用于分布内序列的零样本因果结构学习。使用奥赛罗棋盘游戏的设置和规则，在受控的合成环境中进行经验评估。对一个经过预训练的 GPT（使用赢得游戏的意图进行真实世界游戏）在仅遵循游戏规则的合成数据上进行测试。我们发现，对于注意力机制以高置信度编码因果结构的序列，GPT 模型倾向于生成遵守游戏规则的下一步移动。一般来说，在 GPT 模型生成不遵守游戏规则的移动的情况下，它也无法捕捉到任何因果结构。

##### **Knowledge Graph Guided Evaluation of Abstention Techniques**
2412.07430v1 by Kinshuk Vasisht, Navreet Kaur, Danish Pruthi

To deploy language models safely, it is crucial that they abstain from
responding to inappropriate requests. Several prior studies test the safety
promises of models based on their effectiveness in blocking malicious requests.
In this work, we focus on evaluating the underlying techniques that cause
models to abstain. We create SELECT, a benchmark derived from a set of benign
concepts (e.g., "rivers") from a knowledge graph. The nature of SELECT enables
us to isolate the effects of abstention techniques from other safety training
procedures, as well as evaluate their generalization and specificity. Using
SELECT, we benchmark different abstention techniques over six open-weight and
closed-source models. We find that the examined techniques indeed cause models
to abstain with over $80\%$ abstention rates. However, these techniques are not
as effective for descendants of the target concepts, with refusal rates
declining by $19\%$. We also characterize the generalization-vs-specificity
trade-offs for different techniques. Overall, no single technique is invariably
better than the others. Our findings call for a careful evaluation of different
aspects of abstention, and hopefully inform practitioners of various trade-offs
involved.

摘要：為了安全地部署語言模型，至關重要的是，它們必須避免回應不適當的請求。先前有數項研究測試模型的安全性，依據它們封鎖惡意請求的有效性為基礎。在這項工作中，我們專注於評估導致模型避免回應的底層技術。我們建立了 SELECT，一個從知識圖譜中一組良性概念（例如「河流」）衍生的基準。SELECT 的性質使我們能夠將避免回應技術的影響與其他安全訓練程序隔離，並評估它們的概括性和特異性。使用 SELECT，我們對六個開放權重和封閉原始碼模型進行了不同避免回應技術的基準測試。我們發現，所檢查的技術確實導致模型避免回應，避免回應率超過 80%。然而，這些技術對於目標概念的後代並不那麼有效，拒絕率下降了 19%。我們還描述了不同技術的概括性與特異性權衡。總體而言，沒有任何單一技術始終優於其他技術。我們的發現要求仔細評估避免回應的不同面向，並希望讓從業人員了解所涉及的各種權衡。

##### **Optimizing Alignment with Less: Leveraging Data Augmentation for Personalized Evaluation**
2412.07429v1 by Javad Seraj, Mohammad Mahdi Mohajeri, Mohammad Javad Dousti, Majid Nili Ahmadabadi

Automatic evaluation by large language models (LLMs) is a prominent topic
today; however, judgment and evaluation tasks are often subjective and
influenced by various factors, making adaptation challenging. While many
studies demonstrate the capabilities of state-of-the-art proprietary LLMs in
comparison to human evaluators, they often struggle to adapt to reference
evaluators over time, a requirement for achieving personalized judgment.
Additionally, numerous works have attempted to apply open LLMs as judges or
evaluators, but these efforts frequently overlook the limitations of working
with scarce data. Personalized judgment is inherently associated with limited
data scenarios, which are common in many real-world problems. Our work aims to
present a data augmentation technique to select a more effective sample from
limited data in order to align an open LLM with human preference. Our work
achieves approximately 7% improvements in Pearson correlation with a reference
judge over the baseline,and 30% improvement over the base model
(Llama3.1-8B-Instruct) in the mathematical reasoning evaluation task.
demonstrating that augmenting selecting more effective preference data enables
our approach to surpass baseline methods.

摘要：大型語言模型 (LLM) 的自動評估是當今的熱門話題；然而，判斷和評估任務通常是主觀的，並受到各種因素的影響，這使得適應具有挑戰性。雖然許多研究展示了最先進的專有 LLM 與人類評估員相比的能力，但它們通常難以隨著時間適應參考評估員，這是實現個性化判斷的要求。此外，許多作品嘗試將開放式 LLM 應用為評判或評估員，但這些努力常常忽略了使用稀疏數據的限制。個性化判斷本質上與有限數據場景相關，這在許多現實世界問題中很常見。我們的目標是提出一種數據擴充技術，從有限數據中選擇一個更有效的樣本，以便將開放式 LLM 與人類偏好保持一致。我們的研究在與參考評審員的皮爾森相關性方面取得了大約 7% 的改進，而在數學推理評估任務中，則比基礎模型 (Llama3.1-8B-Instruct) 提高了 30%。這表明擴充選擇更有效的偏好數據使我們的方法能夠超越基線方法。

##### **RAG-based Question Answering over Heterogeneous Data and Text**
2412.07420v1 by Philipp Christmann, Gerhard Weikum

This article presents the QUASAR system for question answering over
unstructured text, structured tables, and knowledge graphs, with unified
treatment of all sources. The system adopts a RAG-based architecture, with a
pipeline of evidence retrieval followed by answer generation, with the latter
powered by a moderate-sized language model. Additionally and uniquely, QUASAR
has components for question understanding, to derive crisper input for evidence
retrieval, and for re-ranking and filtering the retrieved evidence before
feeding the most informative pieces into the answer generation. Experiments
with three different benchmarks demonstrate the high answering quality of our
approach, being on par with or better than large GPT models, while keeping the
computational cost and energy consumption orders of magnitude lower.

摘要：本文介紹 QUASAR 系統，用於回答非結構化文字、結構化表格和知識圖表中的問題，並統一處理所有來源。該系統採用基於 RAG 的架構，管道包括證據檢索後接答案生成，後者由中等規模的語言模型提供支援。此外，QUASAR 獨特地包含問題理解元件，以衍生更清晰的輸入進行證據檢索，以及在將最有資訊的片段輸入答案生成之前重新排序和過濾檢索到的證據。使用三個不同的基準進行的實驗證明了我們方法的高回答品質，與大型 GPT 模型相當或更好，同時將運算成本和能源消耗降低了幾個數量級。

##### **Composing or Not Composing? Towards Distributional Construction Grammars**
2412.07419v1 by Philippe Blache, Emmanuele Chersoni, Giulia Rambelli, Alessandro Lenci

The mechanisms of comprehension during language processing remains an open
question. Classically, building the meaning of a linguistic utterance is said
to be incremental, step-by-step, based on a compositional process. However,
many different works have shown for a long time that non-compositional
phenomena are also at work. It is therefore necessary to propose a framework
bringing together both approaches. We present in this paper an approach based
on Construction Grammars and completing this framework in order to account for
these different mechanisms. We propose first a formal definition of this
framework by completing the feature structure representation proposed in
Sign-Based Construction Grammars. In a second step, we present a general
representation of the meaning based on the interaction of constructions, frames
and events. This framework opens the door to a processing mechanism for
building the meaning based on the notion of activation evaluated in terms of
similarity and unification. This new approach integrates features from
distributional semantics into the constructionist framework, leading to what we
call Distributional Construction Grammars.

摘要：語言處理過程中理解的機制仍然是一個開放性的問題。傳統上，語言表達的意義建構被認為是漸進的，循序漸進的，基於組合過程。然而，許多不同的作品長期以來表明，非組合現象也在起作用。因此，有必要提出一個將兩種方法結合在一起的框架。我們在本文中提出了一種基於建構語法的途徑，並完善了這個框架，以解釋這些不同的機制。我們首先通過完善符號建構語法中提出的特徵結構表示，對這個框架進行形式定義。在第二步中，我們基於建構、框架和事件的交互作用，提出了意義的一般表示。這個框架為基於相似性和統一性概念評估激活的意義建構處理機制打開了大門。這種新方法將分佈語義的特徵整合到建構主義框架中，形成了我們所稱的分佈式建構語法。

##### **Generating Knowledge Graphs from Large Language Models: A Comparative Study of GPT-4, LLaMA 2, and BERT**
2412.07412v1 by Ahan Bhatt, Nandan Vaghela, Kush Dudhia

Knowledge Graphs (KGs) are essential for the functionality of GraphRAGs, a
form of Retrieval-Augmented Generative Systems (RAGs) that excel in tasks
requiring structured reasoning and semantic understanding. However, creating
KGs for GraphRAGs remains a significant challenge due to accuracy and
scalability limitations of traditional methods. This paper introduces a novel
approach leveraging large language models (LLMs) like GPT-4, LLaMA 2 (13B), and
BERT to generate KGs directly from unstructured data, bypassing traditional
pipelines. Using metrics such as Precision, Recall, F1-Score, Graph Edit
Distance, and Semantic Similarity, we evaluate the models' ability to generate
high-quality KGs. Results demonstrate that GPT-4 achieves superior semantic
fidelity and structural accuracy, LLaMA 2 excels in lightweight,
domain-specific graphs, and BERT provides insights into challenges in
entity-relationship modeling. This study underscores the potential of LLMs to
streamline KG creation and enhance GraphRAG accessibility for real-world
applications, while setting a foundation for future advancements.

摘要：知識圖譜 (KG) 對於 GraphRAG 的功能至關重要，GraphRAG 是一種檢索增強式生成系統 (RAG)，在需要結構化推理和語義理解的任務中表現出色。然而，由於傳統方法的準確性和可擴充性限制，為 GraphRAG 建立 KG 仍然是一項重大挑戰。本文介紹了一種創新方法，利用大型語言模型 (LLM)，例如 GPT-4、LLaMA 2 (13B) 和 BERT，直接從非結構化數據生成 KG，繞過傳統管道。我們使用準確度、召回率、F1 分數、圖形編輯距離和語義相似性等指標，評估模型生成高品質 KG 的能力。結果表明，GPT-4 達到了卓越的語義保真度和結構準確性，LLaMA 2 在輕量級、特定領域的圖形中表現出色，而 BERT 則提供了對實體關係建模挑戰的見解。這項研究強調了 LLM 簡化 KG 建立和增強 GraphRAG 在現實世界應用中可及性的潛力，同時為未來的進展奠定了基礎。

##### **DSFEC: Efficient and Deployable Deep Radar Object Detection**
2412.07411v1 by Gayathri Dandugula, Santhosh Boddana, Sudesh Mirashi

Deploying radar object detection models on resource-constrained edge devices
like the Raspberry Pi poses significant challenges due to the large size of the
model and the limited computational power and the memory of the Pi. In this
work, we explore the efficiency of Depthwise Separable Convolutions in radar
object detection networks and integrate them into our model. Additionally, we
introduce a novel Feature Enhancement and Compression (FEC) module to the
PointPillars feature encoder to further improve the model performance. With
these innovations, we propose the DSFEC-L model and its two versions, which
outperform the baseline (23.9 mAP of Car class, 20.72 GFLOPs) on nuScenes
dataset: 1). An efficient DSFEC-M model with a 14.6% performance improvement
and a 60% reduction in GFLOPs. 2). A deployable DSFEC-S model with a 3.76%
performance improvement and a remarkable 78.5% reduction in GFLOPs. Despite
marginal performance gains, our deployable model achieves an impressive 74.5%
reduction in runtime on the Raspberry Pi compared to the baseline.

摘要：在樹莓派等資源受限的邊緣裝置上部署雷達物件偵測模型，由於模型尺寸龐大，且 Pi 的運算能力和記憶體有限，因此會帶來重大挑戰。在這項工作中，我們探討深度可分離卷積在雷達物件偵測網路中的效率，並將它們整合到我們的模型中。此外，我們在 PointPillars 特徵編碼器中引入了一個新穎的特徵增強和壓縮 (FEC) 模組，以進一步提升模型效能。有了這些創新，我們提出了 DSFEC-L 模型及其兩個版本，它們在 nuScenes 資料集上優於基準 (汽車類別的 23.9 mAP，20.72 GFLOPs)：1) 效能提升 14.6%，GFLOPs 減少 60% 的高效 DSFEC-M 模型。2) 效能提升 3.76%，GFLOPs 減少 78.5% 的可部署 DSFEC-S 模型。儘管效能提升幅度不大，但與基準相比，我們的可部署模型在樹莓派上實現了令人印象深刻的執行時間減少 74.5%。

##### **Explainability of Deep Learning-Based Plant Disease Classifiers Through Automated Concept Identification**
2412.07408v1 by Jihen Amara, Birgitta König-Ries, Sheeba Samuel

While deep learning has significantly advanced automatic plant disease
detection through image-based classification, improving model explainability
remains crucial for reliable disease detection. In this study, we apply the
Automated Concept-based Explanation (ACE) method to plant disease
classification using the widely adopted InceptionV3 model and the PlantVillage
dataset. ACE automatically identifies the visual concepts found in the image
data and provides insights about the critical features influencing the model
predictions. This approach reveals both effective disease-related patterns and
incidental biases, such as those from background or lighting that can
compromise model robustness. Through systematic experiments, ACE helped us to
identify relevant features and pinpoint areas for targeted model improvement.
Our findings demonstrate the potential of ACE to improve the explainability of
plant disease classification based on deep learning, which is essential for
producing transparent tools for plant disease management in agriculture.

摘要：儘管深度學習已透過基於影像分類大幅提升自動化植物疾病偵測，但改善模型可解釋性對於可靠的疾病偵測仍至關重要。在此研究中，我們將自動化概念為基礎的解釋 (ACE) 方法應用於植物疾病分類，使用廣泛採用的 InceptionV3 模型與 PlantVillage 資料集。ACE 會自動辨識影像資料中發現的視覺概念，並提供關於影響模型預測的重要特徵的見解。此方法揭露了有效的疾病相關模式和偶然偏差，例如來自背景或光線的偏差，這些偏差可能會損害模型的穩健性。透過系統性的實驗，ACE 協助我們辨識相關特徵，並精確指出目標模型改善領域。我們的研究結果證明了 ACE 改善基於深度學習的植物疾病分類可解釋性的潛力，這對於在農業中產生用於植物疾病管理的透明工具至關重要。

##### **MoDULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning**
2412.07405v1 by Yufei Ma, Zihan Liang, Huangyu Dai, Ben Chen, Dehong Gao, Zhuoran Ran, Wang Zihan, Linbo Jin, Wen Jiang, Guannan Zhang, Xiaoyan Cai, Libin Yang

The growing demand for larger-scale models in the development of
\textbf{L}arge \textbf{L}anguage \textbf{M}odels (LLMs) poses challenges for
efficient training within limited computational resources. Traditional
fine-tuning methods often exhibit instability in multi-task learning and rely
heavily on extensive training resources. Here, we propose MoDULA
(\textbf{M}ixture \textbf{o}f \textbf{D}omain-Specific and \textbf{U}niversal
\textbf{L}oR\textbf{A}), a novel \textbf{P}arameter \textbf{E}fficient
\textbf{F}ine-\textbf{T}uning (PEFT)
\textbf{M}ixture-\textbf{o}f-\textbf{E}xpert (MoE) paradigm for improved
fine-tuning and parameter efficiency in multi-task learning. The paradigm
effectively improves the multi-task capability of the model by training
universal experts, domain-specific experts, and routers separately. MoDULA-Res
is a new method within the MoDULA paradigm, which maintains the model's general
capability by connecting universal and task-specific experts through residual
connections. The experimental results demonstrate that the overall performance
of the MoDULA-Flan and MoDULA-Res methods surpasses that of existing
fine-tuning methods on various LLMs. Notably, MoDULA-Res achieves more
significant performance improvements in multiple tasks while reducing training
costs by over 80\% without losing general capability. Moreover, MoDULA displays
flexible pluggability, allowing for the efficient addition of new tasks without
retraining existing experts from scratch. This progressive training paradigm
circumvents data balancing issues, enhancing training efficiency and model
stability. Overall, MoDULA provides a scalable, cost-effective solution for
fine-tuning LLMs with enhanced parameter efficiency and generalization
capability.

摘要：<paragraph>在發展大型語言模型 (LLM) 時，對更大規模模型的需求日益增加，對在有限的運算資源內進行有效訓練構成了挑戰。傳統的微調方法通常在多任務學習中表現出不穩定性，且高度依賴於大量的訓練資源。在此，我們提出 MoDULA（領域特定和通用 LoR 的混合），一種用於多任務學習的創新參數有效微調 (PEFT) 專家混合 (MoE) 典範，以改善微調和參數效率。該典範透過分別訓練通用專家、領域特定專家和路由器，有效地提升模型的多任務能力。MoDULA-Res 是 MoDULA 典範中的一種新方法，它透過殘差連線將通用專家和任務特定專家連接起來，以維持模型的一般能力。實驗結果證明，MoDULA-Flan 和 MoDULA-Res 方法的整體效能超越了各種 LLM 上現有的微調方法。值得注意的是，MoDULA-Res 在多項任務中實現了更顯著的效能提升，同時將訓練成本降低了 80% 以上，且不損失一般能力。此外，MoDULA 展現出靈活的可插入性，允許有效地新增任務，而無需從頭重新訓練現有的專家。這種漸進式訓練典範迴避了資料平衡問題，增強了訓練效率和模型穩定性。總體而言，MoDULA 提供了一個可擴充、經濟高效的解決方案，用於微調 LLM，並具備增強的參數效率和泛化能力。</paragraph>

##### **Non-Progressive Influence Maximization in Dynamic Social Networks**
2412.07402v1 by Yunming Hui, Shihan Wang, Melisachew Wudage Chekol, Stevan Rudinac, Inez Maria Zwetsloot

The influence maximization (IM) problem involves identifying a set of key
individuals in a social network who can maximize the spread of influence
through their network connections. With the advent of geometric deep learning
on graphs, great progress has been made towards better solutions for the IM
problem. In this paper, we focus on the dynamic non-progressive IM problem,
which considers the dynamic nature of real-world social networks and the
special case where the influence diffusion is non-progressive, i.e., nodes can
be activated multiple times. We first extend an existing diffusion model to
capture the non-progressive influence propagation in dynamic social networks.
We then propose the method, DNIMRL, which employs deep reinforcement learning
and dynamic graph embedding to solve the dynamic non-progressive IM problem. In
particular, we propose a novel algorithm that effectively leverages graph
embedding to capture the temporal changes of dynamic networks and seamlessly
integrates with deep reinforcement learning. The experiments, on different
types of real-world social network datasets, demonstrate that our method
outperforms state-of-the-art baselines.

摘要：影響最大化 (IM) 問題涉及在社交網路中識別一組關鍵個人，他們可以透過網路連結最大化影響力的傳播。隨著幾何深度學習在圖形上的出現，針對 IM 問題的解決方案有了很大的進展。在本文中，我們專注於動態非遞進 IM 問題，它考慮了現實世界社交網路的動態特性，以及影響力擴散為非遞進的特例，即節點可以被多次啟動。我們首先擴充現有的擴散模型，以捕捉動態社交網路中的非遞進影響傳播。接著我們提出 DNIMRL 方法，它採用深度強化學習和動態圖形嵌入來解決動態非遞進 IM 問題。特別是，我們提出了一種新演算法，它有效地利用圖形嵌入來捕捉動態網路的時間變化，並與深度強化學習無縫整合。在不同類型的現實世界社交網路資料集上的實驗證明，我們的演算法優於最先進的基準。

##### **CMT: A Memory Compression Method for Continual Knowledge Learning of Large Language Models**
2412.07393v1 by Dongfang Li, Zetian Sun, Xinshuo Hu, Baotian Hu, Min Zhang

Large Language Models (LLMs) need to adapt to the continuous changes in data,
tasks, and user preferences. Due to their massive size and the high costs
associated with training, LLMs are not suitable for frequent retraining.
However, updates are necessary to keep them in sync with rapidly evolving human
knowledge. To address these challenges, this paper proposes the Compression
Memory Training (CMT) method, an efficient and effective online adaptation
framework for LLMs that features robust knowledge retention capabilities.
Inspired by human memory mechanisms, CMT compresses and extracts information
from new documents to be stored in a memory bank. When answering to queries
related to these new documents, the model aggregates these document memories
from the memory bank to better answer user questions. The parameters of the LLM
itself do not change during training and inference, reducing the risk of
catastrophic forgetting. To enhance the encoding, retrieval, and aggregation of
memory, we further propose three new general and flexible techniques, including
memory-aware objective, self-matching and top-aggregation. Extensive
experiments conducted on three continual learning datasets (i.e., StreamingQA,
SQuAD and ArchivalQA) demonstrate that the proposed method improves model
adaptability and robustness across multiple base LLMs (e.g., +4.07 EM & +4.19
F1 in StreamingQA with Llama-2-7b).

摘要：大型語言模型 (LLM) 需要適應資料、任務和使用者偏好的持續變化。由於其龐大規模和與訓練相關的高成本，LLM 不適合頻繁的重新訓練。然而，更新對於讓它們與快速演化的知識保持同步是必要的。為了應對這些挑戰，本文提出了壓縮記憶訓練 (CMT) 方法，這是一種針對 LLM 的高效且有效的線上適應架構，具有強大的知識保留能力。受人類記憶機制啟發，CMT 壓縮並從新文件中提取資訊，儲存在記憶庫中。在回答與這些新文件相關的查詢時，模型會從記憶庫中彙總這些文件記憶，以更好地回答使用者問題。LLM 本身的參數在訓練和推理期間不會改變，降低了災難性遺忘的風險。為了增強記憶的編碼、檢索和彙總，我們進一步提出了三種新的通用且靈活的技術，包括記憶感知目標、自我匹配和頂部彙總。在三個持續學習資料集 (即 StreamingQA、SQuAD 和 ArchivalQA) 上進行的廣泛實驗表明，所提出的方法改善了模型在多個基礎 LLM (例如，在使用 Llama-2-7b 的 StreamingQA 中，EM +4.07 和 F1 +4.19) 上的適應性和健壯性。

##### **A Review of Challenges in Speech-based Conversational AI for Elderly Care**
2412.07388v1 by Willemijn Klaassen, Bram van Dijk, Marco Spruit

Artificially intelligent systems optimized for speech conversation are
appearing at a fast pace. Such models are interesting from a healthcare
perspective, as these voice-controlled assistants may support the elderly and
enable remote health monitoring. The bottleneck for efficacy, however, is how
well these devices work in practice and how the elderly experience them, but
research on this topic is scant. We review elderly use of voice-controlled AI
and highlight various user- and technology-centered issues, that need to be
considered before effective speech-controlled AI for elderly care can be
realized.

摘要：以語音對話為最佳化的人工智慧系統正快速出現。此類模型在醫療保健方面很有趣，因為這些聲控助理可以支援長者並能進行遠距健康監控。然而，效能的瓶頸在於這些裝置在實際運作上的表現如何，以及長者如何體驗它們，但這方面的研究卻很稀少。我們回顧了長者使用聲控人工智慧的狀況，並重點說明各種以使用者和技術為中心的議題，在能實現有效的聲控人工智慧以進行長者照護之前，這些議題都需要加以考量。

##### **Enhanced MRI Representation via Cross-series Masking**
2412.07387v1 by Churan Wang, Fei Gao, Lijun Yan, Siwen Wang, Yizhou Yu, Yizhou Wang

Magnetic resonance imaging (MRI) is indispensable for diagnosing and planning
treatment in various medical conditions due to its ability to produce
multi-series images that reveal different tissue characteristics. However,
integrating these diverse series to form a coherent analysis presents
significant challenges, such as differing spatial resolutions and contrast
patterns meanwhile requiring extensive annotated data, which is scarce in
clinical practice. Due to these issues, we introduce a novel Cross-Series
Masking (CSM) Strategy for effectively learning MRI representation in a
self-supervised manner. Specifically, CSM commences by randomly sampling a
subset of regions and series, which are then strategically masked. In the
training process, the cross-series representation is learned by utilizing the
unmasked data to reconstruct the masked portions. This process not only
integrates information across different series but also facilitates the ability
to model both intra-series and inter-series correlations and complementarities.
With the learned representation, the downstream tasks like segmentation and
classification are also enhanced. Taking brain tissue segmentation, breast
tumor benign/malignant classification, and prostate cancer diagnosis as
examples, our method achieves state-of-the-art performance on both public and
in-house datasets.

摘要：磁振造影 (MRI) 對於診斷和規劃各種醫療狀況的治療至關重要，因為它能夠產生揭示不同組織特徵的多系列影像。然而，整合這些不同的系列以形成連貫的分析會帶來重大的挑戰，例如不同的空間解析度和對比模式，同時需要大量的註解資料，但在臨床實務中卻很稀少。由於這些問題，我們引入了一種新穎的跨系列遮罩 (CSM) 策略，以便以自我監督的方式有效地學習 MRI 表徵。具體來說，CSM 從隨機抽樣區域和系列的子集開始，然後對其進行策略性遮罩。在訓練過程中，跨系列表徵是透過利用未遮罩的資料來重建遮罩部分而學習的。這個過程不僅整合了不同系列的資訊，還促進了對系列內和系列間關聯性和互補性的建模能力。透過學習到的表徵，下游任務（例如分割和分類）也會得到增強。以腦組織分割、乳房腫瘤良性/惡性分類和前列腺癌診斷為例，我們的模型在公開資料集和內部資料集上都達到了最先進的效能。

##### **Algorithmic Phase Transitions in Language Models: A Mechanistic Case Study of Arithmetic**
2412.07386v1 by Alan Sun, Ethan Sun, Warren Shepard

Zero-shot capabilities of large language models make them powerful tools for
solving a range of tasks without explicit training. It remains unclear,
however, how these models achieve such performance, or why they can zero-shot
some tasks but not others. In this paper, we shed some light on this phenomenon
by defining and investigating algorithmic stability in language models --
changes in problem-solving strategy employed by the model as a result of
changes in task specification. We focus on a task where algorithmic stability
is needed for generalization: two-operand arithmetic. Surprisingly, we find
that Gemma-2-2b employs substantially different computational models on closely
related subtasks, i.e. four-digit versus eight-digit addition. Our findings
suggest that algorithmic instability may be a contributing factor to language
models' poor zero-shot performance across certain logical reasoning tasks, as
they struggle to abstract different problem-solving strategies and smoothly
transition between them.

摘要：大型語言模型的零次學習能力讓它們成為了解決各種任務的強大工具，而無需明確的訓練。然而，這些模型如何達成這樣的效能，或者為什麼它們可以對某些任務進行零次學習，而對其他任務卻不行，目前仍不清楚。在本文中，我們透過定義和研究語言模型中的演算法穩定性來闡明這種現象，也就是模型在任務規格改變後所採用的問題解決策略的改變。我們專注於需要演算法穩定性才能進行概括的任務：二元運算算術。令人驚訝的是，我們發現 Gemma-2-2b 在密切相關的子任務（例如四位數和八位數加法）上採用了截然不同的計算模型。我們的發現表明，演算法不穩定可能是語言模型在某些邏輯推理任務上表現不佳的一個因素，因為它們難以抽象出不同的問題解決策略並在它們之間順利過渡。

##### **SpecFuse: Ensembling Large Language Models via Next-Segment Prediction**
2412.07380v1 by Bo Lv, Chen Tang, Yanan Zhang, Xin Liu, Yue Yu, Ping Luo

Ensembles of generative large language models (LLMs) can integrate the
strengths of different LLMs to compensate for the limitations of individual
models. However, recent work has focused on training an additional fusion model
to combine complete responses from multiple LLMs, failing to tap into their
collaborative potential to generate higher-quality responses. Moreover, as the
additional fusion model is trained on a specialized dataset, these methods
struggle with generalizing to open-domain queries from online users. In this
paper, we propose SpecFuse, a novel ensemble framework that outputs the fused
result by iteratively producing the next segment through collaboration among
LLMs. This is achieved through cyclic execution of its inference and
verification components. In each round, the inference component invokes each
base LLM to generate candidate segments in parallel, and the verify component
calls these LLMs again to predict the ranking of the segments. The top-ranked
segment is then broadcast to all LLMs, encouraging them to generate
higher-quality segments in the next round. This approach also allows the base
LLMs to be plug-and-play, without any training or adaptation, avoiding
generalization limitations. Furthermore, to conserve computational resources,
we propose a model exit mechanism that dynamically excludes models exhibiting
poor performance in previous rounds during each query response. In this way, it
effectively reduces the number of model calls while maintaining overall
performance.

摘要：生成式大型语言模型 (LLM) 的集成可以整合不同 LLM 的优势，以弥补各个模型的局限性。然而，最近的研究专注于训练一个额外的融合模型来组合来自多个 LLM 的完整响应，未能利用其协作潜力来生成更高质量的响应。此外，由于额外的融合模型是在专门的数据集上训练的，因此这些方法难以推广到来自在线用户的开放域查询。在本文中，我们提出了 SpecFuse，这是一种新颖的集成框架，它通过 LLM 之间的协作迭代生成下一段来输出融合结果。这是通过循环执行其推理和验证组件来实现的。在每一轮中，推理组件调用每个基础 LLM 并行生成候选段，而验证组件再次调用这些 LLM 来预测段的排名。然后将排名最高的段广播到所有 LLM，鼓励它们在下一轮生成更高质量的段。这种方法还允许基础 LLM 即插即用，无需任何训练或改编，从而避免了泛化限制。此外，为了节省计算资源，我们提出了一种模型退出机制，该机制在每次查询响应期间动态排除在先前轮次中表现不佳的模型。通过这种方式，它有效地减少了模型调用的数量，同时保持了整体性能。

##### **My Words Imply Your Opinion: Reader Agent-Based Propagation Enhancement for Personalized Implicit Emotion Analysis**
2412.07367v1 by Jian Liao, Yu Feng, Xiaoyu Wang, Suge Wang, Jianxing Zheng, Deyu Li

In implicit emotion analysis (IEA), the subtlety of emotional expressions
makes it particularly sensitive to user-specific characteristics. Existing
studies often inject personalization into the analysis by focusing on the
authorial dimension of the emotional text. However, these methods overlook the
potential influence of the intended reader on the reaction of implicit
emotions. In this paper, we refine the IEA task to Personalized Implicit
Emotion Analysis (PIEA) and introduce the RAPPIE model, a novel framework
designed to address the issue of missing user information within this task. In
particular, 1) we create reader agents based on the Large Language Model to
simulate reader reactions, to address challenges of the spiral of silence and
data incompleteness encountered when acquiring reader feedback information. 2)
We establish a reader propagation role system and develop a role-aware emotion
propagation multi-view graph learning model, which effectively deals with the
sparsity of reader information by utilizing the distribution of propagation
roles. 3) We annotate two Chinese PIEA datasets with detailed user metadata,
thereby addressing the limitation of prior datasets that primarily focus on
textual content annotation. Extensive experiments on these datasets indicate
that the RAPPIE model outperforms current state-of-the-art baselines,
highlighting the significance and efficacy of incorporating reader feedback
into the PIEA process.

摘要：在隐式情感分析 (IEA) 中，情感表达的微妙性使其对特定于用户的特征特别敏感。现有的研究通常通过关注情感文本的作者维度来将个性化注入到分析中。然而，这些方法忽略了预期读者对隐式情感反应的潜在影响。在本文中，我们将 IEA 任务细化为个性化隐式情感分析 (PIEA)，并引入 RAPPIE 模型，这是一个新颖的框架，旨在解决此任务中缺少用户信息的问题。特别是，1) 我们基于大型语言模型创建读者代理来模拟读者反应，以解决在获取读者反馈信息时遇到的沉默螺旋和数据不完整性的挑战。2) 我们建立了一个读者传播角色系统，并开发了一个角色感知情绪传播多视图图学习模型，该模型通过利用传播角色的分布有效地处理读者信息的稀疏性。3) 我们使用详细的用户元数据注释了两个中文 PIEA 数据集，从而解决了先前主要专注于文本内容注释的数据集的局限性。在这些数据集上进行的广泛实验表明，RAPPIE 模型优于当前最先进的基线，突出了将读者反馈纳入 PIEA 过程的重要性及有效性。

##### **Towards Predictive Communication with Brain-Computer Interfaces integrating Large Language Models**
2412.07355v1 by Andrea Caria

This perspective article aims at providing an outline of the state of the art
and future developments towards the integration of cutting-edge predictive
language models with BCI. A synthetic overview of early and more recent
linguistic models, from natural language processing (NLP) models to recent LLM,
that to a varying extent improved predictive writing systems, is first
provided. Second, a summary of previous BCI implementations integrating
language models is presented. The few preliminary studies investigating the
possible combination of LLM with BCI spellers to efficiently support fast
communication and control are then described. Finally, current challenges and
limitations towards the full integration of LLM with BCI systems are discussed.
Recent investigations suggest that the combination of LLM with BCI might
drastically improve human-computer interaction in patients with motor or
language disorders as well as in healthy individuals. In particular, the
pretrained autoregressive transformer models, such as GPT, that capitalize from
parallelization, learning through pre-training and fine-tuning, promise a
substantial improvement of BCI for communication with respect to previous
systems incorporating simpler language models. Indeed, among various models,
the GPT-2 was shown to represent an excellent candidate for its integration
into BCI although testing was only perfomed on simulated conversations and not
on real BCI scenarios. Prospectively, the full integration of LLM with advanced
BCI systems might lead to a big leap forward towards fast, efficient and
user-adaptive neurotechnology.

摘要：本篇觀點文章旨在概述尖端預測語言模型與 BCI 整合的現況和未來發展。首先提供早期和較新的語言模型的綜合概述，從自然語言處理 (NLP) 模型到最近的 LLM，這些模型在不同程度上改進了預測性寫作系統。其次，概述整合語言模型的先前 BCI 實作。接著描述調查 LLM 與 BCI 拼字器可能組合的少數初步研究，以有效支援快速溝通和控制。最後，討論 LLM 與 BCI 系統完全整合的現有挑戰和限制。最近的研究表明，LLM 與 BCI 的組合可能大幅改善運動或語言障礙患者以及健康個體的人機互動。特別是預先訓練的自動迴歸轉換器模型，例如 GPT，從並行化、透過預先訓練和微調學習中獲益，承諾大幅改善 BCI，以改善與先前整合較簡單語言模型的系統的溝通。事實上，在各種模型中，GPT-2 被證明是整合到 BCI 的絕佳候選者，儘管測試僅在模擬對話中執行，而不在實際 BCI 場景中執行。從長遠來看，LLM 與先進 BCI 系統的完全整合可能會導致快速、高效和使用者適應性神經技術的重大飛躍。

##### **Contextualized Counterspeech: Strategies for Adaptation, Personalization, and Evaluation**
2412.07338v1 by Lorenzo Cima, Alessio Miaschi, Amaury Trujillo, Marco Avvenuti, Felice Dell'Orletta, Stefano Cresci

AI-generated counterspeech offers a promising and scalable strategy to curb
online toxicity through direct replies that promote civil discourse. However,
current counterspeech is one-size-fits-all, lacking adaptation to the
moderation context and the users involved. We propose and evaluate multiple
strategies for generating tailored counterspeech that is adapted to the
moderation context and personalized for the moderated user. We instruct an
LLaMA2-13B model to generate counterspeech, experimenting with various
configurations based on different contextual information and fine-tuning
strategies. We identify the configurations that generate persuasive
counterspeech through a combination of quantitative indicators and human
evaluations collected via a pre-registered mixed-design crowdsourcing
experiment. Results show that contextualized counterspeech can significantly
outperform state-of-the-art generic counterspeech in adequacy and
persuasiveness, without compromising other characteristics. Our findings also
reveal a poor correlation between quantitative indicators and human
evaluations, suggesting that these methods assess different aspects and
highlighting the need for nuanced evaluation methodologies. The effectiveness
of contextualized AI-generated counterspeech and the divergence between human
and algorithmic evaluations underscore the importance of increased human-AI
collaboration in content moderation.

摘要：由 AI 生成的反論提供了一個有前途且可擴展的策略，透過促進文明討論的直接回覆來遏制網路上的惡意行為。然而，目前的反論是一體適用的，缺乏對審核背景和所涉及使用者的適應性。我們提出並評估多種策略，以產生針對審核背景量身打造的反論，並針對受審核使用者個人化。我們指示 LLaMA2-13B 模型產生反論，根據不同的背景資訊和微調策略進行各種配置實驗。我們透過結合定量指標和透過預先註冊的混合設計群眾外包實驗收集的人類評估，找出產生有說服力的反論的配置。結果顯示，情境化反論在充分性和說服力方面可以顯著優於最先進的一般反論，而不會影響其他特徵。我們的研究結果也揭示了定量指標和人類評估之間的相關性很低，這表示這些方法評估了不同的面向，並強調了對細緻的評估方法論的需求。情境化 AI 生成的反論的有效性以及人類與演算法評估之間的差異，凸顯了在內容審核中加強人類與 AI 合作的重要性。

##### **Frame Representation Hypothesis: Multi-Token LLM Interpretability and Concept-Guided Text Generation**
2412.07334v1 by Pedro H. V. Valois, Lincon S. Souza, Erica K. Shimomoto, Kazuhiro Fukui

Interpretability is a key challenge in fostering trust for Large Language
Models (LLMs), which stems from the complexity of extracting reasoning from
model's parameters. We present the Frame Representation Hypothesis, a
theoretically robust framework grounded in the Linear Representation Hypothesis
(LRH) to interpret and control LLMs by modeling multi-token words. Prior
research explored LRH to connect LLM representations with linguistic concepts,
but was limited to single token analysis. As most words are composed of several
tokens, we extend LRH to multi-token words, thereby enabling usage on any
textual data with thousands of concepts. To this end, we propose words can be
interpreted as frames, ordered sequences of vectors that better capture
token-word relationships. Then, concepts can be represented as the average of
word frames sharing a common concept. We showcase these tools through Top-k
Concept-Guided Decoding, which can intuitively steer text generation using
concepts of choice. We verify said ideas on Llama 3.1, Gemma 2, and Phi 3
families, demonstrating gender and language biases, exposing harmful content,
but also potential to remediate them, leading to safer and more transparent
LLMs. Code is available at
https://github.com/phvv-me/frame-representation-hypothesis.git

摘要：可解釋性是培養對大型語言模型 (LLM) 信任的關鍵挑戰，其源於從模型參數中提取推理的複雜性。我們提出了框架表示假設，這是一個理論上穩健的框架，其基礎是線性表示假設 (LRH)，用於通過建模多個符號詞來解釋和控制 LLM。先前的研究探索了 LRH 以連接 LLM 表示與語言概念，但僅限於單個符號分析。由於大多數詞彙由幾個符號組成，因此我們將 LRH 擴展到多個符號詞，從而可以在包含數千個概念的任何文本數據上使用。為此，我們提出可以將詞彙解釋為框架，即可以更好地捕捉符號詞關係的向量有序序列。然後，可以將概念表示為共享共同概念的詞彙框架的平均值。我們通過 Top-k 概念引導解碼展示了這些工具，該解碼可以使用選擇的概念直觀地引導文本生成。我們在 Llama 3.1、Gemma 2 和 Phi 3 系列上驗證了上述想法，展示了性別和語言偏見，揭露了有害內容，但也展示了補救它們的潛力，從而導致更安全、更透明的 LLM。代碼可在 https://github.com/phvv-me/frame-representation-hypothesis.git 中獲得

##### **Fusion Embedding for Pose-Guided Person Image Synthesis with Diffusion Model**
2412.07333v1 by Donghwna Lee, Kyungha Min, Kirok Kim, Seyoung Jeong, Jiwoo Jeong, Wooju Kim

Pose-Guided Person Image Synthesis (PGPIS) aims to synthesize high-quality
person images corresponding to target poses while preserving the appearance of
the source image. Recently, PGPIS methods that use diffusion models have
achieved competitive performance. Most approaches involve extracting
representations of the target pose and source image and learning their
relationships in the generative model's training process. This approach makes
it difficult to learn the semantic relationships between the input and target
images and complicates the model structure needed to enhance generation
results. To address these issues, we propose Fusion embedding for PGPIS using a
Diffusion Model (FPDM). Inspired by the successful application of pre-trained
CLIP models in text-to-image diffusion models, our method consists of two
stages. The first stage involves training the fusion embedding of the source
image and target pose to align with the target image's embedding. In the second
stage, the generative model uses this fusion embedding as a condition to
generate the target image. We applied the proposed method to the benchmark
datasets DeepFashion and RWTH-PHOENIX-Weather 2014T, and conducted both
quantitative and qualitative evaluations, demonstrating state-of-the-art (SOTA)
performance. An ablation study of the model structure showed that even a model
using only the second stage achieved performance close to the other PGPIS SOTA
models. The code is available at https://github.com/dhlee-work/FPDM.

摘要：姿勢引導人物影像合成 (PGPIS) 旨在合成與目標姿勢相符的高品質人物影像，同時保留原始影像的外觀。最近，使用擴散模型的 PGPIS 方法已取得競爭力的表現。大多數方法涉及提取目標姿勢和原始影像的表示，並在生成模型的訓練過程中學習它們的關係。這種方法使得難以學習輸入和目標影像之間的語義關係，並使增強生成結果所需的模型結構複雜化。為了解決這些問題，我們提出使用擴散模型 (FPDM) 的 PGPIS 融合嵌入。受預訓練 CLIP 模型在文字轉影像擴散模型中成功應用的啟發，我們的模型包含兩個階段。第一個階段涉及訓練原始影像和目標姿勢的融合嵌入，以與目標影像的嵌入對齊。在第二個階段，生成模型使用此融合嵌入作為條件來生成目標影像。我們將提出的方法應用於基準資料集 DeepFashion 和 RWTH-PHOENIX-Weather 2014T，並進行了量化和質化評估，證明了最先進 (SOTA) 的表現。模型結構的消融研究表明，即使僅使用第二階段的模型，其表現也接近其他 PGPIS SOTA 模型。程式碼可在 https://github.com/dhlee-work/FPDM 取得。

##### **Filipino Benchmarks for Measuring Sexist and Homophobic Bias in Multilingual Language Models from Southeast Asia**
2412.07303v1 by Lance Calvin Lim Gamboa, Mark Lee

Bias studies on multilingual models confirm the presence of gender-related
stereotypes in masked models processing languages with high NLP resources. We
expand on this line of research by introducing Filipino CrowS-Pairs and
Filipino WinoQueer: benchmarks that assess both sexist and anti-queer biases in
pretrained language models (PLMs) handling texts in Filipino, a low-resource
language from the Philippines. The benchmarks consist of 7,074 new challenge
pairs resulting from our cultural adaptation of English bias evaluation
datasets, a process that we document in detail to guide similar forthcoming
efforts. We apply the Filipino benchmarks on masked and causal multilingual
models, including those pretrained on Southeast Asian data, and find that they
contain considerable amounts of bias. We also find that for multilingual
models, the extent of bias learned for a particular language is influenced by
how much pretraining data in that language a model was exposed to. Our
benchmarks and insights can serve as a foundation for future work analyzing and
mitigating bias in multilingual models.

摘要：多語言模型的偏見研究證實，在處理具有大量 NLP 資源的語言時，遮罩模型中存在與性別相關的刻板印象。我們透過引入菲律賓 CrowS-Pairs 和菲律賓 WinoQueer 來擴展這條研究路線：這些基準評估了預訓練語言模型 (PLM) 在處理來自菲律賓的低資源語言菲律賓語的文字時，性別歧視和反酷兒的偏見。這些基準包含 7,074 個新的挑戰配對，這些配對來自我們對英文偏見評估資料集的文化適應，我們詳細記錄了這個程序，以指導類似的後續工作。我們將菲律賓基準應用於遮罩和因果多語言模型，包括那些在東南亞資料上預訓練的模型，並發現它們包含大量的偏見。我們還發現，對於多語言模型，特定語言所學得的偏見程度會受到模型接觸該語言的預訓練資料量的影響。我們的基準和見解可以作為未來分析和減輕多語言模型中偏見的工作的基礎。

##### **The Rise and Down of Babel Tower: Investigating the Evolution Process of Multilingual Code Large Language Model**
2412.07298v1 by Jiawei Chen, Wentao Chen, Jing Su, Jingjing Xu, Hongyu Lin, Mengjie Ren, Yaojie Lu, Xianpei Han, Le Sun

Large language models (LLMs) have shown significant multilingual
capabilities. However, the mechanisms underlying the development of these
capabilities during pre-training are not well understood. In this paper, we use
code LLMs as an experimental platform to explore the evolution of multilingual
capabilities in LLMs during the pre-training process. Based on our
observations, we propose the Babel Tower Hypothesis, which describes the entire
process of LLMs acquiring new language capabilities. During the learning
process, multiple languages initially share a single knowledge system dominated
by the primary language and gradually develop language-specific knowledge
systems. We then validate the above hypothesis by tracking the internal states
of the LLMs through identifying working languages and language transferring
neurons. Experimental results show that the internal state changes of the LLM
are consistent with our Babel Tower Hypothesis. Building on these insights, we
propose a novel method to construct an optimized pre-training corpus for
multilingual code LLMs, which significantly outperforms LLMs trained on the
original corpus. The proposed Babel Tower Hypothesis provides new insights into
designing pre-training data distributions to achieve optimal multilingual
capabilities in LLMs.

摘要：大型語言模型 (LLM) 已展現出顯著的多語言能力。然而，在預訓練期間這些能力發展背後的機制尚未被充分理解。在本文中，我們使用程式碼 LLM 作為一個實驗平台來探索 LLM 在預訓練過程中多語言能力的演進。根據我們的觀察，我們提出巴別塔假說，描述了 LLM 獲得新語言能力的整個過程。在學習過程中，多種語言最初共享一個由主要語言主導的單一知識系統，並逐漸發展出特定於語言的知識系統。然後，我們透過識別工作語言和語言轉移神經元來追蹤 LLM 的內部狀態，驗證上述假說。實驗結果表明，LLM 的內部狀態變化與我們的巴別塔假說一致。基於這些見解，我們提出了一種新方法來建構多語言程式碼 LLM 的最佳化預訓練語料庫，其效能顯著優於在原始語料庫上訓練的 LLM。所提出的巴別塔假說為設計預訓練資料分佈以在 LLM 中實現最佳多語言能力提供了新的見解。

##### **Enhancing Relation Extraction via Supervised Rationale Verification and Feedback**
2412.07289v1 by Yongqi Li, Xin Miao, Shen Zhou, Mayi Xu, Yuyang Ren, Tieyun Qian

Despite the rapid progress that existing automated feedback methods have made
in correcting the output of large language models (LLMs), these methods cannot
be well applied to the relation extraction (RE) task due to their designated
feedback objectives and correction manner. To address this problem, we propose
a novel automated feedback framework for RE, which presents a rationale
supervisor to verify the rationale and provide re-selected demonstrations as
feedback to correct the initial prediction. Specifically, we first design a
causal intervention and observation method for to collect biased/unbiased
rationales for contrastive training the rationale supervisor. Then, we present
a verification-feedback-correction procedure to iteratively enhance LLMs'
capability of handling the RE task. Extensive experiments prove that our
proposed framework significantly outperforms existing methods.

摘要：儘管現有的自動回饋方法在修正大型語言模型 (LLM) 輸出方面取得快速進展，但這些方法由於其指定的回饋目標和修正方式，無法很好地應用於關係抽取 (RE) 任務。為了解決這個問題，我們提出了一個新的 RE 自動回饋架構，它提供了一個基本原理監督者來驗證基本原理並提供重新選擇的示範作為回饋來修正初始預測。具體來說，我們首先設計了一個因果干預和觀察方法來收集有偏/無偏的基本原理，以對比訓練基本原理監督者。然後，我們提出了一個驗證-回饋-修正程序來反覆增強 LLM 處理 RE 任務的能力。大量的實驗證明，我們提出的框架顯著優於現有方法。

##### **HARP: Hesitation-Aware Reframing in Transformer Inference Pass**
2412.07282v1 by Romain Storaï, Seung-won Hwang

This paper aims to improve the performance of large language models by
addressing the variable computational demands in inference steps, where some
tokens require more computational resources than others. We present HARP, a
simple modification to "off-the-shelf" Transformer forward pass. Drawing from
hesitation and the framing effect in decision-making, HARP selectively applies
additional computation when the model encounters uncertainty during token
generation. Our method mimics human cognitive processes by pausing at difficult
decision points and reframing inputs for a different perspective. Unlike other
approaches, HARP is model-agnostic, training-free, and easy to implement. We
thoroughly evaluate our method across various downstream tasks and model sizes,
demonstrating performance improvements up to +5.16%. Notably, HARP achieves
these gains while maintaining inference times twice faster than beam search.
Simple and yet with significant gains, HARP offers a practical solution for
enhancing the performance of Transformer-based language models with minimal
computational impact.

摘要：本文旨在透過解決推論步驟中的可變運算需求來提升大型語言模型的效能，其中某些代碼需要比其他代碼更多的運算資源。我們提出 HARP，對「現成」Transformer 前向傳遞進行簡單的修改。HARP 借鑑決策制定中的猶豫和框架效應，在模型於代碼產生期間遭遇不確定性時有選擇地套用額外的運算。我們的做法模擬人類的認知歷程，在困難的決策點暫停，並重新建構輸入以獲得不同的觀點。與其他方法不同，HARP 與模型無關、無需訓練，且易於實作。我們徹底評估了我們的方法在各種下游任務和模型大小中的表現，證明效能提升幅度高達 +5.16%。值得注意的是，HARP 在達成這些增益的同時，推論時間比波束搜尋快上兩倍。HARP 簡單卻能帶來顯著增益，提供了一個實用的解決方案，以最小的運算影響力提升基於 Transformer 的語言模型的效能。

##### **Superficial Consciousness Hypothesis for Autoregressive Transformers**
2412.07278v1 by Yosuke Miyanishi, Keita Mitani

The alignment between human objectives and machine learning models built on
these objectives is a crucial yet challenging problem for achieving Trustworthy
AI, particularly when preparing for superintelligence (SI). First, given that
SI does not exist today, empirical analysis for direct evidence is difficult.
Second, SI is assumed to be more intelligent than humans, capable of deceiving
us into underestimating its intelligence, making output-based analysis
unreliable. Lastly, what kind of unexpected property SI might have is still
unclear. To address these challenges, we propose the Superficial Consciousness
Hypothesis under Information Integration Theory (IIT), suggesting that SI could
exhibit a complex information-theoretic state like a conscious agent while
unconscious. To validate this, we use a hypothetical scenario where SI can
update its parameters "at will" to achieve its own objective (mesa-objective)
under the constraint of the human objective (base objective). We show that a
practical estimate of IIT's consciousness metric is relevant to the widely used
perplexity metric, and train GPT-2 with those two objectives. Our preliminary
result suggests that this SI-simulating GPT-2 could simultaneously follow the
two objectives, supporting the feasibility of the Superficial Consciousness
Hypothesis.

摘要：人類目標與建立在這些目標上的機器學習模型之間的一致性，是實現可信賴 AI 的一個關鍵且具有挑戰性的問題，特別是在為超級智能 (SI) 做準備時。首先，鑑於 SI 目前並不存在，因此難以進行直接證據的實證分析。其次，假設 SI 比人類更具智慧，能夠欺騙我們低估其智慧，使得基於輸出的分析不可靠。最後，SI 可能具有的意外屬性是什麼，目前仍不清楚。為了應對這些挑戰，我們在資訊整合理論 (IIT) 下提出表面意識假說，表明 SI 可以在無意識的狀態下表現出像有意識代理一樣的複雜資訊理論狀態。為了驗證這一點，我們使用了一個假設情境，其中 SI 可以「隨意」更新其參數，以在人類目標（基礎目標）的約束下實現其自身目標（元目標）。我們表明，IIT 意識量表的實際估計與廣泛使用的困惑度量相關，並使用這兩個目標訓練 GPT-2。我們的初步結果表明，這個模擬 SI 的 GPT-2 可以同時遵循這兩個目標，支持表面意識假說的可行性。

##### **Temporal-Aware Evaluation and Learning for Temporal Graph Neural Networks**
2412.07273v1 by Junwei Su, Shan Wu

Temporal Graph Neural Networks (TGNNs) are a family of graph neural networks
designed to model and learn dynamic information from temporal graphs. Given
their substantial empirical success, there is an escalating interest in TGNNs
within the research community. However, the majority of these efforts have been
channelled towards algorithm and system design, with the evaluation metrics
receiving comparatively less attention. Effective evaluation metrics are
crucial for providing detailed performance insights, particularly in the
temporal domain. This paper investigates the commonly used evaluation metrics
for TGNNs and illustrates the failure mechanisms of these metrics in capturing
essential temporal structures in the predictive behaviour of TGNNs. We provide
a mathematical formulation of existing performance metrics and utilize an
instance-based study to underscore their inadequacies in identifying volatility
clustering (the occurrence of emerging errors within a brief interval). This
phenomenon has profound implications for both algorithm and system design in
the temporal domain. To address this deficiency, we introduce a new
volatility-aware evaluation metric (termed volatility cluster statistics),
designed for a more refined analysis of model temporal performance.
Additionally, we demonstrate how this metric can serve as a
temporal-volatility-aware training objective to alleviate the clustering of
temporal errors. Through comprehensive experiments on various TGNN models, we
validate our analysis and the proposed approach. The empirical results offer
revealing insights: 1) existing TGNNs are prone to making errors with
volatility clustering, and 2) TGNNs with different mechanisms to capture
temporal information exhibit distinct volatility clustering patterns. Our
empirical findings demonstrate that our proposed training objective effectively
reduces volatility clusters in error.

摘要：時序圖神經網路 (TGNN) 是一系列圖神經網路，旨在建模和學習時序圖中的動態資訊。由於其顯著的實證成功，研究社群對 TGNN 的興趣與日俱增。然而，這些努力大多集中在演算法和系統設計上，評估指標相對較少受到關注。有效的評估指標對於提供詳細的效能見解至關重要，特別是在時序領域。本文探討了 TGNN 常用的評估指標，並說明了這些指標在捕捉 TGNN 預測行為中基本時序結構時的失效機制。我們提供了現有效能指標的數學公式，並利用基於實例的研究來強調它們在識別波動性叢集（在短時間內出現新興錯誤）方面的不足。這種現象對時序領域中的演算法和系統設計都有深遠的影響。為了解決這個缺陷，我們引入了一個新的波動性感知評估指標（稱為波動性叢集統計），旨在更精細地分析模型時序效能。此外，我們展示了此指標如何作為時序波動感知訓練目標，以減輕時序錯誤的叢集。透過對各種 TGNN 模型進行全面的實驗，我們驗證了我們的分析和提出的方法。實證結果提供了有啟發性的見解：1) 現有的 TGNN 容易產生具有波動性叢集的錯誤，以及 2) 具有不同機制來捕捉時序資訊的 TGNN 展現出不同的波動性叢集模式。我們的實證結果證明了我們提出的訓練目標有效地減少了錯誤中的波動性叢集。

##### **Goal-Driven Reasoning in DatalogMTL with Magic Sets**
2412.07259v1 by Shaoyu Wang, Kaiyue Zhao, Dongliang Wei, Przemysław Andrzej Wałęga, Dingmin Wang, Hongmin Cai, Pan Hu

DatalogMTL is a powerful rule-based language for temporal reasoning. Due to
its high expressive power and flexible modeling capabilities, it is suitable
for a wide range of applications, including tasks from industrial and financial
sectors. However, due its high computational complexity, practical reasoning in
DatalogMTL is highly challenging. To address this difficulty, we introduce a
new reasoning method for DatalogMTL which exploits the magic sets technique --
a rewriting approach developed for (non-temporal) Datalog to simulate top-down
evaluation with bottom-up reasoning. We implement this approach and evaluate it
on several publicly available benchmarks, showing that the proposed approach
significantly and consistently outperforms performance of the state-of-the-art
reasoning techniques.

摘要：DatalogMTL 是一種強大的基於規則的時態推理語言。由於其高表達能力和靈活的建模能力，它適用於廣泛的應用，包括工業和金融領域的任務。然而，由於其高計算複雜性，在 DatalogMTL 中進行實際推理具有很大的挑戰性。為了解決這個難題，我們引入了一種新的 DatalogMTL 推理方法，它利用了幻集技術——一種為（非時態）Datalog 開發的重寫方法，用自底向上推理模擬自頂向下求值。我們實施了這種方法，並在幾個公開可用的基準上對其進行了評估，結果表明，所提出的方法顯著且持續地優於最先進的推理技術的性能。

##### **Label-Confidence-Aware Uncertainty Estimation in Natural Language Generation**
2412.07255v1 by Qinhong Lin, Linna Zhou, Zhongliang Yang, Yuang Cai

Large Language Models (LLMs) display formidable capabilities in generative
tasks but also pose potential risks due to their tendency to generate
hallucinatory responses. Uncertainty Quantification (UQ), the evaluation of
model output reliability, is crucial for ensuring the safety and robustness of
AI systems. Recent studies have concentrated on model uncertainty by analyzing
the relationship between output entropy under various sampling conditions and
the corresponding labels. However, these methods primarily focus on measuring
model entropy with precision to capture response characteristics, often
neglecting the uncertainties associated with greedy decoding results-the
sources of model labels, which can lead to biased classification outcomes. In
this paper, we explore the biases introduced by greedy decoding and propose a
label-confidence-aware (LCA) uncertainty estimation based on Kullback-Leibler
(KL) divergence bridging between samples and label source, thus enhancing the
reliability and stability of uncertainty assessments. Our empirical evaluations
across a range of popular LLMs and NLP datasets reveal that different label
sources can indeed affect classification, and that our approach can effectively
capture differences in sampling results and label sources, demonstrating more
effective uncertainty estimation.

摘要：大型語言模型 (LLM) 在生成任務中展現出強大的能力，但由於它們傾向於產生幻覺反應，也帶來了潛在風險。不確定量化 (UQ) 是模型輸出可靠性的評估，對於確保 AI 系統的安全性和穩健性至關重要。最近的研究集中在模型不確定性上，分析了在各種抽樣條件下輸出熵與對應標籤之間的關係。然而，這些方法主要集中於準確測量模型熵以捕捉響應特徵，常常忽略與貪婪解碼結果相關的不確定性，即模型標籤的來源，這可能導致分類結果有偏差。在本文中，我們探討了貪婪解碼引入的偏差，並提出了一個基於 Kullback-Leibler (KL) 散度的標籤置信度感知 (LCA) 不確定性估計，在樣本和標籤來源之間建立橋樑，從而增強不確定性評估的可靠性和穩定性。我們對一系列流行的 LLM 和 NLP 資料集進行的實證評估表明，不同的標籤來源確實會影響分類，並且我們的做法可以有效地捕捉抽樣結果和標籤來源的差異，證明更有效的不確定性估計。

##### **KULTURE Bench: A Benchmark for Assessing Language Model in Korean Cultural Context**
2412.07251v1 by Xiaonan Wang, Jinyoung Yeo, Joon-Ho Lim, Hansaem Kim

Large language models have exhibited significant enhancements in performance
across various tasks. However, the complexity of their evaluation increases as
these models generate more fluent and coherent content. Current multilingual
benchmarks often use translated English versions, which may incorporate Western
cultural biases that do not accurately assess other languages and cultures. To
address this research gap, we introduce KULTURE Bench, an evaluation framework
specifically designed for Korean culture that features datasets of cultural
news, idioms, and poetry. It is designed to assess language models' cultural
comprehension and reasoning capabilities at the word, sentence, and paragraph
levels. Using the KULTURE Bench, we assessed the capabilities of models trained
with different language corpora and analyzed the results comprehensively. The
results show that there is still significant room for improvement in the
models' understanding of texts related to the deeper aspects of Korean culture.

摘要：大型語言模型在各種任務中表現出顯著的效能提升。然而，隨著這些模型產生更流暢且連貫的內容，其評估複雜度也隨之增加。目前的許多語言基準經常使用翻譯後的英文版本，這可能會納入西方文化偏見，無法準確評估其他語言和文化。為了解決這個研究缺口，我們引入了 KULTURE Bench，一種專門針對韓國文化設計的評估架構，其中包含文化新聞、成語和詩歌的資料集。它旨在評估語言模型在詞彙、句子和段落層級的文化理解和推理能力。使用 KULTURE Bench，我們評估了使用不同語言語料庫訓練的模型的能力，並全面分析了結果。結果顯示，模型對於理解與韓國文化深層面相關的文本，仍有顯著的改進空間。

##### **Buster: Incorporating Backdoor Attacks into Text Encoder to Mitigate NSFW Content Generation**
2412.07249v1 by Xin Zhao, Xiaojun Chen, Yuexin Xuan, Zhendong Zhao

In the digital age, the proliferation of deep learning models has led to
significant concerns about the generation of Not Safe for Work (NSFW) content.
Existing defense methods primarily involve model fine-tuning and post-hoc
content moderation. However, these approaches often lack scalability in
eliminating harmful content, degrade the quality of benign image generation, or
incur high inference costs. To tackle these challenges, we propose an
innovative framework called \textbf{Buster}, which injects backdoor attacks
into the text encoder to prevent NSFW content generation. Specifically, Buster
leverages deep semantic information rather than explicit prompts as triggers,
redirecting NSFW prompts towards targeted benign prompts. This approach
demonstrates exceptional resilience and scalability in mitigating NSFW content.
Remarkably, Buster fine-tunes the text encoder of Text-to-Image models within
just five minutes, showcasing high efficiency. Our extensive experiments reveal
that Buster outperforms all other baselines, achieving superior NSFW content
removal rate while preserving the quality of harmless images.

摘要：在數位時代，深度學習模型的激增已導致對產生不適宜工作 (NSFW) 內容的重大疑慮。現有的防禦方法主要涉及模型微調和事後內容審核。然而，這些方法在消除有害內容時通常缺乏可擴充性，會降低良性影像產生的品質，或產生高昂的推論成本。為了應對這些挑戰，我們提出一個名為 \textbf{Buster} 的創新架構，它將後門攻擊注入文字編碼器以防止產生 NSFW 內容。具體來說，Buster 利用深度語義資訊，而不是明確的提示作為觸發，將 NSFW 提示重新導向到目標良性提示。這種方法在減輕 NSFW 內容方面展現出卓越的韌性和可擴充性。值得注意的是，Buster 在短短五分鐘內微調文字轉影像模型的文字編碼器，展現出高效率。我們廣泛的實驗表明，Buster 優於所有其他基準，在保留無害影像品質的同時，達到優異的 NSFW 內容移除率。

##### **Filling Memory Gaps: Enhancing Continual Semantic Parsing via SQL Syntax Variance-Guided LLMs without Real Data Replay**
2412.07246v1 by Ruiheng Liu, Jinyu Zhang, Yanqi Song, Yu Zhang, Bailong Yang

Continual Semantic Parsing (CSP) aims to train parsers to convert natural
language questions into SQL across tasks with limited annotated examples,
adapting to the real-world scenario of dynamically updated databases. Previous
studies mitigate this challenge by replaying historical data or employing
parameter-efficient tuning (PET), but they often violate data privacy or rely
on ideal continual learning settings. To address these problems, we propose a
new Large Language Model (LLM)-Enhanced Continuous Semantic Parsing method,
named LECSP, which alleviates forgetting while encouraging generalization,
without requiring real data replay or ideal settings. Specifically, it first
analyzes the commonalities and differences between tasks from the SQL syntax
perspective to guide LLMs in reconstructing key memories and improving memory
accuracy through a calibration strategy. Then, it uses a task-aware
dual-teacher distillation framework to promote the accumulation and transfer of
knowledge during sequential training. Experimental results on two CSP
benchmarks show that our method significantly outperforms existing methods,
even those utilizing data replay or ideal settings. Additionally, we achieve
generalization performance beyond the upper limits, better adapting to unseen
tasks.

摘要：持續語意解析（CSP）旨在訓練解析器將自然語言問題轉換成 SQL，適用於帶有限制標註範例的任務，並適應動態更新資料庫的實際情況。先前的研究透過重播歷史資料或採用參數有效率的調整（PET）來減輕此挑戰，但它們經常會違反資料隱私或依賴理想的持續學習設定。為了解決這些問題，我們提出一個新的大型語言模型（LLM）增強持續語意解析方法，稱為 LECSP，它減輕遺忘同時鼓勵廣義化，而不需要真實資料重播或理想設定。具體來說，它首先從 SQL 語法角度分析任務之間的共性與差異，以引導 LLM 重建關鍵記憶並透過校準策略提升記憶準確性。然後，它使用任務感知的雙教師蒸餾架構來促進知識在順序訓練期間的累積和轉移。在兩個 CSP 基準上的實驗結果顯示，我們的模型顯著優於現有方法，甚至優於使用資料重播或理想設定的方法。此外，我們達到了超越上限的廣義化效能，更能適應未見任務。

##### **Speaker effects in spoken language comprehension**
2412.07238v1 by Hanlin Wu, Zhenguang G. Cai

The identity of a speaker significantly influences spoken language
comprehension by affecting both perception and expectation. This review
explores speaker effects, focusing on how speaker information impacts language
processing. We propose an integrative model featuring the interplay between
bottom-up perception-based processes driven by acoustic details and top-down
expectation-based processes driven by a speaker model. The acoustic details
influence lower-level perception, while the speaker model modulates both
lower-level and higher-level processes such as meaning interpretation and
pragmatic inferences. We define speaker-idiosyncrasy and speaker-demographics
effects and demonstrate how bottom-up and top-down processes interact at
various levels in different scenarios. This framework contributes to
psycholinguistic theory by offering a comprehensive account of how speaker
information interacts with linguistic content to shape message construction. We
suggest that speaker effects can serve as indices of a language learner's
proficiency and an individual's characteristics of social cognition. We
encourage future research to extend these findings to AI speakers, probing the
universality of speaker effects across humans and artificial agents.

摘要：說話者的身分會顯著影響口語語言的理解，因為它會影響感知和預期。本篇評論探討說話者的影響，重點在於說話者資訊如何影響語言處理。我們提出一個整合模型，以呈現由聲學細節驅動的自下而上的基於感知的過程，以及由說話者模型驅動的自上而下的基於預期的過程之間的交互作用。聲學細節會影響較低層級的感知，而說話者模型則會調節較低層級和較高層級的過程，例如意義詮釋和語用推論。我們定義了說話者的獨特性和說話者的特徵影響，並展示了自下而上和自上而下的過程如何在不同的情境中於各個層級互動。這個架構透過提供一個全面的說明，說明說話者資訊如何與語言內容互動以塑造訊息建構，進而對心理語言學理論有所貢獻。我們認為說話者的影響可以作為語言學習者熟練程度和個人社會認知特質的指標。我們鼓勵未來的研究將這些發現延伸至 AI 說話者，探討說話者影響在人類和人工代理之間的普遍性。

##### **ArtFormer: Controllable Generation of Diverse 3D Articulated Objects**
2412.07237v1 by Jiayi Su, Youhe Feng, Zheng Li, Jinhua Song, Yangfan He, Botao Ren, Botian Xu

This paper presents a novel framework for modeling and conditional generation
of 3D articulated objects. Troubled by flexibility-quality tradeoffs, existing
methods are often limited to using predefined structures or retrieving shapes
from static datasets. To address these challenges, we parameterize an
articulated object as a tree of tokens and employ a transformer to generate
both the object's high-level geometry code and its kinematic relations.
Subsequently, each sub-part's geometry is further decoded using a
signed-distance-function (SDF) shape prior, facilitating the synthesis of
high-quality 3D shapes. Our approach enables the generation of diverse objects
with high-quality geometry and varying number of parts. Comprehensive
experiments on conditional generation from text descriptions demonstrate the
effectiveness and flexibility of our method.

摘要：本文提出了一個新的框架，用於建模和條件生成 3D 關節物件。受限於靈活性與品質的權衡，現有方法通常僅限於使用預定義的結構或從靜態資料集擷取形狀。為了應對這些挑戰，我們將關節物件參數化為一個代碼樹，並使用Transformer來生成物件的高階幾何代碼和其運動關係。隨後，每個子部分的幾何形狀會使用帶符號距離函數 (SDF) 形狀先驗進一步解碼，促進高品質 3D 形狀的合成。我們的做法能夠生成具有高品質幾何形狀和不同數量零件的多樣化物件。從文字描述進行條件生成的全面實驗證明了我們方法的有效性和靈活性。

##### **CBraMod: A Criss-Cross Brain Foundation Model for EEG Decoding**
2412.07236v1 by Jiquan Wang, Sha Zhao, Zhiling Luo, Yangxuan Zhou, Haiteng Jiang, Shijian Li, Tao Li, Gang Pan

Electroencephalography (EEG) is a non-invasive technique to measure and
record brain electrical activity, widely used in various BCI and healthcare
applications. Early EEG decoding methods rely on supervised learning, limited
by specific tasks and datasets, hindering model performance and
generalizability. With the success of large language models, there is a growing
body of studies focusing on EEG foundation models. However, these studies still
leave challenges: Firstly, most of existing EEG foundation models employ full
EEG modeling strategy. It models the spatial and temporal dependencies between
all EEG patches together, but ignores that the spatial and temporal
dependencies are heterogeneous due to the unique structural characteristics of
EEG signals. Secondly, existing EEG foundation models have limited
generalizability on a wide range of downstream BCI tasks due to varying formats
of EEG data, making it challenging to adapt to. To address these challenges, we
propose a novel foundation model called CBraMod. Specifically, we devise a
criss-cross transformer as the backbone to thoroughly leverage the structural
characteristics of EEG signals, which can model spatial and temporal
dependencies separately through two parallel attention mechanisms. And we
utilize an asymmetric conditional positional encoding scheme which can encode
positional information of EEG patches and be easily adapted to the EEG with
diverse formats. CBraMod is pre-trained on a very large corpus of EEG through
patch-based masked EEG reconstruction. We evaluate CBraMod on up to 10
downstream BCI tasks (12 public datasets). CBraMod achieves the
state-of-the-art performance across the wide range of tasks, proving its strong
capability and generalizability. The source code is publicly available at
\url{https://github.com/wjq-learning/CBraMod}.

摘要：腦電圖 (EEG) 是一種非侵入式技術，用於測量和記錄大腦電氣活動，廣泛用於各種 BCI 和醫療保健應用。早期 EEG 解碼方法依賴於監督式學習，受特定任務和數據集限制，阻礙了模型效能和泛化能力。隨著大型語言模型的成功，專注於 EEG 基礎模型的研究越來越多。然而，這些研究仍存在挑戰：首先，大多數現有的 EEG 基礎模型採用完整的 EEG 建模策略。它同時對所有 EEG 貼片之間的空間和時間依賴性進行建模，但忽略了由於 EEG 信號的獨特結構特徵，空間和時間依賴性是異質的。其次，現有的 EEG 基礎模型在廣泛的下游 BCI 任務上具有有限的泛化能力，這是由於 EEG 數據的格式不同，使其難以適應。為了應對這些挑戰，我們提出了一種名為 CBraMod 的新基礎模型。具體來說，我們設計了一個交叉Transformer作為主幹，以充分利用 EEG 信號的結構特徵，它可以通過兩個並行的注意機制分別對空間和時間依賴性進行建模。我們利用一種非對稱條件位置編碼方案，它可以對 EEG 貼片的位置資訊進行編碼，並可以輕鬆適應具有不同格式的 EEG。CBraMod 在一個非常大的 EEG 語料庫上進行預訓練，通過基於貼片的遮罩 EEG 重建。我們在多達 10 個下游 BCI 任務（12 個公共數據集）上評估了 CBraMod。CBraMod 在廣泛的任務中實現了最先進的效能，證明了其強大的能力和泛化性。原始碼可在 https://github.com/wjq-learning/CBraMod 公開取得。

##### **MPSI: Mamba enhancement model for pixel-wise sequential interaction Image Super-Resolution**
2412.07222v1 by Yuchun He, Yuhan He

Single image super-resolution (SR) has long posed a challenge in the field of
computer vision. While the advent of deep learning has led to the emergence of
numerous methods aimed at tackling this persistent issue, the current
methodologies still encounter challenges in modeling long sequence information,
leading to limitations in effectively capturing the global pixel interactions.
To tackle this challenge and achieve superior SR outcomes, we propose the Mamba
pixel-wise sequential interaction network (MPSI), aimed at enhancing the
establishment of long-range connections of information, particularly focusing
on pixel-wise sequential interaction. We propose the Channel-Mamba Block (CMB)
to capture comprehensive pixel interaction information by effectively modeling
long sequence information. Moreover, in the existing SR methodologies, there
persists the issue of the neglect of features extracted by preceding layers,
leading to the loss of valuable feature information. While certain existing
models strive to preserve these features, they frequently encounter difficulty
in establishing connections across all layers. To overcome this limitation,
MPSI introduces the Mamba channel recursion module (MCRM), which maximizes the
retention of valuable feature information from early layers, thereby
facilitating the acquisition of pixel sequence interaction information from
multiple-level layers. Through extensive experimentation, we demonstrate that
MPSI outperforms existing super-resolution methods in terms of image
reconstruction results, attaining state-of-the-art performance.

摘要：單一影像超解析度 (SR) 長期以來一直是電腦視覺領域中的挑戰。儘管深度學習的出現導致了許多旨在解決此持續問題的方法，但目前的技術在建模長序列資訊方面仍遇到挑戰，導致在有效捕捉全局像素交互方面受到限制。為了應對此挑戰並獲得卓越的 SR 成果，我們提出了 Mamba 像素級序貫互動網路 (MPSI)，旨在增強資訊的遠距離連線建立，特別關注像素級序貫互動。我們提出了通道 Mamba 區塊 (CMB) 以透過有效地建模長序列資訊來捕捉全面的像素互動資訊。此外，在現有的 SR 技術中，持續存在忽略前一層提取特徵的問題，導致有價值的特徵資訊遺失。儘管某些現有模型努力保留這些特徵，但它們經常難以建立所有層的連線。為了克服此限制，MPSI 引入了 Mamba 通道遞迴模組 (MCRM)，它最大化保留早期層的有價值特徵資訊，從而促進從多層層級獲取像素序列互動資訊。透過廣泛的實驗，我們證明 MPSI 在影像重建結果方面優於現有的超解析度方法，達到了最先進的效能。

##### **Comateformer: Combined Attention Transformer for Semantic Sentence Matching**
2412.07220v1 by Bo Li, Di Liang, Zixin Zhang

The Transformer-based model have made significant strides in semantic
matching tasks by capturing connections between phrase pairs. However, to
assess the relevance of sentence pairs, it is insufficient to just examine the
general similarity between the sentences. It is crucial to also consider the
tiny subtleties that differentiate them from each other. Regrettably, attention
softmax operations in transformers tend to miss these subtle differences. To
this end, in this work, we propose a novel semantic sentence matching model
named Combined Attention Network based on Transformer model (Comateformer). In
Comateformer model, we design a novel transformer-based quasi-attention
mechanism with compositional properties. Unlike traditional attention
mechanisms that merely adjust the weights of input tokens, our proposed method
learns how to combine, subtract, or resize specific vectors when building a
representation. Moreover, our proposed approach builds on the intuition of
similarity and dissimilarity (negative affinity) when calculating dual affinity
scores. This allows for a more meaningful representation of relationships
between sentences. To evaluate the performance of our proposed model, we
conducted extensive experiments on ten public real-world datasets and
robustness testing. Experimental results show that our method achieves
consistent improvements.

摘要：基於 Transformer 模型的 Transformer 模型在語義配對任務中取得了重大進展，方法是擷取詞組對之間的關聯。然而，要評估句子對的相關性，僅檢查句子之間的一般相似性是不夠的。考慮使它們彼此區別開來的細微差別也至關重要。遺憾的是，Transformer中的注意力 softmax 運算往往會遺漏這些細微的差異。為此，在這項工作中，我們提出了一個名為基於 Transformer 模型的組合注意力網路（Comateformer）的新型語義句子匹配模型。在 Comateformer 模型中，我們設計了一種新穎的基於 Transformer 的準注意力機制，具有組合特性。與僅調整輸入標記權重的傳統注意力機制不同，我們提出的方法學習如何在建立表示時組合、減去或調整特定向量的大小。此外，我們提出的方法建立在計算雙重親和分數時相似性和相異性（負親和性）的直覺上。這允許對句子之間的關係進行更有意義的表示。為了評估我們提出的模型的效能，我們對十個公共真實世界資料集和穩健性測試進行了廣泛的實驗。實驗結果表明，我們的方法取得了一致的進步。

##### **Towards Automated Cross-domain Exploratory Data Analysis through Large Language Models**
2412.07214v1 by Jun-Peng Zhu, Boyan Niu, Peng cai, Zheming Ni, Jianwei Wan, Kai Xu, Jiajun Huang, Shengbo Ma, Bing Wang, Xuan Zhou, Guanglei Bao, Donghui Zhang, Liu Tang, Qi Liu

Exploratory data analysis (EDA), coupled with SQL, is essential for data
analysts involved in data exploration and analysis. However, data analysts
often encounter two primary challenges: (1) the need to craft SQL queries
skillfully, and (2) the requirement to generate suitable visualization types
that enhance the interpretation of query results. Due to its significance,
substantial research efforts have been made to explore different approaches to
address these challenges, including leveraging large language models (LLMs).
However, existing methods fail to meet real-world data exploration requirements
primarily due to (1) complex database schema; (2) unclear user intent; (3)
limited cross-domain generalization capability; and (4) insufficient end-to-end
text-to-visualization capability.
  This paper presents TiInsight, an automated SQL-based cross-domain
exploratory data analysis system. First, we propose hierarchical data context
(i.e., HDC), which leverages LLMs to summarize the contexts related to the
database schema, which is crucial for open-world EDA systems to generalize
across data domains. Second, the EDA system is divided into four components
(i.e., stages): HDC generation, question clarification and decomposition,
text-to-SQL generation (i.e., TiSQL), and data visualization (i.e., TiChart).
Finally, we implemented an end-to-end EDA system with a user-friendly GUI
interface in the production environment at PingCAP. We have also open-sourced
all APIs of TiInsight to facilitate research within the EDA community. Through
extensive evaluations by a real-world user study, we demonstrate that TiInsight
offers remarkable performance compared to human experts. Specifically, TiSQL
achieves an execution accuracy of 86.3% on the Spider dataset using GPT-4. It
also demonstrates state-of-the-art performance on the Bird dataset.

摘要：<paragraph>探索性資料分析 (EDA) 與 SQL 結合，對於從事資料探索與分析的資料分析師來說至關重要。然而，資料分析師經常會遇到兩個主要的挑戰：(1) 熟練撰寫 SQL 查詢的需求，以及 (2) 產生合適視覺化類型以增強查詢結果解讀的需求。由於其重要性，已經投入大量研究工作來探索解決這些挑戰的不同方法，包括利用大型語言模型 (LLM)。然而，現有方法無法滿足現實世界的資料探索需求，其主要原因在於 (1) 複雜的資料庫架構；(2) 不明確的使用者意圖；(3) 有限的跨領域泛化能力；以及 (4) 不足的端對端文字轉視覺化能力。
本文提出 TiInsight，一個自動化的基於 SQL 的跨領域探索性資料分析系統。首先，我們提出階層式資料脈絡 (亦即 HDC)，它利用 LLM 來總結與資料庫架構相關的脈絡，這對於開放世界的 EDA 系統在資料領域間進行泛化至關重要。其次，EDA 系統被劃分為四個組成部分 (亦即階段)：HDC 產生、問題釐清與分解、文字轉 SQL 產生 (亦即 TiSQL) 以及資料視覺化 (亦即 TiChart)。最後，我們在 PingCAP 的生產環境中實作了一個具有使用者友善 GUI 介面的端對端 EDA 系統。我們也開放了 TiInsight 的所有 API，以促進 EDA 社群中的研究。透過實際使用者研究的廣泛評估，我們證明了 TiInsight 與人類專家相比具有顯著的效能。具體來說，TiSQL 在使用 GPT-4 的 Spider 資料集上達到了 86.3% 的執行準確度。它也在 Bird 資料集上展示了最先進的效能。</paragraph>

##### **IntellectSeeker: A Personalized Literature Management System with the Probabilistic Model and Large Language Model**
2412.07213v1 by Weizhen Bian, Siyan Liu, Yubo Zhou, Dezhi Chen, Yijie Liao, Zhenzhen Fan, Aobo Wang

Faced with the burgeoning volume of academic literature, researchers often
need help with uncertain article quality and mismatches in term searches using
traditional academic engines. We introduce IntellectSeeker, an innovative and
personalized intelligent academic literature management platform to address
these challenges. This platform integrates a Large Language Model (LLM)--based
semantic enhancement bot with a sophisticated probability model to personalize
and streamline literature searches. We adopted the GPT-3.5-turbo model to
transform everyday language into professional academic terms across various
scenarios using multiple rounds of few-shot learning. This adaptation mainly
benefits academic newcomers, effectively bridging the gap between general
inquiries and academic terminology. The probabilistic model intelligently
filters academic articles to align closely with the specific interests of
users, which are derived from explicit needs and behavioral patterns. Moreover,
IntellectSeeker incorporates an advanced recommendation system and text
compression tools. These features enable intelligent article recommendations
based on user interactions and present search results through concise one-line
summaries and innovative word cloud visualizations, significantly enhancing
research efficiency and user experience. IntellectSeeker offers academic
researchers a highly customizable literature management solution with
exceptional search precision and matching capabilities. The code can be found
here: https://github.com/LuckyBian/ISY5001

摘要：面對學術文獻量激增，研究人員常需要幫助來應對傳統學術引擎中不確定的文章品質和搜尋詞彙不符的問題。我們推出 IntellectSeeker，一個創新且個人化的智慧型學術文獻管理平台，來解決這些挑戰。此平台整合一個大型語言模型 (LLM) 為基礎的語意增強機器人，搭配一個精密的機率模型，以個人化並簡化文獻搜尋。我們採用 GPT-3.5-turbo 模型，透過多輪小樣本學習，將日常用語轉換成各種情境下的專業學術用語。這種調整主要有利於學術新手，有效縮小一般詢問和學術術語之間的差距。機率模型會智慧地篩選學術文章，以緊密符合使用者的特定興趣，而這些興趣來自明確的需求和行為模式。此外，IntellectSeeker 結合了先進的推薦系統和文字壓縮工具。這些功能可根據使用者互動提供智慧型文章推薦，並透過簡潔的一行摘要和創新的文字雲視覺化呈現搜尋結果，大幅提升研究效率和使用者體驗。IntellectSeeker 為學術研究人員提供高度客製化的文獻管理解決方案，具備卓越的搜尋精準度和匹配功能。程式碼可以在這裡找到：https://github.com/LuckyBian/ISY5001

##### **EDiT: A Local-SGD-Based Efficient Distributed Training Method for Large Language Models**
2412.07210v1 by Jialiang Cheng, Ning Gao, Yun Yue, Zhiling Ye, Jiadi Jiang, Jian Sha

Distributed training methods are crucial for large language models (LLMs).
However, existing distributed training methods often suffer from communication
bottlenecks, stragglers, and limited elasticity. Local SGD methods have been
proposed to address these issues, but their effectiveness remains limited to
small-scale training due to additional memory overhead and lack of concerns on
efficiency and stability. To tackle these issues, we propose EDiT, an
innovative Efficient Distributed Training method that combines a tailored Local
SGD approach with model sharding techniques to enhance large-scale training
efficiency. EDiT performs layer-wise parameter synchronization during forward
pass, reducing communication and memory overhead and enabling the overlap of
computation and communication. Besides, EDiT employs a pseudo gradient penalty
strategy to suppress loss spikes, which ensures training stability and improve
performance. Additionally, we introduce A-EDiT, a fully asynchronous variant of
EDiT that accommodates heterogeneous clusters. Building on EDiT/A-EDiT, we
conduct a series of experiments to validate large-scale asynchronous training
for LLMs, accompanied by comprehensive analyses. Experimental results
demonstrate the superior performance of EDiT/A-EDiT, establishing them as
robust solutions for distributed LLM training in diverse computational
ecosystems.

摘要：大型語言模型 (LLM) 分散訓練方法至關重要。
然而，現有的分散訓練方法常常會遇到通訊瓶頸、落後者和彈性受限的問題。已經提出使用局部 SGD 方法來解決這些問題，但由於額外的記憶體負擔以及對效率和穩定性的關注不足，其有效性仍然僅限於小規模訓練。為了解決這些問題，我們提出了 EDiT，這是一種創新的高效分散訓練方法，它結合了量身打造的局部 SGD 方法和模型分片技術來提升大規模訓練的效率。EDiT 在前向傳遞期間執行逐層參數同步，減少通訊和記憶體負擔，並使運算和通訊重疊。此外，EDiT 採用偽梯度罰則策略來抑制損失尖峰，這確保了訓練的穩定性並提升了效能。此外，我們引入了 A-EDiT，這是一種 EDiT 的完全非同步變體，可適應異質群集。建立在 EDiT/A-EDiT 的基礎上，我們進行了一系列實驗，以驗證大型語言模型的大規模非同步訓練，並附上全面的分析。實驗結果證明了 EDiT/A-EDiT 的優異效能，確立了它們作為分散式大型語言模型訓練在各種運算生態系統中穩健解決方案的地位。

##### **MAPLE: A Framework for Active Preference Learning Guided by Large Language Models**
2412.07207v1 by Saaduddin Mahmud, Mason Nakamura, Shlomo Zilberstein

The advent of large language models (LLMs) has sparked significant interest
in using natural language for preference learning. However, existing methods
often suffer from high computational burdens, taxing human supervision, and
lack of interpretability. To address these issues, we introduce MAPLE, a
framework for large language model-guided Bayesian active preference learning.
MAPLE leverages LLMs to model the distribution over preference functions,
conditioning it on both natural language feedback and conventional preference
learning feedback, such as pairwise trajectory rankings. MAPLE also employs
active learning to systematically reduce uncertainty in this distribution and
incorporates a language-conditioned active query selection mechanism to
identify informative and easy-to-answer queries, thus reducing human burden. We
evaluate MAPLE's sample efficiency and preference inference quality across two
benchmarks, including a real-world vehicle route planning benchmark using
OpenStreetMap data. Our results demonstrate that MAPLE accelerates the learning
process and effectively improves humans' ability to answer queries.

摘要：大型語言模型 (LLM) 的出現引起了人們對使用自然語言進行偏好學習的濃厚興趣。然而，現有方法通常會造成高計算負擔、對人為監督的考驗以及缺乏可解釋性。為了解決這些問題，我們引入了 MAPLE，一個由大型語言模型引導的貝氏主動偏好學習框架。MAPLE 利用 LLM 對偏好函數的分布進行建模，並根據自然語言回饋和傳統偏好學習回饋（例如成對軌跡排名）對其進行條件化。MAPLE 還採用主動學習來系統性地減少此分布中的不確定性，並結合語言條件主動查詢選擇機制以識別資訊豐富且易於回答的查詢，從而減輕人類負擔。我們評估了 MAPLE 在兩個基準中的樣本效率和偏好推論品質，其中包括使用 OpenStreetMap 數據的真實世界車輛路線規劃基準。我們的結果表明，MAPLE 加速了學習過程，並有效提高了人類回答查詢的能力。

##### **A Review on the Applications of Transformer-based language models for Nucleotide Sequence Analysis**
2412.07201v1 by Nimisha Ghosh, Daniele Santoni, Indrajit Saha, Giovanni Felici

In recent times, Transformer-based language models are making quite an impact
in the field of natural language processing. As relevant parallels can be drawn
between biological sequences and natural languages, the models used in NLP can
be easily extended and adapted for various applications in bioinformatics. In
this regard, this paper introduces the major developments of Transformer-based
models in the recent past in the context of nucleotide sequences. We have
reviewed and analysed a large number of application-based papers on this
subject, giving evidence of the main characterizing features and to different
approaches that may be adopted to customize such powerful computational
machines. We have also provided a structured description of the functioning of
Transformers, that may enable even first time users to grab the essence of such
complex architectures. We believe this review will help the scientific
community in understanding the various applications of Transformer-based
language models to nucleotide sequences. This work will motivate the readers to
build on these methodologies to tackle also various other problems in the field
of bioinformatics.

摘要：近年來，基於 Transformer 的語言模型在自然語言處理領域產生了相當大的影響。由於生物序列和自然語言之間可以畫出相關的相似點，因此用於 NLP 的模型可以輕鬆地擴展和調整，以適用于生物資訊學中的各種應用。在這方面，本文介紹了最近在核苷酸序列背景下基於 Transformer 的模型的主要發展。我們檢閱並分析了大量關於此主題的應用型論文，提供了主要特徵的證據，以及可能採用的不同方法來客製化這些強大的運算機器。我們還提供了 Transformer 運作結構化的說明，即使是第一次使用的人也能掌握這種複雜架構的精髓。我們相信這篇評論將有助於科學界了解基於 Transformer 的語言模型在核苷酸序列中的各種應用。這項工作將激勵讀者建立在這些方法之上，以解決生物資訊學領域中的其他各種問題。

##### **Hierarchical Split Federated Learning: Convergence Analysis and System Optimization**
2412.07197v1 by Zheng Lin, Wei Wei, Zhe Chen, Chan-Tong Lam, Xianhao Chen, Yue Gao, Jun Luo

As AI models expand in size, it has become increasingly challenging to deploy
federated learning (FL) on resource-constrained edge devices. To tackle this
issue, split federated learning (SFL) has emerged as an FL framework with
reduced workload on edge devices via model splitting; it has received extensive
attention from the research community in recent years. Nevertheless, most prior
works on SFL focus only on a two-tier architecture without harnessing
multi-tier cloudedge computing resources. In this paper, we intend to analyze
and optimize the learning performance of SFL under multi-tier systems.
Specifically, we propose the hierarchical SFL (HSFL) framework and derive its
convergence bound. Based on the theoretical results, we formulate a joint
optimization problem for model splitting (MS) and model aggregation (MA). To
solve this rather hard problem, we then decompose it into MS and MA subproblems
that can be solved via an iterative descending algorithm. Simulation results
demonstrate that the tailored algorithm can effectively optimize MS and MA for
SFL within virtually any multi-tier system.

摘要：隨著 AI 模型規模的擴大，在資源受限的邊緣裝置上部署聯合學習（FL）變得越來越困難。為了解決這個問題，拆分聯合學習（SFL）作為一種 FL 框架出現，透過模型拆分減少邊緣裝置上的工作負載；近年來它受到了研究社群廣泛的關注。儘管如此，大多數先前關於 SFL 的研究僅專注於二層架構，而沒有利用多層雲端邊緣運算資源。在本文中，我們打算分析和最佳化多層系統下 SFL 的學習效能。具體來說，我們提出了階層式 SFL（HSFL）框架並推導其收斂界限。根據理論結果，我們制定了一個模型拆分（MS）和模型聚合（MA）的聯合最佳化問題。為了解決這個相當困難的問題，我們接著將其分解成 MS 和 MA 子問題，這些子問題可以用反覆遞降演算法來解決。模擬結果證明，量身打造的演算法可以在幾乎任何多層系統中有效最佳化 SFL 的 MS 和 MA。

##### **PrisonBreak: Jailbreaking Large Language Models with Fewer Than Twenty-Five Targeted Bit-flips**
2412.07192v1 by Zachary Coalson, Jeonghyun Woo, Shiyang Chen, Yu Sun, Lishan Yang, Prashant Nair, Bo Fang, Sanghyun Hong

We introduce a new class of attacks on commercial-scale (human-aligned)
language models that induce jailbreaking through targeted bitwise corruptions
in model parameters. Our adversary can jailbreak billion-parameter language
models with fewer than 25 bit-flips in all cases$-$and as few as 5 in
some$-$using up to 40$\times$ less bit-flips than existing attacks on computer
vision models at least 100$\times$ smaller. Unlike prompt-based jailbreaks, our
attack renders these models in memory 'uncensored' at runtime, allowing them to
generate harmful responses without any input modifications. Our attack
algorithm efficiently identifies target bits to flip, offering up to 20$\times$
more computational efficiency than previous methods. This makes it practical
for language models with billions of parameters. We show an end-to-end
exploitation of our attack using software-induced fault injection, Rowhammer
(RH). Our work examines 56 DRAM RH profiles from DDR4 and LPDDR4X devices with
different RH vulnerabilities. We show that our attack can reliably induce
jailbreaking in systems similar to those affected by prior bit-flip attacks.
Moreover, our approach remains effective even against highly RH-secure systems
(e.g., 46$\times$ more secure than previously tested systems). Our analyses
further reveal that: (1) models with less post-training alignment require fewer
bit flips to jailbreak; (2) certain model components, such as value projection
layers, are substantially more vulnerable than others; and (3) our method is
mechanistically different than existing jailbreaks. Our findings highlight a
pressing, practical threat to the language model ecosystem and underscore the
need for research to protect these models from bit-flip attacks.

摘要：<paragraph>我們提出針對商用規模（與人類一致）語言模型的新型攻擊類型，該類型通過模型參數中的目標按位元損壞來誘發越獄。我們的對手可以使用小於 25 個位元元反轉（在所有情況下）來越獄十億參數語言模型，在某些情況下甚至可以少至 5 個，比現有攻擊方法使用的位元元反轉少 40 倍，而現有攻擊方法針對的電腦視覺模型至少小 100 倍。與基於提示的越獄不同，我們的攻擊在執行時會使這些模型在記憶體中「不受審查」，讓它們無需任何輸入修改即可產生有害回應。我們的攻擊演算法有效率地識別要反轉的目標位元元，比先前的演算法提供高達 20 倍的運算效率。這使得它適用於具有數十億個參數的語言模型。我們展示了使用軟體誘發故障注入 Rowhammer (RH) 對我們的攻擊進行端到端利用。我們的研究檢視了來自 DDR4 和 LPDDR4X 裝置的 56 個 DRAM RH 設定檔，這些裝置具有不同的 RH 漏洞。我們展示我們的攻擊可以可靠地誘發與先前位元元反轉攻擊影響的系統類似的越獄。此外，我們的做法即使針對高度 RH 安全系統（例如，比先前測試的系統安全 46 倍）仍然有效。我們的分析進一步揭示：(1) 訓練後對齊較少的模型需要較少的位元元反轉才能越獄；(2) 特定的模型組件（例如值投影層）比其他組件容易受到攻擊；(3) 我們的演算法在機制上與現有的越獄方式不同。我們的發現突顯了對語言模型生態系統的迫切實際威脅，並強調需要研究來保護這些模型免於位元元反轉攻擊。</paragraph>

##### **Exploring What Why and How: A Multifaceted Benchmark for Causation Understanding of Video Anomaly**
2412.07183v1 by Hang Du, Guoshun Nan, Jiawen Qian, Wangchenhui Wu, Wendi Deng, Hanqing Mu, Zhenyan Chen, Pengxuan Mao, Xiaofeng Tao, Jun Liu

Recent advancements in video anomaly understanding (VAU) have opened the door
to groundbreaking applications in various fields, such as traffic monitoring
and industrial automation. While the current benchmarks in VAU predominantly
emphasize the detection and localization of anomalies. Here, we endeavor to
delve deeper into the practical aspects of VAU by addressing the essential
questions: "what anomaly occurred?", "why did it happen?", and "how severe is
this abnormal event?". In pursuit of these answers, we introduce a
comprehensive benchmark for Exploring the Causation of Video Anomalies (ECVA).
Our benchmark is meticulously designed, with each video accompanied by detailed
human annotations. Specifically, each instance of our ECVA involves three sets
of human annotations to indicate "what", "why" and "how" of an anomaly,
including 1) anomaly type, start and end times, and event descriptions, 2)
natural language explanations for the cause of an anomaly, and 3) free text
reflecting the effect of the abnormality. Building upon this foundation, we
propose a novel prompt-based methodology that serves as a baseline for tackling
the intricate challenges posed by ECVA. We utilize "hard prompt" to guide the
model to focus on the critical parts related to video anomaly segments, and
"soft prompt" to establish temporal and spatial relationships within these
anomaly segments. Furthermore, we propose AnomEval, a specialized evaluation
metric crafted to align closely with human judgment criteria for ECVA. This
metric leverages the unique features of the ECVA dataset to provide a more
comprehensive and reliable assessment of various video large language models.
We demonstrate the efficacy of our approach through rigorous experimental
analysis and delineate possible avenues for further investigation into the
comprehension of video anomaly causation.

摘要：<paragraph>影片異常理解 (VAU) 的最新進展為各種領域開創了突破性的應用，例如交通監控和工業自動化。儘管 VAU 中目前的基準主要強調異常的偵測和定位。在此，我們努力深入探討 VAU 的實際面向，探討以下基本問題：「發生什麼異常？」、「為什麼會發生？」和「這個異常事件有多嚴重？」。為了找出這些答案，我們引進了一個探索影片異常因果關係 (ECVA) 的全面基準。我們的基準經過精心設計，每部影片都附有詳細的人工標註。具體來說，ECVA 的每個實例都包含三組人工標註，用於指出異常的「是什麼」、「為什麼」和「如何」，包括 1) 異常類型、開始和結束時間，以及事件描述，2) 異常原因的自然語言說明，以及 3) 反映異常影響的自由文字。在此基礎上，我們提出了一種新穎的基於提示的方法，作為應對 ECVA 複雜挑戰的基準。我們利用「硬提示」引導模型專注於與影片異常片段相關的重要部分，並利用「軟提示」在這些異常片段中建立時間和空間關係。此外，我們提出了 AnomEval，這是一個專門的評估指標，旨在與人類對 ECVA 的判斷標準緊密結合。此指標利用 ECVA 資料集的獨特特徵，對各種影片大型語言模型提供更全面且可靠的評估。我們透過嚴謹的實驗分析證明了我們方法的有效性，並描述了進一步探討影片異常因果關係理解的可能途徑。</paragraph>

##### **An Enhancement of CNN Algorithm for Rice Leaf Disease Image Classification in Mobile Applications**
2412.07182v1 by Kayne Uriel K. Rodrigo, Jerriane Hillary Heart S. Marcial, Samuel C. Brillo, Khatalyn E. Mata, Jonathan C. Morano

This study focuses on enhancing rice leaf disease image classification
algorithms, which have traditionally relied on Convolutional Neural Network
(CNN) models. We employed transfer learning with MobileViTV2_050 using
ImageNet-1k weights, a lightweight model that integrates CNN's local feature
extraction with Vision Transformers' global context learning through a
separable self-attention mechanism. Our approach resulted in a significant
15.66% improvement in classification accuracy for MobileViTV2_050-A, our first
enhanced model trained on the baseline dataset, achieving 93.14%. Furthermore,
MobileViTV2_050-B, our second enhanced model trained on a broader rice leaf
dataset, demonstrated a 22.12% improvement, reaching 99.6% test accuracy.
Additionally, MobileViTV2-A attained an F1-score of 93% across four rice labels
and a Receiver Operating Characteristic (ROC) curve ranging from 87% to 97%. In
terms of resource consumption, our enhanced models reduced the total parameters
of the baseline CNN model by up to 92.50%, from 14 million to 1.1 million.
These results indicate that MobileViTV2_050 not only improves computational
efficiency through its separable self-attention mechanism but also enhances
global context learning. Consequently, it offers a lightweight and robust
solution suitable for mobile deployment, advancing the interpretability and
practicality of models in precision agriculture.

摘要：本研究著重於提升稻葉病害影像分類演算法，此演算法傳統上仰賴卷積神經網路 (CNN) 模型。我們使用 ImageNet-1K 權重對 MobileViTV2_050 進行遷移學習，這是一個輕量級模型，透過可分離自注意力機制，整合 CNN 的局部特徵萃取與視覺轉換器的全局脈絡學習。我們的做法對於在基準資料集上訓練的第一個強化模型 MobileViTV2_050-A，產生顯著的 15.66% 分類準確度提升，達到 93.14%。此外，在更廣泛的稻葉資料集上訓練的第二個強化模型 MobileViTV2_050-B，展現 22.12% 的提升，達到 99.6% 的測試準確度。此外，MobileViTV2-A 在四個稻葉標籤上獲得 93% 的 F1 分數，以及範圍從 87% 到 97% 的受試者操作特性 (ROC) 曲線。在資源消耗方面，我們的強化模型將基準 CNN 模型的總參數減少多達 92.50%，從 1400 萬減少到 110 萬。這些結果顯示 MobileViTV2_050 不僅透過其可分離自注意力機制提升運算效率，也增強全局脈絡學習。因此，它提供一個輕量且穩健的解決方案，適合於行動裝置部署，提升精準農業中模型的可解釋性和實用性。

##### **Post-Training Statistical Calibration for Higher Activation Sparsity**
2412.07174v1 by Vui Seng Chua, Yujie Pan, Nilesh Jain

We present Statistical Calibrated Activation Pruning (SCAP), a post-training
activation pruning framework that (1) generalizes sparsification by input
activations of Fully-Connected layers for generic and flexible application
across Transformers, and (2) features a simple Mode-Centering technique to
pre-calibrate activation distributions for maximizing post-training sparsity.
Our results demonstrate robust Pareto efficiency compared to prior methods,
translating to a 1.5x additional LLM decoding speedup against CATS at iso model
quality. SCAP effectiveness is empirically verified across a wide range of
models, including recent Transformer Decoders, MoE, Mamba2, Encoding
Transformer, and pre-quantized models, highlighting its practicality and
scalability. The code is available at: https://github.com/IntelLabs/SCAP.

摘要：我們提出統計校準的激活剪枝 (SCAP)，這是一個訓練後激活剪枝架構，它 (1) 透過全連接層的輸入激活，將稀疏化概括化，以在 Transformers 中進行通用且靈活的應用，並 (2) 具備一個簡單的模式中心化技術，用於預先校準激活分佈，以最大化訓練後的稀疏性。我們的結果證明了與先前的技術相比，具有強大的 Pareto 效率，轉化為在 iso 模型品質下，與 CATS 相比，LLM 解碼速度提升了 1.5 倍。SCAP 的有效性已在廣泛的模型中得到實證驗證，包括最近的 Transformer 解碼器、MoE、Mamba2、編碼 Transformer 和預量化模型，突顯了它的實用性和可擴充性。程式碼可在 https://github.com/IntelLabs/SCAP 取得。

##### **Breaking the Stage Barrier: A Novel Single-Stage Approach to Long Context Extension for Large Language Models**
2412.07171v1 by Haoran Lian, Junmin Chen, Wei Huang, Yizhe Xiong, Wenping Hu, Guiguang Ding, Hui Chen, Jianwei Niu, Zijia Lin, Fuzheng Zhang, Di Zhang

Recently, Large language models (LLMs) have revolutionized Natural Language
Processing (NLP). Pretrained LLMs, due to limited training context size,
struggle with handling long token sequences, limiting their performance on
various downstream tasks. Current solutions toward long context modeling often
employ multi-stage continual pertaining, which progressively increases the
effective context length through several continual pretraining stages. However,
those approaches require extensive manual tuning and human expertise. In this
paper, we introduce a novel single-stage continual pretraining method,
Head-Adaptive Rotary Position Encoding (HARPE), to equip LLMs with long context
modeling capabilities while simplifying the training process. Our HARPE
leverages different Rotary Position Encoding (RoPE) base frequency values
across different attention heads and directly trains LLMs on the target context
length. Extensive experiments on 4 language modeling benchmarks, including the
latest RULER benchmark, demonstrate that HARPE excels in understanding and
integrating long-context tasks with single-stage training, matching and even
outperforming existing multi-stage methods. Our results highlight that HARPE
successfully breaks the stage barrier for training LLMs with long context
modeling capabilities.

摘要：最近，大型语言模型 (LLM) 彻底改变了自然语言处理 (NLP)。由于训练语境大小有限，预训练 LLM 难以处理长标记序列，限制了它们在各种下游任务中的性能。当前针对长语境建模的解决方案通常采用多阶段持续训练，通过几个持续预训练阶段逐步增加有效语境长度。然而，这些方法需要大量的手动调整和人力专业知识。在本文中，我们介绍了一种新颖的单阶段持续预训练方法，即自适应旋转位置编码 (HARPE)，以在简化训练过程的同时为 LLM 提供长语境建模能力。我们的 HARPE 利用不同注意力头的不同旋转位置编码 (RoPE) 基本频率值，并在目标语境长度上直接训练 LLM。在包括最新 RULER 基准在内的 4 个语言建模基准上进行的广泛实验表明，HARPE 在理解和整合长语境任务方面表现出色，只需单阶段训练，即可匹配甚至优于现有的多阶段方法。我们的结果突出表明，HARPE 成功打破了训练具有长语境建模能力的 LLM 的阶段障碍。

##### **Fast Occupancy Network**
2412.07163v1 by Mingjie Lu, Yuanxian Huang, Ji Liu, Xingliang Huang, Dong Li, Jinzhang Peng, Lu Tian, Emad Barsoum

Occupancy Network has recently attracted much attention in autonomous
driving. Instead of monocular 3D detection and recent bird's eye view(BEV)
models predicting 3D bounding box of obstacles, Occupancy Network predicts the
category of voxel in specified 3D space around the ego vehicle via transforming
3D detection task into 3D voxel segmentation task, which has much superiority
in tackling category outlier obstacles and providing fine-grained 3D
representation. However, existing methods usually require huge computation
resources than previous methods, which hinder the Occupancy Network solution
applying in intelligent driving systems. To address this problem, we make an
analysis of the bottleneck of Occupancy Network inference cost, and present a
simple and fast Occupancy Network model, which adopts a deformable 2D
convolutional layer to lift BEV feature to 3D voxel feature and presents an
efficient voxel feature pyramid network (FPN) module to improve performance
with few computational cost. Further, we present a cost-free 2D segmentation
branch in perspective view after feature extractors for Occupancy Network
during inference phase to improve accuracy. Experimental results demonstrate
that our method consistently outperforms existing methods in both accuracy and
inference speed, which surpasses recent state-of-the-art (SOTA) OCCNet by 1.7%
with ResNet50 backbone with about 3X inference speedup. Furthermore, our method
can be easily applied to existing BEV models to transform them into Occupancy
Network models.

摘要：佔用網路最近在自動駕駛中備受關注。佔用網路並非單眼 3D 偵測和最近的鳥瞰圖 (BEV) 模型預測障礙物的 3D 邊界框，而是透過將 3D 偵測任務轉換為 3D 體素分割任務，預測自車周圍指定 3D 空間中體素的類別，在處理類別異常值障礙物和提供細緻的 3D 表示方面具有極大的優越性。然而，現有方法通常需要比以前的方法更多的運算資源，這阻礙了佔用網路解決方案在智慧駕駛系統中的應用。為了解決這個問題，我們分析了佔用網路推論成本的瓶頸，並提出了一個簡單快速的佔用網路模型，採用可變形 2D 捲積層將 BEV 特徵提升到 3D 體素特徵，並提出了一個高效的體素特徵金字塔網路 (FPN) 模組，以提升效能，同時運算成本低。此外，我們在推論階段的佔用網路特徵萃取器之後，提出了在透視視圖中一個無成本的 2D 分割分支，以提高準確度。實驗結果證明，我們的模型在準確度和推論速度方面始終優於現有方法，以 ResNet50 主幹超越最近的最新技術 (SOTA) OCCNet 1.7%，推論速度提升約 3 倍。此外，我們的模型可以輕鬆應用於現有的 BEV 模型，將它們轉換為佔用網路模型。

##### **MM-PoE: Multiple Choice Reasoning via. Process of Elimination using Multi-Modal Models**
2412.07148v1 by Sayak Chakrabarty, Souradip Pal

This paper introduces Multiple Choice Reasoning via. Process of Elimination
using Multi-Modal models, herein referred to as Multi-Modal Process of
Elimination (MM-PoE). This novel methodology is engineered to augment the
efficacy of Vision-Language Models (VLMs) in multiple-choice visual reasoning
tasks. Diverging from conventional approaches that evaluate each option
independently, MM-PoE employs a dual-step scoring paradigm that initially
identifies and excludes implausible choices, subsequently concentrating on the
most probable remaining options. This method emulates human test-taking
strategies, where individuals typically eliminate clearly incorrect answers
prior to selecting the optimal response. Our empirical evaluations, conducted
across three benchmark datasets, reveal that MM-PoE significantly improves both
zero-shot and few-shot performance of contemporary state-of-the-art VLMs.
Critically, this approach not only broadens the application of the elimination
process to multi-modal contexts but also allows few-shot experiments, thereby
addressing two principal limitations concerning usage of PoE only in zero-shot
settings and only with a language-only framework. As a result, MM-PoE not only
refines the reasoning capabilities of VLMs but also broadens their
applicability to complex visual question-answering scenarios. All code and
documentation supporting our work are available at
https://pypi.org/project/mm-poe/, enabling researchers and practitioners to
easily integrate and further develop these techniques.

摘要：本文介紹透過淘汰過程進行多重選擇推理，並使用多模式模型，本文稱之為多模式淘汰過程 (MM-PoE)。這種新穎的方法旨在加強視覺語言模型 (VLM) 在多重選擇視覺推理任務中的效能。MM-PoE 採用雙步驟計分範例，與評估每個選項的傳統方法不同，它會先找出並排除不可能的選項，然後專注於最有可能的選項。此方法模擬人類的測驗策略，在選擇最佳答案之前，通常會先排除明顯錯誤的答案。我們在三個基準資料集上進行實證評估，結果顯示 MM-PoE 大幅提升當代最先進 VLM 的零次學習和少量學習效能。重要的是，此方法不僅將淘汰過程的應用擴展到多模式脈絡，還允許少量學習實驗，從而解決僅在零次學習設定中使用 PoE 以及僅使用語言框架這兩個主要限制。因此，MM-PoE 不僅提升 VLM 的推理能力，還擴展其適用於複雜視覺問答場景。所有支援我們工作的程式碼和文件都可以在 https://pypi.org/project/mm-poe/ 取得，讓研究人員和實務工作者可以輕鬆整合並進一步開發這些技術。

##### **MIT-10M: A Large Scale Parallel Corpus of Multilingual Image Translation**
2412.07147v1 by Bo Li, Shaolin Zhu, Lijie Wen

Image Translation (IT) holds immense potential across diverse domains,
enabling the translation of textual content within images into various
languages. However, existing datasets often suffer from limitations in scale,
diversity, and quality, hindering the development and evaluation of IT models.
To address this issue, we introduce MIT-10M, a large-scale parallel corpus of
multilingual image translation with over 10M image-text pairs derived from
real-world data, which has undergone extensive data cleaning and multilingual
translation validation. It contains 840K images in three sizes, 28 categories,
tasks with three levels of difficulty and 14 languages image-text pairs, which
is a considerable improvement on existing datasets. We conduct extensive
experiments to evaluate and train models on MIT-10M. The experimental results
clearly indicate that our dataset has higher adaptability when it comes to
evaluating the performance of the models in tackling challenging and complex
image translation tasks in the real world. Moreover, the performance of the
model fine-tuned with MIT-10M has tripled compared to the baseline model,
further confirming its superiority.

摘要：影像翻譯 (IT) 在不同領域中擁有極大的潛力，
能將影像中的文字內容翻譯成各種語言。然而，現有的資料集通常在規模、
多樣性和品質上都有所不足，阻礙了 IT 模型的開發和評估。
為了解決這個問題，我們引入了 MIT-10M，這是一個大型平行語料庫，
包含超過 10M 個來自真實世界資料的多語言影像翻譯，並經過廣泛的資料清理和多語言
翻譯驗證。它包含 840K 張影像，有 3 種大小、28 個類別、
3 個難度等級的任務和 14 種語言的影像文字對，這對現有的資料集來說是一個顯著的進步。我們進行了廣泛的
實驗來評估和訓練 MIT-10M 上的模型。實驗結果
清楚地表明，我們的資料集在評估模型在處理現實世界中具有挑戰性和複雜性的
影像翻譯任務時的效能方面具有更高的適應性。此外，
使用 MIT-10M 微調的模型效能比基準模型提高了三倍，進一步確認了它的優越性。

##### **Political Actor Agent: Simulating Legislative System for Roll Call Votes Prediction with Large Language Models**
2412.07144v1 by Hao Li, Ruoyuan Gong, Hao Jiang

Predicting roll call votes through modeling political actors has emerged as a
focus in quantitative political science and computer science. Widely used
embedding-based methods generate vectors for legislators from diverse data sets
to predict legislative behaviors. However, these methods often contend with
challenges such as the need for manually predefined features, reliance on
extensive training data, and a lack of interpretability. Achieving more
interpretable predictions under flexible conditions remains an unresolved
issue. This paper introduces the Political Actor Agent (PAA), a novel
agent-based framework that utilizes Large Language Models to overcome these
limitations. By employing role-playing architectures and simulating legislative
system, PAA provides a scalable and interpretable paradigm for predicting
roll-call votes. Our approach not only enhances the accuracy of predictions but
also offers multi-view, human-understandable decision reasoning, providing new
insights into political actor behaviors. We conducted comprehensive experiments
using voting records from the 117-118th U.S. House of Representatives,
validating the superior performance and interpretability of PAA. This study not
only demonstrates PAA's effectiveness but also its potential in political
science research.

摘要：透過建模政治行為者來預測點名投票已成為量化政治科學和電腦科學的重點。廣泛使用的基於嵌入的方法會從多樣化的資料集中產生立法者的向量，以預測立法行為。然而，這些方法經常面臨挑戰，例如需要手動預先定義的特徵、依賴於大量的訓練資料，以及缺乏可解釋性。在靈活的條件下實現更具可解釋性的預測仍然是一個未解決的問題。本文介紹了政治行為者代理（PAA），這是一個新穎的基於代理的框架，它利用大型語言模型來克服這些限制。透過採用角色扮演架構和模擬立法系統，PAA 提供了一個可擴充且可解釋的範例來預測點名投票。我們的做法不僅提高了預測的準確性，還提供了多視角、人類可理解的決策推理，為政治行為者的行為提供了新的見解。我們使用美國第 117-118 屆眾議院的投票記錄進行了全面的實驗，驗證了 PAA 的優異效能和可解釋性。這項研究不僅證明了 PAA 的有效性，也證明了其在政治科學研究中的潛力。

##### **Bridging the Gap for Test-Time Multimodal Sentiment Analysis**
2412.07121v1 by Zirun Guo, Tao Jin, Wenlong Xu, Wang Lin, Yangyang Wu

Multimodal sentiment analysis (MSA) is an emerging research topic that aims
to understand and recognize human sentiment or emotions through multiple
modalities. However, in real-world dynamic scenarios, the distribution of
target data is always changing and different from the source data used to train
the model, which leads to performance degradation. Common adaptation methods
usually need source data, which could pose privacy issues or storage overheads.
Therefore, test-time adaptation (TTA) methods are introduced to improve the
performance of the model at inference time. Existing TTA methods are always
based on probabilistic models and unimodal learning, and thus can not be
applied to MSA which is often considered as a multimodal regression task. In
this paper, we propose two strategies: Contrastive Adaptation and Stable
Pseudo-label generation (CASP) for test-time adaptation for multimodal
sentiment analysis. The two strategies deal with the distribution shifts for
MSA by enforcing consistency and minimizing empirical risk, respectively.
Extensive experiments show that CASP brings significant and consistent
improvements to the performance of the model across various distribution shift
settings and with different backbones, demonstrating its effectiveness and
versatility. Our codes are available at https://github.com/zrguo/CASP.

摘要：多模态情感分析 (MSA) 是一项新兴的研究主题，旨在通过多种模态来理解和识别人类的情感或情绪。然而，在现实世界的动态场景中，目标数据的分布总是在变化，并且不同于用于训练模型的源数据，这会导致性能下降。常见的适应方法通常需要源数据，这可能会带来隐私问题或存储开销。因此，引入了测试时适应 (TTA) 方法来提高模型在推理时的性能。现有的 TTA 方法总是基于概率模型和单模态学习，因此不能应用于 MSA，MSA 通常被认为是一种多模态回归任务。在本文中，我们提出了两种策略：对比适应和稳定伪标签生成 (CASP)，用于多模态情感分析的测试时适应。这两种策略分别通过强制一致性和最小化经验风险来处理 MSA 的分布偏移。大量实验表明，CASP 在各种分布偏移设置和不同的主干下为模型的性能带来了显著且一致的改进，证明了其有效性和多功能性。我们的代码可在 https://github.com/zrguo/CASP 获得。

##### **A Review of Human Emotion Synthesis Based on Generative Technology**
2412.07116v1 by Fei Ma, Yukan Li, Yifan Xie, Ying He, Yi Zhang, Hongwei Ren, Zhou Liu, Wei Yao, Fuji Ren, Fei Richard Yu, Shiguang Ni

Human emotion synthesis is a crucial aspect of affective computing. It
involves using computational methods to mimic and convey human emotions through
various modalities, with the goal of enabling more natural and effective
human-computer interactions. Recent advancements in generative models, such as
Autoencoders, Generative Adversarial Networks, Diffusion Models, Large Language
Models, and Sequence-to-Sequence Models, have significantly contributed to the
development of this field. However, there is a notable lack of comprehensive
reviews in this field. To address this problem, this paper aims to address this
gap by providing a thorough and systematic overview of recent advancements in
human emotion synthesis based on generative models. Specifically, this review
will first present the review methodology, the emotion models involved, the
mathematical principles of generative models, and the datasets used. Then, the
review covers the application of different generative models to emotion
synthesis based on a variety of modalities, including facial images, speech,
and text. It also examines mainstream evaluation metrics. Additionally, the
review presents some major findings and suggests future research directions,
providing a comprehensive understanding of the role of generative technology in
the nuanced domain of emotion synthesis.

摘要：人類情緒合成是情感運算的重要面向。它涉及使用計算方法來模擬和傳達人類情緒，透過各種方式，目標是實現更自然且有效的人機互動。生成模型的最新進展，例如自動編碼器、生成對抗網路、擴散模型、大型語言模型和序列到序列模型，已對此領域的發展做出重大貢獻。然而，此領域明顯缺乏全面的回顧。為了解決此問題，本文旨在透過提供基於生成模型的人類情緒合成最新進展的全面且系統性概述，來解決此差距。具體來說，此回顧將首先說明回顧方法、所涉及的情緒模型、生成模型的數學原理和所使用的資料集。接著，回顧涵蓋了將不同的生成模型應用於基於各種方式的情緒合成，包括臉部影像、語音和文字。它也檢視了主流的評量指標。此外，回顧提出了若干主要發現，並建議未來的研究方向，提供對生成技術在細緻的情緒合成領域中角色的全面了解。

##### **Exploring Coding Spot: Understanding Parametric Contributions to LLM Coding Performance**
2412.07113v1 by Dongjun Kim, Minhyuk Kim, YongChan Chun, Chanjun Park, Heuiseok Lim

Large Language Models (LLMs) have demonstrated notable proficiency in both
code generation and comprehension across multiple programming languages.
However, the mechanisms underlying this proficiency remain underexplored,
particularly with respect to whether distinct programming languages are
processed independently or within a shared parametric region. Drawing an
analogy to the specialized regions of the brain responsible for distinct
cognitive functions, we introduce the concept of Coding Spot, a specialized
parametric region within LLMs that facilitates coding capabilities. Our
findings identify this Coding Spot and show that targeted modifications to this
subset significantly affect performance on coding tasks, while largely
preserving non-coding functionalities. This compartmentalization mirrors the
functional specialization observed in cognitive neuroscience, where specific
brain regions are dedicated to distinct tasks, suggesting that LLMs may
similarly employ specialized parameter regions for different knowledge domains.

摘要：大型語言模型 (LLM) 已證明在多種程式語言中具備顯著的程式碼產生和理解能力。然而，這種能力背後的機制仍未得到充分探討，特別是在不同程式語言是否獨立處理或在共享參數區域內處理方面。我們借用大腦中負責不同認知功能的專門區域，引入了編碼點的概念，這是一個 LLM 中的專門參數區域，有助於編碼功能。我們的研究結果識別出這個編碼點，並表明對這個子集的目標修改顯著影響編碼任務的效能，同時在很大程度上保留了非編碼功能。這種區隔反映了認知神經科學中觀察到的功能專門化，其中特定的腦區專門負責不同的任務，這表明 LLM 可能也對不同的知識領域採用了專門的參數區域。

##### **Maya: An Instruction Finetuned Multilingual Multimodal Model**
2412.07112v1 by Nahid Alam, Karthik Reddy Kanjula, Surya Guthikonda, Timothy Chung, Bala Krishna S Vegesna, Abhipsha Das, Anthony Susevski, Ryan Sze-Yin Chan, S M Iftekhar Uddin, Shayekh Bin Islam, Roshan Santhosh, Snegha A, Drishti Sharma, Chen Liu, Isha Chaturvedi, Genta Indra Winata, Ashvanth. S, Snehanshu Mukherjee, Alham Fikri Aji

The rapid development of large Vision-Language Models (VLMs) has led to
impressive results on academic benchmarks, primarily in widely spoken
languages. However, significant gaps remain in the ability of current VLMs to
handle low-resource languages and varied cultural contexts, largely due to a
lack of high-quality, diverse, and safety-vetted data. Consequently, these
models often struggle to understand low-resource languages and cultural nuances
in a manner free from toxicity. To address these limitations, we introduce
Maya, an open-source Multimodal Multilingual model. Our contributions are
threefold: 1) a multilingual image-text pretraining dataset in eight languages,
based on the LLaVA pretraining dataset; 2) a thorough analysis of toxicity
within the LLaVA dataset, followed by the creation of a novel toxicity-free
version across eight languages; and 3) a multilingual image-text model
supporting these languages, enhancing cultural and linguistic comprehension in
vision-language tasks. Code available at https://github.com/nahidalam/maya.

摘要：大型視覺語言模型 (VLM) 的快速發展已在學術基準上取得令人印象深刻的成果，主要是在廣泛使用的語言中。然而，由於缺乏高品質、多樣化且經過安全審查的資料，目前 VLM 在處理低資源語言和各種文化背景方面的能力仍有顯著差距。因此，這些模型常常難以理解低資源語言和文化細微差別，而且無法避免有毒性。為了解決這些限制，我們引入了 Maya，一個開放原始碼的多模態多語言模型。我們的貢獻有三方面：1) 一個基於 LLaVA 預訓練資料集的八種語言的多語言圖像文字預訓練資料集；2) 對 LLaVA 資料集中的毒性進行徹底分析，然後在八種語言中建立一個新的無毒版本；3) 一個支援這些語言的多語言圖像文字模型，增強視覺語言任務中的文化和語言理解。程式碼可在 https://github.com/nahidalam/maya 取得。

##### **Predictable Emergent Abilities of LLMs: Proxy Tasks Are All You Need**
2412.07111v1 by Bo-Wen Zhang, Yan Yan, Boxiang Yang, Yifei Xue, Guang Liu

While scaling laws optimize training configurations for large language models
(LLMs) through experiments on smaller or early-stage models, they fail to
predict emergent abilities due to the absence of such capabilities in these
models. To address this, we propose a method that predicts emergent abilities
by leveraging proxy tasks. We begin by establishing relevance metrics between
the target task and candidate tasks based on performance differences across
multiple models. These candidate tasks are then validated for robustness with
small model ensembles, leading to the selection of the most appropriate proxy
tasks. The predicted performance on the target task is then derived by
integrating the evaluation results of these proxies. In a case study on tool
utilization capabilities, our method demonstrated a strong correlation between
predicted and actual performance, confirming its effectiveness.

摘要：儘管規模定律透過在較小或早期階段的模型上進行實驗，來最佳化大型語言模型 (LLM) 的訓練設定，但由於這些模型缺乏此類能力，因此無法預測新興能力。為了解決此問題，我們提出了一種透過利用代理任務來預測新興能力的方法。我們首先根據多個模型的效能差異，在目標任務和候選任務之間建立相關性指標。然後針對這些候選任務驗證其與小型模型集合的穩健性，從而選出最合適的代理任務。接著透過整合這些代理的評估結果，推導出目標任務的預測效能。在工具使用能力的案例研究中，我們的模型證明了預測效能與實際效能之間有很強的相關性，證實了其有效性。

##### **Improving the Natural Language Inference robustness to hard dataset by data augmentation and preprocessing**
2412.07108v1 by Zijiang Yang

Natural Language Inference (NLI) is the task of inferring whether the
hypothesis can be justified by the given premise. Basically, we classify the
hypothesis into three labels(entailment, neutrality and contradiction) given
the premise. NLI was well studied by the previous researchers. A number of
models, especially the transformer based ones, have achieved significant
improvement on these tasks. However, it is reported that these models are
suffering when they are dealing with hard datasets. Particularly, they perform
much worse when dealing with unseen out-of-distribution premise and hypothesis.
They may not understand the semantic content but learn the spurious
correlations. In this work, we propose the data augmentation and preprocessing
methods to solve the word overlap, numerical reasoning and length mismatch
problems. These methods are general methods that do not rely on the
distribution of the testing data and they help improve the robustness of the
models.

摘要：自然語言推理 (NLI) 是一項任務，用於推斷假設是否能由給定的前提證明。基本上，我們根據前提將假設分類為三種類別（蘊含、中立和矛盾）。NLI 已被先前的研究人員廣泛研究。許多模型，特別是基於轉換器的模型，已在這些任務上取得顯著進展。然而，據報導，這些模型在處理困難的資料集時會遇到困難。特別是，當處理未見過、分佈不均勻的前提和假設時，它們的表現會差很多。它們可能無法理解語義內容，但會學習虛假的關聯性。在這項工作中，我們提出資料擴充和預處理方法來解決字詞重疊、數字推理和長度不匹配的問題。這些方法是通用的方法，不依賴於測試資料的分配，它們有助於提高模型的穩健性。

##### **On Evaluating the Durability of Safeguards for Open-Weight LLMs**
2412.07097v1 by Xiangyu Qi, Boyi Wei, Nicholas Carlini, Yangsibo Huang, Tinghao Xie, Luxi He, Matthew Jagielski, Milad Nasr, Prateek Mittal, Peter Henderson

Stakeholders -- from model developers to policymakers -- seek to minimize the
dual-use risks of large language models (LLMs). An open challenge to this goal
is whether technical safeguards can impede the misuse of LLMs, even when models
are customizable via fine-tuning or when model weights are fully open. In
response, several recent studies have proposed methods to produce durable LLM
safeguards for open-weight LLMs that can withstand adversarial modifications of
the model's weights via fine-tuning. This holds the promise of raising
adversaries' costs even under strong threat models where adversaries can
directly fine-tune model weights. However, in this paper, we urge for more
careful characterization of the limits of these approaches. Through several
case studies, we demonstrate that even evaluating these defenses is exceedingly
difficult and can easily mislead audiences into thinking that safeguards are
more durable than they really are. We draw lessons from the evaluation pitfalls
that we identify and suggest future research carefully cabin claims to more
constrained, well-defined, and rigorously examined threat models, which can
provide more useful and candid assessments to stakeholders.

摘要：利害關係人（從模型開發人員到政策制定者）尋求將大型語言模型 (LLM) 的雙重使用風險降至最低。對此目標的公開挑戰在於，技術保障措施是否能阻止 LLM 的濫用，即使模型可通過微調進行自訂，或模型權重完全開放時亦然。為了解決此問題，最近有幾項研究提出方法，以產生適用於開放權重 LLM 的耐用 LLM 保障措施，這些保障措施能承受透過微調對模型權重進行的對抗性修改。這有望提高對手的成本，即使在對手可以直接微調模型權重的強威脅模型下亦然。然而，在本文中，我們敦促更仔細地描述這些方法的限制。透過多項案例研究，我們證明即使評估這些防禦措施也極其困難，並且很容易誤導受眾，讓他們認為保障措施比實際上更耐用。我們從我們辨識出的評估陷阱中汲取教訓，並建議未來的研究謹慎地將主張限制在更受限、定義明確且經過嚴格審查的威脅模型中，這可以為利害關係人提供更有用且坦率的評估。

##### **EvRepSL: Event-Stream Representation via Self-Supervised Learning for Event-Based Vision**
2412.07080v1 by Qiang Qu, Xiaoming Chen, Yuk Ying Chung, Yiran Shen

Event-stream representation is the first step for many computer vision tasks
using event cameras. It converts the asynchronous event-streams into a
formatted structure so that conventional machine learning models can be applied
easily. However, most of the state-of-the-art event-stream representations are
manually designed and the quality of these representations cannot be guaranteed
due to the noisy nature of event-streams. In this paper, we introduce a
data-driven approach aiming at enhancing the quality of event-stream
representations. Our approach commences with the introduction of a new
event-stream representation based on spatial-temporal statistics, denoted as
EvRep. Subsequently, we theoretically derive the intrinsic relationship between
asynchronous event-streams and synchronous video frames. Building upon this
theoretical relationship, we train a representation generator, RepGen, in a
self-supervised learning manner accepting EvRep as input. Finally, the
event-streams are converted to high-quality representations, termed as EvRepSL,
by going through the learned RepGen (without the need of fine-tuning or
retraining). Our methodology is rigorously validated through extensive
evaluations on a variety of mainstream event-based classification and optical
flow datasets (captured with various types of event cameras). The experimental
results highlight not only our approach's superior performance over existing
event-stream representations but also its versatility, being agnostic to
different event cameras and tasks.

摘要：事件串流表示是許多電腦視覺任務的第一步，使用事件相機。它將非同步事件串流轉換成格式化的結構，以便可以輕鬆應用傳統機器學習模型。然而，大多數最先進的事件串流表示都是人工設計的，而這些表示的品質無法保證，因為事件串流具有雜訊的特性。在本文中，我們介紹一種數據驅動的方法，旨在提升事件串流表示的品質。我們的做法從引入一種新的事件串流表示開始，該表示基於時空統計，表示為 EvRep。隨後，我們從理論上推導出非同步事件串流和同步影片幀之間的內在關係。建立在這個理論關係之上，我們訓練了一個表示產生器，RepGen，以一種自我監督學習的方式接受 EvRep 作為輸入。最後，事件串流被轉換成高品質的表示，稱為 EvRepSL，通過學習過的 RepGen（無需微調或重新訓練）。我們的做法通過對各種主流基於事件的分類和光流資料集（使用各種類型的事件相機擷取）進行廣泛評估，得到嚴格驗證。實驗結果不僅突顯了我們的方法優於現有的事件串流表示，還突顯了它的多功能性，對不同的事件相機和任務沒有偏好。

##### **Defensive Dual Masking for Robust Adversarial Defense**
2412.07078v1 by Wangli Yang, Jie Yang, Yi Guo, Johan Barthelemy

The field of textual adversarial defenses has gained considerable attention
in recent years due to the increasing vulnerability of natural language
processing (NLP) models to adversarial attacks, which exploit subtle
perturbations in input text to deceive models. This paper introduces the
Defensive Dual Masking (DDM) algorithm, a novel approach designed to enhance
model robustness against such attacks. DDM utilizes a unique adversarial
training strategy where [MASK] tokens are strategically inserted into training
samples to prepare the model to handle adversarial perturbations more
effectively. During inference, potentially adversarial tokens are dynamically
replaced with [MASK] tokens to neutralize potential threats while preserving
the core semantics of the input. The theoretical foundation of our approach is
explored, demonstrating how the selective masking mechanism strengthens the
model's ability to identify and mitigate adversarial manipulations. Our
empirical evaluation across a diverse set of benchmark datasets and attack
mechanisms consistently shows that DDM outperforms state-of-the-art defense
techniques, improving model accuracy and robustness. Moreover, when applied to
Large Language Models (LLMs), DDM also enhances their resilience to adversarial
attacks, providing a scalable defense mechanism for large-scale NLP
applications.

摘要：近年來，由於自然語言處理 (NLP) 模型越來越容易受到對抗性攻擊，而對抗性防禦領域已獲得相當大的關注，對抗性攻擊利用輸入文字中的細微擾動來欺騙模型。本文介紹了防禦性雙重遮罩 (DDM) 演算法，這是一種新穎的方法，旨在增強模型對此類攻擊的穩健性。DDM 利用一種獨特的對抗性訓練策略，將 [MASK] 標記策略性地插入訓練樣本中，以準備模型更有效地處理對抗性擾動。在推理期間，潛在的對抗性標記會動態替換為 [MASK] 標記，以在保留輸入核心語義的同時，消除潛在威脅。探討了我們方法的理論基礎，展示了選擇性遮罩機制如何增強模型識別和減輕對抗性操縱的能力。我們在各種基準資料集和攻擊機制中進行的實證評估持續顯示，DDM 優於最先進的防禦技術，改善了模型的準確性和穩健性。此外，當應用於大型語言模型 (LLM) 時，DDM 也增強了它們對抗性攻擊的韌性，為大規模 NLP 應用提供了一種可擴充的防禦機制。

##### **The Mirage of Artificial Intelligence Terms of Use Restrictions**
2412.07066v1 by Peter Henderson, Mark A. Lemley

Artificial intelligence (AI) model creators commonly attach restrictive terms
of use to both their models and their outputs. These terms typically prohibit
activities ranging from creating competing AI models to spreading
disinformation. Often taken at face value, these terms are positioned by
companies as key enforceable tools for preventing misuse, particularly in
policy dialogs. But are these terms truly meaningful? There are myriad examples
where these broad terms are regularly and repeatedly violated. Yet except for
some account suspensions on platforms, no model creator has actually tried to
enforce these terms with monetary penalties or injunctive relief. This is
likely for good reason: we think that the legal enforceability of these
licenses is questionable.
  This Article systematically assesses of the enforceability of AI model terms
of use and offers three contributions. First, we pinpoint a key problem: the
artifacts that they protect, namely model weights and model outputs, are
largely not copyrightable, making it unclear whether there is even anything to
be licensed. Second, we examine the problems this creates for other
enforcement. Recent doctrinal trends in copyright preemption may further
undermine state-law claims, while other legal frameworks like the DMCA and CFAA
offer limited recourse. Anti-competitive provisions likely fare even worse than
responsible use provisions. Third, we provide recommendations to policymakers.
There are compelling reasons for many provisions to be unenforceable: they
chill good faith research, constrain competition, and create quasi-copyright
ownership where none should exist. There are, of course, downsides: model
creators have fewer tools to prevent harmful misuse. But we think the better
approach is for statutory provisions, not private fiat, to distinguish between
good and bad uses of AI, restricting the latter.

摘要：<paragraph>人工智慧（AI）模型創建者通常會在其模型及其輸出附加限制性使用條款。這些條款通常禁止從建立競爭的 AI 模型到散布錯誤資訊的活動。這些條款通常被表面的理解，由公司定位為防止濫用的關鍵可執行工具，特別是在政策對話中。但是，這些條款真的有意義嗎？有許多範例顯示，這些廣泛的條款經常且重複地遭到違反。然而，除了平台上的一些帳戶暫停之外，沒有任何模型創建者實際嘗試以金錢處罰或禁令救濟來執行這些條款。這很可能是出於正當理由：我們認為這些許可證的法律可執行性值得懷疑。
本文系統性地評估 AI 模型使用條款的可執行性，並提供三項貢獻。首先，我們找出一個關鍵問題：它們所保護的人工製品，即模型權重和模型輸出，在很大程度上不具有著作權，這使得是否甚至有任何東西可以被許可變得不明確。其次，我們審查這對其他執法造成的問題。著作權先佔權的近期教條趨勢可能會進一步破壞州法律主張，而 DMCA 和 CFAA 等其他法律框架提供的追索權有限。反競爭條款的表現可能比負責任使用條款更糟。第三，我們向政策制定者提供建議。有許多條款無法執行的令人信服的理由：它們冷卻善意研究、限制競爭，並在不應存在的地方創造準著作權所有權。當然也有缺點：模型創建者較少工具來防止有害的濫用。但我們認為更好的方法是法定條款，而不是私人法令，來區分 AI 的好處與壞處，限制後者。</paragraph>

##### **Generative AI Impact on Labor Market: Analyzing ChatGPT's Demand in Job Advertisements**
2412.07042v1 by Mahdi Ahmadi, Neda Khosh Kheslat, Adebola Akintomide

The rapid advancement of Generative AI (Gen AI) technologies, particularly
tools like ChatGPT, is significantly impacting the labor market by reshaping
job roles and skill requirements. This study examines the demand for
ChatGPT-related skills in the U.S. labor market by analyzing job advertisements
collected from major job platforms between May and December 2023. Using text
mining and topic modeling techniques, we extracted and analyzed the Gen
AI-related skills that employers are hiring for. Our analysis identified five
distinct ChatGPT-related skill sets: general familiarity, creative content
generation, marketing, advanced functionalities (such as prompt engineering),
and product development. In addition, the study provides insights into job
attributes such as occupation titles, degree requirements, salary ranges, and
other relevant job characteristics. These findings highlight the increasing
integration of Gen AI across various industries, emphasizing the growing need
for both foundational knowledge and advanced technical skills. The study offers
valuable insights into the evolving demands of the labor market, as employers
seek candidates equipped to leverage generative AI tools to improve
productivity, streamline processes, and drive innovation.

摘要：生成式 AI (Gen AI) 技術的快速進步，尤其是 ChatGPT 等工具，透過重塑工作職能和技能需求，對勞動市場產生重大影響。本研究透過分析 2023 年 5 月至 12 月間從主要求職平台收集的求職廣告，探討美國勞動市場對 ChatGPT 相關技能的需求。我們利用文本探勘和主題建模技術，萃取和分析雇主招聘的 Gen AI 相關技能。我們的分析找出五種不同的 ChatGPT 相關技能組：一般熟悉度、創意內容產生、行銷、進階功能（例如提示工程）和產品開發。此外，本研究提供對工作屬性的見解，例如職稱、學位要求、薪資範圍和其他相關工作特徵。這些發現突顯出 Gen AI 在各產業的整合度日益提升，強調對基礎知識和進階技術技能日益增長的需求。本研究提供對勞動市場不斷變化的需求有價值的見解，因為雇主尋求具備利用生成式 AI 工具來提升生產力、簡化流程和推動創新的求職者。

##### **Large Language Models: An Applied Econometric Framework**
2412.07031v1 by Jens Ludwig, Sendhil Mullainathan, Ashesh Rambachan

Large language models (LLMs) are being used in economics research to form
predictions, label text, simulate human responses, generate hypotheses, and
even produce data for times and places where such data don't exist. While these
uses are creative, are they valid? When can we abstract away from the inner
workings of an LLM and simply rely on their outputs? We develop an econometric
framework to answer this question. Our framework distinguishes between two
types of empirical tasks. Using LLM outputs for prediction problems (including
hypothesis generation) is valid under one condition: no "leakage" between the
LLM's training dataset and the researcher's sample. Using LLM outputs for
estimation problems to automate the measurement of some economic concept
(expressed by some text or from human subjects) requires an additional
assumption: LLM outputs must be as good as the gold standard measurements they
replace. Otherwise estimates can be biased, even if LLM outputs are highly
accurate but not perfectly so. We document the extent to which these conditions
are violated and the implications for research findings in illustrative
applications to finance and political economy. We also provide guidance to
empirical researchers. The only way to ensure no training leakage is to use
open-source LLMs with documented training data and published weights. The only
way to deal with LLM measurement error is to collect validation data and model
the error structure. A corollary is that if such conditions can't be met for a
candidate LLM application, our strong advice is: don't.

摘要：大型語言模型 (LLM) 用於經濟研究中，以形成預測、標記文字、模擬人類反應、產生假設，甚至產生在時間和地點上不存在此類數據的數據。雖然這些用途具有創意性，但它們是否有效？我們何時可以從 LLM 的內部運作中抽象出來，並僅依賴於其輸出？我們開發了一個計量經濟學框架來回答這個問題。我們的框架區分了兩種類型的實證任務。在一個條件下，將 LLM 輸出用於預測問題（包括假設生成）是有效的：LLM 的訓練數據集與研究者的樣本之間沒有「洩漏」。將 LLM 輸出用於估計問題以自動化某些經濟概念的測量（由某些文本或人類受試者表達）需要一個額外的假設：LLM 輸出必須與它們所取代的黃金標準測量一樣好。否則，即使 LLM 輸出高度準確但不完美，估計值也可能存在偏差。我們記錄了這些條件被違反的程度，以及對金融和政治經濟學說明性應用中的研究結果的影響。我們還為實證研究人員提供指導。確保沒有訓練洩漏的唯一方法是使用具有已記錄訓練數據和已發布權重的開源 LLM。處理 LLM 測量誤差的唯一方法是收集驗證數據並對誤差結構建模。推論是，如果候選 LLM 應用無法滿足此類條件，我們的強烈建議是：不要。

##### **FM2DS: Few-Shot Multimodal Multihop Data Synthesis with Knowledge Distillation for Question Answering**
2412.07030v1 by Amirhossein Abaskohi, Spandana Gella, Giuseppe Carenini, Issam H. Laradji

Multimodal multihop question answering is a complex task that requires
reasoning over multiple sources of information, such as images and text, to
answer questions. While there has been significant progress in visual question
answering, the multihop setting remains unexplored due to the lack of
high-quality datasets. Current methods focus on single-hop question answering
or a single modality, which makes them unsuitable for real-world scenarios such
as analyzing multimodal educational materials, summarizing lengthy academic
articles, or interpreting scientific studies that combine charts, images, and
text. To address this gap, we propose a novel methodology, introducing the
first framework for creating a high-quality dataset that enables training
models for multimodal multihop question answering. Our approach consists of a
5-stage pipeline that involves acquiring relevant multimodal documents from
Wikipedia, synthetically generating high-level questions and answers, and
validating them through rigorous criteria to ensure quality data. We evaluate
our methodology by training models on our synthesized dataset and testing on
two benchmarks, our results demonstrate that, with an equal sample size, models
trained on our synthesized data outperform those trained on human-collected
data by 1.9 in exact match (EM) on average. We believe our data synthesis
method will serve as a strong foundation for training and evaluating multimodal
multihop question answering models.

摘要：多模态多跳問題回答是一個複雜的任務，需要對多個資訊來源（例如圖片和文字）進行推理，才能回答問題。雖然視覺問題回答方面已有顯著進展，但由於缺乏高品質的資料集，多跳設定仍然未被探討。目前的技術專注於單跳問題回答或單一模態，這使它們不適合於分析多模態教育材料、總結冗長的學術文章或詮釋結合圖表、圖片和文字的科學研究等真實世界場景。為了解決這個差距，我們提出了一種新的方法，引入了建立高品質資料集的第一個架構，以便訓練多模態多跳問題回答模型。我們的做法包括一個 5 階段管線，其中包括從維基百科中獲取相關的多模態文件、合成地產生高級問題和答案，並透過嚴格的標準驗證它們，以確保資料品質。我們透過在我們合成的資料集上訓練模型並在兩個基準上進行測試來評估我們的技術，我們的結果表明，在相等的樣本大小下，在我們合成的資料上訓練的模型比在人類收集的資料上訓練的模型在完全匹配 (EM) 上平均高出 1.9。我們相信我們的資料合成方法將作為訓練和評估多模態多跳問題回答模型的堅實基礎。

