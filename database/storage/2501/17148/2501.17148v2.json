{"2501.17148": {"publish_time": "2025-01-28", "title": "AxBench: Steering LLMs? Even Simple Baselines Outperform Sparse Autoencoders", "paper_summary": "Fine-grained steering of language model outputs is essential for safety and\nreliability. Prompting and finetuning are widely used to achieve these goals,\nbut interpretability researchers have proposed a variety of\nrepresentation-based techniques as well, including sparse autoencoders (SAEs),\nlinear artificial tomography, supervised steering vectors, linear probes, and\nrepresentation finetuning. At present, there is no benchmark for making direct\ncomparisons between these proposals. Therefore, we introduce AxBench, a\nlarge-scale benchmark for steering and concept detection, and report\nexperiments on Gemma-2-2B and 9B. For steering, we find that prompting\noutperforms all existing methods, followed by finetuning. For concept\ndetection, representation-based methods such as difference-in-means, perform\nthe best. On both evaluations, SAEs are not competitive. We introduce a novel\nweakly-supervised representational method (Rank-1 Representation Finetuning;\nReFT-r1), which is competitive on both tasks while providing the\ninterpretability advantages that prompting lacks. Along with AxBench, we train\nand publicly release SAE-scale feature dictionaries for ReFT-r1 and DiffMean.", "paper_summary_zh": "\u5fae\u8abf\u8a9e\u8a00\u6a21\u578b\u8f38\u51fa\u5c0d\u65bc\u5b89\u5168\u6027\u8207\u53ef\u9760\u6027\u81f3\u95dc\u91cd\u8981\u3002\u63d0\u793a\u8207\u5fae\u8abf\u5ee3\u6cdb\u7528\u65bc\u9054\u6210\u9019\u4e9b\u76ee\u6a19\uff0c\u4f46\u53ef\u89e3\u91cb\u6027\u7814\u7a76\u4eba\u54e1\u4e5f\u63d0\u51fa\u5404\u7a2e\u57fa\u65bc\u8868\u5fb5\u7684\u6280\u8853\uff0c\u5305\u62ec\u7a00\u758f\u81ea\u52d5\u7de8\u78bc\u5668 (SAE)\u3001\u7dda\u6027\u4eba\u5de5\u65b7\u5c64\u651d\u5f71\u3001\u76e3\u7763\u5f15\u5c0e\u5411\u91cf\u3001\u7dda\u6027\u63a2\u6e2c\u548c\u8868\u5fb5\u5fae\u8abf\u3002\u76ee\u524d\u6c92\u6709\u57fa\u6e96\u53ef\u4f9b\u5c0d\u9019\u4e9b\u63d0\u6848\u9032\u884c\u76f4\u63a5\u6bd4\u8f03\u3002\u56e0\u6b64\uff0c\u6211\u5011\u5f15\u5165\u4e86 AxBench\uff0c\u4e00\u500b\u7528\u65bc\u5f15\u5c0e\u548c\u6982\u5ff5\u6aa2\u6e2c\u7684\u5927\u898f\u6a21\u57fa\u6e96\uff0c\u4e26\u5831\u544a\u4e86\u5728 Gemma-2-2B \u548c 9B \u4e0a\u7684\u5be6\u9a57\u3002\u5c0d\u65bc\u5f15\u5c0e\uff0c\u6211\u5011\u767c\u73fe\u63d0\u793a\u512a\u65bc\u6240\u6709\u73fe\u6709\u65b9\u6cd5\uff0c\u5176\u6b21\u662f\u5fae\u8abf\u3002\u5c0d\u65bc\u6982\u5ff5\u6aa2\u6e2c\uff0c\u57fa\u65bc\u8868\u5fb5\u7684\u65b9\u6cd5\uff08\u4f8b\u5982\u5747\u503c\u5dee\uff09\u8868\u73fe\u6700\u4f73\u3002\u5728\u5169\u9805\u8a55\u4f30\u4e2d\uff0cSAE \u6c92\u6709\u7af6\u722d\u529b\u3002\u6211\u5011\u5f15\u5165\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u5f31\u76e3\u7763\u8868\u5fb5\u65b9\u6cd5\uff081 \u7d1a\u8868\u5fb5\u5fae\u8abf\uff1bReFT-r1\uff09\uff0c\u5b83\u5728\u5169\u9805\u4efb\u52d9\u4e0a\u90fd\u5177\u6709\u7af6\u722d\u529b\uff0c\u540c\u6642\u63d0\u4f9b\u4e86\u63d0\u793a\u6240\u7f3a\u4e4f\u7684\u53ef\u89e3\u91cb\u6027\u512a\u52e2\u3002\u96a8\u8457 AxBench\uff0c\u6211\u5011\u8a13\u7df4\u4e26\u516c\u958b\u767c\u5e03\u4e86 ReFT-r1 \u548c DiffMean \u7684 SAE \u7d1a\u5225\u7279\u5fb5\u5b57\u5178\u3002", "author": "Zhengxuan Wu et.al.", "authors": "Zhengxuan Wu, Aryaman Arora, Atticus Geiger, Zheng Wang, Jing Huang, Dan Jurafsky, Christopher D. Manning, Christopher Potts", "id": "2501.17148v2", "paper_url": "http://arxiv.org/abs/2501.17148v2", "repo": "null"}}