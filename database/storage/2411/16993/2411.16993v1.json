{"2411.16993": {"publish_time": "2024-11-25", "title": "Tree Transformers are an Ineffective Model of Syntactic Constituency", "paper_summary": "Linguists have long held that a key aspect of natural language syntax is the\nrecursive organization of language units into constituent structures, and\nresearch has suggested that current state-of-the-art language models lack an\ninherent bias towards this feature. A number of alternative models have been\nproposed to provide inductive biases towards constituency, including the Tree\nTransformer, which utilizes a modified attention mechanism to organize tokens\ninto constituents.\n  We investigate Tree Transformers to study whether they utilize meaningful\nand/or useful constituent structures. We pretrain a large Tree Transformer on\nlanguage modeling in order to investigate the learned constituent tree\nrepresentations of sentences, finding little evidence for meaningful\nstructures. Next, we evaluate Tree Transformers with similar transformer models\non error detection tasks requiring constituent structure. We find that while\nthe Tree Transformer models may slightly outperform at these tasks, there is\nlittle evidence to suggest a meaningful improvement. In general, we conclude\nthat there is little evidence to support Tree Transformer as an effective model\nof syntactic constituency.", "paper_summary_zh": "\u8a9e\u8a00\u5b78\u5bb6\u9577\u671f\u4ee5\u4f86\u8a8d\u70ba\u81ea\u7136\u8a9e\u8a00\u53e5\u6cd5\u7684\u95dc\u9375\u65b9\u9762\u662f\u8a9e\u8a00\u55ae\u4f4d\u905e\u8ff4\u7d44\u7e54\u6210\u7d44\u6210\u7d50\u69cb\uff0c\u800c\u7814\u7a76\u8868\u660e\uff0c\u7576\u524d\u6700\u5148\u9032\u7684\u8a9e\u8a00\u6a21\u578b\u7f3a\u4e4f\u5c0d\u6b64\u7279\u5fb5\u7684\u5167\u5728\u504f\u898b\u3002\u5df2\u7d93\u63d0\u51fa\u4e86\u8a31\u591a\u66ff\u4ee3\u6a21\u578b\u4f86\u63d0\u4f9b\u5c0d\u7d44\u6210\u6210\u5206\u7684\u6b78\u7d0d\u504f\u898b\uff0c\u5305\u62ec Tree Transformer\uff0c\u5b83\u5229\u7528\u4fee\u6539\u5f8c\u7684\u6ce8\u610f\u529b\u6a5f\u5236\u5c07\u4ee4\u724c\u7d44\u7e54\u6210\u7d44\u6210\u6210\u5206\u3002\n\u6211\u5011\u7814\u7a76 Tree Transformer \u4ee5\u7814\u7a76\u5b83\u5011\u662f\u5426\u5229\u7528\u6709\u610f\u7fa9\u548c/\u6216\u6709\u7528\u7684\u7d44\u6210\u7d50\u69cb\u3002\u6211\u5011\u5728\u8a9e\u8a00\u5efa\u6a21\u4e2d\u9810\u8a13\u7df4\u4e00\u500b\u5927\u578b Tree Transformer\uff0c\u4ee5\u7814\u7a76\u53e5\u5b50\u7684\u5b78\u7fd2\u7d44\u6210\u6a39\u8868\u793a\uff0c\u767c\u73fe\u5f88\u5c11\u6709\u6709\u610f\u7fa9\u7684\u7d50\u69cb\u8b49\u64da\u3002\u63a5\u4e0b\u4f86\uff0c\u6211\u5011\u4f7f\u7528\u985e\u4f3c\u7684Transformer\u6a21\u578b\u5c0d Tree Transformer \u9032\u884c\u8a55\u4f30\uff0c\u5c0d\u9700\u8981\u7d44\u6210\u7d50\u69cb\u7684\u932f\u8aa4\u6aa2\u6e2c\u4efb\u52d9\u9032\u884c\u8a55\u4f30\u3002\u6211\u5011\u767c\u73fe\uff0c\u96d6\u7136 Tree Transformer \u6a21\u578b\u5728\u9019\u4e9b\u4efb\u52d9\u4e0a\u53ef\u80fd\u8868\u73fe\u7565\u597d\uff0c\u4f46\u5e7e\u4e4e\u6c92\u6709\u8b49\u64da\u8868\u660e\u6709\u610f\u7fa9\u7684\u6539\u9032\u3002\u7e3d\u7684\u4f86\u8aaa\uff0c\u6211\u5011\u5f97\u51fa\u7d50\u8ad6\uff0c\u5e7e\u4e4e\u6c92\u6709\u8b49\u64da\u652f\u6301 Tree Transformer \u4f5c\u70ba\u53e5\u6cd5\u7d44\u6210\u7684\u6709\u6548\u6a21\u578b\u3002", "author": "Michael Ginn et.al.", "authors": "Michael Ginn", "id": "2411.16993v1", "paper_url": "http://arxiv.org/abs/2411.16993v1", "repo": "null"}}