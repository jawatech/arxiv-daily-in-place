{"2406.16801": {"publish_time": "2024-06-24", "title": "RES-Q: Evaluating Code-Editing Large Language Model Systems at the Repository Scale", "paper_summary": "The instruction-following ability of Large Language Models (LLMs) has\ncultivated a class of LLM-based systems capable of approaching complex tasks\nsuch as making edits to large code repositories. Due to the high sensitivity\nand unpredictability of LLM behavior in response to changes in prompting,\nrobust evaluation tools are needed to drive future iteration of these systems.\nWe propose RES-Q, a natural language instruction-based benchmark for evaluating\n$\\textbf{R}$epository $\\textbf{E}$diting $\\textbf{S}$ystems, which consists of\n100 repository editing tasks derived from real GitHub commits. Given an edit\ninstruction and a code repository, RES-Q evaluates an LLM system's ability to\ngather information and construct an edit that satisfies the criteria set by the\ninstruction. We argue that evaluating LLMs in this way addresses issues with\ntraditional benchmarks and provides a more holistic assessment of a model's\nabilities. We evaluate various state-of-the-art LLMs as language agents in a\nrepository-editing system built on Qurrent OS, our language agent development\nsoftware. Despite their 1% pass@1 performance difference on HumanEval, we find\nClaude Sonnet 3.5 outperforms GPT-4o by 12% pass@1 on RES-Q, indicating RES-Q's\ncapacity to differentiate model capability as traditional benchmarks approach\nsaturation. We further investigate token efficiency, performance relationships\nwith existing benchmarks, and interesting disparities between closed and\nopen-source LLMs. Code and dataset are available at\nhttps://github.com/Qurrent-AI/RES-Q.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u57f9\u990a\u4e86\u4e00\u985e\u57fa\u65bc LLM \u7684\u7cfb\u7d71\uff0c\u80fd\u5920\u8655\u7406\u8907\u96dc\u7684\u4efb\u52d9\uff0c\u4f8b\u5982\u5c0d\u5927\u578b\u7a0b\u5f0f\u78bc\u5132\u5b58\u5eab\u9032\u884c\u7de8\u8f2f\u3002\u7531\u65bc LLM \u884c\u70ba\u5728\u56de\u61c9\u63d0\u793a\u8b8a\u66f4\u6642\u7684\u654f\u611f\u6027\u548c\u4e0d\u53ef\u9810\u6e2c\u6027\uff0c\u56e0\u6b64\u9700\u8981\u5f37\u5065\u7684\u8a55\u4f30\u5de5\u5177\u4f86\u63a8\u52d5\u9019\u4e9b\u7cfb\u7d71\u7684\u672a\u4f86\u8fed\u4ee3\u3002\u6211\u5011\u63d0\u51fa\u4e86 RES-Q\uff0c\u4e00\u500b\u57fa\u65bc\u81ea\u7136\u8a9e\u8a00\u6307\u4ee4\u7684\u57fa\u6e96\uff0c\u7528\u65bc\u8a55\u4f30$\\textbf{R}$epository $\\textbf{E}$diting $\\textbf{S}$ystems\uff0c\u5176\u4e2d\u5305\u542b 100 \u500b\u6e90\u81ea\u771f\u5be6 GitHub \u63d0\u4ea4\u7684\u5132\u5b58\u5eab\u7de8\u8f2f\u4efb\u52d9\u3002\u7d66\u5b9a\u7de8\u8f2f\u6307\u4ee4\u548c\u7a0b\u5f0f\u78bc\u5132\u5b58\u5eab\uff0cRES-Q \u8a55\u4f30 LLM \u7cfb\u7d71\u6536\u96c6\u8cc7\u8a0a\u548c\u5efa\u69cb\u7de8\u8f2f\u7684\u80fd\u529b\uff0c\u4ee5\u6eff\u8db3\u6307\u4ee4\u8a2d\u5b9a\u7684\u6e96\u5247\u3002\u6211\u5011\u8a8d\u70ba\uff0c\u4ee5\u9019\u7a2e\u65b9\u5f0f\u8a55\u4f30 LLM \u53ef\u4ee5\u89e3\u6c7a\u50b3\u7d71\u57fa\u6e96\u7684\u554f\u984c\uff0c\u4e26\u63d0\u4f9b\u5c0d\u6a21\u578b\u80fd\u529b\u66f4\u5168\u9762\u7684\u8a55\u4f30\u3002\u6211\u5011\u8a55\u4f30\u5404\u7a2e\u6700\u5148\u9032\u7684 LLM\uff0c\u4f5c\u70ba\u5efa\u7f6e\u5728 Qurrent OS \u4e0a\u7684\u5132\u5b58\u5eab\u7de8\u8f2f\u7cfb\u7d71\u4e2d\u7684\u8a9e\u8a00\u4ee3\u7406\uff0cQurrent OS \u662f\u6211\u5011\u7684\u8a9e\u8a00\u4ee3\u7406\u958b\u767c\u8edf\u9ad4\u3002\u5118\u7ba1\u5b83\u5011\u5728 HumanEval \u4e0a\u7684 pass@1 \u6548\u80fd\u5dee\u7570\u70ba 1%\uff0c\u4f46\u6211\u5011\u767c\u73fe Claude Sonnet 3.5 \u5728 RES-Q \u4e0a\u7684 pass@1 \u6548\u80fd\u6bd4 GPT-4o \u9ad8\u51fa 12%\uff0c\u9019\u8868\u793a RES-Q \u6709\u80fd\u529b\u5340\u5206\u6a21\u578b\u80fd\u529b\uff0c\u56e0\u70ba\u50b3\u7d71\u57fa\u6e96\u63a5\u8fd1\u98fd\u548c\u3002\u6211\u5011\u9032\u4e00\u6b65\u63a2\u8a0e\u4e86\u4ee3\u5e63\u6548\u7387\u3001\u8207\u73fe\u6709\u57fa\u6e96\u7684\u6548\u80fd\u95dc\u4fc2\uff0c\u4ee5\u53ca\u5c01\u9589\u548c\u958b\u653e\u539f\u59cb\u78bc LLM \u4e4b\u9593\u7684\u6709\u8da3\u5dee\u7570\u3002\u7a0b\u5f0f\u78bc\u548c\u8cc7\u6599\u96c6\u53ef\u5728 https://github.com/Qurrent-AI/RES-Q \u53d6\u5f97\u3002", "author": "Beck LaBash et.al.", "authors": "Beck LaBash, August Rosedale, Alex Reents, Colin Wiel", "id": "2406.16801v1", "paper_url": "http://arxiv.org/abs/2406.16801v1", "repo": "https://github.com/qurrent-ai/res-q"}}