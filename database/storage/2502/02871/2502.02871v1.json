{"2502.02871": {"publish_time": "2025-02-05", "title": "Position: Multimodal Large Language Models Can Significantly Advance Scientific Reasoning", "paper_summary": "Scientific reasoning, the process through which humans apply logic, evidence,\nand critical thinking to explore and interpret scientific phenomena, is\nessential in advancing knowledge reasoning across diverse fields. However,\ndespite significant progress, current scientific reasoning models still\nstruggle with generalization across domains and often fall short of multimodal\nperception. Multimodal Large Language Models (MLLMs), which integrate text,\nimages, and other modalities, present an exciting opportunity to overcome these\nlimitations and enhance scientific reasoning. Therefore, this position paper\nargues that MLLMs can significantly advance scientific reasoning across\ndisciplines such as mathematics, physics, chemistry, and biology. First, we\npropose a four-stage research roadmap of scientific reasoning capabilities, and\nhighlight the current state of MLLM applications in scientific reasoning,\nnoting their ability to integrate and reason over diverse data types. Second,\nwe summarize the key challenges that remain obstacles to achieving MLLM's full\npotential. To address these challenges, we propose actionable insights and\nsuggestions for the future. Overall, our work offers a novel perspective on\nMLLM integration with scientific reasoning, providing the LLM community with a\nvaluable vision for achieving Artificial General Intelligence (AGI).", "paper_summary_zh": "\u79d1\u5b78\u63a8\u7406\uff0c\u5373\u4eba\u985e\u904b\u7528\u908f\u8f2f\u3001\u8b49\u64da\u548c\u6279\u5224\u6027\u601d\u7dad\u63a2\u7d22\u548c\u8a6e\u91cb\u79d1\u5b78\u73fe\u8c61\u7684\u904e\u7a0b\uff0c\u5c0d\u65bc\u63a8\u9032\u4e0d\u540c\u9818\u57df\u7684\u77e5\u8b58\u63a8\u7406\u81f3\u95dc\u91cd\u8981\u3002\u7136\u800c\uff0c\u5118\u7ba1\u53d6\u5f97\u4e86\u986f\u8457\u9032\u5c55\uff0c\u7576\u524d\u7684\u79d1\u5b78\u63a8\u7406\u6a21\u578b\u5728\u8de8\u9818\u57df\u6982\u62ec\u65b9\u9762\u4ecd\u9762\u81e8\u6311\u6230\uff0c\u4e26\u4e14\u5e38\u5e38\u7121\u6cd5\u9054\u5230\u591a\u6a21\u614b\u611f\u77e5\u3002\u6574\u5408\u6587\u672c\u3001\u5f71\u50cf\u548c\u5176\u4ed6\u6a21\u614b\u7684\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM) \u70ba\u514b\u670d\u9019\u4e9b\u9650\u5236\u4e26\u589e\u5f37\u79d1\u5b78\u63a8\u7406\u63d0\u4f9b\u4e86\u4ee4\u4eba\u8208\u596e\u7684\u6a5f\u6703\u3002\u56e0\u6b64\uff0c\u672c\u7acb\u5834\u6587\u4ef6\u8a8d\u70ba\uff0cMLLM \u53ef\u4ee5\u986f\u8457\u63a8\u9032\u6578\u5b78\u3001\u7269\u7406\u3001\u5316\u5b78\u548c\u751f\u7269\u5b78\u7b49\u5b78\u79d1\u7684\u79d1\u5b78\u63a8\u7406\u3002\u9996\u5148\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u79d1\u5b78\u63a8\u7406\u80fd\u529b\u7684\u56db\u968e\u6bb5\u7814\u7a76\u8def\u7dda\u5716\uff0c\u4e26\u91cd\u9ede\u4ecb\u7d39\u4e86 MLLM \u5728\u79d1\u5b78\u63a8\u7406\u4e2d\u7684\u61c9\u7528\u73fe\u72c0\uff0c\u4e26\u6307\u51fa\u4e86\u5b83\u5011\u6574\u5408\u548c\u63a8\u7406\u4e0d\u540c\u6578\u64da\u985e\u578b\u7684\u80fd\u529b\u3002\u5176\u6b21\uff0c\u6211\u5011\u7e3d\u7d50\u4e86\u963b\u7919 MLLM \u5145\u5206\u767c\u63ee\u5176\u6f5b\u529b\u7684\u95dc\u9375\u6311\u6230\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u53ef\u884c\u7684\u898b\u89e3\u548c\u5efa\u8b70\uff0c\u4ee5\u4f9b\u672a\u4f86\u53c3\u8003\u3002\u7e3d\u7684\u4f86\u8aaa\uff0c\u6211\u5011\u7684\u7814\u7a76\u70ba MLLM \u8207\u79d1\u5b78\u63a8\u7406\u7684\u6574\u5408\u63d0\u4f9b\u4e86\u65b0\u7684\u89c0\u9ede\uff0c\u70ba LLM \u793e\u7fa4\u63d0\u4f9b\u4e86\u5be6\u73fe\u4eba\u5de5\u901a\u7528\u667a\u6167 (AGI) \u7684\u5bf6\u8cb4\u9858\u666f\u3002", "author": "Yibo Yan et.al.", "authors": "Yibo Yan, Shen Wang, Jiahao Huo, Jingheng Ye, Zhendong Chu, Xuming Hu, Philip S. Yu, Carla Gomes, Bart Selman, Qingsong Wen", "id": "2502.02871v1", "paper_url": "http://arxiv.org/abs/2502.02871v1", "repo": "null"}}