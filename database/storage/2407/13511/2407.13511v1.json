{"2407.13511": {"publish_time": "2024-07-18", "title": "Can Open-Source LLMs Compete with Commercial Models? Exploring the Few-Shot Performance of Current GPT Models in Biomedical Tasks", "paper_summary": "Commercial large language models (LLMs), like OpenAI's GPT-4 powering ChatGPT\nand Anthropic's Claude 3 Opus, have dominated natural language processing (NLP)\nbenchmarks across different domains. New competing Open-Source alternatives\nlike Mixtral 8x7B or Llama 3 have emerged and seem to be closing the gap while\noften offering higher throughput and being less costly to use. Open-Source LLMs\ncan also be self-hosted, which makes them interesting for enterprise and\nclinical use cases where sensitive data should not be processed by third\nparties. We participated in the 12th BioASQ challenge, which is a retrieval\naugmented generation (RAG) setting, and explored the performance of current GPT\nmodels Claude 3 Opus, GPT-3.5-turbo and Mixtral 8x7b with in-context learning\n(zero-shot, few-shot) and QLoRa fine-tuning. We also explored how additional\nrelevant knowledge from Wikipedia added to the context-window of the LLM might\nimprove their performance. Mixtral 8x7b was competitive in the 10-shot setting,\nboth with and without fine-tuning, but failed to produce usable results in the\nzero-shot setting. QLoRa fine-tuning and Wikipedia context did not lead to\nmeasurable performance gains. Our results indicate that the performance gap\nbetween commercial and open-source models in RAG setups exists mainly in the\nzero-shot setting and can be closed by simply collecting few-shot examples for\ndomain-specific use cases. The code needed to rerun these experiments is\navailable through GitHub.", "paper_summary_zh": "\u5546\u696d\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u4f8b\u5982 OpenAI \u7684 GPT-4 \u652f\u63f4 ChatGPT\uff0c\u4ee5\u53ca Anthropic \u7684 Claude 3 Opus\uff0c\u5df2\u5728\u4e0d\u540c\u9818\u57df\u4e3b\u5bb0\u81ea\u7136\u8a9e\u8a00\u8655\u7406\uff08NLP\uff09\u57fa\u6e96\u3002\u65b0\u7684\u7af6\u722d\u6027\u958b\u6e90\u66ff\u4ee3\u65b9\u6848\uff0c\u4f8b\u5982 Mixtral 8x7B \u6216 Llama 3 \u5df2\u51fa\u73fe\uff0c\u4e26\u4f3c\u4e4e\u6b63\u5728\u7e2e\u5c0f\u5dee\u8ddd\uff0c\u540c\u6642\u901a\u5e38\u63d0\u4f9b\u66f4\u9ad8\u7684\u8655\u7406\u91cf\uff0c\u800c\u4e14\u4f7f\u7528\u6210\u672c\u66f4\u4f4e\u3002\u958b\u6e90 LLM \u4e5f\u53ef\u4ee5\u81ea\u884c\u8a17\u7ba1\uff0c\u9019\u4f7f\u5f97\u5b83\u5011\u5c0d\u654f\u611f\u8cc7\u6599\u4e0d\u61c9\u7531\u7b2c\u4e09\u65b9\u8655\u7406\u7684\u4f01\u696d\u548c\u81e8\u5e8a\u7528\u4f8b\u5f88\u6709\u5438\u5f15\u529b\u3002\u6211\u5011\u53c3\u52a0\u4e86\u7b2c 12 \u5c46 BioASQ \u6311\u6230\uff0c\u9019\u662f\u4e00\u500b\u6aa2\u7d22\u589e\u5f37\u751f\u6210\uff08RAG\uff09\u8a2d\u5b9a\uff0c\u4e26\u63a2\u8a0e\u4e86\u7576\u524d GPT \u6a21\u578b Claude 3 Opus\u3001GPT-3.5-turbo \u548c Mixtral 8x7b \u5728\u60c5\u5883\u5b78\u7fd2\uff08\u96f6\u6b21\u5b78\u7fd2\u3001\u5c11\u6b21\u5b78\u7fd2\uff09\u548c QLoRa \u5fae\u8abf\u4e2d\u7684\u6548\u80fd\u3002\u6211\u5011\u9084\u63a2\u8a0e\u4e86\u5f9e\u7dad\u57fa\u767e\u79d1\u65b0\u589e\u5230 LLM \u7684\u60c5\u5883\u8996\u7a97\u4e2d\u7684\u984d\u5916\u76f8\u95dc\u77e5\u8b58\u5982\u4f55\u63d0\u5347\u5176\u6548\u80fd\u3002Mixtral 8x7b \u5728 10 \u6b21\u5b78\u7fd2\u8a2d\u5b9a\u4e2d\u5177\u6709\u7af6\u722d\u529b\uff0c\u7121\u8ad6\u662f\u5426\u9032\u884c\u5fae\u8abf\uff0c\u4f46\u7121\u6cd5\u5728\u96f6\u6b21\u5b78\u7fd2\u8a2d\u5b9a\u4e2d\u7522\u751f\u53ef\u7528\u7684\u7d50\u679c\u3002QLoRa \u5fae\u8abf\u548c\u7dad\u57fa\u767e\u79d1\u60c5\u5883\u4e26\u672a\u5e36\u4f86\u53ef\u8861\u91cf\u7684\u6548\u80fd\u63d0\u5347\u3002\u6211\u5011\u7684\u7d50\u679c\u8868\u660e\uff0c\u5728 RAG \u8a2d\u5b9a\u4e2d\uff0c\u5546\u696d\u548c\u958b\u6e90\u6a21\u578b\u4e4b\u9593\u7684\u6548\u80fd\u5dee\u8ddd\u4e3b\u8981\u5b58\u5728\u65bc\u96f6\u6b21\u5b78\u7fd2\u8a2d\u5b9a\u4e2d\uff0c\u800c\u4e14\u53ef\u4ee5\u900f\u904e\u50c5\u6536\u96c6\u7279\u5b9a\u9818\u57df\u7528\u4f8b\u7684\u5c11\u6b21\u5b78\u7fd2\u7bc4\u4f8b\u4f86\u7e2e\u5c0f\u5dee\u8ddd\u3002\u57f7\u884c\u9019\u4e9b\u5be6\u9a57\u6240\u9700\u7684\u7a0b\u5f0f\u78bc\u53ef\u900f\u904e GitHub \u53d6\u5f97\u3002", "author": "Samy Ateia et.al.", "authors": "Samy Ateia, Udo Kruschwitz", "id": "2407.13511v1", "paper_url": "http://arxiv.org/abs/2407.13511v1", "repo": "null"}}