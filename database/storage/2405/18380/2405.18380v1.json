{"2405.18380": {"publish_time": "2024-05-28", "title": "OwLore: Outlier-weighed Layerwise Sampled Low-Rank Projection for Memory-Efficient LLM Fine-tuning", "paper_summary": "The rapid advancements in Large Language Models (LLMs) have revolutionized\nvarious natural language processing tasks. However, the substantial size of\nLLMs presents significant challenges in training or fine-tuning. While\nparameter-efficient approaches such as low-rank adaptation (LoRA) have gained\npopularity, they often compromise performance compared to full-rank\nfine-tuning. In this paper, we propose Outlier-weighed Layerwise Sampled\nLow-Rank Projection (OwLore), a new memory-efficient fine-tuning approach,\ninspired by the layerwise outlier distribution of LLMs, which dynamically\nsamples pre-trained layers to fine-tune instead of adding additional adaptors.\nWe first interpret the outlier phenomenon through the lens of Heavy-Tailed\nSelf-Regularization theory (HT-SR), discovering that layers with more outliers\ntend to be more heavy-tailed and consequently better trained. Inspired by this\nfinding, OwLore strategically assigns higher sampling probabilities to layers\nwith more outliers to better leverage the knowledge stored in pre-trained LLMs.\nTo further mitigate the memory demands of fine-tuning, we integrate gradient\nlow-rank projection into our approach, which facilitates each layer to be\nefficiently trained in a low-rank manner. By incorporating the efficient\ncharacteristics of low-rank and optimal layerwise sampling, OwLore\nsignificantly improves the memory-performance trade-off in LLM pruning. Our\nextensive experiments across various architectures, including LLaMa2, LLaMa3,\nand Mistral, demonstrate that OwLore consistently outperforms baseline\napproaches, including full fine-tuning. Specifically, it achieves up to a 1.1%\naverage accuracy gain on the Commonsense Reasoning benchmark, a 3.0%\nimprovement on MMLU, and a notable 10% boost on MT-Bench, while being more\nmemory efficient. OwLore allows us to fine-tune LLaMa2-7B with only 21GB of\nmemory.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5feb\u901f\u9032\u5c55\u5df2\u7d93\u5fb9\u5e95\u6539\u8b8a\u4e86\u5404\u7a2e\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4efb\u52d9\u3002\u7136\u800c\uff0cLLM \u9f90\u5927\u7684\u898f\u6a21\u5728\u8a13\u7df4\u6216\u5fae\u8abf\u65b9\u9762\u5e36\u4f86\u4e86\u986f\u8457\u7684\u6311\u6230\u3002\u96d6\u7136\u4f4e\u79e9\u9069\u61c9 (LoRA) \u7b49\u53c3\u6578\u9ad8\u6548\u65b9\u6cd5\u5df2\u7d93\u5ee3\u53d7\u6b61\u8fce\uff0c\u4f46\u8207\u5168\u79e9\u5fae\u8abf\u76f8\u6bd4\uff0c\u5b83\u5011\u901a\u5e38\u6703\u5f71\u97ff\u6548\u80fd\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u7570\u5e38\u52a0\u6b0a\u5c64\u7d1a\u63a1\u6a23\u4f4e\u79e9\u6295\u5f71 (OwLore)\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7684\u8a18\u61b6\u9ad4\u9ad8\u6548\u5fae\u8abf\u65b9\u6cd5\uff0c\u9748\u611f\u4f86\u81ea LLM \u7684\u5c64\u7d1a\u7570\u5e38\u5206\u4f48\uff0c\u5b83\u52d5\u614b\u63a1\u6a23\u9810\u8a13\u7df4\u5c64\u9032\u884c\u5fae\u8abf\uff0c\u800c\u4e0d\u662f\u65b0\u589e\u984d\u5916\u7684\u9069\u914d\u5668\u3002\u6211\u5011\u9996\u5148\u900f\u904e\u91cd\u5c3e\u81ea\u6b63\u898f\u5316\u7406\u8ad6 (HT-SR) \u7684\u89d2\u5ea6\u4f86\u8a6e\u91cb\u7570\u5e38\u73fe\u8c61\uff0c\u767c\u73fe\u5177\u6709\u8f03\u591a\u7570\u5e38\u503c\u7684\u5c64\u7d1a\u50be\u5411\u65bc\u8f03\u91cd\u5c3e\uff0c\u56e0\u6b64\u8a13\u7df4\u6548\u679c\u8f03\u4f73\u3002\u53d7\u5230\u6b64\u767c\u73fe\u7684\u555f\u767c\uff0cOwLore \u7b56\u7565\u6027\u5730\u5c07\u8f03\u9ad8\u7684\u63a1\u6a23\u6a5f\u7387\u5206\u914d\u7d66\u5177\u6709\u8f03\u591a\u7570\u5e38\u503c\u7684\u5c64\u7d1a\uff0c\u4ee5\u66f4\u597d\u5730\u5229\u7528\u5132\u5b58\u5728\u9810\u8a13\u7df4 LLM \u4e2d\u7684\u77e5\u8b58\u3002\u70ba\u4e86\u9032\u4e00\u6b65\u964d\u4f4e\u5fae\u8abf\u7684\u8a18\u61b6\u9ad4\u9700\u6c42\uff0c\u6211\u5011\u5c07\u68af\u5ea6\u4f4e\u79e9\u6295\u5f71\u6574\u5408\u5230\u6211\u5011\u7684\u505a\u6cd5\u4e2d\uff0c\u9019\u6709\u52a9\u65bc\u4ee5\u4f4e\u79e9\u65b9\u5f0f\u6709\u6548\u7387\u5730\u8a13\u7df4\u6bcf\u500b\u5c64\u7d1a\u3002\u900f\u904e\u7d50\u5408\u4f4e\u79e9\u548c\u6700\u4f73\u5c64\u7d1a\u63a1\u6a23\u7684\u6709\u6548\u7279\u6027\uff0cOwLore \u5927\u5e45\u6539\u5584\u4e86 LLM \u526a\u679d\u4e2d\u7684\u8a18\u61b6\u9ad4\u6548\u80fd\u6b0a\u8861\u3002\u6211\u5011\u5728\u5404\u7a2e\u67b6\u69cb\uff08\u5305\u62ec LLaMa2\u3001LLaMa3 \u548c Mistral\uff09\u4e2d\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u8b49\u660e\uff0cOwLore \u6301\u7e8c\u512a\u65bc\u57fa\u7dda\u65b9\u6cd5\uff0c\u5305\u62ec\u5168\u5fae\u8abf\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u5b83\u5728\u5e38\u8b58\u63a8\u7406\u57fa\u6e96\u4e0a\u7372\u5f97\u9ad8\u9054 1.1% \u7684\u5e73\u5747\u6e96\u78ba\u5ea6\u63d0\u5347\uff0c\u5728 MMLU \u4e0a\u63d0\u5347 3.0%\uff0c\u5728 MT-Bench \u4e0a\u63d0\u5347 10%\uff0c\u540c\u6642\u66f4\u5177\u8a18\u61b6\u9ad4\u6548\u7387\u3002OwLore \u8b93\u6211\u5011\u80fd\u5920\u50c5\u4f7f\u7528 21GB \u7684\u8a18\u61b6\u9ad4\u5fae\u8abf LLaMa2-7B\u3002", "author": "Pengxiang Li et.al.", "authors": "Pengxiang Li, Lu Yin, Xiaowei Gao, Shiwei Liu", "id": "2405.18380v1", "paper_url": "http://arxiv.org/abs/2405.18380v1", "repo": "https://github.com/pixeli99/owlore"}}