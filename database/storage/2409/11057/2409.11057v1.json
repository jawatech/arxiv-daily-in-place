{"2409.11057": {"publish_time": "2024-09-17", "title": "KVPruner: Structural Pruning for Faster and Memory-Efficient Large Language Models", "paper_summary": "The bottleneck associated with the key-value(KV) cache presents a significant\nchallenge during the inference processes of large language models. While depth\npruning accelerates inference, it requires extensive recovery training, which\ncan take up to two weeks. On the other hand, width pruning retains much of the\nperformance but offers slight speed gains. To tackle these challenges, we\npropose KVPruner to improve model efficiency while maintaining performance. Our\nmethod uses global perplexity-based analysis to determine the importance ratio\nfor each block and provides multiple strategies to prune non-essential KV\nchannels within blocks. Compared to the original model, KVPruner reduces\nruntime memory usage by 50% and boosts throughput by over 35%. Additionally,\nour method requires only two hours of LoRA fine-tuning on small datasets to\nrecover most of the performance.", "paper_summary_zh": "\u8207\u9375\u503c (KV) \u5feb\u53d6\u76f8\u95dc\u7684\u74f6\u9838\u5728\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u63a8\u8ad6\u904e\u7a0b\u4e2d\u6703\u9020\u6210\u91cd\u5927\u7684\u6311\u6230\u3002\u5118\u7ba1\u6df1\u5ea6\u526a\u679d\u53ef\u4ee5\u52a0\u901f\u63a8\u8ad6\uff0c\u4f46\u9700\u8981\u5ee3\u6cdb\u7684\u6062\u5fa9\u8a13\u7df4\uff0c\u9019\u53ef\u80fd\u9700\u8981\u9577\u9054\u5169\u9031\u7684\u6642\u9593\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u5bec\u5ea6\u526a\u679d\u4fdd\u7559\u4e86\u5927\u90e8\u5206\u6548\u80fd\uff0c\u4f46\u63d0\u4f9b\u4e86\u8f15\u5fae\u7684\u901f\u5ea6\u63d0\u5347\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa KVPruner\uff0c\u4ee5\u5728\u7dad\u6301\u6548\u80fd\u7684\u540c\u6642\u63d0\u5347\u6a21\u578b\u6548\u7387\u3002\u6211\u5011\u7684\u505a\u6cd5\u4f7f\u7528\u57fa\u65bc\u5168\u5c40\u56f0\u60d1\u5ea6\u7684\u5206\u6790\u4f86\u78ba\u5b9a\u6bcf\u500b\u5340\u584a\u7684\u91cd\u8981\u6027\u6bd4\u4f8b\uff0c\u4e26\u63d0\u4f9b\u591a\u7a2e\u7b56\u7565\u4f86\u526a\u9664\u5340\u584a\u4e2d\u975e\u5fc5\u8981\u7684 KV \u901a\u9053\u3002\u8207\u539f\u59cb\u6a21\u578b\u76f8\u6bd4\uff0cKVPruner \u5c07\u57f7\u884c\u6642\u9593\u8a18\u61b6\u9ad4\u4f7f\u7528\u91cf\u6e1b\u5c11\u4e86 50%\uff0c\u4e26\u5c07\u541e\u5410\u91cf\u63d0\u5347\u4e86 35% \u4ee5\u4e0a\u3002\u6b64\u5916\uff0c\u6211\u5011\u7684\u505a\u6cd5\u53ea\u9700\u8981\u5728\u5c0f\u578b\u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u5169\u5c0f\u6642\u7684 LoRA \u5fae\u8abf\uff0c\u5c31\u80fd\u5920\u6062\u5fa9\u5927\u90e8\u5206\u6548\u80fd\u3002", "author": "Bo Lv et.al.", "authors": "Bo Lv, Quan Zhou, Xuanang Ding, Yan Wang, Zeming Ma", "id": "2409.11057v1", "paper_url": "http://arxiv.org/abs/2409.11057v1", "repo": "null"}}