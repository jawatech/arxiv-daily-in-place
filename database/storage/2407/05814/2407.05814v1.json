{"2407.05814": {"publish_time": "2024-07-08", "title": "Cross-domain Few-shot In-context Learning for Enhancing Traffic Sign Recognition", "paper_summary": "Recent multimodal large language models (MLLM) such as GPT-4o and GPT-4v have\nshown great potential in autonomous driving. In this paper, we propose a\ncross-domain few-shot in-context learning method based on the MLLM for\nenhancing traffic sign recognition (TSR). We first construct a traffic sign\ndetection network based on Vision Transformer Adapter and an extraction module\nto extract traffic signs from the original road images. To reduce the\ndependence on training data and improve the performance stability of\ncross-country TSR, we introduce a cross-domain few-shot in-context learning\nmethod based on the MLLM. To enhance MLLM's fine-grained recognition ability of\ntraffic signs, the proposed method generates corresponding description texts\nusing template traffic signs. These description texts contain key information\nabout the shape, color, and composition of traffic signs, which can stimulate\nthe ability of MLLM to perceive fine-grained traffic sign categories. By using\nthe description texts, our method reduces the cross-domain differences between\ntemplate and real traffic signs. Our approach requires only simple and uniform\ntextual indications, without the need for large-scale traffic sign images and\nlabels. We perform comprehensive evaluations on the German traffic sign\nrecognition benchmark dataset, the Belgium traffic sign dataset, and two\nreal-world datasets taken from Japan. The experimental results show that our\nmethod significantly enhances the TSR performance.", "paper_summary_zh": "\u6700\u8fd1\u7684\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b (MLLM)\uff0c\u4f8b\u5982 GPT-4o \u548c GPT-4v\uff0c\u5728\u81ea\u52a8\u9a7e\u9a76\u65b9\u9762\u663e\u793a\u51fa\u5de8\u5927\u7684\u6f5c\u529b\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e MLLM \u7684\u8de8\u57df\u5c0f\u6837\u672c\u60c5\u5883\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u589e\u5f3a\u4ea4\u901a\u6807\u5fd7\u8bc6\u522b (TSR)\u3002\u6211\u4eec\u9996\u5148\u57fa\u4e8e Vision Transformer \u9002\u914d\u5668\u6784\u5efa\u4e00\u4e2a\u4ea4\u901a\u6807\u5fd7\u68c0\u6d4b\u7f51\u7edc\u548c\u4e00\u4e2a\u63d0\u53d6\u6a21\u5757\uff0c\u4ece\u539f\u59cb\u9053\u8def\u56fe\u50cf\u4e2d\u63d0\u53d6\u4ea4\u901a\u6807\u5fd7\u3002\u4e3a\u4e86\u51cf\u5c11\u5bf9\u8bad\u7ec3\u6570\u636e\u7684\u4f9d\u8d56\u5e76\u63d0\u9ad8\u8de8\u56fd TSR \u7684\u6027\u80fd\u7a33\u5b9a\u6027\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u57fa\u4e8e MLLM \u7684\u8de8\u57df\u5c0f\u6837\u672c\u60c5\u5883\u5b66\u4e60\u65b9\u6cd5\u3002\u4e3a\u4e86\u589e\u5f3a MLLM \u5bf9\u4ea4\u901a\u6807\u5fd7\u7684\u7ec6\u7c92\u5ea6\u8bc6\u522b\u80fd\u529b\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4f7f\u7528\u6a21\u677f\u4ea4\u901a\u6807\u5fd7\u751f\u6210\u76f8\u5e94\u7684\u63cf\u8ff0\u6587\u672c\u3002\u8fd9\u4e9b\u63cf\u8ff0\u6587\u672c\u5305\u542b\u6709\u5173\u4ea4\u901a\u6807\u5fd7\u7684\u5f62\u72b6\u3001\u989c\u8272\u548c\u6784\u6210\u7684\u5173\u952e\u4fe1\u606f\uff0c\u53ef\u4ee5\u6fc0\u53d1 MLLM \u611f\u77e5\u7ec6\u7c92\u5ea6\u4ea4\u901a\u6807\u5fd7\u7c7b\u522b\u7684\u80fd\u529b\u3002\u901a\u8fc7\u4f7f\u7528\u63cf\u8ff0\u6587\u672c\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u51cf\u5c11\u4e86\u6a21\u677f\u548c\u771f\u5b9e\u4ea4\u901a\u6807\u5fd7\u4e4b\u95f4\u7684\u8de8\u57df\u5dee\u5f02\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u53ea\u9700\u8981\u7b80\u5355\u4e14\u7edf\u4e00\u7684\u6587\u672c\u6307\u793a\uff0c\u800c\u4e0d\u9700\u8981\u5927\u89c4\u6a21\u7684\u4ea4\u901a\u6807\u5fd7\u56fe\u50cf\u548c\u6807\u7b7e\u3002\u6211\u4eec\u5728\u5fb7\u56fd\u4ea4\u901a\u6807\u5fd7\u8bc6\u522b\u57fa\u51c6\u6570\u636e\u96c6\u3001\u6bd4\u5229\u65f6\u4ea4\u901a\u6807\u5fd7\u6570\u636e\u96c6\u548c\u4e24\u4e2a\u53d6\u81ea\u65e5\u672c\u7684\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u6267\u884c\u4e86\u5168\u9762\u8bc4\u4f30\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u663e\u7740\u63d0\u9ad8\u4e86 TSR \u6027\u80fd\u3002", "author": "Yaozong Gan et.al.", "authors": "Yaozong Gan, Guang Li, Ren Togo, Keisuke Maeda, Takahiro Ogawa, Miki Haseyama", "id": "2407.05814v1", "paper_url": "http://arxiv.org/abs/2407.05814v1", "repo": "null"}}