{"2501.09972": {"publish_time": "2025-01-17", "title": "GVMGen: A General Video-to-Music Generation Model with Hierarchical Attentions", "paper_summary": "Composing music for video is essential yet challenging, leading to a growing\ninterest in automating music generation for video applications. Existing\napproaches often struggle to achieve robust music-video correspondence and\ngenerative diversity, primarily due to inadequate feature alignment methods and\ninsufficient datasets. In this study, we present General Video-to-Music\nGeneration model (GVMGen), designed for generating high-related music to the\nvideo input. Our model employs hierarchical attentions to extract and align\nvideo features with music in both spatial and temporal dimensions, ensuring the\npreservation of pertinent features while minimizing redundancy. Remarkably, our\nmethod is versatile, capable of generating multi-style music from different\nvideo inputs, even in zero-shot scenarios. We also propose an evaluation model\nalong with two novel objective metrics for assessing video-music alignment.\nAdditionally, we have compiled a large-scale dataset comprising diverse types\nof video-music pairs. Experimental results demonstrate that GVMGen surpasses\nprevious models in terms of music-video correspondence, generative diversity,\nand application universality.", "paper_summary_zh": "\u70ba\u5f71\u7247\u8b5c\u66f2\u81f3\u95dc\u91cd\u8981\u537b\u5145\u6eff\u6311\u6230\uff0c\u56e0\u6b64\u81ea\u52d5\u5316\u5f71\u7247\u61c9\u7528\u7a0b\u5f0f\u97f3\u6a02\u751f\u6210\u5099\u53d7\u95dc\u6ce8\u3002\u73fe\u6709\u505a\u6cd5\u5728\u9054\u6210\u7a69\u5065\u7684\u97f3\u6a02\u5f71\u7247\u5c0d\u61c9\u548c\u751f\u6210\u591a\u6a23\u6027\u65b9\u9762\u5f80\u5f80\u6703\u9047\u5230\u56f0\u96e3\uff0c\u4e3b\u8981\u662f\u7531\u65bc\u7279\u5fb5\u5c0d\u9f4a\u65b9\u6cd5\u4e0d\u8db3\u548c\u8cc7\u6599\u96c6\u4e0d\u8db3\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u901a\u7528\u5f71\u7247\u8f49\u97f3\u6a02\u751f\u6210\u6a21\u578b (GVMGen)\uff0c\u65e8\u5728\u70ba\u5f71\u7247\u8f38\u5165\u7522\u751f\u9ad8\u5ea6\u76f8\u95dc\u7684\u97f3\u6a02\u3002\u6211\u5011\u7684\u6a21\u578b\u63a1\u7528\u968e\u5c64\u5f0f\u6ce8\u610f\u529b\u4f86\u8403\u53d6\u548c\u5c0d\u9f4a\u5f71\u7247\u7279\u5fb5\u8207\u97f3\u6a02\u5728\u7a7a\u9593\u548c\u6642\u9593\u7dad\u5ea6\uff0c\u78ba\u4fdd\u4fdd\u7559\u76f8\u95dc\u7279\u5fb5\u4e26\u5c07\u5197\u9918\u964d\u81f3\u6700\u4f4e\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u6211\u5011\u7684\u65b9\u6cd5\u7528\u9014\u5ee3\u6cdb\uff0c\u80fd\u5920\u5f9e\u4e0d\u540c\u7684\u5f71\u7247\u8f38\u5165\u4e2d\u751f\u6210\u591a\u7a2e\u98a8\u683c\u7684\u97f3\u6a02\uff0c\u5373\u4f7f\u5728\u96f6\u6b21\u5b78\u7fd2\u5834\u666f\u4e2d\u4e5f\u80fd\u505a\u5230\u3002\u6211\u5011\u9084\u63d0\u51fa\u4e00\u500b\u8a55\u4f30\u6a21\u578b\uff0c\u4e26\u63d0\u51fa\u5169\u500b\u65b0\u7684\u5ba2\u89c0\u6307\u6a19\u4f86\u8a55\u4f30\u5f71\u7247\u97f3\u6a02\u5c0d\u9f4a\u3002\u6b64\u5916\uff0c\u6211\u5011\u7de8\u5236\u4e86\u4e00\u500b\u5305\u542b\u5404\u7a2e\u5f71\u7247\u97f3\u6a02\u914d\u5c0d\u7684\u5927\u898f\u6a21\u8cc7\u6599\u96c6\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0cGVMGen \u5728\u97f3\u6a02\u5f71\u7247\u5c0d\u61c9\u3001\u751f\u6210\u591a\u6a23\u6027\u548c\u61c9\u7528\u901a\u7528\u6027\u65b9\u9762\u90fd\u8d85\u8d8a\u4e86\u5148\u524d\u7684\u6a21\u578b\u3002", "author": "Heda Zuo et.al.", "authors": "Heda Zuo, Weitao You, Junxian Wu, Shihong Ren, Pei Chen, Mingxu Zhou, Yujia Lu, Lingyun Sun", "id": "2501.09972v1", "paper_url": "http://arxiv.org/abs/2501.09972v1", "repo": "null"}}