{"2408.14380": {"publish_time": "2024-08-26", "title": "Probing Causality Manipulation of Large Language Models", "paper_summary": "Large language models (LLMs) have shown various ability on natural language\nprocessing, including problems about causality. It is not intuitive for LLMs to\ncommand causality, since pretrained models usually work on statistical\nassociations, and do not focus on causes and effects in sentences. So that\nprobing internal manipulation of causality is necessary for LLMs. This paper\nproposes a novel approach to probe causality manipulation hierarchically, by\nproviding different shortcuts to models and observe behaviors. We exploit\nretrieval augmented generation (RAG) and in-context learning (ICL) for models\non a designed causality classification task. We conduct experiments on\nmainstream LLMs, including GPT-4 and some smaller and domain-specific models.\nOur results suggest that LLMs can detect entities related to causality and\nrecognize direct causal relationships. However, LLMs lack specialized cognition\nfor causality, merely treating them as part of the global semantic of the\nsentence.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4e2d\u5c55\u73fe\u4e86\u5404\u7a2e\u80fd\u529b\uff0c\u5305\u62ec\u56e0\u679c\u95dc\u4fc2\u554f\u984c\u3002\u5c0d\u65bc LLM \u4f86\u8aaa\uff0c\u7406\u89e3\u56e0\u679c\u95dc\u4fc2\u4e26\u975e\u76f4\u89ba\uff0c\u56e0\u70ba\u9810\u8a13\u7df4\u6a21\u578b\u901a\u5e38\u5efa\u7acb\u65bc\u7d71\u8a08\u95dc\u806f\uff0c\u4e26\u4e0d\u5c08\u6ce8\u65bc\u53e5\u5b50\u4e2d\u7684\u539f\u56e0\u548c\u7d50\u679c\u3002\u56e0\u6b64\uff0c\u63a2\u8a0e LLM \u5c0d\u56e0\u679c\u95dc\u4fc2\u7684\u5167\u90e8\u64cd\u4f5c\u662f\u5fc5\u8981\u7684\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u65b9\u6cd5\uff0c\u900f\u904e\u63d0\u4f9b\u4e0d\u540c\u7684\u6377\u5f91\u7d66\u6a21\u578b\u4e26\u89c0\u5bdf\u884c\u70ba\uff0c\u4f86\u5206\u5c64\u63a2\u8a0e\u56e0\u679c\u95dc\u4fc2\u64cd\u4f5c\u3002\u6211\u5011\u5229\u7528\u6aa2\u7d22\u64f4\u589e\u751f\u6210 (RAG) \u548c\u60c5\u5883\u5167\u5b78\u7fd2 (ICL) \u4f86\u8655\u7406\u6a21\u578b\u5728\u8a2d\u8a08\u7684\u56e0\u679c\u95dc\u4fc2\u5206\u985e\u4efb\u52d9\u4e0a\u3002\u6211\u5011\u5c0d\u4e3b\u6d41 LLM \u9032\u884c\u5be6\u9a57\uff0c\u5305\u62ec GPT-4 \u548c\u4e00\u4e9b\u8f03\u5c0f\u4e14\u7279\u5b9a\u65bc\u9818\u57df\u7684\u6a21\u578b\u3002\u6211\u5011\u7684\u7d50\u679c\u8868\u660e\uff0cLLM \u53ef\u4ee5\u5075\u6e2c\u8207\u56e0\u679c\u95dc\u4fc2\u76f8\u95dc\u7684\u5be6\u9ad4\uff0c\u4e26\u8fa8\u8b58\u76f4\u63a5\u7684\u56e0\u679c\u95dc\u4fc2\u3002\u7136\u800c\uff0cLLM \u7f3a\u4e4f\u5c0d\u56e0\u679c\u95dc\u4fc2\u7684\u5c08\u9580\u8a8d\u77e5\uff0c\u50c5\u5c07\u5176\u8996\u70ba\u53e5\u5b50\u6574\u9ad4\u8a9e\u610f\u7684\u90e8\u5206\u3002", "author": "Chenyang Zhang et.al.", "authors": "Chenyang Zhang, Haibo Tong, Bin Zhang, Dongyu Zhang", "id": "2408.14380v1", "paper_url": "http://arxiv.org/abs/2408.14380v1", "repo": "https://github.com/tongjinlp/llm-causality-probing"}}