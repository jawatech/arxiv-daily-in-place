{"2409.01790": {"publish_time": "2024-09-03", "title": "Training on the Benchmark Is Not All You Need", "paper_summary": "The success of Large Language Models (LLMs) relies heavily on the huge amount\nof pre-training data learned in the pre-training phase. The opacity of the\npre-training process and the training data causes the results of many benchmark\ntests to become unreliable. If any model has been trained on a benchmark test\nset, it can seriously hinder the health of the field. In order to automate and\nefficiently test the capabilities of large language models, numerous mainstream\nbenchmarks adopt a multiple-choice format. As the swapping of the contents of\nmultiple-choice options does not affect the meaning of the question itself, we\npropose a simple and effective data leakage detection method based on this\nproperty. Specifically, we shuffle the contents of the options in the data to\ngenerate the corresponding derived data sets, and then detect data leakage\nbased on the model's log probability distribution over the derived data sets.\nIf there is a maximum and outlier in the set of log probabilities, it indicates\nthat the data is leaked. Our method is able to work under black-box conditions\nwithout access to model training data or weights, effectively identifying data\nleakage from benchmark test sets in model pre-training data, including both\nnormal scenarios and complex scenarios where options may have been shuffled\nintentionally or unintentionally. Through experiments based on two LLMs and\nbenchmark designs, we demonstrate the effectiveness of our method. In addition,\nwe evaluate the degree of data leakage of 31 mainstream open-source LLMs on\nfour benchmark datasets and give a ranking of the leaked LLMs for each\nbenchmark, and we find that the Qwen family of LLMs has the highest degree of\ndata leakage.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u6210\u529f\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u53d6\u6c7a\u65bc\u9810\u8a13\u7df4\u968e\u6bb5\u4e2d\u5b78\u7fd2\u5230\u7684\u6d77\u91cf\u9810\u8a13\u7df4\u6578\u64da\u3002\u9810\u8a13\u7df4\u904e\u7a0b\u548c\u8a13\u7df4\u6578\u64da\u7684\u4e0d\u900f\u660e\u6027\u5c0e\u81f4\u8a31\u591a\u57fa\u6e96\u6e2c\u8a66\u7684\u7d50\u679c\u8b8a\u5f97\u4e0d\u53ef\u9760\u3002\u5982\u679c\u4efb\u4f55\u6a21\u578b\u5df2\u5728\u57fa\u6e96\u6e2c\u8a66\u96c6\u4e2d\u9032\u884c\u8a13\u7df4\uff0c\u5247\u53ef\u80fd\u6703\u56b4\u91cd\u963b\u7919\u8a72\u9818\u57df\u7684\u767c\u5c55\u3002\u70ba\u4e86\u81ea\u52d5\u5316\u4e14\u6709\u6548\u5730\u6e2c\u8a66\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u80fd\u529b\uff0c\u8a31\u591a\u4e3b\u6d41\u57fa\u6e96\u63a1\u7528\u591a\u9078\u984c\u683c\u5f0f\u3002\u7531\u65bc\u591a\u9078\u984c\u9078\u9805\u5167\u5bb9\u7684\u4e92\u63db\u4e0d\u5f71\u97ff\u554f\u984c\u672c\u8eab\u7684\u542b\u7fa9\uff0c\u56e0\u6b64\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u57fa\u65bc\u6b64\u5c6c\u6027\u7684\u7c21\u55ae\u4e14\u6709\u6548\u7684\u6570\u636e\u6d29\u6f0f\u6aa2\u6e2c\u65b9\u6cd5\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u5c07\u6578\u64da\u4e2d\u9078\u9805\u7684\u5167\u5bb9\u96a8\u6a5f\u6392\u5217\u4ee5\u751f\u6210\u5c0d\u61c9\u7684\u6d3e\u751f\u6578\u64da\u96c6\uff0c\u7136\u5f8c\u6839\u64da\u6a21\u578b\u5728\u6d3e\u751f\u6578\u64da\u96c6\u4e0a\u7684\u5c0d\u6578\u6982\u7387\u5206\u4f48\u6aa2\u6e2c\u6578\u64da\u6d29\u6f0f\u3002\u5982\u679c\u5c0d\u6578\u6982\u7387\u96c6\u4e2d\u5b58\u5728\u6700\u5927\u503c\u548c\u7570\u5e38\u503c\uff0c\u5247\u8868\u793a\u6578\u64da\u5df2\u6d29\u6f0f\u3002\u6211\u5011\u7684\u65b9\u6cd5\u80fd\u5920\u5728\u4e0d\u8a2a\u554f\u6a21\u578b\u8a13\u7df4\u6578\u64da\u6216\u6b0a\u91cd\u7684\u9ed1\u76d2\u689d\u4ef6\u4e0b\u5de5\u4f5c\uff0c\u6709\u6548\u5730\u8b58\u5225\u6a21\u578b\u9810\u8a13\u7df4\u6578\u64da\u4e2d\u57fa\u6e96\u6e2c\u8a66\u96c6\u7684\u6578\u64da\u6d29\u6f0f\uff0c\u5305\u62ec\u9078\u9805\u53ef\u80fd\u5df2\u6709\u610f\u6216\u7121\u610f\u5730\u88ab\u6253\u4e82\u7684\u6b63\u5e38\u5834\u666f\u548c\u8907\u96dc\u5834\u666f\u3002\u901a\u904e\u57fa\u65bc\u5169\u500b LLM \u548c\u57fa\u6e96\u8a2d\u8a08\u7684\u5be6\u9a57\uff0c\u6211\u5011\u8b49\u660e\u4e86\u6211\u5011\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u6b64\u5916\uff0c\u6211\u5011\u8a55\u4f30\u4e86 31 \u500b\u4e3b\u6d41\u958b\u6e90 LLM \u5728\u56db\u500b\u57fa\u6e96\u6578\u64da\u96c6\u4e0a\u7684\u6578\u64da\u6d29\u6f0f\u7a0b\u5ea6\uff0c\u4e26\u5c0d\u6bcf\u500b\u57fa\u6e96\u7684\u6d29\u6f0f LLM \u9032\u884c\u4e86\u6392\u540d\uff0c\u6211\u5011\u767c\u73fe Qwen \u5bb6\u65cf\u7684 LLM \u5177\u6709\u6700\u9ad8\u7684\u6578\u64da\u6d29\u6f0f\u7a0b\u5ea6\u3002", "author": "Shiwen Ni et.al.", "authors": "Shiwen Ni, Xiangtao Kong, Chengming Li, Xiping Hu, Ruifeng Xu, Jia Zhu, Min Yang", "id": "2409.01790v1", "paper_url": "http://arxiv.org/abs/2409.01790v1", "repo": "null"}}