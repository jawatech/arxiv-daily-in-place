{"2406.11138": {"publish_time": "2024-06-17", "title": "Diffusion Models in Low-Level Vision: A Survey", "paper_summary": "Deep generative models have garnered significant attention in low-level\nvision tasks due to their generative capabilities. Among them, diffusion\nmodel-based solutions, characterized by a forward diffusion process and a\nreverse denoising process, have emerged as widely acclaimed for their ability\nto produce samples of superior quality and diversity. This ensures the\ngeneration of visually compelling results with intricate texture information.\nDespite their remarkable success, a noticeable gap exists in a comprehensive\nsurvey that amalgamates these pioneering diffusion model-based works and\norganizes the corresponding threads. This paper proposes the comprehensive\nreview of diffusion model-based techniques. We present three generic diffusion\nmodeling frameworks and explore their correlations with other deep generative\nmodels, establishing the theoretical foundation. Following this, we introduce a\nmulti-perspective categorization of diffusion models, considering both the\nunderlying framework and the target task. Additionally, we summarize extended\ndiffusion models applied in other tasks, including medical, remote sensing, and\nvideo scenarios. Moreover, we provide an overview of commonly used benchmarks\nand evaluation metrics. We conduct a thorough evaluation, encompassing both\nperformance and efficiency, of diffusion model-based techniques in three\nprominent tasks. Finally, we elucidate the limitations of current diffusion\nmodels and propose seven intriguing directions for future research. This\ncomprehensive examination aims to facilitate a profound understanding of the\nlandscape surrounding denoising diffusion models in the context of low-level\nvision tasks. A curated list of diffusion model-based techniques in over 20\nlow-level vision tasks can be found at\nhttps://github.com/ChunmingHe/awesome-diffusion-models-in-low-level-vision.", "paper_summary_zh": "\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u5728\u4f4e\u5c42\u6b21\u89c6\u89c9\u4efb\u52a1\u4e2d\u83b7\u5f97\u4e86\u663e\u8457\u7684\u5173\u6ce8\uff0c\u56e0\u4e3a\u5b83\u4eec\u5177\u6709\u751f\u6210\u80fd\u529b\u3002\u5176\u4e2d\uff0c\u4ee5\u6b63\u5411\u6269\u6563\u8fc7\u7a0b\u548c\u53cd\u5411\u53bb\u566a\u8fc7\u7a0b\u4e3a\u7279\u5f81\u7684\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u56e0\u5176\u751f\u6210\u66f4\u9ad8\u8d28\u91cf\u548c\u591a\u6837\u6027\u6837\u672c\u7684\u80fd\u529b\u800c\u5907\u53d7\u8d5e\u8a89\u3002\u8fd9\u786e\u4fdd\u4e86\u751f\u6210\u89c6\u89c9\u4e0a\u5f15\u4eba\u6ce8\u76ee\u7684\u7ed3\u679c\uff0c\u5e76\u5177\u6709\u590d\u6742\u7eb9\u7406\u4fe1\u606f\u3002\u5c3d\u7ba1\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6210\u529f\uff0c\u4f46\u5728\u5c06\u8fd9\u4e9b\u5f00\u521b\u6027\u7684\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u5de5\u4f5c\u6c47\u96c6\u8d77\u6765\u5e76\u7ec4\u7ec7\u76f8\u5e94\u7684\u7ebf\u7a0b\u7684\u7efc\u5408\u8c03\u67e5\u4e2d\uff0c\u4ecd\u7136\u5b58\u5728\u660e\u663e\u7684\u5dee\u8ddd\u3002\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u6280\u672f\u7684\u5168\u9762\u7efc\u8ff0\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e09\u4e2a\u901a\u7528\u7684\u6269\u6563\u5efa\u6a21\u6846\u67b6\uff0c\u5e76\u63a2\u8ba8\u4e86\u5b83\u4eec\u4e0e\u5176\u4ed6\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u7684\u76f8\u5173\u6027\uff0c\u5efa\u7acb\u4e86\u7406\u8bba\u57fa\u7840\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u6211\u4eec\u4ecb\u7ecd\u4e86\u6269\u6563\u6a21\u578b\u7684\u591a\u89c6\u89d2\u5206\u7c7b\uff0c\u540c\u65f6\u8003\u8651\u4e86\u5e95\u5c42\u6846\u67b6\u548c\u76ee\u6807\u4efb\u52a1\u3002\u6b64\u5916\uff0c\u6211\u4eec\u603b\u7ed3\u4e86\u5e94\u7528\u4e8e\u5176\u4ed6\u4efb\u52a1\u7684\u6269\u5c55\u6269\u6563\u6a21\u578b\uff0c\u5305\u62ec\u533b\u5b66\u3001\u9065\u611f\u548c\u89c6\u9891\u573a\u666f\u3002\u6b64\u5916\uff0c\u6211\u4eec\u6982\u8ff0\u4e86\u5e38\u7528\u7684\u57fa\u51c6\u548c\u8bc4\u4f30\u6307\u6807\u3002\u6211\u4eec\u5bf9\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u6280\u672f\u5728\u4e09\u4e2a\u7a81\u51fa\u7684\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u548c\u6548\u7387\u8fdb\u884c\u4e86\u5f7b\u5e95\u7684\u8bc4\u4f30\u3002\u6700\u540e\uff0c\u6211\u4eec\u9610\u660e\u4e86\u5f53\u524d\u6269\u6563\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e03\u4e2a\u672a\u6765\u7814\u7a76\u7684\u6709\u8da3\u65b9\u5411\u3002\u8fd9\u6b21\u5168\u9762\u68c0\u67e5\u65e8\u5728\u4fc3\u8fdb\u5bf9\u4f4e\u5c42\u6b21\u89c6\u89c9\u4efb\u52a1\u80cc\u666f\u4e0b\u53bb\u566a\u6269\u6563\u6a21\u578b\u5468\u56f4\u73af\u5883\u7684\u6df1\u5165\u7406\u89e3\u3002\u53ef\u4ee5\u5728 https://github.com/ChunmingHe/awesome-diffusion-models-in-low-level-vision \u627e\u5230\u8d85\u8fc7 20 \u4e2a\u4f4e\u5c42\u6b21\u89c6\u89c9\u4efb\u52a1\u4e2d\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u6280\u672f\u7684\u7cbe\u9009\u5217\u8868\u3002", "author": "Chunming He et.al.", "authors": "Chunming He, Yuqi Shen, Chengyu Fang, Fengyang Xiao, Longxiang Tang, Yulun Zhang, Wangmeng Zuo, Zhenhua Guo, Xiu Li", "id": "2406.11138v1", "paper_url": "http://arxiv.org/abs/2406.11138v1", "repo": "null"}}