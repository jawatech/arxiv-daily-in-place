{"2411.16313": {"publish_time": "2024-11-25", "title": "CATP-LLM: Empowering Large Language Models for Cost-Aware Tool Planning", "paper_summary": "Utilizing large language models (LLMs) for tool planning has emerged as a\npromising avenue for developing general AI systems, where LLMs automatically\nschedule external tools (e.g. vision models) to tackle complex tasks based on\ntask descriptions. To push this paradigm toward practical applications, it is\ncrucial for LLMs to consider tool execution costs (e.g. execution time) for\ntool planning. Unfortunately, prior studies overlook the tool execution costs,\nleading to the generation of expensive plans of which the costs outweigh task\nperformance. To fill this gap, we propose the Cost-Aware Tool Planning with\nLLMs (CATP-LLM) framework, which for the first time provides a coherent design\nto empower LLMs for cost-aware tool planning. Specifically, CATP-LLM\nincorporates a tool planning language to enhance the LLM to generate\nnon-sequential plans of multiple branches for efficient concurrent tool\nexecution and cost reduction. Moreover, it further designs a cost-aware offline\nreinforcement learning algorithm to fine-tune the LLM to optimize the\nperformance-cost trade-off in tool planning. In lack of public cost-related\ndatasets, we further present OpenCATP, the first platform for cost-aware\nplanning evaluation. Experiments on OpenCATP show that CATP-LLM outperforms\nGPT-4 even when using Llama2-7B as its backbone, with the average improvement\nof 28.2%-30.2% higher plan performance and 24.7%-45.8% lower costs even on the\nchallenging planning tasks. The codes of CATP-LLM and OpenCATP will be publicly\navailable.", "paper_summary_zh": "\u5229\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u9032\u884c\u5de5\u5177\u898f\u5283\u5df2\u6210\u70ba\u958b\u767c\u901a\u7528 AI \u7cfb\u7d71\u7684\u4e00\u689d\u6709\u524d\u9014\u7684\u9014\u5f91\uff0c\u5176\u4e2d LLM \u6703\u6839\u64da\u4efb\u52d9\u63cf\u8ff0\u81ea\u52d5\u5b89\u6392\u5916\u90e8\u5de5\u5177\uff08\u4f8b\u5982\u8996\u89ba\u6a21\u578b\uff09\u4f86\u8655\u7406\u8907\u96dc\u7684\u4efb\u52d9\u3002\u70ba\u4e86\u5c07\u6b64\u7bc4\u4f8b\u63a8\u5411\u5be6\u52d9\u61c9\u7528\uff0cLLM \u5fc5\u9808\u8003\u91cf\u5de5\u5177\u57f7\u884c\u6210\u672c\uff08\u4f8b\u5982\u57f7\u884c\u6642\u9593\uff09\u4ee5\u9032\u884c\u5de5\u5177\u898f\u5283\u3002\u907a\u61be\u7684\u662f\uff0c\u5148\u524d\u7684\u7814\u7a76\u5ffd\u7565\u4e86\u5de5\u5177\u57f7\u884c\u6210\u672c\uff0c\u5c0e\u81f4\u7522\u751f\u4e86\u6210\u672c\u5927\u65bc\u4efb\u52d9\u6548\u80fd\u7684\u6602\u8cb4\u8a08\u756b\u3002\u70ba\u4e86\u586b\u88dc\u6b64\u4e00\u7f3a\u53e3\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u5177\u5099\u6210\u672c\u610f\u8b58\u7684 LLM \u5de5\u5177\u898f\u5283 (CATP-LLM) \u67b6\u69cb\uff0c\u8a72\u67b6\u69cb\u9996\u6b21\u63d0\u4f9b\u4e86\u76f8\u5e72\u7684\u8a2d\u8a08\uff0c\u4ee5\u8ce6\u4e88 LLM \u6210\u672c\u610f\u8b58\u7684\u5de5\u5177\u898f\u5283\u80fd\u529b\u3002\u5177\u9ad4\u4f86\u8aaa\uff0cCATP-LLM \u7d50\u5408\u4e86\u5de5\u5177\u898f\u5283\u8a9e\u8a00\uff0c\u4ee5\u589e\u5f37 LLM \u7522\u751f\u975e\u9806\u5e8f\u7684\u591a\u5206\u652f\u8a08\u756b\uff0c\u4ee5\u9032\u884c\u6709\u6548\u7684\u4e26\u884c\u5de5\u5177\u57f7\u884c\u548c\u964d\u4f4e\u6210\u672c\u3002\u6b64\u5916\uff0c\u5b83\u9032\u4e00\u6b65\u8a2d\u8a08\u4e86\u4e00\u7a2e\u5177\u5099\u6210\u672c\u610f\u8b58\u7684\u96e2\u7dda\u5f37\u5316\u5b78\u7fd2\u6f14\u7b97\u6cd5\uff0c\u4ee5\u5fae\u8abf LLM\uff0c\u4ee5\u6700\u4f73\u5316\u5de5\u5177\u898f\u5283\u4e2d\u7684\u6548\u80fd\u6210\u672c\u53d6\u6368\u3002\u7531\u65bc\u7f3a\u4e4f\u516c\u958b\u7684\u6210\u672c\u76f8\u95dc\u8cc7\u6599\u96c6\uff0c\u6211\u5011\u9032\u4e00\u6b65\u63d0\u51fa\u4e86 OpenCATP\uff0c\u9019\u662f\u7b2c\u4e00\u500b\u7528\u65bc\u5177\u5099\u6210\u672c\u610f\u8b58\u7684\u898f\u5283\u8a55\u4f30\u7684\u5e73\u53f0\u3002\u5728 OpenCATP \u4e0a\u7684\u5be6\u9a57\u986f\u793a\uff0c\u5373\u4f7f\u4f7f\u7528 Llama2-7B \u4f5c\u70ba\u5176\u4e3b\u5e79\uff0cCATP-LLM \u4ecd\u512a\u65bc GPT-4\uff0c\u5e73\u5747\u6548\u80fd\u63d0\u5347 28.2%-30.2%\uff0c\u6210\u672c\u964d\u4f4e 24.7%-45.8%\uff0c\u5373\u4f7f\u5728\u5177\u6709\u6311\u6230\u6027\u7684\u898f\u5283\u4efb\u52d9\u4e0a\u4e5f\u662f\u5982\u6b64\u3002CATP-LLM \u548c OpenCATP \u7684\u7a0b\u5f0f\u78bc\u5c07\u516c\u958b\u63d0\u4f9b\u3002", "author": "Duo Wu et.al.", "authors": "Duo Wu, Jinghe Wang, Yuan Meng, Yanning Zhang, Le Sun, Zhi Wang", "id": "2411.16313v1", "paper_url": "http://arxiv.org/abs/2411.16313v1", "repo": "null"}}