{"2405.05904": {"publish_time": "2024-05-09", "title": "Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?", "paper_summary": "When large language models are aligned via supervised fine-tuning, they may\nencounter new factual information that was not acquired through pre-training.\nIt is often conjectured that this can teach the model the behavior of\nhallucinating factually incorrect responses, as the model is trained to\ngenerate facts that are not grounded in its pre-existing knowledge. In this\nwork, we study the impact of such exposure to new knowledge on the capability\nof the fine-tuned model to utilize its pre-existing knowledge. To this end, we\ndesign a controlled setup, focused on closed-book QA, where we vary the\nproportion of the fine-tuning examples that introduce new knowledge. We\ndemonstrate that large language models struggle to acquire new factual\nknowledge through fine-tuning, as fine-tuning examples that introduce new\nknowledge are learned significantly slower than those consistent with the\nmodel's knowledge. However, we also find that as the examples with new\nknowledge are eventually learned, they linearly increase the model's tendency\nto hallucinate. Taken together, our results highlight the risk in introducing\nnew factual knowledge through fine-tuning, and support the view that large\nlanguage models mostly acquire factual knowledge through pre-training, whereas\nfine-tuning teaches them to use it more efficiently.", "paper_summary_zh": "\u7576\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u900f\u904e\u76e3\u7763\u5f0f\u5fae\u8abf\u4f86\u5c0d\u9f4a\u6642\uff0c\u53ef\u80fd\u6703\u9047\u5230\u5728\u9810\u8a13\u7df4\u4e2d\u672a\u7372\u5f97\u7684\u65b0\u4e8b\u5be6\u8cc7\u8a0a\u3002\u4eba\u5011\u7d93\u5e38\u731c\u6e2c\uff0c\u9019\u53ef\u80fd\u6703\u6559\u5c0e\u6a21\u578b\u865b\u69cb\u4e8b\u5be6\u4e0a\u4e0d\u6b63\u78ba\u7684\u56de\u61c9\u7684\u884c\u70ba\uff0c\u56e0\u70ba\u8a72\u6a21\u578b\u7d93\u904e\u8a13\u7df4\u53ef\u4ee5\u7522\u751f\u4e0d\u57fa\u65bc\u5176\u65e2\u6709\u77e5\u8b58\u7684\u4e8b\u5be6\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u7814\u7a76\u4e86\u9019\u7a2e\u63a5\u89f8\u65b0\u77e5\u8b58\u5c0d\u5fae\u8abf\u6a21\u578b\u5229\u7528\u5176\u65e2\u6709\u77e5\u8b58\u7684\u80fd\u529b\u7684\u5f71\u97ff\u3002\u70ba\u6b64\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u53d7\u63a7\u7684\u8a2d\u5b9a\uff0c\u5c08\u6ce8\u65bc\u9589\u5377\u554f\u7b54\uff0c\u5176\u4e2d\u6211\u5011\u6539\u8b8a\u4e86\u5f15\u5165\u65b0\u77e5\u8b58\u7684\u5fae\u8abf\u7bc4\u4f8b\u7684\u6bd4\u4f8b\u3002\u6211\u5011\u8b49\u660e\u4e86\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u96e3\u4ee5\u900f\u904e\u5fae\u8abf\u4f86\u7372\u5f97\u65b0\u7684\u4e8b\u5be6\u77e5\u8b58\uff0c\u56e0\u70ba\u5f15\u5165\u65b0\u77e5\u8b58\u7684\u5fae\u8abf\u7bc4\u4f8b\u7684\u5b78\u7fd2\u901f\u5ea6\u986f\u8457\u4f4e\u65bc\u8207\u6a21\u578b\u77e5\u8b58\u4e00\u81f4\u7684\u7bc4\u4f8b\u3002\u7136\u800c\uff0c\u6211\u5011\u4e5f\u767c\u73fe\uff0c\u96a8\u8457\u5177\u6709\u65b0\u77e5\u8b58\u7684\u7bc4\u4f8b\u6700\u7d42\u88ab\u5b78\u7fd2\uff0c\u5b83\u5011\u6703\u7dda\u6027\u589e\u52a0\u6a21\u578b\u865b\u69cb\u7684\u8da8\u52e2\u3002\u7d9c\u5408\u8d77\u4f86\uff0c\u6211\u5011\u7684\u7d50\u679c\u7a81\u986f\u4e86\u900f\u904e\u5fae\u8abf\u5f15\u5165\u65b0\u7684\u4e8b\u5be6\u77e5\u8b58\u7684\u98a8\u96aa\uff0c\u4e26\u652f\u6301\u9019\u6a23\u4e00\u7a2e\u89c0\u9ede\uff0c\u5373\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u4e3b\u8981\u900f\u904e\u9810\u8a13\u7df4\u4f86\u7372\u5f97\u4e8b\u5be6\u77e5\u8b58\uff0c\u800c\u5fae\u8abf\u5247\u6559\u5c0e\u5b83\u5011\u66f4\u6709\u6548\u5730\u4f7f\u7528\u5b83\u3002", "author": "Zorik Gekhman et.al.", "authors": "Zorik Gekhman, Gal Yona, Roee Aharoni, Matan Eyal, Amir Feder, Roi Reichart, Jonathan Herzig", "id": "2405.05904v1", "paper_url": "http://arxiv.org/abs/2405.05904v1", "repo": "null"}}