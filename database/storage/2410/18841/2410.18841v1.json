{"2410.18841": {"publish_time": "2024-10-24", "title": "From Efficiency to Equity: Measuring Fairness in Preference Learning", "paper_summary": "As AI systems, particularly generative models, increasingly influence\ndecision-making, ensuring that they are able to fairly represent diverse human\npreferences becomes crucial. This paper introduces a novel framework for\nevaluating epistemic fairness in preference learning models inspired by\neconomic theories of inequality and Rawlsian justice. We propose metrics\nadapted from the Gini Coefficient, Atkinson Index, and Kuznets Ratio to\nquantify fairness in these models. We validate our approach using two datasets:\na custom visual preference dataset (AI-EDI-Space) and the Jester Jokes dataset.\nOur analysis reveals variations in model performance across users, highlighting\npotential epistemic injustices. We explore pre-processing and in-processing\ntechniques to mitigate these inequalities, demonstrating a complex relationship\nbetween model efficiency and fairness. This work contributes to AI ethics by\nproviding a framework for evaluating and improving epistemic fairness in\npreference learning models, offering insights for developing more inclusive AI\nsystems in contexts where diverse human preferences are crucial.", "paper_summary_zh": "\u96a8\u8457 AI \u7cfb\u7d71\uff0c\u5c24\u5176\u662f\u751f\u6210\u6a21\u578b\uff0c\u5c0d\u6c7a\u7b56\u5236\u5b9a\u5f71\u97ff\u65e5\u76ca\u589e\u52a0\uff0c\u78ba\u4fdd\u5b83\u5011\u80fd\u5920\u516c\u5e73\u5730\u4ee3\u8868\u4e0d\u540c\u7684\u500b\u4eba\u504f\u597d\u8b8a\u5f97\u81f3\u95dc\u91cd\u8981\u3002\u672c\u6587\u4ecb\u7d39\u4e86\u4e00\u500b\u65b0\u7684\u6846\u67b6\uff0c\u7528\u65bc\u8a55\u4f30\u504f\u597d\u5b78\u7fd2\u6a21\u578b\u4e2d\u7684\u8a8d\u8b58\u516c\u5e73\u6027\uff0c\u9748\u611f\u4f86\u81ea\u4e0d\u5e73\u7b49\u7d93\u6fdf\u7406\u8ad6\u548c\u7f85\u723e\u65af\u6b63\u7fa9\u8ad6\u3002\u6211\u5011\u63d0\u51fa\u5f9e\u57fa\u5c3c\u7cfb\u6578\u3001\u827e\u7279\u91d1\u68ee\u6307\u6578\u548c\u5eab\u8332\u6d85\u8328\u6bd4\u7387\u6539\u7de8\u7684\u6307\u6a19\uff0c\u4ee5\u91cf\u5316\u9019\u4e9b\u6a21\u578b\u4e2d\u7684\u516c\u5e73\u6027\u3002\u6211\u5011\u4f7f\u7528\u5169\u500b\u6578\u64da\u96c6\u9a57\u8b49\u4e86\u6211\u5011\u7684\u505a\u6cd5\uff1a\u4e00\u500b\u81ea\u8a02\u8996\u89ba\u504f\u597d\u6578\u64da\u96c6 (AI-EDI-Space) \u548c Jester Jokes \u6578\u64da\u96c6\u3002\u6211\u5011\u7684\u5206\u6790\u63ed\u793a\u4e86\u6a21\u578b\u5728\u4e0d\u540c\u4f7f\u7528\u8005\u4e4b\u9593\u7684\u6548\u80fd\u5dee\u7570\uff0c\u7a81\u986f\u4e86\u6f5b\u5728\u7684\u8a8d\u8b58\u4e0d\u516c\u6b63\u3002\u6211\u5011\u63a2\u8a0e\u4e86\u9810\u8655\u7406\u548c\u8655\u7406\u4e2d\u6280\u8853\uff0c\u4ee5\u6e1b\u8f15\u9019\u4e9b\u4e0d\u5e73\u7b49\u73fe\u8c61\uff0c\u8b49\u660e\u4e86\u6a21\u578b\u6548\u7387\u548c\u516c\u5e73\u6027\u4e4b\u9593\u7684\u8907\u96dc\u95dc\u4fc2\u3002\u9019\u9805\u5de5\u4f5c\u900f\u904e\u63d0\u4f9b\u4e00\u500b\u6846\u67b6\u4f86\u8a55\u4f30\u548c\u6539\u5584\u504f\u597d\u5b78\u7fd2\u6a21\u578b\u4e2d\u7684\u8a8d\u8b58\u516c\u5e73\u6027\uff0c\u5c0d AI \u502b\u7406\u6709\u8ca2\u737b\uff0c\u4e26\u63d0\u4f9b\u898b\u89e3\u4ee5\u5728\u4e0d\u540c\u500b\u4eba\u504f\u597d\u81f3\u95dc\u91cd\u8981\u7684\u80cc\u666f\u4e0b\u958b\u767c\u66f4\u5177\u5305\u5bb9\u6027\u7684 AI \u7cfb\u7d71\u3002", "author": "Shreeyash Gowaikar et.al.", "authors": "Shreeyash Gowaikar, Hugo Berard, Rashid Mushkani, Shin Koseki", "id": "2410.18841v1", "paper_url": "http://arxiv.org/abs/2410.18841v1", "repo": "null"}}