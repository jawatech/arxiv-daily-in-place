{"2406.11681": {"publish_time": "2024-06-17", "title": "R-Eval: A Unified Toolkit for Evaluating Domain Knowledge of Retrieval Augmented Large Language Models", "paper_summary": "Large language models have achieved remarkable success on general NLP tasks,\nbut they may fall short for domain-specific problems. Recently, various\nRetrieval-Augmented Large Language Models (RALLMs) are proposed to address this\nshortcoming. However, existing evaluation tools only provide a few baselines\nand evaluate them on various domains without mining the depth of domain\nknowledge. In this paper, we address the challenges of evaluating RALLMs by\nintroducing the R-Eval toolkit, a Python toolkit designed to streamline the\nevaluation of different RAG workflows in conjunction with LLMs. Our toolkit,\nwhich supports popular built-in RAG workflows and allows for the incorporation\nof customized testing data on the specific domain, is designed to be\nuser-friendly, modular, and extensible. We conduct an evaluation of 21 RALLMs\nacross three task levels and two representative domains, revealing significant\nvariations in the effectiveness of RALLMs across different tasks and domains.\nOur analysis emphasizes the importance of considering both task and domain\nrequirements when choosing a RAG workflow and LLM combination. We are committed\nto continuously maintaining our platform at https://github.com/THU-KEG/R-Eval\nto facilitate both the industry and the researchers.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u5728\u901a\u7528\u7684 NLP \u4efb\u52d9\u4e0a\u53d6\u5f97\u4e86\u986f\u8457\u7684\u6210\u529f\uff0c\n\u4f46\u5b83\u5011\u5728\u7279\u5b9a\u9818\u57df\u7684\u554f\u984c\u4e0a\u53ef\u80fd\u8868\u73fe\u4e0d\u4f73\u3002\u6700\u8fd1\uff0c\u63d0\u51fa\u4e86\u5404\u7a2e\n\u6aa2\u7d22\u589e\u5f37\u5927\u578b\u8a9e\u8a00\u6a21\u578b (RALLM) \u4f86\u89e3\u6c7a\u9019\u500b\n\u7f3a\u9ede\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684\u8a55\u4f30\u5de5\u5177\u53ea\u63d0\u4f9b\u4e86\u4e00\u4e9b\u57fa\u6e96\uff0c\n\u4e26\u5728\u5404\u7a2e\u9818\u57df\u5c0d\u5b83\u5011\u9032\u884c\u8a55\u4f30\uff0c\u800c\u6c92\u6709\u6316\u6398\u9818\u57df\n\u77e5\u8b58\u7684\u6df1\u5ea6\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u89e3\u6c7a\u4e86\u8a55\u4f30 RALLM \u7684\u6311\u6230\uff0c\n\u5f15\u5165\u4e86 R-Eval \u5de5\u5177\u5305\uff0c\u9019\u662f\u4e00\u500b Python \u5de5\u5177\u5305\uff0c\u65e8\u5728\u7c21\u5316\n\u8a55\u4f30\u4e0d\u540c\u7684 RAG \u5de5\u4f5c\u6d41\u7a0b\u4ee5\u53ca LLM\u3002\u6211\u5011\u7684\u5de5\u5177\u5305\uff0c\n\u5b83\u652f\u6301\u6d41\u884c\u7684\u5167\u5efa RAG \u5de5\u4f5c\u6d41\u7a0b\uff0c\u4e26\u5141\u8a31\u5728\u7279\u5b9a\u9818\u57df\u6574\u5408\n\u81ea\u8a02\u7684\u6e2c\u8a66\u6578\u64da\uff0c\u65e8\u5728\u6210\u70ba\u4f7f\u7528\u8005\u53cb\u5584\u3001\u6a21\u7d44\u5316\u548c\u53ef\u64f4\u5145\u7684\u3002\u6211\u5011\u5c0d 21 \u500b RALLM\n\u9032\u884c\u4e86\u8a55\u4f30\uff0c\u6db5\u84cb\u4e09\u500b\u4efb\u52d9\u5c64\u7d1a\u548c\u5169\u500b\u4ee3\u8868\u6027\u9818\u57df\uff0c\u63ed\u793a\u4e86 RALLM\n\u5728\u4e0d\u540c\u4efb\u52d9\u548c\u9818\u57df\u4e2d\u7684\u6709\u6548\u6027\u6709\u986f\u8457\u5dee\u7570\u3002\n\u6211\u5011\u7684\u5206\u6790\u5f37\u8abf\u4e86\u5728\u9078\u64c7 RAG \u5de5\u4f5c\u6d41\u7a0b\u548c LLM \u7d44\u5408\u6642\u8003\u616e\u4efb\u52d9\u548c\u9818\u57df\n\u9700\u6c42\u7684\u91cd\u8981\u6027\u3002\u6211\u5011\u81f4\u529b\u65bc\u6301\u7e8c\u7dad\u8b77\u6211\u5011\u7684\u5e73\u53f0\uff0c\u7db2\u5740\u70ba https://github.com/THU-KEG/R-Eval\uff0c\n\u4ee5\u4fc3\u9032\u7522\u696d\u548c\u7814\u7a76\u4eba\u54e1\u3002", "author": "Shangqing Tu et.al.", "authors": "Shangqing Tu, Yuanchun Wang, Jifan Yu, Yuyang Xie, Yaran Shi, Xiaozhi Wang, Jing Zhang, Lei Hou, Juanzi Li", "id": "2406.11681v1", "paper_url": "http://arxiv.org/abs/2406.11681v1", "repo": "https://github.com/thu-keg/r-eval"}}