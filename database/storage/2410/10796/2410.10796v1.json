{"2410.10796": {"publish_time": "2024-10-14", "title": "Context-Parametric Inversion: Why Instruction Finetuning May Not Actually Improve Context Reliance", "paper_summary": "Large language models are instruction-finetuned to enhance their ability to\nfollow user instructions and process the input context. However, even\nstate-of-the-art models often struggle to follow the instruction, especially\nwhen the input context is not aligned with the model's parametric knowledge.\nThis manifests as various failures, such as hallucinations where the responses\nare outdated, biased or contain unverified facts. In this work, we try to\nunderstand the underlying reason for this poor context reliance, especially\nafter instruction tuning. We observe an intriguing phenomenon: during\ninstruction tuning, the context reliance initially increases as expected, but\nthen gradually decreases as instruction finetuning progresses. We call this\nphenomenon context-parametric inversion and observe it across multiple general\npurpose instruction tuning datasets like TULU, Alpaca and Ultrachat, as well as\nmodel families such as Llama, Mistral and Pythia. In a simple theoretical\nsetup, we isolate why context-parametric inversion occurs along the gradient\ndescent trajectory of instruction finetuning. We tie this phenomena to examples\nin the instruction finetuning data mixture where the input context provides\ninformation that is already present in the model's parametric knowledge. Our\nanalysis suggests natural mitigation strategies that provide some limited\ngains, while also validating our theoretical insights. We hope that our work\nserves as a starting point in addressing this failure mode in a staple part of\nLLM training.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7d93\u904e\u6307\u4ee4\u5fae\u8abf\uff0c\u4ee5\u589e\u5f37\u5176\u9075\u5faa\u4f7f\u7528\u8005\u6307\u4ee4\u548c\u8655\u7406\u8f38\u5165\u5167\u5bb9\u7684\u80fd\u529b\u3002\u7136\u800c\uff0c\u5373\u4f7f\u662f\u6700\u65b0\u7a4e\u7684\u6a21\u578b\u4e5f\u7d93\u5e38\u96e3\u4ee5\u9075\u5faa\u6307\u4ee4\uff0c\u7279\u5225\u662f\u5728\u8f38\u5165\u5167\u5bb9\u8207\u6a21\u578b\u7684\u53c3\u6578\u5316\u77e5\u8b58\u4e0d\u4e00\u81f4\u6642\u3002\u9019\u6703\u8868\u73fe\u70ba\u5404\u7a2e\u5931\u6557\uff0c\u4f8b\u5982\u5e7b\u89ba\uff0c\u5176\u4e2d\u56de\u61c9\u904e\u6642\u3001\u6709\u504f\u5dee\u6216\u5305\u542b\u672a\u7d93\u9a57\u8b49\u7684\u4e8b\u5be6\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5617\u8a66\u4e86\u89e3\u9019\u7a2e\u4e0d\u826f\u5167\u5bb9\u4f9d\u8cf4\u6027\u7684\u6839\u672c\u539f\u56e0\uff0c\u7279\u5225\u662f\u5728\u6307\u4ee4\u5fae\u8abf\u4e4b\u5f8c\u3002\u6211\u5011\u89c0\u5bdf\u5230\u4e00\u500b\u6709\u8da3\u7684\u73fe\u8c61\uff1a\u5728\u6307\u4ee4\u5fae\u8abf\u671f\u9593\uff0c\u5167\u5bb9\u4f9d\u8cf4\u6027\u6700\u521d\u5982\u9810\u671f\u822c\u589e\u52a0\uff0c\u4f46\u96a8\u8457\u6307\u4ee4\u5fae\u8abf\u7684\u9032\u884c\uff0c\u9010\u6f38\u4e0b\u964d\u3002\u6211\u5011\u5c07\u9019\u7a2e\u73fe\u8c61\u7a31\u70ba\u5167\u5bb9\u53c3\u6578\u53cd\u8f49\uff0c\u4e26\u5728\u591a\u500b\u901a\u7528\u6307\u4ee4\u5fae\u8abf\u8cc7\u6599\u96c6\uff08\u4f8b\u5982 TULU\u3001Alpaca \u548c Ultrachat\uff09\u4ee5\u53ca Llama\u3001Mistral \u548c Pythia \u7b49\u6a21\u578b\u7cfb\u5217\u4e2d\u89c0\u5bdf\u5230\u9019\u7a2e\u73fe\u8c61\u3002\u5728\u4e00\u500b\u7c21\u55ae\u7684\u7406\u8ad6\u8a2d\u5b9a\u4e2d\uff0c\u6211\u5011\u9694\u96e2\u4e86\u5728\u6307\u4ee4\u5fae\u8abf\u7684\u68af\u5ea6\u4e0b\u964d\u8ecc\u8de1\u4e2d\u767c\u751f\u5167\u5bb9\u53c3\u6578\u53cd\u8f49\u7684\u539f\u56e0\u3002\u6211\u5011\u5c07\u9019\u7a2e\u73fe\u8c61\u8207\u6307\u4ee4\u5fae\u8abf\u8cc7\u6599\u6df7\u5408\u4e2d\u7684\u7bc4\u4f8b\u806f\u7e6b\u8d77\u4f86\uff0c\u5176\u4e2d\u8f38\u5165\u5167\u5bb9\u63d0\u4f9b\u4e86\u6a21\u578b\u53c3\u6578\u5316\u77e5\u8b58\u4e2d\u5df2\u5b58\u5728\u8cc7\u8a0a\u3002\u6211\u5011\u7684\u5206\u6790\u5efa\u8b70\u4e86\u81ea\u7136\u7de9\u89e3\u7b56\u7565\uff0c\u9019\u4e9b\u7b56\u7565\u63d0\u4f9b\u4e86\u4e00\u4e9b\u6709\u9650\u7684\u6536\u76ca\uff0c\u540c\u6642\u4e5f\u9a57\u8b49\u4e86\u6211\u5011\u7684\u7406\u8ad6\u898b\u89e3\u3002\u6211\u5011\u5e0c\u671b\u6211\u5011\u7684\u7814\u7a76\u80fd\u4f5c\u70ba\u89e3\u6c7a LLM \u8a13\u7df4\u4e2d\u9019\u500b\u5931\u6557\u6a21\u5f0f\u7684\u8d77\u9ede\u3002", "author": "Sachin Goyal et.al.", "authors": "Sachin Goyal, Christina Baek, J. Zico Kolter, Aditi Raghunathan", "id": "2410.10796v1", "paper_url": "http://arxiv.org/abs/2410.10796v1", "repo": "https://github.com/locuslab/context-parametric-inversion"}}