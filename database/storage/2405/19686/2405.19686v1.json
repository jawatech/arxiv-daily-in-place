{"2405.19686": {"publish_time": "2024-05-30", "title": "Knowledge Graph Tuning: Real-time Large Language Model Personalization based on Human Feedback", "paper_summary": "Large language models (LLMs) have demonstrated remarkable proficiency in a\nrange of natural language processing tasks. Once deployed, LLMs encounter users\nwith personalized factual knowledge, and such personalized knowledge is\nconsistently reflected through users' interactions with the LLMs. To enhance\nuser experience, real-time model personalization is essential, allowing LLMs to\nadapt user-specific knowledge based on user feedback during human-LLM\ninteractions. Existing methods mostly require back-propagation to finetune the\nmodel parameters, which incurs high computational and memory costs. In\naddition, these methods suffer from low interpretability, which will cause\nunforeseen impacts on model performance during long-term use, where the user's\npersonalized knowledge is accumulated extensively.To address these challenges,\nwe propose Knowledge Graph Tuning (KGT), a novel approach that leverages\nknowledge graphs (KGs) to personalize LLMs. KGT extracts personalized factual\nknowledge triples from users' queries and feedback and optimizes KGs without\nmodifying the LLM parameters. Our method improves computational and memory\nefficiency by avoiding back-propagation and ensures interpretability by making\nthe KG adjustments comprehensible to humans.Experiments with state-of-the-art\nLLMs, including GPT-2, Llama2, and Llama3, show that KGT significantly improves\npersonalization performance while reducing latency and GPU memory costs.\nUltimately, KGT offers a promising solution of effective, efficient, and\ninterpretable real-time LLM personalization during user interactions with the\nLLMs.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u8b49\u660e\u5728\u5404\u7a2e\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4efb\u52d9\u4e2d\u5177\u6709\u5353\u8d8a\u7684\u80fd\u529b\u3002\u4e00\u65e6\u90e8\u7f72\uff0cLLM \u6703\u9047\u5230\u64c1\u6709\u500b\u4eba\u5316\u4e8b\u5be6\u77e5\u8b58\u7684\u4f7f\u7528\u8005\uff0c\u800c\u9019\u7a2e\u500b\u4eba\u5316\u77e5\u8b58\u6703\u6301\u7e8c\u53cd\u6620\u5728\u4f7f\u7528\u8005\u8207 LLM \u7684\u4e92\u52d5\u4e2d\u3002\u70ba\u4e86\u63d0\u5347\u4f7f\u7528\u8005\u9ad4\u9a57\uff0c\u5373\u6642\u6a21\u578b\u500b\u4eba\u5316\u81f3\u95dc\u91cd\u8981\uff0c\u9019\u8b93 LLM \u80fd\u5728\u4eba\u985e\u8207 LLM \u7684\u4e92\u52d5\u4e2d\u6839\u64da\u4f7f\u7528\u8005\u7684\u56de\u994b\u8abf\u6574\u4f7f\u7528\u8005\u7279\u5b9a\u7684\u77e5\u8b58\u3002\u73fe\u6709\u65b9\u6cd5\u5927\u591a\u9700\u8981\u53cd\u5411\u50b3\u64ad\u4f86\u5fae\u8abf\u6a21\u578b\u53c3\u6578\uff0c\u9019\u6703\u7522\u751f\u9ad8\u904b\u7b97\u548c\u8a18\u61b6\u9ad4\u6210\u672c\u3002\u6b64\u5916\uff0c\u9019\u4e9b\u65b9\u6cd5\u7684\u53ef\u89e3\u91cb\u6027\u4f4e\uff0c\u9019\u6703\u5728\u9577\u671f\u4f7f\u7528\u671f\u9593\u5c0d\u6a21\u578b\u6548\u80fd\u9020\u6210\u7121\u6cd5\u9810\u898b\u7684\u5f71\u97ff\uff0c\u800c\u4f7f\u7528\u8005\u7684\u500b\u4eba\u5316\u77e5\u8b58\u6703\u5927\u91cf\u7d2f\u7a4d\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa\u77e5\u8b58\u5716\u8b5c\u8abf\u6574 (KGT)\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u77e5\u8b58\u5716\u8b5c (KG) \u4f86\u500b\u4eba\u5316 LLM\u3002KGT \u5f9e\u4f7f\u7528\u8005\u7684\u67e5\u8a62\u548c\u56de\u994b\u4e2d\u8403\u53d6\u500b\u4eba\u5316\u7684\u4e8b\u5be6\u77e5\u8b58\u4e09\u5143\u7d44\uff0c\u4e26\u5728\u4e0d\u4fee\u6539 LLM \u53c3\u6578\u7684\u60c5\u6cc1\u4e0b\u6700\u4f73\u5316 KG\u3002\u6211\u5011\u7684\u9019\u7a2e\u65b9\u6cd5\u900f\u904e\u907f\u514d\u53cd\u5411\u50b3\u64ad\u4f86\u63d0\u5347\u904b\u7b97\u548c\u8a18\u61b6\u9ad4\u6548\u7387\uff0c\u4e26\u900f\u904e\u8b93 KG \u8abf\u6574\u5c0d\u4eba\u985e\u4f86\u8aaa\u6613\u65bc\u7406\u89e3\u4f86\u78ba\u4fdd\u53ef\u89e3\u91cb\u6027\u3002\u4f7f\u7528\u5305\u542b GPT-2\u3001Llama2 \u548c Llama3 \u5728\u5167\u7684\u6700\u65b0 LLM \u9032\u884c\u7684\u5be6\u9a57\u986f\u793a\uff0cKGT \u5728\u964d\u4f4e\u5ef6\u9072\u548c GPU \u8a18\u61b6\u9ad4\u6210\u672c\u7684\u540c\u6642\uff0c\u5927\u5e45\u63d0\u5347\u500b\u4eba\u5316\u6548\u80fd\u3002\u6700\u7d42\uff0cKGT \u63d0\u4f9b\u4e86\u4e00\u500b\u6709\u524d\u9014\u7684\u89e3\u6c7a\u65b9\u6848\uff0c\u53ef\u4ee5\u5728\u4f7f\u7528\u8005\u8207 LLM \u4e92\u52d5\u671f\u9593\u9032\u884c\u6709\u6548\u3001\u9ad8\u6548\u4e14\u53ef\u89e3\u91cb\u7684\u5373\u6642 LLM \u500b\u4eba\u5316\u3002", "author": "Jingwei Sun et.al.", "authors": "Jingwei Sun, Zhixu Du, Yiran Chen", "id": "2405.19686v1", "paper_url": "http://arxiv.org/abs/2405.19686v1", "repo": "null"}}