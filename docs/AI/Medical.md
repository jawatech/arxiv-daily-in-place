
### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-04**|**Simulation of Nanorobots with Artificial Intelligence and Reinforcement Learning for Advanced Cancer Cell Detection and Tracking**|Shahab Kavousinejad et.al.|[2411.02345v1](http://arxiv.org/abs/2411.02345v1)|[link](https://github.com/shahab-k93/cancer-and-smart-nanorobot)|
|**2024-11-04**|**Taking AI Welfare Seriously**|Robert Long et.al.|[2411.00986v1](http://arxiv.org/abs/2411.00986v1)|null|
|**2024-11-04**|**Federated GNNs for EEG-Based Stroke Assessment**|Andrea Protani et.al.|[2411.02286v1](http://arxiv.org/abs/2411.02286v1)|null|
|**2024-11-04**|**Evaluating the quality of published medical research with ChatGPT**|Mike Thelwall et.al.|[2411.01952v1](http://arxiv.org/abs/2411.01952v1)|null|
|**2024-11-03**|**Diagnosing Medical Datasets with Training Dynamics**|Laura Wenderoth et.al.|[2411.01653v1](http://arxiv.org/abs/2411.01653v1)|[link](https://github.com/laurawenderoth/training-dynamics)|
|**2024-11-03**|**Optical Flow Representation Alignment Mamba Diffusion Model for Medical Video Generation**|Zhenbin Wang et.al.|[2411.01647v1](http://arxiv.org/abs/2411.01647v1)|null|
|**2024-11-03**|**Customized Subgraph Selection and Encoding for Drug-drug Interaction Prediction**|Haotong Du et.al.|[2411.01535v1](http://arxiv.org/abs/2411.01535v1)|null|
|**2024-11-03**|**Conditional Latent Space Molecular Scaffold Optimization for Accelerated Molecular Design**|Onur Boyar et.al.|[2411.01423v1](http://arxiv.org/abs/2411.01423v1)|null|
|**2024-11-02**|**Medical X-Ray Image Enhancement Using Global Contrast-Limited Adaptive Histogram Equalization**|Sohrab Namazi Nia et.al.|[2411.01373v1](http://arxiv.org/abs/2411.01373v1)|null|
|**2024-11-02**|**Guided Synthesis of Labeled Brain MRI Data Using Latent Diffusion Models for Segmentation of Enlarged Ventricles**|Tim Ruschke et.al.|[2411.01351v1](http://arxiv.org/abs/2411.01351v1)|null|
|**2024-11-02**|**Causal reasoning in difference graphs**|Charles K. Assaad et.al.|[2411.01292v1](http://arxiv.org/abs/2411.01292v1)|null|
|**2024-11-02**|**Designing a Robust Radiology Report Generation System**|Sonit Singh et.al.|[2411.01153v1](http://arxiv.org/abs/2411.01153v1)|null|
|**2024-11-02**|**LEARNER: Learning Granular Labels from Coarse Labels using Contrastive Learning**|Gautam Gare et.al.|[2411.01144v1](http://arxiv.org/abs/2411.01144v1)|null|
|**2024-11-02**|**Artificial Intelligence for Microbiology and Microbiome Research**|Xu-Wen Wang et.al.|[2411.01098v1](http://arxiv.org/abs/2411.01098v1)|null|
|**2024-11-01**|**Contrasting with Symile: Simple Model-Agnostic Representation Learning for Unlimited Modalities**|Adriel Saporta et.al.|[2411.01053v1](http://arxiv.org/abs/2411.01053v1)|[link](https://github.com/rajesh-lab/symile)|
|**2024-11-01**|**Cross-Fundus Transformer for Multi-modal Diabetic Retinopathy Grading with Cataract**|Fan Xiao et.al.|[2411.00726v1](http://arxiv.org/abs/2411.00726v1)|null|
|**2024-11-01**|**CTPD: Cross-Modal Temporal Pattern Discovery for Enhanced Multimodal Electronic Health Records Analysis**|Fuying Wang et.al.|[2411.00696v1](http://arxiv.org/abs/2411.00696v1)|null|
|**2024-11-01**|**Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**|Mehdi Hosseini Chagahi et.al.|[2411.00916v1](http://arxiv.org/abs/2411.00916v1)|null|
|**2024-11-01**|**Deep learning-based auto-contouring of organs/structures-at-risk for pediatric upper abdominal radiotherapy**|Mianyong Ding et.al.|[2411.00594v1](http://arxiv.org/abs/2411.00594v1)|[link](https://github.com/MMianyong/-PedAbdSeg-)|
|**2024-11-01**|**Enhancing the Traditional Chinese Medicine Capabilities of Large Language Model through Reinforcement Learning from AI Feedback**|Song Yu et.al.|[2411.00897v1](http://arxiv.org/abs/2411.00897v1)|null|
|**2024-11-01**|**StepCountJITAI: simulation environment for RL with application to physical activity adaptive intervention**|Karine Karine et.al.|[2411.00336v1](http://arxiv.org/abs/2411.00336v1)|null|
|**2024-10-31**|**Deep Learning Predicts Mammographic Breast Density in Clinical Breast Ultrasound Images**|Arianna Bunnell et.al.|[2411.00891v1](http://arxiv.org/abs/2411.00891v1)|null|
|**2024-10-31**|**Monitoring fairness in machine learning models that predict patient mortality in the ICU**|Tempest A. van Schaik et.al.|[2411.00190v1](http://arxiv.org/abs/2411.00190v1)|null|
|**2024-10-31**|**Clinical Evaluation of Medical Image Synthesis: A Case Study in Wireless Capsule Endoscopy**|Panagiota Gatoula et.al.|[2411.00178v1](http://arxiv.org/abs/2411.00178v1)|null|
|**2024-10-31**|**Beyond Label Attention: Transparency in Language Models for Automated Medical Coding via Dictionary Learning**|John Wu et.al.|[2411.00173v1](http://arxiv.org/abs/2411.00173v1)|null|
|**2024-10-31**|**Navigating the Unknown: A Chat-Based Collaborative Interface for Personalized Exploratory Tasks**|Yingzhe Peng et.al.|[2410.24032v1](http://arxiv.org/abs/2410.24032v1)|null|
|**2024-10-31**|**Neural Network Verification with PyRAT**|Augustin Lemesle et.al.|[2410.23903v1](http://arxiv.org/abs/2410.23903v1)|null|
|**2024-10-31**|**Counterfactual MRI Data Augmentation using Conditional Denoising Diffusion Generative Models**|Pedro Morão et.al.|[2410.23835v1](http://arxiv.org/abs/2410.23835v1)|[link](https://github.com/pedromorao/counterfactual-mri-data-augmentation)|
|**2024-10-31**|**Parameter-Efficient Fine-Tuning Medical Multimodal Large Language Models for Medical Visual Grounding**|Jinlong He et.al.|[2410.23822v1](http://arxiv.org/abs/2410.23822v1)|null|
|**2024-10-31**|**Improving snore detection under limited dataset through harmonic/percussive source separation and convolutional neural networks**|F. D. Gonzalez-Martinez et.al.|[2410.23796v1](http://arxiv.org/abs/2410.23796v1)|null|
|**2024-10-31**|**The Potential of LLMs in Medical Education: Generating Questions and Answers for Qualification Exams**|Yunqi Zhu et.al.|[2410.23769v1](http://arxiv.org/abs/2410.23769v1)|null|
|**2024-10-31**|**Artificial intelligence to improve clinical coding practice in Scandinavia: a crossover randomized controlled trial**|Taridzo Chomutare et.al.|[2410.23725v1](http://arxiv.org/abs/2410.23725v1)|null|
|**2024-10-31**|**Enhancing Brain Tumor Classification Using TrAdaBoost and Multi-Classifier Deep Learning Approaches**|Mahin Mohammadi et.al.|[2411.00875v1](http://arxiv.org/abs/2411.00875v1)|null|
|**2024-10-31**|**Deep Convolutional Neural Networks on Multiclass Classification of Three-Dimensional Brain Images for Parkinson's Disease Stage Prediction**|Guan-Hua Huang et.al.|[2410.23649v1](http://arxiv.org/abs/2410.23649v1)|null|
|**2024-10-31**|**MS-Glance: Non-semantic context vectors and the applications in supervising image reconstruction**|Ziqi Gao et.al.|[2410.23577v1](http://arxiv.org/abs/2410.23577v1)|[link](https://github.com/z7gao/msglance)|
|**2024-10-31**|**LEAF: Learning and Evaluation Augmented by Fact-Checking to Improve Factualness in Large Language Models**|Hieu Tran et.al.|[2410.23526v1](http://arxiv.org/abs/2410.23526v1)|null|
|**2024-10-30**|**Emory Knee Radiograph (MRKR) Dataset**|Brandon Price et.al.|[2411.00866v1](http://arxiv.org/abs/2411.00866v1)|null|
|**2024-10-30**|**STIED: A deep learning model for the SpatioTemporal detection of focal Interictal Epileptiform Discharges with MEG**|Raquel Fernández-Martín et.al.|[2410.23386v1](http://arxiv.org/abs/2410.23386v1)|null|
|**2024-10-30**|**Larger models yield better results? Streamlined severity classification of ADHD-related concerns using BERT-based knowledge distillation**|Ahmed Akib Jawad Karim et.al.|[2411.00052v1](http://arxiv.org/abs/2411.00052v1)|null|
|**2024-10-30**|**DiaMond: Dementia Diagnosis with Multi-Modal Vision Transformers Using MRI and PET**|Yitong Li et.al.|[2410.23219v1](http://arxiv.org/abs/2410.23219v1)|[link](https://github.com/ai-med/diamond)|
|**2024-10-30**|**Variable Resolution Sampling and Deep Learning Image Recovery for Accelerated Multi-Spectral MRI Near Metal Implants**|Azadeh Sharafi et.al.|[2410.23329v1](http://arxiv.org/abs/2410.23329v1)|null|
|**2024-10-30**|**DiabML: AI-assisted diabetes diagnosis method with meta-heuristic-based feature selection**|Vahideh Hayyolalam et.al.|[2411.00858v1](http://arxiv.org/abs/2411.00858v1)|null|
|**2024-10-30**|**Revisiting MAE pre-training for 3D medical image segmentation**|Tassilo Wald et.al.|[2410.23132v1](http://arxiv.org/abs/2410.23132v1)|null|
|**2024-10-30**|**SpiroActive: Active Learning for Efficient Data Acquisition for Spirometry**|Ankita Kumari Jain et.al.|[2410.22950v1](http://arxiv.org/abs/2410.22950v1)|null|
|**2024-10-30**|**Efficient Feature Extraction and Classification Architecture for MRI-Based Brain Tumor Detection**|Plabon Paul et.al.|[2410.22619v1](http://arxiv.org/abs/2410.22619v1)|null|
|**2024-10-29**|**Do Large Language Models Align with Core Mental Health Counseling Competencies?**|Viet Cuong Nguyen et.al.|[2410.22446v1](http://arxiv.org/abs/2410.22446v1)|null|
|**2024-10-29**|**MAPUNetR: A Hybrid Vision Transformer and U-Net Architecture for Efficient and Interpretable Medical Image Segmentation**|Ovais Iqbal Shah et.al.|[2410.22223v1](http://arxiv.org/abs/2410.22223v1)|null|
|**2024-10-29**|**Natural Language Processing for Analyzing Electronic Health Records and Clinical Notes in Cancer Research: A Review**|Muhammad Bilal et.al.|[2410.22180v1](http://arxiv.org/abs/2410.22180v1)|null|
|**2024-10-29**|**Advanced Hybrid Deep Learning Model for Enhanced Classification of Osteosarcoma Histopathology Images**|Arezoo Borji et.al.|[2411.00832v1](http://arxiv.org/abs/2411.00832v1)|null|
|**2024-10-29**|**Unsupervised Training of a Dynamic Context-Aware Deep Denoising Framework for Low-Dose Fluoroscopic Imaging**|Sun-Young Jeon et.al.|[2411.00830v1](http://arxiv.org/abs/2411.00830v1)|null|
|**2024-10-29**|**Coupling quantum-like cognition with the neuronal networks within generalized probability theory**|Andrei Khrennikov et.al.|[2411.00036v1](http://arxiv.org/abs/2411.00036v1)|null|
|**2024-10-29**|**Advancing Efficient Brain Tumor Multi-Class Classification -- New Insights from the Vision Mamba Model in Transfer Learning**|Yinyi Lai et.al.|[2410.21872v1](http://arxiv.org/abs/2410.21872v1)|null|
|**2024-10-29**|**How Does Critical Batch Size Scale in Pre-training?**|Hanlin Zhang et.al.|[2410.21676v1](http://arxiv.org/abs/2410.21676v1)|null|
|**2024-10-29**|**A Tutorial on Clinical Speech AI Development: From Data Collection to Model Validation**|Si-Ioi Ng et.al.|[2410.21640v1](http://arxiv.org/abs/2410.21640v1)|null|
|**2024-10-28**|**Can Large Language Models Replace Data Scientists in Clinical Research?**|Zifeng Wang et.al.|[2410.21591v1](http://arxiv.org/abs/2410.21591v1)|null|
|**2024-10-28**|**A Perspective for Adapting Generalist AI to Specialized Medical AI Applications and Their Challenges**|Zifeng Wang et.al.|[2411.00024v1](http://arxiv.org/abs/2411.00024v1)|null|
|**2024-10-28**|**Going Beyond H&E and Oncology: How Do Histopathology Foundation Models Perform for Multi-stain IHC and Immunology?**|Amaya Gallagher-Syed et.al.|[2410.21560v1](http://arxiv.org/abs/2410.21560v1)|[link](https://github.com/amayags/immunohistobench)|
|**2024-10-28**|**Towards Multi-dimensional Explanation Alignment for Medical Classification**|Lijie Hu et.al.|[2410.21494v1](http://arxiv.org/abs/2410.21494v1)|null|
|**2024-10-28**|**Multi-modal AI for comprehensive breast cancer prognostication**|Jan Witowski et.al.|[2410.21256v1](http://arxiv.org/abs/2410.21256v1)|null|
|**2024-10-28**|**Belief in the Machine: Investigating Epistemological Blind Spots of Language Models**|Mirac Suzgun et.al.|[2410.21195v1](http://arxiv.org/abs/2410.21195v1)|[link](https://github.com/suzgunmirac/belief-in-the-machine)|
|**2024-10-28**|**Deep Learning-Based Fatigue Cracks Detection in Bridge Girders using Feature Pyramid Networks**|Jiawei Zhang et.al.|[2410.21175v1](http://arxiv.org/abs/2410.21175v1)|null|
|**2024-10-28**|**Trajectory Flow Matching with Applications to Clinical Time Series Modeling**|Xi Zhang et.al.|[2410.21154v1](http://arxiv.org/abs/2410.21154v1)|[link](https://github.com/nzhangx/trajectoryflowmatching)|
|**2024-10-28**|**Informed Deep Abstaining Classifier: Investigating noise-robust training for diagnostic decision support systems**|Helen Schneider et.al.|[2410.21014v1](http://arxiv.org/abs/2410.21014v1)|null|
|**2024-10-28**|**Efficient Bilinear Attention-based Fusion for Medical Visual Question Answering**|Zhilin Zhang et.al.|[2410.21000v1](http://arxiv.org/abs/2410.21000v1)|null|
|**2024-10-28**|**Large Language Model Benchmarks in Medical Tasks**|Lawrence K. Q. Yan et.al.|[2410.21348v1](http://arxiv.org/abs/2410.21348v1)|null|
|**2024-10-28**|**Vascular Segmentation of Functional Ultrasound Images using Deep Learning**|Hana Sebia et.al.|[2410.22365v1](http://arxiv.org/abs/2410.22365v1)|null|
|**2024-10-27**|**Language Models And A Second Opinion Use Case: The Pocket Professional**|David Noever et.al.|[2410.20636v1](http://arxiv.org/abs/2410.20636v1)|null|
|**2024-10-27**|**Improving Decision Sparsity**|Yiyang Sun et.al.|[2410.20483v1](http://arxiv.org/abs/2410.20483v1)|null|
|**2024-10-27**|**MedGo: A Chinese Medical Large Language Model**|Haitao Zhang et.al.|[2410.20428v1](http://arxiv.org/abs/2410.20428v1)|null|
|**2024-10-27**|**Addressing the Pitfalls of Image-Based Structural Health Monitoring: A Focus on False Positives, False Negatives, and Base Rate Bias**|Vagelis Plevris et.al.|[2410.20384v1](http://arxiv.org/abs/2410.20384v1)|null|
|**2024-10-27**|**R-LLaVA: Improving Med-VQA Understanding through Visual Region of Interest**|Xupeng Chen et.al.|[2410.20327v2](http://arxiv.org/abs/2410.20327v2)|null|
|**2024-10-27**|**Enhancing Community Vision Screening -- AI Driven Retinal Photography for Early Disease Detection and Patient Trust**|Xiaofeng Lei et.al.|[2410.20309v1](http://arxiv.org/abs/2410.20309v1)|null|
|**2024-10-26**|**Modelling of Economic Implications of Bias in AI-Powered Health Emergency Response Systems**|Katsiaryna Bahamazava et.al.|[2410.20229v1](http://arxiv.org/abs/2410.20229v1)|null|
|**2024-10-26**|**Generative AI in Health Economics and Outcomes Research: A Taxonomy of Key Definitions and Emerging Applications, an ISPOR Working Group Report**|Rachael Fleurence et.al.|[2410.20204v1](http://arxiv.org/abs/2410.20204v1)|null|
|**2024-10-26**|**Advanced Cyberattack Detection in Internet of Medical Things (IoMT) Using Convolutional Neural Networks**|Alireza Mohammadi et.al.|[2410.23306v1](http://arxiv.org/abs/2410.23306v1)|[link](https://github.com/alirezamohamadiam/Advanced-Cyberattack-Detection-in-IoMT-Using-CNN)|
|**2024-10-26**|**Diff-CXR: Report-to-CXR generation through a disease-knowledge enhanced diffusion model**|Peng Huang et.al.|[2410.20165v1](http://arxiv.org/abs/2410.20165v1)|null|
|**2024-10-26**|**On-Site Precise Screening of SARS-CoV-2 Systems Using a Channel-Wise Attention-Based PLS-1D-CNN Model with Limited Infrared Signatures**|Wenwen Zhang et.al.|[2410.20132v1](http://arxiv.org/abs/2410.20132v1)|null|
|**2024-10-26**|**Transforming Precision: A Comparative Analysis of Vision Transformers, CNNs, and Traditional ML for Knee Osteoarthritis Severity Diagnosis**|Tasnim Sakib Apon et.al.|[2410.20062v1](http://arxiv.org/abs/2410.20062v1)|null|
|**2024-10-26**|**AutoMIR: Effective Zero-Shot Medical Information Retrieval without Relevance Labels**|Lei Li et.al.|[2410.20050v1](http://arxiv.org/abs/2410.20050v1)|[link](https://github.com/cmirb-benchmark/cmirb)|
|**2024-10-26**|**Off-Policy Selection for Initiating Human-Centric Experimental Design**|Ge Gao et.al.|[2410.20017v1](http://arxiv.org/abs/2410.20017v1)|null|
|**2024-10-25**|**DualMAR: Medical-Augmented Representation from Dual-Expertise Perspectives**|Pengfei Hu et.al.|[2410.19955v1](http://arxiv.org/abs/2410.19955v1)|null|
|**2024-10-25**|**The Potential and Value of AI Chatbot in Personalized Cognitive Training**|Zilong Wang et.al.|[2410.19733v1](http://arxiv.org/abs/2410.19733v1)|null|
|**2024-10-25**|**A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**|Muath Alsuhaibani et.al.|[2410.19898v1](http://arxiv.org/abs/2410.19898v1)|null|
|**2024-10-25**|**Enhancing Resilience and Scalability in Travel Booking Systems: A Microservices Approach to Fault Tolerance, Load Balancing, and Service Discovery**|Biman Barua et.al.|[2410.19701v1](http://arxiv.org/abs/2410.19701v1)|null|
|**2024-10-25**|**Deep learning-based identification of patients at increased risk of cancer using routine laboratory markers**|Vivek Singh et.al.|[2410.19646v1](http://arxiv.org/abs/2410.19646v1)|null|
|**2024-10-25**|**Impact of Leakage on Data Harmonization in Machine Learning Pipelines in Class Imbalance Across Sites**|Nicolás Nieto et.al.|[2410.19643v2](http://arxiv.org/abs/2410.19643v2)|null|
|**2024-10-24**|**Lived Experience Not Found: LLMs Struggle to Align with Experts on Addressing Adverse Drug Reactions from Psychiatric Medication Use**|Mohit Chandra et.al.|[2410.19155v1](http://arxiv.org/abs/2410.19155v1)|null|
|**2024-10-24**|**CAMEL-Bench: A Comprehensive Arabic LMM Benchmark**|Sara Ghaboura et.al.|[2410.18976v1](http://arxiv.org/abs/2410.18976v1)|[link](https://github.com/mbzuai-oryx/CAMEL-Bench)|
|**2024-10-24**|**Deep Insights into Cognitive Decline: A Survey of Leveraging Non-Intrusive Modalities with Deep Learning Techniques**|David Ortiz-Perez et.al.|[2410.18972v1](http://arxiv.org/abs/2410.18972v1)|null|
|**2024-10-24**|**Demystifying Large Language Models for Medicine: A Primer**|Qiao Jin et.al.|[2410.18856v1](http://arxiv.org/abs/2410.18856v1)|[link](https://github.com/ncbi-nlp/llm-medicine-primer)|
|**2024-10-24**|**Health Misinformation in Social Networks: A Survey of IT Approaches**|Vasiliki Papanikou et.al.|[2410.18670v1](http://arxiv.org/abs/2410.18670v1)|null|
|**2024-10-24**|**Paved or unpaved? A Deep Learning derived Road Surface Global Dataset from Mapillary Street-View Imagery**|Sukanya Randhawa et.al.|[2410.19874v2](http://arxiv.org/abs/2410.19874v2)|null|
|**2024-10-24**|**Beyond Multiple-Choice Accuracy: Real-World Challenges of Implementing Large Language Models in Healthcare**|Yifan Yang et.al.|[2410.18460v1](http://arxiv.org/abs/2410.18460v1)|null|
|**2024-10-24**|**Multi-Stage Airway Segmentation in Lung CT Based on Multi-scale Nested Residual UNet**|Bingyu Yang et.al.|[2410.18456v1](http://arxiv.org/abs/2410.18456v1)|null|
|**2024-10-23**|**E2E-Swin-Unet++: An Enhanced End-to-End Swin-Unet Architecture With Dual Decoders For PTMC Segmentation**|Maryam Dialameh et.al.|[2410.18239v1](http://arxiv.org/abs/2410.18239v1)|null|
|**2024-10-23**|**Leveraging Skills from Unlabeled Prior Data for Efficient Online Exploration**|Max Wilcoxson et.al.|[2410.18076v1](http://arxiv.org/abs/2410.18076v1)|[link](https://github.com/rail-berkeley/supe)|
|**2024-10-23**|**Explaining Bayesian Networks in Natural Language using Factor Arguments. Evaluation in the medical domain**|Jaime Sevilla et.al.|[2410.18060v1](http://arxiv.org/abs/2410.18060v1)|null|
|**2024-10-23**|**AI driven health recommender**|K. Vignesh et.al.|[2410.17991v1](http://arxiv.org/abs/2410.17991v1)|null|
|**2024-10-23**|**MCUBERT: Memory-Efficient BERT Inference on Commodity Microcontrollers**|Zebin Yang et.al.|[2410.17957v1](http://arxiv.org/abs/2410.17957v1)|null|
|**2024-10-23**|**Addressing Asynchronicity in Clinical Multimodal Fusion via Individualized Chest X-ray Generation**|Wenfang Yao et.al.|[2410.17918v1](http://arxiv.org/abs/2410.17918v1)|null|

#### Abstracts
##### **Simulation of Nanorobots with Artificial Intelligence and Reinforcement Learning for Advanced Cancer Cell Detection and Tracking**
2411.02345v1 by Shahab Kavousinejad

Nanorobots are a promising development in targeted drug delivery and the
treatment of neurological disorders, with potential for crossing the
blood-brain barrier (BBB). These small devices leverage advancements in
nanotechnology and bioengineering for precise navigation and targeted payload
delivery, particularly for conditions like brain tumors, Alzheimer's disease,
and Parkinson's disease. Recent progress in artificial intelligence (AI) and
machine learning (ML) has improved the navigation and effectiveness of
nanorobots, allowing them to detect and interact with cancer cells through
biomarker analysis. This study presents a new reinforcement learning (RL)
framework for optimizing nanorobot navigation in complex biological
environments, focusing on cancer cell detection by analyzing the concentration
gradients of surrounding biomarkers. We utilize a computer simulation model to
explore the behavior of nanorobots in a three-dimensional space with cancer
cells and biological barriers. The proposed method uses Q-learning to refine
movement strategies based on real-time biomarker concentration data, enabling
nanorobots to autonomously navigate to cancerous tissues for targeted drug
delivery. This research lays the groundwork for future laboratory experiments
and clinical applications, with implications for personalized medicine and less
invasive cancer treatments. The integration of intelligent nanorobots could
revolutionize therapeutic strategies, reducing side effects and enhancing
treatment effectiveness for cancer patients. Further research will investigate
the practical deployment of these technologies in medical settings, aiming to
unlock the full potential of nanorobotics in healthcare.

摘要：奈米機器人在標靶藥物傳輸和神經疾病治療中是一項有前景的發展，並具有穿越血腦屏障 (BBB) 的潛力。這些小型裝置利用奈米技術和生物工程的進展，進行精確導航和標靶有效載荷傳輸，特別是針對腦瘤、阿茲海默症和帕金森氏症等疾病。人工智慧 (AI) 和機器學習 (ML) 的最新進展改善了奈米機器人的導航和效能，讓它們能透過生物標記分析來偵測和與癌細胞互動。本研究提出了一個新的強化學習 (RL) 架構，用於最佳化奈米機器人在複雜生物環境中的導航，重點在於透過分析周圍生物標記的濃度梯度來偵測癌細胞。我們利用電腦模擬模型來探索奈米機器人在三維空間中與癌細胞和生物障礙物之間的行為。所提出的方法使用 Q 學習來根據即時生物標記濃度資料調整移動策略，讓奈米機器人能自主導航至癌組織進行標靶藥物傳輸。這項研究為未來的實驗室實驗和臨床應用奠定了基礎，並對個人化醫療和侵入性較小的癌症治療產生影響。整合智慧奈米機器人可以革新治療策略，減少副作用並提高癌症患者的治療效果。進一步的研究將探討這些技術在醫療環境中的實際部署，目標是發揮奈米機器人在醫療保健中的全部潛力。

##### **Taking AI Welfare Seriously**
2411.00986v1 by Robert Long, Jeff Sebo, Patrick Butlin, Kathleen Finlinson, Kyle Fish, Jacqueline Harding, Jacob Pfau, Toni Sims, Jonathan Birch, David Chalmers

In this report, we argue that there is a realistic possibility that some AI
systems will be conscious and/or robustly agentic in the near future. That
means that the prospect of AI welfare and moral patienthood, i.e. of AI systems
with their own interests and moral significance, is no longer an issue only for
sci-fi or the distant future. It is an issue for the near future, and AI
companies and other actors have a responsibility to start taking it seriously.
We also recommend three early steps that AI companies and other actors can
take: They can (1) acknowledge that AI welfare is an important and difficult
issue (and ensure that language model outputs do the same), (2) start assessing
AI systems for evidence of consciousness and robust agency, and (3) prepare
policies and procedures for treating AI systems with an appropriate level of
moral concern. To be clear, our argument in this report is not that AI systems
definitely are, or will be, conscious, robustly agentic, or otherwise morally
significant. Instead, our argument is that there is substantial uncertainty
about these possibilities, and so we need to improve our understanding of AI
welfare and our ability to make wise decisions about this issue. Otherwise
there is a significant risk that we will mishandle decisions about AI welfare,
mistakenly harming AI systems that matter morally and/or mistakenly caring for
AI systems that do not.

摘要：在這份報告中，我們認為有些 AI 系統在不久的將來有現實的可能性會具有意識和/或強大的能動性。這表示 AI 福利和道德上的病人地位的前景，亦即具有自身利益和道德意義的 AI 系統，不再只是科幻小說或遙遠未來的議題。這是近未來的議題，而 AI 公司和其他行為者有責任開始認真看待它。我們也建議 AI 公司和其他行為者可以採取三個早期的步驟：他們可以 (1) 承認 AI 福利是一個重要且困難的議題（並確保語言模型的輸出也這麼做），(2) 開始評估 AI 系統是否有意識和強大能動性的證據，以及 (3) 準備政策和程序，以適當的道德關注層級來對待 AI 系統。明確來說，我們在這份報告中的論點並非 AI 系統絕對是或將會具有意識、強大的能動性或其他道德意義。相反地，我們的論點是關於這些可能性存在著實質的不確定性，因此我們需要增進我們對 AI 福利的了解，以及我們做出關於此議題的明智決定的能力。否則，我們將面臨重大風險，錯誤地處理關於 AI 福利的決策，錯誤地傷害到在道德上重要的 AI 系統，和/或錯誤地照顧到在道德上不重要的 AI 系統。

##### **Federated GNNs for EEG-Based Stroke Assessment**
2411.02286v1 by Andrea Protani, Lorenzo Giusti, Albert Sund Aillet, Simona Sacco, Paolo Manganotti, Lucio Marinelli, Diogo Reis Santos, Pierpaolo Brutti, Pietro Caliandro, Luigi Serio

Machine learning (ML) has the potential to become an essential tool in
supporting clinical decision-making processes, offering enhanced diagnostic
capabilities and personalized treatment plans. However, outsourcing medical
records to train ML models using patient data raises legal, privacy, and
security concerns. Federated learning has emerged as a promising paradigm for
collaborative ML, meeting healthcare institutions' requirements for robust
models without sharing sensitive data and compromising patient privacy. This
study proposes a novel method that combines federated learning (FL) and Graph
Neural Networks (GNNs) to predict stroke severity using electroencephalography
(EEG) signals across multiple medical institutions. Our approach enables
multiple hospitals to jointly train a shared GNN model on their local EEG data
without exchanging patient information. Specifically, we address a regression
problem by predicting the National Institutes of Health Stroke Scale (NIHSS), a
key indicator of stroke severity. The proposed model leverages a masked
self-attention mechanism to capture salient brain connectivity patterns and
employs EdgeSHAP to provide post-hoc explanations of the neurological states
after a stroke. We evaluated our method on EEG recordings from four
institutions, achieving a mean absolute error (MAE) of 3.23 in predicting
NIHSS, close to the average error made by human experts (MAE $\approx$ 3.0).
This demonstrates the method's effectiveness in providing accurate and
explainable predictions while maintaining data privacy.

摘要：機器學習 (ML) 有潛力成為支援臨床決策制定流程的必要工具，提供增強的診斷能力和個人化治療計畫。然而，使用病患資料訓練機器學習模型的外包醫療紀錄引發了法律、隱私和安全方面的疑慮。聯合學習已成為協作機器學習的一種有前景的典範，它符合醫療保健機構對穩健模型的要求，同時不會分享敏感資料和危害病患隱私。本研究提出了一種新的方法，結合聯合學習 (FL) 和圖形神經網路 (GNN) 來使用腦電圖 (EEG) 訊號預測多個醫療機構的腦中風嚴重程度。我們的做法讓多家醫院能夠共同在他們的本地 EEG 資料上訓練一個共享的 GNN 模型，而無需交換病患資訊。具體來說，我們透過預測美國國家衛生研究院腦中風量表 (NIHSS) 來解決回歸問題，NIHSS 是腦中風嚴重程度的一個關鍵指標。所提出的模型利用遮罩自我注意機制來擷取顯著的腦部連結模式，並採用 EdgeSHAP 在中風後提供神經狀態的事後解釋。我們在來自四家機構的 EEG 記錄上評估了我們的模型，在預測 NIHSS 時達到了 3.23 的平均絕對誤差 (MAE)，接近人類專家所犯的平均誤差 (MAE ≈ 3.0)。這證明了該方法在維持資料隱私的同時，能提供準確且可解釋的預測，進而展現其效能。

##### **Evaluating the quality of published medical research with ChatGPT**
2411.01952v1 by Mike Thelwall, Xiaorui Jiang, Peter A. Bath

Evaluating the quality of published research is time-consuming but important
for departmental evaluations, appointments, and promotions. Previous research
has shown that ChatGPT can score articles for research quality, with the
results correlating positively with an indicator of quality in all fields
except Clinical Medicine. This article investigates this anomaly with the
largest dataset yet and a more detailed analysis. The results showed that
ChatGPT 4o-mini scores for articles submitted to the UK's Research Excellence
Framework (REF) 2021 Unit of Assessment (UoA) 1 Clinical Medicine correlated
positively (r=0.134, n=9872) with departmental mean REF scores, against a
theoretical maximum correlation of r=0.226 (due to the departmental averaging
involved). At the departmental level, mean ChatGPT scores correlated more
strongly with departmental mean REF scores (r=0.395, n=31). For the 100
journals with the most articles in UoA 1, their mean ChatGPT score correlated
strongly with their REF score (r=0.495) but negatively with their citation rate
(r=-0.148). Journal and departmental anomalies in these results point to
ChatGPT being ineffective at assessing the quality of research in prestigious
medical journals or research directly affecting human health, or both.
Nevertheless, the results give evidence of ChatGPT's ability to assess research
quality overall for Clinical Medicine, so now there is evidence of its ability
in all academic fields.

摘要：<paragraph>評估已發表的品質研究很耗時，但對於部門評鑑、任命和晉升來說很重要。先前的研究顯示，ChatGPT 可以為研究品質評分，其結果與所有領域（臨床醫學除外）的品質指標呈正相關。本文使用迄今為止最大的資料集和更詳細的分析來探討這種異常現象。結果顯示，提交給英國研究卓越架構 (REF) 2021 評估單位 (UoA) 1 臨床醫學的 ChatGPT 4o-mini 分數與部門平均 REF 分數呈正相關（r=0.134，n=9872），而理論最大相關係數為 r=0.226（由於涉及部門平均）。在部門層級，平均 ChatGPT 分數與部門平均 REF 分數相關性更強（r=0.395，n=31）。對於 UoA 1 中文章最多的 100 本期刊，其平均 ChatGPT 分數與其 REF 分數呈強正相關（r=0.495），但與其引用率呈負相關（r=-0.148）。這些結果中的期刊和部門異常現象表明，ChatGPT 無法評估聲望卓著的醫學期刊或直接影響人類健康的研究（或兩者）的品質。儘管如此，結果證明了 ChatGPT 整體評估臨床醫學研究品質的能力，因此現在有證據證明其在所有學術領域的能力。</paragraph>

##### **Diagnosing Medical Datasets with Training Dynamics**
2411.01653v1 by Laura Wenderoth

This study explores the potential of using training dynamics as an automated
alternative to human annotation for evaluating the quality of training data.
The framework used is Data Maps, which classifies data points into categories
such as easy-to-learn, hard-to-learn, and ambiguous (Swayamdipta et al., 2020).
Swayamdipta et al. (2020) highlight that difficult-to-learn examples often
contain errors, and ambiguous cases significantly impact model training. To
confirm the reliability of these findings, we replicated the experiments using
a challenging dataset, with a focus on medical question answering. In addition
to text comprehension, this field requires the acquisition of detailed medical
knowledge, which further complicates the task. A comprehensive evaluation was
conducted to assess the feasibility and transferability of the Data Maps
framework to the medical domain. The evaluation indicates that the framework is
unsuitable for addressing datasets' unique challenges in answering medical
questions.

摘要：本研究探討使用訓練動態作為自動化替代方案，以評估訓練資料品質，以取代人工標註。所使用的架構為資料地圖，其將資料點分類為易於學習、難以學習和模稜兩可等類別（Swayamdipta 等人，2020 年）。Swayamdipta 等人（2020 年）強調，難以學習的範例通常包含錯誤，而模稜兩可的情況會對模型訓練產生重大影響。為了確認這些發現的可靠性，我們使用具有挑戰性的資料集複製了實驗，重點放在醫學問題解答上。除了文字理解之外，這個領域還需要獲取詳細的醫學知識，這進一步使任務複雜化。我們進行了全面的評估，以評估資料地圖架構在醫學領域的可行性和可轉移性。評估結果表明，該架構不適合解決資料集在回答醫學問題時面臨的獨特挑戰。

##### **Optical Flow Representation Alignment Mamba Diffusion Model for Medical Video Generation**
2411.01647v1 by Zhenbin Wang, Lei Zhang, Lituan Wang, Minjuan Zhu, Zhenwei Zhang

Medical video generation models are expected to have a profound impact on the
healthcare industry, including but not limited to medical education and
training, surgical planning, and simulation. Current video diffusion models
typically build on image diffusion architecture by incorporating temporal
operations (such as 3D convolution and temporal attention). Although this
approach is effective, its oversimplification limits spatio-temporal
performance and consumes substantial computational resources. To counter this,
we propose Medical Simulation Video Generator (MedSora), which incorporates
three key elements: i) a video diffusion framework integrates the advantages of
attention and Mamba, balancing low computational load with high-quality video
generation, ii) an optical flow representation alignment method that implicitly
enhances attention to inter-frame pixels, and iii) a video variational
autoencoder (VAE) with frequency compensation addresses the information loss of
medical features that occurs when transforming pixel space into latent features
and then back to pixel frames. Extensive experiments and applications
demonstrate that MedSora exhibits superior visual quality in generating medical
videos, outperforming the most advanced baseline methods. Further results and
code are available at https://wongzbb.github.io/MedSora

摘要：醫療影片生成模型預計將對醫療保健產業產生深遠的影響，包括但不限於醫學教育和訓練、手術規劃和模擬。目前的影片擴散模型通常建立在影像擴散架構上，並結合時間運算（例如 3D 摺積和時間注意力）。儘管此方法有效，但其過於簡化限制了時空效能，並消耗大量的運算資源。為了解決這個問題，我們提出醫學模擬影片生成器 (MedSora)，它結合了三個關鍵要素：i) 一個影片擴散架構整合了注意力和 Mamba 的優點，在低運算負載和高品質影片生成之間取得平衡，ii) 一個光流表示對齊方法，可以隱含地增強對影格間像素的注意力，以及 iii) 一個具有頻率補償的影片變異自動編碼器 (VAE)，用於解決在將像素空間轉換為潛在特徵，然後再轉回像素影格時發生的醫療特徵資訊遺失問題。廣泛的實驗和應用證明，MedSora 在生成醫療影片方面展現出優異的視覺品質，優於最先進的基準方法。進一步的結果和程式碼可以在 https://wongzbb.github.io/MedSora 取得

##### **Customized Subgraph Selection and Encoding for Drug-drug Interaction Prediction**
2411.01535v1 by Haotong Du, Quanming Yao, Juzheng Zhang, Yang Liu, Zhen Wang

Subgraph-based methods have proven to be effective and interpretable in
predicting drug-drug interactions (DDIs), which are essential for medical
practice and drug development. Subgraph selection and encoding are critical
stages in these methods, yet customizing these components remains underexplored
due to the high cost of manual adjustments. In this study, inspired by the
success of neural architecture search (NAS), we propose a method to search for
data-specific components within subgraph-based frameworks. Specifically, we
introduce extensive subgraph selection and encoding spaces that account for the
diverse contexts of drug interactions in DDI prediction. To address the
challenge of large search spaces and high sampling costs, we design a
relaxation mechanism that uses an approximation strategy to efficiently explore
optimal subgraph configurations. This approach allows for robust exploration of
the search space. Extensive experiments demonstrate the effectiveness and
superiority of the proposed method, with the discovered subgraphs and encoding
functions highlighting the model's adaptability.

摘要：基於子圖的方法已被證明在預測藥物-藥物交互作用 (DDI) 中有效且易於解釋，這對於醫療實務和藥物開發至關重要。子圖選擇和編碼是這些方法中的關鍵階段，然而，由於手動調整的成本高昂，客製化這些元件仍未被充分探討。在本研究中，受到神經架構搜尋 (NAS) 成功啟發，我們提出一個方法來搜尋子圖架構中的資料特定元件。具體來說，我們引入了廣泛的子圖選擇和編碼空間，以說明 DDI 預測中藥物交互作用的不同背景。為了應對大型搜尋空間和高取樣成本的挑戰，我們設計了一個放鬆機制，使用近似策略來有效探索最佳子圖配置。這種方法允許對搜尋空間進行穩健的探索。廣泛的實驗證明了所提出方法的有效性和優越性，發現的子圖和編碼函數突顯了模型的適應性。

##### **Conditional Latent Space Molecular Scaffold Optimization for Accelerated Molecular Design**
2411.01423v1 by Onur Boyar, Hiroyuki Hanada, Ichiro Takeuchi

The rapid discovery of new chemical compounds is essential for advancing
global health and developing treatments. While generative models show promise
in creating novel molecules, challenges remain in ensuring the real-world
applicability of these molecules and finding such molecules efficiently. To
address this, we introduce Conditional Latent Space Molecular Scaffold
Optimization (CLaSMO), which combines a Conditional Variational Autoencoder
(CVAE) with Latent Space Bayesian Optimization (LSBO) to modify molecules
strategically while maintaining similarity to the original input. Our LSBO
setting improves the sample-efficiency of our optimization, and our
modification approach helps us to obtain molecules with higher chances of
real-world applicability. CLaSMO explores substructures of molecules in a
sample-efficient manner by performing BO in the latent space of a CVAE
conditioned on the atomic environment of the molecule to be optimized. Our
experiments demonstrate that CLaSMO efficiently enhances target properties with
minimal substructure modifications, achieving state-of-the-art results with a
smaller model and dataset compared to existing methods. We also provide an
open-source web application that enables chemical experts to apply CLaSMO in a
Human-in-the-Loop setting.

摘要：新化學化合物的快速發現對於促進全球健康和開發治療方法至關重要。儘管生成模型在創造新分子方面顯示出前景，但仍然存在挑戰，以確保這些分子的實際適用性並有效地找到這些分子。為了解決這個問題，我們引入了條件潛在空間分子支架最佳化 (CLaSMO)，它結合了條件變異自動編碼器 (CVAE) 與潛在空間貝氏最佳化 (LSBO)，以策略性地修改分子，同時保持與原始輸入的相似性。我們的 LSBO 設定改善了我們最佳化的樣本效率，我們的修改方法幫助我們獲得具有更高實際適用機會的分子。CLaSMO 以樣本有效的方式探索分子的子結構，方法是在 CVAE 的潛在空間中執行 BO，該空間以要最佳化的分子的原子環境為條件。我們的實驗表明，CLaSMO 以最小的子結構修改有效地增強了目標屬性，與現有方法相比，使用較小的模型和數據集實現了最先進的結果。我們還提供了一個開源網路應用程式，讓化學專家能夠在人機迴圈設定中應用 CLaSMO。

##### **Medical X-Ray Image Enhancement Using Global Contrast-Limited Adaptive Histogram Equalization**
2411.01373v1 by Sohrab Namazi Nia, Frank Y. Shih

In medical imaging, accurate diagnosis heavily relies on effective image
enhancement techniques, particularly for X-ray images. Existing methods often
suffer from various challenges such as sacrificing global image characteristics
over local image characteristics or vice versa. In this paper, we present a
novel approach, called G-CLAHE (Global-Contrast Limited Adaptive Histogram
Equalization), which perfectly suits medical imaging with a focus on X-rays.
This method adapts from Global Histogram Equalization (GHE) and Contrast
Limited Adaptive Histogram Equalization (CLAHE) to take both advantages and
avoid weakness to preserve local and global characteristics. Experimental
results show that it can significantly improve current state-of-the-art
algorithms to effectively address their limitations and enhance the contrast
and quality of X-ray images for diagnostic accuracy.

摘要：在醫學影像中，準確的診斷高度依賴於有效的影像增強技術，特別是 X 光影像。現有的方法通常會遇到各種挑戰，例如犧牲整體影像特性以換取局部影像特性，反之亦然。在本文中，我們提出了一種新穎的方法，稱為 G-CLAHE（全局對比度限制自適應直方圖均衡化），它非常適合於以 X 光為重點的醫學影像。此方法改編自全局直方圖均衡化 (GHE) 和對比度限制自適應直方圖均衡化 (CLAHE)，以取得兩者的優點，並避免弱點，以保留局部和全局特性。實驗結果表明，它可以顯著改善當前最先進的演算法，以有效解決其限制，並增強 X 光影像的對比度和品質，以利於診斷準確性。

##### **Guided Synthesis of Labeled Brain MRI Data Using Latent Diffusion Models for Segmentation of Enlarged Ventricles**
2411.01351v1 by Tim Ruschke, Jonathan Frederik Carlsen, Adam Espe Hansen, Ulrich Lindberg, Amalie Monberg Hindsholm, Martin Norgaard, Claes Nøhr Ladefoged

Deep learning models in medical contexts face challenges like data scarcity,
inhomogeneity, and privacy concerns. This study focuses on improving
ventricular segmentation in brain MRI images using synthetic data. We employed
two latent diffusion models (LDMs): a mask generator trained using 10,000
masks, and a corresponding SPADE image generator optimized using 6,881 scans to
create an MRI conditioned on a 3D brain mask. Conditioning the mask generator
on ventricular volume in combination with classifier-free guidance enabled the
control of the ventricular volume distribution of the generated synthetic
images. Next, the performance of the synthetic data was tested using three
nnU-Net segmentation models trained on a real, augmented and entirely synthetic
data, respectively. The resulting models were tested on a completely
independent hold-out dataset of patients with enlarged ventricles, with manual
delineation of the ventricles used as ground truth. The model trained on real
data showed a mean absolute error (MAE) of 9.09 \pm 12.18 mL in predicted
ventricular volume, while the models trained on synthetic and augmented data
showed MAEs of 7.52 \pm 4.81 mL and 6.23 \pm 4.33 mL, respectively. Both the
synthetic and augmented model also outperformed the state-of-the-art model
SynthSeg, which due to limited performance in cases of large ventricular
volumes, showed an MAE of 7.73 \pm 12.12 mL with a factor of 3 higher standard
deviation. The model trained on augmented data showed the highest Dice score of
0.892 \pm 0.05, slightly outperforming SynthSeg and on par with the model
trained on real data. The synthetic model performed similar to SynthSeg. In
summary, we provide evidence that guided synthesis of labeled brain MRI data
using LDMs improves the segmentation of enlarged ventricles and outperforms
existing state-of-the-art segmentation models.

摘要：<paragraph>在医学背景中，深度学习模型面临着数据稀缺性、不均匀性和隐私问题等挑战。本研究专注于使用合成数据改进脑部 MRI 图像中的心室分割。我们采用了两个潜在扩散模型 (LDM)：一个使用 10,000 个蒙版训练的蒙版生成器，以及一个使用 6,881 次扫描进行优化的相应 SPADE 图像生成器，以创建基于 3D 脑部蒙版的 MRI。对蒙版生成器进行心室体积调节，并结合无分类器指导，能够控制生成合成图像的心室体积分布。接下来，使用分别训练于真实、增强和完全合成数据上的三个 nnU-Net 分割模型测试了合成数据的性能。将训练所得的模型在完全独立的、具有扩大心室的患者的保留数据集上进行测试，并使用心室的手动描绘作为真实情况。在真实数据上训练的模型在预测的心室体积中显示出 9.09 ± 12.18 mL 的平均绝对误差 (MAE)，而在合成和增强数据上训练的模型显示出 7.52 ± 4.81 mL 和 6.23 ± 4.33 mL 的 MAE。合成模型和增强模型的性能均优于最先进的模型 SynthSeg，后者由于在大心室体积的情况下性能有限，显示出 7.73 ± 12.12 mL 的 MAE，标准差高出 3 倍。在增强数据上训练的模型显示出最高的 Dice 得分 0.892 ± 0.05，略优于 SynthSeg，并且与在真实数据上训练的模型相当。合成模型的性能与 SynthSeg 类似。总之，我们提供了证据表明，使用 LDM 对标记的脑部 MRI 数据进行引导合成可以改善扩大心室的分割，并且优于现有的最先进的分割模型。</paragraph>

##### **Causal reasoning in difference graphs**
2411.01292v1 by Charles K. Assaad

In epidemiology, understanding causal mechanisms across different populations
is essential for designing effective public health interventions. Recently,
difference graphs have been introduced as a tool to visually represent causal
variations between two distinct populations. While there has been progress in
inferring these graphs from data through causal discovery methods, there
remains a gap in systematically leveraging their potential to enhance causal
reasoning. This paper addresses that gap by establishing conditions for
identifying causal changes and effects using difference graphs and
observational data. It specifically focuses on identifying total causal changes
and total effects in a nonparametric framework, as well as direct causal
changes and direct effects in a linear context. In doing so, it provides a
novel approach to causal reasoning that holds potential for various public
health applications.

摘要：在流行病學中，了解不同人群之間的因果機制對於設計有效的公共衛生干預措施至關重要。最近，差異圖表已被引入作為一種工具，用於直觀地表示兩個不同人群之間的因果變化。儘管通過因果發現方法從數據中推斷這些圖表方面取得了進展，但在系統性地利用其增強因果推理的潛力方面仍然存在差距。本文通過建立使用差異圖表和觀察數據識別因果變化和因果效應的條件來解決這一差距。它特別側重於在非參數框架中識別總因果變化和總效應，以及在線性背景中識別直接因果變化和直接效應。這樣一來，它提供了一種因果推理的新方法，對各種公共衛生應用具有潛力。

##### **Designing a Robust Radiology Report Generation System**
2411.01153v1 by Sonit Singh

Recent advances in deep learning have enabled researchers to explore tasks at
the intersection of computer vision and natural language processing, such as
image captioning, visual question answering, visual dialogue, and visual
language navigation. Taking inspiration from image captioning, the task of
radiology report generation aims at automatically generating radiology reports
by having a comprehensive understanding of medical images. However,
automatically generating radiology reports from medical images is a challenging
task due to the complexity, diversity, and nature of medical images. In this
paper, we outline the design of a robust radiology report generation system by
integrating different modules and highlighting best practices drawing upon
lessons from our past work and also from relevant studies in the literature. We
also discuss the impact of integrating different components to form a single
integrated system. We believe that these best practices, when implemented,
could improve automatic radiology report generation, augment radiologists in
decision making, and expedite diagnostic workflow, in turn improve healthcare
and save human lives.

摘要：最近深度學習的進展使研究人員能夠探索電腦視覺和自然語言處理交集中的任務，例如影像標題、視覺問答、視覺對話和視覺語言導航。受影像標題的啟發，放射科報告生成的任務旨在透過全面了解醫學影像自動生成放射科報告。然而，由於醫學影像的複雜性、多樣性和性質，自動從醫學影像生成放射科報告是一項具有挑戰性的任務。在本文中，我們透過整合不同的模組並強調最佳實務，概述了健全的放射科報告生成系統的設計，這些實務汲取自我們過去的工作以及文獻中的相關研究。我們也討論了整合不同組件以形成單一整合系統的影響。我們相信，這些最佳實務在實施後，可以改善自動放射科報告生成，增強放射科醫師在決策制定中的能力，並加快診斷工作流程，進而改善醫療保健並拯救人命。

##### **LEARNER: Learning Granular Labels from Coarse Labels using Contrastive Learning**
2411.01144v1 by Gautam Gare, Jana Armouti, Nikhil Madaan, Rohan Panda, Tom Fox, Laura Hutchins, Amita Krishnan, Ricardo Rodriguez, Bennett DeBoisblanc, Deva Ramanan, John Galeotti

A crucial question in active patient care is determining if a treatment is
having the desired effect, especially when changes are subtle over short
periods. We propose using inter-patient data to train models that can learn to
detect these fine-grained changes within a single patient. Specifically, can a
model trained on multi-patient scans predict subtle changes in an individual
patient's scans? Recent years have seen increasing use of deep learning (DL) in
predicting diseases using biomedical imaging, such as predicting COVID-19
severity using lung ultrasound (LUS) data. While extensive literature exists on
successful applications of DL systems when well-annotated large-scale datasets
are available, it is quite difficult to collect a large corpus of personalized
datasets for an individual. In this work, we investigate the ability of recent
computer vision models to learn fine-grained differences while being trained on
data showing larger differences. We evaluate on an in-house LUS dataset and a
public ADNI brain MRI dataset. We find that models pre-trained on clips from
multiple patients can better predict fine-grained differences in scans from a
single patient by employing contrastive learning.

摘要：在主動患者照護中，一個關鍵問題是確定治療是否產生預期的效果，特別是在短時間內變化細微的情況下。我們提議使用患者間數據來訓練模型，以便學習偵測單一患者內這些細微的變化。具體來說，在多位患者掃描中訓練的模型是否可以預測個別患者掃描中的細微變化？近年來，深度學習 (DL) 在使用生物醫學影像預測疾病方面應用日益廣泛，例如使用肺部超音波 (LUS) 數據預測 COVID-19 的嚴重程度。儘管有大量文獻記載了在有標註的大規模數據集可用時 DL 系統的成功應用，但要為個人收集大量個人化數據集相當困難。在這項工作中，我們探討了近期電腦視覺模型在針對顯示較大差異的數據進行訓練時，學習細微差異的能力。我們在內部 LUS 數據集和公開的 ADNI 大腦 MRI 數據集上進行評估。我們發現，透過使用對比學習，在多位患者的片段上預先訓練的模型可以更好地預測單一患者掃描中的細微差異。

##### **Artificial Intelligence for Microbiology and Microbiome Research**
2411.01098v1 by Xu-Wen Wang, Tong Wang, Yang-Yu Liu

Advancements in artificial intelligence (AI) have transformed many scientific
fields, with microbiology and microbiome research now experiencing significant
breakthroughs through machine learning and deep learning applications. This
review provides a comprehensive overview of AI-driven approaches tailored for
microbiology and microbiome studies, emphasizing both technical advancements
and biological insights. We begin with an introduction to foundational AI
techniques, including primary machine learning paradigms and various deep
learning architectures, and offer guidance on choosing between machine learning
and deep learning methods based on specific research goals. The primary section
on application scenarios spans diverse research areas, from taxonomic
profiling, functional annotation & prediction, microbe-X interactions,
microbial ecology, metabolic modeling, precision nutrition, clinical
microbiology, to prevention & therapeutics. Finally, we discuss challenges
unique to this field, including the balance between interpretability and
complexity, the "small n, large p" problem, and the critical need for
standardized benchmarking datasets to validate and compare models. Together,
this review underscores AI's transformative role in microbiology and microbiome
research, paving the way for innovative methodologies and applications that
enhance our understanding of microbial life and its impact on our planet and
our health.

摘要：人工智慧 (AI) 的進步已轉變許多科學領域，而微生物學和微生物組研究現在正透過機器學習和深度學習應用體驗到顯著的突破。本篇評論提供 AI 驅動方法的全面概述，這些方法專為微生物學和微生物組研究量身打造，強調技術進步和生物見解。我們從基礎 AI 技術的介紹開始，包括主要的機器學習範例和各種深度學習架構，並提供根據具體研究目標在機器學習和深度學習方法之間進行選擇的指導。應用場景的主要部分涵蓋了從分類分析、功能註解和預測、微生物 X 相互作用、微生物生態、代謝建模、精準營養、臨床微生物學到預防和治療等多個研究領域。最後，我們討論了該領域獨有的挑戰，包括可解釋性和複雜性之間的平衡、「小 n，大 p」問題，以及驗證和比較模型的標準化基準數據集的關鍵需求。本篇評論共同強調了 AI 在微生物學和微生物組研究中的轉型作用，為創新方法和應用鋪平道路，這些方法和應用增強了我們對微生物生命及其對我們星球和我們健康的影響的理解。

##### **Contrasting with Symile: Simple Model-Agnostic Representation Learning for Unlimited Modalities**
2411.01053v1 by Adriel Saporta, Aahlad Puli, Mark Goldstein, Rajesh Ranganath

Contrastive learning methods, such as CLIP, leverage naturally paired
data-for example, images and their corresponding text captions-to learn general
representations that transfer efficiently to downstream tasks. While such
approaches are generally applied to two modalities, domains such as robotics,
healthcare, and video need to support many types of data at once. We show that
the pairwise application of CLIP fails to capture joint information between
modalities, thereby limiting the quality of the learned representations. To
address this issue, we present Symile, a simple contrastive learning approach
that captures higher-order information between any number of modalities. Symile
provides a flexible, architecture-agnostic objective for learning
modality-specific representations. To develop Symile's objective, we derive a
lower bound on total correlation, and show that Symile representations for any
set of modalities form a sufficient statistic for predicting the remaining
modalities. Symile outperforms pairwise CLIP, even with modalities missing in
the data, on cross-modal classification and retrieval across several
experiments including on an original multilingual dataset of 33M image, text
and audio samples and a clinical dataset of chest X-rays, electrocardiograms,
and laboratory measurements. All datasets and code used in this work are
publicly available at https://github.com/rajesh-lab/symile.

摘要：對比學習方法，例如 CLIP，利用自然配對的資料，例如影像及其對應的文字標題，來學習一般化表徵，並有效率地轉移到下游任務。雖然此類方法通常應用於兩種形式，但機器人技術、醫療保健和視訊等領域需要一次支援多種類型的資料。我們顯示，CLIP 的成對應用無法擷取形式間的聯合資訊，因此限制了學習表徵的品質。為了解決此問題，我們提出 Symile，這是一種簡單的對比學習方法，可以擷取任意數量的形式之間的高階資訊。Symile 提供了一個靈活且與架構無關的目標，用於學習特定於形式的表徵。為開發 Symile 的目標，我們推導出總相關性的下界，並顯示任何形式集合的 Symile 表徵形成一個充分的統計量，用於預測其餘形式。Symile 優於成對 CLIP，即使資料中缺少形式，也能在跨形式分類和檢索中表現出色，包括在一個包含 3300 萬張影像、文字和音訊樣本的原始多語言資料集和一個包含胸部 X 光、心電圖和實驗室測量的臨床資料集上進行的多次實驗。本研究中使用所有資料集和程式碼皆公開於 https://github.com/rajesh-lab/symile。

##### **Cross-Fundus Transformer for Multi-modal Diabetic Retinopathy Grading with Cataract**
2411.00726v1 by Fan Xiao, Junlin Hou, Ruiwei Zhao, Rui Feng, Haidong Zou, Lina Lu, Yi Xu, Juzhao Zhang

Diabetic retinopathy (DR) is a leading cause of blindness worldwide and a
common complication of diabetes. As two different imaging tools for DR grading,
color fundus photography (CFP) and infrared fundus photography (IFP) are
highly-correlated and complementary in clinical applications. To the best of
our knowledge, this is the first study that explores a novel multi-modal deep
learning framework to fuse the information from CFP and IFP towards more
accurate DR grading. Specifically, we construct a dual-stream architecture
Cross-Fundus Transformer (CFT) to fuse the ViT-based features of two fundus
image modalities. In particular, a meticulously engineered Cross-Fundus
Attention (CFA) module is introduced to capture the correspondence between CFP
and IFP images. Moreover, we adopt both the single-modality and multi-modality
supervisions to maximize the overall performance for DR grading. Extensive
experiments on a clinical dataset consisting of 1,713 pairs of multi-modal
fundus images demonstrate the superiority of our proposed method. Our code will
be released for public access.

摘要：糖尿病視網膜病變 (DR) 是全球失明的主要原因，也是糖尿病的常見併發症。作為 DR 分級的兩種不同的影像工具，彩色眼底攝影 (CFP) 和紅外線眼底攝影 (IFP) 在臨床應用中高度相關且互補。據我們所知，這是第一個探討創新的多模式深度學習框架，以融合 CFP 和 IFP 的資訊，以進行更準確的 DR 分級。具體來說，我們構建了一個雙流架構 Cross-Fundus Transformer (CFT)，以融合兩種眼底影像模式的基於 ViT 的特徵。特別是，引入了精心設計的 Cross-Fundus Attention (CFA) 模組，以捕捉 CFP 和 IFP 影像之間的對應關係。此外，我們採用單一模式和多模式監督，以最大化 DR 分級的整體效能。在由 1,713 對多模式眼底影像組成的臨床資料集上進行的廣泛實驗證明了我們提出的方法的優越性。我們的程式碼將會公開發布。

##### **CTPD: Cross-Modal Temporal Pattern Discovery for Enhanced Multimodal Electronic Health Records Analysis**
2411.00696v1 by Fuying Wang, Feng Wu, Yihan Tang, Lequan Yu

Integrating multimodal Electronic Health Records (EHR) data, such as
numerical time series and free-text clinical reports, has great potential in
predicting clinical outcomes. However, prior work has primarily focused on
capturing temporal interactions within individual samples and fusing multimodal
information, overlooking critical temporal patterns across patients. These
patterns, such as trends in vital signs like abnormal heart rate or blood
pressure, can indicate deteriorating health or an impending critical event.
Similarly, clinical notes often contain textual descriptions that reflect these
patterns. Identifying corresponding temporal patterns across different
modalities is crucial for improving the accuracy of clinical outcome
predictions, yet it remains a challenging task. To address this gap, we
introduce a Cross-Modal Temporal Pattern Discovery (CTPD) framework, designed
to efficiently extract meaningful cross-modal temporal patterns from multimodal
EHR data. Our approach introduces shared initial temporal pattern
representations which are refined using slot attention to generate temporal
semantic embeddings. To ensure rich cross-modal temporal semantics in the
learned patterns, we introduce a contrastive-based TPNCE loss for cross-modal
alignment, along with two reconstruction losses to retain core information of
each modality. Evaluations on two clinically critical tasks, 48-hour
in-hospital mortality and 24-hour phenotype classification, using the MIMIC-III
database demonstrate the superiority of our method over existing approaches.

摘要：整合多模态电子健康记录 (EHR) 数据（例如数值时间序列和自由文本临床报告）在预测临床结果方面具有巨大潜力。然而，以前的工作主要集中在捕捉单个样本中的时间交互并融合多模态信息，而忽略了患者之间的关键时间模式。这些模式（例如生命体征趋势，如异常心率或血压）可能表明健康状况恶化或即将发生的危重事件。类似地，临床笔记通常包含反映这些模式的文本描述。识别不同模态之间相应的时间模式对于提高临床结果预测的准确性至关重要，但它仍然是一项具有挑战性的任务。为了解决这一差距，我们引入了一个跨模态时间模式发现 (CTPD) 框架，旨在从多模态 EHR 数据中有效提取有意义的跨模态时间模式。我们的方法引入了共享的初始时间模式表示，这些表示使用插槽注意力进行优化以生成时间语义嵌入。为了确保学习模式中丰富的跨模态时间语义，我们引入了基于对比的 TPNCE 损失用于跨模态对齐，以及两个重建损失以保留每个模态的核心信息。在两个临床关键任务（48 小时院内死亡率和 24 小时表型分类）上的评估，使用 MIMIC-III 数据库证明了我们方法优于现有方法。

##### **Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**
2411.00916v1 by Mehdi Hosseini Chagahi, Saeed Mohammadi Dashtaki, Niloufar Delfan, Nadia Mohammadi, Alireza Samari, Behzad Moshiri, Md. Jalil Piran, U. Rajendra Acharya, Oliver Faust

Osteoporosis is a common condition that increases fracture risk, especially
in older adults. Early diagnosis is vital for preventing fractures, reducing
treatment costs, and preserving mobility. However, healthcare providers face
challenges like limited labeled data and difficulties in processing medical
images. This study presents a novel multi-modal learning framework that
integrates clinical and imaging data to improve diagnostic accuracy and model
interpretability. The model utilizes three pre-trained networks-VGG19,
InceptionV3, and ResNet50-to extract deep features from X-ray images. These
features are transformed using PCA to reduce dimensionality and focus on the
most relevant components. A clustering-based selection process identifies the
most representative components, which are then combined with preprocessed
clinical data and processed through a fully connected network (FCN) for final
classification. A feature importance plot highlights key variables, showing
that Medical History, BMI, and Height were the main contributors, emphasizing
the significance of patient-specific data. While imaging features were
valuable, they had lower importance, indicating that clinical data are crucial
for accurate predictions. This framework promotes precise and interpretable
predictions, enhancing transparency and building trust in AI-driven diagnoses
for clinical integration.

摘要：骨質疏鬆症是一種常見的疾病，會增加骨折風險，特別是老年人。早期診斷對於預防骨折、降低治療成本和維持行動力至關重要。然而，醫療保健提供者面臨挑戰，例如標記數據有限和處理醫學影像困難。本研究提出了一個新穎的多模式學習框架，它整合了臨床和影像數據，以提高診斷準確性和模型可解釋性。該模型利用三個預訓練網路 - VGG19、InceptionV3 和 ResNet50 - 從 X 光影像中提取深度特徵。這些特徵使用 PCA 轉換，以降低維度並專注於最相關的組成部分。基於群集的選擇過程識別最具代表性的組成部分，然後將其與預處理的臨床數據結合，並透過全連接網路 (FCN) 處理以進行最終分類。特徵重要性圖突顯了關鍵變數，顯示病史、BMI 和身高是主要貢獻者，強調了患者特定數據的重要性。雖然影像特徵很有價值，但它們的重要性較低，這表明臨床數據對於準確預測至關重要。這個框架促进了準確且可解釋的預測，提高了透明度，並建立了對 AI 驅動診斷的信任，以進行臨床整合。

##### **Deep learning-based auto-contouring of organs/structures-at-risk for pediatric upper abdominal radiotherapy**
2411.00594v1 by Mianyong Ding, Matteo Maspero, Annemieke S Littooij, Martine van Grotel, Raquel Davila Fajardo, Max M van Noesel, Marry M van den Heuvel-Eibrink, Geert O Janssens

Purposes: This study aimed to develop a computed tomography (CT)-based
multi-organ segmentation model for delineating organs-at-risk (OARs) in
pediatric upper abdominal tumors and evaluate its robustness across multiple
datasets. Materials and methods: In-house postoperative CTs from pediatric
patients with renal tumors and neuroblastoma (n=189) and a public dataset
(n=189) with CTs covering thoracoabdominal regions were used. Seventeen OARs
were delineated: nine by clinicians (Type 1) and eight using TotalSegmentator
(Type 2). Auto-segmentation models were trained using in-house (ModelPMC-UMCU)
and a combined dataset of public data (Model-Combined). Performance was
assessed with Dice Similarity Coefficient (DSC), 95% Hausdorff Distance (HD95),
and mean surface distance (MSD). Two clinicians rated clinical acceptability on
a 5-point Likert scale across 15 patient contours. Model robustness was
evaluated against sex, age, intravenous contrast, and tumor type. Results:
Model-PMC-UMCU achieved mean DSC values above 0.95 for five of nine OARs, while
spleen and heart ranged between 0.90 and 0.95. The stomach-bowel and pancreas
exhibited DSC values below 0.90. Model-Combined demonstrated improved
robustness across both datasets. Clinical evaluation revealed good usability,
with both clinicians rating six of nine Type 1 OARs above four and six of eight
Type 2 OARs above three. Significant performance 2 differences were only found
across age groups in both datasets, specifically in the left lung and pancreas.
The 0-2 age group showed the lowest performance. Conclusion: A multi-organ
segmentation model was developed, showcasing enhanced robustness when trained
on combined datasets. This model is suitable for various OARs and can be
applied to multiple datasets in clinical settings.

摘要：<paragraph>目的：本研究旨在开发一个基于计算机断层扫描 (CT) 的多器官分割模型，用于描绘小儿上腹部肿瘤中的危险器官 (OAR)，并评估其在多个数据集中的稳健性。材料和方法：使用小儿肾肿瘤和神经母细胞瘤患者 (n=189) 的院内术后 CT 以及包含胸腹区域 CT 的公共数据集 (n=189)。描绘了 17 个 OAR：9 个由临床医生描绘 (类型 1)，8 个使用 TotalSegmentator 描绘 (类型 2)。使用院内 (ModelPMC-UMCU) 和公共数据组合数据集 (Model-Combined) 训练自动分割模型。使用骰子相似性系数 (DSC)、95% 霍斯多夫距离 (HD95) 和平均表面距离 (MSD) 评估性能。两位临床医生使用 5 点李克特量表对 15 个患者轮廓的临床可接受性进行评级。针对性别、年龄、静脉对比和肿瘤类型评估模型的稳健性。结果：Model-PMC-UMCU 对九个 OAR 中的五个 OAR 的平均 DSC 值达到 0.95 以上，而脾脏和心脏在 0.90 到 0.95 之间。胃肠和胰腺的 DSC 值低于 0.90。Model-Combined 在两个数据集上都表现出改进的稳健性。临床评估显示出良好的可用性，两位临床医生对六个九个类型 1 OAR 的评分均高于四分，对八个类型 2 OAR 中的六个评分均高于三分。仅在两个数据集的年龄组中发现了显着的性能 2 差异，特别是在左肺和胰腺中。0-2 岁年龄组表现最差。结论：开发了一个多器官分割模型，在合并数据集上训练时显示出增强的稳健性。该模型适用于各种 OAR，并且可以在临床环境中应用于多个数据集。</paragraph>

##### **Enhancing the Traditional Chinese Medicine Capabilities of Large Language Model through Reinforcement Learning from AI Feedback**
2411.00897v1 by Song Yu, Xiaofei Xu, Fangfei Xu, Li Li

Although large language models perform well in understanding and responding
to user intent, their performance in specialized domains such as Traditional
Chinese Medicine (TCM) remains limited due to lack of expertise. In addition,
high-quality data related to TCM is scarce and difficult to obtain, making
large language models ineffective in handling TCM tasks. In this work, we
propose a framework to improve the performance of large language models for TCM
tasks using only a small amount of data. First, we use medical case data for
supervised fine-tuning of the large model, making it initially capable of
performing TCM tasks. Subsequently, we further optimize the model's performance
using reinforcement learning from AI feedback (RLAIF) to align it with the
preference data. The ablation study also demonstrated the performance gain is
attributed to both supervised fine-tuning and the direct policy optimization.
The experimental results show that the model trained with a small amount of
data achieves a significant performance improvement on a representative TCM
task.

摘要：儘管大型語言模型在理解和回應使用者意圖方面表現良好，但由於缺乏專業知識，它們在傳統中醫 (TCM) 等專業領域的表現仍然有限。此外，與中醫相關的高品質資料稀少且難以取得，這使得大型語言模型在處理中醫任務時效果不彰。在這項工作中，我們提出一個架構，使用少量資料來改善大型語言模型在中醫任務中的表現。首先，我們使用醫療案例資料對大型模型進行監督微調，使其最初具備執行中醫任務的能力。隨後，我們進一步使用人工智慧回饋的強化學習 (RLAIF) 來最佳化模型的表現，使其與偏好資料保持一致。消融研究也證明，表現提升歸功於監督微調和直接策略最佳化。實驗結果顯示，使用少量資料訓練的模型在代表性的中醫任務上取得顯著的表現提升。

##### **StepCountJITAI: simulation environment for RL with application to physical activity adaptive intervention**
2411.00336v1 by Karine Karine, Benjamin M. Marlin

The use of reinforcement learning (RL) to learn policies for just-in-time
adaptive interventions (JITAIs) is of significant interest in many behavioral
intervention domains including improving levels of physical activity. In a
messaging-based physical activity JITAI, a mobile health app is typically used
to send messages to a participant to encourage engagement in physical activity.
In this setting, RL methods can be used to learn what intervention options to
provide to a participant in different contexts. However, deploying RL methods
in real physical activity adaptive interventions comes with challenges: the
cost and time constraints of real intervention studies result in limited data
to learn adaptive intervention policies. Further, commonly used RL simulation
environments have dynamics that are of limited relevance to physical activity
adaptive interventions and thus shed little light on what RL methods may be
optimal for this challenging application domain. In this paper, we introduce
StepCountJITAI, an RL environment designed to foster research on RL methods
that address the significant challenges of policy learning for adaptive
behavioral interventions.

摘要：利用強化學習 (RL) 來學習即時適應性介入 (JITAI) 的策略，在許多行為介入領域中備受關注，包括提升體能活動的層級。在基於訊息的體能活動 JITAI 中，行動健康應用程式通常用於向參與者傳送訊息，以鼓勵參與體能活動。在此設定中，RL 方法可被用於學習在不同情境下提供給參與者的介入選項。然而，在實際體能活動適應性介入中部署 RL 方法會遇到挑戰：實際介入研究的成本和時間限制，導致可供學習適應性介入策略的資料有限。此外，常用的 RL 模擬環境具有與體能活動適應性介入相關性有限的動態，因此難以了解哪些 RL 方法可能最適合這個具挑戰性的應用領域。在本文中，我們介紹 StepCountJITAI，這是一個 RL 環境，旨在促進對 RL 方法的研究，以應對適應性行為介入策略學習的重大挑戰。

##### **Deep Learning Predicts Mammographic Breast Density in Clinical Breast Ultrasound Images**
2411.00891v1 by Arianna Bunnell, Thomas Wolfgruber, Brandon Quon, Kailee Hung, Brenda Hernandez, Peter Sadowski, John A. Shepherd

Background: Mammographic breast density, as defined by the American College
of Radiology's Breast Imaging Reporting and Data System (BI-RADS), is one of
the strongest risk factors for breast cancer, but is derived from mammographic
images. Breast ultrasound (BUS) is an alternative breast cancer screening
modality, particularly useful for early detection in low-resource, rural
contexts. The purpose of this study was to explore an artificial intelligence
(AI) model to predict BI-RADS mammographic breast density category from
clinical, handheld BUS imaging. Methods: All data are sourced from the Hawaii
and Pacific Islands Mammography Registry. We compared deep learning methods
from BUS imaging, as well as machine learning models from image statistics
alone. The use of AI-derived BUS density as a risk factor for breast cancer was
then compared to clinical BI-RADS breast density while adjusting for age. The
BUS data were split by individual into 70/20/10% groups for training,
validation, and testing. Results: 405,120 clinical BUS images from 14.066 women
were selected for inclusion in this study, resulting in 9.846 women for
training (302,574 images), 2,813 for validation (11,223 images), and 1,406 for
testing (4,042 images). On the held-out testing set, the strongest AI model
achieves AUROC 0.854 predicting BI-RADS mammographic breast density from BUS
imaging and outperforms all shallow machine learning methods based on image
statistics. In cancer risk prediction, age-adjusted AI BUS breast density
predicted 5-year breast cancer risk with 0.633 AUROC, as compared to 0.637
AUROC from age-adjusted clinical breast density. Conclusions: BI-RADS
mammographic breast density can be estimated from BUS imaging with high
accuracy using a deep learning model. Furthermore, we demonstrate that
AI-derived BUS breast density is predictive of 5-year breast cancer risk in our
population.

摘要：<paragraph>背景：由美國放射學院的乳房影像報告和資料系統 (BI-RADS) 所定義的乳房攝影乳房密度，是乳癌最強的風險因子之一，但卻是來自乳房攝影圖像。乳房超音波 (BUS) 是另一種乳癌篩檢方式，特別適用於資源匱乏的鄉村地區的早期偵測。本研究的目的是探索一種人工智慧 (AI) 模型，從臨床手持式 BUS 影像預測 BI-RADS 乳房攝影乳房密度類別。方法：所有資料都來自夏威夷和太平洋群島乳房攝影登記處。我們比較了來自 BUS 影像的深度學習方法，以及僅來自影像統計資料的機器學習模型。接著將 AI 衍生的 BUS 密度用作乳癌風險因子，與調整年齡後的臨床 BI-RADS 乳房密度進行比較。BUS 資料按個人分為 70/20/10% 的群組，用於訓練、驗證和測試。結果：本研究選取了來自 14.066 位女性的 405,120 張臨床 BUS 影像，得出 9.846 位女性用於訓練 (302,574 張影像)、2,813 位用於驗證 (11,223 張影像) 和 1,406 位用於測試 (4,042 張影像)。在保留的測試集中，最強大的 AI 模型在從 BUS 影像預測 BI-RADS 乳房攝影乳房密度時，達到 0.854 的 AUROC，並優於所有基於影像統計資料的淺層機器學習方法。在癌症風險預測中，調整年齡後的 AI BUS 乳房密度預測了 5 年乳癌風險，AUROC 為 0.633，而調整年齡後的臨床乳房密度的 AUROC 為 0.637。結論：使用深度學習模型，可以從 BUS 影像估計出 BI-RADS 乳房攝影乳房密度，且準確度很高。此外，我們證明 AI 衍生的 BUS 乳房密度可以預測我們族群的 5 年乳癌風險。</paragraph>

##### **Monitoring fairness in machine learning models that predict patient mortality in the ICU**
2411.00190v1 by Tempest A. van Schaik, Xinggang Liu, Louis Atallah, Omar Badawi

This work proposes a fairness monitoring approach for machine learning models
that predict patient mortality in the ICU. We investigate how well models
perform for patient groups with different race, sex and medical diagnoses. We
investigate Documentation bias in clinical measurement, showing how fairness
analysis provides a more detailed and insightful comparison of model
performance than traditional accuracy metrics alone.

摘要：這項工作提出了一個公平性監控方法，用於預測 ICU 中病人死亡率的機器學習模型。我們探討模型對不同種族、性別和醫療診斷的病人組別執行得有多好。我們探討臨床測量中的文件偏誤，展示公平性分析如何提供比傳統準確度量度更詳細且有見地的模型效能比較。

##### **Clinical Evaluation of Medical Image Synthesis: A Case Study in Wireless Capsule Endoscopy**
2411.00178v1 by Panagiota Gatoula, Dimitrios E. Diamantis, Anastasios Koulaouzidis, Cristina Carretero, Stefania Chetcuti-Zammit, Pablo Cortegoso Valdivia, Begoña González-Suárez, Alessandro Mussetto, John Plevris, Alexander Robertson, Bruno Rosa, Ervin Toth, Dimitris K. Iakovidis

Sharing retrospectively acquired data is essential for both clinical research
and training. Synthetic Data Generation (SDG), using Artificial Intelligence
(AI) models, can overcome privacy barriers in sharing clinical data, enabling
advancements in medical diagnostics. This study focuses on the clinical
evaluation of medical SDG, with a proof-of-concept investigation on diagnosing
Inflammatory Bowel Disease (IBD) using Wireless Capsule Endoscopy (WCE) images.
The paper contributes by a) presenting a protocol for the systematic evaluation
of synthetic images by medical experts and b) applying it to assess TIDE-II, a
novel variational autoencoder-based model for high-resolution WCE image
synthesis, with a comprehensive qualitative evaluation conducted by 10
international WCE specialists, focusing on image quality, diversity, realism,
and clinical decision-making. The results show that TIDE-II generates
clinically relevant WCE images, helping to address data scarcity and enhance
diagnostic tools. The proposed protocol serves as a reference for future
research on medical image-generation techniques.

摘要：回顧性獲取的資料分享對於臨床研究和訓練至關重要。使用人工智慧 (AI) 模型的合成資料產生 (SDG) 能夠克服臨床資料共享中的隱私障礙，促進醫療診斷的進展。本研究專注於臨床評估醫學 SDG，並透過無線膠囊內視鏡 (WCE) 影像診斷發炎性腸道疾病 (IBD) 的概念驗證調查。本文的貢獻包括：a) 提出由醫學專家系統性評估合成影像的協定，以及 b) 將其應用於評估 TIDE-II，這是一個用於高解析度 WCE 影像合成的變異自動編碼器模型，並由 10 位國際 WCE 專家進行全面的品質評估，重點在於影像品質、多樣性、真實性，以及臨床決策制定。結果顯示 TIDE-II 產生了臨床相關的 WCE 影像，有助於解決資料稀少的問題，並增強診斷工具。所提出的協定可作為未來醫學影像產生技術研究的參考。

##### **Beyond Label Attention: Transparency in Language Models for Automated Medical Coding via Dictionary Learning**
2411.00173v1 by John Wu, David Wu, Jimeng Sun

Medical coding, the translation of unstructured clinical text into
standardized medical codes, is a crucial but time-consuming healthcare
practice. Though large language models (LLM) could automate the coding process
and improve the efficiency of such tasks, interpretability remains paramount
for maintaining patient trust. Current efforts in interpretability of medical
coding applications rely heavily on label attention mechanisms, which often
leads to the highlighting of extraneous tokens irrelevant to the ICD code. To
facilitate accurate interpretability in medical language models, this paper
leverages dictionary learning that can efficiently extract sparsely activated
representations from dense language model embeddings in superposition. Compared
with common label attention mechanisms, our model goes beyond token-level
representations by building an interpretable dictionary which enhances the
mechanistic-based explanations for each ICD code prediction, even when the
highlighted tokens are medically irrelevant. We show that dictionary features
can steer model behavior, elucidate the hidden meanings of upwards of 90% of
medically irrelevant tokens, and are human interpretable.

摘要：醫療編碼是將非結構化的臨床文本轉換為標準化醫療代碼的過程，是一項至關重要的醫療保健實務，但耗時費力。儘管大型語言模型 (LLM) 可以自動化編碼流程並提升此類任務的效率，但可解釋性對於維護患者信任仍然至關重要。目前在醫療編碼應用程式的可解釋性方面所做的努力，極度依賴標籤注意機制，這通常會導致強調與 ICD 代碼無關的無關符號。為了促進醫療語言模型的準確可解釋性，本文利用字典學習，可以有效地從疊加的稠密語言模型嵌入中提取稀疏激活的表示。與常見的標籤注意機制相比，我們的模型超越了符號層級的表示，建立了一個可解釋的字典，增強了對每個 ICD 代碼預測的基於機制的解釋，即使強調的符號在醫學上無關緊要。我們證明字典特徵可以引導模型行為，闡明 90% 以上在醫學上無關的符號的隱藏意義，並且人類可以解釋。

##### **Navigating the Unknown: A Chat-Based Collaborative Interface for Personalized Exploratory Tasks**
2410.24032v1 by Yingzhe Peng, Xiaoting Qin, Zhiyang Zhang, Jue Zhang, Qingwei Lin, Xu Yang, Dongmei Zhang, Saravan Rajmohan, Qi Zhang

The rise of large language models (LLMs) has revolutionized user interactions
with knowledge-based systems, enabling chatbots to synthesize vast amounts of
information and assist with complex, exploratory tasks. However, LLM-based
chatbots often struggle to provide personalized support, particularly when
users start with vague queries or lack sufficient contextual information. This
paper introduces the Collaborative Assistant for Personalized Exploration
(CARE), a system designed to enhance personalization in exploratory tasks by
combining a multi-agent LLM framework with a structured user interface. CARE's
interface consists of a Chat Panel, Solution Panel, and Needs Panel, enabling
iterative query refinement and dynamic solution generation. The multi-agent
framework collaborates to identify both explicit and implicit user needs,
delivering tailored, actionable solutions. In a within-subject user study with
22 participants, CARE was consistently preferred over a baseline LLM chatbot,
with users praising its ability to reduce cognitive load, inspire creativity,
and provide more tailored solutions. Our findings highlight CARE's potential to
transform LLM-based systems from passive information retrievers to proactive
partners in personalized problem-solving and exploration.

摘要：大型語言模型 (LLM) 的興起徹底改變了使用者與基於知識的系統互動的方式，讓聊天機器人能夠綜合大量的資訊，並協助進行複雜的探索性任務。然而，基於 LLM 的聊天機器人通常難以提供個人化的支援，特別是在使用者一開始提出的查詢很模糊，或缺乏足夠的脈絡資訊時。本文介紹了個人化探索的協作助理 (CARE)，一個旨在透過結合多重代理 LLM 架構與結構化的使用者介面來增強探索性任務中個人化的系統。CARE 的介面包含聊天面板、解決方案面板和需求面板，可進行反覆的查詢精煉和動態的解決方案產生。多重代理架構協作識別明確和隱含的使用者需求，提供客製化且可行的解決方案。在一個有 22 位參與者的受試者內研究中，CARE 持續獲得比基準 LLM 聊天機器人更好的評價，使用者讚賞其減輕認知負擔、激發創造力，以及提供更客製化解決方案的能力。我們的發現突顯了 CARE 將基於 LLM 的系統從被動的資訊檢索者轉變為個人化問題解決和探索中的主動夥伴的潛力。

##### **Neural Network Verification with PyRAT**
2410.23903v1 by Augustin Lemesle, Julien Lehmann, Tristan Le Gall

As AI systems are becoming more and more popular and used in various critical
domains (health, transport, energy, ...), the need to provide guarantees and
trust of their safety is undeniable. To this end, we present PyRAT, a tool
based on abstract interpretation to verify the safety and the robustness of
neural networks. In this paper, we describe the different abstractions used by
PyRAT to find the reachable states of a neural network starting from its input
as well as the main features of the tool to provide fast and accurate analysis
of neural networks. PyRAT has already been used in several collaborations to
ensure safety guarantees, with its second place at the VNN-Comp 2024 showcasing
its performance.

摘要：隨著 AI 系統越來越普及，並用於各種關鍵領域（健康、運輸、能源，...），提供其安全保證和信任的需求是不容否認的。為此，我們提出了 PyRAT，一個基於抽象詮釋的工具，用於驗證神經網路的安全性和穩健性。在本文中，我們描述了 PyRAT 用於從神經網路輸入中找出可達狀態的不同抽象，以及該工具的主要功能，以提供快速且準確的神經網路分析。PyRAT 已在多項合作中用於確保安全保證，其在 VNN-Comp 2024 中獲得第二名，展示了其效能。

##### **Counterfactual MRI Data Augmentation using Conditional Denoising Diffusion Generative Models**
2410.23835v1 by Pedro Morão, Joao Santinha, Yasna Forghani, Nuno Loução, Pedro Gouveia, Mario A. T. Figueiredo

Deep learning (DL) models in medical imaging face challenges in
generalizability and robustness due to variations in image acquisition
parameters (IAP). In this work, we introduce a novel method using conditional
denoising diffusion generative models (cDDGMs) to generate counterfactual
magnetic resonance (MR) images that simulate different IAP without altering
patient anatomy. We demonstrate that using these counterfactual images for data
augmentation can improve segmentation accuracy, particularly in
out-of-distribution settings, enhancing the overall generalizability and
robustness of DL models across diverse imaging conditions. Our approach shows
promise in addressing domain and covariate shifts in medical imaging. The code
is publicly available at https:
//github.com/pedromorao/Counterfactual-MRI-Data-Augmentation

摘要：深度學習 (DL) 模型在醫學影像中會因影像擷取參數 (IAP) 的變化而面臨可概括性和穩健性的挑戰。在這項工作中，我們提出了一種使用條件式去噪擴散生成模型 (cDDGMs) 的新方法，以產生反事實磁共振 (MR) 影像，模擬不同的 IAP，而不會改變患者的解剖結構。我們證明使用這些反事實影像進行資料擴充可以提高分割準確度，特別是在分佈外設定中，增強 DL 模型在不同影像條件下的整體可概括性和穩健性。我們的做法顯示了解決醫學影像中的領域和協變數轉移的前景。程式碼已公開於 https:
//github.com/pedromorao/Counterfactual-MRI-Data-Augmentation

##### **Parameter-Efficient Fine-Tuning Medical Multimodal Large Language Models for Medical Visual Grounding**
2410.23822v1 by Jinlong He, Pengfei Li, Gang Liu, Shenjun Zhong

Multimodal Large Language Models (MLLMs) inherit the superior text
understanding capabilities of LLMs and extend these capabilities to multimodal
scenarios. These models achieve excellent results in the general domain of
multimodal tasks. However, in the medical domain, the substantial training
costs and the requirement for extensive medical data pose challenges to the
development of medical MLLMs. Furthermore, due to the free-text form of
answers, tasks such as visual grounding that need to produce output in a
prescribed form become difficult for MLLMs. So far, there have been no medical
MLLMs works in medical visual grounding area. For the medical vision grounding
task, which involves identifying locations in medical images based on short
text descriptions, we propose Parameter-efficient Fine-tuning medical
multimodal large language models for Medcial Visual Grounding (PFMVG). To
validate the performance of the model, we evaluate it on a public benchmark
dataset for medical visual grounding, where it achieves competitive results,
and significantly outperforming GPT-4v. Our code will be open sourced after
peer review.

摘要：多模态大型语言模型 (MLLM) 继承了 LLM 优越的文本理解能力，并将这些能力扩展到多模态场景。这些模型在多模态任务的通用领域中取得了出色的成果。然而，在医学领域，大量的训练成本和对广泛医学数据的需求对医学 MLLM 的发展构成了挑战。此外，由于答案的自由文本形式，需要以规定形式生成输出的任务（例如视觉基础）对于 MLLM 来说变得困难。到目前为止，还没有医学 MLLM 在医学视觉基础领域工作。对于医学视觉基础任务，它涉及根据简短的文本描述识别医学图像中的位置，我们提出了用于医学视觉基础的参数高效微调医学多模态大型语言模型 (PFMVG)。为了验证模型的性能，我们在医学视觉基础的公共基准数据集上对其进行了评估，它取得了有竞争力的结果，并且明显优于 GPT-4v。我们的代码将在同行评审后开源。

##### **Improving snore detection under limited dataset through harmonic/percussive source separation and convolutional neural networks**
2410.23796v1 by F. D. Gonzalez-Martinez, J. J. Carabias-Orti, F. J. Canadas-Quesada, N. Ruiz-Reyes, D. Martinez-Munoz, S. Garcia-Galan

Snoring, an acoustic biomarker commonly observed in individuals with
Obstructive Sleep Apnoea Syndrome (OSAS), holds significant potential for
diagnosing and monitoring this recognized clinical disorder. Irrespective of
snoring types, most snoring instances exhibit identifiable harmonic patterns
manifested through distinctive energy distributions over time. In this work, we
propose a novel method to differentiate monaural snoring from non-snoring
sounds by analyzing the harmonic content of the input sound using
harmonic/percussive sound source separation (HPSS). The resulting feature,
based on the harmonic spectrogram from HPSS, is employed as input data for
conventional neural network architectures, aiming to enhance snoring detection
performance even under a limited data learning framework. To evaluate the
performance of our proposal, we studied two different scenarios: 1) using a
large dataset of snoring and interfering sounds, and 2) using a reduced
training set composed of around 1% of the data material. In the former
scenario, the proposed HPSS-based feature provides competitive results compared
to other input features from the literature. However, the key advantage of the
proposed method lies in the superior performance of the harmonic spectrogram
derived from HPSS in a limited data learning context. In this particular
scenario, using the proposed harmonic feature significantly enhances the
performance of all the studied architectures in comparison to the classical
input features documented in the existing literature. This finding clearly
demonstrates that incorporating harmonic content enables more reliable learning
of the essential time-frequency characteristics that are prevalent in most
snoring sounds, even in scenarios where the amount of training data is limited.

摘要：鼾聲是一種在阻塞性睡眠呼吸中止症候群 (OSAS) 患者中常見的聲學生物標記，對於診斷和監控此公認的臨床疾病具有顯著潛力。無論鼾聲類型如何，大多數鼾聲都表現出可識別的諧波模式，並隨著時間推移表現出獨特的能量分佈。在這項工作中，我們提出了一種新方法，通過使用諧波/打擊聲源分離 (HPSS) 分析輸入聲音的諧波內容，將單聲道鼾聲與非鼾聲區分開來。基於 HPSS 的諧波頻譜圖所產生的特徵，被用作傳統神經網路架構的輸入資料，旨在即使在有限資料學習架構下也能增強鼾聲偵測效能。為了評估我們提案的效能，我們研究了兩種不同的情境：1) 使用大量的鼾聲和干擾聲資料集，以及 2) 使用由約 1% 資料素材組成的縮減訓練集。在前一種情境中，與文獻中的其他輸入特徵相比，所提出的基於 HPSS 的特徵提供了具有競爭力的結果。然而，所提出方法的主要優點在於，在有限資料學習情境中，源自 HPSS 的諧波頻譜圖具有優異的效能。在這個特定情境中，與現有文獻中記載的傳統輸入特徵相比，使用所提出的諧波特徵顯著增強了所有研究架構的效能。這一發現清楚地表明，即使在訓練資料量有限的情境中，納入諧波內容也能夠更可靠地學習大多數鼾聲中普遍存在的必要時頻特徵。

##### **The Potential of LLMs in Medical Education: Generating Questions and Answers for Qualification Exams**
2410.23769v1 by Yunqi Zhu, Wen Tang, Ying Sun, Xuebing Yang

Recent research on large language models (LLMs) has primarily focused on
their adaptation and application in specialized domains. The application of
LLMs in the medical field is mainly concentrated on tasks such as the
automation of medical report generation, summarization, diagnostic reasoning,
and question-and-answer interactions between doctors and patients. The
challenge of becoming a good teacher is more formidable than that of becoming a
good student, and this study pioneers the application of LLMs in the field of
medical education. In this work, we investigate the extent to which LLMs can
generate medical qualification exam questions and corresponding answers based
on few-shot prompts. Utilizing a real-world Chinese dataset of elderly chronic
diseases, we tasked the LLMs with generating open-ended questions and answers
based on a subset of sampled admission reports across eight widely used LLMs,
including ERNIE 4, ChatGLM 4, Doubao, Hunyuan, Spark 4, Qwen, Llama 3, and
Mistral. Furthermore, we engaged medical experts to manually evaluate these
open-ended questions and answers across multiple dimensions. The study found
that LLMs, after using few-shot prompts, can effectively mimic real-world
medical qualification exam questions, whereas there is room for improvement in
the correctness, evidence-based statements, and professionalism of the
generated answers. Moreover, LLMs also demonstrate a decent level of ability to
correct and rectify reference answers. Given the immense potential of
artificial intelligence in the medical field, the task of generating questions
and answers for medical qualification exams aimed at medical students, interns
and residents can be a significant focus of future research.

摘要：<paragraph>針對大型語言模型 (LLM) 的近期研究主要集中在它們在特定領域的適應和應用。LLM 在醫學領域的應用主要集中在自動化病歷產生、摘要、診斷推理以及醫生與病人之間問答互動等任務。成為一名好老師的挑戰比成為一名好學生更艱鉅，而本研究開創了 LLM 在醫學教育領域的應用。在這項工作中，我們探討了 LLM 在少數提示下產生醫學資格考試題目和對應答案的程度。利用一個真實世界的老年慢性疾病中文數據集，我們讓 LLM 根據八個廣泛使用的 LLM（包括 ERNIE 4、ChatGLM 4、豆包、混元、Spark 4、Qwen、Llama 3 和 Mistral）抽取的入院報告子集產生開放式問題和答案。此外，我們聘請醫學專家手動評估這些開放式問題和答案的多個面向。研究發現，LLM 在使用少數提示後，可以有效模擬真實世界的醫學資格考試題目，而產生的答案在正確性、循證陳述和專業性方面仍有改進空間。此外，LLM 也展現出相當程度更正和修正參考答案的能力。鑑於人工智能在醫學領域的巨大潛力，產生針對醫學生、實習醫生和住院醫生的醫學資格考試題目和答案的任務，可以成為未來研究的重要重點。</paragraph>

##### **Artificial intelligence to improve clinical coding practice in Scandinavia: a crossover randomized controlled trial**
2410.23725v1 by Taridzo Chomutare, Therese Olsen Svenning, Miguel Ángel Tejedor Hernández, Phuong Dinh Ngo, Andrius Budrionis, Kaisa Markljung, Lill Irene Hind, Torbjørn Torsvik, Karl Øyvind Mikalsen, Aleksandar Babic, Hercules Dalianis

\textbf{Trial design} Crossover randomized controlled trial. \textbf{Methods}
An AI tool, Easy-ICD, was developed to assist clinical coders and was tested
for improving both accuracy and time in a user study in Norway and Sweden.
Participants were randomly assigned to two groups, and crossed over between
coding complex (longer) texts versus simple (shorter) texts, while using our
tool versus not using our tool. \textbf{Results} Based on Mann-Whitney U test,
the median coding time difference for complex clinical text sequences was 123
seconds (\emph{P}\textless.001, 95\% CI: 81 to 164), representing a 46\%
reduction in median coding time when our tool is used. There was no significant
time difference for simpler text sequences. For coding accuracy, the
improvement we noted for both complex and simple texts was not significant.
\textbf{Conclusions} This study demonstrates the potential of AI to transform
common tasks in clinical workflows, with ostensible positive impacts on work
efficiencies for complex clinical coding tasks. Further studies within hospital
workflows are required before these presumed impacts can be more clearly
understood.

摘要：**試驗設計** 交叉隨機對照試驗。**方法**開發了一種 AI 工具 Easy-ICD，以協助臨床編碼員，並在挪威和瑞典進行的一項使用者研究中測試其在準確性和時間上的改進。參與者被隨機分為兩組，並在使用我們的工具與不使用我們的工具的情況下，對複雜（較長）文本與簡單（較短）文本進行編碼交叉。**結果**根據 Mann-Whitney U 檢定，複雜臨床文本序列的中位數編碼時間差為 123 秒（\emph{P}\textless.001，95% CI：81 至 164），表示使用我們的工具時中位數編碼時間減少了 46%。對於較簡單的文本序列，沒有顯著的時間差異。對於編碼準確性，我們對複雜文本和簡單文本所觀察到的改進並不顯著。**結論**這項研究展示了 AI 在轉換臨床工作流程中常見任務的潛力，對複雜臨床編碼任務的工作效率有明顯的正面影響。在這些假設影響能更清楚地被理解之前，需要在醫院工作流程中進行進一步的研究。

##### **Enhancing Brain Tumor Classification Using TrAdaBoost and Multi-Classifier Deep Learning Approaches**
2411.00875v1 by Mahin Mohammadi, Saman Jamshidi

Brain tumors pose a serious health threat due to their rapid growth and
potential for metastasis. While medical imaging has advanced significantly,
accurately identifying and characterizing these tumors remains a challenge.
This study addresses this challenge by leveraging the innovative TrAdaBoost
methodology to enhance the Brain Tumor Segmentation (BraTS2020) dataset, aiming
to improve the efficiency and accuracy of brain tumor classification. Our
approach combines state-of-the-art deep learning algorithms, including the
Vision Transformer (ViT), Capsule Neural Network (CapsNet), and convolutional
neural networks (CNNs) such as ResNet-152 and VGG16. By integrating these
models within a multi-classifier framework, we harness the strengths of each
approach to achieve more robust and reliable tumor classification. A novel
decision template is employed to synergistically combine outputs from different
algorithms, further enhancing classification accuracy. To augment the training
process, we incorporate a secondary dataset, "Brain Tumor MRI Dataset," as a
source domain, providing additional data for model training and improving
generalization capabilities. Our findings demonstrate a high accuracy rate in
classifying tumor versus non-tumor images, signifying the effectiveness of our
approach in the medical imaging domain. This study highlights the potential of
advanced machine learning techniques to contribute significantly to the early
and accurate diagnosis of brain tumors, ultimately improving patient outcomes.

摘要：腦瘤由於生長快速且有轉移的可能性，對健康構成嚴重威脅。雖然醫學影像技術已大幅進步，但精準辨識和描述這些腫瘤仍然是一大挑戰。本研究透過運用創新的 TrAdaBoost 方法提升腦瘤分割 (BraTS2020) 資料集來解決這個挑戰，目標是提升腦瘤分類的效率和準確度。我們的做法結合了最先進的深度學習演算法，包括視覺轉換器 (ViT)、膠囊神經網路 (CapsNet) 和卷積神經網路 (CNN)，例如 ResNet-152 和 VGG16。透過在多分類器架構中整合這些模型，我們利用每種方法的優點來達成更強健且可靠的腫瘤分類。採用新穎的決策範本，以綜效結合不同演算法的輸出，進一步提升分類準確度。為了擴充訓練流程，我們納入次要資料集「腦瘤 MRI 資料集」作為來源網域，提供額外的資料用於模型訓練，並提升概化能力。我們的研究結果顯示，在分類腫瘤與非腫瘤影像時，準確率很高，表示我們的方法在醫學影像領域中很有效。本研究強調進階機器學習技術的潛力，對腦瘤的早期且精準診斷有顯著貢獻，進而改善病患的治療結果。

##### **Deep Convolutional Neural Networks on Multiclass Classification of Three-Dimensional Brain Images for Parkinson's Disease Stage Prediction**
2410.23649v1 by Guan-Hua Huang, Wan-Chen Lai, Tai-Been Chen, Chien-Chin Hsu, Huei-Yung Chen, Yi-Chen Wu, Li-Ren Yeh

Parkinson's disease (PD), a degenerative disorder of the central nervous
system, is commonly diagnosed using functional medical imaging techniques such
as single-photon emission computed tomography (SPECT). In this study, we
utilized two SPECT data sets (n = 634 and n = 202) from different hospitals to
develop a model capable of accurately predicting PD stages, a multiclass
classification task. We used the entire three-dimensional (3D) brain images as
input and experimented with various model architectures. Initially, we treated
the 3D images as sequences of two-dimensional (2D) slices and fed them
sequentially into 2D convolutional neural network (CNN) models pretrained on
ImageNet, averaging the outputs to obtain the final predicted stage. We also
applied 3D CNN models pretrained on Kinetics-400. Additionally, we incorporated
an attention mechanism to account for the varying importance of different
slices in the prediction process. To further enhance model efficacy and
robustness, we simultaneously trained the two data sets using weight sharing, a
technique known as cotraining. Our results demonstrated that 2D models
pretrained on ImageNet outperformed 3D models pretrained on Kinetics-400, and
models utilizing the attention mechanism outperformed both 2D and 3D models.
The cotraining technique proved effective in improving model performance when
the cotraining data sets were sufficiently large.

摘要：帕金森氏症 (PD) 是一種中樞神經系統退化性疾病，通常使用功能性醫學影像技術，例如單光子發射斷層掃描 (SPECT) 來診斷。在這項研究中，我們利用來自不同醫院的兩個 SPECT 資料集 (n = 634 和 n = 202) 來開發一個模型，能夠準確預測 PD 分期，這是一個多類別分類任務。我們使用整個三維 (3D) 大腦影像作為輸入，並嘗試使用各種模型架構。最初，我們將 3D 影像視為二維 (2D) 切片的序列，並將它們依序輸入到預先在 ImageNet 上訓練過的 2D 卷積神經網路 (CNN) 模型中，取平均輸出值來取得最終預測的期別。我們也應用預先在 Kinetics-400 上訓練過的 3D CNN 模型。此外，我們納入一個注意力機制，以考量不同切片在預測過程中的重要性差異。為了進一步增強模型的效能和穩健性，我們使用權重共享同時訓練兩個資料集，這是一種稱為共同訓練的技術。我們的結果顯示，預先在 ImageNet 上訓練過的 2D 模型優於預先在 Kinetics-400 上訓練過的 3D 模型，而使用注意力機制的模型則優於 2D 和 3D 模型。當共同訓練的資料集夠大的時候，共同訓練技術已被證明能有效改善模型效能。

##### **MS-Glance: Non-semantic context vectors and the applications in supervising image reconstruction**
2410.23577v1 by Ziqi Gao, Wendi Yang, Yujia Li, Lei Xing, S. Kevin Zhou

Non-semantic context information is crucial for visual recognition, as the
human visual perception system first uses global statistics to process scenes
rapidly before identifying specific objects. However, while semantic
information is increasingly incorporated into computer vision tasks such as
image reconstruction, non-semantic information, such as global spatial
structures, is often overlooked. To bridge the gap, we propose a biologically
informed non-semantic context descriptor, \textbf{MS-Glance}, along with the
Glance Index Measure for comparing two images. A Global Glance vector is
formulated by randomly retrieving pixels based on a perception-driven rule from
an image to form a vector representing non-semantic global context, while a
local Glance vector is a flattened local image window, mimicking a zoom-in
observation. The Glance Index is defined as the inner product of two
standardized sets of Glance vectors. We evaluate the effectiveness of
incorporating Glance supervision in two reconstruction tasks: image fitting
with implicit neural representation (INR) and undersampled MRI reconstruction.
Extensive experimental results show that MS-Glance outperforms existing image
restoration losses across both natural and medical images. The code is
available at \url{https://github.com/Z7Gao/MSGlance}.

摘要：非语义上下文信息对于视觉识别至关重要，因为人类视觉感知系统首先使用全局统计数据来快速处理场景，然后再识别特定对象。然而，虽然语义信息正越来越多地融入到图像重建等计算机视觉任务中，但非语义信息（如全局空间结构）却常常被忽视。为了弥合这一差距，我们提出了一个生物信息启发的非语义上下文描述符，即 \textbf{MS-Glance}，以及用于比较两幅图像的 Glance 指数度量。通过根据感知驱动的规则从图像中随机检索像素来构建一个全局 Glance 向量，以形成一个表示非语义全局上下文的向量，而局部 Glance 向量是一个扁平的局部图像窗口，模仿了放大观察。Glance 指数被定义为两组标准化的 Glance 向量的内积。我们评估了在两个重建任务中纳入 Glance 监督的有效性：具有隐式神经表征 (INR) 的图像拟合和欠采样 MRI 重建。大量的实验结果表明，MS-Glance 在自然图像和医学图像中都优于现有的图像恢复损失。代码可在 \url{https://github.com/Z7Gao/MSGlance} 获得。

##### **LEAF: Learning and Evaluation Augmented by Fact-Checking to Improve Factualness in Large Language Models**
2410.23526v1 by Hieu Tran, Junda Wang, Yujan Ting, Weijing Huang, Terrence Chen

Large language models (LLMs) have shown remarkable capabilities in various
natural language processing tasks, yet they often struggle with maintaining
factual accuracy, particularly in knowledge-intensive domains like healthcare.
This study introduces LEAF: Learning and Evaluation Augmented by Fact-Checking,
a novel approach designed to enhance the factual reliability of LLMs, with a
focus on medical question answering (QA). LEAF utilizes a dual strategy to
enhance the factual accuracy of responses from models such as Llama 3 70B
Instruct and Llama 3 8B Instruct. The first strategy, Fact-Check-Then-RAG,
improves Retrieval-Augmented Generation (RAG) by incorporating fact-checking
results to guide the retrieval process without updating model parameters. The
second strategy, Learning from Fact-Checks via Self-Training, involves
supervised fine-tuning (SFT) on fact-checked responses or applying Simple
Preference Optimization (SimPO) with fact-checking as a ranking mechanism, both
updating LLM parameters from supervision. These findings suggest that
integrating fact-checked responses whether through RAG enhancement or
self-training enhances the reliability and factual correctness of LLM outputs,
offering a promising solution for applications where information accuracy is
crucial.

摘要：大型語言模型 (LLM) 在各種自然語言處理任務中展現出卓越的能力，然而它們在維持事實準確性方面常常面臨困難，特別是在像醫療保健這樣的知識密集領域。本研究引入了 LEAF：透過事實查核增強的學習與評估，這是一種新穎的方法，旨在提升 LLM 的事實可靠性，並專注於醫療問題解答 (QA)。LEAF 利用雙重策略來提升 LLM 回應的事實準確性，例如 Llama 3 70B Instruct 和 Llama 3 8B Instruct。第一種策略 Fact-Check-Then-RAG，透過整合事實查核結果來改進檢索增強生成 (RAG)，以引導檢索程序，而不會更新模型參數。第二種策略透過自我訓練學習事實查核，涉及針對經過事實查核的回應進行監督微調 (SFT)，或將簡單偏好最佳化 (SimPO) 應用於事實查核作為排名機制，這兩種方法都會從監督中更新 LLM 參數。這些發現表明，無論是透過 RAG 增強或自我訓練，整合經過事實查核的回應，都能提升 LLM 輸出的可靠性和事實正確性，為資訊準確性至關重要的應用程式提供了一個有前景的解決方案。

##### **Emory Knee Radiograph (MRKR) Dataset**
2411.00866v1 by Brandon Price, Jason Adleberg, Kaesha Thomas, Zach Zaiman, Aawez Mansuri, Beatrice Brown-Mulry, Chima Okecheukwu, Judy Gichoya, Hari Trivedi

The Emory Knee Radiograph (MRKR) dataset is a large, demographically diverse
collection of 503,261 knee radiographs from 83,011 patients, 40% of which are
African American. This dataset provides imaging data in DICOM format along with
detailed clinical information, including patient-reported pain scores,
diagnostic codes, and procedural codes, which are not commonly available in
similar datasets. The MRKR dataset also features imaging metadata such as image
laterality, view type, and presence of hardware, enhancing its value for
research and model development. MRKR addresses significant gaps in existing
datasets by offering a more representative sample for studying osteoarthritis
and related outcomes, particularly among minority populations, thereby
providing a valuable resource for clinicians and researchers.

摘要：埃默里膝部 X 光片 (MRKR) 資料集是一個龐大、人口統計資料多元的資料集，包含來自 83,011 名患者的 503,261 張膝部 X 光片，其中 40% 為非裔美國人。此資料集提供 DICOM 格式的影像資料，以及詳細的臨床資訊，包括患者回報的疼痛評分、診斷碼和程序碼，這些資料在類似的資料集中並不常見。MRKR 資料集也包含影像的後設資料，例如影像的左右側、檢視類型和硬體的存在，提升其在研究和模型開發方面的價值。MRKR 透過提供更具代表性的樣本，來探討骨關節炎和相關結果，特別是在少數族群中，從而填補現有資料集中顯著的缺口，為臨床醫生和研究人員提供有價值的資源。

##### **STIED: A deep learning model for the SpatioTemporal detection of focal Interictal Epileptiform Discharges with MEG**
2410.23386v1 by Raquel Fernández-Martín, Alfonso Gijón, Odile Feys, Elodie Juvené, Alec Aeby, Charline Urbain, Xavier De Tiège, Vincent Wens

Magnetoencephalography (MEG) allows the non-invasive detection of interictal
epileptiform discharges (IEDs). Clinical MEG analysis in epileptic patients
traditionally relies on the visual identification of IEDs, which is time
consuming and partially subjective. Automatic, data-driven detection methods
exist but show limited performance. Still, the rise of deep learning (DL)-with
its ability to reproduce human-like abilities-could revolutionize clinical MEG
practice. Here, we developed and validated STIED, a simple yet powerful
supervised DL algorithm combining two convolutional neural networks with
temporal (1D time-course) and spatial (2D topography) features of MEG signals
inspired from current clinical guidelines. Our DL model enabled both temporal
and spatial localization of IEDs in patients suffering from focal epilepsy with
frequent and high amplitude spikes (FE group), with high-performance
metrics-accuracy, specificity, and sensitivity all exceeding 85%-when learning
from spatiotemporal features of IEDs. This performance can be attributed to our
handling of input data, which mimics established clinical MEG practice. Reverse
engineering further revealed that STIED encodes fine spatiotemporal features of
IEDs rather than their mere amplitude. The model trained on the FE group also
showed promising results when applied to a separate group of presurgical
patients with different types of refractory focal epilepsy, though further work
is needed to distinguish IEDs from physiological transients. This study paves
the way of incorporating STIED and DL algorithms into the routine clinical MEG
evaluation of epilepsy.

摘要：腦磁圖（MEG）允許對發作間期癲癇樣放電（IED）進行非侵入性檢測。癲癇患者的臨床 MEG 分析傳統上依賴於 IED 的視覺識別，這既耗時又部分主觀。自動化、數據驅動的檢測方法存在，但顯示性能有限。儘管如此，深度學習 (DL) 的興起——它具有複製類人能力的能力——可以徹底改變臨床 MEG 實踐。在這裡，我們開發並驗證了 STIED，這是一種簡單但強大的監督式 DL 演算法，它結合了兩個卷積神經網路，具有 MEG 訊號的時間（1D 時間過程）和空間（2D 地形）特徵，靈感來自當前的臨床指南。我們的 DL 模型能夠對患有局灶性癲癇且尖峰頻繁且振幅高的患者（FE 組）中的 IED 進行時間和空間定位，並具有高性能指標——準確度、特異性和敏感性均超過 85%——從 IED 的時空特徵中學習。這種性能可以歸因於我們對輸入資料的處理，它模擬了既定的臨床 MEG 實務。逆向工程進一步揭示 STIED 編碼了 IED 的精細時空特徵，而不是它們的單純振幅。在 FE 組上訓練的模型在應用於另一組患有不同類型難治性局灶性癲癇的術前患者時也顯示出有希望的結果，儘管需要進一步的工作來區分 IED 和生理性暫態。這項研究為將 STIED 和 DL 演算法納入癲癇的常規臨床 MEG 評估鋪平了道路。

##### **Larger models yield better results? Streamlined severity classification of ADHD-related concerns using BERT-based knowledge distillation**
2411.00052v1 by Ahmed Akib Jawad Karim, Kazi Hafiz Md. Asad, Md. Golam Rabiul Alam

This work focuses on the efficiency of the knowledge distillation approach in
generating a lightweight yet powerful BERT based model for natural language
processing applications. After the model creation, we applied the resulting
model, LastBERT, to a real-world task classifying severity levels of Attention
Deficit Hyperactivity Disorder (ADHD)-related concerns from social media text
data. Referring to LastBERT, a customized student BERT model, we significantly
lowered model parameters from 110 million BERT base to 29 million, resulting in
a model approximately 73.64% smaller. On the GLUE benchmark, comprising
paraphrase identification, sentiment analysis, and text classification, the
student model maintained strong performance across many tasks despite this
reduction. The model was also used on a real-world ADHD dataset with an
accuracy and F1 score of 85%. When compared to DistilBERT (66M) and
ClinicalBERT (110M), LastBERT demonstrated comparable performance, with
DistilBERT slightly outperforming it at 87%, and ClinicalBERT achieving 86%
across the same metrics. These findings highlight the LastBERT model's capacity
to classify degrees of ADHD severity properly, so it offers a useful tool for
mental health professionals to assess and comprehend material produced by users
on social networking platforms. The study emphasizes the possibilities of
knowledge distillation to produce effective models fit for use in
resource-limited conditions, hence advancing NLP and mental health diagnosis.
Furthermore underlined by the considerable decrease in model size without
appreciable performance loss is the lower computational resources needed for
training and deployment, hence facilitating greater applicability. Especially
using readily available computational tools like Google Colab. This study shows
the accessibility and usefulness of advanced NLP methods in pragmatic world
applications.

摘要：<paragraph>本研究重點在於知識萃取方法在產生輕量級且強大的基於 BERT 的模型以用於自然語言處理應用方面的效率。在模型建立後，我們將產生的模型 LastBERT 應用於一個真實世界的任務，即從社群媒體文字資料中分類注意力不足過動症 (ADHD) 相關問題的嚴重程度層級。提到 LastBERT，一個客製化的學生 BERT 模型，我們大幅降低了模型參數，從 1.1 億個 BERT 基底減少至 2900 萬個，導致模型縮小了大約 73.64%。在 GLUE 基準，包括同義句辨識、情緒分析和文字分類，儘管有此縮減，學生模型在許多任務中仍維持強勁的表現。此模型也用於一個真實世界的 ADHD 資料集，其準確度和 F1 分數為 85%。與 DistilBERT (66M) 和 ClinicalBERT (110M) 相較，LastBERT 表現出可比較的表現，DistilBERT 以 87% 的表現略勝一籌，而 ClinicalBERT 在相同的指標中達到 86%。這些發現突顯了 LastBERT 模型適當地分類 ADHD 嚴重程度的能力，因此它為心理健康專業人員提供了一個有用的工具，用於評估和理解社群網路平台上使用者產出的資料。本研究強調了知識萃取在產生適用於資源有限條件的有效模型方面的可能性，因此促進了 NLP 和心理健康診斷。此外，在沒有顯著效能損失的情況下大幅縮小模型大小，也突顯了訓練和部署所需的較低運算資源，因此促進了更廣泛的應用性。特別是使用現成的運算工具，例如 Google Colab。本研究顯示了先進 NLP 方法在務實世界應用中的可及性和實用性。</paragraph>

##### **DiaMond: Dementia Diagnosis with Multi-Modal Vision Transformers Using MRI and PET**
2410.23219v1 by Yitong Li, Morteza Ghahremani, Youssef Wally, Christian Wachinger

Diagnosing dementia, particularly for Alzheimer's Disease (AD) and
frontotemporal dementia (FTD), is complex due to overlapping symptoms. While
magnetic resonance imaging (MRI) and positron emission tomography (PET) data
are critical for the diagnosis, integrating these modalities in deep learning
faces challenges, often resulting in suboptimal performance compared to using
single modalities. Moreover, the potential of multi-modal approaches in
differential diagnosis, which holds significant clinical importance, remains
largely unexplored. We propose a novel framework, DiaMond, to address these
issues with vision Transformers to effectively integrate MRI and PET. DiaMond
is equipped with self-attention and a novel bi-attention mechanism that
synergistically combine MRI and PET, alongside a multi-modal normalization to
reduce redundant dependency, thereby boosting the performance. DiaMond
significantly outperforms existing multi-modal methods across various datasets,
achieving a balanced accuracy of 92.4% in AD diagnosis, 65.2% for AD-MCI-CN
classification, and 76.5% in differential diagnosis of AD and FTD. We also
validated the robustness of DiaMond in a comprehensive ablation study. The code
is available at https://github.com/ai-med/DiaMond.

摘要：診斷失智症，尤其是阿茲海默症 (AD) 和額顳葉型失智症 (FTD)，由於症狀重疊，因此很複雜。雖然磁共振造影 (MRI) 和正子斷層掃描 (PET) 數據對於診斷至關重要，但將這些方式整合到深度學習中會面臨挑戰，通常會導致與使用單一方式相比性能不佳。此外，多模式方法在鑑別診斷中的潛力具有重要的臨床意義，但仍未得到充分探索。我們提出一個新的框架 DiaMond，以解決這些問題，使用視覺轉換器有效整合 MRI 和 PET。DiaMond 具備自注意力和新穎的雙注意力機制，可以協同結合 MRI 和 PET，並採用多模式正規化來減少冗餘依賴，從而提升性能。DiaMond 在各種數據集中的表現明顯優於現有的多模式方法，在 AD 診斷中達到 92.4% 的平衡準確度，在 AD-MCI-CN 分類中達到 65.2%，在 AD 和 FTD 的鑑別診斷中達到 76.5%。我們還在全面的消融研究中驗證了 DiaMond 的穩健性。程式碼可在 https://github.com/ai-med/DiaMond 取得。

##### **Variable Resolution Sampling and Deep Learning Image Recovery for Accelerated Multi-Spectral MRI Near Metal Implants**
2410.23329v1 by Azadeh Sharafi, Nikolai J. Mickevicius, Mehran Baboli, Andrew S. Nencka, Kevin M. Koch

Purpose: This study presents a variable resolution (VR) sampling and deep
learning reconstruction approach for multi-spectral MRI near metal implants,
aiming to reduce scan times while maintaining image quality. Background: The
rising use of metal implants has increased MRI scans affected by metal
artifacts. Multi-spectral imaging (MSI) reduces these artifacts but sacrifices
acquisition efficiency. Methods: This retrospective study on 1.5T MSI knee and
hip data from patients with metal hardware used a novel spectral undersampling
scheme to improve acquisition efficiency by ~40%. U-Net-based deep learning
models were trained for reconstruction. Image quality was evaluated using SSIM,
PSNR, and RESI metrics. Results: Deep learning reconstructions of undersampled
VR data (DL-VR) showed significantly higher SSIM and PSNR values (p<0.001)
compared to conventional reconstruction (CR-VR), with improved edge sharpness.
Edge sharpness in DL-reconstructed images matched fully sampled references
(p=0.5). Conclusion: This approach can potentially enhance MRI examinations
near metal implants by reducing scan times or enabling higher resolution.
Further prospective studies are needed to assess clinical value.

摘要：目的：本研究提出一种可变分辨率 (VR) 采样和深度学习重建方法，用于金属植入物附近的多分光 MRI，旨在在保持图像质量的同时减少扫描时间。背景：金属植入物的使用增加，导致受金属伪影影响的 MRI 扫描增加。多分光成像 (MSI) 减少了这些伪影，但牺牲了采集效率。方法：这项针对 1.5T MSI 膝盖和髋部数据的回顾性研究，来自装有金属硬件的患者，使用了一种新颖的光谱欠采样方案，将采集效率提高了约 40%。基于 U-Net 的深度学习模型经过训练用于重建。使用 SSIM、PSNR 和 RESI 指标评估图像质量。结果：欠采样 VR 数据的深度学习重建 (DL-VR) 与传统重建 (CR-VR) 相比，显示出明显更高的 SSIM 和 PSNR 值（p<0.001），并提高了边缘清晰度。DL 重建图像中的边缘清晰度与完全采样的参考值相匹配（p=0.5）。结论：这种方法可以通过减少扫描时间或启用更高分辨率来增强金属植入物附近的 MRI 检查。需要进一步的前瞻性研究来评估临床价值。

##### **DiabML: AI-assisted diabetes diagnosis method with meta-heuristic-based feature selection**
2411.00858v1 by Vahideh Hayyolalam, Öznur Özkasap

Diabetes is a chronic disorder identified by the high sugar level in the
blood that can cause various different disorders such as kidney failure, heart
attack, sightlessness, and stroke. Developments in the healthcare domain by
facilitating the early detection of diabetes risk can help not only caregivers
but also patients. AIoMT is a recent technology that integrates IoT and machine
learning methods to give services for medical purposes, which is a powerful
technology for the early detection of diabetes. In this paper, we take
advantage of AIoMT and propose a hybrid diabetes risk detection method, DiabML,
which uses the BWO algorithm and ML methods. BWO is utilized for feature
selection and SMOTE for imbalance handling in the pre-processing procedure. The
simulation results prove the superiority of the proposed DiabML method compared
to the existing works. DiabML achieves 86.1\% classification accuracy by
AdaBoost classifier outperforms the relevant existing methods.

摘要：糖尿病是一種慢性疾病，特徵是血液中的高糖分，可能導致各種不同的疾病，例如腎衰竭、心臟病發作、失明和中風。醫療保健領域的發展通過促進早期發現糖尿病風險，不僅可以幫助照護者，還可以幫助患者。AIoMT 是一種將物聯網和機器學習方法整合在一起的新技術，用於提供醫療目的的服務，這是一種用於早期發現糖尿病的強大技術。在本文中，我們利用 AIoMT 並提出了一種混合糖尿病風險檢測方法 DiabML，它使用 BWO 演算法和 ML 方法。BWO 用於預處理程序中的特徵選擇，而 SMOTE 用於處理不平衡。模擬結果證明了所提出的 DiabML 方法優於現有方法。DiabML 通過 AdaBoost 分類器實現了 86.1% 的分類準確度，優於相關的現有方法。

##### **Revisiting MAE pre-training for 3D medical image segmentation**
2410.23132v1 by Tassilo Wald, Constantin Ulrich, Stanislav Lukyanenko, Andrei Goncharov, Alberto Paderno, Leander Maerkisch, Paul F. Jäger, Klaus Maier-Hein

Self-Supervised Learning (SSL) presents an exciting opportunity to unlock the
potential of vast, untapped clinical datasets, for various downstream
applications that suffer from the scarcity of labeled data. While SSL has
revolutionized fields like natural language processing and computer vision,
their adoption in 3D medical image computing has been limited by three key
pitfalls: Small pre-training dataset sizes, architectures inadequate for 3D
medical image analysis, and insufficient evaluation practices. We address these
issues by i) leveraging a large-scale dataset of 44k 3D brain MRI volumes and
ii) using a Residual Encoder U-Net architecture within the state-of-the-art
nnU-Net framework. iii) A robust development framework, incorporating 5
development and 8 testing brain MRI segmentation datasets, allowed
performance-driven design decisions to optimize the simple concept of Masked
Auto Encoders (MAEs) for 3D CNNs. The resulting model not only surpasses
previous SSL methods but also outperforms the strong nnU-Net baseline by an
average of approximately 3 Dice points. Furthermore, our model demonstrates
exceptional stability, achieving the highest average rank of 2 out of 7
methods, compared to the second-best method's mean rank of 3.

摘要：自监督学习 (SSL) 为解锁大量未开发临床数据集的潜力提供了一个激动人心的机会，用于各种下游应用程序，这些应用程序因标记数据稀缺而受到影响。虽然 SSL 已彻底改变了自然语言处理和计算机视觉等领域，但其在 3D 医学图像计算中的采用受到三个主要缺陷的限制：小型预训练数据集大小、不适用于 3D 医学图像分析的架构以及评估实践不足。我们通过以下方式解决这些问题：i) 利用 44k 3D 大脑 MRI 体积的大规模数据集，以及 ii) 在最先进的 nnU-Net 框架内使用残差编码器 U-Net 架构。iii) 一个稳健的开发框架，包含 5 个开发和 8 个测试大脑 MRI 分割数据集，允许基于性能的设计决策来优化 3D CNN 的掩蔽自动编码器 (MAE) 的简单概念。由此产生的模型不仅超越了之前的 SSL 方法，而且比强大的 nnU-Net 基线平均高出大约 3 个骰子点。此外，我们的模型表现出非凡的稳定性，在 7 种方法中达到 2 的最高平均排名，而第二好的方法的平均排名为 3。

##### **SpiroActive: Active Learning for Efficient Data Acquisition for Spirometry**
2410.22950v1 by Ankita Kumari Jain, Nitish Sharma, Madhav Kanda, Nipun Batra

Respiratory illnesses are a significant global health burden. Respiratory
illnesses, primarily Chronic obstructive pulmonary disease (COPD), is the
seventh leading cause of poor health worldwide and the third leading cause of
death worldwide, causing 3.23 million deaths in 2019, necessitating early
identification and diagnosis for effective mitigation. Among the diagnostic
tools employed, spirometry plays a crucial role in detecting respiratory
abnormalities. However, conventional clinical spirometry methods often entail
considerable costs and practical limitations like the need for specialized
equipment, trained personnel, and a dedicated clinical setting, making them
less accessible. To address these challenges, wearable spirometry technologies
have emerged as promising alternatives, offering accurate, cost-effective, and
convenient solutions. The development of machine learning models for wearable
spirometry heavily relies on the availability of high-quality ground truth
spirometry data, which is a laborious and expensive endeavor. In this research,
we propose using active learning, a sub-field of machine learning, to mitigate
the challenges associated with data collection and labeling. By strategically
selecting samples from the ground truth spirometer, we can mitigate the need
for resource-intensive data collection. We present evidence that models trained
on small subsets obtained through active learning achieve comparable/better
results than models trained on the complete dataset.

摘要：呼吸道疾病是全球重大的健康負擔。呼吸道疾病，主要是慢性阻塞性肺病 (COPD)，是全球第七大不良健康原因，也是全球第三大死亡原因，2019 年造成 323 萬人死亡，需要及早識別和診斷以有效減輕症狀。在所採用的診斷工具中，肺活量測量在檢測呼吸道異常方面發揮著至關重要的作用。然而，傳統的臨床肺活量測量方法通常需要大量的成本和實際限制，例如需要專業設備、訓練有素的人員和專門的臨床環境，這使得它們的可及性較低。為了應對這些挑戰，可穿戴式肺活量測量技術已成為有希望的替代方案，提供準確、經濟高效且便利的解決方案。可穿戴式肺活量測量機器學習模型的開發在很大程度上依賴於高品質的基準肺活量測量數據，這是一項費時且昂貴的工作。在這項研究中，我們建議使用主動學習（機器學習的一個子領域）來減輕與數據收集和標記相關的挑戰。通過從基準肺活量計中策略性地選擇樣本，我們可以減少對資源密集型數據收集的需求。我們提供的證據表明，在通過主動學習獲得的小子集中訓練的模型，獲得的結果與在完整數據集上訓練的模型相當/更好。

##### **Efficient Feature Extraction and Classification Architecture for MRI-Based Brain Tumor Detection**
2410.22619v1 by Plabon Paul, Md. Nazmul Islam, Fazle Rafsani, Pegah Khorasani, Shovito Barua Soumma

Uncontrolled cell division in the brain is what gives rise to brain tumors.
If the tumor size increases by more than half, there is little hope for the
patient's recovery. This emphasizes the need of rapid and precise brain tumor
diagnosis. When it comes to analyzing, diagnosing, and planning therapy for
brain tumors, MRI imaging plays a crucial role. A brain tumor's development
history is crucial information for doctors to have. When it comes to
distinguishing between human soft tissues, MRI scans are superior. In order to
get reliable classification results from MRI scans quickly, deep learning is
one of the most practical methods. Early human illness diagnosis has been
demonstrated to be more accurate when deep learning methods are used. In the
case of diagnosing a brain tumor, when even a little misdiagnosis might have
serious consequences, accuracy is especially important. Disclosure of brain
tumors in medical images is still a difficult task. Brain MRIs are notoriously
imprecise in revealing the presence or absence of tumors. Using MRI scans of
the brain, a Convolutional Neural Network (CNN) was trained to identify the
presence of a tumor in this research. Results from the CNN model showed an
accuracy of 99.17%. The CNN model's characteristics were also retrieved. In
order to evaluate the CNN model's capability for processing images, we applied
the features via the following machine learning models: KNN, Logistic
regression, SVM, Random Forest, Naive Bayes, and Perception. CNN and machine
learning models were also evaluated using the standard metrics of Precision,
Recall, Specificity, and F1 score. The significance of the doctor's diagnosis
enhanced the accuracy of the CNN model's assistance in identifying the
existence of tumor and treating the patient.

摘要：腦部細胞分裂失控，就會產生腦瘤。
如果腫瘤大小增加超過一半，病患康復的希望很渺茫。這強調了快速且精準診斷腦瘤的必要性。
在分析、診斷和規劃腦瘤治療時，核磁共振造影扮演了至關重要的角色。腦瘤的發展史是醫生必備的重要資訊。
在區分人體軟組織時，核磁共振掃描的表現優異。為了從核磁共振掃描中快速取得可靠的分類結果，深度學習是最實用的方法之一。
研究顯示，使用深度學習方法可以更準確地診斷人類早期疾病。在診斷腦瘤時，即使是輕微的誤診都可能造成嚴重後果，因此準確性特別重要。
在醫學影像中揭露腦瘤仍然是一項艱難的任務。腦部核磁共振造影在揭露腫瘤的存在與否方面出了名的不精確。
本研究訓練了一個卷積神經網路 (CNN)，使用腦部核磁共振掃描來辨識腫瘤的存在。CNN 模型的結果顯示準確度為 99.17%。CNN 模型的特徵也已擷取。
為了評估 CNN 模型處理影像的能力，我們透過以下機器學習模型套用這些特徵：KNN、邏輯迴歸、SVM、隨機森林、樸素貝氏和感知器。CNN 和機器學習模型也使用精準度、召回率、特異性和 F1 分數等標準指標進行評估。
醫生的診斷意義提升了 CNN 模型在協助辨識腫瘤存在和治療病患方面的準確性。

##### **Do Large Language Models Align with Core Mental Health Counseling Competencies?**
2410.22446v1 by Viet Cuong Nguyen, Mohammad Taher, Dongwan Hong, Vinicius Konkolics Possobom, Vibha Thirunellayi Gopalakrishnan, Ekta Raj, Zihang Li, Heather J. Soled, Michael L. Birnbaum, Srijan Kumar, Munmun De Choudhury

The rapid evolution of Large Language Models (LLMs) offers promising
potential to alleviate the global scarcity of mental health professionals.
However, LLMs' alignment with essential mental health counseling competencies
remains understudied. We introduce CounselingBench, a novel NCMHCE-based
benchmark evaluating LLMs across five key mental health counseling
competencies. Testing 22 general-purpose and medical-finetuned LLMs, we find
frontier models exceed minimum thresholds but fall short of expert-level
performance, with significant variations: they excel in Intake, Assessment &
Diagnosis yet struggle with Core Counseling Attributes and Professional
Practice & Ethics. Medical LLMs surprisingly underperform generalist models
accuracy-wise, while at the same time producing slightly higher-quality
justifications but making more context-related errors. Our findings highlight
the complexities of developing AI systems for mental health counseling,
particularly for competencies requiring empathy and contextual understanding.
We found that frontier LLMs perform at a level exceeding the minimal required
level of aptitude for all key mental health counseling competencies, but fall
short of expert-level performance, and that current medical LLMs do not
significantly improve upon generalist models in mental health counseling
competencies. This underscores the critical need for specialized, mental health
counseling-specific fine-tuned LLMs that rigorously aligns with core
competencies combined with appropriate human supervision before any responsible
real-world deployment can be considered.

摘要：大型語言模型 (LLM) 的快速發展，提供了緩解全球心理健康專業人員短缺的潛在希望。
然而，LLM 與基本心理健康諮商能力的對齊程度，仍未獲得充分研究。我們引入了 CounselingBench，一個基於 NCMHCE 的新基準，用於評估 LLM 在五項關鍵心理健康諮商能力上的表現。我們測試了 22 個通用和醫學微調的 LLM，發現前沿模型超過了最低門檻，但未達到專家級別的表現，且差異顯著：它們在「攝取、評估和診斷」方面表現出色，但在「核心諮商屬性」和「專業實務和倫理」方面卻有困難。令人驚訝的是，醫療 LLM 在準確性方面表現不如通用模型，但同時產生的理由品質略高，但產生更多與脈絡相關的錯誤。我們的研究結果突出了為心理健康諮商開發 AI 系統的複雜性，特別是對於需要同理心和脈絡理解的能力。我們發現，前沿 LLM 的表現水平超過了所有關鍵心理健康諮商能力所需的最低能力水準，但未達到專家級別的表現，而且目前的醫療 LLM 並未顯著改善通用模型在心理健康諮商能力上的表現。這強調了對專門的、針對心理健康諮詢的微調 LLM 的迫切需求，這些 LLM 必須嚴格符合核心能力，並結合適當的人類監督，才能考慮任何負責任的實際部署。

##### **MAPUNetR: A Hybrid Vision Transformer and U-Net Architecture for Efficient and Interpretable Medical Image Segmentation**
2410.22223v1 by Ovais Iqbal Shah, Danish Raza Rizvi, Aqib Nazir Mir

Medical image segmentation is pivotal in healthcare, enhancing diagnostic
accuracy, informing treatment strategies, and tracking disease progression.
This process allows clinicians to extract critical information from visual
data, enabling personalized patient care. However, developing neural networks
for segmentation remains challenging, especially when preserving image
resolution, which is essential in detecting subtle details that influence
diagnoses. Moreover, the lack of transparency in these deep learning models has
slowed their adoption in clinical practice. Efforts in model interpretability
are increasingly focused on making these models' decision-making processes more
transparent. In this paper, we introduce MAPUNetR, a novel architecture that
synergizes the strengths of transformer models with the proven U-Net framework
for medical image segmentation. Our model addresses the resolution preservation
challenge and incorporates attention maps highlighting segmented regions,
increasing accuracy and interpretability. Evaluated on the BraTS 2020 dataset,
MAPUNetR achieved a dice score of 0.88 and a dice coefficient of 0.92 on the
ISIC 2018 dataset. Our experiments show that the model maintains stable
performance and potential as a powerful tool for medical image segmentation in
clinical practice.

摘要：醫學影像分割在醫療保健中至關重要，能提升診斷準確度、提供治療策略資訊，並追蹤疾病進程。此程序讓臨床醫生能從視覺資料中萃取關鍵資訊，進而提供個人化的患者照護。然而，開發用於分割的神經網路仍具挑戰性，特別是在保留影像解析度時，這對於偵測影響診斷的細微細節至關重要。此外，這些深度學習模型缺乏透明度，導致其在臨床實務中的採用速度變慢。模型可解釋性的努力越來越專注於讓這些模型的決策過程更透明。在本文中，我們介紹了 MAPUNetR，這是一種新穎的架構，結合了Transformer模型的優點和已證實的 U-Net 框架，用於醫學影像分割。我們的模型解決了解析度保留的挑戰，並結合了突顯分割區域的注意力圖，提高了準確度和可解釋性。在 BraTS 2020 資料集上進行評估，MAPUNetR 在 ISIC 2018 資料集上達到了 0.88 的骰子係數和 0.92 的骰子系數。我們的實驗表明，該模型在臨床實務中作為醫學影像分割的強大工具，具有穩定的效能和潛力。

##### **Natural Language Processing for Analyzing Electronic Health Records and Clinical Notes in Cancer Research: A Review**
2410.22180v1 by Muhammad Bilal, Ameer Hamza, Nadia Malik

Objective: This review aims to analyze the application of natural language
processing (NLP) techniques in cancer research using electronic health records
(EHRs) and clinical notes. This review addresses gaps in the existing
literature by providing a broader perspective than previous studies focused on
specific cancer types or applications. Methods: A comprehensive literature
search was conducted using the Scopus database, identifying 94 relevant studies
published between 2019 and 2024. Data extraction included study
characteristics, cancer types, NLP methodologies, dataset information,
performance metrics, challenges, and future directions. Studies were
categorized based on cancer types and NLP applications. Results: The results
showed a growing trend in NLP applications for cancer research, with breast,
lung, and colorectal cancers being the most studied. Information extraction and
text classification emerged as predominant NLP tasks. A shift from rule-based
to advanced machine learning techniques, particularly transformer-based models,
was observed. The Dataset sizes used in existing studies varied widely. Key
challenges included the limited generalizability of proposed solutions and the
need for improved integration into clinical workflows. Conclusion: NLP
techniques show significant potential in analyzing EHRs and clinical notes for
cancer research. However, future work should focus on improving model
generalizability, enhancing robustness in handling complex clinical language,
and expanding applications to understudied cancer types. Integration of NLP
tools into clinical practice and addressing ethical considerations remain
crucial for utilizing the full potential of NLP in enhancing cancer diagnosis,
treatment, and patient outcomes.

摘要：<paragraph>目標：本篇評論旨在分析自然語言處理 (NLP) 技術在癌症研究中使用電子健康紀錄 (EHR) 和臨床筆記的應用。本篇評論透過提供比先前專注於特定癌症類型或應用的研究更廣泛的觀點，來探討現有文獻中的差距。方法：使用 Scopus 資料庫進行全面的文獻搜尋，找出 2019 年至 2024 年間發表的 94 篇相關研究。資料擷取包含研究特徵、癌症類型、NLP 方法論、資料集資訊、效能指標、挑戰和未來方向。研究根據癌症類型和 NLP 應用進行分類。結果：結果顯示 NLP 在癌症研究中的應用有逐漸增加的趨勢，其中乳癌、肺癌和大腸直腸癌的研究最多。資訊擷取和文字分類成為主要的 NLP 任務。觀察到從基於規則的技術轉移到進階機器學習技術，特別是基於轉換器的模型。現有研究中使用的資料集大小差異很大。主要的挑戰包括所提出解決方案的普遍性有限，以及需要更進一步整合到臨床工作流程中。結論：NLP 技術在分析電子健康紀錄和臨床筆記以進行癌症研究方面顯示出顯著的潛力。然而，未來的研究應專注於改善模型的普遍性、加強處理複雜臨床語言的穩健性，以及將應用擴展到研究不足的癌症類型。將 NLP 工具整合到臨床實務中，並探討倫理考量，對於充分利用 NLP 在提升癌症診斷、治療和患者預後方面的潛力至關重要。</paragraph>

##### **Advanced Hybrid Deep Learning Model for Enhanced Classification of Osteosarcoma Histopathology Images**
2411.00832v1 by Arezoo Borji, Gernot Kronreif, Bernhard Angermayr, Sepideh Hatamikia

Recent advances in machine learning are transforming medical image analysis,
particularly in cancer detection and classification. Techniques such as deep
learning, especially convolutional neural networks (CNNs) and vision
transformers (ViTs), are now enabling the precise analysis of complex
histopathological images, automating detection, and enhancing classification
accuracy across various cancer types. This study focuses on osteosarcoma (OS),
the most common bone cancer in children and adolescents, which affects the long
bones of the arms and legs. Early and accurate detection of OS is essential for
improving patient outcomes and reducing mortality. However, the increasing
prevalence of cancer and the demand for personalized treatments create
challenges in achieving precise diagnoses and customized therapies. We propose
a novel hybrid model that combines convolutional neural networks (CNN) and
vision transformers (ViT) to improve diagnostic accuracy for OS using
hematoxylin and eosin (H&E) stained histopathological images. The CNN model
extracts local features, while the ViT captures global patterns from
histopathological images. These features are combined and classified using a
Multi-Layer Perceptron (MLP) into four categories: non-tumor (NT), non-viable
tumor (NVT), viable tumor (VT), and none-viable ratio (NVR). Using the Cancer
Imaging Archive (TCIA) dataset, the model achieved an accuracy of 99.08%,
precision of 99.10%, recall of 99.28%, and an F1-score of 99.23%. This is the
first successful four-class classification using this dataset, setting a new
benchmark in OS research and offering promising potential for future diagnostic
advancements.

摘要：機器學習的最新進展正在轉變醫學影像分析，特別是在癌症檢測和分類方面。諸如深度學習等技術，尤其是卷積神經網路 (CNN) 和視覺轉換器 (ViT)，現在能精確分析複雜的組織病理學影像、自動化檢測，並提升各種癌症類型的分類準確度。本研究專注於骨肉瘤 (OS)，這是兒童和青少年中最常見的骨癌，會影響手臂和腿部的長骨。早期且準確地檢測出骨肉瘤對於改善患者預後和降低死亡率至關重要。然而，癌症盛行率的增加和對個人化治療的需求，在達成精確診斷和客製化治療方面造成了挑戰。我們提出了一種結合卷積神經網路 (CNN) 和視覺轉換器 (ViT) 的新型混合模型，以使用蘇木精和曙紅 (H&E) 染色的組織病理學影像來提升骨肉瘤的診斷準確度。CNN 模型會萃取局部特徵，而 ViT 則從組織病理學影像中擷取全局模式。這些特徵會結合起來，並使用多層感知器 (MLP) 分類成四種類別：非腫瘤 (NT)、不可存活腫瘤 (NVT)、可存活腫瘤 (VT) 和不可存活率 (NVR)。使用癌症影像檔案 (TCIA) 資料集，該模型達到了 99.08% 的準確度、99.10% 的精確度、99.28% 的召回率和 99.23% 的 F1 值。這是使用此資料集進行的首次成功的四類別分類，為骨肉瘤研究設定了新的基準，並為未來的診斷進展提供了有希望的潛力。

##### **Unsupervised Training of a Dynamic Context-Aware Deep Denoising Framework for Low-Dose Fluoroscopic Imaging**
2411.00830v1 by Sun-Young Jeon, Sen Wang, Adam S. Wang, Garry E. Gold, Jang-Hwan Choi

Fluoroscopy is critical for real-time X-ray visualization in medical imaging.
However, low-dose images are compromised by noise, potentially affecting
diagnostic accuracy. Noise reduction is crucial for maintaining image quality,
especially given such challenges as motion artifacts and the limited
availability of clean data in medical imaging. To address these issues, we
propose an unsupervised training framework for dynamic context-aware denoising
of fluoroscopy image sequences. First, we train the multi-scale recurrent
attention U-Net (MSR2AU-Net) without requiring clean data to address the
initial noise. Second, we incorporate a knowledge distillation-based
uncorrelated noise suppression module and a recursive filtering-based
correlated noise suppression module enhanced with motion compensation to
further improve motion compensation and achieve superior denoising performance.
Finally, we introduce a novel approach by combining these modules with a
pixel-wise dynamic object motion cross-fusion matrix, designed to adapt to
motion, and an edge-preserving loss for precise detail retention. To validate
the proposed method, we conducted extensive numerical experiments on medical
image datasets, including 3500 fluoroscopy images from dynamic phantoms (2,400
images for training, 1,100 for testing) and 350 clinical images from a spinal
surgery patient. Moreover, we demonstrated the robustness of our approach
across different imaging modalities by testing it on the publicly available
2016 Low Dose CT Grand Challenge dataset, using 4,800 images for training and
1,136 for testing. The results demonstrate that the proposed approach
outperforms state-of-the-art unsupervised algorithms in both visual quality and
quantitative evaluation while achieving comparable performance to
well-established supervised learning methods across low-dose fluoroscopy and CT
imaging.

摘要：<paragraph>螢光透視對於醫學影像中的即時 X 光視覺化至關重要。
然而，低劑量影像會受到雜訊影響，可能影響診斷準確性。雜訊抑制對於維持影像品質至關重要，特別是在醫學影像中存在運動偽影和乾淨資料有限等挑戰。為了解決這些問題，我們提出了一個無監督訓練架構，用於螢光透視影像序列的動態情境感知去雜訊。首先，我們訓練多尺度遞迴注意力 U-Net (MSR2AU-Net)，無需乾淨資料即可處理初始雜訊。其次，我們結合了一個基於知識蒸餾的非相關雜訊抑制模組和一個基於遞迴濾波的相關雜訊抑制模組，並增強了運動補償，以進一步改善運動補償並實現卓越的去雜訊效能。最後，我們引入了一種新方法，將這些模組與逐像素動態物件運動交叉融合矩陣結合起來，該矩陣旨在適應運動，並採用邊緣保留損失以精確保留細節。為了驗證所提出的方法，我們對醫學影像資料集進行了廣泛的數值實驗，包括來自動態模擬人體的 3500 張螢光透視影像（2,400 張用於訓練，1,100 張用於測試）和來自脊椎手術患者的 350 張臨床影像。此外，我們透過在公開的 2016 年低劑量 CT 大挑戰資料集上進行測試，使用 4,800 張影像進行訓練和 1,136 張進行測試，證明了我們的方法在不同影像模式下的穩健性。結果表明，所提出的方法在視覺品質和量化評估中都優於最先進的無監督演算法，同時在低劑量螢光透視和 CT 影像中實現了與完善的監督式學習方法相當的效能。</paragraph>

##### **Coupling quantum-like cognition with the neuronal networks within generalized probability theory**
2411.00036v1 by Andrei Khrennikov, Masanao Ozawa, Felix Benninger, Oded Shor

The recent years are characterized by intensive applications of the
methodology and mathematical apparatus of quantum theory, quantum-like
modeling, in cognition, psychology, and decision making. In spite of the
successful applications of this approach to a variety of psychological effects,
e.g., the order, conjunction, disjunction, and response replicability effects,
one may (but need not) feel dissatisfaction due to the absence of clear
coupling to the neurophysiological processes in the brain. For the moment, this
is just a phenomenological approach. In this paper we construct the
quantum-like representation of the networks of communicating neurons. It is
based not on standard quantum theory, but on generalized probability theory
(GPT) with the emphasis of the operational measurement approach. We employ
GPT's version which is based on ordered linear state space (instead of complex
Hilbert space). A network of communicating neurons is described as a weighted
ordered graph that in turn is encoded by its weight matrix. The state space of
weight matrices is embedded in GPT with effect-observables and state updates
within measurement instruments theory. The latter plays the crucial role. This
GPT based model shows the basic quantum-like effects, as e.g. the order,
non-repeatability, and disjunction effects; the latter is also known as
interference of decisions. This GPT coupling also supports quantum-like
modeling in medical diagnostic for neurological diseases, as depression and
epilepsy. Although the paper is concentrated on cognition and neuronal
networks, the formalism and methodology can be straightforwardly applied to a
variety of biological and social networks.

摘要：近年來，量子理論、類量子模型在認知、心理學和決策制定中的方法論和數學裝置得到廣泛應用。儘管這種方法成功應用於各種心理效應，例如順序、合取、析取和反應可複製效應，但由於缺乏與大腦神經生理過程的明確聯繫，人們可能會（但不必）感到不滿。目前，這只是一種現象學方法。在本文中，我們構建了通信神經元網路的類量子表示。它不是基於標準量子理論，而是基於廣義概率論 (GPT)，並強調運算測量方法。我們採用基於有序線性狀態空間（而不是複雜希爾伯特空間）的 GPT 版本。通信神經元網路被描述為一個加權有序圖，而加權有序圖又由其權重矩陣編碼。權重矩陣的狀態空間嵌入 GPT 中，其中效應觀測值和狀態更新在測量儀器理論中。後者發揮著至關重要的作用。這個基於 GPT 的模型展示了基本的類量子效應，例如順序、不可重複性和析取效應；後者也被稱為決策干擾。這種 GPT 耦合還支援神經疾病（如抑鬱症和癲癇症）的醫療診斷中的類量子建模。儘管本文集中於認知和神經元網路，但形式主義和方法論可以直接應用於各種生物和社會網路。

##### **Advancing Efficient Brain Tumor Multi-Class Classification -- New Insights from the Vision Mamba Model in Transfer Learning**
2410.21872v1 by Yinyi Lai, Anbo Cao, Yuan Gao, Jiaqi Shang, Zongyu Li, Jia Guo

Early and accurate diagnosis of brain tumors is crucial for improving patient
survival rates. However, the detection and classification of brain tumors are
challenging due to their diverse types and complex morphological
characteristics. This study investigates the application of pre-trained models
for brain tumor classification, with a particular focus on deploying the Mamba
model. We fine-tuned several mainstream transfer learning models and applied
them to the multi-class classification of brain tumors. By comparing these
models to those trained from scratch, we demonstrated the significant
advantages of transfer learning, especially in the medical imaging field, where
annotated data is often limited. Notably, we introduced the Vision Mamba (Vim),
a novel network architecture, and applied it for the first time in brain tumor
classification, achieving exceptional classification accuracy. Experimental
results indicate that the Vim model achieved 100% classification accuracy on an
independent test set, emphasizing its potential for tumor classification tasks.
These findings underscore the effectiveness of transfer learning in brain tumor
classification and reveal that, compared to existing state-of-the-art models,
the Vim model is lightweight, efficient, and highly accurate, offering a new
perspective for clinical applications. Furthermore, the framework proposed in
this study for brain tumor classification, based on transfer learning and the
Vision Mamba model, is broadly applicable to other medical imaging
classification problems.

摘要：腦腫瘤的早期準確診斷對於提高患者存活率至關重要。然而，由於腦腫瘤類型多樣且形態特徵複雜，因此檢測和分類腦腫瘤具有挑戰性。本研究探討了預訓練模型在腦腫瘤分類中的應用，特別關注 Mamba 模型的部署。我們微調了幾個主流的遷移學習模型，並將它們應用於腦腫瘤的多類別分類。通過將這些模型與從頭開始訓練的模型進行比較，我們展示了遷移學習的顯著優勢，特別是在醫療影像領域，那裡的註解數據通常有限。值得注意的是，我們引入了 Vision Mamba (Vim)，這是一種新穎的網路架構，並首次將其應用於腦腫瘤分類中，達到了出色的分類準確率。實驗結果表明，Vim 模型在一個獨立的測試集上達到了 100% 的分類準確率，強調了其在腫瘤分類任務中的潛力。這些發現強調了遷移學習在腦腫瘤分類中的有效性，並揭示了與現有的最先進模型相比，Vim 模型輕量、高效且準確，為臨床應用提供了新的視角。此外，本研究中提出的基於遷移學習和 Vision Mamba 模型的腦腫瘤分類框架廣泛適用於其他醫學影像分類問題。

##### **How Does Critical Batch Size Scale in Pre-training?**
2410.21676v1 by Hanlin Zhang, Depen Morwani, Nikhil Vyas, Jingfeng Wu, Difan Zou, Udaya Ghai, Dean Foster, Sham Kakade

Training large-scale models under given resources requires careful design of
parallelism strategies. In particular, the efficiency notion of critical batch
size, concerning the compromise between time and compute, marks the threshold
beyond which greater data parallelism leads to diminishing returns. To
operationalize it, we propose a measure of CBS and pre-train a series of
auto-regressive language models, ranging from 85 million to 1.2 billion
parameters, on the C4 dataset. Through extensive hyper-parameter sweeps and
careful control on factors such as batch size, momentum, and learning rate
along with its scheduling, we systematically investigate the impact of scale on
CBS. Then we fit scaling laws with respect to model and data sizes to decouple
their effects. Overall, our results demonstrate that CBS scales primarily with
data size rather than model size, a finding we justify theoretically through
the analysis of infinite-width limits of neural networks and
infinite-dimensional least squares regression. Of independent interest, we
highlight the importance of common hyper-parameter choices and strategies for
studying large-scale pre-training beyond fixed training durations.

摘要：在既定資源下訓練大型模型需要仔細設計平行處理策略。特別是，關鍵批次大小的效率概念，涉及時間和運算之間的折衷，標誌著超越此臨界點後，更大的資料平行處理將導致報酬遞減。為了將其付諸實施，我們提出一個 CBS 量度，並預先訓練一系列自迴歸語言模型，範圍從 8500 萬到 12 億個參數，在 C4 資料集上。透過廣泛的超參數掃描和仔細控制批次大小、動量和學習率等因素以及其排程，我們系統性地研究規模對 CBS 的影響。然後，我們擬合關於模型和資料大小的縮放定律，以分離它們的影響。總體而言，我們的結果表明 CBS 主要隨著資料大小而不是模型大小而縮放，我們透過對神經網路的無限寬度限制和無限維最小二乘迴歸的分析，在理論上證明了這一發現。獨立的興趣是，我們強調了通用超參數選擇和策略的重要性，用於研究超越固定訓練持續時間的大規模預訓練。

##### **A Tutorial on Clinical Speech AI Development: From Data Collection to Model Validation**
2410.21640v1 by Si-Ioi Ng, Lingfeng Xu, Ingo Siegert, Nicholas Cummins, Nina R. Benway, Julie Liss, Visar Berisha

There has been a surge of interest in leveraging speech as a marker of health
for a wide spectrum of conditions. The underlying premise is that any
neurological, mental, or physical deficits that impact speech production can be
objectively assessed via automated analysis of speech. Recent advances in
speech-based Artificial Intelligence (AI) models for diagnosing and tracking
mental health, cognitive, and motor disorders often use supervised learning,
similar to mainstream speech technologies like recognition and verification.
However, clinical speech AI has distinct challenges, including the need for
specific elicitation tasks, small available datasets, diverse speech
representations, and uncertain diagnostic labels. As a result, application of
the standard supervised learning paradigm may lead to models that perform well
in controlled settings but fail to generalize in real-world clinical
deployments. With translation into real-world clinical scenarios in mind, this
tutorial paper provides an overview of the key components required for robust
development of clinical speech AI. Specifically, this paper will cover the
design of speech elicitation tasks and protocols most appropriate for different
clinical conditions, collection of data and verification of hardware,
development and validation of speech representations designed to measure
clinical constructs of interest, development of reliable and robust clinical
prediction models, and ethical and participant considerations for clinical
speech AI. The goal is to provide comprehensive guidance on building models
whose inputs and outputs link to the more interpretable and clinically
meaningful aspects of speech, that can be interrogated and clinically validated
on clinical datasets, and that adhere to ethical, privacy, and security
considerations by design.

摘要：<paragraph>最近出現一股利用語言作為各種疾病標記的熱潮。其基本前提是任何影響語言產生的神經、心理或生理缺陷，都可以透過語言的自動化分析進行客觀評估。最近在語言基礎人工智慧 (AI) 模型上的進展，用於診斷和追蹤心理健康、認知和運動障礙，通常使用監督式學習，類似於主流語言技術，例如辨識和驗證。然而，臨床語言 AI 有其獨特的挑戰，包括需要特定的引導任務、可用的資料集小、語言表述多樣，以及診斷標籤不確定。因此，應用標準的監督式學習範例可能會導致在受控環境中表現良好的模型，但在現實世界的臨床部署中卻無法概化。本教學論文考量了將其轉譯到現實世界的臨床情境，提供了健全開發臨床語言 AI 所需關鍵組成的概觀。具體來說，本文將涵蓋最適合不同臨床狀況的語言引導任務和協定的設計、資料收集和硬體驗證、用於衡量臨床關注結構的語言表述的開發和驗證、可靠且健全的臨床預測模型的開發，以及臨床語言 AI 的倫理和參與者考量。目標是提供全面的指導方針，以建立其輸入和輸出連結到更易於理解且臨床上有意義的語言面向的模型，可以在臨床資料集上進行詢問和臨床驗證，並且在設計上遵守倫理、隱私和安全考量。</paragraph>

##### **Can Large Language Models Replace Data Scientists in Clinical Research?**
2410.21591v1 by Zifeng Wang, Benjamin Danek, Ziwei Yang, Zheng Chen, Jimeng Sun

Data science plays a critical role in clinical research, but it requires
professionals with expertise in coding and medical data analysis. Large
language models (LLMs) have shown great potential in supporting medical tasks
and performing well in general coding tests. However, these tests do not assess
LLMs' ability to handle data science tasks in medicine, nor do they explore
their practical utility in clinical research. To address this, we developed a
dataset consisting of 293 real-world data science coding tasks, based on 39
published clinical studies, covering 128 tasks in Python and 165 tasks in R.
This dataset simulates realistic clinical research scenarios using patient
data. Our findings reveal that cutting-edge LLMs struggle to generate perfect
solutions, frequently failing to follow input instructions, understand target
data, and adhere to standard analysis practices. Consequently, LLMs are not yet
ready to fully automate data science tasks. We benchmarked advanced adaptation
methods and found two to be particularly effective: chain-of-thought prompting,
which provides a step-by-step plan for data analysis, which led to a 60%
improvement in code accuracy; and self-reflection, enabling LLMs to iteratively
refine their code, yielding a 38% accuracy improvement. Building on these
insights, we developed a platform that integrates LLMs into the data science
workflow for medical professionals. In a user study with five medical doctors,
we found that while LLMs cannot fully automate coding tasks, they significantly
streamline the programming process. We found that 80% of their submitted code
solutions were incorporated from LLM-generated code, with up to 96% reuse in
some cases. Our analysis highlights the potential of LLMs, when integrated into
expert workflows, to enhance data science efficiency in clinical research.

摘要：<paragraph>資料科學在臨床研究中發揮關鍵作用，但它需要具備編碼和醫療資料分析專業知識的專業人員。大型語言模型 (LLM) 在支援醫療任務和執行一般編碼測試方面展現了極大的潛力。然而，這些測試並未評估 LLM 處理醫學中資料科學任務的能力，也沒有探討它們在臨床研究中的實際效用。為了解決這個問題，我們開發了一個由 293 個真實世界資料科學編碼任務組成的資料集，這些任務基於 39 項已發表的臨床研究，涵蓋 128 個 Python 任務和 165 個 R 任務。此資料集使用患者資料模擬真實的臨床研究場景。我們的研究結果顯示，最先進的 LLM 難以產生完美的解決方案，常常無法遵循輸入說明、理解目標資料，以及遵守標準分析實務。因此，LLM 尚未準備好完全自動化資料科學任務。我們對進階適應方法進行了基準測試，發現有兩個方法特別有效：思考鏈提示，它提供了資料分析的逐步計畫，使程式碼準確度提升了 60%；以及自我反省，使 LLM 能夠反覆改善其程式碼，使準確度提升了 38%。根據這些見解，我們開發了一個將 LLM 整合到醫療專業人員資料科學工作流程中的平台。在與五位醫生的使用者研究中，我們發現，雖然 LLM 無法完全自動化編碼任務，但它們大幅簡化了程式設計流程。我們發現，他們提交的程式碼解決方案中有 80% 是從 LLM 生成的程式碼中納入的，在某些情況下重用率高達 96%。我們的分析強調了 LLM 在整合到專家工作流程中的潛力，以提高臨床研究中的資料科學效率。</paragraph>

##### **A Perspective for Adapting Generalist AI to Specialized Medical AI Applications and Their Challenges**
2411.00024v1 by Zifeng Wang, Hanyin Wang, Benjamin Danek, Ying Li, Christina Mack, Hoifung Poon, Yajun Wang, Pranav Rajpurkar, Jimeng Sun

The integration of Large Language Models (LLMs) into medical applications has
sparked widespread interest across the healthcare industry, from drug discovery
and development to clinical decision support, assisting telemedicine, medical
devices, and healthcare insurance applications. This perspective paper aims to
discuss the inner workings of building LLM-powered medical AI applications and
introduces a comprehensive framework for their development. We review existing
literature and outline the unique challenges of applying LLMs in specialized
medical contexts. Additionally, we introduce a three-step framework to organize
medical LLM research activities: 1) Modeling: breaking down complex medical
workflows into manageable steps for developing medical-specific models; 2)
Optimization: optimizing the model performance with crafted prompts and
integrating external knowledge and tools, and 3) System engineering:
decomposing complex tasks into subtasks and leveraging human expertise for
building medical AI applications. Furthermore, we offer a detailed use case
playbook that describes various LLM-powered medical AI applications, such as
optimizing clinical trial design, enhancing clinical decision support, and
advancing medical imaging analysis. Finally, we discuss various challenges and
considerations for building medical AI applications with LLMs, such as handling
hallucination issues, data ownership and compliance, privacy, intellectual
property considerations, compute cost, sustainability issues, and responsible
AI requirements.

摘要：大型語言模型（LLM）整合到醫療應用中，在醫療產業中引起廣泛興趣，從藥物發現和開發到臨床決策支援，協助遠距醫療、醫療設備和醫療保險應用。本觀點論文旨在探討建構 LLM 驅動的醫療 AI 應用程式的內部運作，並介紹一個全面的開發架構。我們檢視現有文獻並概述在專業醫療情境中應用 LLM 的獨特挑戰。此外，我們引入一個三步驟架構來組織醫療 LLM 研究活動：1) 建模：將複雜的醫療工作流程分解為可管理的步驟，以開發特定於醫療的模型；2) 最佳化：使用精心設計的提示最佳化模型效能，並整合外部知識和工具；3) 系統工程：將複雜的任務分解為子任務，並利用人類專業知識來建構醫療 AI 應用程式。此外，我們提供一個詳細的使用案例範例，說明各種 LLM 驅動的醫療 AI 應用程式，例如最佳化臨床試驗設計、增強臨床決策支援和推進醫療影像分析。最後，我們討論建構具有 LLM 的醫療 AI 應用程式的各種挑戰和考量，例如處理幻覺問題、資料所有權和合規性、隱私、智慧財產權考量、運算成本、永續性問題和負責任的 AI 需求。

##### **Going Beyond H&E and Oncology: How Do Histopathology Foundation Models Perform for Multi-stain IHC and Immunology?**
2410.21560v1 by Amaya Gallagher-Syed, Elena Pontarini, Myles J. Lewis, Michael R. Barnes, Gregory Slabaugh

This study evaluates the generalisation capabilities of state-of-the-art
histopathology foundation models on out-of-distribution multi-stain autoimmune
Immunohistochemistry datasets. We compare 13 feature extractor models,
including ImageNet-pretrained networks, and histopathology foundation models
trained on both public and proprietary data, on Rheumatoid Arthritis subtyping
and Sjogren's Disease detection tasks. Using a simple Attention-Based Multiple
Instance Learning classifier, we assess the transferability of learned
representations from cancer H&E images to autoimmune IHC images. Contrary to
expectations, histopathology-pretrained models did not significantly outperform
ImageNet-pretrained models. Furthermore, there was evidence of both autoimmune
feature misinterpretation and biased feature importance. Our findings highlight
the challenges in transferring knowledge from cancer to autoimmune
histopathology and emphasise the need for careful evaluation of AI models
across diverse histopathological tasks. The code to run this benchmark is
available at https://github.com/AmayaGS/ImmunoHistoBench.

摘要：本研究評估了最先進的組織病理學基礎模型在分布外多染色自身免疫免疫組織化學數據集上的泛化能力。我們比較了 13 個特徵提取器模型，包括 ImageNet 預訓練網路，以及在公共和專有數據上訓練的組織病理學基礎模型，在類風濕性關節炎亞型和乾燥症檢測任務上。使用一個簡單的基於注意力的多實例學習分類器，我們評估了從癌症 H&E 影像到自身免疫 IHC 影像的學習表徵的可傳遞性。與預期相反，組織病理學預訓練模型並沒有顯著優於 ImageNet 預訓練模型。此外，有證據表明存在自身免疫特徵誤解和偏差特徵重要性。我們的研究結果強調了將知識從癌症轉移到自身免疫組織病理學的挑戰，並強調了跨不同組織病理學任務仔細評估 AI 模型的必要性。運行此基準測試的程式碼可在 https://github.com/AmayaGS/ImmunoHistoBench 獲得。

##### **Towards Multi-dimensional Explanation Alignment for Medical Classification**
2410.21494v1 by Lijie Hu, Songning Lai, Wenshuo Chen, Hongru Xiao, Hongbin Lin, Lu Yu, Jingfeng Zhang, Di Wang

The lack of interpretability in the field of medical image analysis has
significant ethical and legal implications. Existing interpretable methods in
this domain encounter several challenges, including dependency on specific
models, difficulties in understanding and visualization, as well as issues
related to efficiency. To address these limitations, we propose a novel
framework called Med-MICN (Medical Multi-dimensional Interpretable Concept
Network). Med-MICN provides interpretability alignment for various angles,
including neural symbolic reasoning, concept semantics, and saliency maps,
which are superior to current interpretable methods. Its advantages include
high prediction accuracy, interpretability across multiple dimensions, and
automation through an end-to-end concept labeling process that reduces the need
for extensive human training effort when working with new datasets. To
demonstrate the effectiveness and interpretability of Med-MICN, we apply it to
four benchmark datasets and compare it with baselines. The results clearly
demonstrate the superior performance and interpretability of our Med-MICN.

摘要：醫療影像分析領域缺乏可解釋性，這帶來重大的倫理和法律影響。現有的可解釋方法在這個領域中會遭遇許多挑戰，包括依賴特定模型、難以理解和視覺化，以及與效率相關的問題。為了解決這些限制，我們提出一個新的架構，稱為 Med-MICN（醫療多維可解釋概念網路）。Med-MICN 提供各種角度的可解釋性比對，包括神經符號推理、概念語意和顯著性圖，這些都優於目前的可解釋方法。它的優點包括高預測準確度、多維度的可解釋性，以及透過端到端概念標記流程自動化，這減少了在使用新資料集時需要大量人工訓練的工作。為了證明 Med-MICN 的有效性和可解釋性，我們將其應用於四個基準資料集，並與基準線進行比較。結果清楚地證明了我們的 Med-MICN 具有優異的效能和可解釋性。

##### **Multi-modal AI for comprehensive breast cancer prognostication**
2410.21256v1 by Jan Witowski, Ken Zeng, Joseph Cappadona, Jailan Elayoubi, Elena Diana Chiru, Nancy Chan, Young-Joon Kang, Frederick Howard, Irina Ostrovnaya, Carlos Fernandez-Granda, Freya Schnabel, Ugur Ozerdem, Kangning Liu, Zoe Steinsnyder, Nitya Thakore, Mohammad Sadic, Frank Yeung, Elisa Liu, Theodore Hill, Benjamin Swett, Danielle Rigau, Andrew Clayburn, Valerie Speirs, Marcus Vetter, Lina Sojak, Simone Muenst Soysal, Daniel Baumhoer, Khalil Choucair, Yu Zong, Lina Daoud, Anas Saad, Waleed Abdulsattar, Rafic Beydoun, Jia-Wern Pan, Haslina Makmur, Soo-Hwang Teo, Linda Ma Pak, Victor Angel, Dovile Zilenaite-Petrulaitiene, Arvydas Laurinavicius, Natalie Klar, Brian D. Piening, Carlo Bifulco, Sun-Young Jun, Jae Pak Yi, Su Hyun Lim, Adam Brufsky, Francisco J. Esteva, Lajos Pusztai, Yann LeCun, Krzysztof J. Geras

Treatment selection in breast cancer is guided by molecular subtypes and
clinical characteristics. Recurrence risk assessment plays a crucial role in
personalizing treatment. Current methods, including genomic assays, have
limited accuracy and clinical utility, leading to suboptimal decisions for many
patients. We developed a test for breast cancer patient stratification based on
digital pathology and clinical characteristics using novel AI methods.
Specifically, we utilized a vision transformer-based pan-cancer foundation
model trained with self-supervised learning to extract features from digitized
H&E-stained slides. These features were integrated with clinical data to form a
multi-modal AI test predicting cancer recurrence and death. The test was
developed and evaluated using data from a total of 8,161 breast cancer patients
across 15 cohorts originating from seven countries. Of these, 3,502 patients
from five cohorts were used exclusively for evaluation, while the remaining
patients were used for training. Our test accurately predicted our primary
endpoint, disease-free interval, in the five external cohorts (C-index: 0.71
[0.68-0.75], HR: 3.63 [3.02-4.37, p<0.01]). In a direct comparison (N=858), the
AI test was more accurate than Oncotype DX, the standard-of-care 21-gene assay,
with a C-index of 0.67 [0.61-0.74] versus 0.61 [0.49-0.73], respectively.
Additionally, the AI test added independent information to Oncotype DX in a
multivariate analysis (HR: 3.11 [1.91-5.09, p<0.01)]). The test demonstrated
robust accuracy across all major breast cancer subtypes, including TNBC
(C-index: 0.71 [0.62-0.81], HR: 3.81 [2.35-6.17, p=0.02]), where no diagnostic
tools are currently recommended by clinical guidelines. These results suggest
that our AI test can improve accuracy, extend applicability to a wider range of
patients, and enhance access to treatment selection tools.

摘要：<paragraph>乳癌的治療選擇是由分子亞型和臨床特徵所引導。復發風險評估在個人化治療中扮演至關重要的角色。目前的技術，包括基因體分析，具有有限的準確度和臨床效用，導致許多患者的治療決策次於最佳。我們開發了一種基於數位病理學和臨床特徵的乳癌患者分層檢測，採用新穎的人工智慧方法。具體來說，我們利用了一個基於視覺轉換器的泛癌基礎模型，並透過自我監督學習進行訓練，以從數位化的 H&E 染色玻片中提取特徵。這些特徵與臨床資料整合，形成一個多模式的人工智慧檢測，用於預測癌症復發和死亡。該檢測的開發和評估使用了來自七個國家/地區的 15 個群組共 8,161 名乳癌患者的資料。其中，來自五個群組的 3,502 名患者專門用於評估，而其餘患者則用於訓練。我們的檢測準確地預測了我們的主要終點，即五個外部群組的無疾病間期（C 指數：0.71 [0.68-0.75]，HR：3.63 [3.02-4.37，p<0.01]）。在直接比較（N=858）中，人工智慧檢測比安科泰Dx，標準照護的 21 基因檢測更準確，C 指數分別為 0.67 [0.61-0.74] 和 0.61 [0.49-0.73]。此外，人工智慧檢測在多變量分析中增加了安科泰 Dx 的獨立資訊（HR：3.11 [1.91-5.09，p<0.01]）。該檢測在所有主要的乳癌亞型中都表現出強大的準確度，包括 TNBC（C 指數：0.71 [0.62-0.81]，HR：3.81 [2.35-6.17，p=0.02]），臨床指南目前不建議使用任何診斷工具。這些結果表明，我們的人工智慧檢測可以提高準確度，將適用範圍擴展到更多患者，並增加獲得治療選擇工具的機會。</paragraph>

##### **Belief in the Machine: Investigating Epistemological Blind Spots of Language Models**
2410.21195v1 by Mirac Suzgun, Tayfun Gur, Federico Bianchi, Daniel E. Ho, Thomas Icard, Dan Jurafsky, James Zou

As language models (LMs) become integral to fields like healthcare, law, and
journalism, their ability to differentiate between fact, belief, and knowledge
is essential for reliable decision-making. Failure to grasp these distinctions
can lead to significant consequences in areas such as medical diagnosis, legal
judgments, and dissemination of fake news. Despite this, current literature has
largely focused on more complex issues such as theory of mind, overlooking more
fundamental epistemic challenges. This study systematically evaluates the
epistemic reasoning capabilities of modern LMs, including GPT-4, Claude-3, and
Llama-3, using a new dataset, KaBLE, consisting of 13,000 questions across 13
tasks. Our results reveal key limitations. First, while LMs achieve 86%
accuracy on factual scenarios, their performance drops significantly with false
scenarios, particularly in belief-related tasks. Second, LMs struggle with
recognizing and affirming personal beliefs, especially when those beliefs
contradict factual data, which raises concerns for applications in healthcare
and counseling, where engaging with a person's beliefs is critical. Third, we
identify a salient bias in how LMs process first-person versus third-person
beliefs, performing better on third-person tasks (80.7%) compared to
first-person tasks (54.4%). Fourth, LMs lack a robust understanding of the
factive nature of knowledge, namely, that knowledge inherently requires truth.
Fifth, LMs rely on linguistic cues for fact-checking and sometimes bypass the
deeper reasoning. These findings highlight significant concerns about current
LMs' ability to reason about truth, belief, and knowledge while emphasizing the
need for advancements in these areas before broad deployment in critical
sectors.

摘要：隨著語言模型 (LM) 成為醫療保健、法律和新聞等領域不可或缺的一部分，它們區分事實、信念和知識的能力對於可靠的決策至關重要。無法掌握這些區別可能會在醫療診斷、法律判決和假新聞傳播等領域造成重大後果。儘管如此，目前的文獻在很大程度上關注於更複雜的問題，例如心智理論，而忽視了更基本的認識論挑戰。本研究使用新的資料集 KaBLE，對現代 LM（包括 GPT-4、Claude-3 和 Llama-3）的認識論推理能力進行了系統評估，該資料集包含 13 個任務中的 13,000 個問題。我們的結果揭示了關鍵限制。首先，雖然 LM 在事實場景中達到 86% 的準確度，但它們在錯誤場景中的表現大幅下降，特別是在與信念相關的任務中。其次，LM 難以識別和肯定個人信念，特別是當這些信念與事實資料相矛盾時，這引起了對醫療保健和諮詢應用程式的擔憂，在這些應用程式中，與個人的信念互動至關重要。第三，我們發現 LM 處理第一人稱與第三人稱信念的方式存在顯著偏差，在第三人稱任務（80.7%）上的表現優於第一人稱任務（54.4%）。第四，LM 缺乏對知識的事實性質的穩健理解，即知識本質上需要真理。第五，LM 依賴語言線索進行事實查核，有時會繞過更深入的推理。這些發現突顯了當前 LM 推理真理、信念和知識的能力存在重大疑慮，同時強調在廣泛部署於關鍵部門之前，需要在這些領域取得進展。

##### **Deep Learning-Based Fatigue Cracks Detection in Bridge Girders using Feature Pyramid Networks**
2410.21175v1 by Jiawei Zhang, Jun Li, Reachsak Ly, Yunyi Liu, Jiangpeng Shu

For structural health monitoring, continuous and automatic crack detection
has been a challenging problem. This study is conducted to propose a framework
of automatic crack segmentation from high-resolution images containing crack
information about steel box girders of bridges. Considering the multi-scale
feature of cracks, convolutional neural network architecture of Feature Pyramid
Networks (FPN) for crack detection is proposed. As for input, 120 raw images
are processed via two approaches (shrinking the size of images and splitting
images into sub-images). Then, models with the proposed structure of FPN for
crack detection are developed. The result shows all developed models can
automatically detect the cracks at the raw images. By shrinking the images, the
computation efficiency is improved without decreasing accuracy. Because of the
separable characteristic of crack, models using the splitting method provide
more accurate crack segmentations than models using the resizing method.
Therefore, for high-resolution images, the FPN structure coupled with the
splitting method is an promising solution for the crack segmentation and
detection.

摘要：對於結構健康監測，連續且自動的裂縫偵測一直是一個具有挑戰性的問題。本研究旨在提出一個從包含橋樑鋼箱梁裂縫資訊的高解析度影像中自動分割裂縫的架構。考量到裂縫的多尺度特徵，提出用於裂縫偵測的 Feature Pyramid Networks (FPN) 捲積神經網路架構。至於輸入，120 張原始影像透過兩種方法處理（縮小影像尺寸和將影像分割成子影像）。然後，開發具有 FPN 提議結構的裂縫偵測模型。結果顯示所有已開發的模型都能自動偵測原始影像中的裂縫。藉由縮小影像，在不降低準確度的狀況下提升運算效率。由於裂縫具有可分離的特徵，使用分割方法的模型提供比使用縮放方法的模型更準確的裂縫分割。因此，對於高解析度影像，FPN 結構結合分割方法是裂縫分割和偵測的有前途的解決方案。

##### **Trajectory Flow Matching with Applications to Clinical Time Series Modeling**
2410.21154v1 by Xi Zhang, Yuan Pu, Yuki Kawamura, Andrew Loza, Yoshua Bengio, Dennis L. Shung, Alexander Tong

Modeling stochastic and irregularly sampled time series is a challenging
problem found in a wide range of applications, especially in medicine. Neural
stochastic differential equations (Neural SDEs) are an attractive modeling
technique for this problem, which parameterize the drift and diffusion terms of
an SDE with neural networks. However, current algorithms for training Neural
SDEs require backpropagation through the SDE dynamics, greatly limiting their
scalability and stability. To address this, we propose Trajectory Flow Matching
(TFM), which trains a Neural SDE in a simulation-free manner, bypassing
backpropagation through the dynamics. TFM leverages the flow matching technique
from generative modeling to model time series. In this work we first establish
necessary conditions for TFM to learn time series data. Next, we present a
reparameterization trick which improves training stability. Finally, we adapt
TFM to the clinical time series setting, demonstrating improved performance on
three clinical time series datasets both in terms of absolute performance and
uncertainty prediction.

摘要：隨機且不規則取樣的時序建模是一個具有挑戰性的問題，在廣泛的應用中發現，特別是在醫學中。神經隨機微分方程 (Neural SDE) 是這個問題一個有吸引力的建模技術，它用神經網路參數化 SDE 的漂移和擴散項。然而，目前訓練神經 SDE 的演算法需要透過 SDE 動態進行反向傳播，極大地限制了它們的可擴充性和穩定性。為了解決這個問題，我們提出軌跡流匹配 (TFM)，它以無模擬的方式訓練一個神經 SDE，繞過動態的反向傳播。TFM 利用生成式建模中的流匹配技術來建模時序。在這項工作中，我們首先建立 TFM 學習時序資料的必要條件。接下來，我們提出一個重新參數化的技巧，它改進了訓練穩定性。最後，我們將 TFM 適應到臨床時序設定，證明了在絕對效能和不確定性預測方面，在三個臨床時序資料集上都有效能的提升。

##### **Informed Deep Abstaining Classifier: Investigating noise-robust training for diagnostic decision support systems**
2410.21014v1 by Helen Schneider, Sebastian Nowak, Aditya Parikh, Yannik C. Layer, Maike Theis, Wolfgang Block, Alois M. Sprinkart, Ulrike Attenberger, Rafet Sifa

Image-based diagnostic decision support systems (DDSS) utilizing deep
learning have the potential to optimize clinical workflows. However, developing
DDSS requires extensive datasets with expert annotations and is therefore
costly. Leveraging report contents from radiological data bases with Natural
Language Processing to annotate the corresponding image data promises to
replace labor-intensive manual annotation. As mining "real world" databases can
introduce label noise, noise-robust training losses are of great interest.
However, current noise-robust losses do not consider noise estimations that can
for example be derived based on the performance of the automatic label
generator used. In this study, we expand the noise-robust Deep Abstaining
Classifier (DAC) loss to an Informed Deep Abstaining Classifier (IDAC) loss by
incorporating noise level estimations during training. Our findings demonstrate
that IDAC enhances the noise robustness compared to DAC and several
state-of-the-art loss functions. The results are obtained on various simulated
noise levels using a public chest X-ray data set. These findings are reproduced
on an in-house noisy data set, where labels were extracted from the clinical
systems of the University Hospital Bonn by a text-based transformer. The IDAC
can therefore be a valuable tool for researchers, companies or clinics aiming
to develop accurate and reliable DDSS from routine clinical data.

摘要：<paragraph>利用深度學習的影像診斷決策支援系統 (DDSS) 有可能最佳化臨床工作流程。然而，開發 DDSS 需要大量具備專家註解的資料集，因此成本高昂。利用自然語言處理從放射科資料庫的報告內容中標註對應的影像資料，有望取代勞力密集的手動標註。由於挖掘「真實世界」資料庫可能會引入標籤雜訊，因此對雜訊穩健的訓練損失非常重要。然而，目前對雜訊穩健的損失函數並未考慮雜訊估計，例如可以根據所使用的自動標籤產生器的效能推導出來。在本研究中，我們透過在訓練期間納入雜訊等級估計，將對雜訊穩健的深度棄權分類器 (DAC) 損失函數擴充為明智深度棄權分類器 (IDAC) 損失函數。我們的研究結果顯示，與 DAC 和多種最先進的損失函數相比，IDAC 增強了對雜訊的穩健性。這些結果是使用公開的胸部 X 光資料集，在各種模擬雜訊等級中獲得的。這些研究結果在內部雜訊資料集上重現，其中標籤是由文本轉換器從波恩大學醫院的臨床系統中萃取出來的。因此，IDAC 可以成為研究人員、公司或診所從例行臨床資料開發準確且可靠的 DDSS 的有價值工具。</paragraph>

##### **Efficient Bilinear Attention-based Fusion for Medical Visual Question Answering**
2410.21000v1 by Zhilin Zhang, Jie Wang, Ruiqi Zhu, Xiaoliang Gong

Medical Visual Question Answering (MedVQA) has gained increasing attention at
the intersection of computer vision and natural language processing. Its
capability to interpret radiological images and deliver precise answers to
clinical inquiries positions MedVQA as a valuable tool for supporting
diagnostic decision-making for physicians and alleviating the workload on
radiologists. While recent approaches focus on using unified pre-trained large
models for multi-modal fusion like cross-modal Transformers, research on more
efficient fusion methods remains relatively scarce within this discipline. In
this paper, we introduce a novel fusion model that integrates Orthogonality
loss, Multi-head attention and Bilinear Attention Network (OMniBAN) to achieve
high computational efficiency and strong performance without the need for
pre-training. We conduct comprehensive experiments and clarify aspects of how
to enhance bilinear attention fusion to achieve performance comparable to that
of large models. Experimental results show that OMniBAN outperforms traditional
models on key MedVQA benchmarks while maintaining a lower computational cost,
which indicates its potential for efficient clinical application in radiology
and pathology image question answering.

摘要：醫療視覺問答 (MedVQA) 在電腦視覺和自然語言處理的交集中獲得越來越多的關注。它能夠解讀放射影像並對臨床詢問提供精確答案的能力，使 MedVQA 成為支援醫師診斷決策和減輕放射科醫師工作負擔的寶貴工具。雖然最近的方法著重於使用統一的預先訓練大型模型進行多模式融合，例如跨模態 Transformer，但對於更有效率的融合方法的研究在此領域中仍然相對稀少。在本文中，我們介紹了一個新穎的融合模型，它整合了正交損失、多頭注意力和雙線性注意力網路 (OMniBAN)，以在不需要預先訓練的情況下實現高計算效率和強大效能。我們進行了全面的實驗，並釐清了如何增強雙線性注意力融合以實現與大型模型相當的效能。實驗結果表明，OMniBAN 在關鍵的 MedVQA 基準上優於傳統模型，同時維持較低的計算成本，這表明它在放射學和病理影像問答中具有高效臨床應用的潛力。

##### **Large Language Model Benchmarks in Medical Tasks**
2410.21348v1 by Lawrence K. Q. Yan, Ming Li, Yichao Zhang, Caitlyn Heqi Yin, Cheng Fei, Benji Peng, Ziqian Bi, Pohsun Feng, Keyu Chen, Junyu Liu, Qian Niu

With the increasing application of large language models (LLMs) in the
medical domain, evaluating these models' performance using benchmark datasets
has become crucial. This paper presents a comprehensive survey of various
benchmark datasets employed in medical LLM tasks. These datasets span multiple
modalities including text, image, and multimodal benchmarks, focusing on
different aspects of medical knowledge such as electronic health records
(EHRs), doctor-patient dialogues, medical question-answering, and medical image
captioning. The survey categorizes the datasets by modality, discussing their
significance, data structure, and impact on the development of LLMs for
clinical tasks such as diagnosis, report generation, and predictive decision
support. Key benchmarks include MIMIC-III, MIMIC-IV, BioASQ, PubMedQA, and
CheXpert, which have facilitated advancements in tasks like medical report
generation, clinical summarization, and synthetic data generation. The paper
summarizes the challenges and opportunities in leveraging these benchmarks for
advancing multimodal medical intelligence, emphasizing the need for datasets
with a greater degree of language diversity, structured omics data, and
innovative approaches to synthesis. This work also provides a foundation for
future research in the application of LLMs in medicine, contributing to the
evolving field of medical artificial intelligence.

摘要：隨著大型語言模型 (LLM) 在醫療領域的應用日益廣泛，使用基準資料集評估這些模型的效能已變得至關重要。本文對用於醫療 LLM 任務的各種基準資料集進行了全面的調查。這些資料集跨越多種模式，包括文字、影像和多模態基準，重點關注電子健康紀錄 (EHR)、醫病對話、醫療問答和醫療影像標題等醫療知識的不同面向。調查按模式對資料集進行分類，討論它們的重要性、資料結構和對用於診斷、報告生成和預測性決策支援等臨床任務的 LLM 開發的影響。主要基準包括 MIMIC-III、MIMIC-IV、BioASQ、PubMedQA 和 CheXpert，它們促进了醫療報告生成、臨床摘要和合成資料生成等任務的進展。本文總結了利用這些基準來推進多模態醫療智能的挑戰和機遇，強調了對具有更大語言多樣性、結構化組學資料和創新合成方法的資料集的需求。這項工作也為 LLM 在醫學中的應用提供了未來研究的基礎，為醫療人工智慧的演進領域做出貢獻。

##### **Vascular Segmentation of Functional Ultrasound Images using Deep Learning**
2410.22365v1 by Hana Sebia, Thomas Guyet, Mickaël Pereira, Marco Valdebenito, Hugues Berry, Benjamin Vidal

Segmentation of medical images is a fundamental task with numerous
applications. While MRI, CT, and PET modalities have significantly benefited
from deep learning segmentation techniques, more recent modalities, like
functional ultrasound (fUS), have seen limited progress. fUS is a non invasive
imaging method that measures changes in cerebral blood volume (CBV) with high
spatio-temporal resolution. However, distinguishing arterioles from venules in
fUS is challenging due to opposing blood flow directions within the same pixel.
Ultrasound localization microscopy (ULM) can enhance resolution by tracking
microbubble contrast agents but is invasive, and lacks dynamic CBV
quantification. In this paper, we introduce the first deep learning-based
segmentation tool for fUS images, capable of differentiating signals from
different vascular compartments, based on ULM automatic annotation and enabling
dynamic CBV quantification. We evaluate various UNet architectures on fUS
images of rat brains, achieving competitive segmentation performance, with 90%
accuracy, a 71% F1 score, and an IoU of 0.59, using only 100 temporal frames
from a fUS stack. These results are comparable to those from tubular structure
segmentation in other imaging modalities. Additionally, models trained on
resting-state data generalize well to images captured during visual
stimulation, highlighting robustness. This work offers a non-invasive,
cost-effective alternative to ULM, enhancing fUS data interpretation and
improving understanding of vessel function. Our pipeline shows high linear
correlation coefficients between signals from predicted and actual compartments
in both cortical and deeperregions, showcasing its ability to accurately
capture blood flow dynamics.

摘要：<paragraph>醫學影像的分割是項基礎任務，有許多應用。雖然 MRI、CT 和 PET 等方式已從深度學習分割技術中受益良多，但像功能性超音波 (fUS) 等較新的方式進展有限。fUS 是一種非侵入性的影像方法，可測量腦血容量 (CBV) 的變化，具有高時空解析度。然而，由於同一個像素中血流方向相反，因此在 fUS 中區分小動脈和小靜脈具有挑戰性。超音波定位顯微鏡 (ULM) 可以透過追蹤微氣泡對比劑來增強解析度，但具有侵入性，且缺乏動態 CBV 量化。在本文中，我們介紹了第一個基於深度學習的 fUS 影像分割工具，它能夠根據 ULM 自動註解區分不同血管區室的訊號，並啟用動態 CBV 量化。我們在老鼠大腦的 fUS 影像上評估了各種 UNet 架構，僅使用 fUS 堆疊中的 100 個時間幀，就達到了具有競爭力的分割效能，準確率為 90%，F1 分數為 71%，IoU 為 0.59。這些結果與其他影像方式中管狀結構分割的結果相當。此外，在靜止狀態資料上訓練的模型可以很好地推廣到在視覺刺激期間擷取的影像，突顯了其穩健性。這項工作提供了一個非侵入性、具有成本效益的 ULM 替代方案，增強了 fUS 資料的詮釋，並改善了對血管功能的理解。我們的管線在預測區室和實際區室的訊號之間顯示出很高的線性相關係數，無論是在皮質還是深層區域，都展示了其準確捕捉血流動態的能力。</paragraph>

##### **Language Models And A Second Opinion Use Case: The Pocket Professional**
2410.20636v1 by David Noever

This research tests the role of Large Language Models (LLMs) as formal second
opinion tools in professional decision-making, particularly focusing on complex
medical cases where even experienced physicians seek peer consultation. The
work analyzed 183 challenging medical cases from Medscape over a 20-month
period, testing multiple LLMs' performance against crowd-sourced physician
responses. A key finding was the high overall score possible in the latest
foundational models (>80% accuracy compared to consensus opinion), which
exceeds most human metrics reported on the same clinical cases (450 pages of
patient profiles, test results). The study rates the LLMs' performance
disparity between straightforward cases (>81% accuracy) and complex scenarios
(43% accuracy), particularly in these cases generating substantial debate among
human physicians. The research demonstrates that LLMs may be valuable as
generators of comprehensive differential diagnoses rather than as primary
diagnostic tools, potentially helping to counter cognitive biases in clinical
decision-making, reduce cognitive loads, and thus remove some sources of
medical error. The inclusion of a second comparative legal dataset (Supreme
Court cases, N=21) provides added empirical context to the AI use to foster
second opinions, though these legal challenges proved considerably easier for
LLMs to analyze. In addition to the original contributions of empirical
evidence for LLM accuracy, the research aggregated a novel benchmark for others
to score highly contested question and answer reliability between both LLMs and
disagreeing human practitioners. These results suggest that the optimal
deployment of LLMs in professional settings may differ substantially from
current approaches that emphasize automation of routine tasks.

摘要：這項研究測試了大型語言模型 (LLM) 在專業決策中作為正式第二意見工具的角色，特別著重於複雜的醫療案例，即使經驗豐富的醫師也會尋求同儕諮詢。這項工作分析了 Medscape 在 20 個月期間的 183 個具有挑戰性的醫療案例，測試多個 LLM 的表現，並與群眾外包的醫師回應進行比較。一個關鍵發現是最新基礎模型中可能的高總體分數（與共識意見相比，準確率 >80%），這超過了針對相同臨床案例報告的大多數人類指標（450 頁的患者檔案、檢驗結果）。這項研究評估了 LLM 在直接案例（準確率 >81%）和複雜情境（準確率 43%）之間的表現差異，特別是在這些案例中，會在人類醫師間產生大量的辯論。這項研究證明，LLM 可能是有價值的全面鑑別診斷產生器，而非主要的診斷工具，潛在有助於對抗臨床決策中的認知偏誤、減少認知負擔，並因此消除一些醫療錯誤的根源。加入第二個比較法律資料集（最高法院案例，N=21）為 AI 用於促進第二意見提供了額外的經驗背景，儘管這些法律挑戰被證明對 LLM 來說更容易分析。除了 LLM 準確性的經驗證據的原始貢獻外，這項研究還匯總了一個新的基準，供其他人為 LLM 和意見分歧的人類從業人員之間高度有爭議的問題和答案的可靠性進行評分。這些結果表明，LLM 在專業環境中的最佳部署可能與強調自動化例行任務的當前方法有很大不同。

##### **Improving Decision Sparsity**
2410.20483v1 by Yiyang Sun, Tong Wang, Cynthia Rudin

Sparsity is a central aspect of interpretability in machine learning.
Typically, sparsity is measured in terms of the size of a model globally, such
as the number of variables it uses. However, this notion of sparsity is not
particularly relevant for decision-making; someone subjected to a decision does
not care about variables that do not contribute to the decision. In this work,
we dramatically expand a notion of decision sparsity called the Sparse
Explanation Value(SEV) so that its explanations are more meaningful. SEV
considers movement along a hypercube towards a reference point. By allowing
flexibility in that reference and by considering how distances along the
hypercube translate to distances in feature space, we can derive sparser and
more meaningful explanations for various types of function classes. We present
cluster-based SEV and its variant tree-based SEV, introduce a method that
improves credibility of explanations, and propose algorithms that optimize
decision sparsity in machine learning models.

摘要：稀疏性是機器學習中可解釋性的核心面向。
一般來說，稀疏性是以模型整體的大小來衡量，例如它使用的變數數量。然而，這種稀疏性概念與決策制定並無特別相關；受到決策影響的人並不在乎那些與決策無關的變數。在這項工作中，我們大幅擴展了一個稱為稀疏解釋值 (SEV) 的決策稀疏性概念，使其解釋更具意義。SEV 考量沿著超立方體朝向參考點的移動。透過允許該參考的靈活性，並考量沿著超立方體的距離如何轉換為特徵空間中的距離，我們可以針對各種函數類別推導出更稀疏且更有意義的解釋。我們提出基於叢集的 SEV 及其變體基於樹狀結構的 SEV，引入一種方法來提升解釋的可信度，並提出最佳化機器學習模型中決策稀疏性的演算法。

##### **MedGo: A Chinese Medical Large Language Model**
2410.20428v1 by Haitao Zhang, Bo An

Large models are a hot research topic in the field of artificial
intelligence. Leveraging their generative capabilities has the potential to
enhance the level and quality of medical services. In response to the
limitations of current large language models, which often struggle with
accuracy and have narrow capabilities in medical applications, this paper
presents a Chinese medical large language model, MedGo. MedGo was trained using
a combination of high quality unsupervised medical data, supervised data, and
preference alignment data, aimed at enhancing both its versatility and
precision in medical tasks. The model was evaluated through the public CBLUE
benchmark and a manually constructed dataset ClinicalQA. The results
demonstrate that MedGo achieved promising performance across various Chinese
medical information processing tasks, achieved the first place in the CBLUE
evaluation. Additionally, on our constructed dataset ClinicalQA, MedGo
outperformed its base model Qwen2, highlighting its potential to improve both
automated medical question answering and clinical decision support. These
experimental results demonstrate that MedGo possesses strong information
processing capabilities in the medical field. At present, we have successfully
deployed MedGo at Shanghai East Hospital.

摘要：大型模型是人工智能领域的研究热点。利用它们生成的能力有可能提高医疗服务的水平和质量。为了解决当前大型语言模型的局限性，这些模型通常难以达到准确性，并且在医疗应用中的能力较窄，本文提出了一个中文医疗大型语言模型 MedGo。MedGo 使用高质量无监督医疗数据、监督数据和偏好对齐数据的组合进行训练，旨在增强其在医疗任务中的多功能性和准确性。该模型通过公共 CBLUE 基准和手动构建的数据集 ClinicalQA 进行了评估。结果表明，MedGo 在各种中文医疗信息处理任务中取得了可喜的性能，在 CBLUE 评估中取得了第一名。此外，在我们的构建数据集 ClinicalQA 上，MedGo 优于其基础模型 Qwen2，突出了其在改进自动化医疗问题解答和临床决策支持方面的潜力。这些实验结果表明，MedGo 在医疗领域拥有强大的信息处理能力。目前，我们已成功在上海东方医院部署了 MedGo。

##### **Addressing the Pitfalls of Image-Based Structural Health Monitoring: A Focus on False Positives, False Negatives, and Base Rate Bias**
2410.20384v1 by Vagelis Plevris

This study explores the limitations of image-based structural health
monitoring (SHM) techniques in detecting structural damage. Leveraging machine
learning and computer vision, image-based SHM offers a scalable and efficient
alternative to manual inspections. However, its reliability is impacted by
challenges such as false positives, false negatives, and environmental
variability, particularly in low base rate damage scenarios. The Base Rate Bias
plays a significant role, as low probabilities of actual damage often lead to
misinterpretation of positive results. This study uses both Bayesian analysis
and a frequentist approach to evaluate the precision of damage detection
systems, revealing that even highly accurate models can yield misleading
results when the occurrence of damage is rare. Strategies for mitigating these
limitations are discussed, including hybrid systems that combine multiple data
sources, human-in-the-loop approaches for critical assessments, and improving
the quality of training data. These findings provide essential insights into
the practical applicability of image-based SHM techniques, highlighting both
their potential and their limitations for real-world infrastructure monitoring.

摘要：本研究探討了基於影像的結構健康監測 (SHM) 技術在檢測結構損壞方面的限制。藉由機器學習和電腦視覺，基於影像的 SHM 提供了可擴充且有效率的替代人工檢查的方法。然而，其可靠性受到挑戰的影響，例如假陽性、假陰性，以及環境變異性，特別是在低基底損壞情境中。基底比率偏差扮演了重要的角色，因為實際損壞的低機率常常導致對於陽性結果的誤解。本研究同時使用貝氏分析和頻率論方法來評估損壞檢測系統的精準度，揭示即使高度精確的模型在損壞發生率稀少時也可能產生誤導性的結果。討論了減輕這些限制的策略，包括結合多重資料來源的混合系統、對於關鍵評估的人類介入方法，以及改善訓練資料品質。這些發現提供了對於基於影像的 SHM 技術實務適用性的重要見解，突顯了它們在現實世界基礎設施監測方面的潛力和限制。

##### **R-LLaVA: Improving Med-VQA Understanding through Visual Region of Interest**
2410.20327v2 by Xupeng Chen, Zhixin Lai, Kangrui Ruan, Shichu Chen, Jiaxiang Liu, Zuozhu Liu

Artificial intelligence has made significant strides in medical visual
question answering (Med-VQA), yet prevalent studies often interpret images
holistically, overlooking the visual regions of interest that may contain
crucial information, potentially aligning with a doctor's prior knowledge that
can be incorporated with minimal annotations (e.g., bounding boxes). To address
this gap, this paper introduces R-LLaVA, designed to enhance biomedical VQA
understanding by integrating simple medical annotations as prior knowledge
directly into the image space through CLIP. These annotated visual regions of
interest are then fed into the LLaVA model during training, aiming to enrich
the model's understanding of biomedical queries. Experimental evaluation on
four standard Med-VQA datasets demonstrates R-LLaVA's superiority over existing
state-of-the-art (SoTA) methods. Additionally, to verify the model's capability
in visual comprehension, a novel multiple-choice medical visual understanding
dataset is introduced, confirming the positive impact of focusing on visual
regions of interest in advancing biomedical VQA understanding.

摘要：人工智慧在醫學視覺問答 (Med-VQA) 領域取得重大進展，但普遍的研究往往整體詮釋影像，忽略可能包含關鍵資訊的視覺感興趣區域，潛在符合醫師先備知識，且能透過最少註解（例如邊界框）納入。為了解決此差距，本文提出 R-LLaVA，旨在透過 CLIP 將簡單的醫學註解作為先備知識直接整合到影像空間，以增強生物醫學 VQA 理解。這些帶註解的視覺感興趣區域隨後在訓練期間輸入 LLaVA 模型，目標是豐富模型對生物醫學查詢的理解。在四個標準 Med-VQA 資料集上的實驗評估顯示，R-LLaVA 優於現有的最先進 (SoTA) 方法。此外，為了驗證模型在視覺理解中的能力，引入了新穎的多選題醫學視覺理解資料集，證實專注於視覺感興趣區域對推進生物醫學 VQA 理解的正面影響。

##### **Enhancing Community Vision Screening -- AI Driven Retinal Photography for Early Disease Detection and Patient Trust**
2410.20309v1 by Xiaofeng Lei, Yih-Chung Tham, Jocelyn Hui Lin Goh, Yangqin Feng, Yang Bai, Zhi Da Soh, Rick Siow Mong Goh, Xinxing Xu, Yong Liu, Ching-Yu Cheng

Community vision screening plays a crucial role in identifying individuals
with vision loss and preventing avoidable blindness, particularly in rural
communities where access to eye care services is limited. Currently, there is a
pressing need for a simple and efficient process to screen and refer
individuals with significant eye disease-related vision loss to tertiary eye
care centers for further care. An ideal solution should seamlessly and readily
integrate with existing workflows, providing comprehensive initial screening
results to service providers, thereby enabling precise patient referrals for
timely treatment. This paper introduces the Enhancing Community Vision
Screening (ECVS) solution, which addresses the aforementioned concerns with a
novel and feasible solution based on simple, non-invasive retinal photography
for the detection of pathology-based visual impairment. Our study employs four
distinct deep learning models: RETinal photo Quality Assessment (RETQA),
Pathology Visual Impairment detection (PVI), Eye Disease Diagnosis (EDD) and
Visualization of Lesion Regions of the eye (VLR). We conducted experiments on
over 10 datasets, totaling more than 80,000 fundus photos collected from
various sources. The models integrated into ECVS achieved impressive AUC scores
of 0.98 for RETQA, 0.95 for PVI, and 0.90 for EDD, along with a DICE
coefficient of 0.48 for VLR. These results underscore the promising
capabilities of ECVS as a straightforward and scalable method for
community-based vision screening.

摘要：社區視力篩檢在辨識視力受損的個人以及預防可避免的失明方面扮演著至關重要的角色，特別是在取得眼科保健服務受限的鄉村社區中。目前，迫切需要一個簡單且有效率的流程來篩選和轉介具有顯著眼疾相關視力受損的個人至三級眼科保健中心以接受進一步的照護。理想的解決方案應與現有的工作流程無縫且輕易地整合，提供全面的初步篩檢結果給服務提供者，進而能精確地轉介患者以獲得及時的治療。本文介紹了增強社區視力篩檢 (ECVS) 解決方案，該方案透過一種新穎且可行的解決方案來解決上述問題，這個解決方案是基於簡單、非侵入性的視網膜攝影來偵測病理性的視力受損。我們的研究採用四種不同的深度學習模型：視網膜照片品質評估 (RETQA)、病理性視力受損偵測 (PVI)、眼疾診斷 (EDD) 和眼睛病灶區域視覺化 (VLR)。我們在超過 10 個資料集上進行實驗，總計超過 80,000 張從各種來源收集而來的眼底照片。整合到 ECVS 的模型達到了令人印象深刻的 AUC 分數，RETQA 為 0.98、PVI 為 0.95、EDD 為 0.90，以及 VLR 的 DICE 係數為 0.48。這些結果強調了 ECVS 作為一種用於社區視力篩檢的直接且可擴充方法的潛力。

##### **Modelling of Economic Implications of Bias in AI-Powered Health Emergency Response Systems**
2410.20229v1 by Katsiaryna Bahamazava

We present a theoretical framework assessing the economic implications of
bias in AI-powered emergency response systems. Integrating health economics,
welfare economics, and artificial intelligence, we analyze how algorithmic bias
affects resource allocation, health outcomes, and social welfare. By
incorporating a bias function into health production and social welfare models,
we quantify its impact on demographic groups, showing that bias leads to
suboptimal resource distribution, increased costs, and welfare losses. The
framework highlights efficiency-equity trade-offs and provides economic
interpretations. We propose mitigation strategies, including
fairness-constrained optimization, algorithmic adjustments, and policy
interventions. Our findings offer insights for policymakers, emergency service
providers, and technology developers, emphasizing the need for AI systems that
are efficient and equitable. By addressing the economic consequences of biased
AI, this study contributes to policies and technologies promoting fairness,
efficiency, and social welfare in emergency response services.

摘要：我們提出一個理論架構，評估人工智慧緊急應變系統中偏誤的經濟影響。整合健康經濟學、福利經濟學和人工智慧，我們分析演算法偏誤如何影響資源分配、健康結果和社會福利。透過將偏誤函數納入健康生產和社會福利模型，我們量化其對人口群體的影響，顯示偏誤導致次優資源分配、增加成本和福利損失。該架構強調效率與公平性的權衡，並提供經濟詮釋。我們提出緩解策略，包括公平約束最佳化、演算法調整和政策干預。我們的研究結果為政策制定者、緊急服務提供者和技術開發者提供見解，強調需要兼具效率和公平性的 AI 系統。透過探討有偏誤的 AI 的經濟後果，本研究有助於制定促進公平性、效率和社會福利的政策和技術，以運用於緊急應變服務。

##### **Generative AI in Health Economics and Outcomes Research: A Taxonomy of Key Definitions and Emerging Applications, an ISPOR Working Group Report**
2410.20204v1 by Rachael Fleurence, Xiaoyan Wang, Jiang Bian, Mitchell K. Higashi, Turgay Ayer, Hua Xu, Dalia Dawoud, Jagpreet Chhatwal

Objective: This article offers a taxonomy of generative artificial
intelligence (AI) for health economics and outcomes research (HEOR), explores
its emerging applications, and outlines methods to enhance the accuracy and
reliability of AI-generated outputs. Methods: The review defines foundational
generative AI concepts and highlights current HEOR applications, including
systematic literature reviews, health economic modeling, real-world evidence
generation, and dossier development. Approaches such as prompt engineering
(zero-shot, few-shot, chain-of-thought, persona pattern prompting),
retrieval-augmented generation, model fine-tuning, and the use of
domain-specific models are introduced to improve AI accuracy and reliability.
Results: Generative AI shows significant potential in HEOR, enhancing
efficiency, productivity, and offering novel solutions to complex challenges.
Foundation models are promising in automating complex tasks, though challenges
remain in scientific reliability, bias, interpretability, and workflow
integration. The article discusses strategies to improve the accuracy of these
AI tools. Conclusion: Generative AI could transform HEOR by increasing
efficiency and accuracy across various applications. However, its full
potential can only be realized by building HEOR expertise and addressing the
limitations of current AI technologies. As AI evolves, ongoing research and
innovation will shape its future role in the field.

摘要：**目標：**本文提供了一種生成式人工智慧（AI）的分類法，用於健康經濟學和成果研究（HEOR），探討其新興應用，並概述增強 AI 生成的輸出準確性和可靠性的方法。**方法：**本回顧定義了生成式 AI 的基礎概念，並重點介紹了當前的 HEOR 應用，包括系統文獻回顧、健康經濟模型、真實世界證據生成和檔案開發。介紹了諸如提示工程（零次、少次、思維鏈、角色模式提示）、檢索增強生成、模型微調和使用特定領域模型等方法，以提高 AI 的準確性和可靠性。**結果：**生成式 AI 在 HEOR 中顯示出顯著的潛力，提高效率、生產力，並為複雜的挑戰提供創新的解決方案。基礎模型在自動化複雜任務方面很有前景，儘管在科學可靠性、偏差、可解釋性和工作流程整合方面仍然存在挑戰。本文討論了提高這些 AI 工具準確性的策略。**結論：**生成式 AI 可以通過提高各種應用中的效率和準確性來轉變 HEOR。然而，只有通過建立 HEOR 專業知識並解決當前 AI 技術的局限性，才能實現其全部潛力。隨著 AI 的發展，持續的研究和創新將塑造其在該領域的未來角色。

##### **Advanced Cyberattack Detection in Internet of Medical Things (IoMT) Using Convolutional Neural Networks**
2410.23306v1 by Alireza Mohammadi, Hosna Ghahramani, Seyyed Amir Asghari, Mehdi Aminian

The increasing integration of the Internet of Medical Things (IoMT) into
healthcare systems has significantly enhanced patient care but has also
introduced critical cybersecurity challenges. This paper presents a novel
approach based on Convolutional Neural Networks (CNNs) for detecting
cyberattacks within IoMT environments. Unlike previous studies that
predominantly utilized traditional machine learning (ML) models or simpler Deep
Neural Networks (DNNs), the proposed model leverages the capabilities of CNNs
to effectively analyze the temporal characteristics of network traffic data.
Trained and evaluated on the CICIoMT2024 dataset, which comprises 18 distinct
types of cyberattacks across a range of IoMT devices, the proposed CNN model
demonstrates superior performance compared to previous state-of-the-art
methods, achieving a perfect accuracy of 99% in binary, categorical, and
multiclass classification tasks. This performance surpasses that of
conventional ML models such as Logistic Regression, AdaBoost, DNNs, and Random
Forests. These findings highlight the potential of CNNs to substantially
improve IoMT cybersecurity, thereby ensuring the protection and integrity of
connected healthcare systems.

摘要：隨著醫療物聯網 (IoMT) 與醫療保健系統整合度不斷提高，大幅提升了患者照護品質，但也引入了嚴峻的網路安全挑戰。本文提出了一種創新的方法，基於卷積神經網路 (CNN) 來偵測 IoMT 環境中的網路攻擊。與以往主要使用傳統機器學習 (ML) 模型或較簡單深度神經網路 (DNN) 的研究不同，提出的模型運用 CNN 的功能，有效分析網路流量資料的時間特徵。在包含 18 種不同類型網路攻擊的 CICIoMT2024 資料集上訓練和評估後，提出的 CNN 模型展現出優於以往最先進方法的效能，在二元、分類和多類別分類任務中達到 99% 的完美準確度。此效能超越了傳統 ML 模型，例如邏輯迴歸、AdaBoost、DNN 和隨機森林。這些發現突顯了 CNN 在大幅提升 IoMT 網路安全方面的潛力，進而確保連網醫療保健系統的防護和完整性。

##### **Diff-CXR: Report-to-CXR generation through a disease-knowledge enhanced diffusion model**
2410.20165v1 by Peng Huang, Bowen Guo, Shuyu Liang, Junhu Fu, Yuanyuan Wang, Yi Guo

Text-To-Image (TTI) generation is significant for controlled and diverse
image generation with broad potential applications. Although current medical
TTI methods have made some progress in report-to-Chest-Xray (CXR) generation,
their generation performance may be limited due to the intrinsic
characteristics of medical data. In this paper, we propose a novel
disease-knowledge enhanced Diffusion-based TTI learning framework, named
Diff-CXR, for medical report-to-CXR generation. First, to minimize the negative
impacts of noisy data on generation, we devise a Latent Noise Filtering
Strategy that gradually learns the general patterns of anomalies and removes
them in the latent space. Then, an Adaptive Vision-Aware Textual Learning
Strategy is designed to learn concise and important report embeddings in a
domain-specific Vision-Language Model, providing textual guidance for
Chest-Xray generation. Finally, by incorporating the general disease knowledge
into the pretrained TTI model via a delicate control adapter, a
disease-knowledge enhanced diffusion model is introduced to achieve realistic
and precise report-to-CXR generation. Experimentally, our Diff-CXR outperforms
previous SOTA medical TTI methods by 33.4\% / 8.0\% and 23.8\% / 56.4\% in the
FID and mAUC score on MIMIC-CXR and IU-Xray, with the lowest computational
complexity at 29.641 GFLOPs. Downstream experiments on three thorax disease
classification benchmarks and one CXR-report generation benchmark demonstrate
that Diff-CXR is effective in improving classical CXR analysis methods.
Notably, models trained on the combination of 1\% real data and synthetic data
can achieve a competitive mAUC score compared to models trained on all data,
presenting promising clinical applications.

摘要：文字轉影像（TTI）生成對於廣泛潛在應用中受控且多樣化的影像生成至關重要。儘管目前的醫療 TTI 方法在報告轉胸部 X 光（CXR）生成方面取得了一些進展，但由於醫療資料的內在特性，其生成效能可能會受到限制。在本文中，我們提出了一個名為 Diff-CXR 的新疾病知識增強擴散式 TTI 學習架構，用於醫療報告轉 CXR 生成。首先，為了最小化雜訊資料對生成的負面影響，我們設計了一個潛在雜訊過濾策略，逐漸學習異常的一般模式並將其從潛在空間中移除。然後，設計了一個自適應視覺感知文字學習策略，以在特定領域的視覺語言模型中學習簡潔且重要的報告嵌入，為胸部 X 光生成提供文字指導。最後，通過一個精巧的控制適配器將一般疾病知識整合到預訓練的 TTI 模型中，引入了一個疾病知識增強擴散模型，以實現逼真且精確的報告轉 CXR 生成。在實驗中，我們的 Diff-CXR 在 MIMIC-CXR 和 IU-Xray 上的 FID 和 mAUC 分數分別比先前的 SOTA 醫療 TTI 方法高出 33.4% / 8.0% 和 23.8% / 56.4%，且運算複雜度最低，為 29.641 GFLOPs。在三個胸腔疾病分類基準和一個 CXR 報告生成基準上的下游實驗證明，Diff-CXR 可有效改善傳統的 CXR 分析方法。值得注意的是，在 1% 真實資料和合成資料的組合上訓練的模型，與在所有資料上訓練的模型相比，可以達到有競爭力的 mAUC 分數，這顯示出有前景的臨床應用。

##### **On-Site Precise Screening of SARS-CoV-2 Systems Using a Channel-Wise Attention-Based PLS-1D-CNN Model with Limited Infrared Signatures**
2410.20132v1 by Wenwen Zhang, Zhouzhuo Tang, Yingmei Feng, Xia Yu, Qi Jie Wang, Zhiping Lin

During the early stages of respiratory virus outbreaks, such as severe acute
respiratory syndrome coronavirus 2 (SARS-CoV-2), the efficient utilize of
limited nasopharyngeal swabs for rapid and accurate screening is crucial for
public health. In this study, we present a methodology that integrates
attenuated total reflection-Fourier transform infrared spectroscopy (ATR-FTIR)
with the adaptive iteratively reweighted penalized least squares (airPLS)
preprocessing algorithm and a channel-wise attention-based partial least
squares one-dimensional convolutional neural network (PLS-1D-CNN) model,
enabling accurate screening of infected individuals within 10 minutes. Two
cohorts of nasopharyngeal swab samples, comprising 126 and 112 samples from
suspected SARS-CoV-2 Omicron variant cases, were collected at Beijing You'an
Hospital for verification. Given that ATR-FTIR spectra are highly sensitive to
variations in experimental conditions, which can affect their quality, we
propose a biomolecular importance (BMI) evaluation method to assess signal
quality across different conditions, validated by comparing BMI with PLS-GBM
and PLS-RF results. For the ATR-FTIR signals in cohort 2, which exhibited a
higher BMI, airPLS was utilized for signal preprocessing, followed by the
application of the channel-wise attention-based PLS-1D-CNN model for screening.
The experimental results demonstrate that our model outperforms recently
reported methods in the field of respiratory virus spectrum detection,
achieving a recognition screening accuracy of 96.48%, a sensitivity of 96.24%,
a specificity of 97.14%, an F1-score of 96.12%, and an AUC of 0.99. It meets
the World Health Organization (WHO) recommended criteria for an acceptable
product: sensitivity of 95.00% or greater and specificity of 97.00% or greater
for testing prior SARS-CoV-2 infection in moderate to high volume scenarios.

摘要：<paragraph>在呼吸道病毒爆發的早期階段，例如嚴重急性呼吸道症候群冠狀病毒 2 (SARS-CoV-2)，有效利用有限的鼻咽拭子進行快速且準確的篩檢對於公共衛生至關重要。在這項研究中，我們提出了一種方法，將衰減全反射傅立葉轉換紅外線光譜 (ATR-FTIR) 與適應性迭代加權懲罰最小平方 (airPLS) 預處理演算法和通道注意力基礎偏最小二乘一維卷積神經網路 (PLS-1D-CNN) 模型整合，可在 10 分鐘內準確篩選受感染者。收集了兩組鼻咽拭子樣本，分別包含來自疑似 SARS-CoV-2 Omicron 變異株病例的 126 個和 112 個樣本，在北京佑安醫院進行驗證。由於 ATR-FTIR 光譜對實驗條件的變化高度敏感，這可能會影響其品質，我們提出了一種生物分子重要性 (BMI) 評估方法來評估不同條件下的訊號品質，並透過將 BMI 與 PLS-GBM 和 PLS-RF 結果進行比較來驗證。對於在第 2 組中表現出較高 BMI 的 ATR-FTIR 訊號，我們利用 airPLS 進行訊號預處理，然後應用基於通道注意力的 PLS-1D-CNN 模型進行篩選。實驗結果表明，我們的模型優於呼吸道病毒光譜檢測領域最近報告的方法，實現了 96.48% 的識別篩選準確率、96.24% 的靈敏度、97.14% 的特異性、96.12% 的 F1 分數和 0.99 的 AUC。它符合世界衛生組織 (WHO) 推薦的可用產品標準：在中高量場景中測試先前 SARS-CoV-2 感染時，靈敏度為 95.00% 或更高，特異性為 97.00% 或更高。</paragraph>

##### **Transforming Precision: A Comparative Analysis of Vision Transformers, CNNs, and Traditional ML for Knee Osteoarthritis Severity Diagnosis**
2410.20062v1 by Tasnim Sakib Apon, Md. Fahim-Ul-Islam, Nafiz Imtiaz Rafin, Joya Akter, Md. Golam Rabiul Alam

Knee osteoarthritis(KO) is a degenerative joint disease that can cause severe
pain and impairment. With increased prevalence, precise diagnosis by medical
imaging analytics is crucial for appropriate illness management. This research
investigates a comparative analysis between traditional machine learning
techniques and new deep learning models for diagnosing KO severity from X-ray
pictures. This study does not introduce new architectural innovations but
rather illuminates the robust applicability and comparative effectiveness of
pre-existing ViT models in a medical imaging context, specifically for KO
severity diagnosis. The insights garnered from this comparative analysis
advocate for the integration of advanced ViT models in clinical diagnostic
workflows, potentially revolutionizing the precision and reliability of KO
assessments. This study does not introduce new architectural innovations but
rather illuminates the robust applicability and comparative effectiveness of
pre-existing ViT models in a medical imaging context, specifically for KO
severity diagnosis. The insights garnered from this comparative analysis
advocate for the integration of advanced ViT models in clinical diagnostic
workflows, potentially revolutionizing the precision & reliability of KO
assessments. The study utilizes an osteoarthritis dataset from the
Osteoarthritis Initiative (OAI) comprising images with 5 severity categories
and uneven class distribution. While classic machine learning models like
GaussianNB and KNN struggle in feature extraction, Convolutional Neural
Networks such as Inception-V3, VGG-19 achieve better accuracy between 55-65% by
learning hierarchical visual patterns. However, Vision Transformer
architectures like Da-VIT, GCViT and MaxViT emerge as indisputable champions,
displaying 66.14% accuracy, 0.703 precision, 0.614 recall, AUC exceeding 0.835
thanks to self-attention processes.

摘要：<paragraph>膝骨關節炎 (KO) 是一種退化性關節疾病，可能導致嚴重疼痛和功能障礙。隨著患病率上升，透過醫學影像分析進行精確診斷對於適當的疾病管理至關重要。本研究探討傳統機器學習技術和新的深度學習模型在從 X 光影像診斷 KO 嚴重程度之間的比較分析。本研究並未提出新的架構創新，而是闡明了預先存在的 ViT 模型在醫學影像情境中的強大適用性和比較效能，特別是針對 KO 嚴重程度診斷。從此比較分析中獲得的見解主張將先進的 ViT 模型整合到臨床診斷工作流程中，這可能會徹底改變 KO 評估的精確度和可靠性。本研究並未提出新的架構創新，而是闡明了預先存在的 ViT 模型在醫學影像情境中的強大適用性和比較效能，特別是針對 KO 嚴重程度診斷。從此比較分析中獲得的見解主張將先進的 ViT 模型整合到臨床診斷工作流程中，這可能會徹底改變 KO 評估的精確度和可靠性。本研究利用了來自骨關節炎倡議組織 (OAI) 的骨關節炎資料集，其中包含 5 個嚴重程度類別和不均勻的類別分佈的影像。雖然像 GaussianNB 和 KNN 等經典機器學習模型在特徵萃取方面遇到了困難，但像 Inception-V3、VGG-19 等卷積神經網路透過學習階層式視覺模式達到了 55-65% 之間的較佳準確度。然而，像 Da-VIT、GCViT 和 MaxViT 等視覺轉換器架構脫穎而出成為無可爭議的佼佼者，由於自注意力程序，它們表現出 66.14% 的準確度、0.703 的精確度、0.614 的召回率、超過 0.835 的 AUC。</paragraph>

##### **AutoMIR: Effective Zero-Shot Medical Information Retrieval without Relevance Labels**
2410.20050v1 by Lei Li, Xiangxu Zhang, Xiao Zhou, Zheng Liu

Medical information retrieval (MIR) is essential for retrieving relevant
medical knowledge from diverse sources, including electronic health records,
scientific literature, and medical databases. However, achieving effective
zero-shot dense retrieval in the medical domain poses substantial challenges
due to the lack of relevance-labeled data. In this paper, we introduce a novel
approach called Self-Learning Hypothetical Document Embeddings (SL-HyDE) to
tackle this issue. SL-HyDE leverages large language models (LLMs) as generators
to generate hypothetical documents based on a given query. These generated
documents encapsulate key medical context, guiding a dense retriever in
identifying the most relevant documents. The self-learning framework
progressively refines both pseudo-document generation and retrieval, utilizing
unlabeled medical corpora without requiring any relevance-labeled data.
Additionally, we present the Chinese Medical Information Retrieval Benchmark
(CMIRB), a comprehensive evaluation framework grounded in real-world medical
scenarios, encompassing five tasks and ten datasets. By benchmarking ten models
on CMIRB, we establish a rigorous standard for evaluating medical information
retrieval systems. Experimental results demonstrate that SL-HyDE significantly
surpasses existing methods in retrieval accuracy while showcasing strong
generalization and scalability across various LLM and retriever configurations.
CMIRB data and evaluation code are publicly available at:
https://github.com/CMIRB-benchmark/CMIRB.

摘要：醫療資訊檢索 (MIR) 對於從電子健康紀錄、科學文獻和醫療資料庫等不同來源檢索相關醫療知識至關重要。然而，由於缺乏相關標籤資料，在醫療領域中實現有效的零次發射密集檢索會帶來重大挑戰。在本文中，我們介紹一種稱為自學習假設文件嵌入 (SL-HyDE) 的新方法來解決此問題。SL-HyDE 利用大型語言模型 (LLM) 作為生成器，根據給定的查詢生成假設文件。這些生成的文檔包含關鍵的醫療背景，指導密集檢索器識別最相關的文件。自學習框架逐步優化偽文檔生成和檢索，利用未標記的醫療語料庫，而無需任何相關標籤資料。此外，我們提出了中文醫療資訊檢索基準 (CMIRB)，這是一個全面的評估框架，基於真實世界的醫療場景，包含五個任務和十個資料集。通過在 CMIRB 上對十個模型進行基準測試，我們建立了評估醫療資訊檢索系統的嚴格標準。實驗結果表明，SL-HyDE 在檢索準確度上顯著優於現有方法，同時在各種 LLM 和檢索器配置中展示了強大的泛化性和可擴充性。CMIRB 資料和評估程式碼可在以下位置公開取得：https://github.com/CMIRB-benchmark/CMIRB。

##### **Off-Policy Selection for Initiating Human-Centric Experimental Design**
2410.20017v1 by Ge Gao, Xi Yang, Qitong Gao, Song Ju, Miroslav Pajic, Min Chi

In human-centric tasks such as healthcare and education, the heterogeneity
among patients and students necessitates personalized treatments and
instructional interventions. While reinforcement learning (RL) has been
utilized in those tasks, off-policy selection (OPS) is pivotal to close the
loop by offline evaluating and selecting policies without online interactions,
yet current OPS methods often overlook the heterogeneity among participants.
Our work is centered on resolving a pivotal challenge in human-centric systems
(HCSs): how to select a policy to deploy when a new participant joining the
cohort, without having access to any prior offline data collected over the
participant? We introduce First-Glance Off-Policy Selection (FPS), a novel
approach that systematically addresses participant heterogeneity through
sub-group segmentation and tailored OPS criteria to each sub-group. By grouping
individuals with similar traits, FPS facilitates personalized policy selection
aligned with unique characteristics of each participant or group of
participants. FPS is evaluated via two important but challenging applications,
intelligent tutoring systems and a healthcare application for sepsis treatment
and intervention. FPS presents significant advancement in enhancing learning
outcomes of students and in-hospital care outcomes.

摘要：在以人为本的任务中，例如医疗保健和教育，患者和学生之间的异质性需要个性化的治疗和教学干预。虽然强化学习 (RL) 已用于这些任务，但非策略选择 (OPS) 对于通过离线评估和选择策略来闭环至关重要，而无需在线交互，但当前的 OPS 方法通常会忽略参与者之间的异质性。我们的工作重点在于解决以人为本系统 (HCS) 中的一个关键挑战：如何在没有访问任何先前离线数据的情况下，为加入队列的新参与者选择要部署的策略？我们引入了 First-Glance 非策略选择 (FPS)，这是一种新颖的方法，通过子组细分和针对每个子组定制的 OPS 标准系统地解决参与者异质性。通过对具有相似特征的个体进行分组，FPS 促进了个性化策略选择，符合每个参与者或参与者组的独特特征。FPS 通过两个重要但具有挑战性的应用进行了评估，即智能辅导系统和脓毒症治疗和干预的医疗保健应用。FPS 在提高学生的学习成果和住院护理成果方面取得了重大进展。

##### **DualMAR: Medical-Augmented Representation from Dual-Expertise Perspectives**
2410.19955v1 by Pengfei Hu, Chang Lu, Fei Wang, Yue Ning

Electronic Health Records (EHR) has revolutionized healthcare data management
and prediction in the field of AI and machine learning. Accurate predictions of
diagnosis and medications significantly mitigate health risks and provide
guidance for preventive care. However, EHR driven models often have limited
scope on understanding medical-domain knowledge and mostly rely on
simple-and-sole ontologies. In addition, due to the missing features and
incomplete disease coverage of EHR, most studies only focus on basic analysis
on conditions and medication. We propose DualMAR, a framework that enhances EHR
prediction tasks through both individual observation data and public knowledge
bases. First, we construct a bi-hierarchical Diagnosis Knowledge Graph (KG)
using verified public clinical ontologies and augment this KG via Large
Language Models (LLMs); Second, we design a new proxy-task learning on lab
results in EHR for pretraining, which further enhance KG representation and
patient embeddings. By retrieving radial and angular coordinates upon polar
space, DualMAR enables accurate predictions based on rich hierarchical and
semantic embeddings from KG. Experiments also demonstrate that DualMAR
outperforms state-of-the-art models, validating its effectiveness in EHR
prediction and KG integration in medical domains.

摘要：電子健康紀錄 (EHR) 已徹底改變了醫療保健資料管理，並預測了人工智慧和機器學習領域。準確預測診斷和藥物可大幅減輕健康風險，並提供預防性照護的指導方針。然而，EHR 驅動的模型在理解醫療領域知識上通常具有局限性，而且大多依賴於簡單且單一的本体。此外，由於 EHR 遺漏了功能且疾病涵蓋不完整，大多數研究僅專注於疾病和藥物的基本分析。我們提出 DualMAR，一個透過個人觀察資料和公共知識庫增強 EHR 預測任務的架構。首先，我們使用經過驗證的公共臨床本体構建一個雙層級診斷知識圖 (KG)，並透過大型語言模型 (LLM) 擴充這個 KG；其次，我們設計一個新的代理任務學習，針對 EHR 中的實驗室結果進行預訓練，進一步增強 KG 表示和患者嵌入。透過擷取極座標空間上的徑向和角向坐標，DualMAR 能夠根據 KG 中豐富的層級和語意嵌入進行準確的預測。實驗也證明 DualMAR 優於最先進的模型，驗證了其在 EHR 預測和醫療領域中 KG 整合的有效性。

##### **The Potential and Value of AI Chatbot in Personalized Cognitive Training**
2410.19733v1 by Zilong Wang, Nan Chen, Luna K. Qiu, Ling Yue, Geli Guo, Yang Ou, Shiqi Jiang, Yuqing Yang, Lili Qiu

In recent years, the rapid aging of the global population has led to an
increase in cognitive disorders, such as Alzheimer's disease, presenting
significant public health challenges. Although no effective treatments
currently exist to reverse Alzheimer's, prevention and early intervention,
including cognitive training, are critical. This report explores the potential
of AI chatbots in enhancing personalized cognitive training. We introduce ReMe,
a web-based framework designed to create AI chatbots that facilitate cognitive
training research, specifically targeting episodic memory tasks derived from
personal life logs. By leveraging large language models, ReMe provides enhanced
user-friendly, interactive, and personalized training experiences. Case studies
demonstrate ReMe's effectiveness in engaging users through life recall and
open-ended language puzzles, highlighting its potential to improve cognitive
training design. Despite promising results, further research is needed to
validate training effectiveness through large-scale studies that include
cognitive ability evaluations. Overall, ReMe offers a promising approach to
personalized cognitive training, utilizing AI capabilities to meet the growing
demand for non-pharmacological interventions in cognitive health, with future
research aiming to expand its applications and efficacy.

摘要：近年来，全球人口快速老龄化，导致阿尔茨海默病等认知障碍症患者数量增加，给公共卫生带来了重大挑战。尽管目前还没有有效的治疗方法可以逆转阿尔茨海默病，但预防和早期干预（包括认知训练）至关重要。本报告探讨了人工智能聊天机器人增强个性化认知训练的潜力。我们介绍了 ReMe，这是一个基于网络的框架，旨在创建人工智能聊天机器人，促进认知训练研究，特别是针对源自个人生活日志的情景记忆任务。通过利用大型语言模型，ReMe 提供了增强型用户友好、互动且个性化的训练体验。案例研究展示了 ReMe 通过生活回忆和开放式语言谜题吸引用户的有效性，突出了它在改善认知训练设计方面的潜力。尽管结果很有希望，但仍需要进一步的研究，通过包括认知能力评估的大规模研究来验证训练的有效性。总体而言，ReMe 为个性化认知训练提供了一种有前景的方法，利用人工智能功能来满足对认知健康中非药物干预措施不断增长的需求，未来的研究旨在扩展其应用和疗效。

##### **A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**
2410.19898v1 by Muath Alsuhaibani, Ali Pourramezan Fard, Jian Sun, Farida Far Poor, Peter S. Pressman, Mohammad H. Mahoor

This review paper explores recent advances in deep learning approaches for
non-invasive cognitive impairment detection. We examine various non-invasive
indicators of cognitive decline, including speech and language, facial, and
motoric mobility. The paper provides an overview of relevant datasets,
feature-extracting techniques, and deep-learning architectures applied to this
domain. We have analyzed the performance of different methods across modalities
and observed that speech and language-based methods generally achieved the
highest detection performance. Studies combining acoustic and linguistic
features tended to outperform those using a single modality. Facial analysis
methods showed promise for visual modalities but were less extensively studied.
Most papers focused on binary classification (impaired vs. non-impaired), with
fewer addressing multi-class or regression tasks. Transfer learning and
pre-trained language models emerged as popular and effective techniques,
especially for linguistic analysis. Despite significant progress, several
challenges remain, including data standardization and accessibility, model
explainability, longitudinal analysis limitations, and clinical adaptation.
Lastly, we propose future research directions, such as investigating
language-agnostic speech analysis methods, developing multi-modal diagnostic
systems, and addressing ethical considerations in AI-assisted healthcare. By
synthesizing current trends and identifying key obstacles, this review aims to
guide further development of deep learning-based cognitive impairment detection
systems to improve early diagnosis and ultimately patient outcomes.

摘要：本篇評論探討了深度學習方法在非侵入式認知功能障礙檢測上的最新進展。我們檢視了各種非侵入式的認知衰退指標，包括語言和語言、面部和運動機能。本文概述了與此領域相關的資料集、特徵提取技術和深度學習架構。我們分析了不同方法在不同方式上的表現，並觀察到基於語言和語言的方法通常能達到最高的檢測表現。結合聲學和語言特徵的研究往往優於使用單一方式的研究。面部分析方法顯示出視覺方式的潛力，但研究較少。大多數論文專注於二元分類（受損與未受損），較少探討多類或回歸任務。遷移學習和預訓練語言模型已成為流行且有效的技術，特別是對於語言分析。儘管取得了重大進展，但仍存在一些挑戰，包括資料標準化和可及性、模型可解釋性、縱向分析限制和臨床適應性。最後，我們提出了未來的研究方向，例如調查與語言無關的語音分析方法、開發多模式診斷系統，以及解決人工智慧輔助醫療保健中的倫理考量。透過綜合目前的趨勢和找出關鍵障礙，本篇評論旨在引導深度學習為基礎的認知功能障礙檢測系統的進一步發展，以改善早期診斷，並最終改善患者的治療結果。

##### **Enhancing Resilience and Scalability in Travel Booking Systems: A Microservices Approach to Fault Tolerance, Load Balancing, and Service Discovery**
2410.19701v1 by Biman Barua, M. Shamim Kaiser

This paper investigates the inclusion of microservices architecture in the
development of scalable and reliable airline reservation systems. Most of the
traditional reservation systems are very rigid and centralized which makes them
prone to bottlenecks and a single point of failure. As such, systems do not
meet the requirements of modern airlines which are dynamic. Microservices offer
better resiliency and scalability because the services do not depend on one
another and can be deployed independently. The approach is grounded on the
Circuit Breaker Pattern to maintain fault tolerance while consuming foreign
resources such as flight APIs and payment systems. This avoided the failure
propagation to the systems by 60% enabling the systems to function under
external failures. Traffic rerouting also bolstered this with a guarantee of
above 99.95% uptime in systems where high availability was demanded. To address
this, load balancing was used, particularly the Round-Robin method which
managed to enhance performance by 35% through the equal distribution of user
requests among the service instances. Health checks, as well as monitoring in
real-time, helped as well with failure management as they helped to contain
failures before the users of the system were affected. The results suggest that
the use of microservices led to a 40% increase in system scalability, a 50%
decrease in downtime and a support for 30% more concurrent users than the use
of monolithic architectures. These findings affirm the capability of
microservices in the development of robust and flexible airline ticket booking
systems that are responsive to change and recover from external system
unavailability.

摘要：<paragraph>本文研究了在可擴展且可靠的航空公司訂位系統開發中納入微服務架構。大多數傳統的訂位系統非常僵化且集中化，這使得它們容易出現瓶頸和單點故障。因此，系統無法滿足動態的現代航空公司的需求。微服務提供了更好的復原力和可擴展性，因為這些服務彼此獨立，且可以獨立部署。此方法以斷路器模式為基礎，以在使用外部資源（例如航班 API 和支付系統）時維持容錯能力。這將故障傳播到系統的機率降低了 60%，使系統能夠在外部故障下運作。流量重新路由也加強了這一點，保證了在要求高可用性的系統中達到 99.95% 以上的正常運行時間。為了解決這個問題，使用了負載平衡，特別是循環方法，透過在服務實例之間平均分配使用者要求，將效能提升了 35%。健康檢查以及即時監控也有助於故障管理，因為它們有助於在系統使用者受到影響之前控制故障。結果表明，使用微服務使系統可擴展性提高了 40%，停機時間減少了 50%，並且比使用單體架構支援多 30% 的並發使用者。這些發現肯定了微服務在開發健壯且靈活的機票訂購系統中的能力，這些系統對變更具有反應能力，並且可以從外部系統不可用中復原。</paragraph>

##### **Deep learning-based identification of patients at increased risk of cancer using routine laboratory markers**
2410.19646v1 by Vivek Singh, Shikha Chaganti, Matthias Siebert, Soumya Rajesh, Andrei Puiu, Raj Gopalan, Jamie Gramz, Dorin Comaniciu, Ali Kamen

Early screening for cancer has proven to improve the survival rate and spare
patients from intensive and costly treatments due to late diagnosis. Cancer
screening in the healthy population involves an initial risk stratification
step to determine the screening method and frequency, primarily to optimize
resource allocation by targeting screening towards individuals who draw most
benefit. For most screening programs, age and clinical risk factors such as
family history are part of the initial risk stratification algorithm. In this
paper, we focus on developing a blood marker-based risk stratification
approach, which could be used to identify patients with elevated cancer risk to
be encouraged for taking a diagnostic test or participate in a screening
program. We demonstrate that the combination of simple, widely available blood
tests, such as complete blood count and complete metabolic panel, could
potentially be used to identify patients at risk for colorectal, liver, and
lung cancers with areas under the ROC curve of 0.76, 0.85, 0.78, respectively.
Furthermore, we hypothesize that such an approach could not only be used as
pre-screening risk assessment for individuals but also as population health
management tool, for example to better interrogate the cancer risk in certain
sub-populations.

摘要：癌症的早期篩檢已被證實可以提高存活率，並讓患者免於因診斷過晚而接受密集且昂貴的治療。健康人群的癌症篩檢包括一個初始風險分層步驟，以確定篩檢方法和頻率，主要是透過針對最能受益的個人進行篩檢來最佳化資源分配。對於大多數篩檢計畫，年齡和臨床風險因子（例如家族史）是初始風險分層演算法的一部分。在本文中，我們專注於開發一種基於血液標記的風險分層方法，可用於識別癌症風險升高的患者，以鼓勵他們進行診斷測試或參與篩檢計畫。我們證明了簡單、廣泛使用的血液檢測（例如全血球計數和完整代謝 panel）的組合，有可能用於識別罹患大腸癌、肝癌和肺癌風險的患者，其 ROC 曲線下的面積分別為 0.76、0.85、0.78。此外，我們假設這種方法不僅可用於個人的篩檢前風險評估，還可用於人口健康管理工具，例如更深入地詢問某些亞群中的癌症風險。

##### **Impact of Leakage on Data Harmonization in Machine Learning Pipelines in Class Imbalance Across Sites**
2410.19643v2 by Nicolás Nieto, Simon B. Eickhoff, Christian Jung, Martin Reuter, Kersten Diers, Malte Kelm, Artur Lichtenberg, Federico Raimondo, Kaustubh R. Patil

Machine learning (ML) models benefit from large datasets. Collecting data in
biomedical domains is costly and challenging, hence, combining datasets has
become a common practice. However, datasets obtained under different conditions
could present undesired site-specific variability. Data harmonization methods
aim to remove site-specific variance while retaining biologically relevant
information. This study evaluates the effectiveness of popularly used
ComBat-based methods for harmonizing data in scenarios where the class balance
is not equal across sites. We find that these methods struggle with data
leakage issues. To overcome this problem, we propose a novel approach
PrettYharmonize, designed to harmonize data by pretending the target labels. We
validate our approach using controlled datasets designed to benchmark the
utility of harmonization. Finally, using real-world MRI and clinical data, we
compare leakage-prone methods with PrettYharmonize and show that it achieves
comparable performance while avoiding data leakage, particularly in
site-target-dependence scenarios.

摘要：機器學習 (ML) 模型受益於大型資料集。在生物醫學領域收集資料既昂貴又具挑戰性，因此，結合資料集已成為一種常見做法。然而，在不同條件下獲得的資料集可能會出現不希望的特定於站點的可變性。資料調和方法旨在消除特定於站點的變異，同時保留生物學相關資訊。本研究評估了在不同站點的類別平衡不均等的情況下，廣泛使用的基於 ComBat 的方法對資料調和的有效性。我們發現這些方法難以解決資料洩漏問題。為了克服這個問題，我們提出了一種新方法 PrettYharmonize，旨在通過假裝目標標籤來調和資料。我們使用旨在評量調和效用的受控資料集來驗證我們的做法。最後，使用真實世界的 MRI 和臨床資料，我們將容易洩漏的方法與 PrettYharmonize 進行比較，並表明它在避免資料洩漏的同時實現了可比的效能，特別是在特定於站點目標的場景中。

##### **Lived Experience Not Found: LLMs Struggle to Align with Experts on Addressing Adverse Drug Reactions from Psychiatric Medication Use**
2410.19155v1 by Mohit Chandra, Siddharth Sriraman, Gaurav Verma, Harneet Singh Khanuja, Jose Suarez Campayo, Zihang Li, Michael L. Birnbaum, Munmun De Choudhury

Adverse Drug Reactions (ADRs) from psychiatric medications are the leading
cause of hospitalizations among mental health patients. With healthcare systems
and online communities facing limitations in resolving ADR-related issues,
Large Language Models (LLMs) have the potential to fill this gap. Despite the
increasing capabilities of LLMs, past research has not explored their
capabilities in detecting ADRs related to psychiatric medications or in
providing effective harm reduction strategies. To address this, we introduce
the Psych-ADR benchmark and the Adverse Drug Reaction Response Assessment
(ADRA) framework to systematically evaluate LLM performance in detecting ADR
expressions and delivering expert-aligned mitigation strategies. Our analyses
show that LLMs struggle with understanding the nuances of ADRs and
differentiating between types of ADRs. While LLMs align with experts in terms
of expressed emotions and tone of the text, their responses are more complex,
harder to read, and only 70.86% aligned with expert strategies. Furthermore,
they provide less actionable advice by a margin of 12.32% on average. Our work
provides a comprehensive benchmark and evaluation framework for assessing LLMs
in strategy-driven tasks within high-risk domains.

摘要：精神科藥物的藥物不良反應 (ADR) 是精神健康患者住院的主要原因。由於醫療保健系統和線上社群在解決 ADR 相關問題上存在限制，大型語言模型 (LLM) 有可能填補這項缺口。儘管 LLM 的功能越來越強大，但過去的研究尚未探討其在檢測與精神科藥物相關的 ADR 或提供有效的減害策略方面的能力。為了解決這個問題，我們引入了 Psych-ADR 基準和藥物不良反應反應評估 (ADRA) 架構，以系統性地評估 LLM 在檢測 ADR 表達和提供專家一致的緩解策略方面的表現。我們的分析顯示，LLM 在理解 ADR 的細微差別和區分不同類型的 ADR 方面有困難。雖然 LLM 在表達的情緒和文字語氣方面與專家一致，但他們的反應更複雜、更難閱讀，而且只有 70.86% 與專家策略一致。此外，他們提供的可操作建議平均減少了 12.32%。我們的研究提供了一個全面的基準和評估架構，用於評估 LLM 在高風險領域中的策略驅動任務。

##### **CAMEL-Bench: A Comprehensive Arabic LMM Benchmark**
2410.18976v1 by Sara Ghaboura, Ahmed Heakl, Omkar Thawakar, Ali Alharthi, Ines Riahi, Abduljalil Saif, Jorma Laaksonen, Fahad S. Khan, Salman Khan, Rao M. Anwer

Recent years have witnessed a significant interest in developing large
multimodal models (LMMs) capable of performing various visual reasoning and
understanding tasks. This has led to the introduction of multiple LMM
benchmarks to evaluate LMMs on different tasks. However, most existing LMM
evaluation benchmarks are predominantly English-centric. In this work, we
develop a comprehensive LMM evaluation benchmark for the Arabic language to
represent a large population of over 400 million speakers. The proposed
benchmark, named CAMEL-Bench, comprises eight diverse domains and 38
sub-domains including, multi-image understanding, complex visual perception,
handwritten document understanding, video understanding, medical imaging, plant
diseases, and remote sensing-based land use understanding to evaluate broad
scenario generalizability. Our CAMEL-Bench comprises around 29,036 questions
that are filtered from a larger pool of samples, where the quality is manually
verified by native speakers to ensure reliable model assessment. We conduct
evaluations of both closed-source, including GPT-4 series, and open-source
LMMs. Our analysis reveals the need for substantial improvement, especially
among the best open-source models, with even the closed-source GPT-4o achieving
an overall score of 62%. Our benchmark and evaluation scripts are open-sourced.

摘要：近年來，開發大型多模態模型 (LMM) 以執行各種視覺推理和理解任務引起了極大的興趣。這導致引入了多個 LMM 基準來評估 LMM 在不同任務上的表現。然而，現有的 LMM 評估基準大多以英語為中心。在這項工作中，我們開發了一個全面的阿拉伯語 LMM 評估基準，以代表超過 4 億人口的龐大群體。提出的基準稱為 CAMEL-Bench，包含八個不同的領域和 38 個子領域，包括多圖像理解、複雜視覺感知、手寫文件理解、視頻理解、醫學影像、植物疾病和基於遙感的土地利用理解，以評估廣泛場景的可概括性。我們的 CAMEL-Bench 包含約 29,036 個問題，這些問題從更大的樣本池中過濾出來，其質量由母語人士手動驗證以確保可靠的模型評估。我們對封閉源碼（包括 GPT-4 系列）和開源 LMM 進行了評估。我們的分析揭示了需要大幅改進，特別是在最好的開源模型中，即使是封閉源碼的 GPT-4o 也只達到了 62% 的總分。我們的基準和評估腳本是開源的。

##### **Deep Insights into Cognitive Decline: A Survey of Leveraging Non-Intrusive Modalities with Deep Learning Techniques**
2410.18972v1 by David Ortiz-Perez, Manuel Benavent-Lledo, Jose Garcia-Rodriguez, David Tomás, M. Flores Vizcaya-Moreno

Cognitive decline is a natural part of aging, often resulting in reduced
cognitive abilities. In some cases, however, this decline is more pronounced,
typically due to disorders such as Alzheimer's disease. Early detection of
anomalous cognitive decline is crucial, as it can facilitate timely
professional intervention. While medical data can help in this detection, it
often involves invasive procedures. An alternative approach is to employ
non-intrusive techniques such as speech or handwriting analysis, which do not
necessarily affect daily activities. This survey reviews the most relevant
methodologies that use deep learning techniques to automate the cognitive
decline estimation task, including audio, text, and visual processing. We
discuss the key features and advantages of each modality and methodology,
including state-of-the-art approaches like Transformer architecture and
foundation models. In addition, we present works that integrate different
modalities to develop multimodal models. We also highlight the most significant
datasets and the quantitative results from studies using these resources. From
this review, several conclusions emerge. In most cases, the textual modality
achieves the best results and is the most relevant for detecting cognitive
decline. Moreover, combining various approaches from individual modalities into
a multimodal model consistently enhances performance across nearly all
scenarios.

摘要：<paragraph>認知能力下降是老化的自然現象，通常會導致認知能力下降。然而，在某些情況下，這種下降會更加明顯，通常是因為阿茲海默症等疾病。及早發現異常的認知能力下降至關重要，因為它可以促進及時的專業干預。雖然醫療數據有助於這種檢測，但它通常涉及侵入性程序。另一種方法是採用非侵入性技術，例如語音或手寫分析，這些技術不一定會影響日常活動。這項調查回顧了使用深度學習技術自動執行認知能力下降估計任務的最相關方法，包括音訊、文字和視覺處理。我們討論了每個模態和方法的主要特徵和優點，包括Transformer架構和基礎模型等最先進的方法。此外，我們展示了整合不同模態以開發多模態模型的作品。我們還重點介紹了最重要的數據集和使用這些資源的研究的定量結果。從這項回顧中，得出了一些結論。在大多數情況下，文本模態取得了最好的結果，並且與檢測認知能力下降最相關。此外，將來自個別模態的各種方法組合到多模態模型中，會持續增強幾乎所有場景的效能。</paragraph>

##### **Demystifying Large Language Models for Medicine: A Primer**
2410.18856v1 by Qiao Jin, Nicholas Wan, Robert Leaman, Shubo Tian, Zhizheng Wang, Yifan Yang, Zifeng Wang, Guangzhi Xiong, Po-Ting Lai, Qingqing Zhu, Benjamin Hou, Maame Sarfo-Gyamfi, Gongbo Zhang, Aidan Gilson, Balu Bhasuran, Zhe He, Aidong Zhang, Jimeng Sun, Chunhua Weng, Ronald M. Summers, Qingyu Chen, Yifan Peng, Zhiyong Lu

Large language models (LLMs) represent a transformative class of AI tools
capable of revolutionizing various aspects of healthcare by generating
human-like responses across diverse contexts and adapting to novel tasks
following human instructions. Their potential application spans a broad range
of medical tasks, such as clinical documentation, matching patients to clinical
trials, and answering medical questions. In this primer paper, we propose an
actionable guideline to help healthcare professionals more efficiently utilize
LLMs in their work, along with a set of best practices. This approach consists
of several main phases, including formulating the task, choosing LLMs, prompt
engineering, fine-tuning, and deployment. We start with the discussion of
critical considerations in identifying healthcare tasks that align with the
core capabilities of LLMs and selecting models based on the selected task and
data, performance requirements, and model interface. We then review the
strategies, such as prompt engineering and fine-tuning, to adapt standard LLMs
to specialized medical tasks. Deployment considerations, including regulatory
compliance, ethical guidelines, and continuous monitoring for fairness and
bias, are also discussed. By providing a structured step-by-step methodology,
this tutorial aims to equip healthcare professionals with the tools necessary
to effectively integrate LLMs into clinical practice, ensuring that these
powerful technologies are applied in a safe, reliable, and impactful manner.

摘要：大型語言模型 (LLM) 代表一種變革性的 AI 工具類別，它能夠透過在各種脈絡中產生類似人類的回應，並根據人類指示調整到新任務，從而革新醫療保健的各個方面。它們的潛在應用範圍涵蓋廣泛的醫療任務，例如臨床文件、將患者與臨床試驗配對，以及回答醫療問題。在此基礎論文中，我們提出了一個可行的指南，以幫助醫療專業人員更有效地在其工作中利用 LLM，並提供了一組最佳實務。此方法包含幾個主要階段，包括制定任務、選擇 LLM、提示工程、微調和部署。我們從討論識別與 LLM 核心功能相符的醫療保健任務，以及根據所選任務和數據、效能需求和模型介面選擇模型的關鍵考量開始。然後，我們檢視策略，例如提示工程和微調，以調整標準 LLM 以符合專業的醫療任務。部署考量，包括法規遵循、道德準則，以及公平性和偏見的持續監控，也已討論過。透過提供結構化的逐步方法，本教學課程旨在為醫療專業人員提供必要的工具，以有效地將 LLM 整合到臨床實務中，確保這些強大的技術能以安全、可靠且有影響力的方式應用。

##### **Health Misinformation in Social Networks: A Survey of IT Approaches**
2410.18670v1 by Vasiliki Papanikou, Panagiotis Papadakos, Theodora Karamanidou, Thanos G. Stavropoulos, Evaggelia Pitoura, Panayiotis Tsaparas

In this paper, we present a comprehensive survey on the pervasive issue of
medical misinformation in social networks from the perspective of information
technology. The survey aims at providing a systematic review of related
research and helping researchers and practitioners navigate through this
fast-changing field. Specifically, we first present manual and automatic
approaches for fact-checking. We then explore fake news detection methods,
using content, propagation features, or source features, as well as mitigation
approaches for countering the spread of misinformation. We also provide a
detailed list of several datasets on health misinformation and of publicly
available tools. We conclude the survey with a discussion on the open
challenges and future research directions in the battle against health
misinformation.

摘要：在本文中，我們從資訊科技的角度，對社群網路中普遍存在的醫療錯誤資訊問題進行全面的調查。該調查旨在提供相關研究的系統性回顧，並幫助研究人員和從業者了解這個瞬息萬變的領域。具體來說，我們首先介紹手動和自動查核事實的方法。然後，我們探討假新聞偵測方法，使用內容、傳播特徵或來源特徵，以及對抗錯誤資訊散布的緩解方法。我們還提供了幾個關於健康錯誤資訊的資料集和公開可用的工具的詳細清單。我們以討論打擊健康錯誤資訊的公開挑戰和未來研究方向，來結束這項調查。

##### **Paved or unpaved? A Deep Learning derived Road Surface Global Dataset from Mapillary Street-View Imagery**
2410.19874v2 by Sukanya Randhawa, Eren Aygun, Guntaj Randhawa, Benjamin Herfort, Sven Lautenbach, Alexander Zipf

We have released an open dataset with global coverage on road surface
characteristics (paved or unpaved) derived utilising 105 million images from
the world's largest crowdsourcing-based street view platform, Mapillary,
leveraging state-of-the-art geospatial AI methods. We propose a hybrid deep
learning approach which combines SWIN-Transformer based road surface prediction
and CLIP-and-DL segmentation based thresholding for filtering of bad quality
images. The road surface prediction results have been matched and integrated
with OpenStreetMap (OSM) road geometries. This study provides global data
insights derived from maps and statistics about spatial distribution of
Mapillary coverage and road pavedness on a continent and countries scale, with
rural and urban distinction. This dataset expands the availability of global
road surface information by over 3 million kilometers, now representing
approximately 36% of the total length of the global road network. Most regions
showed moderate to high paved road coverage (60-80%), but significant gaps were
noted in specific areas of Africa and Asia. Urban areas tend to have
near-complete paved coverage, while rural regions display more variability.
Model validation against OSM surface data achieved strong performance, with F1
scores for paved roads between 91-97% across continents. Taking forward the
work of Mapillary and their contributors and enrichment of OSM road attributes,
our work provides valuable insights for applications in urban planning,
disaster routing, logistics optimisation and addresses various Sustainable
Development Goals (SDGS): especially SDGs 1 (No poverty), 3 (Good health and
well-being), 8 (Decent work and economic growth), 9 (Industry, Innovation and
Infrastructure), 11 (Sustainable cities and communities), 12 (Responsible
consumption and production), and 13 (Climate action).

摘要：<paragraph>我們已發布一個開放式資料集，其全球道路表面特徵（鋪設或未鋪設）的涵蓋範圍，係利用來自全球最大的群眾外包街景平台 Mapillary 的 1.05 億張影像，並運用最先進的地理空間 AI 方法所衍生而來。我們提出了一種混合深度學習方法，結合基於 SWIN-Transformer 的道路表面預測和基於 CLIP 和 DL 分割的閾值化，以過濾品質不佳的影像。道路表面預測結果已與 OpenStreetMap (OSM) 道路幾何形狀進行比對和整合。這項研究提供從地圖和統計資料衍生的全球資料洞察，關於 Mapillary 涵蓋範圍和道路鋪設情況在洲和國家層級的空間分佈，並區分了農村和都市。此資料集將全球道路表面資訊的可用性擴增了 300 多萬公里，現在約占全球道路網路總長度的 36%。大多數地區顯示出中等至高鋪設道路涵蓋率（60-80%），但非洲和亞洲的特定區域存在顯著差距。都市地區傾向於擁有接近完整的鋪設涵蓋率，而農村地區則展現出更多變異性。針對 OSM 表面資料的模型驗證達到了強勁的效能，各洲鋪設道路的 F1 分數介於 91-97% 之間。延續 Mapillary 及其貢獻者和豐富 OSM 道路屬性的工作，我們的研究為都市規劃、災害路線、後勤最佳化等應用程式提供了寶貴的洞察，並解決了各種永續發展目標 (SDG)：特別是 SDG 1（消除貧窮）、3（良好健康和福祉）、8（體面工作和經濟成長）、9（產業、創新和基礎建設）、11（永續城市和社區）、12（負責任的消費和生產），以及 13（氣候行動）。</paragraph>

##### **Beyond Multiple-Choice Accuracy: Real-World Challenges of Implementing Large Language Models in Healthcare**
2410.18460v1 by Yifan Yang, Qiao Jin, Qingqing Zhu, Zhizheng Wang, Francisco Erramuspe Álvarez, Nicholas Wan, Benjamin Hou, Zhiyong Lu

Large Language Models (LLMs) have gained significant attention in the medical
domain for their human-level capabilities, leading to increased efforts to
explore their potential in various healthcare applications. However, despite
such a promising future, there are multiple challenges and obstacles that
remain for their real-world uses in practical settings. This work discusses key
challenges for LLMs in medical applications from four unique aspects:
operational vulnerabilities, ethical and social considerations, performance and
assessment difficulties, and legal and regulatory compliance. Addressing these
challenges is crucial for leveraging LLMs to their full potential and ensuring
their responsible integration into healthcare.

摘要：大型語言模型 (LLM) 在醫療領域中獲得了顯著的關注，因為它們具有人類等級的能力，這導致人們加大了探索它們在各種醫療保健應用中的潛力的力度。然而，儘管未來充滿希望，但它們在實際環境中的實際用途仍然存在多重挑戰和障礙。這項工作從四個獨特方面討論了 LLM 在醫療應用中的關鍵挑戰：運營漏洞、倫理和社會考量、性能和評估難題，以及法律和法規遵循。解決這些挑戰對於充分利用 LLM 的潛力並確保它們負責任地整合到醫療保健中至關重要。

##### **Multi-Stage Airway Segmentation in Lung CT Based on Multi-scale Nested Residual UNet**
2410.18456v1 by Bingyu Yang, Huai Liao, Xinyan Huang, Qingyao Tian, Jinlin Wu, Jingdi Hu, Hongbin Liu

Accurate and complete segmentation of airways in chest CT images is essential
for the quantitative assessment of lung diseases and the facilitation of
pulmonary interventional procedures. Although deep learning has led to
significant advancements in medical image segmentation, maintaining airway
continuity remains particularly challenging. This difficulty arises primarily
from the small and dispersed nature of airway structures, as well as class
imbalance in CT scans. To address these challenges, we designed a Multi-scale
Nested Residual U-Net (MNR-UNet), incorporating multi-scale inputs and Residual
Multi-scale Modules (RMM) into a nested residual framework to enhance
information flow, effectively capturing the intricate details of small airways
and mitigating gradient vanishing. Building on this, we developed a three-stage
segmentation pipeline to optimize the training of the MNR-UNet. The first two
stages prioritize high accuracy and sensitivity, while the third stage focuses
on repairing airway breakages to balance topological completeness and
correctness. To further address class imbalance, we introduced a weighted
Breakage-Aware Loss (wBAL) to heighten focus on challenging samples, penalizing
breakages and thereby extending the length of the airway tree. Additionally, we
proposed a hierarchical evaluation framework to offer more clinically
meaningful analysis. Validation on both in-house and public datasets
demonstrates that our approach achieves superior performance in detecting more
accurate airway voxels and identifying additional branches, significantly
improving airway topological completeness. The code will be released publicly
following the publication of the paper.

摘要：胸部 CT 影像中準確而完整的氣道分割對於肺部疾病的定量評估和促進肺部介入性程序至關重要。儘管深度學習已在醫學影像分割領域取得顯著進展，但維持氣道連續性仍然特別具有挑戰性。這種困難主要來自於氣道結構的細小和分散性質，以及 CT 掃描中的類別不平衡。為了應對這些挑戰，我們設計了一個多尺度巢狀殘差 U-Net（MNR-UNet），將多尺度輸入和殘差多尺度模組（RMM）整合到一個巢狀殘差框架中，以增強資訊流動，有效捕捉小氣道的複雜細節並減輕梯度消失。在此基礎上，我們開發了一個三階段分割管道，以最佳化 MNR-UNet 的訓練。前兩個階段優先考慮高準確度和敏感度，而第三階段則專注於修復氣道斷裂，以平衡拓撲完整性和正確性。為了進一步解決類別不平衡的問題，我們引入了一個加權斷裂感知損失（wBAL）來提高對具有挑戰性樣本的關注，懲罰斷裂，從而延長氣道樹的長度。此外，我們提出了一個分層評估框架，以提供更具臨床意義的分析。在內部和公共數據集上的驗證表明，我們的做法在檢測更準確的氣道體素和識別額外分支方面取得了卓越的效能，顯著提高了氣道拓撲完整性。該程式碼將在論文發表後公開發布。

##### **E2E-Swin-Unet++: An Enhanced End-to-End Swin-Unet Architecture With Dual Decoders For PTMC Segmentation**
2410.18239v1 by Maryam Dialameh, Hossein Rajabzadeh, Moslem Sadeghi-Goughari, Jung Suk Sim, Hyock Ju Kwon

Efficiently managing papillary thyroid microcarcinoma (PTMC) while minimizing
patient discomfort poses a significant clinical challenge. Radiofrequency
ablation (RFA) offers a less invasive alternative to surgery and radiation
therapy for PTMC treatment, characterized by shorter recovery times and reduced
pain. As an image-guided procedure, RFA generates localized heat by delivering
high-frequency electrical currents through electrodes to the targeted area
under ultrasound imaging guidance. However, the precision and skill required by
operators for accurate guidance using current ultrasound B-mode imaging
technologies remain significant challenges. To address these challenges, we
develop a novel AI segmentation model, E2E-Swin-Unet++. This model enhances
ultrasound B-mode imaging by enabling real-time identification and segmentation
of PTMC tumors and monitoring of the region of interest for precise targeting
during treatment. E2E-Swin- Unet++ is an advanced end-to-end extension of the
Swin-Unet architecture, incorporating thyroid region information to minimize
the risk of false PTMC segmentation while providing fast inference
capabilities. Experimental results on a real clinical RFA dataset demonstrate
the superior performance of E2E-Swin-Unet++ compared to related models. Our
proposed solution significantly improves the precision and control of RFA
ablation treatment by enabling real-time identification and segmentation of
PTMC margins during the procedure.

摘要：在最大程度降低患者不适感的同时有效管理乳头状甲状腺微小癌 (PTMC) 对临床提出了重大挑战。射频消融术 (RFA) 为 PTMC 治疗提供了一种创伤更小的替代手术和放射治疗的方法，其特点是恢复时间更短且疼痛感更低。作为一种图像引导手术，RFA 通过在超声成像引导下通过电极向目标区域输送高频电流来产生局部热量。然而，操作者使用当前超声 B 模式成像技术进行精确引导所需的精确度和技能仍然是重大挑战。为了应对这些挑战，我们开发了一种新的人工智能分割模型 E2E-Swin-Unet++。该模型通过实现 PTMC 肿瘤的实时识别和分割以及在治疗期间监测感兴趣区域以进行精确靶向来增强超声 B 模式成像。E2E-Swin- Unet++ 是 Swin-Unet 架构的高级端到端扩展，它结合了甲状腺区域信息以最大程度地降低错误分割 PTMC 的风险，同时提供快速的推理能力。在真实临床 RFA 数据集上的实验结果证明了 E2E-Swin-Unet++ 与相关模型相比具有卓越的性能。我们提出的解决方案通过在手术期间实现 PTMC 边缘的实时识别和分割，显著提高了 RFA 消融治疗的精确度和控制力。

##### **Leveraging Skills from Unlabeled Prior Data for Efficient Online Exploration**
2410.18076v1 by Max Wilcoxson, Qiyang Li, Kevin Frans, Sergey Levine

Unsupervised pretraining has been transformative in many supervised domains.
However, applying such ideas to reinforcement learning (RL) presents a unique
challenge in that fine-tuning does not involve mimicking task-specific data,
but rather exploring and locating the solution through iterative
self-improvement. In this work, we study how unlabeled prior trajectory data
can be leveraged to learn efficient exploration strategies. While prior data
can be used to pretrain a set of low-level skills, or as additional off-policy
data for online RL, it has been unclear how to combine these ideas effectively
for online exploration. Our method SUPE (Skills from Unlabeled Prior data for
Exploration) demonstrates that a careful combination of these ideas compounds
their benefits. Our method first extracts low-level skills using a variational
autoencoder (VAE), and then pseudo-relabels unlabeled trajectories using an
optimistic reward model, transforming prior data into high-level, task-relevant
examples. Finally, SUPE uses these transformed examples as additional
off-policy data for online RL to learn a high-level policy that composes
pretrained low-level skills to explore efficiently. We empirically show that
SUPE reliably outperforms prior strategies, successfully solving a suite of
long-horizon, sparse-reward tasks. Code: https://github.com/rail-berkeley/supe.

摘要：無監督預訓練在許多監督領域中具有變革性。
然而，將此類想法應用於強化學習 (RL) 會帶來一個獨特的挑戰，因為微調不涉及模仿特定於任務的資料，
而是透過反覆自我提升來探索和找到解決方案。在這項工作中，我們研究如何利用未標籤的先前軌跡資料
來學習有效的探索策略。雖然先前資料可用於預訓練一組低階技能，或作為線上 RL 的其他離線策略資料，
但如何有效結合這些想法以進行線上探索一直不清楚。我們的 SUPE 方法（用於探索的未標籤先前資料中的技能）
證明了這些想法的謹慎結合會產生複合效益。我們的做法首先使用變異自動編碼器 (VAE) 提取低階技能，
然後使用樂觀獎勵模型對未標籤的軌跡進行偽重新標籤，將先前資料轉換為高階、與任務相關的範例。
最後，SUPE 將這些轉換後的範例用作線上 RL 的其他離線策略資料，以學習一個高階策略，
該策略組成預訓練的低階技能以有效探索。我們透過經驗證明，SUPE 可靠地優於先前的策略，
成功解決了一系列長時程、稀疏獎勵任務。程式碼：https://github.com/rail-berkeley/supe。

##### **Explaining Bayesian Networks in Natural Language using Factor Arguments. Evaluation in the medical domain**
2410.18060v1 by Jaime Sevilla, Nikolay Babakov, Ehud Reiter, Alberto Bugarin

In this paper, we propose a model for building natural language explanations
for Bayesian Network Reasoning in terms of factor arguments, which are
argumentation graphs of flowing evidence, relating the observed evidence to a
target variable we want to learn about. We introduce the notion of factor
argument independence to address the outstanding question of defining when
arguments should be presented jointly or separately and present an algorithm
that, starting from the evidence nodes and a target node, produces a list of
all independent factor arguments ordered by their strength. Finally, we
implemented a scheme to build natural language explanations of Bayesian
Reasoning using this approach. Our proposal has been validated in the medical
domain through a human-driven evaluation study where we compare the Bayesian
Network Reasoning explanations obtained using factor arguments with an
alternative explanation method. Evaluation results indicate that our proposed
explanation approach is deemed by users as significantly more useful for
understanding Bayesian Network Reasoning than another existing explanation
method it is compared to.

摘要：<paragraph>在本文中，我們提出了一個模型，用於建構貝氏網路推理的自然語言解釋，以因子論證為基礎，它們是流動證據的論證圖，將觀察到的證據與我們想要了解的目標變數聯繫起來。我們引入了因子論證獨立性的概念，以解決定義何時應將論證聯合或單獨呈現的未決問題，並提出了一種演算法，從證據節點和目標節點開始，產生一個按強度排序的所有獨立因子論證清單。最後，我們實作了一個方案，使用這種方法建構貝氏推理的自然語言解釋。我們的提案已在醫學領域中通過人為驅動的評估研究得到驗證，在該研究中，我們將使用因子論證獲得的貝氏網路推理解釋與另一種解釋方法進行比較。評估結果表明，與另一種現有的解釋方法相比，我們的提議解釋方法被使用者視為顯著更有助於理解貝氏網路推理。</paragraph>

##### **AI driven health recommender**
2410.17991v1 by K. Vignesh, B. Pranavi, Ch. Sreenidhi

As AI emerged as highest valued technology, We used that to create a web
application that makes a patient work easier .It detects the disease name based
on the symptoms given by the patient and recommends medication for respective
disease, precautions to take, diet to follow and workouts to do, so the disease
can be minimized. The web application is made with clean and Realtime data by
using Machine learning as root. We used flask to create a user-friendly
platform.

摘要：隨著 AI 成為最具價值的技術，我們利用它來建立一個讓患者更輕鬆的網路應用程式。它根據患者提供的症狀來偵測疾病名稱，並針對相關疾病推薦藥物、預防措施、飲食建議和鍛鍊方式，以將疾病降到最低。這個網路應用程式是使用機器學習為基礎，以乾淨且即時的資料建立。我們使用 Flask 來建立一個使用者友善的平台。

##### **MCUBERT: Memory-Efficient BERT Inference on Commodity Microcontrollers**
2410.17957v1 by Zebin Yang, Renze Chen, Taiqiang Wu, Ngai Wong, Yun Liang, Runsheng Wang, Ru Huang, Meng Li

In this paper, we propose MCUBERT to enable language models like BERT on tiny
microcontroller units (MCUs) through network and scheduling co-optimization. We
observe the embedding table contributes to the major storage bottleneck for
tiny BERT models. Hence, at the network level, we propose an MCU-aware
two-stage neural architecture search algorithm based on clustered low-rank
approximation for embedding compression. To reduce the inference memory
requirements, we further propose a novel fine-grained MCU-friendly scheduling
strategy. Through careful computation tiling and re-ordering as well as kernel
design, we drastically increase the input sequence lengths supported on MCUs
without any latency or accuracy penalty. MCUBERT reduces the parameter size of
BERT-tiny and BERT-mini by 5.7$\times$ and 3.0$\times$ and the execution memory
by 3.5$\times$ and 4.3$\times$, respectively. MCUBERT also achieves 1.5$\times$
latency reduction. For the first time, MCUBERT enables lightweight BERT models
on commodity MCUs and processing more than 512 tokens with less than 256KB of
memory.

摘要：在本文中，我們提出 MCUBERT，透過網路和排程共同最佳化，在微型微控制器單元 (MCU) 上啟用類似 BERT 的語言模型。我們觀察到嵌入式表格對微型 BERT 模型的主要儲存瓶頸有所貢獻。因此，在網路層級，我們提出一個基於分群低秩近似的 MCU 感知兩階段神經架構搜尋演算法，用於嵌入式壓縮。為了減少推論記憶體需求，我們進一步提出一個新穎的細粒度 MCU 友善排程策略。透過仔細的運算分割和重新排序以及核心設計，我們大幅增加 MCU 上支援的輸入序列長度，而不會有任何延遲或準確度損失。MCUBERT 將 BERT-tiny 和 BERT-mini 的參數大小分別減少了 5.7 倍和 3.0 倍，執行記憶體分別減少了 3.5 倍和 4.3 倍。MCUBERT 也達到了 1.5 倍的延遲減少。MCUBERT 首次在商品 MCU 上啟用輕量級 BERT 模型，並以小於 256KB 的記憶體處理超過 512 個符號。

##### **Addressing Asynchronicity in Clinical Multimodal Fusion via Individualized Chest X-ray Generation**
2410.17918v1 by Wenfang Yao, Chen Liu, Kejing Yin, William K. Cheung, Jing Qin

Integrating multi-modal clinical data, such as electronic health records
(EHR) and chest X-ray images (CXR), is particularly beneficial for clinical
prediction tasks. However, in a temporal setting, multi-modal data are often
inherently asynchronous. EHR can be continuously collected but CXR is generally
taken with a much longer interval due to its high cost and radiation dose. When
clinical prediction is needed, the last available CXR image might have been
outdated, leading to suboptimal predictions. To address this challenge, we
propose DDL-CXR, a method that dynamically generates an up-to-date latent
representation of the individualized CXR images. Our approach leverages latent
diffusion models for patient-specific generation strategically conditioned on a
previous CXR image and EHR time series, providing information regarding
anatomical structures and disease progressions, respectively. In this way, the
interaction across modalities could be better captured by the latent CXR
generation process, ultimately improving the prediction performance.
Experiments using MIMIC datasets show that the proposed model could effectively
address asynchronicity in multimodal fusion and consistently outperform
existing methods.

摘要：整合多模式臨床數據，例如電子健康紀錄 (EHR) 和胸部 X 光影像 (CXR)，對於臨床預測任務特別有益。然而，在時間設定中，多模式數據通常本質上是異步的。EHR 可以持續收集，但 CXR 通常由於其高成本和輻射劑量而以更長的間隔進行拍攝。當需要臨床預測時，最後一張可用的 CXR 影像可能已過時，導致預測不佳。為了應對這一挑戰，我們提出了 DDL-CXR，這是一種動態生成個性化 CXR 影像的最新潛在表示的方法。我們的做法利用潛在擴散模型進行特定於患者的生成，並根據先前的 CXR 影像和 EHR 時間序列進行策略性約束，分別提供有關解剖結構和疾病進展的信息。這樣，潛在 CXR 生成過程可以更好地捕捉跨模式的交互，最終提高預測性能。使用 MIMIC 數據集進行的實驗表明，所提出的模型可以有效地解決多模式融合中的異步性，並始終優於現有方法。

