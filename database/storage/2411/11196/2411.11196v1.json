{"2411.11196": {"publish_time": "2024-11-17", "title": "PickScan: Object discovery and reconstruction from handheld interactions", "paper_summary": "Reconstructing compositional 3D representations of scenes, where each object\nis represented with its own 3D model, is a highly desirable capability in\nrobotics and augmented reality. However, most existing methods rely heavily on\nstrong appearance priors for object discovery, therefore only working on those\nclasses of objects on which the method has been trained, or do not allow for\nobject manipulation, which is necessary to scan objects fully and to guide\nobject discovery in challenging scenarios. We address these limitations with a\nnovel interaction-guided and class-agnostic method based on object\ndisplacements that allows a user to move around a scene with an RGB-D camera,\nhold up objects, and finally outputs one 3D model per held-up object. Our main\ncontribution to this end is a novel approach to detecting user-object\ninteractions and extracting the masks of manipulated objects. On a\ncustom-captured dataset, our pipeline discovers manipulated objects with 78.3%\nprecision at 100% recall and reconstructs them with a mean chamfer distance of\n0.90cm. Compared to Co-Fusion, the only comparable interaction-based and\nclass-agnostic baseline, this corresponds to a reduction in chamfer distance of\n73% while detecting 99% fewer false positives.", "paper_summary_zh": "\u91cd\u5efa\u5834\u666f\u7684\u5408\u6210 3D \u8868\u793a\uff0c\u5176\u4e2d\u6bcf\u500b\u7269\u4ef6\u90fd\u7528\u5176\u81ea\u5df1\u7684 3D \u6a21\u578b\u8868\u793a\uff0c\u5728\u6a5f\u5668\u4eba\u548c\u64f4\u589e\u5be6\u5883\u4e2d\u662f\u4e00\u7a2e\u975e\u5e38\u7406\u60f3\u7684\u80fd\u529b\u3002\u7136\u800c\uff0c\u5927\u591a\u6578\u73fe\u6709\u65b9\u6cd5\u904e\u5ea6\u4f9d\u8cf4\u7269\u4ef6\u767c\u73fe\u7684\u5f37\u5916\u89c0\u5148\u9a57\uff0c\u56e0\u6b64\u53ea\u9069\u7528\u65bc\u65b9\u6cd5\u5df2\u53d7\u904e\u8a13\u7df4\u7684\u90a3\u4e9b\u985e\u5225\u7684\u7269\u4ef6\uff0c\u6216\u8005\u4e0d\u5141\u8a31\u7269\u4ef6\u64cd\u4f5c\uff0c\u9019\u5c0d\u65bc\u5b8c\u6574\u6383\u63cf\u7269\u4ef6\u548c\u5728\u5177\u6709\u6311\u6230\u6027\u7684\u5834\u666f\u4e2d\u5f15\u5c0e\u7269\u4ef6\u767c\u73fe\u662f\u5fc5\u8981\u7684\u3002\u6211\u5011\u900f\u904e\u4e00\u7a2e\u57fa\u65bc\u7269\u4ef6\u4f4d\u79fb\u7684\u65b0\u7a4e\u4e92\u52d5\u5f15\u5c0e\u4e14\u8207\u985e\u5225\u7121\u95dc\u7684\u65b9\u6cd5\u4f86\u89e3\u6c7a\u9019\u4e9b\u9650\u5236\uff0c\u8a72\u65b9\u6cd5\u5141\u8a31\u4f7f\u7528\u8005\u4f7f\u7528 RGB-D \u76f8\u6a5f\u5728\u5834\u666f\u4e2d\u79fb\u52d5\u3001\u62ff\u8457\u7269\u4ef6\uff0c\u6700\u5f8c\u70ba\u6bcf\u500b\u62ff\u8457\u7684\u7269\u4ef6\u8f38\u51fa\u4e00\u500b 3D \u6a21\u578b\u3002\u6211\u5011\u5c0d\u6b64\u76ee\u7684\u7684\u4e3b\u8981\u8ca2\u737b\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684\u65b9\u6cd5\uff0c\u7528\u65bc\u5075\u6e2c\u4f7f\u7528\u8005\u7269\u4ef6\u4e92\u52d5\u4e26\u63d0\u53d6\u88ab\u64cd\u4f5c\u7269\u4ef6\u7684\u906e\u7f69\u3002\u5728\u81ea\u8a02\u64f7\u53d6\u7684\u8cc7\u6599\u96c6\u4e0a\uff0c\u6211\u5011\u7684\u7ba1\u7dda\u4ee5 100% \u53ec\u56de\u7387\u767c\u73fe\u4e86 78.3% \u7cbe\u78ba\u5ea6\u7684\u88ab\u64cd\u4f5c\u7269\u4ef6\uff0c\u4e26\u4ee5 0.90 \u516c\u5206\u7684\u5e73\u5747\u9322\u5f17\u8ddd\u96e2\u91cd\u5efa\u5b83\u5011\u3002\u8207 Co-Fusion \u76f8\u6bd4\uff0c\u9019\u662f\u552f\u4e00\u53ef\u6bd4\u8f03\u7684\u57fa\u65bc\u4e92\u52d5\u4e14\u8207\u985e\u5225\u7121\u95dc\u7684\u57fa\u6e96\uff0c\u9019\u76f8\u7576\u65bc\u9322\u5f17\u8ddd\u96e2\u6e1b\u5c11\u4e86 73%\uff0c\u540c\u6642\u5075\u6e2c\u5230\u5c11 99% \u7684\u8aa4\u5831\u3002", "author": "Vincent van der Brugge et.al.", "authors": "Vincent van der Brugge, Marc Pollefeys, Joshua B. Tenenbaum, Ayush Tewari, Krishna Murthy Jatavallabhula", "id": "2411.11196v1", "paper_url": "http://arxiv.org/abs/2411.11196v1", "repo": "null"}}