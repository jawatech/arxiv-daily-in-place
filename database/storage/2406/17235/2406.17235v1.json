{"2406.17235": {"publish_time": "2024-06-25", "title": "Task-Agnostic Federated Learning", "paper_summary": "In the realm of medical imaging, leveraging large-scale datasets from various\ninstitutions is crucial for developing precise deep learning models, yet\nprivacy concerns frequently impede data sharing. federated learning (FL)\nemerges as a prominent solution for preserving privacy while facilitating\ncollaborative learning. However, its application in real-world scenarios faces\nseveral obstacles, such as task & data heterogeneity, label scarcity,\nnon-identically distributed (non-IID) data, computational vaiation, etc. In\nreal-world, medical institutions may not want to disclose their tasks to FL\nserver and generalization challenge of out-of-network institutions with un-seen\ntask want to join the on-going federated system. This study address\ntask-agnostic and generalization problem on un-seen tasks by adapting\nself-supervised FL framework. Utilizing Vision Transformer (ViT) as consensus\nfeature encoder for self-supervised pre-training, no initial labels required,\nthe framework enabling effective representation learning across diverse\ndatasets and tasks. Our extensive evaluations, using various real-world non-IID\nmedical imaging datasets, validate our approach's efficacy, retaining 90\\% of\nF1 accuracy with only 5\\% of the training data typically required for\ncentralized approaches and exhibiting superior adaptability to\nout-of-distribution task. The result indicate that federated learning\narchitecture can be a potential approach toward multi-task foundation modeling.", "paper_summary_zh": "\u5728\u533b\u5b66\u5f71\u50cf\u9886\u57df\uff0c\u5229\u7528\u6765\u81ea\u4e0d\u540c\u673a\u6784\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\u5bf9\u4e8e\u5f00\u53d1\u7cbe\u786e\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u9690\u79c1\u95ee\u9898\u7ecf\u5e38\u963b\u788d\u6570\u636e\u5171\u4eab\u3002\u8054\u90a6\u5b66\u4e60 (FL) \u4f5c\u4e3a\u4e00\u79cd\u65e2\u80fd\u4fdd\u62a4\u9690\u79c1\u53c8\u80fd\u4fc3\u8fdb\u534f\u4f5c\u5b66\u4e60\u7684\u7a81\u51fa\u89e3\u51b3\u65b9\u6848\u800c\u51fa\u73b0\u3002\u7136\u800c\uff0c\u5176\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u5e94\u7528\u9762\u4e34\u7740\u4e00\u4e9b\u969c\u788d\uff0c\u4f8b\u5982\u4efb\u52a1\u548c\u6570\u636e\u5f02\u6784\u6027\u3001\u6807\u7b7e\u7a00\u7f3a\u6027\u3001\u975e\u540c\u5206\u5e03\uff08\u975e IID\uff09\u6570\u636e\u3001\u8ba1\u7b97\u53d8\u5f02\u7b49\u3002\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\uff0c\u533b\u7597\u673a\u6784\u53ef\u80fd\u4e0d\u60f3\u5411 FL \u670d\u52a1\u5668\u900f\u9732\u5176\u4efb\u52a1\uff0c\u5e76\u4e14\u7f51\u7edc\u5916\u673a\u6784\u5728\u9047\u5230\u672a\u89c1\u4efb\u52a1\u65f6\u60f3\u8981\u52a0\u5165\u6b63\u5728\u8fdb\u884c\u7684\u8054\u90a6\u7cfb\u7edf\u7684\u6cdb\u5316\u6311\u6218\u3002\u672c\u7814\u7a76\u901a\u8fc7\u91c7\u7528\u81ea\u76d1\u7763 FL \u6846\u67b6\u6765\u89e3\u51b3\u4e0e\u4efb\u52a1\u65e0\u5173\u548c\u672a\u89c1\u4efb\u52a1\u7684\u6cdb\u5316\u95ee\u9898\u3002\u5229\u7528\u89c6\u89c9 Transformer (ViT) \u4f5c\u4e3a\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u7684\u5171\u8bc6\u7279\u5f81\u7f16\u7801\u5668\uff0c\u65e0\u9700\u521d\u59cb\u6807\u7b7e\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u5728\u4e0d\u540c\u7684\u6570\u636e\u96c6\u548c\u4efb\u52a1\u4e2d\u8fdb\u884c\u6709\u6548\u7684\u8868\u793a\u5b66\u4e60\u3002\u6211\u4eec\u4f7f\u7528\u5404\u79cd\u73b0\u5b9e\u4e16\u754c\u975e IID \u533b\u5b66\u5f71\u50cf\u6570\u636e\u96c6\u8fdb\u884c\u7684\u5e7f\u6cdb\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u6211\u4eec\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4ec5\u4f7f\u7528\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u901a\u5e38\u6240\u9700\u7684 5% \u7684\u8bad\u7ec3\u6570\u636e\u5c31\u4fdd\u7559\u4e86 90% \u7684 F1 \u51c6\u786e\u5ea6\uff0c\u5e76\u4e14\u8868\u73b0\u51fa\u5bf9\u5206\u5e03\u5916\u4efb\u52a1\u7684\u5353\u8d8a\u9002\u5e94\u6027\u3002\u7ed3\u679c\u8868\u660e\uff0c\u8054\u90a6\u5b66\u4e60\u67b6\u6784\u53ef\u4ee5\u6210\u4e3a\u591a\u4efb\u52a1\u57fa\u7840\u5efa\u6a21\u7684\u6f5c\u5728\u65b9\u6cd5\u3002", "author": "Zhengtao Yao et.al.", "authors": "Zhengtao Yao, Hong Nguyen, Ajitesh Srivastava, Jose Luis Ambite", "id": "2406.17235v1", "paper_url": "http://arxiv.org/abs/2406.17235v1", "repo": "null"}}