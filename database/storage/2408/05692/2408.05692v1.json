{"2408.05692": {"publish_time": "2024-08-11", "title": "A Novel Momentum-Based Deep Learning Techniques for Medical Image Classification and Segmentation", "paper_summary": "Accurately segmenting different organs from medical images is a critical\nprerequisite for computer-assisted diagnosis and intervention planning. This\nstudy proposes a deep learning-based approach for segmenting various organs\nfrom CT and MRI scans and classifying diseases. Our study introduces a novel\ntechnique integrating momentum within residual blocks for enhanced training\ndynamics in medical image analysis. We applied our method in two distinct\ntasks: segmenting liver, lung, & colon data and classifying abdominal pelvic CT\nand MRI scans. The proposed approach has shown promising results, outperforming\nstate-of-the-art methods on publicly available benchmarking datasets. For\ninstance, in the lung segmentation dataset, our approach yielded significant\nenhancements over the TransNetR model, including a 5.72% increase in dice\nscore, a 5.04% improvement in mean Intersection over Union (mIoU), an 8.02%\nimprovement in recall, and a 4.42% improvement in precision. Hence,\nincorporating momentum led to state-of-the-art performance in both segmentation\nand classification tasks, representing a significant advancement in the field\nof medical imaging.", "paper_summary_zh": "\u6e96\u78ba\u5730\u5f9e\u91ab\u7642\u5f71\u50cf\u4e2d\u5206\u5272\u51fa\u4e0d\u540c\u7684\u5668\u5b98\uff0c\u662f\u96fb\u8166\u8f14\u52a9\u8a3a\u65b7\u548c\u4ecb\u5165\u898f\u5283\u7684\u95dc\u9375\u5148\u6c7a\u689d\u4ef6\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u7a2e\u57fa\u65bc\u6df1\u5ea6\u5b78\u7fd2\u7684\u65b9\u6cd5\uff0c\u7528\u65bc\u5206\u5272 CT \u548c MRI \u6383\u63cf\u4e2d\u7684\u5404\u7a2e\u5668\u5b98\u4e26\u5c0d\u75be\u75c5\u9032\u884c\u5206\u985e\u3002\u6211\u5011\u7684\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u7a2e\u65b0\u6280\u8853\uff0c\u5c07\u52d5\u91cf\u6574\u5408\u5230\u6b98\u5dee\u584a\u4e2d\uff0c\u4ee5\u589e\u5f37\u91ab\u7642\u5f71\u50cf\u5206\u6790\u4e2d\u7684\u8a13\u7df4\u52d5\u614b\u3002\u6211\u5011\u5c07\u65b9\u6cd5\u61c9\u7528\u65bc\u5169\u500b\u4e0d\u540c\u7684\u4efb\u52d9\uff1a\u5206\u5272\u809d\u81df\u3001\u80ba\u81df\u548c\u7d50\u8178\u8cc7\u6599\uff0c\u4ee5\u53ca\u5c0d\u8179\u90e8\u9aa8\u76c6 CT \u548c MRI \u6383\u63cf\u9032\u884c\u5206\u985e\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5df2\u986f\u793a\u51fa\u6709\u5e0c\u671b\u7684\u7d50\u679c\uff0c\u5728\u516c\u958b\u7684\u57fa\u6e96\u8cc7\u6599\u96c6\u4e0a\u512a\u65bc\u6700\u5148\u9032\u7684\u65b9\u6cd5\u3002\u4f8b\u5982\uff0c\u5728\u80ba\u90e8\u5206\u5272\u8cc7\u6599\u96c6\u4e2d\uff0c\u6211\u5011\u7684\u6a21\u578b\u6bd4 TransNetR \u6a21\u578b\u7522\u751f\u4e86\u986f\u8457\u7684\u63d0\u5347\uff0c\u5305\u62ec\u9ab0\u5b50\u4fc2\u6578\u589e\u52a0\u4e86 5.72%\uff0c\u5e73\u5747\u806f\u5408\u4ea4\u96c6 (mIoU) \u63d0\u9ad8\u4e86 5.04%\uff0c\u53ec\u56de\u7387\u63d0\u9ad8\u4e86 8.02%\uff0c\u7cbe\u5ea6\u63d0\u9ad8\u4e86 4.42%\u3002\u56e0\u6b64\uff0c\u7d50\u5408\u52d5\u91cf\u5728\u5206\u5272\u548c\u5206\u985e\u4efb\u52d9\u4e2d\u90fd\u5e36\u4f86\u4e86\u6700\u5148\u9032\u7684\u6548\u80fd\uff0c\u4ee3\u8868\u4e86\u91ab\u7642\u5f71\u50cf\u9818\u57df\u7684\u91cd\u5927\u9032\u5c55\u3002", "author": "Koushik Biswas et.al.", "authors": "Koushik Biswas, Ridal Pal, Shaswat Patel, Debesh Jha, Meghana Karri, Amit Reza, Gorkem Durak, Alpay Medetalibeyoglu, Matthew Antalek, Yury Velichko, Daniela Ladner, Amir Borhani, Ulas Bagci", "id": "2408.05692v1", "paper_url": "http://arxiv.org/abs/2408.05692v1", "repo": "null"}}