{"2406.06371": {"publish_time": "2024-06-10", "title": "mHuBERT-147: A Compact Multilingual HuBERT Model", "paper_summary": "We present mHuBERT-147, the first general-purpose massively multilingual\nHuBERT speech representation model trained on 90K hours of clean, open-license\ndata. To scale up the multi-iteration HuBERT approach, we use faiss-based\nclustering, achieving 5.2x faster label assignment over the original method. We\nalso apply a new multilingual batching up-sampling strategy, leveraging both\nlanguage and dataset diversity. After 3 training iterations and with only 95M\nparameters, mHuBERT-147 outperforms larger models trained on substantially more\ndata. We rank second and first on the ML-SUPERB 10min/1h leaderboards\nrespectively, with SOTA scores for all LID tasks. Across ASR/LID tasks, our\nmodel consistently surpasses XLS-R (300M params; 436K hours) and demonstrates\nstrong competitiveness against the much larger MMS (1B params; 491K hours). Our\nfindings suggest that mHuBERT-147 is a promising model for multilingual speech\nprocessing tasks, offering an unprecedented balance between high performance\nand parameter efficiency.", "paper_summary_zh": "\u6211\u5011\u5c55\u793a mHuBERT-147\uff0c\u9019\u662f\u4e00\u500b\u7d93\u904e 90K \u5c0f\u6642\u4e7e\u6de8\u3001\u958b\u653e\u8a31\u53ef\u8b49\u8cc7\u6599\u8a13\u7df4\u7684\u7b2c\u4e00\u500b\u901a\u7528\u3001\u5927\u91cf\u591a\u8a9e\u8a00 HuBERT \u8a9e\u97f3\u8868\u793a\u6a21\u578b\u3002\u70ba\u4e86\u64f4\u5927\u591a\u91cd\u53cd\u8986\u904b\u7b97\u7684 HuBERT \u65b9\u6cd5\uff0c\u6211\u5011\u4f7f\u7528\u57fa\u65bc faiss \u7684\u5206\u7fa4\uff0c\u9054\u6210\u6bd4\u539f\u59cb\u65b9\u6cd5\u5feb 5.2 \u500d\u7684\u6a19\u7c64\u6307\u6d3e\u3002\u6211\u5011\u4e5f\u904b\u7528\u4e00\u7a2e\u65b0\u7684\u591a\u8a9e\u8a00\u6279\u6b21\u4e0a\u63a1\u6a23\u7b56\u7565\uff0c\u540c\u6642\u5229\u7528\u8a9e\u8a00\u548c\u8cc7\u6599\u96c6\u7684\u591a\u6a23\u6027\u3002\u7d93\u904e 3 \u6b21\u8a13\u7df4\u53cd\u8986\u904b\u7b97\uff0c\u4e14\u50c5\u6709 95M \u53c3\u6578\uff0cmHuBERT-147 \u5c31\u512a\u65bc\u7d93\u904e\u66f4\u591a\u8cc7\u6599\u8a13\u7df4\u7684\u8f03\u5927\u578b\u6a21\u578b\u3002\u6211\u5011\u5206\u5225\u5728 ML-SUPERB 10 \u5206\u9418/1 \u5c0f\u6642\u6392\u884c\u699c\u4e0a\u6392\u540d\u7b2c\u4e8c\u548c\u7b2c\u4e00\uff0c\u4e14\u6240\u6709 LID \u4efb\u52d9\u90fd\u6709 SOTA \u5206\u6578\u3002\u5728 ASR/LID \u4efb\u52d9\u4e2d\uff0c\u6211\u5011\u7684\u6a21\u578b\u6301\u7e8c\u8d85\u8d8a XLS-R\uff08300M \u53c3\u6578\uff1b436K \u5c0f\u6642\uff09\uff0c\u4e26\u5c55\u73fe\u51fa\u8207\u66f4\u5927\u898f\u6a21\u7684 MMS\uff081B \u53c3\u6578\uff1b491K \u5c0f\u6642\uff09\u7684\u5f37\u52c1\u7af6\u722d\u529b\u3002\u6211\u5011\u7684\u767c\u73fe\u986f\u793a\uff0cmHuBERT-147 \u662f\u591a\u8a9e\u8a00\u8a9e\u97f3\u8655\u7406\u4efb\u52d9\u7684\u4e00\u500b\u6709\u524d\u9014\u7684\u6a21\u578b\uff0c\u5728\u9ad8\u6027\u80fd\u548c\u53c3\u6578\u6548\u7387\u4e4b\u9593\u63d0\u4f9b\u524d\u6240\u672a\u6709\u7684\u5e73\u8861\u3002", "author": "Marcely Zanon Boito et.al.", "authors": "Marcely Zanon Boito, Vivek Iyer, Nikolaos Lagos, Laurent Besacier, Ioan Calapodescu", "id": "2406.06371v1", "paper_url": "http://arxiv.org/abs/2406.06371v1", "repo": "null"}}