{"2409.14904": {"publish_time": "2024-09-23", "title": "DSG-KD: Knowledge Distillation from Domain-Specific to General Language Models", "paper_summary": "The use of pre-trained language models fine-tuned to address specific\ndownstream tasks is a common approach in natural language processing (NLP).\nHowever, acquiring domain-specific knowledge via fine-tuning is challenging.\nTraditional methods involve pretraining language models using vast amounts of\ndomain-specific data before fine-tuning for particular tasks. This study\ninvestigates emergency/non-emergency classification tasks based on electronic\nmedical record (EMR) data obtained from pediatric emergency departments (PEDs)\nin Korea. Our findings reveal that existing domain-specific pre-trained\nlanguage models underperform compared to general language models in handling\nN-lingual free-text data characteristics of non-English-speaking regions. To\naddress these limitations, we propose a domain knowledge transfer methodology\nthat leverages knowledge distillation to infuse general language models with\ndomain-specific knowledge via fine-tuning. This study demonstrates the\neffective transfer of specialized knowledge between models by defining a\ngeneral language model as the student model and a domain-specific pre-trained\nmodel as the teacher model. In particular, we address the complexities of EMR\ndata obtained from PEDs in non-English-speaking regions, such as Korea, and\ndemonstrate that the proposed method enhances classification performance in\nsuch contexts. The proposed methodology not only outperforms baseline models on\nKorean PED EMR data, but also promises broader applicability in various\nprofessional and technical domains. In future works, we intend to extend this\nmethodology to include diverse non-English-speaking regions and address\nadditional downstream tasks, with the aim of developing advanced model\narchitectures using state-of-the-art KD techniques. The code is available in\nhttps://github.com/JoSangYeon/DSG-KD.", "paper_summary_zh": "<paragraph>\u4f7f\u7528\u91dd\u5c0d\u7279\u5b9a\u4e0b\u6e38\u4efb\u52d9\u9032\u884c\u5fae\u8abf\u7684\u9810\u5148\u8a13\u7df4\u8a9e\u8a00\u6a21\u578b\u662f\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u4e2d\u7684\u5e38\u898b\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u900f\u904e\u5fae\u8abf\u4f86\u7372\u53d6\u7279\u5b9a\u9818\u57df\u7684\u77e5\u8b58\u5177\u6709\u6311\u6230\u6027\u3002\u50b3\u7d71\u65b9\u6cd5\u6d89\u53ca\u4f7f\u7528\u5927\u91cf\u7684\u7279\u5b9a\u9818\u57df\u8cc7\u6599\u4f86\u9810\u8a13\u7df4\u8a9e\u8a00\u6a21\u578b\uff0c\u7136\u5f8c\u91dd\u5c0d\u7279\u5b9a\u4efb\u52d9\u9032\u884c\u5fae\u8abf\u3002\u672c\u7814\u7a76\u8abf\u67e5\u4e86\u57fa\u65bc\u5f9e\u97d3\u570b\u5c0f\u5152\u6025\u8a3a\u79d1 (PED) \u53d6\u5f97\u7684\u96fb\u5b50\u91ab\u7642\u7d00\u9304 (EMR) \u8cc7\u6599\u7684\u7dca\u6025/\u975e\u7dca\u6025\u5206\u985e\u4efb\u52d9\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u986f\u793a\uff0c\u73fe\u6709\u7684\u7279\u5b9a\u9818\u57df\u9810\u8a13\u7df4\u8a9e\u8a00\u6a21\u578b\u5728\u8655\u7406\u975e\u82f1\u8a9e\u7cfb\u5730\u5340\u7684 N \u8a9e\u8a00\u81ea\u7531\u6587\u5b57\u8cc7\u6599\u7279\u6027\u6642\uff0c\u8868\u73fe\u4e0d\u5982\u4e00\u822c\u8a9e\u8a00\u6a21\u578b\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u9650\u5236\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u9818\u57df\u77e5\u8b58\u8f49\u79fb\u65b9\u6cd5\uff0c\u8a72\u65b9\u6cd5\u5229\u7528\u77e5\u8b58\u84b8\u993e\uff0c\u900f\u904e\u5fae\u8abf\u5c07\u4e00\u822c\u8a9e\u8a00\u6a21\u578b\u6ce8\u5165\u7279\u5b9a\u9818\u57df\u7684\u77e5\u8b58\u3002\u672c\u7814\u7a76\u900f\u904e\u5c07\u4e00\u822c\u8a9e\u8a00\u6a21\u578b\u5b9a\u7fa9\u70ba\u5b78\u751f\u6a21\u578b\uff0c\u5c07\u7279\u5b9a\u9818\u57df\u7684\u9810\u8a13\u7df4\u6a21\u578b\u5b9a\u7fa9\u70ba\u8001\u5e2b\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u6a21\u578b\u4e4b\u9593\u5c08\u696d\u77e5\u8b58\u7684\u6709\u6548\u8f49\u79fb\u3002\u7279\u5225\u662f\uff0c\u6211\u5011\u89e3\u6c7a\u4e86\u5f9e\u975e\u82f1\u8a9e\u7cfb\u5730\u5340\uff08\u4f8b\u5982\u97d3\u570b\uff09\u7684 PED \u53d6\u5f97\u7684 EMR \u8cc7\u6599\u7684\u8907\u96dc\u6027\uff0c\u4e26\u5c55\u793a\u4e86\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u589e\u5f37\u4e86\u6b64\u985e\u60c5\u5883\u4e2d\u7684\u5206\u985e\u6548\u80fd\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4e0d\u50c5\u5728\u97d3\u6587 PED EMR \u8cc7\u6599\u4e0a\u512a\u65bc\u57fa\u6e96\u6a21\u578b\uff0c\u9084\u627f\u8afe\u5728\u5404\u7a2e\u5c08\u696d\u548c\u6280\u8853\u9818\u57df\u4e2d\u66f4\u5ee3\u6cdb\u7684\u61c9\u7528\u6027\u3002\u5728\u672a\u4f86\u7684\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u6253\u7b97\u64f4\u5c55\u6b64\u65b9\u6cd5\u4ee5\u7d0d\u5165\u4e0d\u540c\u7684\u975e\u82f1\u8a9e\u7cfb\u5730\u5340\uff0c\u4e26\u89e3\u6c7a\u5176\u4ed6\u4e0b\u6e38\u4efb\u52d9\uff0c\u76ee\u6a19\u662f\u4f7f\u7528\u6700\u5148\u9032\u7684 KD \u6280\u8853\u958b\u767c\u5148\u9032\u7684\u6a21\u578b\u67b6\u69cb\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/JoSangYeon/DSG-KD \u53d6\u5f97\u3002</paragraph>", "author": "Sangyeon Cho et.al.", "authors": "Sangyeon Cho, Jangyeong Jeon, Dongjoon Lee, Changhee Lee, Junyeong Kim", "id": "2409.14904v1", "paper_url": "http://arxiv.org/abs/2409.14904v1", "repo": "null"}}