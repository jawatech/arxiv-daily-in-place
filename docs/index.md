# arxiv-daily
 Automated deployment @ 2024-07-14 20:31:42 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-11**|**Video Diffusion Alignment via Reward Gradients**|Mihir Prabhudesai et.al.|[2407.08737v1](http://arxiv.org/abs/2407.08737v1)|[link](https://github.com/mihirp1998/vader)|
|**2024-07-11**|**Real-Time Anomaly Detection and Reactive Planning with Large Language Models**|Rohan Sinha et.al.|[2407.08735v1](http://arxiv.org/abs/2407.08735v1)|null|
|**2024-07-11**|**Transformer Circuit Faithfulness Metrics are not Robust**|Joseph Miller et.al.|[2407.08734v1](http://arxiv.org/abs/2407.08734v1)|[link](https://github.com/ufo-101/auto-circuit)|
|**2024-07-11**|**Is Your Model Really A Good Math Reasoner? Evaluating Mathematical Reasoning with Checklist**|Zihao Zhou et.al.|[2407.08733v1](http://arxiv.org/abs/2407.08733v1)|null|
|**2024-07-11**|**A Taxonomy for Data Contamination in Large Language Models**|Medha Palavalli et.al.|[2407.08716v1](http://arxiv.org/abs/2407.08716v1)|null|
|**2024-07-11**|**GTA: A Benchmark for General Tool Agents**|Jize Wang et.al.|[2407.08713v1](http://arxiv.org/abs/2407.08713v1)|[link](https://github.com/open-compass/GTA)|
|**2024-07-11**|**eyeballvul: a future-proof benchmark for vulnerability detection in the wild**|Timothee Chauvin et.al.|[2407.08708v1](http://arxiv.org/abs/2407.08708v1)|[link](https://github.com/timothee-chauvin/eyeballvul_experiments)|
|**2024-07-11**|**Towards Efficient Deployment of Hybrid SNNs on Neuromorphic and Edge AI Hardware**|James Seekings et.al.|[2407.08704v1](http://arxiv.org/abs/2407.08704v1)|null|
|**2024-07-11**|**Cloud Atlas: Efficient Fault Localization for Cloud Systems using Language Models and Causal Insight**|Zhiqiang Xie et.al.|[2407.08694v1](http://arxiv.org/abs/2407.08694v1)|null|
|**2024-07-11**|**ElasticAST: An Audio Spectrogram Transformer for All Length and Resolutions**|Jiu Feng et.al.|[2407.08691v1](http://arxiv.org/abs/2407.08691v1)|[link](https://github.com/jiufengsc/elasticast)|
|**2024-07-11**|**CAD-Prompted Generative Models: A Pathway to Feasible and Novel Engineering Designs**|Leah Chong et.al.|[2407.08675v1](http://arxiv.org/abs/2407.08675v1)|null|
|**2024-07-11**|**Uncertainty Estimation of Large Language Models in Medical Question Answering**|Jiaxin Wu et.al.|[2407.08662v1](http://arxiv.org/abs/2407.08662v1)|null|
|**2024-07-11**|**Confidence-based Estimators for Predictive Performance in Model Monitoring**|Juhani Kivimäki et.al.|[2407.08649v1](http://arxiv.org/abs/2407.08649v1)|null|
|**2024-07-11**|**Towards Building Specialized Generalist AI with System 1 and System 2 Fusion**|Kaiyan Zhang et.al.|[2407.08642v1](http://arxiv.org/abs/2407.08642v1)|null|
|**2024-07-11**|**$β$-DPO: Direct Preference Optimization with Dynamic $β$**|Junkang Wu et.al.|[2407.08639v1](http://arxiv.org/abs/2407.08639v1)|[link](https://github.com/junkangwu/beta-dpo)|
|**2024-07-11**|**Tamil Language Computing: the Present and the Future**|Kengatharaiyer Sarveswaran et.al.|[2407.08618v1](http://arxiv.org/abs/2407.08618v1)|null|
|**2024-07-11**|**FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision**|Jay Shah et.al.|[2407.08608v1](http://arxiv.org/abs/2407.08608v1)|null|
|**2024-07-11**|**Turn-Level Empathy Prediction Using Psychological Indicators**|Shaz Furniturewala et.al.|[2407.08607v1](http://arxiv.org/abs/2407.08607v1)|null|
|**2024-07-11**|**The Synergy between Data and Multi-Modal Large Language Models: A Survey from Co-Development Perspective**|Zhen Qin et.al.|[2407.08583v1](http://arxiv.org/abs/2407.08583v1)|[link](https://github.com/modelscope/data-juicer)|
|**2024-07-11**|**On the Universal Truthfulness Hyperplane Inside LLMs**|Junteng Liu et.al.|[2407.08582v1](http://arxiv.org/abs/2407.08582v1)|null|
|**2024-07-11**|**The Career Interests of Large Language Models**|Meng Hua et.al.|[2407.08564v1](http://arxiv.org/abs/2407.08564v1)|null|
|**2024-07-11**|**Vox Populi, Vox AI? Using Language Models to Estimate German Public Opinion**|Leah von der Heyde et.al.|[2407.08563v1](http://arxiv.org/abs/2407.08563v1)|[link](https://github.com/leahvdh/vox-populi-vox-ai)|
|**2024-07-11**|**ST-Mamba: Spatial-Temporal Mamba for Traffic Flow Estimation Recovery using Limited Data**|Doncheng Yuan et.al.|[2407.08558v1](http://arxiv.org/abs/2407.08558v1)|null|
|**2024-07-11**|**Establishing Rigorous and Cost-effective Clinical Trials for Artificial Intelligence Models**|Wanling Gao et.al.|[2407.08554v1](http://arxiv.org/abs/2407.08554v1)|[link](https://github.com/benchcouncil/vc-medai)|
|**2024-07-11**|**Autoregressive Speech Synthesis without Vector Quantization**|Lingwei Meng et.al.|[2407.08551v1](http://arxiv.org/abs/2407.08551v1)|null|
|**2024-07-11**|**Incorporating Large Language Models into Production Systems for Enhanced Task Automation and Flexibility**|Yuchen Xia et.al.|[2407.08550v1](http://arxiv.org/abs/2407.08550v1)|null|
|**2024-07-11**|**Emergent Visual-Semantic Hierarchies in Image-Text Representations**|Morris Alper et.al.|[2407.08521v1](http://arxiv.org/abs/2407.08521v1)|null|
|**2024-07-11**|**Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents**|Haoyi Xiong et.al.|[2407.08516v1](http://arxiv.org/abs/2407.08516v1)|null|
|**2024-07-11**|**15M Multimodal Facial Image-Text Dataset**|Dawei Dai et.al.|[2407.08515v1](http://arxiv.org/abs/2407.08515v1)|null|
|**2024-07-11**|**Latent Conditional Diffusion-based Data Augmentation for Continuous-Time Dynamic Graph Mode**|Yuxing Tian et.al.|[2407.08500v1](http://arxiv.org/abs/2407.08500v1)|null|
|**2024-07-11**|**Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024**|Ilias Chalkidis et.al.|[2407.08495v1](http://arxiv.org/abs/2407.08495v1)|null|
|**2024-07-11**|**Lynx: An Open Source Hallucination Evaluation Model**|Selvan Sunitha Ravi et.al.|[2407.08488v1](http://arxiv.org/abs/2407.08488v1)|null|
|**2024-07-11**|**Investigating Public Fine-Tuning Datasets: A Complex Review of Current Practices from a Construction Perspective**|Runyuan Ma et.al.|[2407.08475v1](http://arxiv.org/abs/2407.08475v1)|null|
|**2024-07-11**|**Natural language is not enough: Benchmarking multi-modal generative AI for Verilog generation**|Kaiyan Chang et.al.|[2407.08473v1](http://arxiv.org/abs/2407.08473v1)|[link](https://github.com/aichipdesign/chipgptv)|
|**2024-07-11**|**Brain Tumor Segmentation in MRI Images with 3D U-Net and Contextual Transformer**|Thien-Qua T. Nguyen et.al.|[2407.08470v1](http://arxiv.org/abs/2407.08470v1)|null|
|**2024-07-11**|**Model Tells You Where to Merge: Adaptive KV Cache Merging for LLMs on Long-Context Tasks**|Zheng Wang et.al.|[2407.08454v1](http://arxiv.org/abs/2407.08454v1)|null|
|**2024-07-11**|**Paving the way toward foundation models for irregular and unaligned Satellite Image Time Series**|Iris Dumeur et.al.|[2407.08448v1](http://arxiv.org/abs/2407.08448v1)|null|
|**2024-07-11**|**How Deep is your Guess? A Fresh Perspective on Deep Learning for Medical Time-Series Imputation**|Linglong Qian et.al.|[2407.08442v1](http://arxiv.org/abs/2407.08442v1)|null|
|**2024-07-11**|**Are Large Language Models Really Bias-Free? Jailbreak Prompts for Assessing Adversarial Robustness to Bias Elicitation**|Riccardo Cantini et.al.|[2407.08441v1](http://arxiv.org/abs/2407.08441v1)|null|
|**2024-07-11**|**Beyond Instruction Following: Evaluating Rule Following of Large Language Models**|Wangtao Sun et.al.|[2407.08440v1](http://arxiv.org/abs/2407.08440v1)|null|
|**2024-07-11**|**A Comprehensive Survey on Human Video Generation: Challenges, Methods, and Insights**|Wentao Lei et.al.|[2407.08428v1](http://arxiv.org/abs/2407.08428v1)|[link](https://github.com/wentaol86/awesome-human-body-video-generation)|
|**2024-07-11**|**On the (In)Security of LLM App Stores**|Xinyi Hou et.al.|[2407.08422v1](http://arxiv.org/abs/2407.08422v1)|null|
|**2024-07-11**|**Specialist vision-language models for clinical ophthalmology**|Robbie Holland et.al.|[2407.08410v1](http://arxiv.org/abs/2407.08410v1)|null|
|**2024-07-11**|**A Two-Stage Machine Learning-Aided Approach for Quench Identification at the European XFEL**|Lynda Boukela et.al.|[2407.08408v1](http://arxiv.org/abs/2407.08408v1)|null|
|**2024-07-11**|**Self-training Language Models for Arithmetic Reasoning**|Marek Kadlčík et.al.|[2407.08400v1](http://arxiv.org/abs/2407.08400v1)|null|
|**2024-07-11**|**On the attribution of confidence to large language models**|Geoff Keeling et.al.|[2407.08388v1](http://arxiv.org/abs/2407.08388v1)|null|
|**2024-07-11**|**Digital twins to alleviate the need for real field data in vision-based vehicle speed detection systems**|Antonio Hernández Martínez et.al.|[2407.08380v1](http://arxiv.org/abs/2407.08380v1)|null|
|**2024-07-11**|**AutoBencher: Creating Salient, Novel, Difficult Datasets for Language Models**|Xiang Lisa Li et.al.|[2407.08351v1](http://arxiv.org/abs/2407.08351v1)|[link](https://github.com/XiangLi1999/AutoBencher)|
|**2024-07-11**|**Skywork-Math: Data Scaling Laws for Mathematical Reasoning in Large Language Models -- The Story Goes On**|Liang Zeng et.al.|[2407.08348v1](http://arxiv.org/abs/2407.08348v1)|null|
|**2024-07-11**|**Towards Explainable Evolution Strategies with Large Language Models**|Jill Baumann et.al.|[2407.08331v1](http://arxiv.org/abs/2407.08331v1)|null|
|**2024-07-11**|**Unveiling Disparities in Maternity Care: A Topic Modelling Approach to Analysing Maternity Incident Investigation Reports**|Georgina Cosma et.al.|[2407.08328v1](http://arxiv.org/abs/2407.08328v1)|null|
|**2024-07-11**|**Intelligent Multi-Document Summarisation for Extracting Insights on Racial Inequalities from Maternity Incident Investigation Reports**|Georgina Cosma et.al.|[2407.08322v1](http://arxiv.org/abs/2407.08322v1)|null|
|**2024-07-11**|**Adversarial-MidiBERT: Symbolic Music Understanding Model Based on Unbias Pre-training and Mask Fine-tuning**|Zijian Zhao et.al.|[2407.08306v1](http://arxiv.org/abs/2407.08306v1)|[link](https://github.com/RS2002/Adversarial-MidiBERT)|
|**2024-07-11**|**DenseFusion-1M: Merging Vision Experts for Comprehensive Multimodal Perception**|Xiaotong Li et.al.|[2407.08303v1](http://arxiv.org/abs/2407.08303v1)|[link](https://github.com/baaivision/densefusion)|
|**2024-07-11**|**Impact Measures for Gradual Argumentation Semantics**|Caren Al Anaissy et.al.|[2407.08302v1](http://arxiv.org/abs/2407.08302v1)|null|
|**2024-07-11**|**Continually Learn to Map Visual Concepts to Large Language Models in Resource-constrained Environments**|Clea Rebillard et.al.|[2407.08279v1](http://arxiv.org/abs/2407.08279v1)|null|
|**2024-07-11**|**RB-SQL: A Retrieval-based LLM Framework for Text-to-SQL**|Zhenhe Wu et.al.|[2407.08273v1](http://arxiv.org/abs/2407.08273v1)|null|
|**2024-07-11**|**SciQu: Accelerating Materials Properties Prediction with Automated Literature Mining for Self-Driving Laboratories**|Anand Babu et.al.|[2407.08270v1](http://arxiv.org/abs/2407.08270v1)|[link](https://github.com/abnano/sciqu)|
|**2024-07-11**|**LLMs' morphological analyses of complex FST-generated Finnish words**|Anssi Moisio et.al.|[2407.08269v1](http://arxiv.org/abs/2407.08269v1)|[link](https://github.com/aalto-speech/llm-morph-tests)|
|**2024-07-11**|**Knowledge distillation to effectively attain both region-of-interest and global semantics from an image where multiple objects appear**|Seonwhee Jin et.al.|[2407.08257v1](http://arxiv.org/abs/2407.08257v1)|[link](https://github.com/seonwhee-genome/rvernet)|
|**2024-07-11**|**GeNet: A Multimodal LLM-Based Co-Pilot for Network Topology and Configuration**|Beni Ifland et.al.|[2407.08249v1](http://arxiv.org/abs/2407.08249v1)|null|
|**2024-07-11**|**Toward accessible comics for blind and low vision readers**|Christophe Rigaud et.al.|[2407.08248v1](http://arxiv.org/abs/2407.08248v1)|null|
|**2024-07-11**|**Leveraging LLMs to Predict Affective States via Smartphone Sensor Features**|Tianyi Zhang et.al.|[2407.08240v1](http://arxiv.org/abs/2407.08240v1)|null|
|**2024-07-11**|**DALL-M: Context-Aware Clinical Data Augmentation with LLMs**|Chihcheng Hsieh et.al.|[2407.08227v1](http://arxiv.org/abs/2407.08227v1)|[link](https://github.com/chihchenghsieh/dall-m)|
|**2024-07-11**|**Speculative RAG: Enhancing Retrieval Augmented Generation through Drafting**|Zilong Wang et.al.|[2407.08223v1](http://arxiv.org/abs/2407.08223v1)|null|
|**2024-07-11**|**Generating Contextually-Relevant Navigation Instructions for Blind and Low Vision People**|Zain Merchant et.al.|[2407.08219v1](http://arxiv.org/abs/2407.08219v1)|null|
|**2024-07-11**|**Multimodal contrastive learning for spatial gene expression prediction using histology images**|Wenwen Min et.al.|[2407.08216v1](http://arxiv.org/abs/2407.08216v1)|[link](https://github.com/shizhiceng/mclstexp)|
|**2024-07-11**|**System Report for CCL24-Eval Task 7: Multi-Error Modeling and Fluency-Targeted Pre-training for Chinese Essay Evaluation**|Jingshen Zhang et.al.|[2407.08206v1](http://arxiv.org/abs/2407.08206v1)|null|
|**2024-07-11**|**Chromosomal Structural Abnormality Diagnosis by Homologous Similarity**|Juren Li et.al.|[2407.08204v1](http://arxiv.org/abs/2407.08204v1)|[link](https://github.com/zjunet/homnet)|
|**2024-07-11**|**SoupLM: Model Integration in Large Language and Multi-Modal Models**|Yue Bai et.al.|[2407.08196v1](http://arxiv.org/abs/2407.08196v1)|null|
|**2024-07-11**|**A Text-to-Game Engine for UGC-Based Role-Playing Games**|Lei Zhang et.al.|[2407.08195v1](http://arxiv.org/abs/2407.08195v1)|null|
|**2024-07-11**|**ARCO:Adaptive Multi-Agent Reinforcement Learning-Based Hardware/Software Co-Optimization Compiler for Improved Performance in DNN Accelerator Design**|Arya Fayyazi et.al.|[2407.08192v1](http://arxiv.org/abs/2407.08192v1)|null|
|**2024-07-11**|**fairBERTs: Erasing Sensitive Information Through Semantic and Fairness-aware Perturbations**|Jinfeng Li et.al.|[2407.08189v1](http://arxiv.org/abs/2407.08189v1)|null|
|**2024-07-11**|**Automatic Generation of Web Censorship Probe Lists**|Jenny Tang et.al.|[2407.08185v1](http://arxiv.org/abs/2407.08185v1)|null|
|**2024-07-11**|**Beyond Text: Leveraging Multi-Task Learning and Cognitive Appraisal Theory for Post-Purchase Intention Analysis**|Gerard Christopher Yeo et.al.|[2407.08182v1](http://arxiv.org/abs/2407.08182v1)|null|
|**2024-07-11**|**CoGS: Causality Constrained Counterfactual Explanations using goal-directed ASP**|Sopam Dasgupta et.al.|[2407.08179v1](http://arxiv.org/abs/2407.08179v1)|null|
|**2024-07-11**|**Foundation Model Engineering: Engineering Foundation Models Just as Engineering Software**|Dezhi Ran et.al.|[2407.08176v1](http://arxiv.org/abs/2407.08176v1)|null|
|**2024-07-11**|**Faster Machine Unlearning via Natural Gradient Descent**|Omri Lev et.al.|[2407.08169v1](http://arxiv.org/abs/2407.08169v1)|null|
|**2024-07-11**|**Synthetic Electroretinogram Signal Generation Using Conditional Generative Adversarial Network for Enhancing Classification of Autism Spectrum Disorder**|Mikhail Kulyabin et.al.|[2407.08166v1](http://arxiv.org/abs/2407.08166v1)|null|
|**2024-07-11**|**Privacy-Preserving Data Deduplication for Enhancing Federated Learning of Language Models**|Aydin Abadi et.al.|[2407.08152v1](http://arxiv.org/abs/2407.08152v1)|null|
|**2024-07-11**|**Looks can be Deceptive: Distinguishing Repetition Disfluency from Reduplication**|Arif Ahmad et.al.|[2407.08147v1](http://arxiv.org/abs/2407.08147v1)|null|
|**2024-07-11**|**Highway Networks for Improved Surface Reconstruction: The Role of Residuals and Weight Updates**|A. Noorizadegan et.al.|[2407.08134v1](http://arxiv.org/abs/2407.08134v1)|[link](https://github.com/cmmai/resnet_for_pinn)|
|**2024-07-11**|**Nonverbal Interaction Detection**|Jianan Wei et.al.|[2407.08133v1](http://arxiv.org/abs/2407.08133v1)|null|
|**2024-07-11**|**Label-anticipated Event Disentanglement for Audio-Visual Video Parsing**|Jinxing Zhou et.al.|[2407.08126v1](http://arxiv.org/abs/2407.08126v1)|null|
|**2024-07-11**|**How Well Can a Long Sequence Model Model Long Sequences? Comparing Architechtural Inductive Biases on Long-Context Abilities**|Jerry Huang et.al.|[2407.08112v1](http://arxiv.org/abs/2407.08112v1)|null|
|**2024-07-11**|**Urban Waterlogging Detection: A Challenging Benchmark and Large-Small Model Co-Adapter**|Suqi Song et.al.|[2407.08109v1](http://arxiv.org/abs/2407.08109v1)|[link](https://github.com/zhang-chenxu/lsm-adapter)|
|**2024-07-11**|**CADC: Encoding User-Item Interactions for Compressing Recommendation Model Training Data**|Hossein Entezari Zarch et.al.|[2407.08108v1](http://arxiv.org/abs/2407.08108v1)|null|
|**2024-07-11**|**Federated Learning and AI Regulation in the European Union: Who is liable? An Interdisciplinary Analysis**|Herbert Woisetschläger et.al.|[2407.08105v1](http://arxiv.org/abs/2407.08105v1)|null|
|**2024-07-11**|**Automata-based constraints for language model decoding**|Terry Koo et.al.|[2407.08103v1](http://arxiv.org/abs/2407.08103v1)|null|
|**2024-07-11**|**How does Burrows' Delta work on medieval Chinese poetic texts?**|Boris Orekhov et.al.|[2407.08099v1](http://arxiv.org/abs/2407.08099v1)|null|
|**2024-07-10**|**Virtual Agents for Alcohol Use Counseling: Exploring LLM-Powered Motivational Interviewing**|Ian Steenstra et.al.|[2407.08095v1](http://arxiv.org/abs/2407.08095v1)|null|
|**2024-07-10**|**MemWarp: Discontinuity-Preserving Cardiac Registration with Memorized Anatomical Filters**|Hang Zhang et.al.|[2407.08093v1](http://arxiv.org/abs/2407.08093v1)|null|
|**2024-07-10**|**NDST: Neural Driving Style Transfer for Human-Like Vision-Based Autonomous Driving**|Donghyun Kim et.al.|[2407.08073v1](http://arxiv.org/abs/2407.08073v1)|null|
|**2024-07-10**|**On LLM Wizards: Identifying Large Language Models' Behaviors for Wizard of Oz Experiments**|Jingchao Fang et.al.|[2407.08067v1](http://arxiv.org/abs/2407.08067v1)|null|
|**2024-07-10**|**Towards Interpretable Foundation Models of Robot Behavior: A Task Specific Policy Generation Approach**|Isaac Sheidlower et.al.|[2407.08065v1](http://arxiv.org/abs/2407.08065v1)|null|
|**2024-07-10**|**Spatial-Temporal Attention Model for Traffic State Estimation with Sparse Internet of Vehicles**|Jianzhe Xue et.al.|[2407.08047v1](http://arxiv.org/abs/2407.08047v1)|null|
|**2024-07-10**|**RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization**|Xijie Huang et.al.|[2407.08044v1](http://arxiv.org/abs/2407.08044v1)|[link](https://github.com/huangowen/rolora)|
|**2024-07-10**|**Knowledge Overshadowing Causes Amalgamated Hallucination in Large Language Models**|Yuji Zhang et.al.|[2407.08039v1](http://arxiv.org/abs/2407.08039v1)|null|
|**2024-07-10**|**FsPONER: Few-shot Prompt Optimization for Named Entity Recognition in Domain-specific Scenarios**|Yongjian Tang et.al.|[2407.08035v1](http://arxiv.org/abs/2407.08035v1)|null|
|**2024-07-10**|**A Critical Review of Causal Reasoning Benchmarks for Large Language Models**|Linying Yang et.al.|[2407.08029v1](http://arxiv.org/abs/2407.08029v1)|null|

#### Abstracts
##### **Video Diffusion Alignment via Reward Gradients**
2407.08737v1 by Mihir Prabhudesai, Russell Mendonca, Zheyang Qin, Katerina Fragkiadaki, Deepak Pathak

We have made significant progress towards building foundational video
diffusion models. As these models are trained using large-scale unsupervised
data, it has become crucial to adapt these models to specific downstream tasks.
Adapting these models via supervised fine-tuning requires collecting target
datasets of videos, which is challenging and tedious. In this work, we utilize
pre-trained reward models that are learned via preferences on top of powerful
vision discriminative models to adapt video diffusion models. These models
contain dense gradient information with respect to generated RGB pixels, which
is critical to efficient learning in complex search spaces, such as videos. We
show that backpropagating gradients from these reward models to a video
diffusion model can allow for compute and sample efficient alignment of the
video diffusion model. We show results across a variety of reward models and
video diffusion models, demonstrating that our approach can learn much more
efficiently in terms of reward queries and computation than prior gradient-free
approaches. Our code, model weights,and more visualization are available at
https://vader-vid.github.io.

摘要：我們在建立基礎影片擴散模型方面取得重大進展。由於這些模型使用大規模無監督資料進行訓練，因此必須將這些模型調整到特定下游任務。透過監督微調調整這些模型需要收集影片的目標資料集，這具有挑戰性且繁瑣。在這項工作中，我們利用預訓練的獎勵模型，這些模型是透過偏好在強大的視覺辨別模型上學習，以調整影片擴散模型。這些模型包含關於生成 RGB 像素的密集梯度資訊，這對於在複雜的搜尋空間（例如影片）中進行有效率的學習至關重要。我們展示了從這些獎勵模型反向傳播梯度到影片擴散模型可以允許計算和樣本有效地對齊影片擴散模型。我們展示了各種獎勵模型和影片擴散模型的結果，證明我們的做法在獎勵查詢和計算方面可以比先前的無梯度方法學習更有效率。我們的程式碼、模型權重和更多視覺化資訊可在 https://vader-vid.github.io/ 取得。

##### **Real-Time Anomaly Detection and Reactive Planning with Large Language Models**
2407.08735v1 by Rohan Sinha, Amine Elhafsi, Christopher Agia, Matthew Foutter, Edward Schmerling, Marco Pavone

Foundation models, e.g., large language models (LLMs), trained on
internet-scale data possess zero-shot generalization capabilities that make
them a promising technology towards detecting and mitigating
out-of-distribution failure modes of robotic systems. Fully realizing this
promise, however, poses two challenges: (i) mitigating the considerable
computational expense of these models such that they may be applied online, and
(ii) incorporating their judgement regarding potential anomalies into a safe
control framework. In this work, we present a two-stage reasoning framework:
First is a fast binary anomaly classifier that analyzes observations in an LLM
embedding space, which may then trigger a slower fallback selection stage that
utilizes the reasoning capabilities of generative LLMs. These stages correspond
to branch points in a model predictive control strategy that maintains the
joint feasibility of continuing along various fallback plans to account for the
slow reasoner's latency as soon as an anomaly is detected, thus ensuring
safety. We show that our fast anomaly classifier outperforms autoregressive
reasoning with state-of-the-art GPT models, even when instantiated with
relatively small language models. This enables our runtime monitor to improve
the trustworthiness of dynamic robotic systems, such as quadrotors or
autonomous vehicles, under resource and time constraints. Videos illustrating
our approach in both simulation and real-world experiments are available on
this project page: https://sites.google.com/view/aesop-llm.

摘要：基础模型（例如大型语言模型 (LLM)）在互联网规模的数据上进行训练，拥有零样本泛化能力，这使得它们成为检测和缓解机器人系统分布外故障模式的一项有前途的技术。然而，要充分实现这一承诺，需要应对两项挑战：(i) 降低这些模型的巨大计算开销，以便可以在线应用它们，以及 (ii) 将它们对潜在异常的判断纳入安全控制框架中。在这项工作中，我们提出了一个两阶段推理框架：首先是一个快速的二进制异常分类器，它分析 LLM 嵌入空间中的观测值，然后可能触发一个较慢的回退选择阶段，该阶段利用生成式 LLM 的推理能力。这些阶段对应于模型预测控制策略中的分支点，该策略保持继续执行各种回退计划的联合可行性，以便在检测到异常后立即考虑慢速推理器的延迟，从而确保安全性。我们表明，即使使用相对较小的语言模型实例化，我们的快速异常分类器也优于采用最先进的 GPT 模型的自回归推理。这使我们的运行时监视器能够在资源和时间限制下提高动态机器人系统（例如四旋翼飞机或自动驾驶汽车）的可信度。说明我们方法的模拟和真实世界实验视频可在该项目页面上找到：https://sites.google.com/view/aesop-llm。

##### **Transformer Circuit Faithfulness Metrics are not Robust**
2407.08734v1 by Joseph Miller, Bilal Chughtai, William Saunders

Mechanistic interpretability work attempts to reverse engineer the learned
algorithms present inside neural networks. One focus of this work has been to
discover 'circuits' -- subgraphs of the full model that explain behaviour on
specific tasks. But how do we measure the performance of such circuits? Prior
work has attempted to measure circuit 'faithfulness' -- the degree to which the
circuit replicates the performance of the full model. In this work, we survey
many considerations for designing experiments that measure circuit faithfulness
by ablating portions of the model's computation. Concerningly, we find existing
methods are highly sensitive to seemingly insignificant changes in the ablation
methodology. We conclude that existing circuit faithfulness scores reflect both
the methodological choices of researchers as well as the actual components of
the circuit - the task a circuit is required to perform depends on the ablation
used to test it. The ultimate goal of mechanistic interpretability work is to
understand neural networks, so we emphasize the need for more clarity in the
precise claims being made about circuits. We open source a library at
https://github.com/UFO-101/auto-circuit that includes highly efficient
implementations of a wide range of ablation methodologies and circuit discovery
algorithms.

摘要：<paragraph>机制可解释性工作尝试对神经网络中存在的学习算法进行逆向工程。这项工作的重点之一是发现“电路”-- 完整模型的子图，它解释了特定任务的行为。但是，我们如何衡量此类电路的性能？先前的工作尝试测量电路“保真度”-- 电路复制完整模型性能的程度。在这项工作中，我们调查了许多考虑因素，用于设计通过消融模型计算部分来测量电路保真度的实验。令人担忧的是，我们发现现有方法对消融方法中看似微不足道的变化高度敏感。我们得出结论，现有的电路保真度得分反映了研究人员的方法论选择以及电路的实际组件 - 电路需要执行的任务取决于用于测试它的消融。机制可解释性工作的最终目标是理解神经网络，因此我们强调需要更清楚地阐述关于电路的具体主张。我们在 https://github.com/UFO-101/auto-circuit 开源了一个库，其中包括广泛的消融方法和电路发现算法的高效实现。</paragraph>

##### **Is Your Model Really A Good Math Reasoner? Evaluating Mathematical Reasoning with Checklist**
2407.08733v1 by Zihao Zhou, Shudong Liu, Maizhen Ning, Wei Liu, Jindong Wang, Derek F. Wong, Xiaowei Huang, Qiufeng Wang, Kaizhu Huang

Exceptional mathematical reasoning ability is one of the key features that
demonstrate the power of large language models (LLMs). How to comprehensively
define and evaluate the mathematical abilities of LLMs, and even reflect the
user experience in real-world scenarios, has emerged as a critical issue.
Current benchmarks predominantly concentrate on problem-solving capabilities,
which presents a substantial risk of model overfitting and fails to accurately
represent genuine mathematical reasoning abilities. In this paper, we argue
that if a model really understands a problem, it should be robustly and readily
applied across a diverse array of tasks. Motivated by this, we introduce
MATHCHECK, a well-designed checklist for testing task generalization and
reasoning robustness, as well as an automatic tool to generate checklists
efficiently. MATHCHECK includes multiple mathematical reasoning tasks and
robustness test types to facilitate a comprehensive evaluation of both
mathematical reasoning ability and behavior testing. Utilizing MATHCHECK, we
develop MATHCHECK-GSM and MATHCHECK-GEO to assess mathematical textual
reasoning and multi-modal reasoning capabilities, respectively, serving as
upgraded versions of benchmarks including GSM8k, GeoQA, UniGeo, and Geometry3K.
We adopt MATHCHECK-GSM and MATHCHECK-GEO to evaluate over 20 LLMs and 11 MLLMs,
assessing their comprehensive mathematical reasoning abilities. Our results
demonstrate that while frontier LLMs like GPT-4o continue to excel in various
abilities on the checklist, many other model families exhibit a significant
decline. Further experiments indicate that, compared to traditional math
benchmarks, MATHCHECK better reflects true mathematical abilities and
represents mathematical intelligence more linearly, thereby supporting our
design. On our MATHCHECK, we can easily conduct detailed behavior analysis to
deeply investigate models.

摘要：傑出的數學推理能力是展示大型語言模型 (LLM) 強大的關鍵特徵之一。如何全面定義和評估 LLM 的數學能力，甚至反映真實場景中的使用者體驗，已成為一個關鍵問題。目前的基準主要集中於問題解決能力，這會造成模型過度擬合的重大風險，且無法準確表示真正的數學推理能力。在本文中，我們論證如果一個模型真正理解一個問題，它應該可以穩健且容易地應用於各種任務中。受此啟發，我們引入了 MATHCHECK，這是一個精心設計的檢查清單，用於測試任務概化和推理穩健性，以及一個用於有效產生檢查清單的自動化工具。MATHCHECK 包含多項數學推理任務和穩健性測試類型，以利於對數學推理能力和行為測試進行全面評估。利用 MATHCHECK，我們開發了 MATHCHECK-GSM 和 MATHCHECK-GEO，分別用於評估數學文本推理和多模態推理能力，作為包括 GSM8k、GeoQA、UniGeo 和 Geometry3K 在內的基準的升級版本。我們採用 MATHCHECK-GSM 和 MATHCHECK-GEO 來評估超過 20 個 LLM 和 11 個 MLLM，評估它們的綜合數學推理能力。我們的結果表明，儘管像 GPT-4o 這樣的邊疆 LLM 繼續在檢查清單上的各種能力中表現出色，但許多其他模型系列卻出現顯著下降。進一步的實驗表明，與傳統數學基準相比，MATHCHECK 更好地反映了真正的數學能力，並更線性地表示數學智能，從而支持我們的設計。在我們的 MATHCHECK 上，我們可以輕鬆進行詳細的行為分析，以深入研究模型。

##### **A Taxonomy for Data Contamination in Large Language Models**
2407.08716v1 by Medha Palavalli, Amanda Bertsch, Matthew R. Gormley

Large language models pretrained on extensive web corpora demonstrate
remarkable performance across a wide range of downstream tasks. However, a
growing concern is data contamination, where evaluation datasets may be
contained in the pretraining corpus, inflating model performance.
Decontamination, the process of detecting and removing such data, is a
potential solution; yet these contaminants may originate from altered versions
of the test set, evading detection during decontamination. How different types
of contamination impact the performance of language models on downstream tasks
is not fully understood. We present a taxonomy that categorizes the various
types of contamination encountered by LLMs during the pretraining phase and
identify which types pose the highest risk. We analyze the impact of
contamination on two key NLP tasks -- summarization and question answering --
revealing how different types of contamination influence task performance
during evaluation.

摘要：大型語言模型在廣泛的網路語料庫上進行預訓練，在各種下游任務中展現出卓越的表現。然而，一個日益受到關注的問題是資料污染，評估資料集可能包含在預訓練語料庫中，進而誇大了模型的表現。去污，也就是偵測並移除此類資料的程序，是一種可能的解決方案；然而這些污染物可能來自測試集的修改版本，在去污過程中逃避偵測。不同類型的污染如何影響語言模型在下游任務中的表現，目前尚未完全了解。我們提出了一個分類法，將大型語言模型在預訓練階段遇到的各種污染類型分類，並找出風險最高的類型。我們分析了污染對兩個關鍵的自然語言處理任務的影響——摘要和問答——揭示了不同類型的污染如何在評估過程中影響任務表現。

##### **GTA: A Benchmark for General Tool Agents**
2407.08713v1 by Jize Wang, Zerun Ma, Yining Li, Songyang Zhang, Cailian Chen, Kai Chen, Xinyi Le

Significant focus has been placed on integrating large language models (LLMs)
with various tools in developing general-purpose agents. This poses a challenge
to LLMs' tool-use capabilities. However, there are evident gaps between
existing tool-use evaluations and real-world scenarios. Current evaluations
often use AI-generated queries, single-step tasks, dummy tools, and text-only
interactions, failing to reveal the agents' real-world problem-solving
abilities effectively. To address this, we propose GTA, a benchmark for General
Tool Agents, featuring three main aspects: (i) Real user queries: human-written
queries with simple real-world objectives but implicit tool-use, requiring the
LLM to reason the suitable tools and plan the solution steps. (ii) Real
deployed tools: an evaluation platform equipped with tools across perception,
operation, logic, and creativity categories to evaluate the agents' actual task
execution performance. (iii) Real multimodal inputs: authentic image files,
such as spatial scenes, web page screenshots, tables, code snippets, and
printed/handwritten materials, used as the query contexts to align with
real-world scenarios closely. We design 229 real-world tasks and executable
tool chains to evaluate mainstream LLMs. Our findings show that real-world user
queries are challenging for existing LLMs, with GPT-4 completing less than 50%
of the tasks and most LLMs achieving below 25%. This evaluation reveals the
bottlenecks in the tool-use capabilities of current LLMs in real-world
scenarios, which provides future direction for advancing general-purpose tool
agents. The code and dataset are available at
https://github.com/open-compass/GTA.

摘要：<paragraph>在開發通用代理時，整合大型語言模型 (LLM) 與各種工具已成為重點。這對 LLM 的工具使用能力構成挑戰。然而，現有的工具使用評估與實際場景之間存在明顯差距。目前的評估通常使用 AI 生成的查詢、單步任務、虛擬工具和純文字互動，未能有效揭示代理的實際問題解決能力。為了解決這個問題，我們提出 GTA，一個通用工具代理的基準，具有三個主要方面：(i) 真實使用者查詢：人類撰寫的查詢，具有簡單的實際目標但隱含工具使用，要求 LLM 推論適當的工具並規劃解決步驟。(ii) 真實部署工具：一個評估平台，配備感知、操作、邏輯和創意類別的工具，以評估代理的實際任務執行效能。(iii) 真實多模態輸入：真實的影像檔案，例如空間場景、網頁截圖、表格、程式碼片段，以及印刷/手寫材料，用作查詢背景，以緊密配合實際場景。我們設計了 229 個真實世界的任務和可執行工具鏈，以評估主流 LLM。我們的研究結果顯示，實際世界的使用者查詢對現有的 LLM 構成挑戰，GPT-4 完成不到 50% 的任務，而大多數 LLM 的完成率低於 25%。此評估揭示了當前 LLM 在實際場景中工具使用能力的瓶頸，這為推進通用工具代理提供了未來的方向。程式碼和資料集可在 https://github.com/open-compass/GTA 取得。</paragraph>

##### **eyeballvul: a future-proof benchmark for vulnerability detection in the wild**
2407.08708v1 by Timothee Chauvin

Long contexts of recent LLMs have enabled a new use case: asking models to
find security vulnerabilities in entire codebases. To evaluate model
performance on this task, we introduce eyeballvul: a benchmark designed to test
the vulnerability detection capabilities of language models at scale, that is
sourced and updated weekly from the stream of published vulnerabilities in
open-source repositories. The benchmark consists of a list of revisions in
different repositories, each associated with the list of known vulnerabilities
present at that revision. An LLM-based scorer is used to compare the list of
possible vulnerabilities returned by a model to the list of known
vulnerabilities for each revision. As of July 2024, eyeballvul contains 24,000+
vulnerabilities across 6,000+ revisions and 5,000+ repositories, and is around
55GB in size.

摘要：近期大型語言模型的長語境讓一個新應用案例成為可能：讓模型在整個程式碼庫中尋找安全漏洞。為了評估模型在這個任務上的表現，我們引入了 eyeballvul：一個基準測試，旨在測試語言模型在大規模情況下檢測漏洞的能力，它從開源儲存庫中已發布的漏洞串流中獲取並每周更新。這個基準測試包含一個清單，列出不同儲存庫中的修訂，每個修訂都與該修訂中存在已知漏洞的清單相關聯。一個基於 LLM 的評分器用於將模型返回的可能漏洞清單與每個修訂的已知漏洞清單進行比較。截至 2024 年 7 月，eyeballvul 包含超過 24,000 個漏洞，分佈在 6,000 多個修訂和 5,000 多個儲存庫中，大小約為 55GB。

##### **Towards Efficient Deployment of Hybrid SNNs on Neuromorphic and Edge AI Hardware**
2407.08704v1 by James Seekings, Peyton Chandarana, Mahsa Ardakani, MohammadReza Mohammadi, Ramtin Zand

This paper explores the synergistic potential of neuromorphic and edge
computing to create a versatile machine learning (ML) system tailored for
processing data captured by dynamic vision sensors. We construct and train
hybrid models, blending spiking neural networks (SNNs) and artificial neural
networks (ANNs) using PyTorch and Lava frameworks. Our hybrid architecture
integrates an SNN for temporal feature extraction and an ANN for
classification. We delve into the challenges of deploying such hybrid
structures on hardware. Specifically, we deploy individual components on
Intel's Neuromorphic Processor Loihi (for SNN) and Jetson Nano (for ANN). We
also propose an accumulator circuit to transfer data from the spiking to the
non-spiking domain. Furthermore, we conduct comprehensive performance analyses
of hybrid SNN-ANN models on a heterogeneous system of neuromorphic and edge AI
hardware, evaluating accuracy, latency, power, and energy consumption. Our
findings demonstrate that the hybrid spiking networks surpass the baseline ANN
model across all metrics and outperform the baseline SNN model in accuracy and
latency.

摘要：本文探討神經型態和邊緣運算的協同潛力，以建立一個多功能機器學習 (ML) 系統，專門用於處理動態視覺感測器擷取的資料。我們使用 PyTorch 和 Lava 架構構建並訓練混合模型，結合了脈衝神經網路 (SNN) 和人工神經網路 (ANN)。我們的混合架構整合了一個用於時間特徵提取的 SNN 和一個用於分類的 ANN。我們深入探討了在硬體上部署此類混合結構的挑戰。具體來說，我們在 Intel 的神經型態處理器 Loihi（用於 SNN）和 Jetson Nano（用於 ANN）上部署個別元件。我們還提出了一個累加器電路，用於將資料從脈衝傳輸到非脈衝域。此外，我們對神經型態和邊緣 AI 硬體的異質系統上的混合 SNN-ANN 模型進行了全面的效能分析，評估準確度、延遲、功耗和能耗。我們的研究結果表明，混合脈衝網路在所有指標上都超越了基準 ANN 模型，並且在準確度和延遲方面優於基準 SNN 模型。

##### **Cloud Atlas: Efficient Fault Localization for Cloud Systems using Language Models and Causal Insight**
2407.08694v1 by Zhiqiang Xie, Yujia Zheng, Lizi Ottens, Kun Zhang, Christos Kozyrakis, Jonathan Mace

Runtime failure and performance degradation is commonplace in modern cloud
systems. For cloud providers, automatically determining the root cause of
incidents is paramount to ensuring high reliability and availability as prompt
fault localization can enable faster diagnosis and triage for timely
resolution. A compelling solution explored in recent work is causal reasoning
using causal graphs to capture relationships between varied cloud system
performance metrics. To be effective, however, systems developers must
correctly define the causal graph of their system, which is a time-consuming,
brittle, and challenging task that increases in difficulty for large and
dynamic systems and requires domain expertise. Alternatively, automated
data-driven approaches have limited efficacy for cloud systems due to the
inherent rarity of incidents. In this work, we present Atlas, a novel approach
to automatically synthesizing causal graphs for cloud systems. Atlas leverages
large language models (LLMs) to generate causal graphs using system
documentation, telemetry, and deployment feedback. Atlas is complementary to
data-driven causal discovery techniques, and we further enhance Atlas with a
data-driven validation step. We evaluate Atlas across a range of fault
localization scenarios and demonstrate that Atlas is capable of generating
causal graphs in a scalable and generalizable manner, with performance that far
surpasses that of data-driven algorithms and is commensurate to the
ground-truth baseline.

摘要：在現代雲端系統中，執行時期故障和效能降低是司空見慣的事。對於雲端供應商而言，自動找出事件的根本原因對於確保高可靠性和可用性至關重要，因為及時的故障定位可以讓診斷和分類更快速，以利於及時解決問題。最近的工作中探討了一個引人注目的解決方案，即使用因果圖來擷取各種雲端系統效能指標之間關係的因果推理。然而，系統開發人員必須正確定義其系統的因果圖才能發揮效用，而這項任務耗時、脆弱且具有挑戰性，對於大型且動態的系統而言難度更高，而且需要領域專家知識。或者，由於事件的固有稀少性，自動化資料驅動方法對於雲端系統的效力有限。在這項工作中，我們提出 Atlas，一種自動合成雲端系統因果圖的新方法。Atlas 利用大型語言模型 (LLM) 使用系統文件、遙測和部署回饋來產生因果圖。Atlas 是資料驅動因果發現技術的補充，我們進一步使用資料驅動驗證步驟來增強 Atlas。我們在各種故障定位情境中評估 Atlas，並證明 Atlas 能夠以可擴充且可概化的方式產生因果圖，其效能遠遠超過資料驅動演算法，並且與真實基線相當。

##### **ElasticAST: An Audio Spectrogram Transformer for All Length and Resolutions**
2407.08691v1 by Jiu Feng, Mehmet Hamza Erol, Joon Son Chung, Arda Senocak

Transformers have rapidly overtaken CNN-based architectures as the new
standard in audio classification. Transformer-based models, such as the Audio
Spectrogram Transformers (AST), also inherit the fixed-size input paradigm from
CNNs. However, this leads to performance degradation for ASTs in the inference
when input lengths vary from the training. This paper introduces an approach
that enables the use of variable-length audio inputs with AST models during
both training and inference. By employing sequence packing, our method
ElasticAST, accommodates any audio length during training, thereby offering
flexibility across all lengths and resolutions at the inference. This
flexibility allows ElasticAST to maintain evaluation capabilities at various
lengths or resolutions and achieve similar performance to standard ASTs trained
at specific lengths or resolutions. Moreover, experiments demonstrate
ElasticAST's better performance when trained and evaluated on native-length
audio datasets.

摘要：Transformer已迅速超越基於 CNN 的架構，成為音訊分類中的新標準。基於Transformer的模型，例如音訊光譜Transformer (AST)，也繼承了 CNN 的固定大小輸入範例。然而，這會導致 AST 在輸入長度與訓練不同時的推論效能下降。本文介紹了一種方法，可在訓練和推論期間使用變長音訊輸入與 AST 模型。我們的 ElasticAST 方法採用序列封裝，可以在訓練期間容納任何音訊長度，從而提供推論時所有長度和解析度的彈性。這種彈性使 ElasticAST 能夠在各種長度或解析度下維持評估能力，並達到與在特定長度或解析度下訓練的標準 AST 相似的效能。此外，實驗證明了 ElasticAST 在原生長度音訊資料集上訓練和評估時具有更好的效能。

##### **CAD-Prompted Generative Models: A Pathway to Feasible and Novel Engineering Designs**
2407.08675v1 by Leah Chong, Jude Rayan, Steven Dow, Ioanna Lykourentzou, Faez Ahmed

Text-to-image generative models have increasingly been used to assist
designers during concept generation in various creative domains, such as
graphic design, user interface design, and fashion design. However, their
applications in engineering design remain limited due to the models' challenges
in generating images of feasible designs concepts. To address this issue, this
paper introduces a method that improves the design feasibility by prompting the
generation with feasible CAD images. In this work, the usefulness of this
method is investigated through a case study with a bike design task using an
off-the-shelf text-to-image model, Stable Diffusion 2.1. A diverse set of bike
designs are produced in seven different generation settings with varying CAD
image prompting weights, and these designs are evaluated on their perceived
feasibility and novelty. Results demonstrate that the CAD image prompting
successfully helps text-to-image models like Stable Diffusion 2.1 create
visibly more feasible design images. While a general tradeoff is observed
between feasibility and novelty, when the prompting weight is kept low around
0.35, the design feasibility is significantly improved while its novelty
remains on par with those generated by text prompts alone. The insights from
this case study offer some guidelines for selecting the appropriate CAD image
prompting weight for different stages of the engineering design process. When
utilized effectively, our CAD image prompting method opens doors to a wider
range of applications of text-to-image models in engineering design.

摘要：文本到影像的生成模型越來越常被用於協助設計師在各種創意領域中進行概念生成，例如平面設計、使用者介面設計和時尚設計。然而，由於模型在生成可行的設計概念影像時面臨挑戰，因此它們在工程設計中的應用仍然有限。為了解決這個問題，本文介紹了一種方法，透過使用可行的 CAD 影像提示生成，來改善設計的可行性。在這項工作中，透過使用現成的文本到影像模型 Stable Diffusion 2.1 進行自行車設計任務的案例研究，來探討這種方法的實用性。在七種不同的生成設定中，使用不同的 CAD 影像提示權重產生了多樣化的自行車設計，並針對這些設計的感知可行性和新穎性進行評估。結果表明，CAD 影像提示確實有助於像 Stable Diffusion 2.1 這樣的文本到影像模型建立出可見度更高的可行設計影像。雖然在可行性和新穎性之間觀察到了一般的權衡，但當提示權重保持在 0.35 左右的較低水準時，設計的可行性會顯著提升，而其新穎性則與僅由文字提示產生的設計保持一致。這個案例研究的見解為選擇適當的 CAD 影像提示權重以利於工程設計流程的不同階段提供了一些準則。當有效運用時，我們的 CAD 影像提示方法為文本到影像模型在工程設計中更廣泛的應用開啟了大門。

##### **Uncertainty Estimation of Large Language Models in Medical Question Answering**
2407.08662v1 by Jiaxin Wu, Yizhou Yu, Hong-Yu Zhou

Large Language Models (LLMs) show promise for natural language generation in
healthcare, but risk hallucinating factually incorrect information. Deploying
LLMs for medical question answering necessitates reliable uncertainty
estimation (UE) methods to detect hallucinations. In this work, we benchmark
popular UE methods with different model sizes on medical question-answering
datasets. Our results show that current approaches generally perform poorly in
this domain, highlighting the challenge of UE for medical applications. We also
observe that larger models tend to yield better results, suggesting a
correlation between model size and the reliability of UE. To address these
challenges, we propose Two-phase Verification, a probability-free Uncertainty
Estimation approach. First, an LLM generates a step-by-step explanation
alongside its initial answer, followed by formulating verification questions to
check the factual claims in the explanation. The model then answers these
questions twice: first independently, and then referencing the explanation.
Inconsistencies between the two sets of answers measure the uncertainty in the
original response. We evaluate our approach on three biomedical
question-answering datasets using Llama 2 Chat models and compare it against
the benchmarked baseline methods. The results show that our Two-phase
Verification method achieves the best overall accuracy and stability across
various datasets and model sizes, and its performance scales as the model size
increases.

摘要：大型語言模型 (LLM) 在醫療保健領域的自然語言生成方面顯示出前景，但存在虛構事實不正確資訊的風險。部署 LLM 來回答醫療問題需要可靠的不確定性估計 (UE) 方法來偵測虛構。在這項工作中，我們使用不同模型大小對熱門 UE 方法進行基準測試，針對醫療問題回答資料集。我們的結果顯示，目前的作法在這方面通常表現不佳，突顯了 UE 在醫療應用中的挑戰。我們還觀察到，較大的模型往往會產生更好的結果，這表明模型大小與 UE 的可靠性之間存在相關性。為了應對這些挑戰，我們提出了兩階段驗證，一種無機率的不確定性估計方法。首先，LLM 會在其初始答案旁邊產生逐步說明，然後制定驗證問題來檢查說明中的事實聲明。然後，模型回答這些問題兩次：第一次獨立回答，然後參考說明。兩組答案之間的不一致性衡量原始回應中的不確定性。我們使用 Llama 2 Chat 模型在三個生物醫學問題回答資料集上評估我們的作法，並將其與基準基準方法進行比較。結果顯示，我們的兩階段驗證方法在各種資料集和模型大小中實現了最佳的整體準確性和穩定性，並且其效能隨著模型大小的增加而擴展。

##### **Confidence-based Estimators for Predictive Performance in Model Monitoring**
2407.08649v1 by Juhani Kivimäki, Jakub Białek, Jukka K. Nurminen, Wojtek Kuberski

After a machine learning model has been deployed into production, its
predictive performance needs to be monitored. Ideally, such monitoring can be
carried out by comparing the model's predictions against ground truth labels.
For this to be possible, the ground truth labels must be available relatively
soon after inference. However, there are many use cases where ground truth
labels are available only after a significant delay, or in the worst case, not
at all. In such cases, directly monitoring the model's predictive performance
is impossible.
  Recently, novel methods for estimating the predictive performance of a model
when ground truth is unavailable have been developed. Many of these methods
leverage model confidence or other uncertainty estimates and are experimentally
compared against a naive baseline method, namely Average Confidence (AC), which
estimates model accuracy as the average of confidence scores for a given set of
predictions. However, until now the theoretical properties of the AC method
have not been properly explored. In this paper, we try to fill this gap by
reviewing the AC method and show that under certain general assumptions, it is
an unbiased and consistent estimator of model accuracy with many desirable
properties. We also compare this baseline estimator against some more complex
estimators empirically and show that in many cases the AC method is able to
beat the others, although the comparative quality of the different estimators
is heavily case-dependent.

摘要：在機器學習模型部署到生產環境後，需要監控其預測效能。理想情況下，這種監控可以透過將模型的預測與真實標籤進行比較來進行。為此，必須在推理後不久就能取得真實標籤。然而，有許多使用案例中的真實標籤只能在延遲一段時間後取得，或在最糟的情況下，根本無法取得。在這種情況下，直接監控模型的預測效能是不可能的。
最近，已經開發出新的方法來估計在沒有真實標籤時模型的預測效能。其中許多方法利用模型信心或其他不確定性估計，並針對一個簡單的基準方法進行實驗比較，也就是平均信心 (AC)，它將模型準確度估計為給定一組預測的信心分數平均值。然而，到目前為止，AC 方法的理論特性尚未得到適當的探討。在本文中，我們試圖透過檢視 AC 方法，並證明在某些一般假設下，它是一個無偏且一致的模型準確度估計器，具有許多理想的特性，來填補這個空白。我們也針對一些更複雜的估計器對這個基準估計器進行經驗比較，並證明在許多情況下，AC 方法能夠勝過其他方法，儘管不同估計器的比較品質高度依賴於案例。

##### **Towards Building Specialized Generalist AI with System 1 and System 2 Fusion**
2407.08642v1 by Kaiyan Zhang, Biqing Qi, Bowen Zhou

In this perspective paper, we introduce the concept of Specialized Generalist
Artificial Intelligence (SGAI or simply SGI) as a crucial milestone toward
Artificial General Intelligence (AGI). Compared to directly scaling general
abilities, SGI is defined as AI that specializes in at least one task,
surpassing human experts, while also retaining general abilities. This fusion
path enables SGI to rapidly achieve high-value areas. We categorize SGI into
three stages based on the level of mastery over professional skills and
generality performance. Additionally, we discuss the necessity of SGI in
addressing issues associated with large language models, such as their
insufficient generality, specialized capabilities, uncertainty in innovation,
and practical applications. Furthermore, we propose a conceptual framework for
developing SGI that integrates the strengths of Systems 1 and 2 cognitive
processing. This framework comprises three layers and four key components,
which focus on enhancing individual abilities and facilitating collaborative
evolution. We conclude by summarizing the potential challenges and suggesting
future directions. We hope that the proposed SGI will provide insights into
further research and applications towards achieving AGI.

摘要：<paragraph>在本文中，我們引入了專業通才人工智慧 (SGAI 或簡稱 SGI) 的概念，視為邁向人工通用智慧 (AGI) 的關鍵里程碑。與直接擴展一般能力相比，SGI 被定義為至少在一個任務中表現優於人類專家的 AI，同時也保留一般能力。這種融合路徑使 SGI 能夠快速實現高價值領域。我們根據對專業技能和一般性表現的掌握程度，將 SGI 分為三個階段。此外，我們討論了在解決與大型語言模型相關的問題（例如它們的普遍性不足、專業能力、創新中的不確定性和實際應用）中 SGI 的必要性。此外，我們提出了整合系統 1 和 2 認知處理優勢的 SGI 開發概念框架。此框架包含三層和四個關鍵組成部分，重點在於增強個人能力和促進協作演進。最後，我們總結了潛在挑戰並提出了未來的方向。我們希望提出的 SGI 能為進一步的研究和應用提供見解，以實現 AGI。</paragraph>

##### **$β$-DPO: Direct Preference Optimization with Dynamic $β$**
2407.08639v1 by Junkang Wu, Yuexiang Xie, Zhengyi Yang, Jiancan Wu, Jinyang Gao, Bolin Ding, Xiang Wang, Xiangnan He

Direct Preference Optimization (DPO) has emerged as a compelling approach for
training Large Language Models (LLMs) to adhere to human preferences. However,
the performance of DPO is sensitive to the fine-tuning of its trade-off
parameter $\beta$, as well as to the quality of the preference data. We analyze
the impact of $\beta$ and data quality on DPO, uncovering that optimal $\beta$
values vary with the informativeness of pairwise data. Addressing the
limitations of static $\beta$ values, we introduce a novel framework that
dynamically calibrates $\beta$ at the batch level, informed by data quality
considerations. Additionally, our method incorporates $\beta$-guided data
filtering to safeguard against the influence of outliers. Through empirical
evaluation, we demonstrate that our dynamic $\beta$ adjustment technique
significantly improves DPO's performance across a range of models and datasets,
offering a more robust and adaptable training paradigm for aligning LLMs with
human feedback. The code is available at
\url{https://github.com/junkangwu/beta-DPO}.

摘要：直接偏好最佳化 (DPO) 已成為訓練大型語言模型 (LLM) 以符合人類偏好的引人注目的方法。然而，DPO 的效能對其折衷參數 $\beta$ 的微調以及偏好資料的品質很敏感。我們分析了 $\beta$ 和資料品質對 DPO 的影響，發現最佳 $\beta$ 值會隨著成對資料的資訊量而有所不同。針對靜態 $\beta$ 值的限制，我們引入了在批次層級動態校準 $\beta$ 的新穎架構，並根據資料品質考量提供資訊。此外，我們的技術結合了 $\beta$ 引導資料過濾，以防止異常值的影響。透過實證評估，我們證明了我們的動態 $\beta$ 調整技術大幅改善了 DPO 在各種模型和資料集上的效能，為與人類回饋對齊 LLM 提供了更穩健且適應性更強的訓練範例。程式碼可在
\url{https://github.com/junkangwu/beta-DPO} 取得。

##### **Tamil Language Computing: the Present and the Future**
2407.08618v1 by Kengatharaiyer Sarveswaran

This paper delves into the text processing aspects of Language Computing,
which enables computers to understand, interpret, and generate human language.
Focusing on tasks such as speech recognition, machine translation, sentiment
analysis, text summarization, and language modelling, language computing
integrates disciplines including linguistics, computer science, and cognitive
psychology to create meaningful human-computer interactions. Recent
advancements in deep learning have made computers more accessible and capable
of independent learning and adaptation. In examining the landscape of language
computing, the paper emphasises foundational work like encoding, where Tamil
transitioned from ASCII to Unicode, enhancing digital communication. It
discusses the development of computational resources, including raw data,
dictionaries, glossaries, annotated data, and computational grammars, necessary
for effective language processing. The challenges of linguistic annotation, the
creation of treebanks, and the training of large language models are also
covered, emphasising the need for high-quality, annotated data and advanced
language models. The paper underscores the importance of building practical
applications for languages like Tamil to address everyday communication needs,
highlighting gaps in current technology. It calls for increased research
collaboration, digitization of historical texts, and fostering digital usage to
ensure the comprehensive development of Tamil language processing, ultimately
enhancing global communication and access to digital services.

摘要：這篇論文深入探討語言運算的文字處理面向，
讓電腦能夠理解、詮釋和產生人類語言。
專注於語音辨識、機器翻譯、情緒分析、文字摘要和語言建模等任務，語言運算
整合了語言學、電腦科學和認知心理學等領域，以創造有意義的人機互動。最近
深度學習的進展讓電腦更易於使用，並且能夠獨立學習和適應。在探討語言運算的領域時，這篇論文強調了基礎工作，例如編碼，其中淡米爾語
從 ASCII 轉換為 Unicode，增強了數位通訊。它討論了運算資源的發展，包括原始資料、
字典、詞彙表、註釋資料和運算文法，這些對於有效的語言處理是必要的。語言註釋的挑戰、樹庫的建立和大型語言模型的訓練也涵蓋在內，強調了對高品質、註釋資料和進階
語言模型的需求。這篇論文強調了建構實用的應用程式以滿足淡米爾語等語言的日常溝通需求的重要性，並強調了當前技術的差距。它呼籲加強研究合作、歷史文本的數位化和促進數位使用，以確保淡米爾語處理的全面發展，最終增強全球通訊和數位服務的取得。

##### **FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision**
2407.08608v1 by Jay Shah, Ganesh Bikshandi, Ying Zhang, Vijay Thakkar, Pradeep Ramani, Tri Dao

Attention, as a core layer of the ubiquitous Transformer architecture, is the
bottleneck for large language models and long-context applications.
FlashAttention elaborated an approach to speed up attention on GPUs through
minimizing memory reads/writes. However, it has yet to take advantage of new
capabilities present in recent hardware, with FlashAttention-2 achieving only
35% utilization on the H100 GPU. We develop three main techniques to speed up
attention on Hopper GPUs: exploiting asynchrony of the Tensor Cores and TMA to
(1) overlap overall computation and data movement via warp-specialization and
(2) interleave block-wise matmul and softmax operations, and (3) block
quantization and incoherent processing that leverages hardware support for FP8
low-precision. We demonstrate that our method, FlashAttention-3, achieves
speedup on H100 GPUs by 1.5-2.0$\times$ with FP16 reaching up to 740 TFLOPs/s
(75% utilization), and with FP8 reaching close to 1.2 PFLOPs/s. We validate
that FP8 FlashAttention-3 achieves 2.6$\times$ lower numerical error than a
baseline FP8 attention.

摘要：注意力，作為無處不在的 Transformer 架構的核心層，是大型語言模型和長語境應用程式的瓶頸。
FlashAttention 透過最小化記憶體讀取/寫入，闡述了一種在 GPU 上加速注意力的方法。然而，它尚未利用最新硬體中存在的新功能，而 FlashAttention-2 在 H100 GPU 上僅達到 35% 的利用率。我們開發了三種主要技術來加速 Hopper GPU 上的注意力：利用張量核心的異步性和 TMA 來 (1) 透過扭曲專門化重疊整體運算和資料移動，以及 (2) 交錯區塊矩陣乘法和 softmax 運算，以及 (3) 利用硬體對 FP8 低精度的支援來進行區塊量化和非相干處理。我們證明我們的 FlashAttention-3 方法，在 H100 GPU 上透過 FP16 達到 1.5-2.0 倍的加速，最高可達 740 TFLOP/s（75% 利用率），而透過 FP8 接近 1.2 PFLOP/s。我們驗證 FP8 FlashAttention-3 比基線 FP8 注意力獲得低 2.6 倍的數值誤差。

##### **Turn-Level Empathy Prediction Using Psychological Indicators**
2407.08607v1 by Shaz Furniturewala, Kokil Jaidka

For the WASSA 2024 Empathy and Personality Prediction Shared Task, we propose
a novel turn-level empathy detection method that decomposes empathy into six
psychological indicators: Emotional Language, Perspective-Taking, Sympathy and
Compassion, Extroversion, Openness, and Agreeableness. A pipeline of text
enrichment using a Large Language Model (LLM) followed by DeBERTA fine-tuning
demonstrates a significant improvement in the Pearson Correlation Coefficient
and F1 scores for empathy detection, highlighting the effectiveness of our
approach. Our system officially ranked 7th at the CONV-turn track.

摘要：對於 WASSA 2024 同理心與人格預測共享任務，我們提出了一種新穎的回合級同理心偵測方法，將同理心分解為六個心理指標：情緒語言、觀點採擇、同情與憐憫、外向性、開放性，以及親和性。使用大型語言模型 (LLM) 進行文本豐富化，接著進行 DeBERTA 微調的管線，在同理心偵測的 Pearson 相關係數和 F1 得分方面顯著提升，突顯了我們方法的有效性。我們的系統在 CONV-turn 軌道中正式排名第 7。

##### **The Synergy between Data and Multi-Modal Large Language Models: A Survey from Co-Development Perspective**
2407.08583v1 by Zhen Qin, Daoyuan Chen, Wenhao Zhang, Liuyi Yao, Yilun Huang, Bolin Ding, Yaliang Li, Shuiguang Deng

The rapid development of large language models (LLMs) has been witnessed in
recent years. Based on the powerful LLMs, multi-modal LLMs (MLLMs) extend the
modality from text to a broader spectrum of domains, attracting widespread
attention due to the broader range of application scenarios. As LLMs and MLLMs
rely on vast amounts of model parameters and data to achieve emergent
capabilities, the importance of data is receiving increasingly widespread
attention and recognition. Tracing and analyzing recent data-oriented works for
MLLMs, we find that the development of models and data is not two separate
paths but rather interconnected. On the one hand, vaster and higher-quality
data contribute to better performance of MLLMs, on the other hand, MLLMs can
facilitate the development of data. The co-development of multi-modal data and
MLLMs requires a clear view of 1) at which development stage of MLLMs can
specific data-centric approaches be employed to enhance which capabilities, and
2) by utilizing which capabilities and acting as which roles can models
contribute to multi-modal data. To promote the data-model co-development for
MLLM community, we systematically review existing works related to MLLMs from
the data-model co-development perspective. A regularly maintained project
associated with this survey is accessible at
https://github.com/modelscope/data-juicer/blob/main/docs/awesome_llm_data.md.

摘要：<paragraph>近年來見證了大型語言模型 (LLM) 的快速發展。基於強大的 LLM，多模態 LLM (MLLM) 將模態從文本擴展到更廣泛的領域，由於應用場景更廣泛，因此備受關注。由於 LLM 和 MLLM 依賴大量的模型參數和資料才能實現新興能力，因此資料的重要性越來越受到廣泛關注和認可。追蹤和分析針對 MLLM 的最新資料導向工作，我們發現模型和資料的發展並非兩條獨立的道路，而是相互關聯的。一方面，更大且品質更高的資料有助於提升 MLLM 的效能，另一方面，MLLM 可以促進資料的發展。多模態資料和 MLLM 的共同開發需要明確了解 1) 在 MLLM 的哪個開發階段可以採用特定的資料中心方法來增強哪些能力，以及 2) 模型可以利用哪些能力並扮演哪些角色來貢獻多模態資料。為了促進 MLLM 社群的資料模型共同開發，我們從資料模型共同開發的角度系統性地回顧與 MLLM 相關的現有工作。與這項調查相關的定期維護專案可於 https://github.com/modelscope/data-juicer/blob/main/docs/awesome_llm_data.md 取得。</paragraph>

##### **On the Universal Truthfulness Hyperplane Inside LLMs**
2407.08582v1 by Junteng Liu, Shiqi Chen, Yu Cheng, Junxian He

While large language models (LLMs) have demonstrated remarkable abilities
across various fields, hallucination remains a significant challenge. Recent
studies have explored hallucinations through the lens of internal
representations, proposing mechanisms to decipher LLMs' adherence to facts.
However, these approaches often fail to generalize to out-of-distribution data,
leading to concerns about whether internal representation patterns reflect
fundamental factual awareness, or only overfit spurious correlations on the
specific datasets. In this work, we investigate whether a universal
truthfulness hyperplane that distinguishes the model's factually correct and
incorrect outputs exists within the model. To this end, we scale up the number
of training datasets and conduct an extensive evaluation -- we train the
truthfulness hyperplane on a diverse collection of over 40 datasets and examine
its cross-task, cross-domain, and in-domain generalization. Our results
indicate that increasing the diversity of the training datasets significantly
enhances the performance in all scenarios, while the volume of data samples
plays a less critical role. This finding supports the optimistic hypothesis
that a universal truthfulness hyperplane may indeed exist within the model,
offering promising directions for future research.

摘要：儘管大型語言模型 (LLM) 已在各個領域展現出卓越的能力，但幻覺仍是一項嚴峻的挑戰。最近的研究透過內部表徵的觀點探討幻覺，提出機制來解碼 LLM 對事實的堅持。然而，這些方法通常無法廣泛化到分佈外資料，導致人們擔憂內部表徵模式是否反映了基本的現實意識，或僅過度擬合特定資料集上的虛假關聯。在這項工作中，我們探討模型內是否存在一個通用的真實性超平面，用以區分模型的事實正確輸出和不正確輸出。為此，我們擴大了訓練資料集的數量並進行廣泛評估——我們在超過 40 個資料集的多元集合上訓練真實性超平面，並檢查其跨任務、跨領域和領域內廣義化。我們的結果表明，增加訓練資料集的多樣性會顯著提升所有場景中的效能，而資料樣本的數量則扮演較不重要的角色。此發現支持樂觀的假設，即模型內可能確實存在一個通用的真實性超平面，為未來的研究提供了有前景的方向。

##### **The Career Interests of Large Language Models**
2407.08564v1 by Meng Hua, Yuan Cheng, Hengshu Zhu

Recent advancements in Large Language Models (LLMs) have significantly
extended their capabilities, evolving from basic text generation to complex,
human-like interactions. In light of the possibilities that LLMs could assume
significant workplace responsibilities, it becomes imminently necessary to
explore LLMs' capacities as professional assistants. This study focuses on the
aspect of career interests by applying the Occupation Network's Interest
Profiler short form to LLMs as if they were human participants and investigates
their hypothetical career interests and competence, examining how these vary
with language changes and model advancements. We analyzed the answers using a
general linear mixed model approach and found distinct career interest
inclinations among LLMs, particularly towards the social and artistic domains.
Interestingly, these preferences did not align with the occupations where LLMs
exhibited higher competence. This novel approach of using psychometric
instruments and sophisticated statistical tools on LLMs unveils fresh
perspectives on their integration into professional environments, highlighting
human-like tendencies and promoting a reevaluation of LLMs' self-perception and
competency alignment in the workforce.

摘要：大型語言模型 (LLM) 的最新進展顯著擴展了它們的能力，從基本的文字生成演變到複雜的人類互動。鑑於 LLM 可能承擔重大工作場所責任的可能性，迫切需要探索 LLM 作為專業助理的能力。本研究重點關注職業興趣方面，將職業網絡的興趣分析器簡表應用於 LLM，就像它們是人類參與者一樣，並調查它們的假設職業興趣和能力，探討這些興趣和能力如何隨著語言變化和模型進步而變化。我們使用一般線性混合模型方法分析答案，並發現 LLM 之間有不同的職業興趣傾向，特別是對社會和藝術領域。有趣的是，這些偏好與 LLM 表現出較高能力的職業並不一致。這種在 LLM 上使用心理測量工具和複雜統計工具的新穎方法揭示了它們融入專業環境的新觀點，突出了類人的傾向，並促進了重新評估 LLM 在勞動力中的自我認知和能力一致性。

##### **Vox Populi, Vox AI? Using Language Models to Estimate German Public Opinion**
2407.08563v1 by Leah von der Heyde, Anna-Carolina Haensch, Alexander Wenz

The recent development of large language models (LLMs) has spurred
discussions about whether LLM-generated "synthetic samples" could complement or
replace traditional surveys, considering their training data potentially
reflects attitudes and behaviors prevalent in the population. A number of
mostly US-based studies have prompted LLMs to mimic survey respondents, with
some of them finding that the responses closely match the survey data. However,
several contextual factors related to the relationship between the respective
target population and LLM training data might affect the generalizability of
such findings. In this study, we investigate the extent to which LLMs can
estimate public opinion in Germany, using the example of vote choice. We
generate a synthetic sample of personas matching the individual characteristics
of the 2017 German Longitudinal Election Study respondents. We ask the LLM
GPT-3.5 to predict each respondent's vote choice and compare these predictions
to the survey-based estimates on the aggregate and subgroup levels. We find
that GPT-3.5 does not predict citizens' vote choice accurately, exhibiting a
bias towards the Green and Left parties. While the LLM captures the tendencies
of "typical" voter subgroups, such as partisans, it misses the multifaceted
factors swaying individual voter choices. By examining the LLM-based prediction
of voting behavior in a new context, our study contributes to the growing body
of research about the conditions under which LLMs can be leveraged for studying
public opinion. The findings point to disparities in opinion representation in
LLMs and underscore the limitations in applying them for public opinion
estimation.

摘要：<paragraph>大型語言模型 (LLM) 近期發展，引發了關於 LLM 生成的「合成樣本」能否補充或取代傳統調查的討論，考慮到其訓練資料可能反映了在人口中普遍存在的態度和行為。許多主要以美國為基礎的研究促使 LLM 模仿調查受訪者，其中一些研究發現，回應與調查資料非常吻合。然而，與各自目標族群和 LLM 訓練資料之間相關的幾個情境因素，可能會影響此類發現的概括性。在本研究中，我們探討 LLM 在何種程度上可以估計德國的民意，並以投票選擇為例。我們產生了一個合成樣本的人物，其個人特徵與 2017 年德國縱向選舉研究受訪者相符。我們要求 LLM GPT-3.5 預測每個受訪者的投票選擇，並將這些預測與在總體和子群層級上的基於調查的估計值進行比較。我們發現 GPT-3.5 無法準確預測公民的投票選擇，表現出對綠黨和左派的偏見。雖然 LLM 捕捉到了「典型」選民子群的傾向，例如黨派人士，但它錯失了影響個別選民選擇的多方面因素。透過檢視 LLM 為基礎的投票行為預測，在一個新的情境中，我們的研究有助於越來越多的研究，探討在哪些條件下可以利用 LLM 來研究民意。這些發現指出 LLM 中意見代表性的差異，並強調了在民意估計中應用 LLM 的限制。</paragraph>

##### **ST-Mamba: Spatial-Temporal Mamba for Traffic Flow Estimation Recovery using Limited Data**
2407.08558v1 by Doncheng Yuan, Jianzhe Xue, Jinshan Su, Wenchao Xu, Haibo Zhou

Traffic flow estimation (TFE) is crucial for urban intelligent traffic
systems. While traditional on-road detectors are hindered by limited coverage
and high costs, cloud computing and data mining of vehicular network data, such
as driving speeds and GPS coordinates, present a promising and cost-effective
alternative. Furthermore, minimizing data collection can significantly reduce
overhead. However, limited data can lead to inaccuracies and instability in
TFE. To address this, we introduce the spatial-temporal Mamba (ST-Mamba), a
deep learning model combining a convolutional neural network (CNN) with a Mamba
framework. ST-Mamba is designed to enhance TFE accuracy and stability by
effectively capturing the spatial-temporal patterns within traffic flow. Our
model aims to achieve results comparable to those from extensive data sets
while only utilizing minimal data. Simulations using real-world datasets have
validated our model's ability to deliver precise and stable TFE across an urban
landscape based on limited data, establishing a cost-efficient solution for
TFE.

摘要：交通流量估計 (TFE) 對於城市智慧交通系統至關重要。雖然傳統的道路偵測器受到覆蓋範圍有限和成本高的阻礙，但雲端運算和車輛網路資料的資料探勘，例如行駛速度和 GPS 座標，提供了一個有前途且具有成本效益的替代方案。此外，最小化資料收集可以大幅減少開銷。然而，有限的資料可能會導致 TFE 的不準確性和不穩定性。為了解決這個問題，我們引入了時空 Mamba (ST-Mamba)，這是一個結合了卷積神經網路 (CNN) 和 Mamba 框架的深度學習模型。ST-Mamba 旨在透過有效擷取交通流量中的時空模式來增強 TFE 的準確性和穩定性。我們的模型旨在達成與廣泛資料集相當的結果，同時僅使用最少的資料。使用真實世界資料集的模擬驗證了我們的模型在基於有限資料的城市景觀中提供精確且穩定的 TFE 的能力，為 TFE 建立了一個具有成本效益的解決方案。

##### **Establishing Rigorous and Cost-effective Clinical Trials for Artificial Intelligence Models**
2407.08554v1 by Wanling Gao, Yunyou Huang, Dandan Cui, Zhuoming Yu, Wenjing Liu, Xiaoshuang Liang, Jiahui Zhao, Jiyue Xie, Hao Li, Li Ma, Ning Ye, Yumiao Kang, Dingfeng Luo, Peng Pan, Wei Huang, Zhongmou Liu, Jizhong Hu, Gangyuan Zhao, Chongrong Jiang, Fan Huang, Tianyi Wei, Suqin Tang, Bingjie Xia, Zhifei Zhang, Jianfeng Zhan

A profound gap persists between artificial intelligence (AI) and clinical
practice in medicine, primarily due to the lack of rigorous and cost-effective
evaluation methodologies. State-of-the-art and state-of-the-practice AI model
evaluations are limited to laboratory studies on medical datasets or direct
clinical trials with no or solely patient-centered controls. Moreover, the
crucial role of clinicians in collaborating with AI, pivotal for determining
its impact on clinical practice, is often overlooked. For the first time, we
emphasize the critical necessity for rigorous and cost-effective evaluation
methodologies for AI models in clinical practice, featuring
patient/clinician-centered (dual-centered) AI randomized controlled trials
(DC-AI RCTs) and virtual clinician-based in-silico trials (VC-MedAI) as an
effective proxy for DC-AI RCTs. Leveraging 7500 diagnosis records from
two-phase inaugural DC-AI RCTs across 14 medical centers with 125 clinicians,
our results demonstrate the necessity of DC-AI RCTs and the effectiveness of
VC-MedAI. Notably, VC-MedAI performs comparably to human clinicians,
replicating insights and conclusions from prospective DC-AI RCTs. We envision
DC-AI RCTs and VC-MedAI as pivotal advancements, presenting innovative and
transformative evaluation methodologies for AI models in clinical practice,
offering a preclinical-like setting mirroring conventional medicine, and
reshaping development paradigms in a cost-effective and fast-iterative manner.
Chinese Clinical Trial Registration: ChiCTR2400086816.

摘要：<paragraph>人工智慧（AI）與臨床醫療實務之間存在著巨大的鴻溝，其主要原因在於缺乏嚴謹且具成本效益的評估方法。最先進且符合實務的 AI 模型評估僅限於針對醫學資料集進行的實驗室研究，或僅有患者為中心的對照組的直接臨床試驗。此外，臨床醫師在與 AI 合作中所扮演的關鍵角色，對於決定其對臨床實務的影響至關重要，卻經常被忽視。我們首度強調在臨床實務中採用嚴謹且具成本效益的 AI 模型評估方法至關重要，其特色在於以患者／臨床醫師為中心的（雙中心）AI 隨機對照試驗（DC-AI RCT）和虛擬臨床醫師為基礎的電腦模擬試驗（VC-MedAI），做為 DC-AI RCT 的有效替代方案。利用來自 14 個醫療中心、125 位臨床醫師的兩階段首次 DC-AI RCT 中的 7500 筆診斷紀錄，我們的結果證明了 DC-AI RCT 的必要性與 VC-MedAI 的有效性。值得注意的是，VC-MedAI 的表現與人類臨床醫師相當，複製了前瞻性 DC-AI RCT 的見解和結論。我們將 DC-AI RCT 和 VC-MedAI 視為關鍵的進展，它們提出了創新且具有變革性的 AI 模型評估方法，在臨床實務中提供類似於臨床前設定的環境，反映傳統醫學，並以具成本效益且快速反覆運算的方式重新塑造開發模式。中國臨床試驗註冊：ChiCTR2400086816。</paragraph>

##### **Autoregressive Speech Synthesis without Vector Quantization**
2407.08551v1 by Lingwei Meng, Long Zhou, Shujie Liu, Sanyuan Chen, Bing Han, Shujie Hu, Yanqing Liu, Jinyu Li, Sheng Zhao, Xixin Wu, Helen Meng, Furu Wei

We present MELLE, a novel continuous-valued tokens based language modeling
approach for text to speech synthesis (TTS). MELLE autoregressively generates
continuous mel-spectrogram frames directly from text condition, bypassing the
need for vector quantization, which are originally designed for audio
compression and sacrifice fidelity compared to mel-spectrograms. Specifically,
(i) instead of cross-entropy loss, we apply regression loss with a proposed
spectrogram flux loss function to model the probability distribution of the
continuous-valued tokens. (ii) we have incorporated variational inference into
MELLE to facilitate sampling mechanisms, thereby enhancing the output diversity
and model robustness. Experiments demonstrate that, compared to the two-stage
codec language models VALL-E and its variants, the single-stage MELLE mitigates
robustness issues by avoiding the inherent flaws of sampling discrete codes,
achieves superior performance across multiple metrics, and, most importantly,
offers a more streamlined paradigm. See https://aka.ms/melle for demos of our
work.

摘要：我們提出了 MELLE，一種基於連續值符號的新穎語言模型化方法，用於文字轉語音合成 (TTS)。MELLE 自迴歸地直接從文字條件生成連續的 Mel 頻譜圖幀，繞過了原本設計用於音訊壓縮且與 Mel 頻譜圖相比犧牲了保真度的向量量化需求。具體來說，(i) 我們應用回歸損失，並提出了建議的頻譜圖通量損失函數來建模連續值符號的機率分佈，而不是交叉熵損失。(ii) 我們已將變異推論納入 MELLE，以促進抽樣機制，從而增強輸出多樣性和模型穩健性。實驗證明，與兩階段編解碼器語言模型 VALL-E 及其變體相比，單階段 MELLE 透過避免抽樣離散碼的固有缺陷來減輕穩健性問題，在多項指標上均達到卓越的效能，而且最重要的是，提供更簡化的範例。請參閱 https://aka.ms/melle，瞭解我們工作的示範。

##### **Incorporating Large Language Models into Production Systems for Enhanced Task Automation and Flexibility**
2407.08550v1 by Yuchen Xia, Jize Zhang, Nasser Jazdi, Michael Weyrich

This paper introduces a novel approach to integrating large language model
(LLM) agents into automated production systems, aimed at enhancing task
automation and flexibility. We organize production operations within a
hierarchical framework based on the automation pyramid. Atomic operation
functionalities are modeled as microservices, which are executed through
interface invocation within a dedicated digital twin system. This allows for a
scalable and flexible foundation for orchestrating production processes. In
this digital twin system, low-level, hardware-specific data is semantically
enriched and made interpretable for LLMs for production planning and control
tasks. Large language model agents are systematically prompted to interpret
these production-specific data and knowledge. Upon receiving a user request or
identifying a triggering event, the LLM agents generate a process plan. This
plan is then decomposed into a series of atomic operations, executed as
microservices within the real-world automation system. We implement this
overall approach on an automated modular production facility at our laboratory,
demonstrating how the LLMs can handle production planning and control tasks
through a concrete case study. This results in an intuitive production facility
with higher levels of task automation and flexibility. Finally, we reveal the
several limitations in realizing the full potential of the large language
models in autonomous systems and point out promising benefits. Demos of this
series of ongoing research series can be accessed at:
https://github.com/YuchenXia/GPT4IndustrialAutomation

摘要：這篇論文介紹一種新穎的方法，將大型語言模型 (LLM) 代理整合到自動化生產系統中，旨在增強任務自動化和靈活性。我們在基於自動化金字塔的分層架構中組織生產作業。原子操作功能被建模成微服務，這些微服務通過專用數位雙胞胎系統中的介面呼叫來執行。這為編排生產流程提供了可擴充且彈性的基礎。在此數位雙胞胎系統中，低階、特定於硬體的資料會被語意化豐富化，並讓 LLM 能夠詮釋，以進行生產規劃和控制任務。大型語言模型代理會被系統性地提示，以詮釋這些特定於生產的資料和知識。在收到使用者要求或識別觸發事件後，LLM 代理會產生流程計畫。然後，此計畫會分解成一系列原子操作，並在真實世界的自動化系統中以微服務的形式執行。我們在實驗室的自動化模組化生產設施中實作此整體方法，並透過具體案例研究展示 LLM 如何處理生產規劃和控制任務。這會產生一個直覺式的生產設施，並具有更高層級的任務自動化和靈活性。最後，我們揭露了在自體系統中實現大型語言模型全部潛力的若干限制，並指出有希望的好處。可以透過以下網址存取這個持續研究系列的展示：
https://github.com/YuchenXia/GPT4IndustrialAutomation

##### **Emergent Visual-Semantic Hierarchies in Image-Text Representations**
2407.08521v1 by Morris Alper, Hadar Averbuch-Elor

While recent vision-and-language models (VLMs) like CLIP are a powerful tool
for analyzing text and images in a shared semantic space, they do not
explicitly model the hierarchical nature of the set of texts which may describe
an image. Conversely, existing multimodal hierarchical representation learning
methods require costly training from scratch, failing to leverage the knowledge
encoded by state-of-the-art multimodal foundation models. In this work, we
study the knowledge of existing foundation models, finding that they exhibit
emergent understanding of visual-semantic hierarchies despite not being
directly trained for this purpose. We propose the Radial Embedding (RE)
framework for probing and optimizing hierarchical understanding, and contribute
the HierarCaps dataset, a benchmark facilitating the study of hierarchical
knowledge in image--text representations, constructed automatically via large
language models. Our results show that foundation VLMs exhibit zero-shot
hierarchical understanding, surpassing the performance of prior models
explicitly designed for this purpose. Furthermore, we show that foundation
models may be better aligned to hierarchical reasoning via a text-only
fine-tuning phase, while retaining pretraining knowledge.

摘要：雖然像 CLIP 等最近的視覺語言模型 (VLM) 是用於在共享語義空間中分析文字和影像的強大工具，但它們並未明確建模可能描述影像的文字集合的層級性質。相反地，現有的多模態層級表徵學習方法需要從頭開始進行昂貴的訓練，無法利用由最先進的多模態基礎模型編碼的知識。在這項工作中，我們研究了現有基礎模型的知識，發現它們表現出對視覺語義層級的理解，儘管並未直接針對此目的進行訓練。我們提出了徑向嵌入 (RE) 框架，用於探測和最佳化層級理解，並貢獻了 HierarCaps 資料集，這是一個基於大型語言模型自動建構的基準，促進了對影像文字表徵中層級知識的研究。我們的結果顯示，基礎 VLM 表現出零次學習的層級理解，超越了先前專門為此目的設計的模型的效能。此外，我們顯示基礎模型可能會透過僅文字的微調階段與層級推理更好地對齊，同時保留預訓練知識。

##### **Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents**
2407.08516v1 by Haoyi Xiong, Zhiyuan Wang, Xuhong Li, Jiang Bian, Zeke Xie, Shahid Mumtaz, Laura E. Barnes

This article explores the convergence of connectionist and symbolic
artificial intelligence (AI), from historical debates to contemporary
advancements. Traditionally considered distinct paradigms, connectionist AI
focuses on neural networks, while symbolic AI emphasizes symbolic
representation and logic. Recent advancements in large language models (LLMs),
exemplified by ChatGPT and GPT-4, highlight the potential of connectionist
architectures in handling human language as a form of symbols. The study argues
that LLM-empowered Autonomous Agents (LAAs) embody this paradigm convergence.
By utilizing LLMs for text-based knowledge modeling and representation, LAAs
integrate neuro-symbolic AI principles, showcasing enhanced reasoning and
decision-making capabilities. Comparing LAAs with Knowledge Graphs within the
neuro-symbolic AI theme highlights the unique strengths of LAAs in mimicking
human-like reasoning processes, scaling effectively with large datasets, and
leveraging in-context samples without explicit re-training. The research
underscores promising avenues in neuro-vector-symbolic integration,
instructional encoding, and implicit reasoning, aimed at further enhancing LAA
capabilities. By exploring the progression of neuro-symbolic AI and proposing
future research trajectories, this work advances the understanding and
development of AI technologies.

摘要：這篇文章探討了連接主義與符號人工智慧 (AI) 的匯流，從歷史辯論到當代進展。傳統上被認為是不同的典範，連接主義 AI 專注於神經網路，而符號 AI 則強調符號表徵與邏輯。大型語言模型 (LLM) 的最新進展，以 ChatGPT 和 GPT-4 為例，突顯了連接主義架構在將人類語言視為符號形式處理的潛力。該研究論證，由 LLM 賦能的自主代理 (LAA) 體現了這種典範的匯流。透過利用 LLM 進行基於文字的知識建模與表徵，LAA 整合了神經符號 AI 原則，展示增強的推理和決策能力。在神經符號 AI 主題中將 LAA 與知識圖譜進行比較，突顯了 LAA 在模擬類人推理過程、有效擴充大型資料集以及在沒有明確重新訓練的情況下利用情境範例中的獨特優勢。該研究強調了神經向量符號整合、指令編碼和隱式推理中具有前景的途徑，旨在進一步增強 LAA 的能力。透過探討神經符號 AI 的進展並提出未來的研究軌跡，這項研究推動了對 AI 技術的理解和發展。

##### **15M Multimodal Facial Image-Text Dataset**
2407.08515v1 by Dawei Dai, YuTang Li, YingGe Liu, Mingming Jia, Zhang YuanHui, Guoyin Wang

Currently, image-text-driven multi-modal deep learning models have
demonstrated their outstanding potential in many fields. In practice, tasks
centered around facial images have broad application prospects. This paper
presents \textbf{FaceCaption-15M}, a large-scale, diverse, and high-quality
dataset of facial images accompanied by their natural language descriptions
(facial image-to-text). This dataset aims to facilitate a study on
face-centered tasks. FaceCaption-15M comprises over 15 million pairs of facial
images and their corresponding natural language descriptions of facial
features, making it the largest facial image-caption dataset to date. We
conducted a comprehensive analysis of image quality, text naturalness, text
complexity, and text-image relevance to demonstrate the superiority of
FaceCaption-15M. To validate the effectiveness of FaceCaption-15M, we first
trained a facial language-image pre-training model (FLIP, similar to CLIP) to
align facial image with its corresponding captions in feature space.
Subsequently, using both image and text encoders and fine-tuning only the
linear layer, our FLIP-based models achieved state-of-the-art results on two
challenging face-centered tasks. The purpose is to promote research in the
field of face-related tasks through the availability of the proposed
FaceCaption-15M dataset. All data, codes, and models are publicly available.
https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaption-15M

摘要：<paragraph>目前，图像文本驱动的多模态深度学习模型已在众多领域展示了其卓越的潜力。在实践中，以面部图像为中心的任务具有广泛的应用前景。本文提出了\textbf{FaceCaption-15M}，这是一个大规模、多样化且高质量的面部图像数据集，并附有其自然语言描述（面部图像到文本）。此数据集旨在促进对以面部为中心的任务的研究。FaceCaption-15M 包含超过 1500 万对面部图像及其对应面部特征的自然语言描述，使其成为迄今为止最大的面部图像标题数据集。我们对图像质量、文本自然性、文本复杂性和文本图像相关性进行了全面分析，以证明 FaceCaption-15M 的优越性。为了验证 FaceCaption-15M 的有效性，我们首先训练了一个面部语言图像预训练模型 (FLIP，类似于 CLIP)，以在特征空间中将面部图像与其对应的标题对齐。随后，使用图像和文本编码器并仅微调线性层，我们基于 FLIP 的模型在两项具有挑战性的以面部为中心的任务上取得了最先进的结果。目的是通过提供建议的 FaceCaption-15M 数据集来促进面部相关任务领域的研究。所有数据、代码和模型均公开可用。https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaption-15M</paragraph>

##### **Latent Conditional Diffusion-based Data Augmentation for Continuous-Time Dynamic Graph Mode**
2407.08500v1 by Yuxing Tian, Yiyan Qi, Aiwen Jiang, Qi Huang, Jian Guo

Continuous-Time Dynamic Graph (CTDG) precisely models evolving real-world
relationships, drawing heightened interest in dynamic graph learning across
academia and industry. However, existing CTDG models encounter challenges
stemming from noise and limited historical data. Graph Data Augmentation (GDA)
emerges as a critical solution, yet current approaches primarily focus on
static graphs and struggle to effectively address the dynamics inherent in
CTDGs. Moreover, these methods often demand substantial domain expertise for
parameter tuning and lack theoretical guarantees for augmentation efficacy. To
address these issues, we propose Conda, a novel latent diffusion-based GDA
method tailored for CTDGs. Conda features a sandwich-like architecture,
incorporating a Variational Auto-Encoder (VAE) and a conditional diffusion
model, aimed at generating enhanced historical neighbor embeddings for target
nodes. Unlike conventional diffusion models trained on entire graphs via
pre-training, Conda requires historical neighbor sequence embeddings of target
nodes for training, thus facilitating more targeted augmentation. We integrate
Conda into the CTDG model and adopt an alternating training strategy to
optimize performance. Extensive experimentation across six widely used
real-world datasets showcases the consistent performance improvement of our
approach, particularly in scenarios with limited historical data.

摘要：連續時間動態圖 (CTDG) 精確地模擬了演化的真實世界關係，引起了學術界和產業對動態圖學習的高度興趣。然而，現有的 CTDG 模型會遇到源自於雜訊和有限歷史資料的挑戰。圖資料擴充 (GDA) 成為了一個關鍵的解決方案，但目前的做法主要專注於靜態圖，並難以有效地解決 CTDG 中固有的動態問題。此外，這些方法通常需要大量的領域專業知識來進行參數調整，並且缺乏理論保證來確保擴充的效能。為了解決這些問題，我們提出了 Conda，這是一種針對 CTDG 量身打造的新型潛在擴散式 GDA 方法。Conda 採用三明治式的架構，結合了變異自動編碼器 (VAE) 和條件擴散模型，旨在為目標節點產生增強的歷史鄰居嵌入。與透過預訓練在整個圖上訓練的傳統擴散模型不同，Conda 需要目標節點的歷史鄰居序列嵌入來進行訓練，從而促進更具針對性的擴充。我們將 Conda 整合到 CTDG 模型中，並採用交替訓練策略來最佳化效能。在六個廣泛使用的真實世界資料集上進行的廣泛實驗，展示了我們的方法一致的效能提升，特別是在歷史資料有限的情況下。

##### **Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024**
2407.08495v1 by Ilias Chalkidis

Instruction-finetuned Large Language Models exhibit unprecedented Natural
Language Understanding capabilities. Recent work has been exploring political
biases and political reasoning capabilities in LLMs, mainly scoped in the US
context. In light of the recent 2024 European Parliament elections, we are
investigating if LLMs can be used as Voting Advice Applications (VAAs). We
audit MISTRAL and MIXTRAL models and evaluate their accuracy in predicting the
stance of political parties based on the latest "EU and I" voting assistance
questionnaire. Furthermore, we explore alternatives to improve models'
performance by augmenting the input context via Retrieval-Augmented Generation
(RAG) relying on web search, and Self-Reflection using staged conversations
that aim to re-collect relevant content from the model's internal memory. We
find that MIXTRAL is highly accurate with an 82% accuracy on average.
Augmenting the input context with expert-curated information can lead to a
significant boost of approx. 9%, which remains an open challenge for automated
approaches.

摘要：經過指令微調的大型語言模型展現出前所未有的自然語言理解能力。最近的研究探索了大型語言模型的政治偏見和政治推理能力，主要集中在美國的背景下。鑑於最近 2024 年歐洲議會選舉，我們正在調查大型語言模型是否可用作投票建議應用程式 (VAA)。我們審查 MISTRAL 和 MIXTRAL 模型，並根據最新的「歐盟和我」投票協助問卷評估它們在預測政黨立場方面的準確性。此外，我們探索了通過檢索增強生成 (RAG)（依賴網路搜尋）和使用旨在從模型內部記憶體重新收集相關內容的分階段對話的自省來擴充輸入內容以改善模型效能的替代方案。我們發現 MIXTRAL 非常準確，平均準確度為 82%。使用專家策劃的資訊擴充輸入內容可能會導致約 9% 的顯著提升，這對於自動化方法來說仍然是一個公開的挑戰。

##### **Lynx: An Open Source Hallucination Evaluation Model**
2407.08488v1 by Selvan Sunitha Ravi, Bartosz Mielczarek, Anand Kannappan, Douwe Kiela, Rebecca Qian

Retrieval Augmented Generation (RAG) techniques aim to mitigate
hallucinations in Large Language Models (LLMs). However, LLMs can still produce
information that is unsupported or contradictory to the retrieved contexts. We
introduce LYNX, a SOTA hallucination detection LLM that is capable of advanced
reasoning on challenging real-world hallucination scenarios. To evaluate LYNX,
we present HaluBench, a comprehensive hallucination evaluation benchmark,
consisting of 15k samples sourced from various real-world domains. Our
experiment results show that LYNX outperforms GPT-4o, Claude-3-Sonnet, and
closed and open-source LLM-as-a-judge models on HaluBench. We release LYNX,
HaluBench and our evaluation code for public access.

摘要：檢索增強生成（RAG）技術旨在減輕大型語言模型（LLM）中的幻覺。然而，LLM 仍然會產生不受支持或與檢索的背景相矛盾的資訊。我們介紹 LYNX，一種 SOTA 幻覺偵測 LLM，它能夠對具有挑戰性的真實世界幻覺場景進行高級推理。為了評估 LYNX，我們提出了 HaluBench，一個全面的幻覺評估基準，由來自各種真實世界領域的 15k 個範例組成。我們的實驗結果表明，LYNX 在 HaluBench 上優於 GPT-4o、Claude-3-Sonnet，以及封閉和開放原始碼 LLM 作為評審模型。我們釋出 LYNX、HaluBench 和我們的評估程式碼供公眾使用。

##### **Investigating Public Fine-Tuning Datasets: A Complex Review of Current Practices from a Construction Perspective**
2407.08475v1 by Runyuan Ma, Wei Li, Fukai Shang

With the rapid development of the large model domain, research related to
fine-tuning has concurrently seen significant advancement, given that
fine-tuning is a constituent part of the training process for large-scale
models. Data engineering plays a fundamental role in the training process of
models, which includes data infrastructure, data processing, etc. Data during
fine-tuning likewise forms the base for large models. In order to embrace the
power and explore new possibilities of fine-tuning datasets, this paper reviews
current public fine-tuning datasets from the perspective of data construction.
An overview of public fine-tuning datasets from two sides: evolution and
taxonomy, is provided in this review, aiming to chart the development
trajectory. Construction techniques and methods for public fine-tuning datasets
of Large Language Models (LLMs), including data generation and data
augmentation among others, are detailed. This elaboration follows the
aforementioned taxonomy, specifically across demonstration, comparison, and
generalist categories. Additionally, a category tree of data generation
techniques has been abstracted in our review to assist researchers in gaining a
deeper understanding of fine-tuning datasets from the construction dimension.
Our review also summarizes the construction features in different data
preparation phases of current practices in this field, aiming to provide a
comprehensive overview and inform future research. Fine-tuning dataset
practices, encompassing various data modalities, are also discussed from a
construction perspective in our review. Towards the end of the article, we
offer insights and considerations regarding the future construction and
developments of fine-tuning datasets.

摘要：<paragraph>隨著大型模型領域的快速發展，與微調相關的研究也取得了顯著進展，因為微調是大型模型訓練過程的組成部分。資料工程在模型的訓練過程中扮演著基礎性的角色，其中包括資料基礎設施、資料處理等。微調期間的資料同樣構成了大型模型的基礎。為了擁抱微調資料集的力量並探索新的可能性，本文從資料構建的角度回顧了當前公開的微調資料集。本文從演進和分類兩個方面概述了公開微調資料集，旨在描繪其發展軌跡。詳細介紹了大型語言模型 (LLM) 的公開微調資料集的構建技術和方法，包括資料生成和資料擴充等。這種闡述遵循上述分類法，特別是在示範、比較和通才類別中。此外，本文還抽象了一個資料生成技術的類別樹，以幫助研究人員從構建維度更深入地理解微調資料集。本文還總結了當前該領域實務中不同資料準備階段的構建特徵，旨在提供全面的概述並為未來的研究提供資訊。本文還從構建的角度討論了涵蓋各種資料模式的微調資料集實務。在本文的最後，我們提供了對微調資料集未來構建和發展的見解和考量。</paragraph>

##### **Natural language is not enough: Benchmarking multi-modal generative AI for Verilog generation**
2407.08473v1 by Kaiyan Chang, Zhirong Chen, Yunhao Zhou, Wenlong Zhu, kun wang, Haobo Xu, Cangyuan Li, Mengdi Wang, Shengwen Liang, Huawei Li, Yinhe Han, Ying Wang

Natural language interfaces have exhibited considerable potential in the
automation of Verilog generation derived from high-level specifications through
the utilization of large language models, garnering significant attention.
Nevertheless, this paper elucidates that visual representations contribute
essential contextual information critical to design intent for hardware
architectures possessing spatial complexity, potentially surpassing the
efficacy of natural-language-only inputs. Expanding upon this premise, our
paper introduces an open-source benchmark for multi-modal generative models
tailored for Verilog synthesis from visual-linguistic inputs, addressing both
singular and complex modules. Additionally, we introduce an open-source visual
and natural language Verilog query language framework to facilitate efficient
and user-friendly multi-modal queries. To evaluate the performance of the
proposed multi-modal hardware generative AI in Verilog generation tasks, we
compare it with a popular method that relies solely on natural language. Our
results demonstrate a significant accuracy improvement in the multi-modal
generated Verilog compared to queries based solely on natural language. We hope
to reveal a new approach to hardware design in the large-hardware-design-model
era, thereby fostering a more diversified and productive approach to hardware
design.

摘要：自然語言介面在透過利用大型語言模型，從高階規格中自動生成 Verilog 上展現出相當的潛力，並因此獲得大量的關注。然而，本論文闡明了視覺表徵提供了對硬體架構設計意圖至關重要的背景資訊，其空間複雜性可能超越僅使用自然語言輸入的效能。本論文在這個前提下進一步延伸，介紹了一個開放原始碼基準，用於針對視覺語言輸入進行 Verilog 合成的多模式生成模型，並同時處理單一和複雜的模組。此外，我們還介紹了一個開放原始碼的視覺和自然語言 Verilog 查詢語言架構，以利進行有效且使用者友善的多模式查詢。為了評估所提出的多模式硬體生成 AI 在 Verilog 生成任務中的效能，我們將其與一種僅依賴自然語言的熱門方法進行比較。我們的結果顯示，與僅基於自然語言的查詢相比，多模式生成的 Verilog 在準確性上有顯著的提升。我們希望在大型硬體設計模型時代揭示硬體設計的新方法，從而促進更多元化且高生產力的硬體設計方法。

##### **Brain Tumor Segmentation in MRI Images with 3D U-Net and Contextual Transformer**
2407.08470v1 by Thien-Qua T. Nguyen, Hieu-Nghia Nguyen, Thanh-Hieu Bui, Thien B. Nguyen-Tat, Vuong M. Ngo

This research presents an enhanced approach for precise segmentation of brain
tumor masses in magnetic resonance imaging (MRI) using an advanced 3D-UNet
model combined with a Context Transformer (CoT). By architectural expansion
CoT, the proposed model extends its architecture to a 3D format, integrates it
smoothly with the base model to utilize the complex contextual information
found in MRI scans, emphasizing how elements rely on each other across an
extended spatial range. The proposed model synchronizes tumor mass
characteristics from CoT, mutually reinforcing feature extraction, facilitating
the precise capture of detailed tumor mass structures, including location,
size, and boundaries. Several experimental results present the outstanding
segmentation performance of the proposed method in comparison to current
state-of-the-art approaches, achieving Dice score of 82.0%, 81.5%, 89.0% for
Enhancing Tumor, Tumor Core and Whole Tumor, respectively, on BraTS2019.

摘要：本研究提出一個增強的方法，使用進階的 3D-UNet 模型結合 Context Transformer (CoT) 來精確分割磁振造影 (MRI) 中的腦瘤腫塊。透過架構擴充 CoT，所提出的模型將其架構擴充到 3D 格式，並將其與基礎模型順利整合，以利用 MRI 掃描中發現的複雜背景資訊，強調元素如何跨越擴展的空間範圍相互依賴。所提出的模型從 CoT 同步化腫瘤質量特徵，相互加強特徵提取，促進精確擷取詳細的腫瘤質量結構，包括位置、大小和邊界。多項實驗結果顯示，所提出的方法與目前最先進的方法相比，具有出色的分割效能，分別在 BraTS2019 上針對增強腫瘤、腫瘤核心和整體腫瘤達到 82.0%、81.5%、89.0% 的 Dice 分數。

##### **Model Tells You Where to Merge: Adaptive KV Cache Merging for LLMs on Long-Context Tasks**
2407.08454v1 by Zheng Wang, Boxiao Jin, Zhongzhi Yu, Minjia Zhang

How to efficiently serve Large Language Models (LLMs) has become a pressing
issue because of their huge computational cost in their autoregressive
generation process. To mitigate computational costs, LLMs often employ the KV
Cache technique to improve the generation speed. While improving the
computational efficiency, the storage requirements of the KV cache are
substantial, particularly in long-context scenarios, leading to significant
memory consumption. Existing KV cache eviction methods often degrade the
performance of LLMs in long-context scenarios due to the information loss
introduced by eviction. In this paper, we propose a novel KV cache merging
approach, called KVMerger, to achieve adaptive KV cache compression for
long-context tasks without significant performance degradation under
constrained memory budgets. Our approach is inspired by the intriguing
observation that key states exhibit high similarity at the token level within a
single sequence. To facilitate merging, we develop an effective yet
straightforward merging set identification algorithm to identify suitable KV
states for merging. Our merging set identification algorithm stimulates the
second observation that KV cache sparsity, from similarity perspective, is
independent of the dataset and remains persistent at the model level.
Subsequently, we propose a Gaussian kernel weighted merging algorithm to
selectively merge all states within each merging set. We conduct extensive
experiments to demonstrate the effectiveness of KVMerger for long-context tasks
under constrained memory budgets, applying it to models including
Llama2-7B-chat and Llama2-13B-chat. Using the LongBench and ZeroScroll
benchmarks, we compare our method with other KV cache compression techniques,
including H2O and CaM, showing that our method achieves superior performance
across tasks with both 50% and 35% KV cache budgets.

摘要：<paragraph>如何有效地提供大型语言模型 (LLM) 已成为一项紧迫的问题，因为它们在自回归生成过程中的计算成本巨大。为了降低计算成本，LLM 经常采用 KV 缓存技术来提高生成速度。虽然提高了计算效率，但 KV 缓存的存储需求很大，尤其是在长上下文场景中，从而导致了大量的内存消耗。现有的 KV 缓存驱逐方法通常会因驱逐引入的信息丢失而降低 LLM 在长上下文场景中的性能。在本文中，我们提出了一种新颖的 KV 缓存合并方法，称为 KVMerger，以实现自适应 KV 缓存压缩，用于在受限内存预算下进行长上下文任务，而不会显着降低性能。我们的方法受到以下有趣观察的启发：关键状态在单个序列中的标记级别表现出高度相似性。为了促进合并，我们开发了一种有效且直接的合并集识别算法，以识别适合合并的 KV 状态。我们的合并集识别算法激发了第二个观察结果，即从相似性的角度来看，KV 缓存稀疏性与数据集无关，并且在模型级别保持不变。随后，我们提出了一种高斯核加权合并算法，以选择性地合并每个合并集中的所有状态。我们进行了广泛的实验，以证明 KVMerger 在受限内存预算下对长上下文任务的有效性，将其应用于包括 Llama2-7B-chat 和 Llama2-13B-chat 在内的模型。使用 LongBench 和 ZeroScroll 基准，我们将我们的方法与其他 KV 缓存压缩技术（包括 H2O 和 CaM）进行了比较，结果表明我们的方法在 KV 缓存预算为 50% 和 35% 的所有任务中都取得了卓越的性能。</paragraph>

##### **Paving the way toward foundation models for irregular and unaligned Satellite Image Time Series**
2407.08448v1 by Iris Dumeur, Silvia Valero, Jordi Inglada

Although recently several foundation models for satellite remote sensing
imagery have been proposed, they fail to address major challenges of
real/operational applications. Indeed, embeddings that don't take into account
the spectral, spatial and temporal dimensions of the data as well as the
irregular or unaligned temporal sampling are of little use for most real world
uses.As a consequence, we propose an ALIgned Sits Encoder (ALISE), a novel
approach that leverages the spatial, spectral, and temporal dimensions of
irregular and unaligned SITS while producing aligned latent representations.
Unlike SSL models currently available for SITS, ALISE incorporates a flexible
query mechanism to project the SITS into a common and learned temporal
projection space. Additionally, thanks to a multi-view framework, we explore
integration of instance discrimination along a masked autoencoding task to
SITS. The quality of the produced representation is assessed through three
downstream tasks: crop segmentation (PASTIS), land cover segmentation
(MultiSenGE), and a novel crop change detection dataset. Furthermore, the
change detection task is performed without supervision. The results suggest
that the use of aligned representations is more effective than previous SSL
methods for linear probing segmentation tasks.

摘要：儘管最近提出了數個用於衛星遙測影像的基礎模型，它們仍無法解決實際/操作應用中的重大挑戰。事實上，未考慮資料的光譜、空間和時間維度以及不規則或未對齊的時間抽樣的嵌入式處理，對於大多數實際應用來說幾乎沒有用處。因此，我們提出了一種對齊式情境編碼器 (ALISE)，這是一種新穎的方法，它能利用不規則且未對齊的 SITS 的空間、光譜和時間維度，同時產生對齊的潛在表示。與目前可用的 SITS SSL 模型不同，ALISE 結合了一種靈活的查詢機制，將 SITS 投影到一個共同且學習的時間投影空間中。此外，由於採用了多視角架構，我們探索了將實例區分整合到 SITS 的遮罩自動編碼任務中。所產生表示的品質透過三項下游任務進行評估：作物分割 (PASTIS)、土地覆蓋分割 (MultiSenGE) 和一個新穎的作物變化偵測資料集。此外，變更偵測任務是在沒有監督的情況下執行的。結果表明，使用對齊表示比先前的 SSL 方法對於線性探測分割任務更有效。

##### **How Deep is your Guess? A Fresh Perspective on Deep Learning for Medical Time-Series Imputation**
2407.08442v1 by Linglong Qian, Tao Wang, Jun Wang, Hugh Logan Ellis, Robin Mitra, Richard Dobson, Zina Ibrahim

We introduce a novel classification framework for time-series imputation
using deep learning, with a particular focus on clinical data. By identifying
conceptual gaps in the literature and existing reviews, we devise a taxonomy
grounded on the inductive bias of neural imputation frameworks, resulting in a
classification of existing deep imputation strategies based on their
suitability for specific imputation scenarios and data-specific properties. Our
review further examines the existing methodologies employed to benchmark deep
imputation models, evaluating their effectiveness in capturing the missingness
scenarios found in clinical data and emphasising the importance of reconciling
mathematical abstraction with clinical insights. Our classification aims to
serve as a guide for researchers to facilitate the selection of appropriate
deep learning imputation techniques tailored to their specific clinical data.
Our novel perspective also highlights the significance of bridging the gap
between computational methodologies and medical insights to achieve clinically
sound imputation models.

摘要：我們提出了一個新的時間序列插補分類架構，使用深度學習，特別關注臨床數據。通過找出文獻和現有評論中的概念差距，我們設計了一個分類法，該分類法基於神經插補框架的歸納偏誤，從而對現有的深度插補策略進行分類，基於它們對特定插補場景和數據特定屬性的適用性。我們的回顧進一步檢驗了用於對深度插補模型進行基準測試的現有方法，評估了它們在捕捉臨床數據中發現的缺失場景方面的有效性，並強調了調和數學抽象與臨床見解的重要性。我們的分類旨在作為研究人員的指南，以促進根據其特定臨床數據選擇適當的深度學習插補技術。我們的新觀點還強調了彌合計算方法和醫學見解之間差距以實現臨床合理插補模型的重要性。

##### **Are Large Language Models Really Bias-Free? Jailbreak Prompts for Assessing Adversarial Robustness to Bias Elicitation**
2407.08441v1 by Riccardo Cantini, Giada Cosenza, Alessio Orsino, Domenico Talia

Large Language Models (LLMs) have revolutionized artificial intelligence,
demonstrating remarkable computational power and linguistic capabilities.
However, these models are inherently prone to various biases stemming from
their training data. These include selection, linguistic, and confirmation
biases, along with common stereotypes related to gender, ethnicity, sexual
orientation, religion, socioeconomic status, disability, and age. This study
explores the presence of these biases within the responses given by the most
recent LLMs, analyzing the impact on their fairness and reliability. We also
investigate how known prompt engineering techniques can be exploited to
effectively reveal hidden biases of LLMs, testing their adversarial robustness
against jailbreak prompts specially crafted for bias elicitation. Extensive
experiments are conducted using the most widespread LLMs at different scales,
confirming that LLMs can still be manipulated to produce biased or
inappropriate responses, despite their advanced capabilities and sophisticated
alignment processes. Our findings underscore the importance of enhancing
mitigation techniques to address these safety issues, toward a more sustainable
and inclusive artificial intelligence.

摘要：大型語言模型 (LLM) 徹底改變了人工智慧，展示出非凡的運算能力和語言能力。然而，這些模型本質上容易受到來自訓練資料的各種偏見影響。這些偏見包括選擇、語言和確認偏誤，以及與性別、種族、性取向、宗教、社會經濟地位、殘疾和年齡相關的常見刻板印象。本研究探討了最新 LLM 給出的回應中這些偏見的存在，分析了對其公平性和可靠性的影響。我們還研究了如何利用已知的提示工程技術有效揭示 LLM 的隱藏偏見，測試其對專門用於偏見引發的越獄提示的對抗性穩健性。使用不同規模的最廣泛 LLM 進行了廣泛的實驗，證實了儘管 LLM 具有先進的功能和複雜的對齊流程，但仍可以被操縱以產生有偏見或不適當的回應。我們的研究結果強調了加強緩解技術以解決這些安全問題的重要性，朝著更具永續性和包容性的 AI 邁進。

##### **Beyond Instruction Following: Evaluating Rule Following of Large Language Models**
2407.08440v1 by Wangtao Sun, Chenxiang Zhang, Xueyou Zhang, Ziyang Huang, Haotian Xu, Pei Chen, Shizhu He, Jun Zhao, Kang Liu

Although Large Language Models (LLMs) have demonstrated strong
instruction-following ability to be helpful, they are further supposed to be
controlled and guided by rules in real-world scenarios to be safe, and accurate
in responses. This demands the possession of rule-following capability of LLMs.
However, few works have made a clear evaluation of the rule-following
capability of LLMs. Previous studies that try to evaluate the rule-following
capability of LLMs fail to distinguish the rule-following scenarios from the
instruction-following scenarios. Therefore, this paper first makes a
clarification of the concept of rule-following, and curates a comprehensive
benchmark, RuleBench, to evaluate a diversified range of rule-following
abilities. Our experimental results on a variety of LLMs show that they are
still limited in following rules. Our further analysis provides insights into
the improvements for LLMs toward a better rule-following intelligent agent. The
data and code can be found at:
https://anonymous.4open.science/r/llm-rule-following-B3E3/

摘要：儘管大型語言模型 (LLM) 已展現強大的指令遵循能力，有助益，但進一步假設它們在實際情境中會受到規則控制和引導，以確保回應安全且準確。這需要 LLM 具備遵循規則的能力。然而，很少有研究明確評估 LLM 的規則遵循能力。先前嘗試評估 LLM 規則遵循能力的研究，未能區分規則遵循情境與指令遵循情境。因此，本文首先釐清規則遵循的概念，並策劃一個全面的基準測試 RuleBench，以評估多樣化的規則遵循能力。我們在各種 LLM 上的實驗結果顯示，它們在遵循規則方面仍然有限。我們的進一步分析提供了見解，以改善 LLM 朝向更好的規則遵循智能代理邁進。資料和程式碼可在以下網址找到：
https://anonymous.4open.science/r/llm-rule-following-B3E3/

##### **A Comprehensive Survey on Human Video Generation: Challenges, Methods, and Insights**
2407.08428v1 by Wentao Lei, Jinting Wang, Fengji Ma, Guanjie Huang, Li Liu

Human video generation is a dynamic and rapidly evolving task that aims to
synthesize 2D human body video sequences with generative models given control
conditions such as text, audio, and pose. With the potential for wide-ranging
applications in film, gaming, and virtual communication, the ability to
generate natural and realistic human video is critical. Recent advancements in
generative models have laid a solid foundation for the growing interest in this
area. Despite the significant progress, the task of human video generation
remains challenging due to the consistency of characters, the complexity of
human motion, and difficulties in their relationship with the environment. This
survey provides a comprehensive review of the current state of human video
generation, marking, to the best of our knowledge, the first extensive
literature review in this domain. We start with an introduction to the
fundamentals of human video generation and the evolution of generative models
that have facilitated the field's growth. We then examine the main methods
employed for three key sub-tasks within human video generation: text-driven,
audio-driven, and pose-driven motion generation. These areas are explored
concerning the conditions that guide the generation process. Furthermore, we
offer a collection of the most commonly utilized datasets and the evaluation
metrics that are crucial in assessing the quality and realism of generated
videos. The survey concludes with a discussion of the current challenges in the
field and suggests possible directions for future research. The goal of this
survey is to offer the research community a clear and holistic view of the
advancements in human video generation, highlighting the milestones achieved
and the challenges that lie ahead.

摘要：人類影片生成是一項動態且快速演進的任務，旨在利用生成模型合成 2D 人體影片序列，並給予文字、音訊和姿勢等控制條件。隨著在電影、遊戲和虛擬通訊中廣泛應用的潛力，生成自然且逼真的影片至關重要。生成模型的最新進展為這個領域日益增長的興趣奠定了堅實的基礎。儘管取得了顯著進展，但由於角色的一致性、人類動作的複雜性和與環境關係的困難，人類影片生成的任務仍然具有挑戰性。這項調查全面回顧了人類影片生成的現狀，標誌著我們所知，這是該領域首次廣泛的文獻回顧。我們從人類影片生成的基本原理和促成該領域成長的生成模型的演進開始介紹。然後我們探討了用於人類影片生成中三個關鍵子任務的主要方法：文字驅動、音訊驅動和姿勢驅動的動作生成。這些領域是根據指導生成過程的條件進行探討的。此外，我們提供了一系列最常使用的資料集和評估指標，這些指標對於評估生成影片的品質和真實性至關重要。這項調查最後討論了該領域目前的挑戰，並建議了未來研究可能的方向。這項調查的目標是為研究社群提供人類影片生成進展的清晰且全面的觀點，重點介紹已達成的里程碑和未來的挑戰。

##### **On the (In)Security of LLM App Stores**
2407.08422v1 by Xinyi Hou, Yanjie Zhao, Haoyu Wang

LLM app stores have seen rapid growth, leading to the proliferation of
numerous custom LLM apps. However, this expansion raises security concerns. In
this study, we propose a three-layer concern framework to identify the
potential security risks of LLM apps, i.e., LLM apps with abusive potential,
LLM apps with malicious intent, and LLM apps with exploitable vulnerabilities.
Over five months, we collected 786,036 LLM apps from six major app stores: GPT
Store, FlowGPT, Poe, Coze, Cici, and Character.AI. Our research integrates
static and dynamic analysis, the development of a large-scale toxic word
dictionary (i.e., ToxicDict) comprising over 31,783 entries, and automated
monitoring tools to identify and mitigate threats. We uncovered that 15,146
apps had misleading descriptions, 1,366 collected sensitive personal
information against their privacy policies, and 15,996 generated harmful
content such as hate speech, self-harm, extremism, etc. Additionally, we
evaluated the potential for LLM apps to facilitate malicious activities,
finding that 616 apps could be used for malware generation, phishing, etc. Our
findings highlight the urgent need for robust regulatory frameworks and
enhanced enforcement mechanisms.

摘要：LLM 應用程式商店已迅速成長，導致大量自訂 LLM 應用程式激增。然而，此擴張引發了安全疑慮。在此研究中，我們提出一個三層關注架構，以識別 LLM 應用程式的潛在安全風險，亦即具有濫用潛力的 LLM 應用程式、具有惡意意圖的 LLM 應用程式以及具有可利用漏洞的 LLM 應用程式。在五個月內，我們從六個主要應用程式商店收集了 786,036 個 LLM 應用程式：GPT Store、FlowGPT、Poe、Coze、Cici 和 Character.AI。我們的研究整合了靜態和動態分析、開發包含超過 31,783 個條目的、大規模的毒害字詞字典（亦即 ToxicDict），以及用於識別和減輕威脅的自動化監控工具。我們發現有 15,146 個應用程式的說明具有誤導性，1,366 個應用程式違反其隱私權政策收集敏感的個人資訊，15,996 個應用程式產生仇恨言論、自殘、極端主義等有害內容。此外，我們評估了 LLM 應用程式促進惡意活動的潛力，發現有 616 個應用程式可用於產生惡意軟體、網路釣魚等。我們的研究結果突顯了對健全法規架構和加強執法機制的迫切需求。

##### **Specialist vision-language models for clinical ophthalmology**
2407.08410v1 by Robbie Holland, Thomas R. P. Taylor, Christopher Holmes, Sophie Riedl, Julia Mai, Maria Patsiamanidi, Dimitra Mitsopoulou, Paul Hager, Philip Müller, Hendrik P. N. Scholl, Hrvoje Bogunović, Ursula Schmidt-Erfurth, Daniel Rueckert, Sobha Sivaprasad, Andrew J. Lotery, Martin J. Menten

Clinicians spend a significant amount of time reviewing medical images and
transcribing their findings regarding patient diagnosis, referral and treatment
in text form. Vision-language models (VLMs), which automatically interpret
images and summarize their findings as text, have enormous potential to
alleviate clinical workloads and increase patient access to high-quality
medical care. While foundational models have stirred considerable interest in
the medical community, it is unclear whether their general capabilities
translate to real-world clinical utility. In this work, we show that foundation
VLMs markedly underperform compared to practicing ophthalmologists on
specialist tasks crucial to the care of patients with age-related macular
degeneration (AMD). To address this, we initially identified the essential
capabilities required for image-based clinical decision-making, and then
developed a curriculum to selectively train VLMs in these skills. The resulting
model, RetinaVLM, can be instructed to write reports that significantly
outperform those written by leading foundation medical VLMs in disease staging
(F1 score of 0.63 vs. 0.11) and patient referral (0.67 vs. 0.39), and
approaches the diagnostic performance of junior ophthalmologists (who achieve
0.77 and 0.78 on the respective tasks). Furthermore, in a reader study
involving two senior ophthalmologists with up to 32 years of experience,
RetinaVLM's reports were found to be similarly correct (78.6% vs. 82.1%) and
complete (both 78.6%) as reports written by junior ophthalmologists with up to
10 years of experience. These results demonstrate that our curriculum-based
approach provides a blueprint for specializing generalist foundation medical
VLMs to handle real-world clinical tasks.

摘要：<paragraph>臨床醫生花費大量時間檢閱醫療影像，並以文字形式記錄他們關於患者診斷、轉診和治療的發現。視覺語言模型 (VLM) 會自動解讀影像並將其發現摘要成文字，具有減輕臨床工作負載和增加患者獲得優質醫療保健的機會的巨大潛力。雖然基礎模型在醫療界引起了相當大的興趣，但尚不清楚它們的一般能力是否能轉化為實際的臨床效用。在這項工作中，我們表明基礎 VLM 在與年齡相關性黃斑部病變 (AMD) 患者照護至關重要的專門任務上，表現明顯不如執業眼科醫生。為了解決這個問題，我們最初找出影像式臨床決策所需的必要能力，然後制定課程來選擇性地訓練 VLM 這些技能。所產生的模型 RetinaVLM 可以被指示撰寫報告，其在疾病分期（F1 分數為 0.63 對 0.11）和患者轉診（0.67 對 0.39）方面明顯優於領先的基礎醫療 VLM 所撰寫的報告，並接近初級眼科醫生的診斷表現（在各項任務中分別達到 0.77 和 0.78）。此外，在涉及兩位擁有長達 32 年經驗的高級眼科醫生的讀者研究中，發現 RetinaVLM 的報告正確性（78.6% 對 82.1%）和完整性（均為 78.6%）與擁有長達 10 年經驗的初級眼科醫生所撰寫的報告相似。這些結果表明，我們基於課程的方法提供了將通才基礎醫療 VLM 專門化以處理實際臨床任務的藍圖。</paragraph>

##### **A Two-Stage Machine Learning-Aided Approach for Quench Identification at the European XFEL**
2407.08408v1 by Lynda Boukela, Annika Eichler, Julien Branlard, Nur Zulaiha Jomhari

This paper introduces a machine learning-aided fault detection and isolation
method applied to the case study of quench identification at the European X-Ray
Free-Electron Laser. The plant utilizes 800 superconducting radio-frequency
cavities in order to accelerate electron bunches to high energies of up to 17.5
GeV. Various faulty events can disrupt the nominal functioning of the
accelerator, including quenches that can lead to a loss of the
superconductivity of the cavities and the interruption of their operation. In
this context, our solution consists in analyzing signals reflecting the
dynamics of the cavities in a two-stage approach. (I) Fault detection that uses
analytical redundancy to process the data and generate a residual. The
evaluation of the residual through the generalized likelihood ratio allows
detecting the faulty behaviors. (II) Fault isolation which involves the
distinction of the quenches from the other faults. To this end, we proceed with
a data-driven model of the k-medoids algorithm that explores different
similarity measures, namely, the Euclidean and the dynamic time warping.
Finally, we evaluate the new method and compare it to the currently deployed
quench detection system, the results show the improved performance achieved by
our method.

摘要：本文介紹了一種機器學習輔助的故障偵測與隔離方法，應用於歐洲 X 光自由電子雷射的猝發識別案例研究。該工廠利用 800 個超導射頻腔來加速電子束達到高達 17.5 GeV 的高能量。各種故障事件會中斷加速器的正常運作，包括可能導致腔體超導性喪失和中斷其運作的猝發。在此背景下，我們的解決方案包括分析反映腔體動態的信號，採用兩階段方法。(I) 故障偵測，使用分析冗餘處理資料並產生殘差。透過廣義似然比評估殘差，可以偵測故障行為。(II) 故障隔離，涉及將猝發與其他故障區分開來。為此，我們使用 k-medoids 演算法的資料驅動模型來探討不同的相似性測量，即歐幾里得和動態時間規整。最後，我們評估新方法並將其與目前部署的猝發偵測系統進行比較，結果顯示我們的方法達到了改進的效能。

##### **Self-training Language Models for Arithmetic Reasoning**
2407.08400v1 by Marek Kadlčík, Michal Štefánik

Language models achieve impressive results in tasks involving complex
multistep reasoning, but scaling these capabilities further traditionally
requires expensive collection of more annotated data. In this work, we explore
the potential of improving the capabilities of language models without new
data, merely using automated feedback to the validity of their predictions in
arithmetic reasoning (self-training). We find that models can substantially
improve in both single-round (offline) and online self-training. In the offline
setting, supervised methods are able to deliver gains comparable to preference
optimization, but in online self-training, preference optimization shows to
largely outperform supervised training thanks to superior stability and
robustness on unseen types of problems.

摘要：語言模型在涉及複雜多步驟推理的任務中取得令人印象深刻的成果，但進一步擴展這些能力傳統上需要大量收集更多註釋資料。在這項工作中，我們探討了在沒有新資料的情況下提高語言模型能力的潛力，僅使用自動化回饋來驗證其在算術推理（自我訓練）中的預測的有效性。我們發現，模型可以在單輪（離線）和線上自我訓練中大幅改進。在離線設置中，監督式方法能夠提供與偏好最佳化相當的增益，但在線上自我訓練中，偏好最佳化顯示出由於在未見問題類型上的優異穩定性和穩健性而大幅優於監督式訓練。

##### **On the attribution of confidence to large language models**
2407.08388v1 by Geoff Keeling, Winnie Street

Credences are mental states corresponding to degrees of confidence in
propositions. Attribution of credences to Large Language Models (LLMs) is
commonplace in the empirical literature on LLM evaluation. Yet the theoretical
basis for LLM credence attribution is unclear. We defend three claims. First,
our semantic claim is that LLM credence attributions are (at least in general)
correctly interpreted literally, as expressing truth-apt beliefs on the part of
scientists that purport to describe facts about LLM credences. Second, our
metaphysical claim is that the existence of LLM credences is at least
plausible, although current evidence is inconclusive. Third, our epistemic
claim is that LLM credence attributions made in the empirical literature on LLM
evaluation are subject to non-trivial sceptical concerns. It is a distinct
possibility that even if LLMs have credences, LLM credence attributions are
generally false because the experimental techniques used to assess LLM
credences are not truth-tracking.

摘要：信念是與對命題的信心程度相應的心智狀態。在 LLM 評估的實證文獻中，將信念歸因於大型語言模型 (LLM) 是很常見的。然而，LLM 信念歸因的理論基礎尚不清楚。我們捍衛三項主張。首先，我們的語義主張是，LLM 信念歸因（至少在一般情況下）被正確地逐字解釋，作為科學家對 LLM 信念的事實描述的真值適應信念的表達。其次，我們的形上學主張是，LLM 信念的存在至少是合理的，儘管目前的證據尚無定論。第三，我們的認識論主張是，在 LLM 評估的實證文獻中提出的 LLM 信念歸因會受到非平凡的懷疑論關注。即使 LLM 具有信念，LLM 信念歸因通常也是錯誤的，因為用於評估 LLM 信念的實驗技術並非追蹤真值的，這是一個不同的可能性。

##### **Digital twins to alleviate the need for real field data in vision-based vehicle speed detection systems**
2407.08380v1 by Antonio Hernández Martínez, Iván García Daza, Carlos Fernández López, David Fernández Llorca

Accurate vision-based speed estimation is much more cost-effective than
traditional methods based on radar or LiDAR. However, it is also challenging
due to the limitations of perspective projection on a discrete sensor, as well
as the high sensitivity to calibration, lighting and weather conditions.
Interestingly, deep learning approaches (which dominate the field of computer
vision) are very limited in this context due to the lack of available data.
Indeed, obtaining video sequences of real road traffic with accurate speed
values associated with each vehicle is very complex and costly, and the number
of available datasets is very limited. Recently, some approaches are focusing
on the use of synthetic data. However, it is still unclear how models trained
on synthetic data can be effectively applied to real world conditions. In this
work, we propose the use of digital-twins using CARLA simulator to generate a
large dataset representative of a specific real-world camera. The synthetic
dataset contains a large variability of vehicle types, colours, speeds,
lighting and weather conditions. A 3D CNN model is trained on the digital twin
and tested on the real sequences. Unlike previous approaches that generate
multi-camera sequences, we found that the gap between the the real and the
virtual conditions is a key factor in obtaining low speed estimation errors.
Even with a preliminary approach, the mean absolute error obtained remains
below 3km/h.

摘要：準確的基於視覺的速度估計比傳統基於雷達或 LiDAR 的方法更具成本效益。然而，由於透視投影在離散感測器上的限制，以及對校準、光線和天氣條件的高度敏感性，這也具有挑戰性。有趣的是，深度學習方法（在電腦視覺領域佔主導地位）由於缺乏可用數據，因此在此背景下受到極大限制。的確，獲取與每輛車輛相關聯的準確速度值的真實道路交通影片序列非常複雜且昂貴，可用資料集的數量非常有限。最近，一些方法專注於使用合成數據。然而，在合成數據上訓練的模型如何有效應用於真實世界條件仍然不清楚。在這項工作中，我們建議使用 CARLA 模擬器中的數位雙胞胎來生成一個代表特定真實世界相機的大型資料集。合成資料集包含大量車輛類型、顏色、速度、光線和天氣條件的變化。3D CNN 模型在數位雙胞胎上訓練，並在真實序列上進行測試。與產生多相機序列的先前方法不同，我們發現真實和虛擬條件之間的差距是獲得低速度估計誤差的關鍵因素。即使採用初步方法，獲得的平均絕對誤差仍低於 3km/h。

##### **AutoBencher: Creating Salient, Novel, Difficult Datasets for Language Models**
2407.08351v1 by Xiang Lisa Li, Evan Zheran Liu, Percy Liang, Tatsunori Hashimoto

Evaluation is critical for assessing capabilities, tracking scientific
progress, and informing model selection. In this paper, we present three
desiderata for a good benchmark for language models: (i) salience (e.g.,
knowledge about World War II is more salient than a random day in history),
(ii) novelty (i.e., the benchmark reveals new trends in model rankings not
shown by previous benchmarks), and (iii) difficulty (i.e., the benchmark should
be difficult for existing models, leaving headroom for future improvement). We
operationalize these three desiderata and cast benchmark creation as a search
problem, that of finding benchmarks that that satisfy all three desiderata. To
tackle this search problem, we present AutoBencher, which uses a language model
to automatically search for datasets that meet the three desiderata.
AutoBencher uses privileged information (e.g. relevant documents) to construct
reliable datasets, and adaptivity with reranking to optimize for the search
objective. We use AutoBencher to create datasets for math, multilingual, and
knowledge-intensive question answering. The scalability of AutoBencher allows
it to test fine-grained categories and tail knowledge, creating datasets that
are on average 27% more novel and 22% more difficult than existing benchmarks.
A closer investigation of our constructed datasets shows that we can identify
specific gaps in LM knowledge in language models that are not captured by
existing benchmarks, such as Gemini Pro performing much worse on question
answering about the Permian Extinction and Fordism, while OpenAGI-7B performing
surprisingly well on QA about COVID-19.

摘要：評量對於評估能力、追蹤科學進展和提供模型選擇至關重要。在本文中，我們提出一個好的語言模型基準的三個理想條件：(i) 顯著性（例如，有關二戰的知識比歷史中的隨機一天更顯著），(ii) 新穎性（即基準揭示了模型排名的新趨勢，而先前基準未顯示），以及 (iii) 困難度（即基準對於現有模型而言應具有難度，為未來的改進留下進步空間）。我們將這三個理想條件具體化，並將基準建立視為一個搜尋問題，即找出滿足所有三個理想條件的基準。為了解決這個搜尋問題，我們提出了 AutoBencher，它使用語言模型自動搜尋符合這三個理想條件的資料集。AutoBencher 使用特權資訊（例如相關文件）來建構可靠的資料集，並透過重新排名進行適應性調整，以最佳化搜尋目標。我們使用 AutoBencher 為數學、多語言和知識密集型問題解答建立資料集。AutoBencher 的可擴充性允許它測試細緻的類別和尾部知識，建立的資料集平均比現有基準新穎 27% 且困難 22%。對我們建構的資料集進行更深入的調查顯示，我們可以找出語言模型中 LM 知識的具體差距，而現有基準並未捕捉到這些差距，例如 Gemini Pro 在有關二疊紀大滅絕和福特主義的問題解答中表現得更差，而 OpenAGI-7B 在有關 COVID-19 的 QA 中表現出人意料的好。

##### **Skywork-Math: Data Scaling Laws for Mathematical Reasoning in Large Language Models -- The Story Goes On**
2407.08348v1 by Liang Zeng, Liangjun Zhong, Liang Zhao, Tianwen Wei, Liu Yang, Jujie He, Cheng Cheng, Rui Hu, Yang Liu, Shuicheng Yan, Han Fang, Yahui Zhou

In this paper, we investigate the underlying factors that potentially enhance
the mathematical reasoning capabilities of large language models (LLMs). We
argue that the data scaling law for math reasoning capabilities in modern LLMs
is far from being saturated, highlighting how the model's quality improves with
increases in data quantity. To support this claim, we introduce the
Skywork-Math model series, supervised fine-tuned (SFT) on common 7B LLMs using
our proposed 2.5M-instance Skywork-MathQA dataset. Skywork-Math 7B has achieved
impressive accuracies of 51.2% on the competition-level MATH benchmark and
83.9% on the GSM8K benchmark using only SFT data, outperforming an early
version of GPT-4 on MATH. The superior performance of Skywork-Math models
contributes to our novel two-stage data synthesis and model SFT pipelines,
which include three different augmentation methods and a diverse seed problem
set, ensuring both the quantity and quality of Skywork-MathQA dataset across
varying difficulty levels. Most importantly, we provide several practical
takeaways to enhance math reasoning abilities in LLMs for both research and
industry applications.

摘要：<paragraph>在本文中，我們探討了潛在提升大型語言模型 (LLM) 數學推理能力的基礎因素。我們主張，現代 LLM 中數學推理能力的資料擴充法則遠未達到飽和，強調模型的品質會隨著資料量的增加而提升。為了支持此論點，我們引入了 Skywork-Math 模型系列，使用我們提出的 250 萬個例子的 Skywork-MathQA 資料集，對常見的 7B LLM 進行監督式微調 (SFT)。Skywork-Math 7B 僅使用 SFT 資料，就在競賽級別的 MATH 基準測試中達到了 51.2% 的驚人準確度，在 GSM8K 基準測試中達到了 83.9%，表現優於 GPT-4 的早期版本。Skywork-Math 模型的優異性能歸功於我們新穎的兩階段資料合成和模型 SFT 管線，其中包括三種不同的擴充方法和一個多樣化的種子問題集，確保了 Skywork-MathQA 資料集在不同難度級別上的數量和品質。最重要的是，我們提供了幾個實用的外帶事項，以增強 LLM 在研究和產業應用中的數學推理能力。</paragraph>

##### **Towards Explainable Evolution Strategies with Large Language Models**
2407.08331v1 by Jill Baumann, Oliver Kramer

This paper introduces an approach that integrates self-adaptive Evolution
Strategies (ES) with Large Language Models (LLMs) to enhance the explainability
of complex optimization processes. By employing a self-adaptive ES equipped
with a restart mechanism, we effectively navigate the challenging landscapes of
benchmark functions, capturing detailed logs of the optimization journey,
including fitness evolution, step-size adjustments, and restart events due to
stagnation. An LLM is then utilized to process these logs, generating concise,
user-friendly summaries that highlight key aspects such as convergence
behavior, optimal fitness achievements, and encounters with local optima. Our
case study on the Rastrigin function demonstrates how our approach makes the
complexities of ES optimization transparent and accessible. Our findings
highlight the potential of using LLMs to bridge the gap between advanced
optimization algorithms and their interpretability.

摘要：本文介紹一種方法，將自適應演化策略 (ES) 與大型語言模型 (LLM) 整合，以增強複雜最佳化程序的可解釋性。透過採用配備重新啟動機制的自適應 ES，我們有效地導航基準函數的挑戰性環境，擷取最佳化旅程的詳細記錄，包括適應度演化、步長調整和因停滯而重新啟動的事件。接著使用 LLM 處理這些記錄，產生簡潔、使用者友善的摘要，重點說明關鍵面向，例如收斂行為、最佳適應度達成和遭遇局部最優。我們在 Rastrigin 函數上的案例研究展示了我們的做法如何讓 ES 最佳化的複雜性變得透明且容易理解。我們的發現突顯了使用 LLM 來彌合進階最佳化演算法與其可解釋性之間差距的潛力。

##### **Unveiling Disparities in Maternity Care: A Topic Modelling Approach to Analysing Maternity Incident Investigation Reports**
2407.08328v1 by Georgina Cosma, Mohit Kumar Singh, Patrick Waterson, Gyuchan Thomas Jun, Jonathan Back

This study applies Natural Language Processing techniques, including Latent
Dirichlet Allocation, to analyse anonymised maternity incident investigation
reports from the Healthcare Safety Investigation Branch. The reports underwent
preprocessing, annotation using the Safety Intelligence Research taxonomy, and
topic modelling to uncover prevalent topics and detect differences in maternity
care across ethnic groups. A combination of offline and online methods was
utilised to ensure data protection whilst enabling advanced analysis, with
offline processing for sensitive data and online processing for non-sensitive
data using the `Claude 3 Opus' language model. Interactive topic analysis and
semantic network visualisation were employed to extract and display thematic
topics and visualise semantic relationships among keywords. The analysis
revealed disparities in care among different ethnic groups, with distinct focus
areas for the Black, Asian, and White British ethnic groups. The study
demonstrates the effectiveness of topic modelling and NLP techniques in
analysing maternity incident investigation reports and highlighting disparities
in care. The findings emphasise the crucial role of advanced data analysis in
improving maternity care quality and equity.

摘要：本研究應用自然語言處理技術，包括潛在狄利克雷分配，分析醫療保健安全調查局的匿名產婦事件調查報告。這些報告經過預處理、使用安全情報研究分類法註解，以及主題建模，以找出普遍的主題並找出不同族群在產前照護的差異。結合離線和線上方法，以確保資料保護，同時進行進階分析，使用 Claude 3 Opus 語言模型對敏感資料進行離線處理，對非敏感資料進行線上處理。採用互動主題分析和語意網路視覺化，以萃取和顯示主題主題，並視覺化關鍵字之間的語意關係。分析顯示不同族群之間的照護差異，黑人、亞洲人和白人英國人族群的關注領域不同。本研究證明了主題建模和自然語言處理技術在分析產婦事件調查報告和強調照護差異方面的有效性。研究結果強調了進階資料分析在提升產前照護品質和公平性方面的關鍵角色。

##### **Intelligent Multi-Document Summarisation for Extracting Insights on Racial Inequalities from Maternity Incident Investigation Reports**
2407.08322v1 by Georgina Cosma, Mohit Kumar Singh, Patrick Waterson, Gyuchan Thomas Jun, Jonathan Back

In healthcare, thousands of safety incidents occur every year, but learning
from these incidents is not effectively aggregated. Analysing incident reports
using AI could uncover critical insights to prevent harm by identifying
recurring patterns and contributing factors. To aggregate and extract valuable
information, natural language processing (NLP) and machine learning techniques
can be employed to summarise and mine unstructured data, potentially surfacing
systemic issues and priority areas for improvement. This paper presents
I-SIRch:CS, a framework designed to facilitate the aggregation and analysis of
safety incident reports while ensuring traceability throughout the process. The
framework integrates concept annotation using the Safety Intelligence Research
(SIRch) taxonomy with clustering, summarisation, and analysis capabilities.
Utilising a dataset of 188 anonymised maternity investigation reports annotated
with 27 SIRch human factors concepts, I-SIRch:CS groups the annotated sentences
into clusters using sentence embeddings and k-means clustering, maintaining
traceability via file and sentence IDs. Summaries are generated for each
cluster using offline state-of-the-art abstractive summarisation models (BART,
DistilBART, T5), which are evaluated and compared using metrics assessing
summary quality attributes. The generated summaries are linked back to the
original file and sentence IDs, ensuring traceability and allowing for
verification of the summarised information. Results demonstrate BART's
strengths in creating informative and concise summaries.

摘要：<paragraph>在醫療保健領域，每年都會發生數千起安全事故，但從這些事故中學習的經驗並未有效彙總。利用 AI 分析事故報告可以發現重要的見解，藉由找出重複模式和促成因素來預防傷害。為了彙總和萃取有價值的資訊，可以採用自然語言處理 (NLP) 和機器學習技術來整理和挖掘非結構化資料，潛在找出系統性問題和優先改善領域。本文提出 I-SIRch:CS，一個旨在促進安全事件報告的彙總和分析的架構，同時確保整個流程的可追溯性。此架構整合了使用安全情報研究 (SIRch) 分類法進行概念註解，以及分群、摘要和分析功能。利用一個包含 188 份匿名產科調查報告的資料集，並使用 27 個 SIRch 人為因素概念進行註解，I-SIRch:CS 使用句子嵌入和 k 均值分群將註解句子分組到群集中，並透過檔案和句子 ID 來維持可追溯性。針對每個群集使用離線最先進的抽象摘要模型 (BART、DistilBART、T5) 來產生摘要，並使用評估摘要品質屬性的指標進行評估和比較。產生的摘要連結回原始檔案和句子 ID，確保可追溯性並允許驗證摘要資訊。結果證明 BART 在建立具有資訊性和簡潔性的摘要方面具有優勢。</paragraph>

##### **Adversarial-MidiBERT: Symbolic Music Understanding Model Based on Unbias Pre-training and Mask Fine-tuning**
2407.08306v1 by Zijian Zhao

As an important part of Music Information Retrieval (MIR), Symbolic Music
Understanding (SMU) has gained substantial attention, as it can assist
musicians and amateurs in learning and creating music. Recently, pre-trained
language models have been widely adopted in SMU because the symbolic music
shares a huge similarity with natural language, and the pre-trained manner also
helps make full use of limited music data. However, the issue of bias, such as
sexism, ageism, and racism, has been observed in pre-trained language models,
which is attributed to the imbalanced distribution of training data. It also
has a significant influence on the performance of downstream tasks, which also
happens in SMU. To address this challenge, we propose Adversarial-MidiBERT, a
symbolic music understanding model based on Bidirectional Encoder
Representations from Transformers (BERT). We introduce an unbiased pre-training
method based on adversarial learning to minimize the participation of tokens
that lead to biases during training. Furthermore, we propose a mask fine-tuning
method to narrow the data gap between pre-training and fine-tuning, which can
help the model converge faster and perform better. We evaluate our method on
four music understanding tasks, and our approach demonstrates excellent
performance in all of them. The code for our model is publicly available at
https://github.com/RS2002/Adversarial-MidiBERT.

摘要：作為音樂資訊檢索 (MIR) 的重要部分，符號音樂理解 (SMU) 已獲得大量關注，因為它可以協助音樂家和業餘愛好者學習和創作音樂。最近，預訓練語言模型已廣泛應用於 SMU，因為符號音樂與自然語言有很大的相似性，而且預訓練方式也有助於充分利用有限的音樂資料。然而，在預訓練語言模型中觀察到偏見問題，例如性別歧視、年齡歧視和種族歧視，這歸因於訓練資料的不平衡分佈。這也對下游任務的執行產生重大影響，這也發生在 SMU 中。為了應對這一挑戰，我們提出了對抗式 MidiBERT，這是一個基於來自 Transformer 的雙向編碼器表徵 (BERT) 的符號音樂理解模型。我們引入了一種基於對抗學習的無偏見預訓練方法，以最小化導致訓練期間偏見的符號參與。此外，我們提出了一種遮罩微調方法，以縮小預訓練和微調之間的資料差距，這可以幫助模型更快收斂並執行得更好。我們在四項音樂理解任務上評估了我們的方法，我們的做法在所有任務中都表現出色的執行能力。我們模型的程式碼可在 https://github.com/RS2002/Adversarial-MidiBERT 公開取得。

##### **DenseFusion-1M: Merging Vision Experts for Comprehensive Multimodal Perception**
2407.08303v1 by Xiaotong Li, Fan Zhang, Haiwen Diao, Yueze Wang, Xinlong Wang, Ling-Yu Duan

Existing Multimodal Large Language Models (MLLMs) increasingly emphasize
complex understanding of various visual elements, including multiple objects,
text information, and spatial relations. Their development for comprehensive
visual perception hinges on the availability of high-quality image-text
datasets that offer diverse visual elements and throughout image descriptions.
However, the scarcity of such hyper-detailed datasets currently hinders
progress within the MLLM community. The bottleneck stems from the limited
perceptual capabilities of current caption engines, which fall short in
providing complete and accurate annotations. To facilitate the cutting-edge
research of MLLMs on comprehensive vision perception, we thereby propose
Perceptual Fusion, using a low-budget but highly effective caption engine for
complete and accurate image descriptions. Specifically, Perceptual Fusion
integrates diverse perception experts as image priors to provide explicit
information on visual elements and adopts an efficient MLLM as a centric pivot
to mimic advanced MLLMs' perception abilities. We carefully select 1M highly
representative images from uncurated LAION dataset and generate dense
descriptions using our engine, dubbed DenseFusion-1M. Extensive experiments
validate that our engine outperforms its counterparts, where the resulting
dataset significantly improves the perception and cognition abilities of
existing MLLMs across diverse vision-language benchmarks, especially with
high-resolution images as inputs. The dataset and code are publicly available
at https://github.com/baaivision/DenseFusion.

摘要：現有的多模態大型語言模型 (MLLM) 愈來愈重視對各種視覺元素的複雜理解，包括多個物件、文字資訊和空間關係。它們對於全面視覺感知的發展取決於高品質影像文字資料集的可用性，這些資料集提供多樣化的視覺元素和整個影像描述。然而，此類超詳細資料集的稀少性目前阻礙了 MLLM 社群內的進展。瓶頸源自於當前標題引擎有限的感知能力，無法提供完整且準確的註解。為了促進 MLLM 在全面視覺感知方面的尖端研究，我們因此提出感知融合，使用低預算但高效率的標題引擎來提供完整且準確的影像描述。具體來說，感知融合將多樣化的感知專家整合為影像先驗，以提供視覺元素的明確資訊，並採用高效能的 MLLM 作為中心樞紐來模擬進階 MLLM 的感知能力。我們仔細從未經整理的 LAION 資料集中挑選 100 萬張極具代表性的影像，並使用我們稱為 DenseFusion-1M 的引擎產生密集描述。廣泛的實驗驗證我們的引擎優於同類型引擎，其中產生的資料集顯著提升現有 MLLM 在各種視覺語言基準上的感知和認知能力，特別是以高解析度影像作為輸入時。資料集和程式碼可在 https://github.com/baaivision/DenseFusion 公開取得。

##### **Impact Measures for Gradual Argumentation Semantics**
2407.08302v1 by Caren Al Anaissy, Jérôme Delobelle, Srdjan Vesic, Bruno Yun

Argumentation is a formalism allowing to reason with contradictory
information by modeling arguments and their interactions. There are now an
increasing number of gradual semantics and impact measures that have emerged to
facilitate the interpretation of their outcomes. An impact measure assesses,
for each argument, the impact of other arguments on its score. In this paper,
we refine an existing impact measure from Delobelle and Villata and introduce a
new impact measure rooted in Shapley values. We introduce several principles to
evaluate those two impact measures w.r.t. some well-known gradual semantics.
This comprehensive analysis provides deeper insights into their functionality
and desirability.

摘要：論證是一種形式主義，允許透過建模論證及其互動來對矛盾資訊進行推理。現在有越來越多漸進語義和影響力測量方法出現，以利於解釋其結果。影響力測量評估每個論證中其他論證對其分數的影響力。在本文中，我們改進了 Delobelle 和 Villata 現有的影響力測量，並引入了一個根植於 Shapley 值的新影響力測量。我們引入了一些原則來評估這兩個影響力測量，相對於一些著名的漸進語義。這種全面的分析提供了對其功能和可取性的更深入見解。

##### **Continually Learn to Map Visual Concepts to Large Language Models in Resource-constrained Environments**
2407.08279v1 by Clea Rebillard, Julio Hurtado, Andrii Krutsylo, Lucia Passaro, Vincenzo Lomonaco

Learning continually from a stream of non-i.i.d. data is an open challenge in
deep learning, even more so when working in resource-constrained environments
such as embedded devices. Visual models that are continually updated through
supervised learning are often prone to overfitting, catastrophic forgetting,
and biased representations. On the other hand, large language models contain
knowledge about multiple concepts and their relations, which can foster a more
robust, informed and coherent learning process. This work proposes Continual
Visual Mapping (CVM), an approach that continually ground vision
representations to a knowledge space extracted from a fixed Language model.
Specifically, CVM continually trains a small and efficient visual model to map
its representations into a conceptual space established by a fixed Large
Language Model. Due to their smaller nature, CVM can be used when directly
adapting large visual pre-trained models is unfeasible due to computational or
data constraints. CVM overcome state-of-the-art continual learning methods on
five benchmarks and offers a promising avenue for addressing generalization
capabilities in continual learning, even in computationally constrained
devices.

摘要：從非獨立同分布資料串流中持續學習是深度學習的一項公開挑戰，尤其是在資源受限的環境中工作時，例如嵌入式裝置。透過監督式學習持續更新的視覺模型通常容易過度擬合、災難性遺忘和有偏差的表示。另一方面，大型語言模型包含了關於多個概念及其關係的知識，這可以促進更強大、更豐富且更一致的學習過程。這項工作提出了持續視覺對應 (CVM)，一種方法是持續將視覺表示基礎於從固定語言模型中提取的知識空間。具體來說，CVM 持續訓練一個小型且高效的視覺模型，將其表示對應到由固定大型語言模型建立的概念空間中。由於其較小的特性，當由於運算或資料限制而無法直接調整大型視覺預訓練模型時，可以使用 CVM。CVM 在五個基準上克服了最先進的持續學習方法，並為解決持續學習中的概化能力提供了一個有前途的途徑，即使在運算受限的裝置上也是如此。

##### **RB-SQL: A Retrieval-based LLM Framework for Text-to-SQL**
2407.08273v1 by Zhenhe Wu, Zhongqiu Li, Jie Zhang, Mengxiang Li, Yu Zhao, Ruiyu Fang, Zhongjiang He, Xuelong Li, Zhoujun Li, Shuangyong Song

Large language models (LLMs) with in-context learning have significantly
improved the performance of text-to-SQL task. Previous works generally focus on
using exclusive SQL generation prompt to improve the LLMs' reasoning ability.
However, they are mostly hard to handle large databases with numerous tables
and columns, and usually ignore the significance of pre-processing database and
extracting valuable information for more efficient prompt engineering. Based on
above analysis, we propose RB-SQL, a novel retrieval-based LLM framework for
in-context prompt engineering, which consists of three modules that retrieve
concise tables and columns as schema, and targeted examples for in-context
learning. Experiment results demonstrate that our model achieves better
performance than several competitive baselines on public datasets BIRD and
Spider.

摘要：具備情境學習的大型語言模型 (LLM) 已大幅提升文字轉 SQL 任務的效能。先前的研究通常專注於使用獨特的 SQL 產生提示來提升 LLM 的推理能力。然而，它們大多難以處理具有大量表格和欄位的龐大資料庫，且通常忽略預處理資料庫和擷取有價值資訊以進行更有效率的提示工程。基於上述分析，我們提出 RB-SQL，一個新穎的基於檢索的 LLM 架構，用於情境提示工程，它包含三個模組，用於檢索簡潔的表格和欄位作為架構，以及針對情境學習的目標範例。實驗結果顯示，我們的模型在公開資料集 BIRD 和 Spider 上的表現優於數個競爭基線。

##### **SciQu: Accelerating Materials Properties Prediction with Automated Literature Mining for Self-Driving Laboratories**
2407.08270v1 by Anand Babu

Assessing different material properties to predict specific attributes, such
as band gap, resistivity, young modulus, work function, and refractive index,
is a fundamental requirement for materials science-based applications. However,
the process is time-consuming and often requires extensive literature reviews
and numerous experiments. Our study addresses these challenges by leveraging
machine learning to analyze material properties with greater precision and
efficiency. By automating the data extraction process and using the extracted
information to train machine learning models, our developed model, SciQu,
optimizes material properties. As a proof of concept, we predicted the
refractive index of materials using data extracted from numerous research
articles with SciQu, considering input descriptors such as space group, volume,
and bandgap with Root Mean Square Error (RMSE) 0.068 and R2 0.94. Thus, SciQu
not only predicts the properties of materials but also plays a key role in
self-driving laboratories by optimizing the synthesis parameters to achieve
precise shape, size, and phase of the materials subjected to the input
parameters.

摘要：評估不同的材料屬性以預測特定屬性，例如帶隙、電阻率、楊氏模數、功函數和折射率，是基於材料科學的應用之基本要求。然而，此過程耗時且通常需要廣泛的文獻回顧和大量的實驗。我們的研究透過利用機器學習來分析材料屬性，以更高的精確度和效率來解決這些挑戰。透過自動化資料萃取流程並使用萃取的資訊來訓練機器學習模型，我們開發的模型 SciQu 最佳化了材料屬性。作為概念驗證，我們使用從大量研究文章中萃取的資料來預測材料的折射率，SciQu 考量了輸入描述符，例如空間群、體積和帶隙，其均方根誤差 (RMSE) 為 0.068，R2 為 0.94。因此，SciQu 不僅預測材料的屬性，也透過最佳化合成參數來達成輸入參數所設定的材料精確形狀、大小和相位，在自動化實驗室中扮演關鍵角色。

##### **LLMs' morphological analyses of complex FST-generated Finnish words**
2407.08269v1 by Anssi Moisio, Mathias Creutz, Mikko Kurimo

Rule-based language processing systems have been overshadowed by neural
systems in terms of utility, but it remains unclear whether neural NLP systems,
in practice, learn the grammar rules that humans use. This work aims to shed
light on the issue by evaluating state-of-the-art LLMs in a task of
morphological analysis of complex Finnish noun forms. We generate the forms
using an FST tool, and they are unlikely to have occurred in the training sets
of the LLMs, therefore requiring morphological generalisation capacity. We find
that GPT-4-turbo has some difficulties in the task while GPT-3.5-turbo
struggles and smaller models Llama2-70B and Poro-34B fail nearly completely.

摘要：基於規則的語言處理系統在實用性方面已被神經系統取代，但目前仍不清楚神經 NLP 系統在實際上是否學習人類使用的語法規則。這項工作旨在透過在複雜芬蘭語名詞形式的形態分析任務中評估最先進的 LLM 來闡明這個問題。我們使用 FST 工具產生這些形式，而且這些形式不太可能出現在 LLM 的訓練集中，因此需要形態概括能力。我們發現 GPT-4-turbo 在此任務中遇到了一些困難，而 GPT-3.5-turbo 則苦苦掙扎，而較小的模型 Llama2-70B 和 Poro-34B 幾乎完全失敗。

##### **Knowledge distillation to effectively attain both region-of-interest and global semantics from an image where multiple objects appear**
2407.08257v1 by Seonwhee Jin

Models based on convolutional neural networks (CNN) and transformers have
steadily been improved. They also have been applied in various computer vision
downstream tasks. However, in object detection tasks, accurately localizing and
classifying almost infinite categories of foods in images remains challenging.
To address these problems, we first segmented the food as the
region-of-interest (ROI) by using the segment-anything model (SAM) and masked
the rest of the region except ROI as black pixels. This process simplified the
problems into a single classification for which annotation and training were
much simpler than object detection. The images in which only the ROI was
preserved were fed as inputs to fine-tune various off-the-shelf models that
encoded their own inductive biases. Among them, Data-efficient image
Transformers (DeiTs) had the best classification performance. Nonetheless, when
foods' shapes and textures were similar, the contextual features of the
ROI-only images were not enough for accurate classification. Therefore, we
introduced a novel type of combined architecture, RveRNet, which consisted of
ROI, extra-ROI, and integration modules that allowed it to account for both the
ROI's and global contexts. The RveRNet's F1 score was 10% better than other
individual models when classifying ambiguous food images. If the RveRNet's
modules were DeiT with the knowledge distillation from the CNN, performed the
best. We investigated how architectures can be made robust against input noise
caused by permutation and translocation. The results indicated that there was a
trade-off between how much the CNN teacher's knowledge could be distilled to
DeiT and DeiT's innate strength. Code is publicly available at:
https://github.com/Seonwhee-Genome/RveRNet.

摘要：<paragraph>基於卷積神經網路 (CNN) 和 Transformer 的模型已持續獲得改善。它們也已應用於各種電腦視覺下游任務。然而，在物件偵測任務中，準確定位和分類影像中幾乎無限類別的食物仍然具有挑戰性。為了解決這些問題，我們首先使用分割任何東西模型 (SAM) 將食物分割為感興趣區域 (ROI)，並將 ROI 以外的區域遮罩為黑色像素。此程序將問題簡化為單一分類，其註解和訓練比物件偵測簡單許多。僅保留 ROI 的影像被提供為輸入，用於微調各種內建模型，這些模型編碼了其自身的歸納偏差。其中，資料有效率的影像 Transformer (DeiTs) 具有最佳的分類效能。儘管如此，當食物的形狀和質地相似時，僅 ROI 影像的脈絡特徵不足以進行準確分類。因此，我們引入了一種新穎的複合架構 RveRNet，它包含 ROI、ROI 外部和整合模組，使其能夠考量 ROI 和全域脈絡。RveRNet 的 F1 分數比其他個別模型高出 10%，用於分類模稜兩可的食物影像。如果 RveRNet 的模組是具備 CNN 知識萃取的 DeiT，則表現最佳。我們探討了如何讓架構對由排列和轉位造成的輸入雜訊具有穩健性。結果表明，CNN 教師的知識能萃取到 DeiT 的程度與 DeiT 的內在強度之間存在權衡。程式碼已公開於：https://github.com/Seonwhee-Genome/RveRNet。</paragraph>

##### **GeNet: A Multimodal LLM-Based Co-Pilot for Network Topology and Configuration**
2407.08249v1 by Beni Ifland, Elad Duani, Rubin Krief, Miro Ohana, Aviram Zilberman, Andres Murillo, Ofir Manor, Ortal Lavi, Hikichi Kenji, Asaf Shabtai, Yuval Elovici, Rami Puzis

Communication network engineering in enterprise environments is traditionally
a complex, time-consuming, and error-prone manual process. Most research on
network engineering automation has concentrated on configuration synthesis,
often overlooking changes in the physical network topology. This paper
introduces GeNet, a multimodal co-pilot for enterprise network engineers. GeNet
is a novel framework that leverages a large language model (LLM) to streamline
network design workflows. It uses visual and textual modalities to interpret
and update network topologies and device configurations based on user intents.
GeNet was evaluated on enterprise network scenarios adapted from Cisco
certification exercises. Our results demonstrate GeNet's ability to interpret
network topology images accurately, potentially reducing network engineers'
efforts and accelerating network design processes in enterprise environments.
Furthermore, we show the importance of precise topology understanding when
handling intents that require modifications to the network's topology.

摘要：企業環境中的通訊網路工程傳統上是一個複雜、耗時且容易出錯的手動程序。大多數關於網路工程自動化的研究都集中在組態合成，常常忽略實體網路拓撲的變動。本文介紹 GeNet，一個針對企業網路工程師的多模態副駕駛。GeNet 是一個新穎的架構，利用大型語言模型 (LLM) 來簡化網路設計工作流程。它使用視覺和文字模式來根據使用者的意圖，解釋和更新網路拓撲和裝置組態。GeNet 在改編自思科認證練習的企業網路場景中進行評估。我們的結果證明了 GeNet 準確解釋網路拓撲影像的能力，這有可能減少網路工程師的負擔，並加速企業環境中的網路設計程序。此外，我們展示了在處理需要修改網路拓撲的意圖時，精確了解拓撲的重要性。

##### **Toward accessible comics for blind and low vision readers**
2407.08248v1 by Christophe Rigaud, Jean-Christophe Burie, Samuel Petit

This work explores how to fine-tune large language models using prompt
engineering techniques with contextual information for generating an accurate
text description of the full story, ready to be forwarded to off-the-shelve
speech synthesis tools. We propose to use existing computer vision and optical
character recognition techniques to build a grounded context from the comic
strip image content, such as panels, characters, text, reading order and the
association of bubbles and characters. Then we infer character identification
and generate comic book script with context-aware panel description including
character's appearance, posture, mood, dialogues etc. We believe that such
enriched content description can be easily used to produce audiobook and eBook
with various voices for characters, captions and playing sound effects.

摘要：本研究探討如何使用提示工程技術微調大型語言模型，並利用脈絡資訊產生完整故事的精確文字描述，以便轉傳到現成的語音合成工具。我們建議使用現有的電腦視覺和光學字元辨識技術，從漫畫圖像內容建立一個基礎脈絡，例如面板、角色、文字、閱讀順序以及對話框和角色的關聯。然後，我們推論角色識別，並產生具有脈絡感知面板描述的漫畫腳本，包括角色的外觀、姿勢、情緒、對話等。我們相信這種豐富的內容描述可以輕鬆用於製作有聲書和電子書，並為角色、字幕和播放音效提供各種聲音。

##### **Leveraging LLMs to Predict Affective States via Smartphone Sensor Features**
2407.08240v1 by Tianyi Zhang, Songyan Teng, Hong Jia, Simon D'Alfonso

As mental health issues for young adults present a pressing public health
concern, daily digital mood monitoring for early detection has become an
important prospect. An active research area, digital phenotyping, involves
collecting and analysing data from personal digital devices such as smartphones
(usage and sensors) and wearables to infer behaviours and mental health. Whilst
this data is standardly analysed using statistical and machine learning
approaches, the emergence of large language models (LLMs) offers a new approach
to make sense of smartphone sensing data. Despite their effectiveness across
various domains, LLMs remain relatively unexplored in digital mental health,
particularly in integrating mobile sensor data. Our study aims to bridge this
gap by employing LLMs to predict affect outcomes based on smartphone sensing
data from university students. We demonstrate the efficacy of zero-shot and
few-shot embedding LLMs in inferring general wellbeing. Our findings reveal
that LLMs can make promising predictions of affect measures using solely
smartphone sensing data. This research sheds light on the potential of LLMs for
affective state prediction, emphasizing the intricate link between smartphone
behavioral patterns and affective states. To our knowledge, this is the first
work to leverage LLMs for affective state prediction and digital phenotyping
tasks.

摘要：隨著年輕人的心理健康問題成為迫切的公共衛生問題，每日數位情緒監控已成為早期偵測的重要前景。數位表型化是一個積極的研究領域，涉及收集和分析來自個人數位裝置（例如智慧型手機（使用和感測器）和可穿戴裝置）的資料，以推論行為和心理健康。雖然這些資料通常使用統計和機器學習方法進行分析，但大型語言模型 (LLM) 的出現提供了一種新的方法來理解智慧型手機感測資料。儘管 LLM 在各種領域都非常有效，但其在數位心理健康領域仍相對未被探索，特別是在整合行動感測器資料方面。我們的研究旨在透過使用 LLM 來根據大學生的智慧型手機感測資料預測影響結果，以彌合這一差距。我們展示了零次學習和少次學習嵌入式 LLM 在推論一般幸福感方面的效能。我們的研究結果顯示，LLM 可以僅使用智慧型手機感測資料對影響測量進行有希望的預測。本研究揭示了 LLM 在情感狀態預測方面的潛力，強調了智慧型手機行為模式和情感狀態之間的複雜聯繫。據我們所知，這是第一個利用 LLM 進行情感狀態預測和數位表型化任務的研究。

##### **DALL-M: Context-Aware Clinical Data Augmentation with LLMs**
2407.08227v1 by Chihcheng Hsieh, Catarina Moreira, Isabel Blanco Nobre, Sandra Costa Sousa, Chun Ouyang, Margot Brereton, Joaquim Jorge, Jacinto C. Nascimento

X-ray images are vital in medical diagnostics, but their effectiveness is
limited without clinical context. Radiologists often find chest X-rays
insufficient for diagnosing underlying diseases, necessitating comprehensive
clinical features and data integration. We present a novel technique to enhance
the clinical context through augmentation techniques with clinical tabular
data, thereby improving its applicability and reliability in AI medical
diagnostics. To address this, we introduce a pioneering approach to clinical
data augmentation that employs large language models (LLMs) to generate patient
contextual synthetic data. This methodology is crucial for training more robust
deep learning models in healthcare. It preserves the integrity of real patient
data while enriching the dataset with contextually relevant synthetic features,
significantly enhancing model performance. DALL-M uses a three-phase feature
generation process: (i) clinical context storage, (ii) expert query generation,
and (iii) context-aware feature augmentation. DALL-M generates new, clinically
relevant features by synthesizing chest X-ray images and reports. Applied to
799 cases using nine features from the MIMIC-IV dataset, it created an
augmented set of 91 features. This is the first work to generate contextual
values for existing and new features based on patients' X-ray reports, gender,
and age and to produce new contextual knowledge during data augmentation.
Empirical validation with machine learning models, including Decision Trees,
Random Forests, XGBoost, and TabNET, showed significant performance
improvements. Incorporating augmented features increased the F1 score by 16.5%
and Precision and Recall by approximately 25%. DALL-M addresses a critical gap
in clinical data augmentation, offering a robust framework for generating
contextually enriched datasets.

摘要：<paragraph>X 光影像在医学诊断中至关重要，但如果没有临床背景，其有效性会受到限制。放射科医生经常发现胸部 X 光影像不足以诊断潜在疾病，因此需要全面的临床特征和数据整合。我们提出了一种新技术，通过使用临床表格数据进行增强技术来增强临床背景，从而提高其在 AI 医学诊断中的适用性和可靠性。为了解决这个问题，我们引入了一种开创性的临床数据增强方法，该方法采用大型语言模型 (LLM) 来生成患者背景合成数据。这种方法对于在医疗保健领域训练更强大的深度学习模型至关重要。它保留了真实患者数据的完整性，同时使用与上下文相关的合成特征丰富了数据集，从而显著提高了模型性能。DALL-M 使用了一个三阶段特征生成过程：(i) 临床背景存储，(ii) 专家查询生成，(iii) 上下文感知特征增强。DALL-M 通过合成胸部 X 光影像和报告来生成新的、与临床相关的特征。将其应用于 MIMIC-IV 数据集中的 799 个案例，使用九个特征，它创建了一个包含 91 个特征的增强集合。这是第一项基于患者的 X 光报告、性别和年龄为现有和新特征生成上下文值的著作，并在数据增强期间产生新的上下文知识。使用包括决策树、随机森林、XGBoost 和 TabNET 在内的机器学习模型进行的经验验证显示出显著的性能改进。合并增强功能将 F1 分数提高了 16.5%，并将精确度和召回率提高了大约 25%。DALL-M 解决了一个临床数据增强中的关键空白，提供了一个用于生成上下文丰富的数据集的稳健框架。</paragraph>

##### **Speculative RAG: Enhancing Retrieval Augmented Generation through Drafting**
2407.08223v1 by Zilong Wang, Zifeng Wang, Long Le, Huaixiu Steven Zheng, Swaroop Mishra, Vincent Perot, Yuwei Zhang, Anush Mattapalli, Ankur Taly, Jingbo Shang, Chen-Yu Lee, Tomas Pfister

Retrieval augmented generation (RAG) combines the generative abilities of
large language models (LLMs) with external knowledge sources to provide more
accurate and up-to-date responses. Recent RAG advancements focus on improving
retrieval outcomes through iterative LLM refinement or self-critique
capabilities acquired through additional instruction tuning of LLMs. In this
work, we introduce Speculative RAG - a framework that leverages a larger
generalist LM to efficiently verify multiple RAG drafts produced in parallel by
a smaller, distilled specialist LM. Each draft is generated from a distinct
subset of retrieved documents, offering diverse perspectives on the evidence
while reducing input token counts per draft. This approach enhances
comprehension of each subset and mitigates potential position bias over long
context. Our method accelerates RAG by delegating drafting to the smaller
specialist LM, with the larger generalist LM performing a single verification
pass over the drafts. Extensive experiments demonstrate that Speculative RAG
achieves state-of-the-art performance with reduced latency on TriviaQA,
MuSiQue, PubHealth, and ARC-Challenge benchmarks. It notably enhances accuracy
by up to 12.97% while reducing latency by 51% compared to conventional RAG
systems on PubHealth.

摘要：撷取增强生成（RAG）结合了大型语言模型（LLM）的生成能力和外部知识来源，以提供更准确且最新的回应。最近的 RAG 改进重点在于通过迭代 LLM 优化或经由 LLM 的额外指令微调所获得的自省能力来改善撷取结果。在这项工作中，我们引入了推测性 RAG，这是一个框架，它利用一个较大的通才 LM 来有效验证由较小的、精炼的专家 LM 并行产生的多个 RAG 草稿。每个草稿都是从撷取文件的一个不同子集生成的，它提供了证据的不同观点，同时减少了每个草稿的输入标记计数。这种方法增强了对每个子集的理解，并减轻了对长语境的潜在位置偏差。我们的方法通过将起草委派给较小的专家 LM 来加速 RAG，而较大的通才 LM 对草稿执行单次验证。广泛的实验表明，推测性 RAG 在 TriviaQA、MuSiQue、PubHealth 和 ARC-Challenge 基准测试中实现了最先进的性能，且延迟更低。与传统的 RAG 系统相比，它显著提高了准确度（最高提高 12.97%），同时将延迟降低了 51%，尤其是在 PubHealth 上。

##### **Generating Contextually-Relevant Navigation Instructions for Blind and Low Vision People**
2407.08219v1 by Zain Merchant, Abrar Anwar, Emily Wang, Souti Chattopadhyay, Jesse Thomason

Navigating unfamiliar environments presents significant challenges for blind
and low-vision (BLV) individuals. In this work, we construct a dataset of
images and goals across different scenarios such as searching through kitchens
or navigating outdoors. We then investigate how grounded instruction generation
methods can provide contextually-relevant navigational guidance to users in
these instances. Through a sighted user study, we demonstrate that large
pretrained language models can produce correct and useful instructions
perceived as beneficial for BLV users. We also conduct a survey and interview
with 4 BLV users and observe useful insights on preferences for different
instructions based on the scenario.

摘要：對於視障人士 (BLV) 來說，在陌生的環境中移動會造成重大的挑戰。在這項工作中，我們建立了一個資料集，其中包含不同情境中的影像和目標，例如在廚房中搜尋或在戶外導航。接著，我們探討如何運用基礎指令產生方法，在這些情況下為使用者提供與情境相關的導航指南。透過一項明眼使用者研究，我們證明大型預訓練語言模型可以產生正確且有用的指令，這些指令被視為對 BLV 使用者有益。我們也進行了一項調查，並訪談了 4 位 BLV 使用者，並觀察到基於情境的不同指令偏好方面的有用見解。

##### **Multimodal contrastive learning for spatial gene expression prediction using histology images**
2407.08216v1 by Wenwen Min, Zhiceng Shi, Jun Zhang, Jun Wan, Changmiao Wang

In recent years, the advent of spatial transcriptomics (ST) technology has
unlocked unprecedented opportunities for delving into the complexities of gene
expression patterns within intricate biological systems. Despite its
transformative potential, the prohibitive cost of ST technology remains a
significant barrier to its widespread adoption in large-scale studies. An
alternative, more cost-effective strategy involves employing artificial
intelligence to predict gene expression levels using readily accessible
whole-slide images (WSIs) stained with Hematoxylin and Eosin (H\&E). However,
existing methods have yet to fully capitalize on multimodal information
provided by H&E images and ST data with spatial location. In this paper, we
propose \textbf{mclSTExp}, a multimodal contrastive learning with Transformer
and Densenet-121 encoder for Spatial Transcriptomics Expression prediction. We
conceptualize each spot as a "word", integrating its intrinsic features with
spatial context through the self-attention mechanism of a Transformer encoder.
This integration is further enriched by incorporating image features via
contrastive learning, thereby enhancing the predictive capability of our model.
Our extensive evaluation of \textbf{mclSTExp} on two breast cancer datasets and
a skin squamous cell carcinoma dataset demonstrates its superior performance in
predicting spatial gene expression. Moreover, mclSTExp has shown promise in
interpreting cancer-specific overexpressed genes, elucidating immune-related
genes, and identifying specialized spatial domains annotated by pathologists.
Our source code is available at https://github.com/shizhiceng/mclSTExp.

摘要：<paragraph>近年來，空間轉錄組學 (ST) 技術的出現為深入研究複雜生物系統中基因表現模式的複雜性提供了前所未有的機會。儘管具有轉變潛力，但 ST 技術的高昂成本仍然是大規模研究中廣泛採用的重大障礙。一種替代的、更具成本效益的策略涉及使用人工智慧來預測使用易於取得的、染有蘇木精和曙紅 (H&E) 的全玻片影像 (WSI) 的基因表現水準。然而，現有方法尚未充分利用 H&E 影像和具有空間位置的 ST 資料所提供的多模態資訊。在本文中，我們提出 \textbf{mclSTExp}，一個多模態對比學習，使用 Transformer 和 Densenet-121 編碼器進行空間轉錄組學表現預測。我們將每個點概念化为一個「字」，透過 Transformer 編碼器的自注意力機制，將其內在特徵與空間脈絡整合在一起。這種整合通過對比學習進一步豐富了影像特徵，從而增強了我們模型的預測能力。我們對兩個乳癌資料集和一個皮膚鱗狀細胞癌資料集的 \textbf{mclSTExp} 進行廣泛評估，證明了其在預測空間基因表現方面的優異效能。此外，mclSTExp 已顯示出在解釋癌症特異性過度表現基因、闡明免疫相關基因以及識別病理學家註解的專門空間領域方面的前景。我們的原始碼可在 https://github.com/shizhiceng/mclSTExp 取得。</paragraph>

##### **System Report for CCL24-Eval Task 7: Multi-Error Modeling and Fluency-Targeted Pre-training for Chinese Essay Evaluation**
2407.08206v1 by Jingshen Zhang, Xiangyu Yang, Xinkai Su, Xinglu Chen, Tianyou Huang, Xinying Qiu

This system report presents our approaches and results for the Chinese Essay
Fluency Evaluation (CEFE) task at CCL-2024. For Track 1, we optimized
predictions for challenging fine-grained error types using binary
classification models and trained coarse-grained models on the Chinese Learner
4W corpus. In Track 2, we enhanced performance by constructing a pseudo-dataset
with multiple error types per sentence. For Track 3, where we achieved first
place, we generated fluency-rated pseudo-data via back-translation for
pre-training and used an NSP-based strategy with Symmetric Cross Entropy loss
to capture context and mitigate long dependencies. Our methods effectively
address key challenges in Chinese Essay Fluency Evaluation.

摘要：本系統報告介紹了我們在 CCL-2024 中文作文流暢度評估 (CEFE) 任務中的方法和結果。對於軌道 1，我們使用二元分類模型優化了對具有挑戰性的細粒度錯誤類型的預測，並在中文學習者 4W 語料庫上訓練了粗粒度模型。在軌道 2 中，我們通過構建每句話具有多種錯誤類型的偽數據集來增強性能。對於我們獲得第一名的軌道 3，我們通過反向翻譯生成了流暢度評級的偽數據，用於預訓練，並使用基於 NSP 的策略與對稱交叉熵損失來捕捉上下文並減輕長依賴性。我們的這些方法有效地應對了中文作文流暢度評估中的關鍵挑戰。

##### **Chromosomal Structural Abnormality Diagnosis by Homologous Similarity**
2407.08204v1 by Juren Li, Fanzhe Fu, Ran Wei, Yifei Sun, Zeyu Lai, Ning Song, Xin Chen, Yang Yang

Pathogenic chromosome abnormalities are very common among the general
population. While numerical chromosome abnormalities can be quickly and
precisely detected, structural chromosome abnormalities are far more complex
and typically require considerable efforts by human experts for identification.
This paper focuses on investigating the modeling of chromosome features and the
identification of chromosomes with structural abnormalities. Most existing
data-driven methods concentrate on a single chromosome and consider each
chromosome independently, overlooking the crucial aspect of homologous
chromosomes. In normal cases, homologous chromosomes share identical
structures, with the exception that one of them is abnormal. Therefore, we
propose an adaptive method to align homologous chromosomes and diagnose
structural abnormalities through homologous similarity. Inspired by the process
of human expert diagnosis, we incorporate information from multiple pairs of
homologous chromosomes simultaneously, aiming to reduce noise disturbance and
improve prediction performance. Extensive experiments on real-world datasets
validate the effectiveness of our model compared to baselines.

摘要：病原性染色體異常在一般族群中非常常見。雖然數目性染色體異常可以快速且精確地被偵測出來，但結構性染色體異常則複雜得多，通常需要人類專家投入大量的精力才能辨識出來。本文重點在於探討染色體特徵的建模，以及結構異常染色體的辨識。現有的大多數資料驅動方法都專注於單一染色體，並獨立考量每個染色體，忽略了同源染色體這個重要的面向。在正常情況下，同源染色體具有相同的結構，但其中一條染色體異常。因此，我們提出了一種自適應方法來比對同源染色體，並透過同源相似性診斷結構異常。受到人類專家診斷過程的啟發，我們同時納入多對同源染色體的資訊，目的是減少雜訊干擾並提升預測效能。針對真實世界的資料集進行的廣泛實驗驗證了我們模型的有效性，並與基準線進行比較。

##### **SoupLM: Model Integration in Large Language and Multi-Modal Models**
2407.08196v1 by Yue Bai, Zichen Zhang, Jiasen Lu, Yun Fu

Training large language models (LLMs) and multimodal LLMs necessitates
significant computing resources, and existing publicly available LLMs are
typically pre-trained on diverse, privately curated datasets spanning various
tasks. For instance, LLaMA, Vicuna, and LLaVA are three LLM variants trained
with LLaMA base models using very different training recipes, tasks, and data
modalities. The training cost and complexity for such LLM variants grow
rapidly. In this study, we propose to use a soup strategy to assemble these LLM
variants into a single well-generalized multimodal LLM (SoupLM) in a
cost-efficient manner. Assembling these LLM variants efficiently brings
knowledge and specialities trained from different domains and data modalities
into an integrated one (e.g., chatbot speciality from user-shared conversations
for Vicuna, and visual capacity from vision-language data for LLaVA),
therefore, to avoid computing costs of repetitive training on several different
domains. We propose series of soup strategies to systematically benchmark
performance gains across various configurations, and probe the soup behavior
across base models in the interpolation space.

摘要：訓練大型語言模型 (LLM) 和多模態 LLM 需要大量的運算資源，而現有的公開 LLM 通常使用多元且私有策展的資料集進行預先訓練，涵蓋各種任務。例如，LLaMA、Vicuna 和 LLaVA 是三個 LLM 變體，使用 LLaMA 基礎模型進行訓練，採用非常不同的訓練配方、任務和資料模式。此類 LLM 變體的訓練成本和複雜度會快速增加。在本研究中，我們建議使用湯策略將這些 LLM 變體組裝成一個單一的良好泛化多模態 LLM (SoupLM)，以一種具有成本效益的方式進行。有效地組裝這些 LLM 變體，將從不同領域和資料模式訓練而來的知識和專長帶入一個整合的模式（例如，Vicuna 的使用者共享對話中的聊天機器人專長，以及 LLaVA 的視覺語言資料中的視覺能力），因此，可以避免在多個不同領域進行重複訓練的運算成本。我們提出了一系列湯策略，以系統性地比較各種組態的效能提升，並探討插值空間中基礎模型之間的湯行為。

##### **A Text-to-Game Engine for UGC-Based Role-Playing Games**
2407.08195v1 by Lei Zhang, Xuezheng Peng, Shuyi Yang, Feiyang Wang

The shift from professionally generated content (PGC) to user-generated
content (UGC) has revolutionized various media formats, from text to video.
With the rapid advancements in generative AI, a similar shift is set to
transform the game industry, particularly in the realm of role-playing games
(RPGs). This paper introduces a new framework for a text-to-game engine that
utilizes foundation models to convert simple textual inputs into complex,
interactive RPG experiences. The engine dynamically renders the game story in a
multi-modal format and adjusts the game character, environment, and mechanics
in real-time in response to player actions. Using this framework, we developed
the "Zagii" game engine, which has successfully supported hundreds of RPG games
across a diverse range of genres and facilitated tens of thousands of online
user gameplay instances. This validates the effectiveness of our frame-work.
Our work showcases the potential for a more open and democratized gaming
paradigm, highlighting the transformative impact of generative AI on the game
life cycle.

摘要：從專業產製內容 (PGC) 轉變為使用者產製內容 (UGC) 已革新各種媒體格式，從文字到影片。
隨著生成式 AI 的快速進展，類似轉變將轉換遊戲產業，特別是在角色扮演遊戲 (RPG) 的領域。這篇論文介紹一個新的文字轉遊戲引擎架構，利用基礎模型將簡單的文字輸入轉換為複雜、互動式的 RPG 體驗。引擎以多模式格式動態呈現遊戲故事，並根據玩家行動即時調整遊戲角色、環境和機制。使用這個架構，我們開發了「Zagii」遊戲引擎，它已成功支援數百款 RPG 遊戲，涵蓋各種類型，並促進數萬個線上使用者遊戲實例。這驗證了我們架構的有效性。
我們的作品展示了一個更開放、更民主化的遊戲模式的潛力，突顯了生成式 AI 對遊戲生命週期的變革性影響。

##### **ARCO:Adaptive Multi-Agent Reinforcement Learning-Based Hardware/Software Co-Optimization Compiler for Improved Performance in DNN Accelerator Design**
2407.08192v1 by Arya Fayyazi, Mehdi Kamal, Massoud Pedram

This paper presents ARCO, an adaptive Multi-Agent Reinforcement Learning
(MARL)-based co-optimizing compilation framework designed to enhance the
efficiency of mapping machine learning (ML) models - such as Deep Neural
Networks (DNNs) - onto diverse hardware platforms. The framework incorporates
three specialized actor-critic agents within MARL, each dedicated to a distinct
aspect of compilation/optimization at an abstract level: one agent focuses on
hardware, while two agents focus on software optimizations. This integration
results in a collaborative hardware/software co-optimization strategy that
improves the precision and speed of DNN deployments. Concentrating on
high-confidence configurations simplifies the search space and delivers
superior performance compared to current optimization methods. The ARCO
framework surpasses existing leading frameworks, achieving a throughput
increase of up to 37.95% while reducing the optimization time by up to 42.2%
across various DNNs.

摘要：本文提出 ARCO，一種基於適應性多智能體強化學習 (MARL) 的共同最佳化編譯架構，旨在提升將機器學習 (ML) 模型（例如深度神經網路 (DNN)) 對應到不同硬體平台的效率。此架構在 MARL 中整合了三個專門的動作-評論智能體，每個智能體在抽象層面上專注於編譯/最佳化的不同面向：一個智能體專注於硬體，而另外兩個智能體則專注於軟體最佳化。這種整合產生一種協作式硬體/軟體共同最佳化策略，可提升 DNN 部署的精準度和速度。專注於高信心的組態可簡化搜尋空間，並提供優於現有最佳化方法的卓越效能。ARCO 架構超越現有的領先架構，在各種 DNN 中實現吞吐量增加高達 37.95%，同時將最佳化時間減少高達 42.2%。

##### **fairBERTs: Erasing Sensitive Information Through Semantic and Fairness-aware Perturbations**
2407.08189v1 by Jinfeng Li, Yuefeng Chen, Xiangyu Liu, Longtao Huang, Rong Zhang, Hui Xue

Pre-trained language models (PLMs) have revolutionized both the natural
language processing research and applications. However, stereotypical biases
(e.g., gender and racial discrimination) encoded in PLMs have raised negative
ethical implications for PLMs, which critically limits their broader
applications. To address the aforementioned unfairness issues, we present
fairBERTs, a general framework for learning fair fine-tuned BERT series models
by erasing the protected sensitive information via semantic and fairness-aware
perturbations generated by a generative adversarial network. Through extensive
qualitative and quantitative experiments on two real-world tasks, we
demonstrate the great superiority of fairBERTs in mitigating unfairness while
maintaining the model utility. We also verify the feasibility of transferring
adversarial components in fairBERTs to other conventionally trained BERT-like
models for yielding fairness improvements. Our findings may shed light on
further research on building fairer fine-tuned PLMs.

摘要：預訓練語言模型（PLM）徹底改變了自然語言處理研究和應用。然而，PLM 中編碼的刻板印象偏差（例如，性別和種族歧視）對 PLM 產生了負面的道德影響，這嚴重限制了它們更廣泛的應用。為了解決上述不公平問題，我們提出了 fairBERT，這是一個通用的框架，用於學習公平微調 BERT 系列模型，方法是通過生成對抗網路產生的語義和公平感知擾動來消除受保護的敏感資訊。透過在兩個真實世界任務中進行廣泛的質性和量化實驗，我們證明了 fairBERT 在減輕不公平性方面的優越性，同時還能維持模型效用。我們也驗證了將 fairBERT 中的對抗組件轉移到其他傳統訓練的 BERT 類模型以產生公平性改進的可行性。我們的發現可能會為進一步研究構建更公平的微調 PLM 奠定基礎。

##### **Automatic Generation of Web Censorship Probe Lists**
2407.08185v1 by Jenny Tang, Leo Alvarez, Arjun Brar, Nguyen Phong Hoang, Nicolas Christin

Domain probe lists--used to determine which URLs to probe for Web
censorship--play a critical role in Internet censorship measurement studies.
Indeed, the size and accuracy of the domain probe list limits the set of
censored pages that can be detected; inaccurate lists can lead to an incomplete
view of the censorship landscape or biased results. Previous efforts to
generate domain probe lists have been mostly manual or crowdsourced. This
approach is time-consuming, prone to errors, and does not scale well to the
ever-changing censorship landscape.
  In this paper, we explore methods for automatically generating probe lists
that are both comprehensive and up-to-date for Web censorship measurement. We
start from an initial set of 139,957 unique URLs from various existing test
lists consisting of pages from a variety of languages to generate new candidate
pages. By analyzing content from these URLs (i.e., performing topic and keyword
extraction), expanding these topics, and using them as a feed to search
engines, our method produces 119,255 new URLs across 35,147 domains. We then
test the new candidate pages by attempting to access each URL from servers in
eleven different global locations over a span of four months to check for their
connectivity and potential signs of censorship. Our measurements reveal that
our method discovered over 1,400 domains--not present in the original
dataset--we suspect to be blocked. In short, automatically updating probe lists
is possible, and can help further automate censorship measurements at scale.

摘要：網域探測清單（用於判斷哪些網址要探測網路審查）在網路審查測量研究中扮演著關鍵角色。事實上，網域探測清單的大小和準確性會限制可偵測到的受審查網頁；不準確的清單可能會導致審查情況的觀點不完整或結果有偏差。過去產生網域探測清單的方法大多是手動或群眾外包。這種方法耗時、容易出錯，而且無法很好地應對不斷變化的審查情況。
在本文中，我們探討了自動產生既全面又最新的探測清單的方法，以用於網路審查測量。我們從 139,957 個來自各種現有測試清單的獨特網址開始，這些清單包含各種語言的網頁，以產生新的候選網頁。透過分析這些網址的內容（例如，執行主題和關鍵字萃取），擴充這些主題，並將它們用作搜尋引擎的饋送，我們的做法產生了 35,147 個網域中的 119,255 個新網址。然後，我們透過嘗試從 11 個不同全球位置的伺服器存取每個網址，在四個月的時間跨度內測試新的候選網頁，以檢查它們的連線性和潛在的審查跡象。我們的測量顯示，我們的做法發現了超過 1,400 個網域（未出現在原始資料集中）我們懷疑遭到封鎖。簡而言之，自動更新探測清單是可行的，而且有助於進一步自動化大規模的審查測量。

##### **Beyond Text: Leveraging Multi-Task Learning and Cognitive Appraisal Theory for Post-Purchase Intention Analysis**
2407.08182v1 by Gerard Christopher Yeo, Shaz Furniturewala, Kokil Jaidka

Supervised machine-learning models for predicting user behavior offer a
challenging classification problem with lower average prediction performance
scores than other text classification tasks. This study evaluates multi-task
learning frameworks grounded in Cognitive Appraisal Theory to predict user
behavior as a function of users' self-expression and psychological attributes.
Our experiments show that users' language and traits improve predictions above
and beyond models predicting only from text. Our findings highlight the
importance of integrating psychological constructs into NLP to enhance the
understanding and prediction of user actions. We close with a discussion of the
implications for future applications of large language models for computational
psychology.

摘要：監督機器學習模型用於預測使用者行為，提供具有較低平均預測效能評分的挑戰性分類問題，低於其他文字分類任務。本研究評估以認知評估理論為基礎的多任務學習架構，以預測使用者行為為使用者自我表達和心理屬性的函數。我們的實驗顯示，使用者的語言和特質可改善預測，且優於僅從文字預測的模型。我們的研究結果強調將心理建構整合到自然語言處理中的重要性，以增進對使用者行為的理解和預測。我們以討論大型語言模型在計算心理學中未來應用程式之含意做為結尾。

##### **CoGS: Causality Constrained Counterfactual Explanations using goal-directed ASP**
2407.08179v1 by Sopam Dasgupta, Joaquín Arias, Elmer Salazar, Gopal Gupta

Machine learning models are increasingly used in areas such as loan approvals
and hiring, yet they often function as black boxes, obscuring their
decision-making processes. Transparency is crucial, and individuals need
explanations to understand decisions, especially for the ones not desired by
the user. Ethical and legal considerations require informing individuals of
changes in input attribute values (features) that could lead to a desired
outcome for the user. Our work aims to generate counterfactual explanations by
considering causal dependencies between features. We present the CoGS
(Counterfactual Generation with s(CASP)) framework that utilizes the
goal-directed Answer Set Programming system s(CASP) to generate counterfactuals
from rule-based machine learning models, specifically the FOLD-SE algorithm.
CoGS computes realistic and causally consistent changes to attribute values
taking causal dependencies between them into account. It finds a path from an
undesired outcome to a desired one using counterfactuals. We present details of
the CoGS framework along with its evaluation.

摘要：機器學習模型在貸款核准和聘雇等領域中使用越來越廣泛，但它們通常以黑盒子的方式運作，讓人無法了解其決策過程。透明度至關重要，個人需要解釋才能了解決策，特別是使用者不想要的決策。倫理和法律考量要求告知個人輸入屬性值（特徵）的變更，這可能會導致使用者想要的結果。我們的研究旨在透過考量特徵之間的因果關係來產生反事實解釋。我們提出 CoGS（反事實產生與 s(CASP)）架構，它利用目標導向的 Answer Set 程式設計系統 s(CASP) 從基於規則的機器學習模型（特別是 FOLD-SE 演算法）產生反事實。CoGS 計算屬性值的實際且因果一致的變更，並考量它們之間的因果關係。它使用反事實找出從不想要的結果到想要的結果的路徑。我們會說明 CoGS 架構的詳細資訊以及其評估。

##### **Foundation Model Engineering: Engineering Foundation Models Just as Engineering Software**
2407.08176v1 by Dezhi Ran, Mengzhou Wu, Wei Yang, Tao Xie

By treating data and models as the source code, Foundation Models (FMs)
become a new type of software. Mirroring the concept of software crisis, the
increasing complexity of FMs making FM crisis a tangible concern in the coming
decade, appealing for new theories and methodologies from the field of software
engineering. In this paper, we outline our vision of introducing Foundation
Model (FM) engineering, a strategic response to the anticipated FM crisis with
principled engineering methodologies. FM engineering aims to mitigate potential
issues in FM development and application through the introduction of
declarative, automated, and unified programming interfaces for both data and
model management, reducing the complexities involved in working with FMs by
providing a more structured and intuitive process for developers. Through the
establishment of FM engineering, we aim to provide a robust, automated, and
extensible framework that addresses the imminent challenges, and discovering
new research opportunities for the software engineering field.

摘要：透過將資料和模型視為原始碼，基礎模型 (FM) 成為一種新型軟體。呼應軟體危機的概念，FM 的複雜性日益提升，使得 FM 危機在未來十年內成為具體的隱憂，呼籲軟體工程領域提出新的理論和方法。在本文中，我們概述了我們推動基礎模型 (FM) 工程的願景，這是一種策略性的回應，旨在透過有原則的工程方法來應對預期的 FM 危機。FM 工程旨在透過為資料和模型管理導入宣告式、自動化且統一的程式設計介面，來減輕 FM 開發和應用中的潛在問題，並透過為開發人員提供更結構化且直觀的流程，來降低使用 FM 所涉及的複雜性。透過建立 FM 工程，我們旨在提供一個強健、自動化且可擴充的架構，以應對迫在眉睫的挑戰，並為軟體工程領域探索新的研究機會。

##### **Faster Machine Unlearning via Natural Gradient Descent**
2407.08169v1 by Omri Lev, Ashia Wilson

We address the challenge of efficiently and reliably deleting data from
machine learning models trained using Empirical Risk Minimization (ERM), a
process known as machine unlearning. To avoid retraining models from scratch,
we propose a novel algorithm leveraging Natural Gradient Descent (NGD). Our
theoretical framework ensures strong privacy guarantees for convex models,
while a practical Min/Max optimization algorithm is developed for non-convex
models. Comprehensive evaluations show significant improvements in privacy,
computational efficiency, and generalization compared to state-of-the-art
methods, advancing both the theoretical and practical aspects of machine
unlearning.

摘要：我們處理從使用經驗風險最小化 (ERM) 訓練的機器學習模型中有效且可靠地刪除資料的挑戰，這個程序稱為機器遺忘。為了避免從頭開始重新訓練模型，我們提出了一種利用自然梯度下降 (NGD) 的新演算法。我們的理論架構確保了凸模型的強隱私保證，同時為非凸模型開發了一個實用的 Min/Max 最佳化演算法。全面的評估顯示，與最先進的方法相比，隱私、運算效率和概化都有顯著的改善，推動了機器遺忘的理論和實務層面。

##### **Synthetic Electroretinogram Signal Generation Using Conditional Generative Adversarial Network for Enhancing Classification of Autism Spectrum Disorder**
2407.08166v1 by Mikhail Kulyabin, Paul A. Constable, Aleksei Zhdanov, Irene O. Lee, David H. Skuse, Dorothy A. Thompson, Andreas Maier

The electroretinogram (ERG) is a clinical test that records the retina's
electrical response to light. The ERG is a promising way to study different
neurodevelopmental and neurodegenerative disorders, including autism spectrum
disorder (ASD) - a neurodevelopmental condition that impacts language,
communication, and reciprocal social interactions. However, in heterogeneous
populations, such as ASD, where the ability to collect large datasets is
limited, the application of artificial intelligence (AI) is complicated.
Synthetic ERG signals generated from real ERG recordings carry similar
information as natural ERGs and, therefore, could be used as an extension for
natural data to increase datasets so that AI applications can be fully
utilized. As proof of principle, this study presents a Generative Adversarial
Network capable of generating synthetic ERG signals of children with ASD and
typically developing control individuals. We applied a Time Series Transformer
and Visual Transformer with Continuous Wavelet Transform to enhance
classification results on the extended synthetic signals dataset. This approach
may support classification models in related psychiatric conditions where the
ERG may help classify disorders.

摘要：視網膜電圖 (ERG) 是一種臨床測試，用於記錄視網膜對光的電氣反應。ERG 是一種很有前途的研究不同神經發育和神經退化性疾病的方法，包括自閉症譜系障礙 (ASD) - 一種影響語言、溝通和社交互動的神經發育狀況。然而，在異質人群中，例如 ASD，收集大型數據集的能力有限，人工智能 (AI) 的應用很複雜。從真實 ERG 記錄中產生的合成 ERG 信號攜帶與自然 ERG 相似的信息，因此可用作自然數據的擴展，以增加數據集，以便 AI 應用程序可以得到充分利用。作為原理證明，本研究提出了一個生成對抗網路，能夠產生自閉症兒童和正常發育對照個人的合成 ERG 信號。我們應用時序轉換器和具有連續小波轉換的視覺轉換器來增強擴展合成信號數據集上的分類結果。這種方法可以支持相關精神疾病的分類模型，在這些疾病中，ERG 可能有助於對疾病進行分類。

##### **Privacy-Preserving Data Deduplication for Enhancing Federated Learning of Language Models**
2407.08152v1 by Aydin Abadi, Vishnu Asutosh Dasu, Sumanta Sarkar

Deduplication is a vital preprocessing step that enhances machine learning
model performance and saves training time and energy. However, enhancing
federated learning through deduplication poses challenges, especially regarding
scalability and potential privacy violations if deduplication involves sharing
all clients' data. In this paper, we address the problem of deduplication in a
federated setup by introducing a pioneering protocol, Efficient
Privacy-Preserving Multi-Party Deduplication (EP-MPD). It efficiently removes
duplicates from multiple clients' datasets without compromising data privacy.
EP-MPD is constructed in a modular fashion, utilizing two novel variants of the
Private Set Intersection protocol. Our extensive experiments demonstrate the
significant benefits of deduplication in federated learning of large language
models. For instance, we observe up to 19.61% improvement in perplexity and up
to 27.95% reduction in running time. EP-MPD effectively balances privacy and
performance in federated learning, making it a valuable solution for
large-scale applications.

摘要：重複資料刪除是一個重要的預處理步驟，可以提升機器學習模型的效能，並節省訓練時間和精力。然而，透過重複資料刪除來強化聯邦學習會帶來挑戰，特別是在可擴充性和潛在的隱私權侵犯方面，如果重複資料刪除涉及分享所有用戶的資料。在本文中，我們透過引入一個創新的協定，有效率的隱私保護多方重複資料刪除（EP-MPD），來解決聯邦設定中的重複資料刪除問題。它可以有效率地從多個用戶的資料集中移除重複資料，而不會損害資料隱私。EP-MPD 是以模組化方式建構的，利用了私密集合交集協定的兩個新變體。我們廣泛的實驗證明了重複資料刪除在大型語言模型的聯邦學習中具有顯著的優點。例如，我們觀察到困惑度最高改善了 19.61%，執行時間最多減少了 27.95%。EP-MPD 有效地在聯邦學習中平衡了隱私和效能，使其成為大規模應用的一個有價值的解決方案。

##### **Looks can be Deceptive: Distinguishing Repetition Disfluency from Reduplication**
2407.08147v1 by Arif Ahmad, Mothika Gayathri Khyathi, Pushpak Bhattacharyya

Reduplication and repetition, though similar in form, serve distinct
linguistic purposes. Reduplication is a deliberate morphological process used
to express grammatical, semantic, or pragmatic nuances, while repetition is
often unintentional and indicative of disfluency. This paper presents the first
large-scale study of reduplication and repetition in speech using computational
linguistics. We introduce IndicRedRep, a new publicly available dataset
containing Hindi, Telugu, and Marathi text annotated with reduplication and
repetition at the word level. We evaluate transformer-based models for
multi-class reduplication and repetition token classification, utilizing the
Reparandum-Interregnum-Repair structure to distinguish between the two
phenomena. Our models achieve macro F1 scores of up to 85.62% in Hindi, 83.95%
in Telugu, and 84.82% in Marathi for reduplication-repetition classification.

摘要：重複和重言雖然形式相似，但在語言學上卻有不同的用途。重複是一種故意的形態過程，用於表達語法、語義或語用上的細微差別，而重言通常是不自覺的，且表示言語不流暢。本文提出使用計算語言學進行重複和重言的第一個大規模研究。我們引入了 IndicRedRep，一個新的公開可用的資料集，其中包含標註了印地語、泰盧固語和馬拉地語文字中詞級的重複和重言。我們評估了基於Transformer的多類重複和重言標記分類模型，利用 Reparandum-Interregnum-Repair 結構來區分這兩種現象。我們的模型在印地語中重複-重言分類的宏觀 F1 分數高達 85.62%，泰盧固語為 83.95%，馬拉地語為 84.82%。

##### **Highway Networks for Improved Surface Reconstruction: The Role of Residuals and Weight Updates**
2407.08134v1 by A. Noorizadegan, Y. C. Hon, D. L. Young, C. S. Chen

Surface reconstruction from point clouds is a fundamental challenge in
computer graphics and medical imaging. In this paper, we explore the
application of advanced neural network architectures for the accurate and
efficient reconstruction of surfaces from data points. We introduce a novel
variant of the Highway network (Hw) called Square-Highway (SqrHw) within the
context of multilayer perceptrons and investigate its performance alongside
plain neural networks and a simplified Hw in various numerical examples. These
examples include the reconstruction of simple and complex surfaces, such as
spheres, human hands, and intricate models like the Stanford Bunny. We analyze
the impact of factors such as the number of hidden layers, interior and
exterior points, and data distribution on surface reconstruction quality. Our
results show that the proposed SqrHw architecture outperforms other neural
network configurations, achieving faster convergence and higher-quality surface
reconstructions. Additionally, we demonstrate the SqrHw's ability to predict
surfaces over missing data, a valuable feature for challenging applications
like medical imaging. Furthermore, our study delves into further details,
demonstrating that the proposed method based on highway networks yields more
stable weight norms and backpropagation gradients compared to the Plain Network
architecture. This research not only advances the field of computer graphics
but also holds utility for other purposes such as function interpolation and
physics-informed neural networks, which integrate multilayer perceptrons into
their algorithms.

摘要：從點雲進行曲面重建是電腦圖學和醫學影像中的一項基本挑戰。在本文中，我們探討了先進神經網路架構在從資料點精確且有效重建曲面中的應用。我們在多層感知器的架構中，引入了高速公路網路（Hw）的一種新變體，稱為 Square-Highway（SqrHw），並在各種數值範例中探討其效能，以及與一般神經網路和簡化的 Hw 的效能。這些範例包括重建簡單和複雜的曲面，例如球體、人手和像 Stanford Bunny 那樣複雜的模型。我們分析了隱藏層數、內部和外部點以及資料分佈等因素對曲面重建品質的影響。我們的結果顯示，所提出的 SqrHw 架構優於其他神經網路組態，能達成更快的收斂速度和更高品質的曲面重建。此外，我們展示了 SqrHw 能夠預測遺失資料上的曲面，這對於像醫學影像那樣具有挑戰性的應用來說，是一個有價值的功能。此外，我們的研究深入探討了更多細節，證明了基於高速公路網路的所提出方法，與一般網路架構相比，產生了更穩定的權重範數和反向傳播梯度。這項研究不僅推動了電腦圖學領域，也對其他用途有幫助，例如函數內插和物理資訊神經網路，將多層感知器整合到其演算法中。

##### **Nonverbal Interaction Detection**
2407.08133v1 by Jianan Wei, Tianfei Zhou, Yi Yang, Wenguan Wang

This work addresses a new challenge of understanding human nonverbal
interaction in social contexts. Nonverbal signals pervade virtually every
communicative act. Our gestures, facial expressions, postures, gaze, even
physical appearance all convey messages, without anything being said. Despite
their critical role in social life, nonverbal signals receive very limited
attention as compared to the linguistic counterparts, and existing solutions
typically examine nonverbal cues in isolation. Our study marks the first
systematic effort to enhance the interpretation of multifaceted nonverbal
signals. First, we contribute a novel large-scale dataset, called NVI, which is
meticulously annotated to include bounding boxes for humans and corresponding
social groups, along with 22 atomic-level nonverbal behaviors under five broad
interaction types. Second, we establish a new task NVI-DET for nonverbal
interaction detection, which is formalized as identifying triplets in the form
<individual, group, interaction> from images. Third, we propose a nonverbal
interaction detection hypergraph (NVI-DEHR), a new approach that explicitly
models high-order nonverbal interactions using hypergraphs. Central to the
model is a dual multi-scale hypergraph that adeptly addresses
individual-to-individual and group-to-group correlations across varying scales,
facilitating interactional feature learning and eventually improving
interaction prediction. Extensive experiments on NVI show that NVI-DEHR
improves various baselines significantly in NVI-DET. It also exhibits leading
performance on HOI-DET, confirming its versatility in supporting related tasks
and strong generalization ability. We hope that our study will offer the
community new avenues to explore nonverbal signals in more depth.

摘要：<paragraph>這項工作解決了在社交情境中理解人類非語言互動的新挑戰。非語言信號幾乎存在於每一個溝通行為中。我們的肢體動作、面部表情、姿勢、注視，甚至外觀都會傳達訊息，而無需言語。儘管非語言信號在社交生活中扮演著重要的角色，但與語言信號相比，它們受到的關注卻非常有限，而現有的解決方案通常孤立地檢視非語言線索。我們的研究標誌著首次有系統地努力增強對多面向非語言信號的詮釋。首先，我們貢獻了一個新穎的大規模資料集，稱為 NVI，它經過仔細註解，包括人類和對應社交群體的邊界框，以及五種類型互動中的 22 種原子級非語言行為。其次，我們建立了一個新的任務 NVI-DET，用於非語言互動偵測，其形式化為從影像中識別形式為<個人、群體、互動>的三元組。第三，我們提出了一個非語言互動偵測超圖（NVI-DEHR），這是一種新方法，它使用超圖明確地建模高階非語言互動。該模型的核心是一個雙多尺度超圖，它巧妙地處理了不同尺度上的個人對個人和群體對群體的相關性，促進了互動特徵學習，並最終改進了互動預測。在 NVI 上進行的廣泛實驗表明，NVI-DEHR 在 NVI-DET 中顯著改善了各種基準。它還在 HOI-DET 上展現了領先的效能，確認了它在支援相關任務和強大的泛化能力方面的多功能性。我們希望我們的研究能為社群提供新的途徑，更深入地探索非語言信號。</paragraph>

##### **Label-anticipated Event Disentanglement for Audio-Visual Video Parsing**
2407.08126v1 by Jinxing Zhou, Dan Guo, Yuxin Mao, Yiran Zhong, Xiaojun Chang, Meng Wang

Audio-Visual Video Parsing (AVVP) task aims to detect and temporally locate
events within audio and visual modalities. Multiple events can overlap in the
timeline, making identification challenging. While traditional methods usually
focus on improving the early audio-visual encoders to embed more effective
features, the decoding phase -- crucial for final event classification, often
receives less attention. We aim to advance the decoding phase and improve its
interpretability. Specifically, we introduce a new decoding paradigm,
\underline{l}abel s\underline{e}m\underline{a}ntic-based \underline{p}rojection
(LEAP), that employs labels texts of event categories, each bearing distinct
and explicit semantics, for parsing potentially overlapping events.LEAP works
by iteratively projecting encoded latent features of audio/visual segments onto
semantically independent label embeddings. This process, enriched by modeling
cross-modal (audio/visual-label) interactions, gradually disentangles event
semantics within video segments to refine relevant label embeddings,
guaranteeing a more discriminative and interpretable decoding process. To
facilitate the LEAP paradigm, we propose a semantic-aware optimization
strategy, which includes a novel audio-visual semantic similarity loss
function. This function leverages the Intersection over Union of audio and
visual events (EIoU) as a novel metric to calibrate audio-visual similarities
at the feature level, accommodating the varied event densities across
modalities. Extensive experiments demonstrate the superiority of our method,
achieving new state-of-the-art performance for AVVP and also enhancing the
relevant audio-visual event localization task.

摘要：視聽影片解析 (AVVP) 任務旨在偵測和暫時定位音訊和視覺模式中的事件。多重事件可能會在時間軸中重疊，使得識別具有挑戰性。雖然傳統方法通常專注於改進早期音訊視覺編碼器以嵌入更有效的特徵，但對於最終事件分類至關重要的解碼階段，通常較少受到關注。我們旨在推進解碼階段並改善其可解釋性。具體來說，我們引入一種新的解碼範例，\underline{l}abel s\underline{e}m\underline{a}ntic-based \underline{p}rojection (LEAP)，它採用事件類別的標籤文字，每個文字都帶有不同的明確語義，用於解析潛在重疊事件。LEAP 的運作方式是將音訊/視覺片段的編碼潛在特徵反覆投影到語義獨立的標籤嵌入中。這個過程透過建模跨模態（音訊/視覺標籤）互動而得到豐富，逐漸解開影片片段中的事件語義，以改善相關標籤嵌入，保證更具區辨力和可解釋性的解碼過程。為了促進 LEAP 範例，我們提出一個語義感知最佳化策略，其中包括一個新穎的音訊視覺語義相似性損失函數。此函數利用音訊和視覺事件的聯合相對於交集 (EIoU) 作為一個新穎的指標，用於校準特徵層級的音訊視覺相似性，以適應各種跨模態的事件密度。廣泛的實驗證明了我們方法的優越性，在 AVVP 中取得了新的最先進效能，並增強了相關的音訊視覺事件定位任務。

##### **How Well Can a Long Sequence Model Model Long Sequences? Comparing Architechtural Inductive Biases on Long-Context Abilities**
2407.08112v1 by Jerry Huang

Long sequences occur in abundance within real-world scenarios, hence properly
modelling them opens numerous down-stream use-cases. Deep neural networks,
however, have often struggled with these for a variety of reasons. Recent
advances, both in system engineering as well as model design, have enabled the
scaling up of model that are purported to support extended context length. In
particular, the state-space and linear recurrent neural network families of
models hypothetically can entend to infinite sequence lenth. However, is this
too good to be true? We conduct an evaluation to show that while such claims
may be sound theoretically, there remain large practical gaps that are
empirically observed. In particular, recurrent models still suffer in the same
settings as long-context LLMs with attention. We further show that different
inductive biases have inconsistent extrapolation capabilities, highlighting the
need to further study such paradigms and investigate why long-context models
seemingly fail to behave as one might expect.

摘要：長序列在現實世界中大量出現，因此適當的建模為我們開啟了許多下游用例。然而，由於各種原因，深度神經網路經常難以處理這些序列。系統工程和模型設計的最新進展，使得擴展模型的上下文長度成為可能，而這些模型據稱可以支援擴展的上下文長度。特別是，狀態空間和線性遞迴神經網路的模型族在理論上可以延伸到無限序列長度。然而，這是否好得令人難以置信？我們進行了一項評估，以表明雖然這些說法在理論上可能是合理的，但仍存在大量在經驗上觀察到的實際差距。特別是，遞迴模型在與具有注意力的長上下文 LLM 相同的設定中仍然表現不佳。我們進一步表明，不同的歸納偏差具有不一致的外推能力，強調了進一步研究這些範例和調查為什麼長上下文模型看似無法按照預期行為的必要性。

##### **Urban Waterlogging Detection: A Challenging Benchmark and Large-Small Model Co-Adapter**
2407.08109v1 by Suqi Song, Chenxu Zhang, Peng Zhang, Pengkun Li, Fenglong Song, Lei Zhang

Urban waterlogging poses a major risk to public safety and infrastructure.
Conventional methods using water-level sensors need high-maintenance to hardly
achieve full coverage. Recent advances employ surveillance camera imagery and
deep learning for detection, yet these struggle amidst scarce data and adverse
environmental conditions. In this paper, we establish a challenging Urban
Waterlogging Benchmark (UW-Bench) under diverse adverse conditions to advance
real-world applications. We propose a Large-Small Model co-adapter paradigm
(LSM-adapter), which harnesses the substantial generic segmentation potential
of large model and the specific task-directed guidance of small model.
Specifically, a Triple-S Prompt Adapter module alongside a Dynamic Prompt
Combiner are proposed to generate then merge multiple prompts for mask decoder
adaptation. Meanwhile, a Histogram Equalization Adap-ter module is designed to
infuse the image specific information for image encoder adaptation. Results and
analysis show the challenge and superiority of our developed benchmark and
algorithm. Project page: \url{https://github.com/zhang-chenxu/LSM-Adapter}

摘要：城市內澇對公共安全和基礎設施構成重大風險。
使用水位感測器的傳統方法需要高維護，難以實現全面覆蓋。最近的進展採用監控相機影像和深度學習進行偵測，但這些方法在稀缺的資料和惡劣的環境條件下仍面臨挑戰。在本文中，我們建立了一個具有挑戰性的城市內澇基準 (UW-Bench)，在各種不利條件下推進實際應用。我們提出了一個大型-小型模型共適應範例 (LSM-adapter)，它利用了大型模型的強大通用分割潛力和小模型的特定任務指導。
具體來說，提出了一個三 S 提示適配器模組和一個動態提示組合器，用於生成然後合併多個提示以進行遮罩解碼器適應。同時，設計了一個直方圖均衡適配器模組，用於為影像編碼器適應注入影像特定資訊。結果和分析顯示了我們開發的基準和演算法的挑戰和優越性。專案頁面：\url{https://github.com/zhang-chenxu/LSM-Adapter}

##### **CADC: Encoding User-Item Interactions for Compressing Recommendation Model Training Data**
2407.08108v1 by Hossein Entezari Zarch, Abdulla Alshabanah, Chaoyi Jiang, Murali Annavaram

Deep learning recommendation models (DLRMs) are at the heart of the current
e-commerce industry. However, the amount of training data used to train these
large models is growing exponentially, leading to substantial training hurdles.
The training dataset contains two primary types of information: content-based
information (features of users and items) and collaborative information
(interactions between users and items). One approach to reduce the training
dataset is to remove user-item interactions. But that significantly diminishes
collaborative information, which is crucial for maintaining accuracy due to its
inclusion of interaction histories. This loss profoundly impacts DLRM
performance.
  This paper makes an important observation that if one can capture the
user-item interaction history to enrich the user and item embeddings, then the
interaction history can be compressed without losing model accuracy. Thus, this
work, Collaborative Aware Data Compression (CADC), takes a two-step approach to
training dataset compression. In the first step, we use matrix factorization of
the user-item interaction matrix to create a novel embedding representation for
both the users and items. Once the user and item embeddings are enriched by the
interaction history information the approach then applies uniform random
sampling of the training dataset to drastically reduce the training dataset
size while minimizing model accuracy drop. The source code of CADC is available
at
\href{https://anonymous.4open.science/r/DSS-RM-8C1D/README.md}{https://anonymous.4open.science/r/DSS-RM-8C1D/README.md}.

摘要：深度學習推薦模型 (DLRM) 是當前電子商務產業的核心。然而，用於訓練這些大型模型的訓練資料量呈指數級增長，導致訓練面臨重大障礙。訓練資料集包含兩種類型的主要資訊：基於內容的資訊（使用者和商品的特徵）與協作資訊（使用者與商品之間的互動）。一種減少訓練資料集的方法是移除使用者與商品的互動。但是，這會大幅減少協作資訊，而協作資訊對於維持準確性至關重要，因為它包含互動記錄。這種損失會嚴重影響 DLRM 的效能。
本文提出一個重要的觀察，如果能擷取使用者與商品的互動記錄來豐富使用者和商品的嵌入，那麼互動記錄就可以在不降低模型準確性的情況下進行壓縮。因此，這項協作感知資料壓縮 (CADC) 工作採取兩步驟的方式來進行訓練資料集壓縮。在第一步中，我們使用使用者與商品互動矩陣的矩陣分解，為使用者和商品建立一個新穎的嵌入表示。一旦使用者和商品的嵌入通過互動記錄資訊得到豐富，此方法就會對訓練資料集套用均勻隨機抽樣，以大幅減少訓練資料集大小，同時將模型準確度下降降到最低。CADC 的原始程式碼可在
\href{https://anonymous.4open.science/r/DSS-RM-8C1D/README.md}{https://anonymous.4open.science/r/DSS-RM-8C1D/README.md} 取得。

##### **Federated Learning and AI Regulation in the European Union: Who is liable? An Interdisciplinary Analysis**
2407.08105v1 by Herbert Woisetschläger, Simon Mertel, Christoph Krönke, Ruben Mayer, Hans-Arno Jacobsen

The European Union Artificial Intelligence Act mandates clear stakeholder
responsibilities in developing and deploying machine learning applications to
avoid substantial fines, prioritizing private and secure data processing with
data remaining at its origin. Federated Learning (FL) enables the training of
generative AI Models across data siloes, sharing only model parameters while
improving data security. Since FL is a cooperative learning paradigm, clients
and servers naturally share legal responsibility in the FL pipeline. Our work
contributes to clarifying the roles of both parties, explains strategies for
shifting responsibilities to the server operator, and points out open technical
challenges that we must solve to improve FL's practical applicability under the
EU AI Act.

摘要：歐盟人工智慧法規要求在開發和部署機器學習應用程式時明確利害關係人的責任，以避免巨額罰款，並優先考量私密且安全的資料處理，且資料必須保留在原始位置。聯邦學習 (FL) 能夠在資料孤島之間訓練生成式 AI 模型，僅分享模型參數，同時提升資料安全性。由於 FL 是一種協作式學習範例，因此客戶端和伺服器在 FL 管道中自然會共同承擔法律責任。我們的研究有助於釐清雙方的角色，說明將責任轉移給伺服器操作員的策略，並指出在歐盟 AI 法規下改善 FL 實際適用性的開放式技術挑戰，我們必須解決這些挑戰。

##### **Automata-based constraints for language model decoding**
2407.08103v1 by Terry Koo, Frederick Liu, Luheng He

LMs are often expected to generate strings in some formal language; for
example, structured data, API calls, or code snippets. Although LMs can be
tuned to improve their adherence to formal syntax, this does not guarantee
conformance, especially with smaller LMs suitable for large-scale deployment.
In addition, tuning requires significant resources, making it impractical for
uncommon or task-specific formats. To prevent downstream parsing errors we
would ideally constrain the LM to only produce valid output, but this is
severely complicated by tokenization, which is typically both ambiguous and
misaligned with the formal grammar. We solve these issues through the
application of automata theory, deriving an efficient closed-form solution for
the regular languages, a broad class of formal languages with many practical
applications, including API calls or schema-guided JSON and YAML. We also
discuss pragmatic extensions for coping with the issue of high branching
factor. Finally, we extend our techniques to deterministic context-free
languages, which similarly admit an efficient closed-form solution. In spite of
its flexibility and representative power, our approach only requires access to
per-token decoding logits and lowers into simple calculations that are
independent of LM size, making it both efficient and easy to apply to almost
any LM architecture.

摘要：語言模型通常會被期待產生一些形式語言的字串；例如結構化資料、API 呼叫或程式碼片段。雖然語言模型可以調整以改善它們對形式語法的遵循，這並不保證相容性，特別是對於適合大規模部署的小型語言模型。此外，調整需要大量的資源，這使得它對於不常見或特定於任務的格式來說不切實際。為了防止下游的解析錯誤，我們理想上會限制語言模型只產生有效的輸出，但這會因為通常模稜兩可且與形式文法不一致的標記化而變得非常複雜。我們透過應用自動機理論來解決這些問題，為正則語言導出一個有效的閉合形式解，正則語言是形式語言的一大類別，有許多實際應用，包括 API 呼叫或受架構引導的 JSON 和 YAML。我們還會討論用於應對高分支係數問題的務實擴充。最後，我們將我們的技術擴充到確定上下文無關語言，它同樣承認一個有效的閉合形式解。儘管具有靈活性與代表能力，我們的做法只需要存取每個標記的解碼 logit，並降低為與語言模型大小無關的簡單計算，這使得它既有效率又容易應用於幾乎任何語言模型架構。

##### **How does Burrows' Delta work on medieval Chinese poetic texts?**
2407.08099v1 by Boris Orekhov

Burrows' Delta was introduced in 2002 and has proven to be an effective tool
for author attribution. Despite the fact that these are different languages,
they mostly belong to the same grammatical type and use the same graphic
principle to convey speech in writing: a phonemic alphabet with word separation
using spaces. The question I want to address in this article is how well this
attribution method works with texts in a language with a different grammatical
structure and a script based on different principles. There are fewer studies
analyzing the effectiveness of the Delta method on Chinese texts than on texts
in European languages. I believe that such a low level of attention to Delta
from sinologists is due to the structure of the scientific field dedicated to
medieval Chinese poetry. Clustering based on intertextual distances worked
flawlessly. Delta produced results where clustering showed that the samples of
one author were most similar to each other, and Delta never confused different
poets. Despite the fact that I used an unconventional approach and applied the
Delta method to a language poorly suited for it, the method demonstrated its
effectiveness. Tang dynasty poets are correctly identified using Delta, and the
empirical pattern observed for authors writing in European standard languages
has been confirmed once again.

摘要：伯羅斯三角洲於 2002 年推出，已被證明是一種有效的作者歸屬工具。儘管這些是不同的語言，但它們大多屬於相同的語法類型，並使用相同的圖形原理以書面形式傳達語言：一個音素字母表，使用空格進行單詞分隔。我想在這篇文章中探討的問題是，這種歸屬方法在語言結構不同且基於不同原理的腳本中的文本中效果如何。分析三角洲方法對中文文本的有效性的研究少於對歐洲語言文本的研究。我相信漢學家對三角洲的關注度如此之低，是因為致力於中國中古詩歌的科學領域的結構。基於互文距離的聚類運作良好。三角洲產生了聚類結果，表明一位作者的樣本彼此最相似，而三角洲從未混淆過不同的詩人。儘管我使用了非常規的方法，並將三角洲方法應用於一種不太適合它的語言，但該方法證明了它的有效性。唐代詩人使用三角洲被正確識別，並且在歐洲標準語言中寫作的作者觀察到的經驗模式再次得到證實。

##### **Virtual Agents for Alcohol Use Counseling: Exploring LLM-Powered Motivational Interviewing**
2407.08095v1 by Ian Steenstra, Farnaz Nouraei, Mehdi Arjmand, Timothy W. Bickmore

We introduce a novel application of large language models (LLMs) in
developing a virtual counselor capable of conducting motivational interviewing
(MI) for alcohol use counseling. Access to effective counseling remains
limited, particularly for substance abuse, and virtual agents offer a promising
solution by leveraging LLM capabilities to simulate nuanced communication
techniques inherent in MI. Our approach combines prompt engineering and
integration into a user-friendly virtual platform to facilitate realistic,
empathetic interactions. We evaluate the effectiveness of our virtual agent
through a series of studies focusing on replicating MI techniques and human
counselor dialog. Initial findings suggest that our LLM-powered virtual agent
matches human counselors' empathetic and adaptive conversational skills,
presenting a significant step forward in virtual health counseling and
providing insights into the design and implementation of LLM-based therapeutic
interactions.

摘要：我們提出了一個大型語言模型 (LLM) 的新應用，用於開發一個虛擬諮詢師，能夠進行動機性訪談 (MI) 以進行酒精使用諮詢。獲得有效的諮詢仍然有限，特別是對於物質濫用，而虛擬代理則提供了一個有前途的解決方案，利用 LLM 能力來模擬 MI 中固有的細微溝通技巧。我們的做法結合了提示工程並整合到一個使用者友善的虛擬平台中，以促進真實、同理的互動。我們透過一系列專注於複製 MI 技術和人類諮詢師對話的研究來評估我們虛擬代理的有效性。初步發現表明，我們由 LLM 驅動的虛擬代理與人類諮詢師的同理心和適應性對話技能相匹配，這代表了虛擬健康諮詢向前邁進一大步，並提供了對基於 LLM 的治療性互動的設計和實施的見解。

##### **MemWarp: Discontinuity-Preserving Cardiac Registration with Memorized Anatomical Filters**
2407.08093v1 by Hang Zhang, Xiang Chen, Renjiu Hu, Dongdong Liu, Gaolei Li, Rongguang Wang

Many existing learning-based deformable image registration methods impose
constraints on deformation fields to ensure they are globally smooth and
continuous. However, this assumption does not hold in cardiac image
registration, where different anatomical regions exhibit asymmetric motions
during respiration and movements due to sliding organs within the chest.
Consequently, such global constraints fail to accommodate local discontinuities
across organ boundaries, potentially resulting in erroneous and unrealistic
displacement fields. In this paper, we address this issue with MemWarp, a
learning framework that leverages a memory network to store prototypical
information tailored to different anatomical regions. MemWarp is different from
earlier approaches in two main aspects: firstly, by decoupling feature
extraction from similarity matching in moving and fixed images, it facilitates
more effective utilization of feature maps; secondly, despite its capability to
preserve discontinuities, it eliminates the need for segmentation masks during
model inference. In experiments on a publicly available cardiac dataset, our
method achieves considerable improvements in registration accuracy and
producing realistic deformations, outperforming state-of-the-art methods with a
remarkable 7.1\% Dice score improvement over the runner-up semi-supervised
method. Source code will be available at https://github.com/tinymilky/Mem-Warp.

摘要：許多現有的基於學習的形變影像配準方法對形變場施加約束，以確保它們在整體上是平滑且連續的。然而，此假設不適用於心臟影像配準，其中不同的解剖區域在呼吸和胸部器官滑動所造成的運動中表現出不對稱的運動。因此，此類全局約束無法適應器官邊界上的局部不連續性，可能會導致錯誤且不切實際的位移場。在本文中，我們使用 MemWarp 來解決此問題，MemWarp 是一種學習架構，它利用記憶網路來儲存針對不同解剖區域量身打造的原型資訊。MemWarp 在兩個主要方面不同於早期的做法：首先，透過將特徵萃取與移動和固定影像中的相似性比對分開，它促進了特徵圖的更有效利用；其次，儘管它有能力保留不連續性，但在模型推論期間卻消除了對分割遮罩的需求。在公開的心臟資料集上進行的實驗中，我們的模型在配準準確度和產生逼真的形變方面取得了顯著的進步，優於最先進的方法，與亞軍半監督方法相比，Dice 分數提高了 7.1%。原始碼將在 https://github.com/tinymilky/Mem-Warp 中提供。

##### **NDST: Neural Driving Style Transfer for Human-Like Vision-Based Autonomous Driving**
2407.08073v1 by Donghyun Kim, Aws Khalil, Haewoon Nam, Jaerock Kwon

Autonomous Vehicles (AV) and Advanced Driver Assistant Systems (ADAS)
prioritize safety over comfort. The intertwining factors of safety and comfort
emerge as pivotal elements in ensuring the effectiveness of Autonomous Driving
(AD). Users often experience discomfort when AV or ADAS drive the vehicle on
their behalf. Providing a personalized human-like AD experience, tailored to
match users' unique driving styles while adhering to safety prerequisites,
presents a significant opportunity to boost the acceptance of AVs. This paper
proposes a novel approach, Neural Driving Style Transfer (NDST), inspired by
Neural Style Transfer (NST), to address this issue. NDST integrates a
Personalized Block (PB) into the conventional Baseline Driving Model (BDM),
allowing for the transfer of a user's unique driving style while adhering to
safety parameters. The PB serves as a self-configuring system, learning and
adapting to an individual's driving behavior without requiring modifications to
the BDM. This approach enables the personalization of AV models, aligning the
driving style more closely with user preferences while ensuring baseline safety
critical actuation. Two contrasting driving styles (Style A and Style B) were
used to validate the proposed NDST methodology, demonstrating its efficacy in
transferring personal driving styles to the AV system. Our work highlights the
potential of NDST to enhance user comfort in AVs by providing a personalized
and familiar driving experience. The findings affirm the feasibility of
integrating NDST into existing AV frameworks to bridge the gap between safety
and individualized driving styles, promoting wider acceptance and improved user
experiences.

摘要：<paragraph>自動駕駛車輛 (AV) 和先進駕駛輔助系統 (ADAS)
優先考慮安全性而非舒適性。安全性和舒適性的交織因素
成為確保自動駕駛 (AD) 有效性的關鍵要素。當 AV 或 ADAS 代表
使用者駕駛車輛時，使用者經常會感到不適。提供個人化的類人 AD 體驗，
量身打造以符合使用者的獨特駕駛風格，同時遵守安全前提，
這是一個提升 AV 接受度的重大契機。本文
提出一個新穎的方法，神經駕駛風格轉移 (NDST)，靈感來自
神經風格轉移 (NST)，以解決此問題。NDST 將
個人化區塊 (PB) 整合到傳統的基準駕駛模型 (BDM) 中，
允許在遵守安全參數的同時轉移使用者的獨特駕駛風格。PB 作為一個自組態系統，
學習和適應個人的駕駛行為，而不需要修改 BDM。這種方法使 AV 模型個人化，
讓駕駛風格更符合使用者偏好，同時確保基準安全
關鍵動作。兩種對比的駕駛風格（風格 A 和風格 B）被
用於驗證所提出的 NDST 方法，證明其在將個人駕駛風格轉移到 AV 系統中的有效性。我們的研究重點介紹了 NDST 在 AV 中增強使用者舒適度的潛力，方法是提供個人化
且熟悉的駕駛體驗。研究結果肯定了將 NDST 整合到現有 AV 框架中的可行性，以彌合安全
和個性化駕駛風格之間的差距，促進更廣泛的接受度和改善使用者
體驗。</paragraph>

##### **On LLM Wizards: Identifying Large Language Models' Behaviors for Wizard of Oz Experiments**
2407.08067v1 by Jingchao Fang, Nikos Arechiga, Keiichi Namaoshi, Nayeli Bravo, Candice Hogan, David A. Shamma

The Wizard of Oz (WoZ) method is a widely adopted research approach where a
human Wizard ``role-plays'' a not readily available technology and interacts
with participants to elicit user behaviors and probe the design space. With the
growing ability for modern large language models (LLMs) to role-play, one can
apply LLMs as Wizards in WoZ experiments with better scalability and lower cost
than the traditional approach. However, methodological guidance on responsibly
applying LLMs in WoZ experiments and a systematic evaluation of LLMs'
role-playing ability are lacking. Through two LLM-powered WoZ studies, we take
the first step towards identifying an experiment lifecycle for researchers to
safely integrate LLMs into WoZ experiments and interpret data generated from
settings that involve Wizards role-played by LLMs. We also contribute a
heuristic-based evaluation framework that allows the estimation of LLMs'
role-playing ability in WoZ experiments and reveals LLMs' behavior patterns at
scale.

摘要：綠野仙蹤 (WoZ) 方法是一種廣泛採用的研究方法，其中人類「扮演」一種尚未問世的技術，並與參與者互動以引發使用者行為並探討設計空間。隨著現代大型語言模型 (LLM) 扮演角色的能力日益增強，人們可以將 LLM 應用於 WoZ 實驗中的精靈，其可擴充性和成本低於傳統方法。然而，目前缺乏關於在 WoZ 實驗中負責任地應用 LLM 的方法指導，以及對 LLM 角色扮演能力的系統性評估。透過兩項 LLM 驅動的 WoZ 研究，我們邁出了第一步，以識別實驗生命週期，讓研究人員可以安全地將 LLM 整合到 WoZ 實驗中，並解釋從精靈扮演 LLM 的設定中產生的資料。我們還提供了一個基於啟發法的評估架構，可以估計 LLM 在 WoZ 實驗中的角色扮演能力，並揭示 LLM 的行為模式。

##### **Towards Interpretable Foundation Models of Robot Behavior: A Task Specific Policy Generation Approach**
2407.08065v1 by Isaac Sheidlower, Reuben Aronson, Elaine Schaertl Short

Foundation models are a promising path toward general-purpose and
user-friendly robots. The prevalent approach involves training a generalist
policy that, like a reinforcement learning policy, uses observations to output
actions. Although this approach has seen much success, several concerns arise
when considering deployment and end-user interaction with these systems. In
particular, the lack of modularity between tasks means that when model weights
are updated (e.g., when a user provides feedback), the behavior in other,
unrelated tasks may be affected. This can negatively impact the system's
interpretability and usability. We present an alternative approach to the
design of robot foundation models, Diffusion for Policy Parameters (DPP), which
generates stand-alone, task-specific policies. Since these policies are
detached from the foundation model, they are updated only when a user wants,
either through feedback or personalization, allowing them to gain a high degree
of familiarity with that policy. We demonstrate a proof-of-concept of DPP in
simulation then discuss its limitations and the future of interpretable
foundation models.

摘要：基礎模型是朝向通用且使用者友善機器人的一條有前途的道路。普遍的方法涉及訓練一個通才政策，它像一個強化學習政策，使用觀察來輸出動作。儘管這種方法已經看到許多成功，但在考慮這些系統的部署和最終使用者互動時，會出現一些問題。特別是，任務之間缺乏模組化意味著當模型權重更新時（例如，當使用者提供回饋時），其他不相關任務中的行為可能會受到影響。這可能會對系統的可解釋性和可用性產生負面影響。我們提出了一種機器人基礎模型設計的替代方法，即政策參數擴散 (DPP)，它會產生獨立的、特定於任務的政策。由於這些政策與基礎模型分離，因此只有在使用者需要時才會更新，無論是透過回饋或個人化，讓他們能夠高度熟悉該政策。我們在模擬中展示了 DPP 的概念驗證，然後討論了它的限制和可解釋基礎模型的未來。

##### **Spatial-Temporal Attention Model for Traffic State Estimation with Sparse Internet of Vehicles**
2407.08047v1 by Jianzhe Xue, Dongcheng Yuan, Yu Sun, Tianqi Zhang, Wenchao Xu, Haibo Zhou, Xuemin, Shen

The growing number of connected vehicles offers an opportunity to leverage
internet of vehicles (IoV) data for traffic state estimation (TSE) which plays
a crucial role in intelligent transportation systems (ITS). By utilizing only a
portion of IoV data instead of the entire dataset, the significant overheads
associated with collecting and processing large amounts of data can be avoided.
In this paper, we introduce a novel framework that utilizes sparse IoV data to
achieve cost-effective TSE. Particularly, we propose a novel spatial-temporal
attention model called the convolutional retentive network (CRNet) to improve
the TSE accuracy by mining spatial-temporal traffic state correlations. The
model employs the convolutional neural network (CNN) for spatial correlation
aggregation and the retentive network (RetNet) based on the attention mechanism
to extract temporal correlations. Extensive simulations on a real-world IoV
dataset validate the advantage of the proposed TSE approach in achieving
accurate TSE using sparse IoV data, demonstrating its cost effectiveness and
practicality for real-world applications.

摘要：隨著連網車輛數量增加，提供了利用車聯網 (IoV) 資料進行交通狀態估計 (TSE) 的機會，這在智慧運輸系統 (ITS) 中扮演著關鍵的角色。透過僅利用 IoV 資料的一部分，而非整個資料集，可以避免與收集和處理大量資料相關的顯著負擔。在本文中，我們介紹一個利用稀疏 IoV 資料來達成具成本效益的 TSE 的新架構。特別是，我們提出一個稱為卷積保留網路 (CRNet) 的新時空注意力模型，以透過探勘時空交通狀態關聯性來提升 TSE 精確度。該模型採用卷積神經網路 (CNN) 進行時空關聯性聚合，以及基於注意力機制的保留網路 (RetNet) 來萃取時序關聯性。在真實世界 IoV 資料集上進行的廣泛模擬驗證了所提出的 TSE 方法在使用稀疏 IoV 資料達成精確 TSE 的優勢，展現其對於真實世界應用而言的成本效益和實用性。

##### **RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization**
2407.08044v1 by Xijie Huang, Zechun Liu, Shih-Yang Liu, Kwang-Ting Cheng

Low-Rank Adaptation (LoRA), as a representative Parameter-Efficient
Fine-Tuning (PEFT)method, significantly enhances the training efficiency by
updating only a small portion of the weights in Large Language Models (LLMs).
Recently, weight-only quantization techniques have also been applied to LoRA
methods to reduce the memory footprint of fine-tuning. However, applying
weight-activation quantization to the LoRA pipeline is under-explored, and we
observe substantial performance degradation primarily due to the presence of
activation outliers. In this work, we propose RoLoRA, the first LoRA-based
scheme for effective weight-activation quantization. RoLoRA utilizes rotation
for outlier elimination and proposes rotation-aware fine-tuning to preserve the
outlier-free characteristics in rotated LLMs. Experimental results show RoLoRA
consistently improves low-bit LoRA convergence and post-training quantization
robustness in weight-activation settings. We evaluate RoLoRA across
LLaMA2-7B/13B, LLaMA3-8B models, achieving up to 29.5% absolute accuracy gain
of 4-bit weight-activation quantized LLaMA2- 13B on commonsense reasoning tasks
compared to LoRA baseline. We further demonstrate its effectiveness on Large
Multimodal Models (LLaVA-1.5-7B). Codes are available at
https://github.com/HuangOwen/RoLoRA

摘要：低秩適應 (LoRA) 作為代表性的參數有效微調 (PEFT) 方法，透過僅更新大型語言模型 (LLM) 中的一小部分權重，大幅提升訓練效率。最近，權重僅量化技術也已應用於 LoRA 方法，以減少微調的記憶體使用量。然而，將權重啟用量化應用於 LoRA 管線尚未充分探討，而我們觀察到大幅效能降低，主要是由於存在啟用值異常值。在這項工作中，我們提出 RoLoRA，這是第一個基於 LoRA 的有效權重啟用值量化方案。RoLoRA 利用旋轉進行異常值消除，並提出旋轉感知微調，以保留旋轉 LLM 中無異常值的特性。實驗結果顯示，RoLoRA 持續改善低位元 LoRA 收斂性，以及權重啟用值設定中的訓練後量化穩健性。我們在 LLaMA2-7B/13B、LLaMA3-8B 模型中評估 RoLoRA，與 LoRA 基準相比，在常識推理任務上，達到 4 位元權重啟用值量化 LLaMA2-13B 高達 29.5% 的絕對準確度提升。我們進一步展示其在大型多模態模型 (LLaVA-1.5-7B) 上的有效性。程式碼可在 https://github.com/HuangOwen/RoLoRA 取得

##### **Knowledge Overshadowing Causes Amalgamated Hallucination in Large Language Models**
2407.08039v1 by Yuji Zhang, Sha Li, Jiateng Liu, Pengfei Yu, Yi R. Fung, Jing Li, Manling Li, Heng Ji

Hallucination is often regarded as a major impediment for using large
language models (LLMs), especially for knowledge-intensive tasks. Even when the
training corpus consists solely of true statements, language models still
generate hallucinations in the form of amalgamations of multiple facts. We coin
this phenomenon as ``knowledge overshadowing'': when we query knowledge from a
language model with multiple conditions, some conditions overshadow others,
leading to hallucinated outputs. This phenomenon partially stems from training
data imbalance, which we verify on both pretrained models and fine-tuned
models, over a wide range of LM model families and sizes.From a theoretical
point of view, knowledge overshadowing can be interpreted as
over-generalization of the dominant conditions (patterns). We show that the
hallucination rate grows with both the imbalance ratio (between the popular and
unpopular condition) and the length of dominant condition description,
consistent with our derived generalization bound. Finally, we propose to
utilize overshadowing conditions as a signal to catch hallucination before it
is produced, along with a training-free self-contrastive decoding method to
alleviate hallucination during inference. Our proposed approach showcases up to
82% F1 for hallucination anticipation and 11.2% to 39.4% hallucination control,
with different models and datasets.

摘要：幻觉通常被视为使用大型语言模型 (LLM) 的主要障碍，尤其是对于知识密集型任务。即使训练语料库仅包含真实陈述，语言模型仍会以多种事实的混合形式产生幻觉。我们把这种现象称为“知识掩盖”：当我们用多个条件从语言模型中查询知识时，一些条件会掩盖其他条件，从而导致产生幻觉的输出。这种现象部分源于训练数据不平衡，我们在预训练模型和微调模型上以及在广泛的 LM 模型系列和规模上对此进行了验证。从理论角度来看，知识掩盖可以解释为对主要条件（模式）的过度概括。我们表明，幻觉率随着不平衡率（流行条件和不受欢迎条件之间）和主要条件描述的长度而增加，这与我们得出的概括界限一致。最后，我们建议利用掩盖条件作为一种信号，在产生幻觉之前捕获幻觉，并使用无训练的自对比解码方法来减轻推理过程中的幻觉。我们提出的方法展示了高达 82% 的 F1 幻觉预测和 11.2% 到 39.4% 的幻觉控制，具有不同的模型和数据集。

##### **FsPONER: Few-shot Prompt Optimization for Named Entity Recognition in Domain-specific Scenarios**
2407.08035v1 by Yongjian Tang, Rakebul Hasan, Thomas Runkler

Large Language Models (LLMs) have provided a new pathway for Named Entity
Recognition (NER) tasks. Compared with fine-tuning, LLM-powered prompting
methods avoid the need for training, conserve substantial computational
resources, and rely on minimal annotated data. Previous studies have achieved
comparable performance to fully supervised BERT-based fine-tuning approaches on
general NER benchmarks. However, none of the previous approaches has
investigated the efficiency of LLM-based few-shot learning in domain-specific
scenarios. To address this gap, we introduce FsPONER, a novel approach for
optimizing few-shot prompts, and evaluate its performance on domain-specific
NER datasets, with a focus on industrial manufacturing and maintenance, while
using multiple LLMs -- GPT-4-32K, GPT-3.5-Turbo, LLaMA 2-chat, and Vicuna.
FsPONER consists of three few-shot selection methods based on random sampling,
TF-IDF vectors, and a combination of both. We compare these methods with a
general-purpose GPT-NER method as the number of few-shot examples increases and
evaluate their optimal NER performance against fine-tuned BERT and LLaMA
2-chat. In the considered real-world scenarios with data scarcity, FsPONER with
TF-IDF surpasses fine-tuned models by approximately 10% in F1 score.

摘要：大型語言模型 (LLM) 為命名實體識別 (NER) 任務提供了新的途徑。與微調相比，LLM 驅動提示方法避免了訓練的需要，節省了大量的計算資源，並依賴於最少的註解數據。先前的研究已在一般 NER 基準上實現了與完全監督的 BERT 微調方法相當的性能。然而，先前的研究方法都沒有探討 LLM 基於少量學習在特定領域場景中的效率。為了解決這個差距，我們引入了 FsPONER，這是一種優化少量提示的新方法，並評估了它在特定領域 NER 資料集上的性能，重點放在工業製造和維護上，同時使用多個 LLM -- GPT-4-32K、GPT-3.5-Turbo、LLaMA 2-chat 和 Vicuna。FsPONER 包含三種基於隨機抽樣、TF-IDF 向量和兩者的組合的少量選擇方法。我們將這些方法與通用 GPT-NER 方法進行比較，因為少量範例的數量增加，並評估它們相對於微調 BERT 和 LLaMA 2-chat 的最佳 NER 性能。在考慮的數據稀缺的真實世界場景中，帶有 TF-IDF 的 FsPONER 在 F1 分數上比微調模型高出約 10%。

##### **A Critical Review of Causal Reasoning Benchmarks for Large Language Models**
2407.08029v1 by Linying Yang, Vik Shirvaikar, Oscar Clivio, Fabian Falck

Numerous benchmarks aim to evaluate the capabilities of Large Language Models
(LLMs) for causal inference and reasoning. However, many of them can likely be
solved through the retrieval of domain knowledge, questioning whether they
achieve their purpose. In this review, we present a comprehensive overview of
LLM benchmarks for causality. We highlight how recent benchmarks move towards a
more thorough definition of causal reasoning by incorporating interventional or
counterfactual reasoning. We derive a set of criteria that a useful benchmark
or set of benchmarks should aim to satisfy. We hope this work will pave the way
towards a general framework for the assessment of causal understanding in LLMs
and the design of novel benchmarks.

摘要：許多基準旨在評估大型語言模型 (LLM) 在因果推論和推理方面的能力。然而，其中許多問題可能可以透過檢索領域知識來解決，這讓人質疑它們是否達到了目的。在這篇評論中，我們提出了 LLM 因果關係基準的全面概述。我們強調了最近的基準如何透過納入介入式或反事實推理，朝向因果推理的更徹底定義邁進。我們衍生出一組有用的基準或基準組應力求滿足的標準。我們希望這項工作將為評估 LLM 中的因果理解和設計新的基準奠定一個通用的架構。


### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v1](http://arxiv.org/abs/2407.05440v1)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v1](http://arxiv.org/abs/2406.16908v1)|null|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel Miró-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v1](http://arxiv.org/abs/2404.12832v1)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|Séamus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|Timothée Schmude et.al.|[2401.13324v4](http://arxiv.org/abs/2401.13324v4)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|
|**2023-11-21**|**Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**|Robert Gorwa et.al.|[2311.12573v2](http://arxiv.org/abs/2311.12573v2)|null|
|**2023-11-20**|**Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**|Muta Tah Hira et.al.|[2311.11932v1](http://arxiv.org/abs/2311.11932v1)|null|
|**2023-11-18**|**Representing visual classification as a linear combination of words**|Shobhit Agarwal et.al.|[2311.10933v1](http://arxiv.org/abs/2311.10933v1)|[link](https://github.com/lotterlab/task_word_explainability)|
|**2023-11-03**|**Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**|Emma A. M. Stanley et.al.|[2311.02115v2](http://arxiv.org/abs/2311.02115v2)|[link](https://github.com/estanley16/simba)|
|**2023-10-29**|**Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**|Adam White et.al.|[2310.19174v1](http://arxiv.org/abs/2310.19174v1)|null|
|**2023-10-03**|**Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**|Hossein Shreim et.al.|[2310.01828v2](http://arxiv.org/abs/2310.01828v2)|[link](https://github.com/geoaigroup/geoai-ecrs2023)|
|**2023-09-26**|**Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**|Muhammad Aurangzeb Ahmad et.al.|[2311.01463v1](http://arxiv.org/abs/2311.01463v1)|null|
|**2023-09-20**|**When to Trust AI: Advances and Challenges for Certification of Neural Networks**|Marta Kwiatkowska et.al.|[2309.11196v1](http://arxiv.org/abs/2309.11196v1)|null|
|**2023-09-19**|**Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**|Juan M. García-Gómez et.al.|[2309.10424v1](http://arxiv.org/abs/2309.10424v1)|null|
|**2023-09-19**|**QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**|Thanveer Shaik et.al.|[2309.10293v3](http://arxiv.org/abs/2309.10293v3)|null|
|**2023-09-18**|**Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**|Adarsa Sivaprasad et.al.|[2309.09917v1](http://arxiv.org/abs/2309.09917v1)|null|
|**2023-08-28**|**Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**|Yanjun Gao et.al.|[2308.14321v1](http://arxiv.org/abs/2308.14321v1)|null|
|**2023-08-18**|**Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**|Yun Xin Teoh et.al.|[2308.09380v1](http://arxiv.org/abs/2308.09380v1)|null|
|**2023-08-16**|**Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**|Munib Mesinovic et.al.|[2308.08407v1](http://arxiv.org/abs/2308.08407v1)|null|
|**2023-08-11**|**FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**|Karim Lekadir et.al.|[2309.12325v3](http://arxiv.org/abs/2309.12325v3)|null|
|**2023-08-10**|**Explainable AI applications in the Medical Domain: a systematic review**|Nicoletta Prentzas et.al.|[2308.05411v1](http://arxiv.org/abs/2308.05411v1)|null|
|**2023-08-01**|**Exploring the Role of Explainability in AI-Assisted Embryo Selection**|Lucia Urcelay et.al.|[2308.02534v1](http://arxiv.org/abs/2308.02534v1)|null|
|**2023-07-26**|**A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**|Timo Speith et.al.|[2307.14246v1](http://arxiv.org/abs/2307.14246v1)|null|
|**2023-07-26**|**Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**|Barnaby Crook et.al.|[2307.14239v1](http://arxiv.org/abs/2307.14239v1)|null|
|**2023-07-26**|**Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough**|Henry Fraser et.al.|[2308.02047v1](http://arxiv.org/abs/2308.02047v1)|null|
|**2023-07-21**|**eXplainable Artificial Intelligence (XAI) in aging clock models**|Alena Kalyakulina et.al.|[2307.13704v3](http://arxiv.org/abs/2307.13704v3)|null|
|**2023-07-19**|**Interpreting and Correcting Medical Image Classification with PIP-Net**|Meike Nauta et.al.|[2307.10404v2](http://arxiv.org/abs/2307.10404v2)|[link](https://github.com/m-nauta/pipnet)|
|**2023-07-15**|**Explaining and visualizing black-box models through counterfactual paths**|Bastian Pfeifer et.al.|[2307.07764v3](http://arxiv.org/abs/2307.07764v3)|[link](https://github.com/pievos101/cpath)|
|**2023-07-05**|**Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research**|Toygar Tanyel et.al.|[2307.02131v5](http://arxiv.org/abs/2307.02131v5)|[link](https://github.com/toygarr/counterfactual-explanations-for-medical-research)|
|**2023-06-30**|**AI and Non AI Assessments for Dementia**|Mahboobeh Parsapoor et.al.|[2307.01210v1](http://arxiv.org/abs/2307.01210v1)|null|
|**2023-06-12**|**Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation**|Ruitao Xie et.al.|[2306.07306v1](http://arxiv.org/abs/2306.07306v1)|null|
|**2023-06-09**|**HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine**|Rodrigo Agerri et.al.|[2306.06029v1](http://arxiv.org/abs/2306.06029v1)|null|
|**2023-06-07**|**XInsight: Revealing Model Insights for GNNs with Flow-based Explanations**|Eli Laird et.al.|[2306.04791v1](http://arxiv.org/abs/2306.04791v1)|null|
|**2023-06-06**|**Explainable AI using expressive Boolean formulas**|Gili Rosenberg et.al.|[2306.03976v1](http://arxiv.org/abs/2306.03976v1)|null|
|**2023-06-06**|**Utterance Classification with Logical Neural Network: Explainable AI for Mental Disorder Diagnosis**|Yeldar Toleubay et.al.|[2306.03902v1](http://arxiv.org/abs/2306.03902v1)|null|
|**2023-06-02**|**XAI Renaissance: Redefining Interpretability in Medical Diagnostic Models**|Sujith K Mandala et.al.|[2306.01668v1](http://arxiv.org/abs/2306.01668v1)|null|
|**2023-05-26**|**A Novel real-time arrhythmia detection model using YOLOv8**|Guang Jun Nicholas Ang et.al.|[2305.16727v3](http://arxiv.org/abs/2305.16727v3)|null|
|**2023-05-22**|**Breast Cancer Segmentation using Attention-based Convolutional Network and Explainable AI**|Jai Vardhan et.al.|[2305.14389v2](http://arxiv.org/abs/2305.14389v2)|null|
|**2023-05-18**|**What Symptoms and How Long? An Interpretable AI Approach for Depression Detection in Social Media**|Junwei Kuang et.al.|[2305.13127v2](http://arxiv.org/abs/2305.13127v2)|null|
|**2023-05-17**|**Echoes of Biases: How Stigmatizing Language Affects AI Performance**|Yizhi Liu et.al.|[2305.10201v4](http://arxiv.org/abs/2305.10201v4)|null|
|**2023-05-05**|**Explaining the ghosts: Feminist intersectional XAI and cartography as methods to account for invisible labour**|Goda Klumbyte et.al.|[2305.03376v1](http://arxiv.org/abs/2305.03376v1)|null|
|**2023-04-25**|**Towards Explainable and Safe Conversational Agents for Mental Health: A Survey**|Surjodeep Sarkar et.al.|[2304.13191v1](http://arxiv.org/abs/2304.13191v1)|null|
|**2023-04-04**|**A Brief Review of Explainable Artificial Intelligence in Healthcare**|Zahra Sadeghi et.al.|[2304.01543v1](http://arxiv.org/abs/2304.01543v1)|null|
|**2023-03-22**|**Reveal to Revise: An Explainable AI Life Cycle for Iterative Bias Correction of Deep Models**|Frederik Pahde et.al.|[2303.12641v2](http://arxiv.org/abs/2303.12641v2)|[link](https://github.com/maxdreyer/reveal2revise)|
|**2023-03-11**|**Explainable AI for Time Series via Virtual Inspection Layers**|Johanna Vielhaben et.al.|[2303.06365v1](http://arxiv.org/abs/2303.06365v1)|null|
|**2023-03-08**|**Towards Trust of Explainable AI in Thyroid Nodule Diagnosis**|Truong Thanh Hung Nguyen et.al.|[2303.04731v1](http://arxiv.org/abs/2303.04731v1)|[link](https://github.com/hungntt/xai_thyroid)|
|**2023-03-06**|**Cybersecurity of AI medical devices: risks, legislation, and challenges**|Elisabetta Biasin et.al.|[2303.03140v1](http://arxiv.org/abs/2303.03140v1)|null|
|**2023-02-06**|**LAVA: Granular Neuron-Level Explainable AI for Alzheimer's Disease Assessment from Fundus Images**|Nooshin Yousefzadeh et.al.|[2302.03008v2](http://arxiv.org/abs/2302.03008v2)|null|
|**2023-02-02**|**Diagrammatization: Rationalizing with diagrammatic AI explanations for abductive-deductive reasoning on hypotheses**|Brian Y. Lim et.al.|[2302.01241v2](http://arxiv.org/abs/2302.01241v2)|null|
|**2023-02-02**|**LesionAid: Vision Transformers-based Skin Lesion Generation and Classification**|Ghanta Sai Krishna et.al.|[2302.01104v1](http://arxiv.org/abs/2302.01104v1)|null|
|**2023-02-01**|**SkinCon: A skin disease dataset densely annotated by domain experts for fine-grained model debugging and analysis**|Roxana Daneshjou et.al.|[2302.00785v1](http://arxiv.org/abs/2302.00785v1)|null|
|**2023-01-19**|**Decision-Focused Evaluation: Analyzing Performance of Deployed Restless Multi-Arm Bandits**|Paritosh Verma et.al.|[2301.07835v1](http://arxiv.org/abs/2301.07835v1)|null|
|**2023-01-18**|**Exemplars and Counterexemplars Explanations for Image Classifiers, Targeting Skin Lesion Labeling**|Carlo Metta et.al.|[2302.03033v1](http://arxiv.org/abs/2302.03033v1)|null|

#### Abstracts
##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

摘要：人工智能 (AI) 支持的決策制定是未來 6G 網路中的關鍵元素，其中將引入原生 AI 的概念。此外，AI 廣泛用於不同的關鍵應用中，例如自動駕駛和醫療診斷。在這些應用中，使用 AI 作為黑盒模型是有風險且具有挑戰性的。因此，理解和信任這些模型做出的決策至關重要。解決此問題的方法是開發可解釋 AI (XAI) 架構，旨在解釋黑盒模型行為背後的邏輯，從而確保其有效且安全的部署。最近，我們提出了一個新的基於擾動的 XAI-CHEST 框架，該框架面向無線通信中的信道估計。XAI-CHEST 框架的核心思想是通過在無關輸入上引入高噪聲來識別相關模型輸入。這份手稿提供了 XAI-CHEST 框架的詳細理論基礎。特別是，我們推導了 XAI-CHEST 損失函數和噪聲閾值微調優化問題的解析表達式。因此，設計的 XAI-CHEST 提供了一種智能輸入特徵選擇方法，可以在優化所用模型的架構的同時進一步提高整體性能。模擬結果表明，XAI-CHEST 框架提供了有效的解釋，在降低所需的計算複雜度的同時，提供了改進的比特錯誤率性能，而這與基於傳統 DL 的信道估計相比。

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v1 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

摘要：<paragraph>本文提出了用于视网膜眼底图像疾病分类的扩张残差网络 (ResNet) 模型。扩张卷积滤波器用于替换 ResNet 模型较高层中的正常卷积滤波器（扩张 ResNet），以改善与用于疾病分类的正常 ResNet 模型相比的感受野。本研究介绍了采用深度学习的计算机辅助诊断工具，并通过可解释的 AI 技术进行了增强。这些技术旨在使该工具的决策过程透明化，从而使医疗专业人员能够理解和信任 AI 的诊断决策。它们在当今医疗保健领域尤为重要，因为对 AI 应用程序的透明度需求不断增长，以确保其可靠性和道德使用。扩张 ResNet 用作正常 ResNet 的替代品，以提高视网膜眼病的分类准确性并减少所需的计算时间。本工作中使用的数据集是 Ocular Disease Intelligent Recognition (ODIR) 数据集，这是一个结构化的眼科数据库，包含八类涵盖大多数常见视网膜眼病。本工作中使用的评估指标包括精确度、召回率、准确度和 F1 分数。在这项工作中，对正常 ResNet 模型和扩张 ResNet 模型在五个变体（即 ResNet-18、ResNet-34、ResNet-50、ResNet-101 和 ResNet-152）之间进行了比较研究。与正常 ResNet 相比，扩张 ResNet 模型显示出有希望的结果，在 ODIR 多类疾病分类中，上述各个变体的平均 F1 分数分别为 0.71、0.70、0.69、0.67 和 0.70。</paragraph>

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

摘要：床邊超音波 (POCUS) 是臨床醫師在患者床邊進行和解讀超音波掃描的實務。然而，解讀這些影像所需的專業知識相當可觀，而且在緊急情況下可能並非隨時具備。這種現實情況使得機器學習分類器等演算法對於加強人類決策變得極為有價值。POCUS 裝置正以合理成本推出，尺寸為手機大小。將 POCUS 裝置轉變為救生工具的挑戰在於，解讀超音波影像需要專門訓練和經驗。不幸的是，取得正向訓練影像的困難度代表著建置有效率且準確的分類器的一大障礙。因此，我們嘗試探討的問題是如何探索策略，以提高使用稀疏資料訓練的分類器的準確度。我們假設使用少數資料實例進行訓練可能不足以讓分類器概括，導致它們過度擬合。我們的做法使用可解釋 AI 增強方法，以協助演算法從較少的資料中學習更多，並潛在協助分類器更好地概括。

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

摘要：近年來，美國見證了電子煙或電子香菸使用率大幅激增，導致電子煙和電子煙使用相關肺損傷 (EVALI) 病例顯著增加，在 2019 年 EVALI 爆發期間造成住院和死亡，凸顯了理解電子煙行為和制定有效戒菸策略的迫切性。由於社群媒體平台的普及，全球超過 47 億使用者使用它們進行連結、溝通、新聞和娛樂，其中很大一部分與健康相關，因此將社群媒體資料建立為公共衛生研究中無價的有機資料資源。在本研究中，我們從 Reddit 上一個電子煙子社群中提取一個範例資料集，以分析使用者的戒電子煙意圖。利用 OpenAI 最新的大型語言模型 GPT-4 進行句子層級的戒電子煙意圖偵測，本研究比較了此模型的結果與外行人和臨床專家註解。使用不同的提示策略，例如零次學習、一次學習、少次學習和思考鏈提示，我們開發了 8 個提示，詳細程度不同，向 GPT-4 解釋任務，並評估這些策略彼此之間的效能。這些初步發現強調了 GPT-4 在社群媒體資料分析中的潛力，特別是在識別人類偵測可能無法察覺的使用者微妙意圖方面。

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

摘要：<paragraph>人工智慧（AI）目前在很大程度上依賴於缺乏可解釋性的黑盒機器學習模型。可解釋性人工智慧（XAI）領域致力於解決這個主要問題，這在金融、法律和健康等高風險領域至關重要。
我們提出了一種基於範疇論定義 AI 模型及其可解釋性的方法。為此，我們採用組合模型的概念，它以形式弦圖的形式看待模型，這些弦圖捕獲了模型的抽象結構及其具體實現。這種綜合觀點包含了確定性、概率性和量子模型。我們將各種 AI 模型作為組合模型進行比較，包括線性和基於規則的模型、（遞迴）神經網路、Transformer、VAE，以及因果和 DisCoCirc 模型。
接下來，我們根據模型的組合結構給出模型解釋的定義，展示如何分析模型的可解釋性，並使用它來澄清 XAI 中的常見主題。我們發現，讓標準的「內在可解釋」模型如此透明的原因在圖表中表現得最為清楚。這引導我們得出更一般的組合可解釋（CI）模型概念，它另外還包括因果、概念空間和 DisCoCirc 模型。
接下來，我們展示了 CI 模型的可解釋性優勢。首先，它們的組合結構允許計算其他感興趣的量，並可能通過匹配模型的結構來促進從模型到被建模現象的推理。其次，它們允許對其行為進行圖解說明，這些說明基於影響約束、圖解手術和重寫說明。最後，我們討論了這種方法的許多未來方向，提出了如何在實踐中學習這種有意義的結構化模型的問題。</paragraph>

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

摘要：元宇宙的概念在各個領域都備受關注，其重要應用之一便是醫療保健。元宇宙有巨大的潛力透過改變病患照護、醫學教育，以及教學/學習和研究的方式來轉型醫療保健。本研究的目的是提供元宇宙基本概念和基礎技術的介紹。本文探討了元宇宙在醫療保健背景下的優缺點，並從技術和 AI 的角度分析其潛力。特別是，討論了機器學習方法的角色；我們將說明如何將機器學習演算法應用於元宇宙產生的資料，以獲得醫療保健應用方面的更佳見解。此外，我們透過探討區塊鏈等新興技術，並解決隱私問題，來探討元宇宙在醫療保健方面的未來願景。本研究的發現有助於更深入地了解元宇宙在醫療保健中的應用，以及其在醫療服務提供方面發揮革命性變革的潛力。

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

摘要：慢性腎臟病（CKD）是一種廣泛的慢性疾病，沒有已知的最終療法且發病率很高。研究表明，進行性慢性腎臟病（CKD）是一種異質性疾病，會顯著影響腎臟結構和功能，最終導致腎衰竭。隨著時間的推移，慢性腎臟病已從影響少數人的致命疾病轉變為一種嚴重程度不同的常見疾病。本研究的目標是使用集成學習和可解釋的 AI 進行早期預後和 CKD 檢測，並視覺化主導特徵、特徵分數和表現出的值。為此，提出了一種 AI 驅動的預測分析方法，以幫助臨床醫生為個別患者開具生活方式修改建議，以降低這種疾病的進展速度。我們的數據集是從 CKD 患者和健康受試者的身體生命體徵中收集的，以準確開發我們提出的 AI 驅動的解決方案。在這方面，提供了血液和尿液檢測結果，並應用基於集成樹的機器學習模型來預測未發現的 CKD 病例。我們的研究結果經過與腎臟科醫生的長期諮詢後得到驗證。我們的實驗和解釋結果與各種醫療保健領域中現有的可解釋 AI 應用進行了比較，包括 CKD。比較表明，我們開發的 AI 模型，特別是隨機森林模型，已經確定了比 XgBoost 更多作為重要貢獻者的特徵。可解釋性 (I) 衡量重要特徵與掩蓋特徵的比率，表明我們的 XgBoost 模型在這個指標中獲得了更高的分數，特別是 98% 的保真度，並且在 FII 指數中自然高於競爭模型。

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

摘要：心理健康構成了一項複雜且普遍的全球挑戰，影響了數百萬人的生活，並經常導致嚴重的後果。在本文中，我們進行了一項徹底的調查，以探索數據科學、人工智慧和心理保健的交集，重點關注通過線上社交媒體 (OSM) 進行心理疾病檢測的最新發展。很大一部分人口積極參與 OSM 平台，創造了一個龐大的人員資料庫，對心理健康分析具有巨大的潛力。本文探討了傳統的診斷方法、最先進的資料和 AI 驅動的研究，以及心理保健中可解釋 AI (XAI) 模型的出現。我們回顧了最先進的機器學習方法，特別是那些基於現代深度學習的方法，同時強調了醫療保健 AI 模型中可解釋性的必要性。實驗設計部分提供了對普遍做法的見解，包括可用的資料集和評估方法。我們還找出該領域的主要問題和挑戰，並提出了有希望的未來研究方向。由於心理健康決策需要透明度、可解釋性和道德考量，本文有助於推進心理保健中透過社交媒體推進 XAI 的持續討論。這裡提出的全面概述旨在引導研究人員、從業人員和政策制定者發展心理疾病檢測領域。

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

摘要：<paragraph>醫療照護中需要 AI 輔助的臨床診斷。現有的深度學習模型缺乏可解釋性，並且主要專注於影像分析。最近開發的動態不確定因果關係圖 (DUCG) 方法是因果驅動的、可解釋的，並且在不同的應用場景中是不變的，沒有資料收集、標記、擬合、隱私、偏見、概化、高成本和高能耗的問題。通過臨床專家和 DUCG 技術人員之間的密切合作，構建了涵蓋 54 個主訴的 46 個 DUCG 模型。可以在沒有分流的情況下診斷出 1,000 多種疾病。在應用於實際世界之前，46 個 DUCG 模型已由第三方醫院回溯性驗證。驗證的診斷精度不低於 95%，其中包括罕見疾病在內的每種疾病的診斷精度不低於 80%。驗證後，46 個 DUCG 模型已在中國實際應用。已經執行了超過一百萬個真實診斷案例，僅發現 17 個不正確的診斷。由於 DUCG 的透明性，發現並糾正了導致不正確診斷的錯誤。頻繁應用 DUCG 的臨床醫生的診斷能力得到了顯著提高。在介紹了前面提出的 DUCG 方法論之後，提出了潛在健康檢查的推薦演算法，並提取了 DUCG 的關鍵思想。</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

摘要：精確且及時地偵測乳癌對於改善患者預後至關重要。診斷方法傳統上依賴於單一模式方法；然而，醫療資料分析正在整合超越傳統影像的各種資料來源。使用整合影像和非影像資料的多模式技術，標誌著乳癌診斷的變革性進展。本篇綜述的目的是探討多模式技術的新興領域，特別是將組織病理學影像與非影像資料融合。此外，可解釋人工智慧 (XAI) 將用於闡明複雜演算法的決策過程，強調診斷過程中可解釋性的必要性。本綜述利用多模式資料並強調可解釋性，以提高診斷準確性、臨床醫師的信心和患者參與度，最終促進乳癌更個人化的治療策略，同時也找出多模式和可解釋性的研究差距，引導未來的研究，並為該領域的策略方向做出貢獻。

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

摘要：自注意力機制已被採用於多個廣泛使用的訊息傳遞神經網路 (MPNN)（例如 GAT），它可以自適應地控制沿著底層圖形邊緣流動的資訊量。這種注意力的使用使得此類模型成為可解釋 AI (XAI) 研究的基線，因為透過注意力的詮釋已在各種領域（例如自然語言處理和電腦視覺）中普及。然而，現有的研究通常使用天真的計算方法從注意力中推導出歸因分數，並且沒有考慮到邊緣歸因的精確且仔細的計算。在我們的研究中，我們旨在填補注意力啟用 MPNN 的廣泛使用與它們在很大程度上未被充分探索的可解釋性之間的差距，這個主題已在其他領域積極研究。為此，作為第一次嘗試，我們將 GNN 中注意力權重的邊緣歸因問題形式化。然後，我們提出 GATT，一種建立在計算樹上的邊緣歸因計算方法。透過全面的實驗，我們展示了我們提出的方法在評估 GAT 的歸因時所具有的效果。相反地，我們憑經驗驗證了僅對圖注意力層上的注意力權重取平均值不足以詮釋 GAT 模型的行為。程式碼已公開於 https://github.com/jordan7186/GAtt/tree/main。

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v1 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

摘要：新生兒期是大腦發育最容易出現癲癇的時期。大腦尚未成熟時發生的癲癇會造成不良後果，因此需要提早診斷。目前新生兒癲癇檢測的黃金標準依賴於持續的視訊腦電圖 (EEG) 監控；其中包括在新生兒加護病房 (NICU) 內錄製多通道腦電圖 (EEG) 和進行即時視訊監控。然而，視訊腦電圖監控技術需要臨床專業知識，而且通常僅限於技術先進且資源豐富的環境。具成本效益的新技術可以幫助醫療界準確診斷並立即提倡治療。在這項工作中，提出了一個新穎的可解釋深度學習模型，以自動化新生兒癲癇檢測流程，並減少腦電圖裝置，採用卷積神經網路、圖注意力層和全連接層。除了能夠即時偵測癲癇發作並減少裝置外，此模型還提供了即時可解釋性的獨特優勢。透過評估 Zenodo 資料集的 10 倍交叉驗證效能，提出的模型在曲線下面積 (AUC) 和召回率分別達到 8.31% 和 42.86% 的絕對改善。

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

摘要：乳癌 (BC) 是影響全球女性最常見的惡性腫瘤之一，因此需要進步的診斷方法，以改善臨床結果。本文全面探討了可解釋人工智慧 (XAI) 技術在乳癌偵測和診斷中的應用。隨著人工智慧 (AI) 技術持續滲透醫療保健領域，特別是在腫瘤學中，透明且可解釋的模型需求變得勢在必行，以增強臨床決策制定和患者照護。此篇評論探討了各種 XAI 方法的整合，例如 SHAP、LIME、Grad-CAM 等，以及用於乳癌偵測和分類的機器學習和深度學習模型。透過探討乳癌資料集的模式，包括乳房攝影、超音波及其在 AI 中的處理，本文重點說明 XAI 如何能導致更準確的診斷和個人化治療計畫。它也探討了實施這些技術的挑戰，以及制定標準化評量指標以評估 XAI 在臨床環境中的有效性的重要性。透過詳細的分析和討論，本文旨在強調 XAI 在縮小複雜 AI 模型與實務醫療保健應用之間差距的潛力，進而促進醫療專業人員之間的信任與理解，並改善患者的結果。

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

摘要：語音情緒辨識 (SER) 由於其在心理健康、教育和人機互動等多個應用領域而備受關注。然而，SER 系統的準確性受到高維特徵集的阻礙，這些特徵集可能包含不相關和冗餘的資訊。為了克服這個挑戰，本研究提出了一種用於 SER 的迭代特徵提升方法，該方法強調特徵相關性和可解釋性，以增強機器學習模型的效能。我們的做法涉及仔細的特徵選擇和分析，以建立高效的 SER 系統。為了透過模型可解釋性解決我們的核心問題，我們採用了具有 Shapley 值的特徵評估迴圈，以反覆改善特徵集。這個過程在模型效能和透明度之間取得平衡，這使得我們能夠全面了解模型的預測。所提出的方法提供了多項優點，包括識別和移除不相關和冗餘的特徵，從而建立更有效的模型。此外，它促進了可解釋性，有助於理解模型的預測以及識別情緒決定的關鍵特徵。所提出的方法的有效性已在多倫多情緒語音集 (TESS)、柏林情緒語音資料庫 (EMO-DB)、賴爾森音訊視覺情緒語音和歌曲資料庫 (RAVDESS) 和薩里音訊視覺表達情緒 (SAVEE) 資料集的 SER 基準上得到驗證，其效能優於現有方法。據我們所知，這是第一個將模型可解釋性納入 SER 架構的研究。本文的原始碼可透過此連結公開取得：https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition。

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, Héloïse de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

摘要：可解释性通常对于人工智能 (AI) 的可接受实施至关重要。在医疗保健领域，这一点尤为重要，因为决策直接影响患者，并且对 AI 系统的信任至关重要。这种信任通常建立在 AI 提供的解释和诠释之上。尽管 AI 可解释性取得了重大进展，但仍然需要明确的指导方针，说明在医疗环境中何时以及在多大程度上需要解释。我们提出了一种新颖的分类系统，该系统具有四种不同的解释必要性类别，指导所需的解释级别：患者或样本（局部）级别、队列或数据集（全局）级别，或两个级别。我们引入了一个数学公式，该公式区分了这些类别，并为研究人员提供了一个实用框架，以确定医疗 AI 应用中所需的解释的必要性和深度。考虑了三个关键因素：评估协议的稳健性、专家观察的可变性以及应用程序的表示维数。从这个角度来看，我们解决了这个问题：AI 医疗应用何时需要解释，以及需要解释到何种程度？

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

摘要：人工智慧 (AI) 領域正快速影響著健康與醫療保健，但對於面臨廣泛結構性壓迫的人群來說，偏見和不良表現依然存在。先前的研究已清楚說明，需要更嚴格地注意資料代表性和模型效能，以促進公平性並減少偏見。然而，我們有機會透過運用社會流行病學和健康公平的最佳實務，來改善 AI 的可解釋性，以幫助我們針對發現的關聯性，發展假設。在本文中，我們專注於可解釋 AI (XAI)，並描述一個跨領域專家小組審查架構，以從多重觀點討論和批判性評估 AI 模型的解釋，並找出偏見領域和未來研究的方向。我們強調跨領域專家小組對於產生更準確、公平的詮釋至關重要，而這些詮釋是根據歷史和脈絡而來的。跨領域小組討論有助於減少偏見、找出潛在的混淆因素，並在文獻中有缺口時找出額外研究的機會。反過來，這些見解可以建議 AI 模型改進的機會。

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

摘要：隨著先進的 AI/ML，對可解釋 AI (XAI) 的研究不斷增加，以及關於人類如何與 AI 和 XAI 互動以進行有效的人工智慧協作決策制定。然而，我們仍然缺乏對 AI 系統和 XAI 應如何首先呈現給沒有技術背景的用戶的了解。在本文中，我們展示了與醫療專業人員 (n=12) 和主修醫學和健康的學生 (n=4) 進行半結構化訪談的結果，以研究如何改善 AI 和 XAI 的入門。對於訪談，我們建立在人機互動準則之上，為中風康復評估和 AI 解釋的 AI 系統創建入門材料，並將它們介紹給參與者。我們的研究結果表明，除了呈現傳統的 AI 性能指標外，參與者還希望基准信息、AI 的實際好處以及交互試驗，以更好地將 AI 性能情境化，並完善 AI 的目標和性能。根據這些發現，我們強調了改進 AI 和 XAI 以及人機協作決策制定的入門方向。

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

摘要：本文使用機器學習 (ML) 和可解釋人工智慧 (XAI) 技術來探討營養狀況與阿茲海默症 (AD) 相關的死亡率之間的關係。採用第三次全國健康與營養檢查調查 (NHANES III) 資料庫進行分析。選擇隨機森林模型作為 XAI 分析的基礎模型，並使用 Shapley Additive Explanations (SHAP) 方法來評估特徵重要性。結果突顯了重要的營養因素，例如血清維生素 B12 和糖化血紅蛋白。該研究證明了隨機森林在預測 AD 死亡率方面相較於其他疾病的有效性。本研究提供了營養對 AD 的影響的見解，並有助於更深入地了解疾病的進展。

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

摘要：在醫學影像中，特別是在早期疾病檢測和預後任務中，辨別 AI 模型預測背後的原理對於評估其決策的可靠性至關重要。傳統的解釋方法在識別醫學影像分類中可識別的決定性特徵時面臨挑戰，其中區別性特徵很微妙或並不明顯。為了彌合這一差距，我們提出了一個可解釋的模型，該模型具備決策推理和特徵識別能力。我們的做法不僅檢測有影響力的影像模式，還揭示了推動模型最終預測的決定性特徵。通過實施我們的模型，我們可以有效識別和視覺化由數據驅動模型利用的類特定特徵，從而深入了解深度學習模型的決策過程。我們在要求嚴格的醫學預後任務領域驗證了我們的模型，展示了其在提高 AI 在醫療保健中的可靠性和發現預後理解受限疾病的新知識方面的功效和潛力。

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

摘要：本研究探討線上健康社群中尋求資訊支持的問題、回應，以及有幫助的評分之間的關係。我們建立了一組標記的問答配對資料集，並開發了多模態機器學習和深度學習模型，以可靠地預測資訊支持問題和回應。我們採用可解釋的 AI 來揭示資訊支持交流中蘊含的情緒，證明情緒在提供資訊支持中的重要性。這種情緒支持和資訊支持之間的複雜交互作用以前並未被研究過。本研究改進了社會支持理論，並為使用者決策輔助工具的開發奠定了基礎。討論了進一步的影響。

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

摘要：在科技飛速發展的時代，一位意外的訪客已在全球教室中佔有一席之地，那就是人工智慧。生成式 AI，例如 ChatGPT，承諾在教育領域掀起一場革命，但它卻是一把雙面刃。它在個人化學習方面的潛力，卻因作弊、不準確以及教育工作者難以將其有效融入教學設計等問題而抵銷。我們正站在這教育前沿的邊緣，顯然我們需要非常小心地探索這片領域。這是一個重大的挑戰，可能會損害我們教育過程的完整性和價值。那麼，我們如何將這些挑戰轉化為機遇？當不適當地使用時，AI 工具可能會成為複製貼上心態的完美工具，並迅速腐蝕批判性思維、創造力和深入理解，這些都是我們快速變化的世界中最重要的技能。教師們覺得他們沒有能力利用這項技術，這擴大了教育工作者和機構之間的數位鴻溝。解決這些問題需要深入的研究方法。我們將採用實證研究，借鑑技術接受模型，來評估教育工作者和學生對生成式 AI 的態度。了解他們的看法、使用模式和障礙是創造有效解決方案的第一個關鍵步驟。本研究將作為未來研究人員應用的流程手冊，根據此處說明的步驟運行他們自己的數據

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike Grüne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, André Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

摘要：隨著醫療保健系統的數位化，人工智慧在醫學領域中變得更加普及。特別是機器學習在時間序列分類等複雜任務中展現出極大的潛力，但通常是以透明度和可理解性為代價。這導致人類缺乏信任，從而阻礙了其積極使用。可解釋的人工智慧試圖通過提供對決策過程的洞察來彌補這一差距，但其不同方法的實際效用尚不清楚。本文提出了一個基於使用者研究的評估，其中包含了 Grad-CAM 解釋方法，並將其應用於神經網路以分類時間序列新生兒呼吸數據中的呼吸。我們展示了不同利益相關者對可解釋性方法的感知效用，揭示了實現實際透明度的難度，以及許多參與者希望獲得更深入的解釋。

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

摘要：大型語言模型 (LLM) 與醫療診斷整合
為臨床決策提供了一個有前景的途徑。本研究概述了一種新穎方法的開發，用於零次學習/少量學習情境學習 (ICL)，方法是使用多層結構化提示整合醫療領域知識。我們還探討了使用者與 LLM 之間兩種溝通方式的功效：數值對話 (NC) 方式，它會逐步處理資料，以及自然語言單回合 (NL-ST) 方式，它會使用長篇敘事提示。
我們的研究系統性地評估了診斷準確性和風險因子，包括性別偏見和假陰性率，使用了一個包含 920 個患者記錄的資料集，採用各種少量學習情境。結果表明，傳統的臨床機器學習 (ML) 模型通常在零次學習和少量學習設定中表現優於 LLM。然而，當使用少量學習範例以及有效的可解釋 AI (XAI) 方法作為領域知識來源時，效能差距會顯著縮小。此外，隨著時間充足和範例數量增加，對話方式 (NC) 幾乎可以媲美 ML 模型的效能。最值得注意的是，LLM 相對於 ML 模型展現出相當或更佳的成本敏感準確度。
本研究證實，透過適當的領域知識和量身打造的溝通策略，LLM 可以顯著增強診斷程序。這些發現突顯了最佳化訓練範例數量和溝通方式的重要性，以提高準確度並減少 LLM 應用中的偏差。

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel Miró-Nicolau, Gabriel Moyà-Alcover, Antoni Jaume-i-Capó, Manuel González-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

摘要：隨著對深度學習模型依賴性的增加，加上其固有的透明度不足，促使一個新的研究領域發展，稱為可解釋 AI (XAI) 方法。這些方法旨在透過深入了解決策背後的原理，來提升最終使用者對自動化系統的信賴。本文提出了一種衡量使用者對 XAI 系統信賴度的新穎方法，允許對其進行改進。我們提出的指標結合了客觀觀點下的效能指標和信賴指標。為了驗證這個新穎的方法，我們在一個真實的醫療場景中進行了一個案例研究：使用 XAI 系統從 X 光影像中偵測肺炎。

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

摘要：COVID-19 疫情對全球公共衛生造成壓力，必須進行準確的診斷和干預，以控制疾病傳播並降低死亡率。本文介紹了一個可解釋的深度生存預測模型，專門設計用於透過胸部 X 光 (CXR) 影像改善對 COVID-19 預後的理解和信賴。透過整合大規模預訓練影像編碼器、風險特定 Grad-CAM 和解剖區域偵測技術，我們的做法產生區域可解釋的結果，有效捕捉必要的疾病特徵，同時專注於罕見但關鍵的異常區域。我們的模型預測結果透過風險區域定位提供增強的清晰度和透明度，讓臨床醫生能夠在更了解預後見解的情況下，就 COVID-19 診斷做出明智的決策。我們在多中心生存資料集上評估所提出的方法，並透過量化和質化評估證明其有效性，達到優異的 C 指數（0.764 和 0.727）和時間相關 AUC（0.799 和 0.691）。這些結果表明，我們可解釋的深度生存預測模型在風險預測方面超越傳統的生存分析方法，提升臨床決策的解釋性，並增強 AI 系統的信賴度。

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

摘要：<paragraph>在過去幾年，臨床決策支援系統 (CDSS) 中的人工智慧 (AI) 在利用機器學習和深度學習架構方面發揮了關鍵作用。儘管 AI 模型具有令人滿意的能力，但缺乏透明度和可解釋性，特別是在可靠性為必要考量的醫療背景下，這帶來了重大的挑戰。在不影響預測精準度的情況下實現透明度仍然是一項關鍵挑戰。本文提出了一種新方法，即 Rad4XCNN，以增強 CNN 衍生特徵的預測能力，同時具備放射特徵固有的可解釋性。Rad4XCNN 不同於基於顯著性圖的傳統方法，它通過放射組學將可理解的含義與 CNN 衍生特徵關聯起來，為超越視覺化圖表的解釋方法提供了新的觀點。我們以乳癌分類任務作為案例研究，在超音波影像資料集上評估 Rad4XCNN，包括一個線上資料集和兩個用於內部和外部驗證的內部資料集。一些關鍵結果如下：i) 與 ViT 衍生特徵和放射特徵相比，CNN 衍生特徵保證了更穩健的準確度；ii) 傳統的視覺化圖解釋方法存在一些缺陷；iii) Rad4XCNN 沒有犧牲模型準確度來換取其可解釋性；iv) Rad4XCNN 提供了全局解釋見解，使醫師能夠分析模型輸出和發現。此外，我們強調將可解釋性整合到 AI 模型中對於增強臨床實務中的信任和採用至關重要，並強調了我們的方法如何能緩解與可解釋 AI 方法相關的一些疑慮。</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

摘要：隨著人工智慧 (AI) 的普及整合，在涉及 AI 驅動系統的事故中，責任和義務歸屬產生了複雜的挑戰。這些系統的互連性、AI 引發事故的倫理問題，加上 AI 技術的不確定性和缺乏相應法規，使得傳統責任歸屬面臨挑戰。為此，本研究提出了一種計算反思均衡 (CRE) 方法，以建立一個連貫且在倫理上可接受的責任歸屬架構，適用於所有利害關係人。計算方法提供了結構化的分析，克服了概念方法在處理動態且多面向情境時的限制，展示了該架構在責任歸屬過程中具備的可解釋性、連貫性和適應性。我們探討了與均衡計算中索賠相關的初始啟動層級的關鍵作用。我們以 AI 輔助醫療決策支援系統為案例研究，說明不同的初始化如何導致不同的責任分配。該架構提供了對 AI 引發事故中問責制的寶貴見解，透過持續監控、修訂和反思，促進了永續且有韌性的系統發展。

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

摘要：人工智慧透過預測模型協助醫療專業人員，大幅轉變了臨床決策制定。本研究探討了在醫療保健中使用人工智慧應用程式時公平性和可解釋性的關鍵需求，以確保在不同的患者人口統計資料中獲得公平的結果。透過專注於敗血症相關死亡率的預測模型，我們提出了一種方法，該方法會學習一個效能最佳化的預測模型，然後採用轉移學習過程來產生一個具有更好公平性的模型。我們的模型還引入了一種新穎的基於排列的特徵重要性演算法，旨在闡明每個特徵在增強預測公平性方面的貢獻。與現有的可解釋性方法專注於解釋特徵對預測效能的貢獻不同，我們提出的方法獨特地彌補了理解每個特徵如何有助於公平性的差距。這項進展至關重要，因為敗血症的死亡率很高，且在三分之一的醫院死亡中扮演著角色。我們的模型不僅有助於識別和減輕預測模型中的偏差，還能透過提高模型預測的透明度和公平性來培養醫療保健利益相關者之間的信任，進而有助於提供更公平且值得信賴的醫療保健服務。

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

摘要：現今，憂鬱症是一個重要的議題。根據世界衛生組織 (WHO) 的資料，在 2023 年，超過 2.8 億人正在與憂鬱症搏鬥。這是一個龐大的數字；如果不認真看待，這些數字將會快速增加。大約有 48.9 億人是社群媒體使用者。人們在 Twitter、Facebook、Reddit、Instagram 等平台上表達自己的感受和情緒。這些平台包含有價值的資訊，可用於研究目的。已經在各種社群媒體平台上進行了大量的研究。然而，這些努力仍存在某些限制。特別是，先前的研究僅專注於偵測推文中的憂鬱症和憂鬱症的強度。此外，資料集標籤中存在不準確的情況。在這項研究工作中，使用基於詞彙標籤的 Twitter 資料庫中的推文預測了五種類型的憂鬱症（雙極型、重度、精神病型、非典型和產後）。可解釋的 AI 用於透過強調代表憂鬱症類型的推文部分來提供推理。從 Transformers（BERT）中提取的雙向編碼器表示用於特徵提取和訓練。機器學習和深度學習方法用於訓練模型。BERT 模型呈現出最有希望的結果，達到 0.96 的整體準確度。

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v1 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

摘要：深度學習正劇烈地轉變醫學影像和放射學領域，能識別醫學影像中的病理，包括電腦斷層掃描 (CT) 和 X 光掃描。然而，深度學習模型的效能，特別是在分割任務中，常常受到廣泛註解資料集需求的限制。為了應對此挑戰，透過可解釋 AI 和反事實解釋的產生，探討了弱監督語意分割的能力。本研究的範圍是開發一種新穎的反事實內繪方法 (COIN)，它透過使用生成模型，將預測分類標籤從異常翻轉為正常。例如，如果分類器將輸入醫學影像 X 視為異常，表示存在病理，生成模型旨在內繪異常區域，從而逆轉分類器的原始預測標籤。此方法使我們能夠產生病理的精確分割，而不依賴於預先存在的分割遮罩。至關重要的是，利用影像層級標籤，這比建立詳細的分割遮罩容易取得得多。該方法的有效性透過分割合成目標和從愛沙尼亞塔爾圖大學醫院取得的 CT 影像中的實際腎臟腫瘤來證明。研究結果表明，COIN 遠遠超越了既定的歸因方法，例如 RISE、ScoreCAM 和 LayerCAM，以及 Singla 等人提出的另一種反事實解釋方法。此證據表明，COIN 是一種很有前景的 CT 影像中腫瘤語意分割方法，並在使深度學習應用在註解資料稀缺的醫療保健中更易於取得和更有效方面邁進了一步。

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

摘要：在本文中，我們探討數位人文學科 (DH) 作為一門學科與混合智能 (HI) 作為一個研究典範之間的協同作用。在 DH 研究中，數位方法的使用，特別是人工智慧的使用，受到一系列要求和限制。我們認為這些要求和限制獲得 HI 的能力和目標的充分支持。我們的貢獻包括找出五個這樣的 DH 要求：成功的 AI 系統需要能夠 1) 與（人類）學者合作；2) 支援資料批評；3) 支援工具批評；4) 察覺並迎合各種觀點；5) 支援遠距和近距離閱讀。我們將混合智能的 CARE 原則（協作、適應、負責和可解釋）作為理論架構，並將這些原則對應到 DH 要求。在此對應中，我們納入範例研究專案。最後，我們探討如何將 DH 的見解應用於 HI，並討論結合這兩個學科的開放挑戰。

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

摘要：基礎模型 (FM) 具有徹底改變醫學影像的巨大潛力。然而，它們在現實世界臨床環境中的部署需要廣泛的倫理考量。本文旨在強調與 FM 相關的倫理問題，並提出一個框架來指導它們在醫學中的負責任開發和實施。我們仔細審查了倫理問題，例如患者數據隱私、偏差緩解、演算法透明度、可解釋性和問責制。所提出的框架旨在優先考慮患者福利、減輕潛在風險，並培養對 AI 輔助醫療保健的信任。

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

摘要：甲狀腺癌是一種日益嚴重的全球健康問題，需要先進的診斷方法。本篇評論探討了人工智能與放射特徵分析在甲狀腺癌診斷中的應用。在符合 PRISMA 指南的情況下，對多個資料庫進行了回顧，直到 2023 年 10 月。通過結合關鍵字，發現了一篇關於甲狀腺癌和相關主題的英文學術出版物。在移除 109 篇重複文獻後，原始搜尋共回傳 267 篇論文。在根據預先確定的標準，淘汰了 124 篇文章的摘要和標題後，選出了相關研究。在進行全面分析後，額外排除了六項研究。在納入的 28 項研究中，結合超音波 (US) 影像的放射特徵分析，證明了其在診斷甲狀腺癌方面的有效性。研究結果不一，有些研究提出了優於現狀的新策略。文獻強調了人工智能模型面臨的各種挑戰，包括可解釋性問題、資料集限制和操作員依賴性。28 項納入研究的綜合發現提到，需要標準化工作和前瞻性多中心研究來解決這些問題。此外，還確定了克服這些障礙的方法，例如可解釋人工智能技術和個人化醫療技術的進步。本篇評論重點探討了人工智能和放射特徵分析如何轉變甲狀腺癌的診斷和治療。儘管存在挑戰，但未來對多學科合作、臨床適用性驗證和演算法改進的研究，仍有潛力改善甲狀腺癌治療中的患者預後和診斷精準度。

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

摘要：<paragraph>近年來，乳癌的盛行率迅速增加，使其成為全球主要的死亡原因之一。在所有癌症中，乳癌迄今為止是最常見的。手動診斷此疾病需要大量的時間和專業知識。由於乳癌的檢測過程耗時，因此透過建立機器學習模型來預測，有助於防止其進一步擴散。機器學習和可解釋 AI 在分類中至關重要，因為它們不僅可以提供準確的預測，還可以深入了解模型如何做出決策，有助於理解和信賴分類結果。在此研究中，我們評估並比較了五種不同的機器學習方法的分類準確度、精確度、召回率和 F1 分數，使用了一個主要的資料集（達卡醫學院醫院的 500 名患者）。五種不同的監督式機器學習技術，包括決策樹、隨機森林、邏輯迴歸、朴素貝氏和 XGBoost，已用於在我們的資料集上取得最佳結果。此外，本研究將 SHAP 分析應用於 XGBoost 模型，以解釋模型的預測並了解每個特徵對模型輸出的影響。我們比較了幾種演算法對資料進行分類的準確度，並與該領域的其他文獻進行對比。在最後評估後，本研究發現 XGBoost 達到了最佳的模型準確度，為 97%。</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

摘要：深度學習 (DL) 用於從乳房攝影術影像診斷乳癌的模型通常以「黑盒子」方式運作，這使得醫療保健專業人員難以信任和理解其決策過程。本研究提出一個整合架構，結合卷積神經網路 (CNN) 和可解釋人工智慧 (XAI)，以使用 CBIS-DDSM 資料集增強乳癌的診斷。方法包含一個精細的資料前處理管線和進階資料擴充技術，以對抗資料集限制，並採用預先訓練的網路（例如 VGG-16、Inception-V3 和 ResNet）進行遷移學習。我們研究的重點是評估 XAI 在解釋模型預測中的有效性，重點利用豪斯多夫測度量化評估 AI 生成的解釋和專家註解之間的一致性。這種方法對於 XAI 在促進 AI 輔助診斷中的可信度和倫理公平性至關重要。我們研究的發現說明了 CNN 和 XAI 在推進乳癌診斷方法中的有效協作，從而促進了先進 AI 技術在臨床環境中的更順暢整合。透過增強 AI 驅動決策的可解釋性，這項工作為 AI 系統和醫療從業人員之間的改善協作奠定了基礎，最終豐富了患者照護。此外，我們研究的影響遠遠超出了目前的技術。它鼓勵進一步研究如何結合多模式資料並改善 AI 解釋，以滿足臨床實務的需求。

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

摘要：以人为本的可解释 AI (HCXAI) 倡导将社会层面整合到 AI 解释中。HCXAI 话语的核心是社会透明度 (ST) 框架，其目标是让 AI 系统的社会组织背景对用户来说是可理解的。在这项工作中，我们建议扩展 ST 框架以解决大型语言模型 (LLM) 中社会错误归因的风险，尤其是在心理健康等敏感领域。事实上，LLM 能够出色地模拟角色和人格，这可能导致设计者的意图和用户对社会属性的认知之间出现错配，从而有风险促进情绪操纵和危险行为、认知不公正和不合理的信任。为了解决这些问题，我们建议用第五个“W 问题”来增强 ST 框架，以明确设计者和用户赋予 LLM 的具体社会属性。此补充旨在弥合 LLM 能力和用户认知之间的差距，促进基于 LLM 的技术在道德上负责任地开发和使用。

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

摘要：<paragraph>背景：氣胸是一種因肺部與胸壁之間異常集氣所引起的急性胸腔疾病。為了解決深度學習（DL）模型經常伴隨的不透明性，可解釋人工智慧（XAI）方法已被引入，用於概述與 DL 模型做出的氣胸診斷相關的區域。然而，這些解釋有時會與實際病灶區域有所出入，突顯出進一步改進的必要性。方法：我們提出了一種模板引導式方法，將氣胸的臨床知識納入 XAI 方法產生的模型解釋中，從而提升這些解釋的品質。利用放射科醫師建立的病灶描繪，我們的做法首先產生一個模板，用於表示氣胸可能發生的區域。然後將此模板疊加在模型解釋上，以篩選出超出模板邊界的無關解釋。為了驗證其效力，我們對三種 XAI 方法進行了比較分析，在兩個真實世界資料集中解釋兩個 DL 模型時，分別採用和不採用我們的模板引導。結果：所提出的方法在建立於三種 XAI 方法、兩個 DL 模型和兩個資料集的十二種基準情境中，始終改善了基準 XAI 方法。在比較模型解釋和真實病灶區域時，透過基準效能的效能改進計算出的平均增量百分比為交集比（IoU）的 97.8% 和骰子相似性係數（DSC）的 94.1%。結論：在氣胸診斷的背景下，我們提出了一種模板引導式方法，用於改善 AI 解釋。我們預期我們的模板引導將透過整合臨床領域專業知識，為闡明 AI 模型建立一種新方法。</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by Séamus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

摘要：<paragraph>在當前機器翻譯 (MT) 領域中，Transformer 架構脫穎而出，成為黃金標準，特別是對於高資源語言對。本研究探討其對低資源語言對的效能，包括英語↔愛爾蘭語和英語↔馬拉地語語言對。值得注意的是，本研究識別出最佳超參數和子詞模型類型，以顯著提高 Transformer 模型對低資源語言對的翻譯品質。
低資源語言的平行資料集的稀缺會阻礙 MT 的發展。為了解決這個問題，開發了 gaHealth，這是愛爾蘭語的第一個雙語健康資料語料庫。專注於健康領域，使用此域內資料集開發的模型在 BLEU 得分方面表現出非常顯著的進步，與 LoResMT2021 共享任務中的模型相比。隨後使用多維品質指標錯誤分類法進行的人工評估顯示，與基於 RNN 的對應模型相比，Transformer 系統在減少準確性和流暢性錯誤方面表現出優異的性能。
此外，本論文介紹了 adaptNMT 和 adaptMLLM，這兩個開源應用程式簡化了神經機器翻譯模型的開發、微調和部署。這些工具大幅簡化了設定和評估流程，讓 MT 更容易讓開發人員和翻譯人員使用。值得注意的是，adaptNMT 以 OpenNMT 生態系統為基礎，通過強調模型開發的環境足跡來促進生態友好的自然語言處理研究。與 LoResMT2021 共享任務中的基準相比，adaptMLLM 對 MLLM 的微調證明了英語↔愛爾蘭語和英語↔馬拉地語這兩個低資源語言對的翻譯性能進步。</paragraph>

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

摘要：糖尿病（DM）使患者容易出現血管併發症。
視網膜影像和血管反映身體的微血管和巨血管健康狀況。它們可用於診斷糖尿病併發症，包括糖尿病視網膜病變（DR）、神經病變、腎病和動脈粥樣硬化性心血管疾病，以及預測心血管事件的風險。為使用數位化視網膜影像進行高通量 DR 檢測而開發的人工智慧（AI）啟用系統已在臨床採用。除了 DR 篩檢外，AI 整合也具有巨大的潛力來應對與糖尿病患者整體照護相關的挑戰。在這項工作中，我們旨在全面回顧基於視網膜影像的 AI 應用相關研究的文獻，這些研究與糖尿病的診斷、預後和管理有關。我們將描述整體 AI 輔助糖尿病照護的發現，包括但不限於 DR 篩檢，並討論實施此類系統的障礙，包括與倫理、資料隱私、公平存取和可解釋性有關的問題。透過評估患者的健康狀況，同時考量糖尿病併發症以及未來心血管併發症的風險預後，AI 輔助視網膜影像分析有潛力成為糖尿病患者現代化個人化醫療的中心工具。

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

摘要：這項研究從多個利害關係人的角度探討不同的人工智慧 (AI) 應用在教育上的可接受性，包括學生、老師和家長。承認 AI 在教育上的轉型潛力，它解決了與資料隱私、AI 代理、透明度、可解釋性和 AI 的道德部署相關的疑慮。透過小插曲方法，參與者被呈現了四種情境，其中 AI 的代理、透明度、可解釋性和隱私受到操縱。在每個情境後，參與者完成了一項調查，該調查捕捉了他們對 AI 的整體效用、個人效用、正義、信心、風險和如果可用，使用每個情境的 AI 的意圖的看法。資料蒐集包含來自合作機構和社群媒體活動的 1198 位多利害關係人參與者的最終樣本，並專注於對四個 AI 使用案例的個別回應。對資料的調解分析表明，對 AI 的接受度和信任在利害關係人團體之間有顯著差異。我們發現，AI 的代理、透明度和可解釋性高低程度之間的關鍵調解者，以及使用不同教育 AI 的意圖，包括感知到的整體效用、正義和信心。這項研究強調，接受 AI 在教育上的應用是一個微妙且多面向的問題，除了不同的利害關係人的看法外，還需要仔細考慮具體的 AI 應用及其特徵。

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

摘要：<paragraph>基於可穿戴式單導程心電圖 (ECG) 裝置的遠端病患監測在早期偵測心臟疾病方面具有顯著的潛力，特別是與用於自動化心臟疾病偵測的人工智慧 (AI) 方法結合使用時。先前已有研究應用基於深度學習的 AI 方法進行心臟疾病偵測。然而，這些模型尚未被廣泛接受為臨床診斷的可靠輔助工具，部分原因在於圍繞許多 AI 演算法的當前黑箱感知。特別是，有必要找出有助於做出準確診斷的 ECG 訊號關鍵特徵，從而增強模型的可解釋性。在本研究中，我們開發了一種視覺轉換器方法，以根據單導程 ECG 資料找出心房顫動。殘差網路 (ResNet) 方法也已開發出來，以便與視覺轉換器方法進行比較。這些模型應用於 Chapman-Shaoxing 資料集，以分類心房顫動，以及另一種常見的心律不整，竇性心動過緩，和正常竇性心律的心跳。這些模型能夠找出決定最終分類的心跳關鍵區域，並強調 P 波和 T 波，以及心跳持續時間和訊號振幅在區分正常竇性心律與心房顫動和竇性心動過緩方面的重要性。</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

摘要：本文介紹了一種使用先進大型語言模型 (LLM) 進行憂鬱症偵測和治療的新模式：生成式預訓練Transformer 4 (GPT-4)、Llama 2 聊天機器人和 Gemini。這些 LLM 經過微調，具備專業提示，可診斷、解釋並建議憂鬱症的治療介入方法。一種獨特的少次提示方法增強了模型根據 DSM-5 標準分析和解釋憂鬱症狀的能力。在互動階段，這些模型會參與同理心對話管理，從 PsychDB 和認知行為療法 (CBT) 指南等資源中汲取，促進與經歷重度憂鬱症的人們的支持性互動。此外，這項研究還介紹了 Illuminate 資料庫，其中包含各種 CBT 模組，有助於個性化治療建議。這項研究使用 F1 分數、準確率、召回率、餘弦相似度和面向召回率的 Gisting 評估替身 (ROUGE) 等指標，在不同的測試集中評估 LLM 的表現，證明了它們的有效性。這種綜合方法結合了尖端的 AI 與既定的心理方法，為心理保健提供了新的可能性，並展示了 LLM 在革新憂鬱症診斷和治療策略方面的潛力。

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v4 by Timothée Schmude, Laura Koesten, Torsten Möller, Sebastian Tschiatschek

Explanations of AI systems rarely address the information needs of people
affected by algorithmic decision-making (ADM). This gap between conveyed
information and information that matters to affected stakeholders can impede
understanding and adherence to regulatory frameworks such as the AI Act. To
address this gap, we present the "XAI Novice Question Bank": A catalog of
affected stakeholders' information needs in two ADM use cases (employment
prediction and health monitoring), covering the categories data, system
context, system usage, and system specifications. Information needs were
gathered in an interview study where participants received explanations in
response to their inquiries. Participants further reported their understanding
and decision confidence, showing that while confidence tended to increase after
receiving explanations, participants also met understanding challenges, such as
being unable to tell why their understanding felt incomplete. Explanations
further influenced participants' perceptions of the systems' risks and
benefits, which they confirmed or changed depending on the use case. When risks
were perceived as high, participants expressed particular interest in
explanations about intention, such as why and to what end a system was put in
place. With this work, we aim to support the inclusion of affected stakeholders
into explainability by contributing an overview of information and challenges
relevant to them when deciding on the adoption of ADM systems. We close by
summarizing our findings in a list of six key implications that inform the
design of future explanations for affected stakeholder audiences.

摘要：<paragraph>人工智慧系統的說明很少能滿足受演算法決策 (ADM) 影響的人們的資訊需求。傳達的資訊與影響利害關係人重要的資訊之間的差距，可能會阻礙了解和遵守法規架構，例如人工智慧法案。為了解決這個差距，我們提出了「XAI 初學者問題庫」：受影響利害關係人資訊需求的目錄，涵蓋兩個 ADM 使用案例（就業預測和健康監測），涵蓋資料、系統脈絡、系統使用和系統規格類別。資訊需求是透過訪談研究收集的，參與者在詢問後收到說明。參與者進一步回報他們的理解和決策信心，顯示雖然在收到說明後信心傾向於增加，但參與者也遇到了理解挑戰，例如無法說明為什麼他們的理解感覺不完整。說明進一步影響參與者對系統風險和好處的看法，他們會根據使用案例確認或改變這些看法。當風險被認為很高時，參與者表示特別有興趣了解意圖的說明，例如為什麼以及為了什麼目的而建立系統。透過這項工作，我們旨在透過在決策採用 ADM 系統時提供相關資訊和挑戰的概覽，來支援將受影響的利害關係人納入可解釋性。我們最後總結我們的發現，列出六項關鍵影響，這些影響會告知未來針對受影響利害關係人受眾說明的設計。</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet Gürkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

摘要：人工智慧 (AI) 的快速演進，尤其是在大型語言模型 (LLM) 和生成式 AI 的領域，為各個領域的應用開啟了新途徑，但其在商業教育中的角色仍未被充分探討。本研究首次引入了基準，用以評估七個主要 LLM 的效能，包括 OpenAI 的模型 (GPT-3.5 Turbo、GPT-4 和 GPT-4 Turbo)、Google 的模型 (PaLM 2、Gemini 1.0 Pro) 和 Anthropic 的模型 (Claude 2 和 Claude 2.1)，這些模型將用於研究生商業課程入學程序中的關鍵考試 GMAT。我們的分析顯示，大多數 LLM 的表現都優於人類考生，其中 GPT-4 Turbo 不僅優於其他模型，更超越了頂尖商學院的研究生平均分數。透過案例研究，本研究探討了 GPT-4 Turbo 在解釋答案、評估回應、辨識錯誤、調整說明和產生替代情境方面的能力。與前一代版本相比，最新的 LLM 版本 GPT-4 Turbo、Claude 2.1 和 Gemini 1.0 Pro 在推理任務方面有顯著的進步，凸顯了其在解決複雜問題方面的潛力。儘管 AI 在教育、評量和輔導方面的承諾很明確，但仍有挑戰存在。我們的研究不僅闡明了 LLM 的學術潛力，也強調了在教育中審慎開發和應用 AI 的必要性。隨著 AI 技術的進步，建立 AI 互動的架構和協定、驗證 AI 生成的內容的準確性、確保全球各地多元學習者的存取權，以及創造一個 AI 支持人類專業知識的教育環境至關重要。本研究為進一步探索負責任地使用 AI 來豐富教育體驗並改善考試準備和評量方法奠定了基礎。

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

摘要：預測加護病房 (ICU) 病患的院內死亡率是最終臨床結果的關鍵。AI 已展現出優異的準確度，但卻缺乏可解釋性。為了解決這個問題，本文提出了一個可解釋的多模式死亡率預測器 (X-MMP)，採用有效且可解釋的 AI 方式，藉由多模式 ICU 資料來預測院內死亡率。我們在架構中採用多模式學習，可以接收來自臨床資料的異質輸入並做出決策。此外，我們引入了一個可解釋的方法，也就是分層傳播至 Transformer，作為 LRP 方法適當地延伸至 Transformer，對多模式輸入產生解釋，並揭露歸因於預測的顯著特徵。此外，每個模式對臨床結果的貢獻可以視覺化，協助臨床醫師了解決策背後的理由。我們根據 MIMIC-III 和 MIMIC-III 波形資料庫比對子集建構了一個多模式資料集。在基準資料集上的全面實驗證明，我們提出的架構可以達成合理的詮釋，並具備競爭力的預測準確度。特別是，我們的架構可以輕鬆地轉移到其他臨床任務，這有助於在醫療保健研究中發現關鍵因素。

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian Geißler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, Björn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias Küster, André Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

摘要：在過去的十年中，病理學中的人工智慧 (AI) 方法已大幅進步。然而，由於許多挑戰，包括將研究結果轉化為臨床診斷產品在技術和法規方面的障礙，以及缺乏標準化介面，導致整合到常規臨床實務中進展緩慢。開放且與供應商無關的 EMPAIA 計畫應對了這些挑戰。在此，我們提供 EMPAIA 的成就和經驗教訓的概述。EMPAIA 整合了病理學 AI 生態系統的各個利害關係人，即病理學家、電腦科學家和產業。在密切合作下，我們制定了技術互通性標準、AI 測試和產品開發建議，以及可解釋性方法。我們實作了模組化且開放原始碼的 EMPAIA 平臺，並成功整合了來自 8 個不同供應商的 14 個基於 AI 的影像分析應用程式，展示了不同的應用程式如何使用單一的標準化介面。我們優先考慮需求，並評估了 AI 在歐洲和亞洲的 14 個不同病理實驗室中的實際臨床應用。除了技術開發外，我們還為所有利害關係人建立了一個論壇，以分享數位病理學和 AI 的資訊和經驗。商業、臨床和學術利害關係人現在可以採用 EMPAIA 的常見開放原始碼介面，這為大規模標準化和簡化流程提供了獨特的機會。需要進一步的努力才能有效且廣泛地建立例行實驗室使用中的 AI 輔助。為此，已成立非營利協會 EMPAIA International，以作為永續基礎架構，繼續進行標準化，並支援廣泛實作和倡導 AI 輔助數位病理學的未來。

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

摘要：反事實解釋 (CE) 技術已引起關注，作為一種為與 AI 系統互動的使用者提供見解的方法。雖然在醫學影像和自動駕駛汽車等領域廣泛研究，圖形反事實解釋 (GCE) 方法相對較少被探索。GCE 會產生一個類似於原始圖形的新圖形，並根據基礎預測模型產生不同的結果。在這些 GCE 技術中，儘管在其他領域（例如藝術風格和自然語言建模）中展現出令人印象深刻的成就，但植基於生成機制的技術獲得的關注相對有限。對生成式解釋器的偏好源於它們在推理期間產生反事實實例的能力，利用輸入圖形的自主獲取擾動。基於上述理由，我們的研究引入了 RSGG-CE，一種用於反事實解釋的新型穩健隨機圖形生成器，能夠從學習到的潛在空間中產生反事實範例，考慮部分有序的生成序列。此外，我們進行定量和定性分析，以比較 RSGG-CE 的效能與 SoA 生成式解釋器，強調其增強了產生合理解釋候選的能力。

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

摘要：可解釋 AI 的動機之一是讓人們在使用和部署 AI 模型時做出更好、更明智的決策。但需要仔細評估以評估是否已達到此預期。目前的評估主要集中在解釋的演算法特性，而涉及人類受試者的評估通常採用主觀問題來測試人類對解釋有用性的看法，而沒有基於客觀指標和測量。在這項工作中，我們評估解釋是否可以在機器學習模型開發的實際場景中改善人類決策制定。我們進行了一項涉及影像資料的混合方法使用者研究，以評估 SmoothGrad、GradCAM 和預言解釋在兩個任務中產生的顯著性圖：模型選擇和反事實模擬。令人驚訝的是，我們沒有發現任何顯著性圖（即使是設計為易於理解且高度指示答案的合成預言解釋）能讓使用者在這些任務上顯著改善的證據。儘管如此，解釋確實有助於使用者更準確地描述模型。這些發現提示我們要對基於顯著性的解釋中可能存在誤解的有用性保持謹慎。

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

摘要：可解釋性和安全性建立信任。這些需要一個模型來展示一致性和可靠性。為了實現這些，有必要使用和分析數據和知識，並使用與 AI 應用相關的統計和符號 AI 方法 - 單獨使用任何一種方法都不會奏效。因此，我們主張並試圖證明 NeuroSymbolic AI 方法更適合於使 AI 成為受信任的 AI 系統。我們提出了 CREST 框架，展示了一致性、可靠性、使用者層級的可解釋性和安全性是如何建立在 NeuroSymbolic 方法上的，該方法使用數據和知識來支持關鍵應用（例如健康和福祉）的要求。本文重點關注大型語言模型 (LLM)，因為它是 CREST 框架中選擇的 AI 系統。LLM 因其在處理廣泛的自然語言處理 (NLP) 場景方面的多功能性而備受研究人員的關注。例如，ChatGPT 和 Google 的 MedPaLM 已成為提供一般和健康相關查詢信息的極有希望的平台。儘管如此，這些模型仍然是黑盒子，儘管納入了人類反饋和指令引導的調整。例如，儘管制定了安全防護措施，ChatGPT 仍可能產生不安全的回應。CREST 提出了一種合理的方法，在 NeuroSymbolic 框架中利用程序和基於圖表的知識，以闡明與 LLM 相關的挑戰。

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano, Stephen Glass, Ravi P. Ramachandran, Sharad Patel, Aaron J. Masino, Ghulam Rasool

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

摘要：本研究调查了在 COVID-19 疫情期间及以后预测死亡率时，已部署人工智能 (AI) 模型的性能、可解释性和稳健性。作为同类研究中的首例，我们发现贝叶斯神经网络 (BNN) 和智能训练技术让我们的模型在数据发生重大变化时仍能保持性能。我们的结果强调了开发稳健的 AI 模型的重要性，即使在具有挑战性的条件下，这些模型也能匹配或超越临床医生的预测。我们对模型可解释性的探索表明，随机模型会产生更多样化且个性化的解释，从而突出了在现实世界的临床环境中提供详细且个性化见解的 AI 模型的必要性。此外，我们强调了量化 AI 模型中不确定性的重要性，这使临床医生能够根据可靠的预测做出更明智的决策。我们的研究提倡在医疗保健的 AI 研究中优先考虑实施科学，并确保 AI 解决方案在现实世界的临床环境中实用、有益且可持续。通过解决医疗保健环境中的独特挑战和复杂性，研究人员可以开发出有效改善临床实践和患者预后的 AI 模型。

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel, Aaron Quyn, David Jayne, Samuel D. Relton

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

摘要：肺癌占英國癌症死亡人數的 21%，五年存活率很大程度取決於癌症被發現的階段。最近的研究已證明人工智能方法具有從例行掃描中準確及早診斷肺癌的能力。然而，此證據尚未轉化為臨床實務，其中一個障礙是缺乏可解釋的模型。本研究探討了應用變分自動編碼器 (VAE)，一種生成式人工智能模型，於肺癌病灶。將提出的模型訓練於從 LIDC-IDRI 公共數據集中提取的 3D 電腦斷層掃描病灶。通過聚類探索了 VAE 生成的 2D 切片的潛在向量表示，以證明其品質，並用於肺癌診斷的 MLP 分類器模型，最佳模型達到了 AUC 0.98 和 93.1% 準確度的最先進指標。聚類分析顯示，VAE 潛在空間根據有意義的特徵組成（包括腫瘤大小、形狀、患者和惡性類別）將惡性和良性病灶的數據集分開。我們還包括標準高斯 VAE (GVAE) 和更新的狄利克雷 VAE (DirVAE) 的比較分析，後者用狄利克雷分佈取代先驗，以促進具有解開特徵表示的更具可解釋性的潛在空間。最後，我們展示了與臨床有意義的特徵變化相應的潛在空間橫越的潛力。

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

摘要：現有的圖像分類器輸出解釋工具可分為依賴於模型內部存取權限的白盒，以及與模型無關的黑盒。隨著 AI 在醫療領域的使用增加，可解釋性工具的使用也隨之增加。現有醫學影像解釋的工作重點在於白盒工具，例如 gradcam。然而，切換到黑盒工具有明顯的優點，包括能夠與任何分類器一起使用，以及廣泛的黑盒工具可供選擇。在標準影像上，黑盒工具與白盒一樣精確。在本文中，我們比較了多種黑盒方法在腦癌 MRI 資料集上與 gradcam 的效能。我們證明大多數黑盒工具不適合解釋醫學影像分類，並詳細分析其缺點的原因。我們還表明一種黑盒工具，基於因果可解釋性的 rex，表現與 \gradcam 一樣好。

##### **Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**
2311.12573v2 by Robert Gorwa, Michael Veale

The AI development community is increasingly making use of hosting
intermediaries such as Hugging Face provide easy access to user-uploaded models
and training data. These model marketplaces lower technical deployment barriers
for hundreds of thousands of users, yet can be used in numerous potentially
harmful and illegal ways. In this article, we explain ways in which AI systems,
which can both `contain' content and be open-ended tools, present one of the
trickiest platform governance challenges seen to date. We provide case studies
of several incidents across three illustrative platforms -- Hugging Face,
GitHub and Civitai -- to examine how model marketplaces moderate models.
Building on this analysis, we outline important (and yet nevertheless limited)
practices that industry has been developing to respond to moderation demands:
licensing, access and use restrictions, automated content moderation, and open
policy development. While the policy challenge at hand is a considerable one,
we conclude with some ideas as to how platforms could better mobilize resources
to act as a careful, fair, and proportionate regulatory access point.

摘要：AI 發展社群日益利用 Hugging Face 等託管中介，提供使用者上傳之模型與訓練資料的簡易取得管道。這些模型市集降低了數十萬名使用者的技術部署門檻，但卻可能被用於許多潛在有害且非法的用途。在本文中，我們說明了 AI 系統既可以「包含」內容，也可以作為開放式工具，這提出了迄今為止最棘手的平台治理挑戰之一。我們提供 Hugging Face、GitHub 和 Civitai 等三個說明性平台上數起事件的案例研究，以探討模型市集如何控管模型。根據此分析，我們概述了產業為回應控管需求而發展的重要（但仍有限）實務：授權、存取和使用限制、自動內容控管和開放式政策發展。儘管目前面臨的政策挑戰相當嚴峻，我們仍提出了一些想法，說明平台如何能更好地動員資源，作為謹慎、公平和適度的法規存取點。

##### **Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**
2311.11932v1 by Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker

Background and objectives: By extracting this information, Machine or Deep
Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and
cancer researchers in discovering patterns and relationships from complex data
sets. Many DL-based analyses on ovarian cancer (OC) data have recently been
published. These analyses are highly diverse in various aspects of cancer
(e.g., subdomain(s) and cancer type they address) and data analysis features.
However, a comprehensive understanding of these analyses in terms of these
features and AI assurance (AIA) is currently lacking. This systematic review
aims to fill this gap by examining the existing literature and identifying
important aspects of OC data analysis using DL, explicitly focusing on the key
features and AI assurance perspectives. Methods: The PRISMA framework was used
to conduct comprehensive searches in three journal databases. Only studies
published between 2015 and 2023 in peer-reviewed journals were included in the
analysis. Results: In the review, a total of 96 DL-driven analyses were
examined. The findings reveal several important insights regarding DL-driven
ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on
detection and diagnosis, while no study addressed the prediction and prevention
of OC. - The analyses were predominantly based on samples from a non-diverse
population (75% (72/96 studies)), limited to a geographic location or country.
- Only a small proportion of studies (only 33% (32/96)) performed integrated
analyses, most of which used homogeneous data (clinical or omics). - Notably, a
mere 8.3% (8/96) of the studies validated their models using external and
diverse data sets, highlighting the need for enhanced model validation, and -
The inclusion of AIA in cancer data analysis is in a very early stage; only
2.1% (2/96) explicitly addressed AIA through explainability.

摘要：<paragraph>背景和目標：通過提取這些資訊，機器或深度學習 (ML/DL) 基於自主數據分析工具可以協助臨床醫生和癌症研究人員從複雜的數據集中發現模式和關係。最近已發表許多基於 DL 的卵巢癌 (OC) 數據分析。這些分析在癌症的各個方面（例如，它們涉及的子領域和癌症類型）和數據分析功能方面高度多樣化。然而，目前缺乏對這些分析在這些特徵和 AI 保證 (AIA) 方面的全面理解。這篇系統性回顧旨在通過檢視現有文獻並明確關注關鍵特徵和 AI 保證觀點，來填補這個空白。方法：使用 PRISMA 架構在三個期刊資料庫中進行全面搜尋。分析僅包括 2015 年至 2023 年間發表於同行評審期刊的研究。結果：在回顧中，總共檢視了 96 項由 DL 驅動的分析。研究結果揭示了幾個關於由 DL 驅動的卵巢癌數據分析的重要見解：- 大多數研究 71%（96 項中有 68 項）專注於檢測和診斷，而沒有研究探討 OC 的預測和預防。- 這些分析主要基於來自非多元族群的樣本（75%（96 項研究中的 72 項）），僅限於某個地理位置或國家。- 只有少部分研究（僅 33%（96 項研究中的 32 項）執行整合分析，其中大多數使用同質數據（臨床或組學）。- 值得注意的是，只有 8.3%（96 項研究中的 8 項）使用外部和多元數據集驗證了其模型，強調了加強模型驗證的必要性，以及- 將 AIA 納入癌症數據分析仍處於非常早期的階段；只有 2.1%（96 項研究中的 2 項）透過可解釋性明確探討了 AIA。</paragraph>

##### **Representing visual classification as a linear combination of words**
2311.10933v1 by Shobhit Agarwal, Yevgeniy R. Semenov, William Lotter

Explainability is a longstanding challenge in deep learning, especially in
high-stakes domains like healthcare. Common explainability methods highlight
image regions that drive an AI model's decision. Humans, however, heavily rely
on language to convey explanations of not only "where" but "what".
Additionally, most explainability approaches focus on explaining individual AI
predictions, rather than describing the features used by an AI model in
general. The latter would be especially useful for model and dataset auditing,
and potentially even knowledge generation as AI is increasingly being used in
novel tasks. Here, we present an explainability strategy that uses a
vision-language model to identify language-based descriptors of a visual
classification task. By leveraging a pre-trained joint embedding space between
images and text, our approach estimates a new classification task as a linear
combination of words, resulting in a weight for each word that indicates its
alignment with the vision-based classifier. We assess our approach using two
medical imaging classification tasks, where we find that the resulting
descriptors largely align with clinical knowledge despite a lack of
domain-specific language training. However, our approach also identifies the
potential for 'shortcut connections' in the public datasets used. Towards a
functional measure of explainability, we perform a pilot reader study where we
find that the AI-identified words can enable non-expert humans to perform a
specialized medical task at a non-trivial level. Altogether, our results
emphasize the potential of using multimodal foundational models to deliver
intuitive, language-based explanations of visual tasks.

摘要：<paragraph>解釋性是深度學習中長期的挑戰，特別是在醫療保健等高風險領域。常見的解釋性方法會強調驅動 AI 模型決策的影像區域。然而，人類很大程度依賴語言來傳達不僅是「在哪裡」，還有「是什麼」的解釋。此外，大多數解釋性方法都專注於解釋個別 AI 預測，而不是描述 AI 模型一般使用的特徵。後者對於模型和資料集稽核特別有用，甚至可能在 AI 愈來愈用於新穎任務時產生知識。在此，我們提出一個使用視覺語言模型來辨識視覺分類任務的語言描述符的解釋性策略。透過利用影像和文字之間預先訓練的聯合嵌入空間，我們的做法將新的分類任務估計為一個線性文字組合，導致每個文字都有權重，表示它與基於視覺的分類器對齊。我們使用兩個醫學影像分類任務來評估我們的做法，我們發現產生的描述符在很大程度上與臨床知識一致，儘管缺乏特定領域的語言訓練。然而，我們的做法也發現了所用公開資料集中的「捷徑連線」的可能性。為了達到解釋性的功能性衡量，我們進行了一項試驗讀者研究，發現 AI 識別的文字能讓非專家人類在非平凡的層級執行專業的醫療任務。總之，我們的結果強調了使用多模式基礎模型來提供直觀的、基於語言的視覺任務解釋的潛力。</paragraph>

##### **Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**
2311.02115v2 by Emma A. M. Stanley, Raissa Souza, Anthony Winder, Vedant Gulve, Kimberly Amador, Matthias Wilms, Nils D. Forkert

Artificial intelligence (AI) models trained using medical images for clinical
tasks often exhibit bias in the form of disparities in performance between
subgroups. Since not all sources of biases in real-world medical imaging data
are easily identifiable, it is challenging to comprehensively assess how those
biases are encoded in models, and how capable bias mitigation methods are at
ameliorating performance disparities. In this article, we introduce a novel
analysis framework for systematically and objectively investigating the impact
of biases in medical images on AI models. We developed and tested this
framework for conducting controlled in silico trials to assess bias in medical
imaging AI using a tool for generating synthetic magnetic resonance images with
known disease effects and sources of bias. The feasibility is showcased by
using three counterfactual bias scenarios to measure the impact of simulated
bias effects on a convolutional neural network (CNN) classifier and the
efficacy of three bias mitigation strategies. The analysis revealed that the
simulated biases resulted in expected subgroup performance disparities when the
CNN was trained on the synthetic datasets. Moreover, reweighing was identified
as the most successful bias mitigation strategy for this setup, and we
demonstrated how explainable AI methods can aid in investigating the
manifestation of bias in the model using this framework. Developing fair AI
models is a considerable challenge given that many and often unknown sources of
biases can be present in medical imaging datasets. In this work, we present a
novel methodology to objectively study the impact of biases and mitigation
strategies on deep learning pipelines, which can support the development of
clinical AI that is robust and responsible.

摘要：<paragraph>使用醫療影像訓練的人工智慧 (AI) 模型，用於臨床任務時，常會在效能上展現出次群體之間的差異，形成偏見。由於並非所有真實世界醫療影像資料中的偏見來源都容易辨識，因此全面評估這些偏見是如何編碼到模型中，以及偏見緩解方法在改善效能差異方面的能力，是一項挑戰。在本文中，我們介紹了一個新穎的分析架構，用於系統化且客觀地調查醫療影像中的偏見對 AI 模型的影響。我們開發並測試了這個架構，以進行受控的電腦模擬試驗，使用一個工具來評估醫療影像 AI 中的偏見，該工具用於產生具有已知疾病影響和偏見來源的合成磁共振影像。可行性透過使用三個反事實偏見情境來衡量模擬偏見效應對卷積神經網路 (CNN) 分類器和三個偏見緩解策略的影響，並展示出來。分析顯示，當 CNN 在合成資料集上受訓時，模擬偏見會導致預期的次群體效能差異。此外，重新加權被認為是此設定中最成功的偏見緩解策略，我們展示了解釋性 AI 方法如何協助使用這個架構調查模型中偏見的表現。開發公平的 AI 模型是一項重大的挑戰，因為醫療影像資料集中可能存在許多且經常未知的偏見來源。在這項工作中，我們提出了一種新穎的方法，用於客觀地研究偏見和緩解策略對深度學習管線的影響，這可以支援健全且負責任的臨床 AI 的開發。</paragraph>

##### **Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**
2310.19174v1 by Adam White, Margarita Saranti, Artur d'Avila Garcez, Thomas M. H. Hope, Cathy J. Price, Howard Bowman

Machine learning offers great potential for automated prediction of
post-stroke symptoms and their response to rehabilitation. Major challenges for
this endeavour include the very high dimensionality of neuroimaging data, the
relatively small size of the datasets available for learning, and how to
effectively combine neuroimaging and tabular data (e.g. demographic information
and clinical characteristics). This paper evaluates several solutions based on
two strategies. The first is to use 2D images that summarise MRI scans. The
second is to select key features that improve classification accuracy.
Additionally, we introduce the novel approach of training a convolutional
neural network (CNN) on images that combine regions-of-interest extracted from
MRIs, with symbolic representations of tabular data. We evaluate a series of
CNN architectures (both 2D and a 3D) that are trained on different
representations of MRI and tabular data, to predict whether a composite measure
of post-stroke spoken picture description ability is in the aphasic or
non-aphasic range. MRI and tabular data were acquired from 758 English speaking
stroke survivors who participated in the PLORAS study. The classification
accuracy for a baseline logistic regression was 0.678 for lesion size alone,
rising to 0.757 and 0.813 when initial symptom severity and recovery time were
successively added. The highest classification accuracy 0.854 was observed when
8 regions-of-interest was extracted from each MRI scan and combined with lesion
size, initial severity and recovery time in a 2D Residual Neural Network.Our
findings demonstrate how imaging and tabular data can be combined for high
post-stroke classification accuracy, even when the dataset is small in machine
learning terms. We conclude by proposing how the current models could be
improved to achieve even higher levels of accuracy using images from hospital
scanners.

摘要：機器學習為自動預測中風後症狀及其對復健的反應提供了極大的潛力。這項工作的重大挑戰包括神經影像資料的維度非常高、可用於學習的資料集規模相對較小，以及如何有效結合神經影像和表格資料（例如人口統計資訊和臨床特徵）。本文根據兩種策略評估了多種解決方案。第一種是使用總結 MRI 掃描的 2D 影像。第二種是選擇有助於提高分類精確度的關鍵特徵。此外，我們引入了在結合從 MRI 中提取的感興趣區域與表格資料的符號表示的影像上訓練卷積神經網路 (CNN) 的新穎方法。我們評估了一系列 CNN 架構（2D 和 3D），這些架構在 MRI 和表格資料的不同表示上進行訓練，以預測中風後口述圖片描述能力的綜合測量是否在失語症或非失語症範圍內。MRI 和表格資料來自 758 名參與 PLORAS 研究的英語中風倖存者。僅針對病灶大小的基線邏輯迴歸分類準確度為 0.678，當依序加入初始症狀嚴重程度和恢復時間時，上升至 0.757 和 0.813。在從每個 MRI 掃描中提取 8 個感興趣區域並在 2D 殘差神經網路中與病灶大小、初始嚴重程度和恢復時間結合時，觀察到最高的分類準確度 0.854。我們的研究結果展示了如何將影像和表格資料結合起來以獲得高於中風後分類準確度，即使在機器學習術語中資料集很小的情況下也是如此。最後，我們提出如何改進目前的模型，以使用來自醫院掃描儀的影像來實現更高的準確度。

##### **Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**
2310.01828v2 by Hossein Shreim, Abdul Karim Gizzini, Ali J. Ghandour

eXplainable Artificial Intelligence (XAI) has emerged as an essential
requirement when dealing with mission-critical applications, ensuring
transparency and interpretability of the employed black box AI models. The
significance of XAI spans various domains, from healthcare to finance, where
understanding the decision-making process of deep learning algorithms is
essential. Most AI-based computer vision models are often black boxes; hence,
providing explainability of deep neural networks in image processing is crucial
for their wide adoption and deployment in medical image analysis, autonomous
driving, and remote sensing applications. Recently, several XAI methods for
image classification tasks have been introduced. On the contrary, image
segmentation has received comparatively less attention in the context of
explainability, although it is a fundamental task in computer vision
applications, especially in remote sensing. Only some research proposes
gradient-based XAI algorithms for image segmentation. This paper adapts the
recent gradient-free Sobol XAI method for semantic segmentation. To measure the
performance of the Sobol method for segmentation, we propose a quantitative XAI
evaluation method based on a learnable noise model. The main objective of this
model is to induce noise on the explanation maps, where higher induced noise
signifies low accuracy and vice versa. A benchmark analysis is conducted to
evaluate and compare performance of three XAI methods, including Seg-Grad-CAM,
Seg-Grad-CAM++ and Seg-Sobol using the proposed noise-based evaluation
technique. This constitutes the first attempt to run and evaluate XAI methods
using high-resolution satellite images.

摘要：可解釋人工智慧 (XAI) 已成為處理任務關鍵應用程式時的一項基本需求，確保採用黑盒 AI 模型的透明度和可解釋性。XAI 的重要性涵蓋從醫療保健到金融的各種領域，在這些領域中，了解深度學習演算法的決策制定過程至關重要。大多數基於 AI 的電腦視覺模型通常是黑盒子；因此，在影像處理中提供深度神經網路的可解釋性對於其在醫學影像分析、自動駕駛和遙測應用中的廣泛採用和部署至關重要。最近，已針對影像分類任務引入了多種 XAI 方法。相反地，影像分割在可解釋性的背景下受到的關注相對較少，儘管它是電腦視覺應用中的一項基本任務，特別是在遙測中。只有部分研究提出用於影像分割的基於梯度的 XAI 演算法。本文改編了最近的無梯度 Sobol XAI 方法以進行語意分割。為了衡量 Sobol 方法在分割中的效能，我們提出了一種基於可學習雜訊模型的定量 XAI 評估方法。此模型的主要目的是在解釋圖上誘發雜訊，其中較高的誘發雜訊表示較低的準確度，反之亦然。進行基準分析以評估和比較三種 XAI 方法的效能，包括 Seg-Grad-CAM、Seg-Grad-CAM++ 和 Seg-Sobol，並使用所提出的基於雜訊的評估技術。這構成了使用高解析度衛星影像執行和評估 XAI 方法的首次嘗試。

##### **Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**
2311.01463v1 by Muhammad Aurangzeb Ahmad, Ilker Yaramis, Taposh Dutta Roy

Large language models have proliferated across multiple domains in as short
period of time. There is however hesitation in the medical and healthcare
domain towards their adoption because of issues like factuality, coherence, and
hallucinations. Give the high stakes nature of healthcare, many researchers
have even cautioned against its usage until these issues are resolved. The key
to the implementation and deployment of LLMs in healthcare is to make these
models trustworthy, transparent (as much possible) and explainable. In this
paper we describe the key elements in creating reliable, trustworthy, and
unbiased models as a necessary condition for their adoption in healthcare.
Specifically we focus on the quantification, validation, and mitigation of
hallucinations in the context in healthcare. Lastly, we discuss how the future
of LLMs in healthcare may look like.

摘要：大型語言模型在短時間內已在多個領域中大量激增。然而，由於事實性、連貫性和幻覺等問題，醫療和保健領域對其採用猶豫不決。鑑於醫療保健的高風險性質，許多研究人員甚至警告不要使用它，直到這些問題得到解決。在醫療保健中實施和部署 LLM 的關鍵是使這些模型值得信賴、透明（盡可能多）且可解釋。在本文中，我們描述了建立可靠、值得信賴和無偏見模型的關鍵要素，作為它們在醫療保健中得到採用的必要條件。具體來說，我們專注於在醫療保健背景下對幻覺進行量化、驗證和緩解。最後，我們討論了 LLM 在醫療保健中的未來可能是什麼樣子。

##### **When to Trust AI: Advances and Challenges for Certification of Neural Networks**
2309.11196v1 by Marta Kwiatkowska, Xiyue Zhang

Artificial intelligence (AI) has been advancing at a fast pace and it is now
poised for deployment in a wide range of applications, such as autonomous
systems, medical diagnosis and natural language processing. Early adoption of
AI technology for real-world applications has not been without problems,
particularly for neural networks, which may be unstable and susceptible to
adversarial examples. In the longer term, appropriate safety assurance
techniques need to be developed to reduce potential harm due to avoidable
system failures and ensure trustworthiness. Focusing on certification and
explainability, this paper provides an overview of techniques that have been
developed to ensure safety of AI decisions and discusses future challenges.

摘要：人工智慧（AI）已快速進步，現已準備部署於廣泛的應用程式中，例如自主系統、醫療診斷和自然語言處理。及早採用 AI 技術於實際應用程式並非沒有問題，特別是對於神經網路，它可能不穩定且容易受到對抗性範例的影響。從長遠來看，需要開發適當的安全保證技術，以減少因可避免的系統故障而造成的潛在傷害，並確保可信賴性。本文著重於認證和可解釋性，概述了已開發用於確保 AI 決策安全的技術，並討論未來的挑戰。

##### **Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**
2309.10424v1 by Juan M. García-Gómez, Vicent Blanes-Selva, José Carlos de Bartolomé Cenzano, Jaime Cebolla-Cornejo, Ascensión Doñate-Martínez

The Directorate General for Parliamentary Research Services of the European
Parliament has prepared a report to the Members of the European Parliament
where they enumerate seven main risks of Artificial Intelligence (AI) in
medicine and healthcare: patient harm due to AI errors, misuse of medical AI
tools, bias in AI and the perpetuation of existing inequities, lack of
transparency, privacy and security issues, gaps in accountability, and
obstacles in implementation.
  In this study, we propose fourteen functional requirements that AI systems
may implement to reduce the risks associated with their medical purpose: AI
passport, User management, Regulation check, Academic use only disclaimer, data
quality assessment, Clinicians double check, Continuous performance evaluation,
Audit trail, Continuous usability test, Review of retrospective/simulated
cases, Bias check, eXplainable AI, Encryption and use of field-tested
libraries, and Semantic interoperability.
  Our intention here is to provide specific high-level specifications of
technical solutions to ensure continuous good performance and use of AI systems
to benefit patients in compliance with the future EU regulatory framework.

摘要：歐洲議會議會研究服務總局已為歐洲議會議員準備了一份報告，其中列舉了人工智能 (AI) 在醫療保健領域的七項主要風險：AI 錯誤導致患者受到傷害、醫療 AI 工具被濫用、AI 存在偏見並導致現有 inequities 持續存在、缺乏透明度、隱私和安全問題、問責差距以及實施障礙。
  在這項研究中，我們提出了十四項功能性要求，AI 系統可以實施這些要求來降低與其醫療目的相關的風險：AI 護照、使用者管理、法規檢查、僅限學術用途免責聲明、資料品質評估、臨床醫生雙重檢查、持續效能評估、稽核追蹤、持續可用性測試、回顧回溯/模擬案例、偏見檢查、可解釋 AI、加密和使用經過實地測試的程式庫，以及語意互通性。
  我們在此的目的是提供技術解決方案的特定高階規格，以確保持續良好的效能，並使用 AI 系統，以符合未來的歐盟法規架構，從而使患者受益。

##### **QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**
2309.10293v3 by Thanveer Shaik, Xiaohui Tao, Haoran Xie, Lin Li, Juan D. Velasquez, Niall Higgins

Artificial Intelligence techniques can be used to classify a patient's
physical activities and predict vital signs for remote patient monitoring.
Regression analysis based on non-linear models like deep learning models has
limited explainability due to its black-box nature. This can require
decision-makers to make blind leaps of faith based on non-linear model results,
especially in healthcare applications. In non-invasive monitoring, patient data
from tracking sensors and their predisposing clinical attributes act as input
features for predicting future vital signs. Explaining the contributions of
various features to the overall output of the monitoring application is
critical for a clinician's decision-making. In this study, an Explainable AI
for Quantitative analysis (QXAI) framework is proposed with post-hoc model
explainability and intrinsic explainability for regression and classification
tasks in a supervised learning approach. This was achieved by utilizing the
Shapley values concept and incorporating attention mechanisms in deep learning
models. We adopted the artificial neural networks (ANN) and attention-based
Bidirectional LSTM (BiLSTM) models for the prediction of heart rate and
classification of physical activities based on sensor data. The deep learning
models achieved state-of-the-art results in both prediction and classification
tasks. Global explanation and local explanation were conducted on input data to
understand the feature contribution of various patient data. The proposed QXAI
framework was evaluated using PPG-DaLiA data to predict heart rate and mobile
health (MHEALTH) data to classify physical activities based on sensor data.
Monte Carlo approximation was applied to the framework to overcome the time
complexity and high computation power requirements required for Shapley value
calculations.

摘要：人工智慧技術可用於分類病患的身體活動並預測遠距病患監控的重要生命徵象。基於深度學習模型等非線性模型的回歸分析由於其黑盒子的性質而具有有限的可解釋性。這可能需要決策者根據非線性模型結果做出盲目的信仰飛躍，特別是在醫療保健應用中。在非侵入性監控中，來自追蹤感測器和其易感臨床屬性的病患資料充當預測未來生命徵象的輸入特徵。解釋各種特徵對監控應用程式整體輸出的貢獻對於臨床醫生的決策至關重要。在本研究中，提出了一個用於量化分析的可解釋人工智慧 (QXAI) 架構，該架構具有監督式學習方法中回歸和分類任務的事後模型可解釋性和內在可解釋性。這透過利用 Shapley 值概念並將注意力機制納入深度學習模型來實現。我們採用人工神經網路 (ANN) 和基於注意力的雙向 LSTM (BiLSTM) 模型，根據感測器資料預測心率和分類身體活動。深度學習模型在預測和分類任務中都取得了最先進的成果。對輸入資料進行全局解釋和局部解釋，以了解各種病患資料的特徵貢獻。所提出的 QXAI 架構使用 PPG-DaLiA 資料評估，以預測心率，並使用行動健康 (MHEALTH) 資料根據感測器資料對身體活動進行分類。蒙地卡羅近似法應用於該架構，以克服 Shapley 值計算所需的時間複雜度和高運算能力需求。

##### **Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**
2309.09917v1 by Adarsa Sivaprasad, Ehud Reiter, Nava Tintarev, Nir Oren

In explainable artificial intelligence (XAI) research, the predominant focus
has been on interpreting models for experts and practitioners. Model agnostic
and local explanation approaches are deemed interpretable and sufficient in
many applications. However, in domains like healthcare, where end users are
patients without AI or domain expertise, there is an urgent need for model
explanations that are more comprehensible and instil trust in the model's
operations. We hypothesise that generating model explanations that are
narrative, patient-specific and global(holistic of the model) would enable
better understandability and enable decision-making. We test this using a
decision tree model to generate both local and global explanations for patients
identified as having a high risk of coronary heart disease. These explanations
are presented to non-expert users. We find a strong individual preference for a
specific type of explanation. The majority of participants prefer global
explanations, while a smaller group prefers local explanations. A task based
evaluation of mental models of these participants provide valuable feedback to
enhance narrative global explanations. This, in turn, guides the design of
health informatics systems that are both trustworthy and actionable.

摘要：在可解释人工智能 (XAI) 研究中，主要重点在于为专家和从业者解释模型。模型不可知和局部解释方法在许多应用中被认为是可解释且足够的。然而，在医疗保健等领域，最终用户是缺乏人工智能或领域专业知识的患者，因此迫切需要更易于理解且能激发对模型操作的信任的模型解释。我们假设生成叙述性、患者特定且全局（模型整体）的模型解释将能够提高可理解性并支持决策制定。我们使用决策树模型对此进行测试，为被识别为患有冠心病高风险的患者生成局部和全局解释。这些解释会呈现给非专家用户。我们发现用户强烈偏好特定类型的解释。大多数参与者偏好全局解释，而较小的一组参与者偏好局部解释。基于任务的心理模型评估为这些参与者提供了有价值的反馈，以增强叙述性全局解释。这反过来又指导了既值得信赖又可操作的健康信息学系统的设计。

##### **Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**
2308.14321v1 by Yanjun Gao, Ruizhe Li, John Caskey, Dmitriy Dligach, Timothy Miller, Matthew M. Churpek, Majid Afshar

Electronic Health Records (EHRs) and routine documentation practices play a
vital role in patients' daily care, providing a holistic record of health,
diagnoses, and treatment. However, complex and verbose EHR narratives overload
healthcare providers, risking diagnostic inaccuracies. While Large Language
Models (LLMs) have showcased their potential in diverse language tasks, their
application in the healthcare arena needs to ensure the minimization of
diagnostic errors and the prevention of patient harm. In this paper, we outline
an innovative approach for augmenting the proficiency of LLMs in the realm of
automated diagnosis generation, achieved through the incorporation of a medical
knowledge graph (KG) and a novel graph model: Dr.Knows, inspired by the
clinical diagnostic reasoning process. We derive the KG from the National
Library of Medicine's Unified Medical Language System (UMLS), a robust
repository of biomedical knowledge. Our method negates the need for
pre-training and instead leverages the KG as an auxiliary instrument aiding in
the interpretation and summarization of complex medical concepts. Using
real-world hospital datasets, our experimental results demonstrate that the
proposed approach of combining LLMs with KG has the potential to improve the
accuracy of automated diagnosis generation. More importantly, our approach
offers an explainable diagnostic pathway, edging us closer to the realization
of AI-augmented diagnostic decision support systems.

摘要：電子健康紀錄 (EHR) 和例行文件記錄實務在病患的日常照護中扮演著至關重要的角色，提供健康、診斷和治療的整體紀錄。然而，複雜且冗長的 EHR 敘述會讓醫療保健提供者超載，有診斷不準確的風險。大型語言模型 (LLM) 已展現其在各種語言任務上的潛力，但其在醫療保健領域的應用需要確保將診斷錯誤降到最低，並防止病患受到傷害。在本文中，我們概述一種創新的方法，透過整合醫學知識圖譜 (KG) 和一種新穎的圖譜模型：Dr.Knows（靈感來自臨床診斷推理過程），來增強 LLM 在自動化診斷產生領域的能力。我們從美國國家醫學圖書館的統一醫學語言系統 (UMLS) 中衍生出 KG，這是一個強大的生物醫學知識儲存庫。我們的做法否定了預先訓練的需要，而是將 KG 作為輔助工具，協助解釋和總結複雜的醫學概念。使用真實世界的醫院資料集，我們的實驗結果證明，將 LLM 與 KG 結合的建議方法有潛力提高自動化診斷產生的準確性。更重要的是，我們的做法提供了一條可解釋的診斷途徑，讓我們更接近實現 AI 增強的診斷決策支援系統。

##### **Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**
2308.09380v1 by Yun Xin Teoh, Alice Othmani, Siew Li Goh, Juliana Usman, Khin Wee Lai

Existing artificial intelligence (AI) models for diagnosing knee
osteoarthritis (OA) have faced criticism for their lack of transparency and
interpretability, despite achieving medical-expert-like performance. This
opacity makes them challenging to trust in clinical practice. Recently,
explainable artificial intelligence (XAI) has emerged as a specialized
technique that can provide confidence in the model's prediction by revealing
how the prediction is derived, thus promoting the use of AI systems in
healthcare. This paper presents the first survey of XAI techniques used for
knee OA diagnosis. The XAI techniques are discussed from two perspectives: data
interpretability and model interpretability. The aim of this paper is to
provide valuable insights into XAI's potential towards a more reliable knee OA
diagnosis approach and encourage its adoption in clinical practice.

摘要：現有的用於診斷膝骨關節炎 (OA) 的人工智慧 (AI) 模型因其缺乏透明度和可解釋性而受到批評，儘管它們達到了類似醫學專家的表現。這種不透明性使得它們在臨床實務中難以被信任。最近，可解釋人工智慧 (XAI) 已成為一種專門技術，它能透過揭示預測的推導方式來提供對模型預測的信心，從而促進在醫療保健中使用 AI 系統。本文提供了針對膝骨關節炎診斷所使用的 XAI 技術的第一份調查。XAI 技術從兩個角度進行討論：資料可解釋性和模型可解釋性。本文的目的是提供對 XAI 在更可靠的膝骨關節炎診斷方法中的潛力的寶貴見解，並鼓勵在臨床實務中採用它。

##### **Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**
2308.08407v1 by Munib Mesinovic, Peter Watkinson, Tingting Zhu

Recent advancements in AI applications to healthcare have shown incredible
promise in surpassing human performance in diagnosis and disease prognosis.
With the increasing complexity of AI models, however, concerns regarding their
opacity, potential biases, and the need for interpretability. To ensure trust
and reliability in AI systems, especially in clinical risk prediction models,
explainability becomes crucial. Explainability is usually referred to as an AI
system's ability to provide a robust interpretation of its decision-making
logic or the decisions themselves to human stakeholders. In clinical risk
prediction, other aspects of explainability like fairness, bias, trust, and
transparency also represent important concepts beyond just interpretability. In
this review, we address the relationship between these concepts as they are
often used together or interchangeably. This review also discusses recent
progress in developing explainable models for clinical risk prediction,
highlighting the importance of quantitative and clinical evaluation and
validation across multiple common modalities in clinical practice. It
emphasizes the need for external validation and the combination of diverse
interpretability methods to enhance trust and fairness. Adopting rigorous
testing, such as using synthetic datasets with known generative factors, can
further improve the reliability of explainability methods. Open access and
code-sharing resources are essential for transparency and reproducibility,
enabling the growth and trustworthiness of explainable research. While
challenges exist, an end-to-end approach to explainability in clinical risk
prediction, incorporating stakeholders from clinicians to developers, is
essential for success.

摘要：最近在醫療保健中的人工智慧應用進展顯示出令人難以置信的承諾，在診斷和疾病預後方面超越人類表現。然而，隨著人工智能模型的日益複雜，人們對其不透明性、潛在偏差和對可解釋性的需求感到擔憂。為了確保人工智能系統的信任和可靠性，尤其是在臨床風險預測模型中，可解釋性變得至關重要。可解釋性通常被稱為人工智能系統提供其決策邏輯或決策本身對人類利益相關者的強有力解釋的能力。在臨床風險預測中，可解釋性的其他方面，如公平性、偏見、信任和透明度，也代表了超越可解釋性的重要概念。在本次審查中，我們探討了這些概念之間的關係，因為它們經常一起或互換使用。本審查還討論了為臨床風險預測開發可解釋模型的最新進展，強調了在臨床實踐中對多種常見模式進行定量和臨床評估和驗證的重要性。它強調了外部驗證和多樣化可解釋性方法相結合的必要性，以增強信任和公平性。採用嚴格的測試，例如使用具有已知生成因素的合成數據集，可以進一步提高可解釋性方法的可靠性。開放獲取和代碼共享資源對於透明度和可重複性至關重要，從而促進可解釋研究的增長和可信度。儘管存在挑戰，但從臨床醫生到開發人員，採用端到端的可解釋性方法對於臨床風險預測的成功至關重要。

##### **FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**
2309.12325v3 by Karim Lekadir, Aasa Feragen, Abdul Joseph Fofanah, Alejandro F Frangi, Alena Buyx, Anais Emelie, Andrea Lara, Antonio R Porras, An-Wen Chan, Arcadi Navarro, Ben Glocker, Benard O Botwe, Bishesh Khanal, Brigit Beger, Carol C Wu, Celia Cintas, Curtis P Langlotz, Daniel Rueckert, Deogratias Mzurikwao, Dimitrios I Fotiadis, Doszhan Zhussupov, Enzo Ferrante, Erik Meijering, Eva Weicken, Fabio A González, Folkert W Asselbergs, Fred Prior, Gabriel P Krestin, Gary Collins, Geletaw S Tegenaw, Georgios Kaissis, Gianluca Misuraca, Gianna Tsakou, Girish Dwivedi, Haridimos Kondylakis, Harsha Jayakody, Henry C Woodruf, Horst Joachim Mayer, Hugo JWL Aerts, Ian Walsh, Ioanna Chouvarda, Irène Buvat, Isabell Tributsch, Islem Rekik, James Duncan, Jayashree Kalpathy-Cramer, Jihad Zahir, Jinah Park, John Mongan, Judy W Gichoya, Julia A Schnabel, Kaisar Kushibar, Katrine Riklund, Kensaku Mori, Kostas Marias, Lameck M Amugongo, Lauren A Fromont, Lena Maier-Hein, Leonor Cerdá Alberich, Leticia Rittner, Lighton Phiri, Linda Marrakchi-Kacem, Lluís Donoso-Bach, Luis Martí-Bonmatí, M Jorge Cardoso, Maciej Bobowicz, Mahsa Shabani, Manolis Tsiknakis, Maria A Zuluaga, Maria Bielikova, Marie-Christine Fritzsche, Marina Camacho, Marius George Linguraru, Markus Wenzel, Marleen De Bruijne, Martin G Tolsgaard, Marzyeh Ghassemi, Md Ashrafuzzaman, Melanie Goisauf, Mohammad Yaqub, Mónica Cano Abadía, Mukhtar M E Mahmoud, Mustafa Elattar, Nicola Rieke, Nikolaos Papanikolaou, Noussair Lazrak, Oliver Díaz, Olivier Salvado, Oriol Pujol, Ousmane Sall, Pamela Guevara, Peter Gordebeke, Philippe Lambin, Pieta Brown, Purang Abolmaesumi, Qi Dou, Qinghua Lu, Richard Osuala, Rose Nakasi, S Kevin Zhou, Sandy Napel, Sara Colantonio, Shadi Albarqouni, Smriti Joshi, Stacy Carter, Stefan Klein, Steffen E Petersen, Susanna Aussó, Suyash Awate, Tammy Riklin Raviv, Tessa Cook, Tinashe E M Mutsvangwa, Wendy A Rogers, Wiro J Niessen, Xènia Puig-Bosch, Yi Zeng, Yunusa G Mohammed, Yves Saint James Aquino, Zohaib Salahuddin, Martijn P A Starmans

Despite major advances in artificial intelligence (AI) for medicine and
healthcare, the deployment and adoption of AI technologies remain limited in
real-world clinical practice. In recent years, concerns have been raised about
the technical, clinical, ethical and legal risks associated with medical AI. To
increase real world adoption, it is essential that medical AI tools are trusted
and accepted by patients, clinicians, health organisations and authorities.
This work describes the FUTURE-AI guideline as the first international
consensus framework for guiding the development and deployment of trustworthy
AI tools in healthcare. The FUTURE-AI consortium was founded in 2021 and
currently comprises 118 inter-disciplinary experts from 51 countries
representing all continents, including AI scientists, clinicians, ethicists,
and social scientists. Over a two-year period, the consortium defined guiding
principles and best practices for trustworthy AI through an iterative process
comprising an in-depth literature review, a modified Delphi survey, and online
consensus meetings. The FUTURE-AI framework was established based on 6 guiding
principles for trustworthy AI in healthcare, i.e. Fairness, Universality,
Traceability, Usability, Robustness and Explainability. Through consensus, a
set of 28 best practices were defined, addressing technical, clinical, legal
and socio-ethical dimensions. The recommendations cover the entire lifecycle of
medical AI, from design, development and validation to regulation, deployment,
and monitoring. FUTURE-AI is a risk-informed, assumption-free guideline which
provides a structured approach for constructing medical AI tools that will be
trusted, deployed and adopted in real-world practice. Researchers are
encouraged to take the recommendations into account in proof-of-concept stages
to facilitate future translation towards clinical practice of medical AI.

摘要：儘管在醫學和醫療保健方面的人工智慧 (AI) 有重大的進展，但 AI 技術的部署和採用在現實世界的臨床實務中仍然有限。近年來，人們對於與醫療 AI 相關的技術、臨床、倫理和法律風險提出了疑慮。為了增加現實世界的採用率，醫療 AI 工具必須獲得患者、臨床醫生、醫療機構和當局的信任和接受。這項工作將 FUTURE-AI 指南描述為指導醫療保健中可信賴 AI 工具開發和部署的第一個國際共識架構。FUTURE-AI 聯盟成立於 2021 年，目前由來自 51 個國家的 118 位跨領域專家組成，代表所有洲，包括 AI 科學家、臨床醫生、倫理學家和社會科學家。在兩年的時間裡，該聯盟通過一個反覆運算的過程定義了可信賴 AI 的指導原則和最佳實務，包括深入的文獻回顧、修改後的德爾菲調查和線上共識會議。FUTURE-AI 架構是基於醫療保健中可信賴 AI 的 6 項指導原則建立的，即公平性、普遍性、可追溯性、可用性、穩健性和可解釋性。通過共識，定義了一組 28 項最佳實務，涵蓋技術、臨床、法律和社會倫理層面。建議涵蓋了醫療 AI 的整個生命週期，從設計、開發和驗證到法規、部署和監控。FUTURE-AI 是一個基於風險、無假設的指南，提供了一個結構化的方法，用於建構將在現實世界實務中受到信任、部署和採用的醫療 AI 工具。鼓勵研究人員在概念驗證階段考慮這些建議，以促進未來將醫療 AI 轉化為臨床實務。

##### **Explainable AI applications in the Medical Domain: a systematic review**
2308.05411v1 by Nicoletta Prentzas, Antonis Kakas, Constantinos S. Pattichis

Artificial Intelligence in Medicine has made significant progress with
emerging applications in medical imaging, patient care, and other areas. While
these applications have proven successful in retrospective studies, very few of
them were applied in practice.The field of Medical AI faces various challenges,
in terms of building user trust, complying with regulations, using data
ethically.Explainable AI (XAI) aims to enable humans understand AI and trust
its results. This paper presents a literature review on the recent developments
of XAI solutions for medical decision support, based on a representative sample
of 198 articles published in recent years. The systematic synthesis of the
relevant articles resulted in several findings. (1) model-agnostic XAI
techniques were mostly employed in these solutions, (2) deep learning models
are utilized more than other types of machine learning models, (3)
explainability was applied to promote trust, but very few works reported the
physicians participation in the loop, (4) visual and interactive user interface
is more useful in understanding the explanation and the recommendation of the
system. More research is needed in collaboration between medical and AI
experts, that could guide the development of suitable frameworks for the
design, implementation, and evaluation of XAI solutions in medicine.

摘要：人工智慧在醫療領域中已取得顯著進展，在醫學影像、病人照護和其他領域中出現了新興應用。雖然這些應用已在回顧性研究中被證實是成功的，但實際上只有極少數應用於實務。醫療 AI 領域面臨著各種挑戰，包括建立使用者信任、遵守法規、使用資料符合倫理。可解釋 AI (XAI) 的目標是讓人類了解 AI 並相信其結果。本文針對最近幾年發表的 198 篇文章的具代表性樣本，提出有關醫療決策支援的 XAI 解決方案的最新發展的文獻回顧。相關文章的系統性綜合整理產生了多項發現：(1) 這些解決方案大多採用與模型無關的 XAI 技術，(2) 深度學習模型的使用率高於其他類型的機器學習模型，(3) 可解釋性被用於促進信任，但很少有研究報告醫師參與迴圈，(4) 視覺和互動式使用者介面對於理解系統的解釋和建議更有用。需要更多醫療和 AI 專家合作進行研究，這有助於為醫療領域的 XAI 解決方案的設計、實作和評估提供適當架構。

##### **Exploring the Role of Explainability in AI-Assisted Embryo Selection**
2308.02534v1 by Lucia Urcelay, Daniel Hinjos, Pablo A. Martin-Torres, Marta Gonzalez, Marta Mendez, Salva Cívico, Sergio Álvarez-Napagao, Dario Garcia-Gasulla

In Vitro Fertilization is among the most widespread treatments for
infertility. One of its main challenges is the evaluation and selection of
embryo for implantation, a process with large inter- and intra-clinician
variability. Deep learning based methods are gaining attention, but their
opaque nature compromises their acceptance in the clinical context, where
transparency in the decision making is key. In this paper we analyze the
current work in the explainability of AI-assisted embryo analysis models,
identifying the limitations. We also discuss how these models could be
integrated in the clinical context as decision support systems, considering the
needs of clinicians and patients. Finally, we propose guidelines for the sake
of increasing interpretability and trustworthiness, pushing this technology
forward towards established clinical practice.

摘要：體外受精是治療不孕症最廣泛的方法之一。其主要挑戰之一是評估和選擇胚胎進行植入，此過程具有很大的臨床間和臨床內變異性。基於深度學習的方法正受到關注，但其不透明的性質會影響其在臨床環境中的接受度，而透明度在決策制定中至關重要。在本文中，我們分析了 AI 輔助胚胎分析模型的可解釋性方面的現有工作，並找出其局限性。我們還討論了如何將這些模型作為決策支持系統整合到臨床環境中，同時考慮臨床醫生和患者的需求。最後，我們提出了提高可解釋性和可信度的準則，推進這項技術朝著既定的臨床實務邁進。

##### **A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**
2307.14246v1 by Timo Speith, Markus Langer

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

摘要：在需求工程 (RE) 領域中，可解釋人工智慧 (XAI) 在將 AI 支持的系統與使用者需求、社會期望和法規標準相符方面的重要性日益顯著，已獲得認可。一般來說，可解釋性已成為影響系統品質的重要非功能需求。然而，可解釋性與效能之間的假定權衡挑戰了可解釋性的假定正面影響。如果滿足可解釋性的需求需要降低系統效能，那麼必須仔細考慮這些品質面向中哪一個優先，以及如何在它們之間進行折衷。在本文中，我們批判性地探討了這種假定的權衡。我們認為，最好的方法是以一種細緻的方式來處理，這種方式包含資源可用性、領域特性和風險考量。透過提供未來研究和最佳實務的基礎，這項工作旨在提升 AI 的 RE 領域。

##### **Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**
2307.14239v1 by Barnaby Crook, Maximilian Schlüter, Timo Speith

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

摘要：在需求工程（RE）领域，可解释人工智能（XAI）在将人工智能支持的系统与用户需求、社会期望和监管标准相一致方面的重要性日益凸显，并获得了认可。一般来说，可解释性已成为影响系统质量的重要非功能性需求。然而，可解释性和性能之间的权衡挑战了可解释性的正面影响。如果满足可解释性的要求需要降低系统性能，那么必须仔细考虑这些质量方面中的哪一个优先，以及如何在它们之间进行权衡。在本文中，我们批判性地考察了所谓的权衡。我们认为，最好以一种细致入微的方式来处理它，这种方式结合了资源可用性、领域特征和风险考虑。通过为未来的研究和最佳实践提供基础，这项工作旨在推进人工智能的 RE 领域。

##### **Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough**
2308.02047v1 by Henry Fraser, Jose-Miguel Bello y Villarino

This paper critically evaluates the European Commission's proposed AI Act's
approach to risk management and risk acceptability for high-risk AI systems
that pose risks to fundamental rights and safety. The Act aims to promote
"trustworthy" AI with a proportionate regulatory burden. Its provisions on risk
acceptability require residual risks from high-risk systems to be reduced or
eliminated "as far as possible", having regard to the "state of the art". This
criterion, especially if interpreted narrowly, is unworkable and promotes
neither proportionate regulatory burden, nor trustworthiness. By contrast the
Parliament's most recent draft amendments to the risk management provisions
introduce "reasonableness", cost-benefit analysis, and are more transparent
about the value-laden and contextual nature of risk acceptability judgements.
This paper argues that the Parliament's approach is more workable, and better
balances the goals of proportionality and trustworthiness. It explains what
reasonableness in risk acceptability judgments would entail, drawing on
principles from negligence law and European medical devices regulation. And it
contends that the approach to risk acceptability judgments need a firm
foundation of civic legitimacy: including detailed guidance or involvement from
regulators, and meaningful input from affected stakeholders.

摘要：本文嚴格評估歐洲委員會提出的 AI 法案對風險管理和風險可接受性的方法，用於對基本權利和安全構成風險的高風險 AI 系統。該法案旨在以相稱的監管負擔促進「值得信賴」的 AI。其關於風險可接受性的條款要求將高風險系統的殘餘風險減低或消除「盡可能」，並考慮「技術狀態」。此準則，特別是如果狹義解釋，無法執行，既不促進相稱的監管負擔，也不促進可信賴性。相比之下，議會對風險管理條款的最新修正草案引入了「合理性」、成本效益分析，並且更透明地說明了風險可接受性判斷的價值觀和背景性質。本文論證議會的方法更可行，且能更好地平衡相稱性和可信賴性的目標。本文說明風險可接受性判斷中的合理性會帶來什麼，並根據過失法和歐洲醫療器材法規中的原則進行說明。本文主張風險可接受性判斷的方法需要穩固的公民合法性基礎：包括監管機構的詳細指導或參與，以及受影響利害關係人的有意義投入。

##### **eXplainable Artificial Intelligence (XAI) in aging clock models**
2307.13704v3 by Alena Kalyakulina, Igor Yusipov, Alexey Moskalev, Claudio Franceschi, Mikhail Ivanchenko

eXplainable Artificial Intelligence (XAI) is a rapidly progressing field of
machine learning, aiming to unravel the predictions of complex models. XAI is
especially required in sensitive applications, e.g. in health care, when
diagnosis, recommendations and treatment choices might rely on the decisions
made by artificial intelligence systems. AI approaches have become widely used
in aging research as well, in particular, in developing biological clock models
and identifying biomarkers of aging and age-related diseases. However, the
potential of XAI here awaits to be fully appreciated. We discuss the
application of XAI for developing the "aging clocks" and present a
comprehensive analysis of the literature categorized by the focus on particular
physiological systems.

摘要：可解釋人工智慧 (XAI) 是機器學習中快速進展的領域，旨在解開複雜模型的預測。XAI 在敏感應用中特別需要，例如在醫療保健中，當診斷、建議和治療選擇可能依賴於人工智慧系統做出的決策時。人工智慧方法也已廣泛用於老化研究，特別是在開發生物時鐘模型和識別老化和與年齡相關疾病的生物標誌物方面。然而，這裡 XAI 的潛力有待充分認識。我們討論了 XAI 在開發「老化時鐘」方面的應用，並對按特定生理系統的重點分類的文獻進行了全面的分析。

##### **Interpreting and Correcting Medical Image Classification with PIP-Net**
2307.10404v2 by Meike Nauta, Johannes H. Hegeman, Jeroen Geerdink, Jörg Schlötterer, Maurice van Keulen, Christin Seifert

Part-prototype models are explainable-by-design image classifiers, and a
promising alternative to black box AI. This paper explores the applicability
and potential of interpretable machine learning, in particular PIP-Net, for
automated diagnosis support on real-world medical imaging data. PIP-Net learns
human-understandable prototypical image parts and we evaluate its accuracy and
interpretability for fracture detection and skin cancer diagnosis. We find that
PIP-Net's decision making process is in line with medical classification
standards, while only provided with image-level class labels. Because of
PIP-Net's unsupervised pretraining of prototypes, data quality problems such as
undesired text in an X-ray or labelling errors can be easily identified.
Additionally, we are the first to show that humans can manually correct the
reasoning of PIP-Net by directly disabling undesired prototypes. We conclude
that part-prototype models are promising for medical applications due to their
interpretability and potential for advanced model debugging.

摘要：部分原型模型是可解釋設計的影像分類器，也是黑箱 AI 的一個有前途的替代方案。這篇論文探討了解釋性機器學習，特別是 PIP-Net，在真實世界醫學影像資料上自動化診斷支援的適用性和潛力。PIP-Net 學習人類可理解的原型影像部分，我們評估其在骨折檢測和皮膚癌診斷方面的準確性和可解釋性。我們發現 PIP-Net 的決策制定過程符合醫學分類標準，同時僅提供影像層級類別標籤。由於 PIP-Net 對原型的無監督預訓練，因此可以輕鬆識別資料品質問題，例如 X 光中的不需要文字或標籤錯誤。此外，我們首次展示人類可以透過直接停用不需要的原型來手動修正 PIP-Net 的推理。我們得出結論，部分原型模型由於其可解釋性和進階模型除錯的潛力，因此有望應用於醫療。

##### **Explaining and visualizing black-box models through counterfactual paths**
2307.07764v3 by Bastian Pfeifer, Mateusz Krzyzinski, Hubert Baniecki, Anna Saranti, Andreas Holzinger, Przemyslaw Biecek

Explainable AI (XAI) is an increasingly important area of machine learning
research, which aims to make black-box models transparent and interpretable. In
this paper, we propose a novel approach to XAI that uses the so-called
counterfactual paths generated by conditional permutations of features. The
algorithm measures feature importance by identifying sequential permutations of
features that most influence changes in model predictions. It is particularly
suitable for generating explanations based on counterfactual paths in knowledge
graphs incorporating domain knowledge. Counterfactual paths introduce an
additional graph dimension to current XAI methods in both explaining and
visualizing black-box models. Experiments with synthetic and medical data
demonstrate the practical applicability of our approach.

摘要：可解釋 AI (XAI) 是機器學習研究中日益重要的領域，其目標是讓黑箱模型透明且可解釋。在本文中，我們提出了一種新的 XAI 方法，該方法使用由特徵條件置換產生的所謂反事實路徑。該演算法透過識別特徵的順序置換來衡量特徵重要性，這些置換最能影響模型預測的變化。它特別適合根據包含領域知識的知識圖譜中的反事實路徑來產生解釋。反事實路徑在解釋和視覺化黑箱模型時，為目前的 XAI 方法引入了額外的圖形維度。使用合成和醫療資料進行的實驗證明了我們方法的實用適用性。

##### **Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research**
2307.02131v5 by Toygar Tanyel, Serkan Ayvaz, Bilgin Keserci

The field of explainability in artificial intelligence (AI) has witnessed a
growing number of studies and increasing scholarly interest. However, the lack
of human-friendly and individual interpretations in explaining the outcomes of
machine learning algorithms has significantly hindered the acceptance of these
methods by clinicians in their research and clinical practice. To address this
issue, our study uses counterfactual explanations to explore the applicability
of "what if?" scenarios in medical research. Our aim is to expand our
understanding of magnetic resonance imaging (MRI) features used for diagnosing
pediatric posterior fossa brain tumors beyond existing boundaries. In our case
study, the proposed concept provides a novel way to examine alternative
decision-making scenarios that offer personalized and context-specific
insights, enabling the validation of predictions and clarification of
variations under diverse circumstances. Additionally, we explore the potential
use of counterfactuals for data augmentation and evaluate their feasibility as
an alternative approach in our medical research case. The results demonstrate
the promising potential of using counterfactual explanations to enhance
acceptance of AI-driven methods in clinical research.

摘要：在人工智能 (AI) 的可解釋性領域中，已經看到越來越多的研究和學術興趣。然而，在解釋機器學習演算法的結果時缺乏人性化和個人化的詮釋，這顯著阻礙了臨床醫生在研究和臨床實務中接受這些方法。為了解決這個問題，我們的研究使用反事實解釋來探討「如果？」情境在醫學研究中的適用性。我們的目標是擴展我們對用於診斷小兒後顱窩腦腫瘤的磁共振成像 (MRI) 特徵的理解，超越現有的界線。在我們的案例研究中，所提出的概念提供了一種新穎的方法來檢視替代決策情境，提供個人化和特定於情境的見解，從而能夠驗證預測並釐清在不同情況下的差異。此外，我們探討了反事實用於資料擴充的潛在用途，並評估其作為我們醫學研究案例中替代方法的可行性。結果證明了使用反事實解釋來增強臨床研究中 AI 驅動方法的接受度的潛力。

##### **AI and Non AI Assessments for Dementia**
2307.01210v1 by Mahboobeh Parsapoor, Hamed Ghodrati, Vincenzo Dentamaro, Christopher R. Madan, Ioulietta Lazarou, Spiros Nikolopoulos, Ioannis Kompatsiaris

Current progress in the artificial intelligence domain has led to the
development of various types of AI-powered dementia assessments, which can be
employed to identify patients at the early stage of dementia. It can
revolutionize the dementia care settings. It is essential that the medical
community be aware of various AI assessments and choose them considering their
degrees of validity, efficiency, practicality, reliability, and accuracy
concerning the early identification of patients with dementia (PwD). On the
other hand, AI developers should be informed about various non-AI assessments
as well as recently developed AI assessments. Thus, this paper, which can be
readable by both clinicians and AI engineers, fills the gap in the literature
in explaining the existing solutions for the recognition of dementia to
clinicians, as well as the techniques used and the most widespread dementia
datasets to AI engineers. It follows a review of papers on AI and non-AI
assessments for dementia to provide valuable information about various dementia
assessments for both the AI and medical communities. The discussion and
conclusion highlight the most prominent research directions and the maturity of
existing solutions.

摘要：目前人工智能領域的進展導致了各種類型的人工智慧驅動的失智症評估的發展，可用於識別處於失智症早期階段的患者。它可以徹底改變失智症護理設置。重要的是，醫療界要了解各種人工智能評估，並根據其有效性、效率、實用性、可靠性和準確性程度，考慮選擇它們來早期識別失智症患者 (PwD)。另一方面，人工智能開發人員也應該了解各種非人工智能評估以及最近開發的人工智能評估。因此，這篇臨床醫生和人工智能工程師都可以閱讀的論文填補了文獻中關於向臨床醫生解釋現有失智症識別解決方案以及向人工智能工程師解釋所用技術和最廣泛的失智症數據集的空白。它遵循對人工智能和非人工智能失智症評估論文的回顧，為人工智能和醫療界提供有關各種失智症評估的寶貴信息。討論和結論重點介紹了最突出的研究方向和現有解決方案的成熟度。

##### **Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation**
2306.07306v1 by Ruitao Xie, Jingbang Chen, Limai Jiang, Rui Xiao, Yi Pan, Yunpeng Cai

Explainability poses a major challenge to artificial intelligence (AI)
techniques. Current studies on explainable AI (XAI) lack the efficiency of
extracting global knowledge about the learning task, thus suffer deficiencies
such as imprecise saliency, context-aware absence and vague meaning. In this
paper, we propose the class association embedding (CAE) approach to address
these issues. We employ an encoder-decoder architecture to embed sample
features and separate them into class-related and individual-related style
vectors simultaneously. Recombining the individual-style code of a given sample
with the class-style code of another leads to a synthetic sample with preserved
individual characters but changed class assignment, following a cyclic
adversarial learning strategy. Class association embedding distills the global
class-related features of all instances into a unified domain with well
separation between classes. The transition rules between different classes can
be then extracted and further employed to individual instances. We then propose
an active XAI framework which manipulates the class-style vector of a certain
sample along guided paths towards the counter-classes, resulting in a series of
counter-example synthetic samples with identical individual characters.
Comparing these counterfactual samples with the original ones provides a
global, intuitive illustration to the nature of the classification tasks. We
adopt the framework on medical image classification tasks, which show that more
precise saliency maps with powerful context-aware representation can be
achieved compared with existing methods. Moreover, the disease pathology can be
directly visualized via traversing the paths in the class-style space.

摘要：<paragraph>可解釋性對人工智慧 (AI) 技術構成一項重大挑戰。當前對可解釋 AI (XAI) 的研究缺乏提取學習任務整體知識的效率，因此存在不精確的顯著性、與情境無關的缺失和含糊意義等缺陷。在本文中，我們提出類別關聯嵌入 (CAE) 方法來解決這些問題。我們採用編碼器-解碼器架構來嵌入樣本特徵，並同時將它們分為類別相關和個體相關的樣式向量。將給定樣本的個體樣式代碼與另一個樣本的類別樣式代碼重新組合，會產生一個具有保留個體特徵但改變類別分配的合成樣本，遵循循環對抗學習策略。類別關聯嵌入將所有實例的全局類別相關特徵提煉到一個統一的領域中，並在類別之間有良好的區分。然後可以提取不同類別之間的轉換規則，並進一步應用於個別實例。然後，我們提出一個主動 XAI 框架，它沿著引導路徑操作特定樣本的類別樣式向量，朝著反類別移動，從而產生一系列具有相同個體特徵的反例合成樣本。將這些反事實樣本與原始樣本進行比較，可以對分類任務的性質提供全局、直觀的說明。我們採用該框架進行醫學影像分類任務，結果表明，與現有方法相比，可以獲得更精確的顯著性圖，並具有強大的與情境無關的表示。此外，疾病病理學可以直接通過在類別樣式空間中遍歷路徑來進行可視化。</paragraph>

##### **HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine**
2306.06029v1 by Rodrigo Agerri, Iñigo Alonso, Aitziber Atutxa, Ander Berrondo, Ainara Estarrona, Iker Garcia-Ferrero, Iakes Goenaga, Koldo Gojenola, Maite Oronoz, Igor Perez-Tejedor, German Rigau, Anar Yeginbergenova

Providing high quality explanations for AI predictions based on machine
learning is a challenging and complex task. To work well it requires, among
other factors: selecting a proper level of generality/specificity of the
explanation; considering assumptions about the familiarity of the explanation
beneficiary with the AI task under consideration; referring to specific
elements that have contributed to the decision; making use of additional
knowledge (e.g. expert evidence) which might not be part of the prediction
process; and providing evidence supporting negative hypothesis. Finally, the
system needs to formulate the explanation in a clearly interpretable, and
possibly convincing, way. Given these considerations, ANTIDOTE fosters an
integrated vision of explainable AI, where low-level characteristics of the
deep learning process are combined with higher level schemes proper of the
human argumentation capacity. ANTIDOTE will exploit cross-disciplinary
competences in deep learning and argumentation to support a broader and
innovative view of explainable AI, where the need for high-quality explanations
for clinical cases deliberation is critical. As a first result of the project,
we publish the Antidote CasiMedicos dataset to facilitate research on
explainable AI in general, and argumentation in the medical domain in
particular.

摘要：提供基於機器學習的 AI 預測的高品質說明是一項具有挑戰性和複雜性的任務。要順利進行，它需要具備下列因素：選擇適當的說明普遍性/特殊性層級；考量說明受益人對所考慮的 AI 任務的熟悉程度假設；參照促成決策的特定元素；利用可能不屬於預測程序的一部分的額外知識（例如專家證據）；並提供支持否定假設的證據。最後，系統需要以清晰可解釋且可能令人信服的方式制定說明。基於這些考量，ANTIDOTE 促成了可解釋 AI 的整合願景，其中深度學習程序的低階特徵與人類論證能力的高階架構相結合。ANTIDOTE 將利用深度學習與論證的跨領域能力，來支持可解釋 AI 更廣泛且創新的觀點，其中對臨床案例審議的高品質說明需求至關重要。作為該專案的第一個成果，我們發布了 Antidote CasiMedicos 資料集，以利於一般可解釋 AI 的研究，特別是醫療領域的論證。

##### **XInsight: Revealing Model Insights for GNNs with Flow-based Explanations**
2306.04791v1 by Eli Laird, Ayesh Madushanka, Elfi Kraka, Corey Clark

Progress in graph neural networks has grown rapidly in recent years, with
many new developments in drug discovery, medical diagnosis, and recommender
systems. While this progress is significant, many networks are `black boxes'
with little understanding of the `what' exactly the network is learning. Many
high-stakes applications, such as drug discovery, require human-intelligible
explanations from the models so that users can recognize errors and discover
new knowledge. Therefore, the development of explainable AI algorithms is
essential for us to reap the benefits of AI.
  We propose an explainability algorithm for GNNs called eXplainable Insight
(XInsight) that generates a distribution of model explanations using GFlowNets.
Since GFlowNets generate objects with probabilities proportional to a reward,
XInsight can generate a diverse set of explanations, compared to previous
methods that only learn the maximum reward sample. We demonstrate XInsight by
generating explanations for GNNs trained on two graph classification tasks:
classifying mutagenic compounds with the MUTAG dataset and classifying acyclic
graphs with a synthetic dataset that we have open-sourced. We show the utility
of XInsight's explanations by analyzing the generated compounds using QSAR
modeling, and we find that XInsight generates compounds that cluster by
lipophilicity, a known correlate of mutagenicity. Our results show that
XInsight generates a distribution of explanations that uncovers the underlying
relationships demonstrated by the model. They also highlight the importance of
generating a diverse set of explanations, as it enables us to discover hidden
relationships in the model and provides valuable guidance for further analysis.

摘要：<paragraph>近年來，圖神經網路的進展迅速，在藥物發現、醫療診斷和推薦系統方面都有許多新發展。雖然這些進展很重要，但許多網路都是「黑盒子」，對於網路到底在學習「什麼」了解甚少。許多高風險應用，例如藥物發現，需要模型提供人類可以理解的解釋，以便使用者可以辨識錯誤並發現新知識。因此，可解釋 AI 演算法的開發對於我們獲取 AI 的好處至關重要。
我們提出了一種稱為 eXplainable Insight (XInsight) 的 GNN 可解釋性演算法，它使用 GFlowNets 產生模型解釋分佈。由於 GFlowNets 會產生機率與獎勵成正比的物件，因此與先前僅學習最大獎勵範例的方法相比，XInsight 可以產生多樣化的解釋集合。我們透過為在兩個圖形分類任務中訓練的 GNN 產生解釋來展示 XInsight：使用 MUTAG 資料集對致突變化合物進行分類，並使用我們已開放原始碼的合成資料集對非環狀圖形進行分類。我們透過使用 QSAR 建模分析產生的化合物來展示 XInsight 解釋的效用，我們發現 XInsight 會產生按親脂性（已知的致突變相關性）分群的化合物。我們的結果顯示 XInsight 會產生一個解釋分佈，揭示模型所展示的底層關係。它們也強調產生多樣化解釋集合的重要性，因為它使我們能夠發現模型中的隱藏關係，並為進一步分析提供有價值的指導。</paragraph>

##### **Explainable AI using expressive Boolean formulas**
2306.03976v1 by Gili Rosenberg, J. Kyle Brubaker, Martin J. A. Schuetz, Grant Salton, Zhihuai Zhu, Elton Yechao Zhu, Serdar Kadıoğlu, Sima E. Borujeni, Helmut G. Katzgraber

We propose and implement an interpretable machine learning classification
model for Explainable AI (XAI) based on expressive Boolean formulas. Potential
applications include credit scoring and diagnosis of medical conditions. The
Boolean formula defines a rule with tunable complexity (or interpretability),
according to which input data are classified. Such a formula can include any
operator that can be applied to one or more Boolean variables, thus providing
higher expressivity compared to more rigid rule-based and tree-based
approaches. The classifier is trained using native local optimization
techniques, efficiently searching the space of feasible formulas. Shallow rules
can be determined by fast Integer Linear Programming (ILP) or Quadratic
Unconstrained Binary Optimization (QUBO) solvers, potentially powered by
special purpose hardware or quantum devices. We combine the expressivity and
efficiency of the native local optimizer with the fast operation of these
devices by executing non-local moves that optimize over subtrees of the full
Boolean formula. We provide extensive numerical benchmarking results featuring
several baselines on well-known public datasets. Based on the results, we find
that the native local rule classifier is generally competitive with the other
classifiers. The addition of non-local moves achieves similar results with
fewer iterations, and therefore using specialized or quantum hardware could
lead to a speedup by fast proposal of non-local moves.

摘要：我們提出並實作一個可解釋機器學習分類模型，用於基於表達式布林公式的可解釋 AI (XAI)。潛在應用包括信用評分和醫療狀況診斷。布林公式定義了一個具有可調整複雜性（或可解釋性）的規則，根據該規則對輸入數據進行分類。這樣的公式可以包含任何可應用於一個或多個布林變數的運算子，從而與更嚴格的基於規則和基於樹的方法相比，提供更高的表達能力。分類器使用原生局部最佳化技術進行訓練，有效地搜索可行公式的空間。淺層規則可以用快速的整數線性規劃 (ILP) 或二次無約束二元最佳化 (QUBO) 求解器來確定，這些求解器可能由特殊用途的硬體或量子裝置提供支援。我們將原生局部最佳化器的表達能力和效率與這些裝置的快速運算相結合，透過執行非局部移動來最佳化完整布林公式的子樹。我們提供廣泛的數值基準測試結果，其中包含在眾所周知的公共資料集上使用多個基線。根據結果，我們發現原生局部規則分類器通常與其他分類器具有競爭力。加入非局部移動以較少的反覆運算次數達成類似的結果，因此使用專用或量子硬體可能會透過快速提出非局部移動來加速。

##### **Utterance Classification with Logical Neural Network: Explainable AI for Mental Disorder Diagnosis**
2306.03902v1 by Yeldar Toleubay, Don Joven Agravante, Daiki Kimura, Baihan Lin, Djallel Bouneffouf, Michiaki Tatsubori

In response to the global challenge of mental health problems, we proposes a
Logical Neural Network (LNN) based Neuro-Symbolic AI method for the diagnosis
of mental disorders. Due to the lack of effective therapy coverage for mental
disorders, there is a need for an AI solution that can assist therapists with
the diagnosis. However, current Neural Network models lack explainability and
may not be trusted by therapists. The LNN is a Recurrent Neural Network
architecture that combines the learning capabilities of neural networks with
the reasoning capabilities of classical logic-based AI. The proposed system
uses input predicates from clinical interviews to output a mental disorder
class, and different predicate pruning techniques are used to achieve
scalability and higher scores. In addition, we provide an insight extraction
method to aid therapists with their diagnosis. The proposed system addresses
the lack of explainability of current Neural Network models and provides a more
trustworthy solution for mental disorder diagnosis.

摘要：為了解決心理健康問題的全球挑戰，我們提出一個基於邏輯神經網路 (LNN) 的神經符號 AI 方法來診斷心理疾病。由於缺乏有效的心理疾病治療涵蓋範圍，因此需要一種 AI 解決方案來協助治療師進行診斷。然而，目前的類神經網路模型缺乏可解釋性，治療師可能無法信任它們。LNN 是一種遞迴神經網路架構，它結合了神經網路的學習能力和基於經典邏輯的 AI 的推理能力。所提出的系統使用來自臨床訪談的輸入謂詞來輸出心理疾病類別，並使用不同的謂詞剪枝技術來實現可擴充性和更高的分數。此外，我們提供了一個見解提取方法來協助治療師進行診斷。所提出的系統解決了當前類神經網路模型缺乏可解釋性的問題，並為心理疾病診斷提供了更值得信賴的解決方案。

##### **XAI Renaissance: Redefining Interpretability in Medical Diagnostic Models**
2306.01668v1 by Sujith K Mandala

As machine learning models become increasingly prevalent in medical
diagnostics, the need for interpretability and transparency becomes paramount.
The XAI Renaissance signifies a significant shift in the field, aiming to
redefine the interpretability of medical diagnostic models. This paper explores
the innovative approaches and methodologies within the realm of Explainable AI
(XAI) that are revolutionizing the interpretability of medical diagnostic
models. By shedding light on the underlying decision-making process, XAI
techniques empower healthcare professionals to understand, trust, and
effectively utilize these models for accurate and reliable medical diagnoses.
This review highlights the key advancements in XAI for medical diagnostics and
their potential to transform the healthcare landscape, ultimately improving
patient outcomes and fostering trust in AI-driven diagnostic systems.

摘要：隨著機器學習模型在醫療診斷中越來越普遍，可解釋性和透明度的需求變得至關重要。XAI 復興標誌著該領域的重大轉變，旨在重新定義醫療診斷模型的可解釋性。本文探討了可解釋 AI (XAI) 領域內的創新方法和方法論，這些方法和方法論正在革新醫療診斷模型的可解釋性。通過闡明基礎決策制定過程，XAI 技術使醫療保健專業人員能夠理解、信任並有效地利用這些模型進行準確且可靠的醫療診斷。本綜述重點介紹了 XAI 在醫療診斷方面的關鍵進展及其轉變醫療保健領域的潛力，最終改善患者的治療效果並培養對 AI 驅動的診斷系統的信任。

##### **A Novel real-time arrhythmia detection model using YOLOv8**
2305.16727v3 by Guang Jun Nicholas Ang, Aritejh Kr Goil, Henryk Chan, Jieyi Jeric Lew, Xin Chun Lee, Raihan Bin Ahmad Mustaffa, Timotius Jason, Ze Ting Woon, Bingquan Shen

In a landscape characterized by heightened connectivity and mobility, coupled
with a surge in cardiovascular ailments, the imperative to curtail healthcare
expenses through remote monitoring of cardiovascular health has become more
pronounced. The accurate detection and classification of cardiac arrhythmias
are pivotal for diagnosing individuals with heart irregularities. This study
underscores the feasibility of employing electrocardiograms (ECG) measurements
in the home environment for real-time arrhythmia detection. Presenting a fresh
application for arrhythmia detection, this paper leverages the cutting-edge
You-Only-Look-Once (YOLO)v8 algorithm to categorize single-lead ECG signals. We
introduce a novel loss-modified YOLOv8 model, fine-tuned on the MIT-BIH
arrhythmia dataset, enabling real-time continuous monitoring. The obtained
results substantiate the efficacy of our approach, with the model attaining an
average accuracy of 99.5% and 0.992 mAP@50, and a rapid detection time of 0.002
seconds on an NVIDIA Tesla V100. Our investigation exemplifies the potential of
real-time arrhythmia detection, enabling users to visually interpret the model
output within the comfort of their homes. Furthermore, this study lays the
groundwork for an extension into a real-time explainable AI (XAI) model capable
of deployment in the healthcare sector, thereby significantly advancing the
realm of healthcare solutions.

摘要：<paragraph>在以高度連接性和流動性為特徵的環境中，加上心血管疾病的激增，通過遠程監控心血管健康來削減醫療保健支出的必要性變得更加明顯。準確檢測和分類心律不整對於診斷患有心臟不規則的人至關重要。本研究強調了在家中使用心電圖 (ECG) 測量進行實時心律不整檢測的可行性。本文提出了一種新的心律不整檢測應用，利用尖端的 You-Only-Look-Once (YOLO)v8 演算法對單導聯 ECG 訊號進行分類。我們引入了一個新穎的損失修改 YOLOv8 模型，並針對 MIT-BIH 心律不整資料集進行了微調，從而實現了實時的持續監控。獲得的結果證實了我們方法的有效性，該模型在 NVIDIA Tesla V100 上達到了 99.5% 的平均準確度和 0.992 mAP@50，以及 0.002 秒的快速檢測時間。我們的研究說明了實時心律不整檢測的潛力，使用戶能夠在家中舒適地視覺化解讀模型輸出。此外，本研究為擴展到實時可解釋 AI (XAI) 模型奠定了基礎，該模型能夠部署在醫療保健領域，從而顯著推進醫療保健解決方案的領域。</paragraph>

##### **Breast Cancer Segmentation using Attention-based Convolutional Network and Explainable AI**
2305.14389v2 by Jai Vardhan, Taraka Satya Krishna Teja Malisetti

Breast cancer (BC) remains a significant health threat, with no long-term
cure currently available. Early detection is crucial, yet mammography
interpretation is hindered by high false positives and negatives. With BC
incidence projected to surpass lung cancer, improving early detection methods
is vital. Thermography, using high-resolution infrared cameras, offers promise,
especially when combined with artificial intelligence (AI). This work presents
an attention-based convolutional neural network for segmentation, providing
increased speed and precision in BC detection and classification. The system
enhances images and performs cancer segmentation with explainable AI. We
propose a transformer-attention-based convolutional architecture (UNet) for
fault identification and employ Gradient-weighted Class Activation Mapping
(Grad-CAM) to analyze areas of bias and weakness in the UNet architecture with
IRT images. The superiority of our proposed framework is confirmed when
compared with existing deep learning frameworks.

摘要：乳癌（BC）仍然是一個重大的健康威脅，目前尚無長期治癒的方法。早期發現至關重要，但乳房攝影的判讀卻受到高假陽性和假陰性的阻礙。由於乳癌的發生率預計將超過肺癌，因此改善早期檢測方法至關重要。熱像攝影使用高解析度紅外線相機，特別是在與人工智慧（AI）結合使用時，提供了希望。這項工作提出了一個基於注意力的卷積神經網路用於分割，在乳癌檢測和分類中提供了更高的速度和精度。該系統增強影像並執行可解釋的 AI 癌症分割。我們提出了一個基於Transformer注意力的卷積架構（UNet）用於故障識別，並使用梯度加權類激活映射（Grad-CAM）來分析 UNet 架構中偏見和弱點的區域，使用 IRT 影像。與現有的深度學習框架相比，我們提出的框架的優越性得到證實。

##### **What Symptoms and How Long? An Interpretable AI Approach for Depression Detection in Social Media**
2305.13127v2 by Junwei Kuang, Jiaheng Xie, Zhijun Yan

Depression is the most prevalent and serious mental illness, which induces
grave financial and societal ramifications. Depression detection is key for
early intervention to mitigate those consequences. Such a high-stake decision
inherently necessitates interpretability. Although a few depression detection
studies attempt to explain the decision based on the importance score or
attention weights, these explanations misalign with the clinical depression
diagnosis criterion that is based on depressive symptoms. To fill this gap, we
follow the computational design science paradigm to develop a novel Multi-Scale
Temporal Prototype Network (MSTPNet). MSTPNet innovatively detects and
interprets depressive symptoms as well as how long they last. Extensive
empirical analyses using a large-scale dataset show that MSTPNet outperforms
state-of-the-art depression detection methods with an F1-score of 0.851. This
result also reveals new symptoms that are unnoted in the survey approach, such
as sharing admiration for a different life. We further conduct a user study to
demonstrate its superiority over the benchmarks in interpretability. This study
contributes to IS literature with a novel interpretable deep learning model for
depression detection in social media. In practice, our proposed method can be
implemented in social media platforms to provide personalized online resources
for detected depressed patients.

摘要：憂鬱症是最普遍且嚴重的精神疾病，會造成嚴重的財務和社會後果。憂鬱症的偵測對於早期介入以減輕這些後果至關重要。如此重大的決定本質上需要可解釋性。儘管一些憂鬱症偵測研究嘗試根據重要性分數或注意力權重來解釋這個決定，但這些解釋與基於憂鬱症狀的臨床憂鬱症診斷標準不一致。為了填補這個缺口，我們遵循計算設計科學範例來開發一個新穎的多尺度時間原型網路 (MSTPNet)。MSTPNet 創新地偵測並解釋憂鬱症狀以及它們持續多久。使用大規模資料集進行的廣泛實證分析顯示，MSTPNet 以 0.851 的 F1 分數優於最先進的憂鬱症偵測方法。此結果還揭示了調查方法中未注意到的新症狀，例如分享對不同生活的欽佩。我們進一步進行使用者研究，以證明其在可解釋性方面優於基準。本研究以一個新穎的可解釋深度學習模型為憂鬱症偵測在社群媒體中的 IS 文獻做出貢獻。在實務上，我們提出的方法可以實作在社群媒體平台中，以提供個人化的線上資源給被偵測出憂鬱症的患者。

##### **Echoes of Biases: How Stigmatizing Language Affects AI Performance**
2305.10201v4 by Yizhi Liu, Weiguang Wang, Guodong Gordon Gao, Ritu Agarwal

Electronic health records (EHRs) serve as an essential data source for the
envisioned artificial intelligence (AI)-driven transformation in healthcare.
However, clinician biases reflected in EHR notes can lead to AI models
inheriting and amplifying these biases, perpetuating health disparities. This
study investigates the impact of stigmatizing language (SL) in EHR notes on
mortality prediction using a Transformer-based deep learning model and
explainable AI (XAI) techniques. Our findings demonstrate that SL written by
clinicians adversely affects AI performance, particularly so for black
patients, highlighting SL as a source of racial disparity in AI model
development. To explore an operationally efficient way to mitigate SL's impact,
we investigate patterns in the generation of SL through a clinicians'
collaborative network, identifying central clinicians as having a stronger
impact on racial disparity in the AI model. We find that removing SL written by
central clinicians is a more efficient bias reduction strategy than eliminating
all SL in the entire corpus of data. This study provides actionable insights
for responsible AI development and contributes to understanding clinician
behavior and EHR note writing in healthcare.

摘要：電子健康紀錄 (EHR) 作為預想中由人工智慧 (AI) 推動的醫療保健轉型的重要資料來源。然而，反映在 EHR 備註中的臨床偏見可能導致 AI 模型繼承並擴大這些偏見，進而造成健康差異。本研究探討 EHR 備註中汙名化語言 (SL) 對使用基於 Transformer 的深度學習模型和可解釋 AI (XAI) 技術預測死亡率的影響。我們的研究結果表明，由臨床醫生撰寫的 SL 會對 AI 效能產生不利影響，特別是對黑人患者而言，突顯 SL 是 AI 模型開發中種族差異的來源。為了探索一種運作上有效率的方法來減輕 SL 的影響，我們透過臨床醫生的協作網路探討 SL 產生的模式，並找出核心臨床醫生對 AI 模型中的種族差異有較大的影響。我們發現，移除由核心臨床醫生撰寫的 SL 是比消除資料集中所有 SL 更有效率的偏見減少策略。本研究提供可行的見解，用於負責任的 AI 開發，並有助於了解臨床醫生行為和醫療保健中的 EHR 備註撰寫。

##### **Explaining the ghosts: Feminist intersectional XAI and cartography as methods to account for invisible labour**
2305.03376v1 by Goda Klumbyte, Hannah Piehl, Claude Draude

Contemporary automation through AI entails a substantial amount of
behind-the-scenes human labour, which is often both invisibilised and
underpaid. Since invisible labour, including labelling and maintenance work, is
an integral part of contemporary AI systems, it remains important to sensitise
users to its role. We suggest that this could be done through explainable AI
(XAI) design, particularly feminist intersectional XAI. We propose the method
of cartography, which stems from feminist intersectional research, to draw out
a systemic perspective of AI and include dimensions of AI that pertain to
invisible labour.

摘要：當代通過 AI 的自動化需要大量的幕後人力，這通常既不可見且薪資過低。由於不可見的勞動，包括標籤和維護工作，是當代 AI 系統的組成部分，因此讓使用者了解其角色仍然很重要。我們建議這可以透過可解釋的 AI（XAI）設計來完成，特別是女性主義交叉的 XAI。我們提出源自女性主義交叉研究的製圖方法，以提出 AI 的系統觀點，並納入與不可見勞動相關的 AI 維度。

##### **Towards Explainable and Safe Conversational Agents for Mental Health: A Survey**
2304.13191v1 by Surjodeep Sarkar, Manas Gaur, L. Chen, Muskan Garg, Biplav Srivastava, Bhaktee Dongaonkar

Virtual Mental Health Assistants (VMHAs) are seeing continual advancements to
support the overburdened global healthcare system that gets 60 million primary
care visits, and 6 million Emergency Room (ER) visits annually. These systems
are built by clinical psychologists, psychiatrists, and Artificial Intelligence
(AI) researchers for Cognitive Behavioral Therapy (CBT). At present, the role
of VMHAs is to provide emotional support through information, focusing less on
developing a reflective conversation with the patient. A more comprehensive,
safe and explainable approach is required to build responsible VMHAs to ask
follow-up questions or provide a well-informed response. This survey offers a
systematic critical review of the existing conversational agents in mental
health, followed by new insights into the improvements of VMHAs with contextual
knowledge, datasets, and their emerging role in clinical decision support. We
also provide new directions toward enriching the user experience of VMHAs with
explainability, safety, and wholesome trustworthiness. Finally, we provide
evaluation metrics and practical considerations for VMHAs beyond the current
literature to build trust between VMHAs and patients in active communications.

摘要：虛擬心理健康助理 (VMHA) 持續進步，以支援每年有 6000 萬人次初級保健就診和 600 萬人次急診室 (ER) 就診的超負荷全球醫療保健系統。這些系統是由臨床心理學家、精神科醫師和人工智慧 (AI) 研究人員為認知行為療法 (CBT) 所建構。目前，VMHA 的角色是透過資訊提供情緒支持，較少著重於與患者發展反思性的對話。需要更全面、安全且可解釋的方法來建構負責任的 VMHA，以提出後續問題或提供充分的回應。這項調查提供了對心理健康中現有對話代理的系統性批判性回顧，接著深入探討了 VMHA 在脈絡知識、資料集和其在臨床決策支援中新興角色的改進。我們也提供了新的方向，以透過可解釋性、安全性與整體可信度來豐富 VMHA 的使用者體驗。最後，我們提供了評量指標和 VMHA 的實務考量，超越目前的文獻，在 VMHA 與患者的積極溝通中建立信任。

##### **A Brief Review of Explainable Artificial Intelligence in Healthcare**
2304.01543v1 by Zahra Sadeghi, Roohallah Alizadehsani, Mehmet Akif Cifci, Samina Kausar, Rizwan Rehman, Priyakshi Mahanta, Pranjal Kumar Bora, Ammar Almasri, Rami S. Alkhawaldeh, Sadiq Hussain, Bilal Alatas, Afshin Shoeibi, Hossein Moosaei, Milan Hladik, Saeid Nahavandi, Panos M. Pardalos

XAI refers to the techniques and methods for building AI applications which
assist end users to interpret output and predictions of AI models. Black box AI
applications in high-stakes decision-making situations, such as medical domain
have increased the demand for transparency and explainability since wrong
predictions may have severe consequences. Model explainability and
interpretability are vital successful deployment of AI models in healthcare
practices. AI applications' underlying reasoning needs to be transparent to
clinicians in order to gain their trust. This paper presents a systematic
review of XAI aspects and challenges in the healthcare domain. The primary
goals of this study are to review various XAI methods, their challenges, and
related machine learning models in healthcare. The methods are discussed under
six categories: Features-oriented methods, global methods, concept models,
surrogate models, local pixel-based methods, and human-centric methods. Most
importantly, the paper explores XAI role in healthcare problems to clarify its
necessity in safety-critical applications. The paper intends to establish a
comprehensive understanding of XAI-related applications in the healthcare field
by reviewing the related experimental results. To facilitate future research
for filling research gaps, the importance of XAI models from different
viewpoints and their limitations are investigated.

摘要：XAI 指的是用於建構 AI 應用程式的技術和方法，這些應用程式可協助最終使用者詮釋 AI 模型的輸出和預測。在高風險決策情境中，例如醫療領域，黑箱 AI 應用程式增加了透明度和可解釋性的需求，因為錯誤的預測可能會造成嚴重的後果。模型可解釋性和可詮釋性對於在醫療實務中成功部署 AI 模型至關重要。AI 應用程式的基本推理需要對臨床醫生透明，才能獲得他們的信任。本文提供了醫療領域中 XAI 面向和挑戰的系統性回顧。本研究的主要目標是回顧各種 XAI 方法、其挑戰，以及相關的醫療保健機器學習模型。這些方法分為六類討論：面向特徵的方法、整體方法、概念模型、代理模型、局部基於像素的方法，以及以人為中心的方法。最重要的是，本文探討了 XAI 在醫療保健問題中的角色，以釐清其在安全關鍵應用中的必要性。本文旨在透過回顧相關的實驗結果，建立對醫療保健領域中 XAI 相關應用程式的全面了解。為了促進未來研究填補研究差距，本文探討了 XAI 模型從不同觀點來看的重要性及其限制。

##### **Reveal to Revise: An Explainable AI Life Cycle for Iterative Bias Correction of Deep Models**
2303.12641v2 by Frederik Pahde, Maximilian Dreyer, Wojciech Samek, Sebastian Lapuschkin

State-of-the-art machine learning models often learn spurious correlations
embedded in the training data. This poses risks when deploying these models for
high-stake decision-making, such as in medical applications like skin cancer
detection. To tackle this problem, we propose Reveal to Revise (R2R), a
framework entailing the entire eXplainable Artificial Intelligence (XAI) life
cycle, enabling practitioners to iteratively identify, mitigate, and
(re-)evaluate spurious model behavior with a minimal amount of human
interaction. In the first step (1), R2R reveals model weaknesses by finding
outliers in attributions or through inspection of latent concepts learned by
the model. Secondly (2), the responsible artifacts are detected and spatially
localized in the input data, which is then leveraged to (3) revise the model
behavior. Concretely, we apply the methods of RRR, CDEP and ClArC for model
correction, and (4) (re-)evaluate the model's performance and remaining
sensitivity towards the artifact. Using two medical benchmark datasets for
Melanoma detection and bone age estimation, we apply our R2R framework to VGG,
ResNet and EfficientNet architectures and thereby reveal and correct real
dataset-intrinsic artifacts, as well as synthetic variants in a controlled
setting. Completing the XAI life cycle, we demonstrate multiple R2R iterations
to mitigate different biases. Code is available on
https://github.com/maxdreyer/Reveal2Revise.

摘要：最先进的机器学习模型通常会学习训练数据中嵌入的虚假关联。这在将这些模型部署于高风险决策时会带来风险，例如在皮肤癌检测等医学应用中。为了解决这个问题，我们提出了 Reveal to Revise (R2R)，一个涵盖整个可解释人工智能 (XAI) 生命周期的框架，使从业者能够以最少的人工交互迭代识别、缓解和（重新）评估虚假模型行为。在第一步 (1) 中，R2R 通过找出归因中的异常值或通过检查模型学习的潜在概念来揭示模型的弱点。其次 (2)，检测负责的伪像并在输入数据中进行空间定位，然后利用它来 (3) 修改模型行为。具体来说，我们应用 RRR、CDEP 和 ClArC 的方法来进行模型校正，并 (4)（重新）评估模型的性能和对伪像的剩余敏感性。使用两个用于黑色素瘤检测和骨龄估计的医学基准数据集，我们将我们的 R2R 框架应用于 VGG、ResNet 和 EfficientNet 架构，从而揭示和纠正了真实数据集固有的伪像，以及受控设置中的合成变体。完成 XAI 生命周期，我们演示了多个 R2R 迭代以减轻不同的偏差。代码可在 https://github.com/maxdreyer/Reveal2Revise 上找到。

##### **Explainable AI for Time Series via Virtual Inspection Layers**
2303.06365v1 by Johanna Vielhaben, Sebastian Lapuschkin, Grégoire Montavon, Wojciech Samek

The field of eXplainable Artificial Intelligence (XAI) has greatly advanced
in recent years, but progress has mainly been made in computer vision and
natural language processing. For time series, where the input is often not
interpretable, only limited research on XAI is available. In this work, we put
forward a virtual inspection layer, that transforms the time series to an
interpretable representation and allows to propagate relevance attributions to
this representation via local XAI methods like layer-wise relevance propagation
(LRP). In this way, we extend the applicability of a family of XAI methods to
domains (e.g. speech) where the input is only interpretable after a
transformation. Here, we focus on the Fourier transformation which is
prominently applied in the interpretation of time series and LRP and refer to
our method as DFT-LRP. We demonstrate the usefulness of DFT-LRP in various time
series classification settings like audio and electronic health records. We
showcase how DFT-LRP reveals differences in the classification strategies of
models trained in different domains (e.g., time vs. frequency domain) or helps
to discover how models act on spurious correlations in the data.

摘要：可解釋人工智慧 (XAI) 領域在近年來取得長足進步，但進展主要是在電腦視覺和自然語言處理方面。對於輸入通常無法解釋的時間序列，只有有限的研究可供使用 XAI。在這項工作中，我們提出了一個虛擬檢查層，它將時間序列轉換為可解釋的表示，並允許通過層級相關性傳播 (LRP) 等局部 XAI 方法將相關性歸因傳播到此表示。藉此，我們將一系列 XAI 方法的適用性擴展到輸入僅在轉換後才能解釋的領域（例如語音）。在此，我們專注於傅立葉轉換，它主要應用於時間序列和 LRP 的解釋，並將我們的稱之為 DFT-LRP。我們展示了 DFT-LRP 在各種時間序列分類設定（例如音訊和電子健康紀錄）中的效用。我們展示了 DFT-LRP 如何揭示在不同領域（例如時間與頻率域）訓練的模型的分類策略差異，或有助於發現模型如何處理資料中的虛假關聯。

##### **Towards Trust of Explainable AI in Thyroid Nodule Diagnosis**
2303.04731v1 by Truong Thanh Hung Nguyen, Van Binh Truong, Vo Thanh Khang Nguyen, Quoc Hung Cao, Quoc Khanh Nguyen

The ability to explain the prediction of deep learning models to end-users is
an important feature to leverage the power of artificial intelligence (AI) for
the medical decision-making process, which is usually considered
non-transparent and challenging to comprehend. In this paper, we apply
state-of-the-art eXplainable artificial intelligence (XAI) methods to explain
the prediction of the black-box AI models in the thyroid nodule diagnosis
application. We propose new statistic-based XAI methods, namely Kernel Density
Estimation and Density map, to explain the case of no nodule detected. XAI
methods' performances are considered under a qualitative and quantitative
comparison as feedback to improve the data quality and the model performance.
Finally, we survey to assess doctors' and patients' trust in XAI explanations
of the model's decisions on thyroid nodule images.

摘要：解釋深度學習模型預測結果的能力對最終使用者而言是一項重要功能，可利用人工智慧 (AI) 的力量進行醫療決策流程，這通常被認為是不透明且難以理解的。在本文中，我們運用最先進的可解釋人工智慧 (XAI) 方法來解釋黑盒 AI 模型在甲狀腺結節診斷應用中的預測結果。我們提出新的基於統計的 XAI 方法，即核密度估計和密度圖，來解釋未檢測到結節的情況。XAI 方法的效能會在定性和定量比較下被視為改善資料品質和模型效能的回饋。最後，我們進行調查以評估醫師和患者對 XAI 對模型在甲狀腺結節影像中決策的解釋的信任度。

##### **Cybersecurity of AI medical devices: risks, legislation, and challenges**
2303.03140v1 by Elisabetta Biasin, Erik Kamenjasevic, Kaspar Rosager Ludvigsen

Medical devices and artificial intelligence systems rapidly transform
healthcare provisions. At the same time, due to their nature, AI in or as
medical devices might get exposed to cyberattacks, leading to patient safety
and security risks. This book chapter is divided into three parts. The first
part starts by setting the scene where we explain the role of cybersecurity in
healthcare. Then, we briefly define what we refer to when we talk about AI that
is considered a medical device by itself or supports one. To illustrate the
risks such medical devices pose, we provide three examples: the poisoning of
datasets, social engineering, and data or source code extraction. In the second
part, the paper provides an overview of the European Union's regulatory
framework relevant for ensuring the cybersecurity of AI as or in medical
devices (MDR, NIS Directive, Cybersecurity Act, GDPR, the AI Act proposal and
the NIS 2 Directive proposal). Finally, the third part of the paper examines
possible challenges stemming from the EU regulatory framework. In particular,
we look toward the challenges deriving from the two legislative proposals and
their interaction with the existing legislation concerning AI medical devices'
cybersecurity. They are structured as answers to the following questions: (1)
how will the AI Act interact with the MDR regarding the cybersecurity and
safety requirements?; (2) how should we interpret incident notification
requirements from the NIS 2 Directive proposal and MDR?; and (3) what are the
consequences of the evolving term of critical infrastructures?
  [This is a draft chapter. The final version will be available in Research
Handbook on Health, AI and the Law edited by Barry Solaiman & I. Glenn Cohen,
forthcoming 2023, Edward Elgar Publishing Ltd]

摘要：醫療設備和人工智慧系統快速轉化醫療保健的提供方式。同時，由於其本質，醫療設備中或作為醫療設備的人工智慧可能會遭受網路攻擊，進而導致患者安全和安全風險。本章節分為三部分。第一部分從設定場景開始，說明網路安全在醫療保健中的角色。然後，我們簡要定義我們在談論被視為醫療設備本身或支援醫療設備的人工智慧時所指涉的內容。為了說明此類醫療設備帶來的風險，我們提供了三個範例：資料集中毒、社會工程和資料或原始碼萃取。在第二部分，本文概述了歐盟的監管架構，與確保醫療設備中或作為醫療設備的人工智慧的網路安全相關（醫療器材法規、網路與資訊安全指令、網路安全法、一般資料保護規範、人工智慧法提案和網路與資訊安全 2 指令提案）。最後，本文的第三部分探討源自歐盟監管架構的潛在挑戰。特別是，我們展望源自這兩項立法提案的挑戰，以及它們與現有關於人工智慧醫療設備網路安全的立法之間的互動。它們被架構為以下問題的解答：(1) 人工智慧法將如何與醫療器材法規互動，就網路安全和安全要求而言？(2) 我們應如何解讀網路與資訊安全 2 指令提案和醫療器材法規的事件通知要求？(3) 關鍵基礎設施演進的術語會帶來什麼後果？
[這是草稿章節。最終版本將刊載於 Barry Solaiman 和 I. Glenn Cohen 編輯的《健康、人工智慧與法律研究手冊》中，2023 年出版，Edward Elgar Publishing Ltd]

##### **LAVA: Granular Neuron-Level Explainable AI for Alzheimer's Disease Assessment from Fundus Images**
2302.03008v2 by Nooshin Yousefzadeh, Charlie Tran, Adolfo Ramirez-Zamora, Jinghua Chen, Ruogu Fang, My T. Thai

Alzheimer's Disease (AD) is a progressive neurodegenerative disease and the
leading cause of dementia. Early diagnosis is critical for patients to benefit
from potential intervention and treatment. The retina has been hypothesized as
a diagnostic site for AD detection owing to its anatomical connection with the
brain. Developed AI models for this purpose have yet to provide a rational
explanation about the decision and neither infer the stage of disease's
progression. Along this direction, we propose a novel model-agnostic
explainable-AI framework, called Granular Neuron-level Explainer (LAVA), an
interpretation prototype that probes into intermediate layers of the
Convolutional Neural Network (CNN) models to assess the AD continuum directly
from the retinal imaging without longitudinal or clinical evaluation. This
method is applied to validate the retinal vasculature as a biomarker and
diagnostic modality for Alzheimer's Disease (AD) evaluation. UK Biobank
cognitive tests and vascular morphological features suggest LAVA shows strong
promise and effectiveness in identifying AD stages across the progression
continuum.

摘要：阿茲海默症 (AD) 是一種進行性的神經退化性疾病，也是導致失智症的主因。早期診斷對於患者接受潛在干預和治療至關重要。由於視網膜與大腦有解剖學上的連結，因此假設視網膜可以作為 AD 檢測的診斷部位。為此目的而開發的 AI 模型，尚未對決策提供合理的解釋，也無法推論疾病進展的階段。沿著這個方向，我們提出了一個新穎的模型不可知論可解釋 AI 架構，稱為顆粒神經元級別解釋器 (LAVA)，這是一個解釋原型，可以探測卷積神經網路 (CNN) 模型的中間層，以直接從視網膜影像評估 AD 連續體，而無需縱向或臨床評估。此方法用於驗證視網膜血管作為生物標記和阿茲海默症 (AD) 評估的診斷方式。英國生物資料庫的認知測試和血管形態特徵表明，LAVA 在識別進展連續體中的 AD 階段方面顯示出強大的前景和有效性。

##### **Diagrammatization: Rationalizing with diagrammatic AI explanations for abductive-deductive reasoning on hypotheses**
2302.01241v2 by Brian Y. Lim, Joseph P. Cahaly, Chester Y. F. Sng, Adam Chew

Many visualizations have been developed for explainable AI (XAI), but they
often require further reasoning by users to interpret. We argue that XAI should
support diagrammatic and abductive reasoning for the AI to perform hypothesis
generation and evaluation to reduce the interpretability gap. We propose
Diagrammatization to i) perform Peircean abductive-deductive reasoning, ii)
follow domain conventions, and iii) explain with diagrams visually or verbally.
We implemented DiagramNet for a clinical application to predict cardiac
diagnoses from heart auscultation, and explain with shape-based murmur
diagrams. In modeling studies, we found that DiagramNet not only provides
faithful murmur shape explanations, but also has better prediction performance
than baseline models. We further demonstrate the interpretability and
trustworthiness of diagrammatic explanations in a qualitative user study with
medical students, showing that clinically-relevant, diagrammatic explanations
are preferred over technical saliency map explanations. This work contributes
insights into providing domain-conventional abductive explanations for
user-centric XAI.

摘要：許多視覺化已被開發用於可解釋的 AI (XAI)，但它們通常需要使用者進一步推理才能解讀。我們主張 XAI 應支援圖解和演繹推理，讓 AI 執行假設產生和評估以縮小可解釋性差距。我們提出圖解化以 i) 執行皮爾士演繹-演繹推理，ii) 遵循領域慣例，以及 iii) 以視覺或口語方式說明圖表。我們實作了 DiagramNet 進行臨床應用，以從心臟聽診預測心臟診斷，並以形狀為基礎的雜音圖說明。在建模研究中，我們發現 DiagramNet 不僅提供了忠實的雜音形狀說明，而且比基準模型具有更好的預測效能。我們進一步在與醫學生的質性使用者研究中展示了圖解說明的可解釋性和可信度，顯示出以臨床相關的圖解說明優於技術顯著性圖說明。這項工作有助於提供以使用者為中心的 XAI 的領域慣例演繹說明。

##### **LesionAid: Vision Transformers-based Skin Lesion Generation and Classification**
2302.01104v1 by Ghanta Sai Krishna, Kundrapu Supriya, Mallikharjuna Rao K, Meetiksha Sorgile

Skin cancer is one of the most prevalent forms of human cancer. It is
recognized mainly visually, beginning with clinical screening and continuing
with the dermoscopic examination, histological assessment, and specimen
collection. Deep convolutional neural networks (CNNs) perform highly segregated
and potentially universal tasks against a classified finegrained object. This
research proposes a novel multi-class prediction framework that classifies skin
lesions based on ViT and ViTGAN. Vision transformers-based GANs (Generative
Adversarial Networks) are utilized to tackle the class imbalance. The framework
consists of four main phases: ViTGANs, Image processing, and explainable AI.
Phase 1 consists of generating synthetic images to balance all the classes in
the dataset. Phase 2 consists of applying different data augmentation
techniques and morphological operations to increase the size of the data.
Phases 3 & 4 involve developing a ViT model for edge computing systems that can
identify patterns and categorize skin lesions from the user's skin visible in
the image. In phase 3, after classifying the lesions into the desired class
with ViT, we will use explainable AI (XAI) that leads to more explainable
results (using activation maps, etc.) while ensuring high predictive accuracy.
Real-time images of skin diseases can capture by a doctor or a patient using
the camera of a mobile application to perform an early examination and
determine the cause of the skin lesion. The whole framework is compared with
the existing frameworks for skin lesion detection.

摘要：皮膚癌是人類最普遍的癌症類型之一。它的識別主要依賴視覺，從臨床篩檢開始，接著是皮膚鏡檢查、組織學評估，以及檢體收集。深度卷積神經網路 (CNN) 可針對分類的細粒度物件執行高度區隔且潛在通用的任務。本研究提出一個新穎的多類別預測架構，它以 ViT 和 ViTGAN 為基礎對皮膚病灶進行分類。基於視覺轉換器的 GAN（生成對抗網路）用於解決類別不平衡問題。此架構包含四個主要階段：ViTGAN、影像處理和可解釋 AI。第一階段包括產生合成影像，以平衡資料集中的所有類別。第二階段包括應用不同的資料擴充技術和形態運算，以增加資料大小。第三和第四階段涉及開發適用於邊緣運算系統的 ViT 模型，該模型可以識別圖案，並對影像中用戶皮膚可見的皮膚病灶進行分類。在第三階段，在使用 ViT 將病灶分類到所需的類別後，我們將使用可解釋 AI (XAI)，它會產生更具可解釋性的結果（使用啟用圖等），同時確保高預測準確度。皮膚疾病的即時影像可以用行動應用程式的相機由醫生或患者擷取，以執行早期檢查並確定皮膚病灶的原因。整個架構與現有的皮膚病灶偵測架構進行比較。

##### **SkinCon: A skin disease dataset densely annotated by domain experts for fine-grained model debugging and analysis**
2302.00785v1 by Roxana Daneshjou, Mert Yuksekgonul, Zhuo Ran Cai, Roberto Novoa, James Zou

For the deployment of artificial intelligence (AI) in high-risk settings,
such as healthcare, methods that provide interpretability/explainability or
allow fine-grained error analysis are critical. Many recent methods for
interpretability/explainability and fine-grained error analysis use concepts,
which are meta-labels that are semantically meaningful to humans. However,
there are only a few datasets that include concept-level meta-labels and most
of these meta-labels are relevant for natural images that do not require domain
expertise. Densely annotated datasets in medicine focused on meta-labels that
are relevant to a single disease such as melanoma. In dermatology, skin disease
is described using an established clinical lexicon that allows clinicians to
describe physical exam findings to one another. To provide a medical dataset
densely annotated by domain experts with annotations useful across multiple
disease processes, we developed SkinCon: a skin disease dataset densely
annotated by dermatologists. SkinCon includes 3230 images from the Fitzpatrick
17k dataset densely annotated with 48 clinical concepts, 22 of which have at
least 50 images representing the concept. The concepts used were chosen by two
dermatologists considering the clinical descriptor terms used to describe skin
lesions. Examples include "plaque", "scale", and "erosion". The same concepts
were also used to label 656 skin disease images from the Diverse Dermatology
Images dataset, providing an additional external dataset with diverse skin tone
representations. We review the potential applications for the SkinCon dataset,
such as probing models, concept-based explanations, and concept bottlenecks.
Furthermore, we use SkinCon to demonstrate two of these use cases: debugging
mistakes of an existing dermatology AI model with concepts and developing
interpretable models with post-hoc concept bottleneck models.

摘要：<paragraph>在高風險環境中部署人工智慧 (AI)（例如醫療保健），提供可解釋性/可說明性的方法或允許精細錯誤分析非常重要。許多近期用於可解釋性/可說明性和精細錯誤分析的方法都使用概念，這些概念是對人類具有語義意義的元標籤。然而，只有少數資料集包含概念層級的元標籤，而且這些元標籤大多與不需要領域專業知識的自然影像相關。專注於單一疾病（例如黑色素瘤）的元標籤的醫學密集標記資料集。在皮膚科中，皮膚疾病的描述使用既定的臨床詞彙，讓臨床醫生可以彼此描述身體檢查結果。為了提供由領域專家密集標記的醫學資料集，其中包含可跨多種疾病過程使用的標記，我們開發了 SkinCon：由皮膚科醫師密集標記的皮膚疾病資料集。SkinCon 包含來自 Fitzpatrick 17k 資料集的 3230 張影像，密集標記了 48 個臨床概念，其中 22 個概念至少有 50 張影像代表該概念。所使用的概念是由兩位皮膚科醫師在考量用於描述皮膚病變的臨床描述詞彙後選出的。範例包括「斑塊」、「鱗屑」和「糜爛」。相同的概念也用於標記來自 Diverse Dermatology Images 資料集的 656 張皮膚疾病影像，提供具有多樣膚色表示的額外外部資料集。我們檢視 SkinCon 資料集的潛在應用，例如探測模型、基於概念的說明和概念瓶頸。此外，我們使用 SkinCon 來展示這兩個使用案例：使用概念除錯現有皮膚科 AI 模型的錯誤，以及使用事後概念瓶頸模型開發可解釋的模型。</paragraph>

##### **Decision-Focused Evaluation: Analyzing Performance of Deployed Restless Multi-Arm Bandits**
2301.07835v1 by Paritosh Verma, Shresth Verma, Aditya Mate, Aparna Taneja, Milind Tambe

Restless multi-arm bandits (RMABs) is a popular decision-theoretic framework
that has been used to model real-world sequential decision making problems in
public health, wildlife conservation, communication systems, and beyond.
Deployed RMAB systems typically operate in two stages: the first predicts the
unknown parameters defining the RMAB instance, and the second employs an
optimization algorithm to solve the constructed RMAB instance.
  In this work we provide and analyze the results from a first-of-its-kind
deployment of an RMAB system in public health domain, aimed at improving
maternal and child health. Our analysis is focused towards understanding the
relationship between prediction accuracy and overall performance of deployed
RMAB systems. This is crucial for determining the value of investing in
improving predictive accuracy towards improving the final system performance,
and is useful for diagnosing, monitoring deployed RMAB systems.
  Using real-world data from our deployed RMAB system, we demonstrate that an
improvement in overall prediction accuracy may even be accompanied by a
degradation in the performance of RMAB system -- a broad investment of
resources to improve overall prediction accuracy may not yield expected
results. Following this, we develop decision-focused evaluation metrics to
evaluate the predictive component and show that it is better at explaining
(both empirically and theoretically) the overall performance of a deployed RMAB
system.

摘要：不安分的多臂強盜 (RMAB) 是一個流行的決策理論架構，已被用於模擬公共衛生、野生動物保育、通訊系統等領域的真實世界順序決策問題。已部署的 RMAB 系統通常分兩個階段運作：第一個階段預測定義 RMAB 執行個體的未知參數，第二個階段採用最佳化演算法來解決已建構的 RMAB 執行個體。
在本研究中，我們提供並分析了在公共衛生領域中首次部署 RMAB 系統的結果，目標是改善孕產婦和兒童健康。我們的分析著重於了解預測準確度與已部署 RMAB 系統的整體效能之間的關係。這對於決定投資於改善預測準確度以提升最終系統效能的價值至關重要，並且有助於診斷、監控已部署的 RMAB 系統。
使用我們已部署 RMAB 系統中的真實世界資料，我們證明了整體預測準確度的提升甚至可能伴隨著 RMAB 系統效能的下降——廣泛投入資源以改善整體預測準確度可能無法產生預期的結果。在此之後，我們開發了以決策為重點的評估指標來評估預測元件，並證明它更能解釋已部署 RMAB 系統的整體效能（無論是經驗上或理論上）。

##### **Exemplars and Counterexemplars Explanations for Image Classifiers, Targeting Skin Lesion Labeling**
2302.03033v1 by Carlo Metta, Riccardo Guidotti, Yuan Yin, Patrick Gallinari, Salvatore Rinzivillo

Explainable AI consists in developing mechanisms allowing for an interaction
between decision systems and humans by making the decisions of the formers
understandable. This is particularly important in sensitive contexts like in
the medical domain. We propose a use case study, for skin lesion diagnosis,
illustrating how it is possible to provide the practitioner with explanations
on the decisions of a state of the art deep neural network classifier trained
to characterize skin lesions from examples. Our framework consists of a trained
classifier onto which an explanation module operates. The latter is able to
offer the practitioner exemplars and counterexemplars for the classification
diagnosis thus allowing the physician to interact with the automatic diagnosis
system. The exemplars are generated via an adversarial autoencoder. We
illustrate the behavior of the system on representative examples.

摘要：可解釋 AI 是在開發機制，讓決策系統與人類之間能互動，並讓前者的決策變得可以理解。這在敏感的脈絡中特別重要，例如在醫療領域。我們提出一個使用案例研究，用於皮膚病變診斷，說明如何讓執業醫師了解最先進的深度神經網路分類器在決策上的解釋，該分類器經過訓練，可以從範例中描述皮膚病變。我們的架構包含一個訓練過的分類器，解釋模組會在該分類器上運作。後者能夠為分類診斷提供執業醫師範例和反例，因此讓醫師可以與自動診斷系統互動。範例是透過對抗式自動編碼器產生的。我們說明系統在代表性範例上的行為。


### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-11**|**Cloud Atlas: Efficient Fault Localization for Cloud Systems using Language Models and Causal Insight**|Zhiqiang Xie et.al.|[2407.08694v1](http://arxiv.org/abs/2407.08694v1)|null|
|**2024-07-11**|**Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents**|Haoyi Xiong et.al.|[2407.08516v1](http://arxiv.org/abs/2407.08516v1)|null|
|**2024-07-10**|**A Comprehensive Survey on the Security of Smart Grid: Challenges, Mitigations, and Future Research Opportunities**|Arastoo Zibaeirad et.al.|[2407.07966v1](http://arxiv.org/abs/2407.07966v1)|null|
|**2024-07-10**|**Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs**|Hao-Tien Lewis Chiang et.al.|[2407.07775v1](http://arxiv.org/abs/2407.07775v1)|null|
|**2024-07-10**|**Teaching Transformers Causal Reasoning through Axiomatic Training**|Aniket Vashishtha et.al.|[2407.07612v1](http://arxiv.org/abs/2407.07612v1)|null|
|**2024-07-10**|**GLBench: A Comprehensive Benchmark for Graph with Large Language Models**|Yuhan Li et.al.|[2407.07457v2](http://arxiv.org/abs/2407.07457v2)|[link](https://github.com/nineabyss/glbench)|
|**2024-07-09**|**Decoding Climate Disagreement: A Graph Neural Network-Based Approach to Understanding Social Media Dynamics**|Ruiran Su et.al.|[2407.07038v1](http://arxiv.org/abs/2407.07038v1)|null|
|**2024-07-09**|**Graph-Based Captioning: Enhancing Visual Descriptions by Interconnecting Region Captions**|Yu-Guan Hsieh et.al.|[2407.06723v1](http://arxiv.org/abs/2407.06723v1)|null|
|**2024-07-09**|**Combining Knowledge Graphs and Large Language Models**|Amanda Kau et.al.|[2407.06564v1](http://arxiv.org/abs/2407.06564v1)|null|
|**2024-07-08**|**MST5 -- Multilingual Question Answering over Knowledge Graphs**|Nikit Srivastava et.al.|[2407.06041v1](http://arxiv.org/abs/2407.06041v1)|[link](https://github.com/dice-group/MST5)|
|**2024-07-08**|**Enhancing Vision-Language Models with Scene Graphs for Traffic Accident Understanding**|Aaron Lohner et.al.|[2407.05910v1](http://arxiv.org/abs/2407.05910v1)|null|
|**2024-07-08**|**Affordances-Oriented Planning using Foundation Models for Continuous Vision-Language Navigation**|Jiaqi Chen et.al.|[2407.05890v1](http://arxiv.org/abs/2407.05890v1)|null|
|**2024-07-08**|**KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions**|Yanxu Zhu et.al.|[2407.05868v1](http://arxiv.org/abs/2407.05868v1)|[link](https://github.com/yanxuzhu/kg-fpq)|
|**2024-07-07**|**Language Models Encode Collaborative Signals in Recommendation**|Leheng Sheng et.al.|[2407.05441v1](http://arxiv.org/abs/2407.05441v1)|[link](https://github.com/lehengthu/alpharec)|
|**2024-07-07**|**LTLBench: Towards Benchmarks for Evaluating Temporal Logic Reasoning in Large Language Models**|Weizhi Tang et.al.|[2407.05434v1](http://arxiv.org/abs/2407.05434v1)|[link](https://github.com/rutatang/ltlbench)|
|**2024-07-05**|**Leveraging Graph Structures to Detect Hallucinations in Large Language Models**|Noa Nonkes et.al.|[2407.04485v1](http://arxiv.org/abs/2407.04485v1)|[link](https://github.com/noanonkes/Hallucination-Detection-in-LLMs)|
|**2024-07-05**|**AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents**|Petr Anokhin et.al.|[2407.04363v1](http://arxiv.org/abs/2407.04363v1)|[link](https://github.com/airi-institute/arigraph)|
|**2024-07-04**|**Semantic Graphs for Syntactic Simplification: A Revisit from the Age of LLM**|Peiran Yao et.al.|[2407.04067v1](http://arxiv.org/abs/2407.04067v1)|[link](https://github.com/U-Alberta/AMRS3)|
|**2024-07-04**|**Functional Faithfulness in the Wild: Circuit Discovery with Differentiable Computation Graph Pruning**|Lei Yu et.al.|[2407.03779v1](http://arxiv.org/abs/2407.03779v1)|null|
|**2024-07-03**|**BACON: Supercharge Your VLM with Bag-of-Concept Graph to Mitigate Hallucinations**|Zhantao Yang et.al.|[2407.03314v1](http://arxiv.org/abs/2407.03314v1)|null|
|**2024-07-03**|**GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models**|Zike Yuan et.al.|[2407.02936v1](http://arxiv.org/abs/2407.02936v1)|[link](https://github.com/zikeyuan/gracore)|
|**2024-07-03**|**Croppable Knowledge Graph Embedding**|Yushan Zhu et.al.|[2407.02779v1](http://arxiv.org/abs/2407.02779v1)|null|
|**2024-07-02**|**Reasoning in Large Language Models: A Geometric Perspective**|Romain Cosentino et.al.|[2407.02678v1](http://arxiv.org/abs/2407.02678v1)|null|
|**2024-07-02**|**Ensuring Responsible Sourcing of Large Language Model Training Data Through Knowledge Graph Comparison**|Devam Mondal et.al.|[2407.02659v1](http://arxiv.org/abs/2407.02659v1)|null|
|**2024-07-02**|**Multi-Peptide: Multimodality Leveraged Language-Graph Learning of Peptide Properties**|Srivathsan Badrinarayanan et.al.|[2407.03380v1](http://arxiv.org/abs/2407.03380v1)|[link](https://github.com/srivathsanb14/multipeptide)|
|**2024-07-02**|**Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification**|Pritish Sahu et.al.|[2407.02352v1](http://arxiv.org/abs/2407.02352v1)|null|
|**2024-07-02**|**Is Your Large Language Model Knowledgeable or a Choices-Only Cheater?**|Nishant Balepur et.al.|[2407.01992v1](http://arxiv.org/abs/2407.01992v1)|null|
|**2024-07-01**|**CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents**|Tianqi Xu et.al.|[2407.01511v1](http://arxiv.org/abs/2407.01511v1)|[link](https://github.com/camel-ai/crab)|
|**2024-07-01**|**Dynamic Few-Shot Learning for Knowledge Graph Question Answering**|Jacopo D'Abramo et.al.|[2407.01409v1](http://arxiv.org/abs/2407.01409v1)|null|
|**2024-07-01**|**Adapting Multilingual LLMs to Low-Resource Languages with Knowledge Graphs via Adapters**|Daniil Gurgurov et.al.|[2407.01406v1](http://arxiv.org/abs/2407.01406v1)|[link](https://github.com/d-gurgurov/Injecting-Commonsense-Knowledge-into-LLMs)|
|**2024-07-01**|**SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model**|Lingyue Fu et.al.|[2407.01245v1](http://arxiv.org/abs/2407.01245v1)|null|
|**2024-07-01**|**Revisiting Random Walks for Learning on Graphs**|Jinwoo Kim et.al.|[2407.01214v1](http://arxiv.org/abs/2407.01214v1)|[link](https://github.com/jw9730/random-walk)|
|**2024-07-01**|**LLM Uncertainty Quantification through Directional Entailment Graph and Claim Level Response Augmentation**|Longchao Da et.al.|[2407.00994v2](http://arxiv.org/abs/2407.00994v2)|null|
|**2024-06-30**|**Actionable Cyber Threat Intelligence using Knowledge Graphs and Large Language Models**|Romy Fieblinger et.al.|[2407.02528v1](http://arxiv.org/abs/2407.02528v1)|null|
|**2024-06-30**|**Chain-of-Knowledge: Integrating Knowledge Reasoning into Large Language Models by Learning from Knowledge Graphs**|Yifei Zhang et.al.|[2407.00653v1](http://arxiv.org/abs/2407.00653v1)|null|
|**2024-06-29**|**BioKGBench: A Knowledge Graph Checking Benchmark of AI Agent for Biomedical Science**|Xinna Lin et.al.|[2407.00466v1](http://arxiv.org/abs/2407.00466v1)|[link](https://github.com/westlake-autolab/biokgbench.github.io)|
|**2024-06-29**|**GraphArena: Benchmarking Large Language Models on Graph Computational Problems**|Jianheng Tang et.al.|[2407.00379v1](http://arxiv.org/abs/2407.00379v1)|[link](https://github.com/squareroot3/grapharena)|
|**2024-06-29**|**Teola: Towards End-to-End Optimization of LLM-based Applications**|Xin Tan et.al.|[2407.00326v1](http://arxiv.org/abs/2407.00326v1)|null|
|**2024-06-28**|**Into the Unknown: Generating Geospatial Descriptions for New Environments**|Tzuf Paz-Argaman et.al.|[2406.19967v1](http://arxiv.org/abs/2406.19967v1)|null|
|**2024-06-27**|**Investigating How Large Language Models Leverage Internal Knowledge to Perform Complex Reasoning**|Miyoung Ko et.al.|[2406.19502v1](http://arxiv.org/abs/2406.19502v1)|[link](https://github.com/kaistai/knowledge-reasoning)|
|**2024-06-27**|**Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment**|Hao Fei et.al.|[2406.19255v1](http://arxiv.org/abs/2406.19255v1)|null|
|**2024-06-27**|**TrustUQA: A Trustful Framework for Unified Structured Data Question Answering**|Wen Zhang et.al.|[2406.18916v1](http://arxiv.org/abs/2406.18916v1)|null|
|**2024-06-26**|**Fast Optimizer Benchmark**|Simon Blauth et.al.|[2406.18701v1](http://arxiv.org/abs/2406.18701v1)|[link](https://github.com/automl/fob)|
|**2024-06-26**|**Cascading Large Language Models for Salient Event Graph Generation**|Xingwei Tan et.al.|[2406.18449v1](http://arxiv.org/abs/2406.18449v1)|[link](https://github.com/xingwei-warwick/callmsae)|
|**2024-06-26**|**Sanskrit Knowledge-based Systems: Annotation and Computational Tools**|Hrishikesh Terdalkar et.al.|[2406.18276v1](http://arxiv.org/abs/2406.18276v1)|null|
|**2024-06-26**|**Multilingual Knowledge Graph Completion from Pretrained Language Models with Knowledge Constraints**|Ran Song et.al.|[2406.18085v1](http://arxiv.org/abs/2406.18085v1)|[link](https://github.com/Maxpa1n/gcplm-kgc)|
|**2024-06-26**|**AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning**|Yifan Yang et.al.|[2406.18060v1](http://arxiv.org/abs/2406.18060v1)|[link](https://github.com/yifanycc/adazeta)|
|**2024-06-25**|**DARG: Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph**|Zhehao Zhang et.al.|[2406.17271v1](http://arxiv.org/abs/2406.17271v1)|[link](https://github.com/salt-nlp/darg)|
|**2024-06-25**|**CogMG: Collaborative Augmentation Between Large Language Model and Knowledge Graph**|Tong Zhou et.al.|[2406.17231v1](http://arxiv.org/abs/2406.17231v1)|[link](https://github.com/tongzhou21/CogMG)|
|**2024-06-24**|**Link Prediction with Untrained Message Passing Layers**|Lisi Qarkaxhija et.al.|[2406.16687v1](http://arxiv.org/abs/2406.16687v1)|null|
|**2024-06-24**|**CLEAR: Can Language Models Really Understand Causal Graphs?**|Sirui Chen et.al.|[2406.16605v1](http://arxiv.org/abs/2406.16605v1)|[link](https://github.com/opencausalab/clear)|
|**2024-06-24**|**KEHRL: Learning Knowledge-Enhanced Language Representations with Hierarchical Reinforcement Learning**|Dongyang Li et.al.|[2406.16374v1](http://arxiv.org/abs/2406.16374v1)|[link](https://github.com/MatNLP/KEHRL)|
|**2024-06-24**|**Prompt-Consistency Image Generation (PCIG): A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models**|Yichen Sun et.al.|[2406.16333v1](http://arxiv.org/abs/2406.16333v1)|null|
|**2024-06-24**|**Graph-Augmented LLMs for Personalized Health Insights: A Case Study in Sleep Analysis**|Ajan Subramanian et.al.|[2406.16252v2](http://arxiv.org/abs/2406.16252v2)|null|
|**2024-06-23**|**GraphEval2000: Benchmarking and Improving Large Language Models on Graph Datasets**|Qiming Wu et.al.|[2406.16176v1](http://arxiv.org/abs/2406.16176v1)|null|
|**2024-06-23**|**Can LLM Graph Reasoning Generalize beyond Pattern Memorization?**|Yizhuo Zhang et.al.|[2406.15992v1](http://arxiv.org/abs/2406.15992v1)|null|
|**2024-06-22**|**LLM-Powered Explanations: Unraveling Recommendations Through Subgraph Reasoning**|Guangsi Shi et.al.|[2406.15859v2](http://arxiv.org/abs/2406.15859v2)|null|
|**2024-06-22**|**Large Language Models for Link Stealing Attacks Against Graph Neural Networks**|Faqian Guan et.al.|[2406.16963v1](http://arxiv.org/abs/2406.16963v1)|null|
|**2024-06-21**|**Inferring Pluggable Types with Machine Learning**|Kazi Amanul Islam Siddiqui et.al.|[2406.15676v1](http://arxiv.org/abs/2406.15676v1)|null|
|**2024-06-21**|**NLP-KG: A System for Exploratory Search of Scientific Literature in Natural Language Processing**|Tim Schopf et.al.|[2406.15294v2](http://arxiv.org/abs/2406.15294v2)|[link](https://github.com/nlp-knowledge-graph/nlp-kg-webapp)|
|**2024-06-21**|**Unsupervised Extraction of Dialogue Policies from Conversations**|Makesh Narsimhan Sreedhar et.al.|[2406.15214v1](http://arxiv.org/abs/2406.15214v1)|null|
|**2024-06-21**|**Uni-Mol2: Exploring Molecular Pretraining Model at Scale**|Xiaohong Ji et.al.|[2406.14969v2](http://arxiv.org/abs/2406.14969v2)|null|
|**2024-06-20**|**Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks**|Sefika Efeoglu et.al.|[2406.14745v2](http://arxiv.org/abs/2406.14745v2)|null|
|**2024-06-20**|**Do LLMs Have Distinct and Consistent Personality? TRAIT: Personality Testset designed for LLMs with Psychometrics**|Seungbeen Lee et.al.|[2406.14703v1](http://arxiv.org/abs/2406.14703v1)|null|
|**2024-06-20**|**TAGLAS: An atlas of text-attributed graph datasets in the era of large graph and language models**|Jiarui Feng et.al.|[2406.14683v1](http://arxiv.org/abs/2406.14683v1)|[link](https://github.com/jiaruifeng/taglas)|
|**2024-06-20**|**HYPERmotion: Learning Hybrid Behavior Planning for Autonomous Loco-manipulation**|Jin Wang et.al.|[2406.14655v1](http://arxiv.org/abs/2406.14655v1)|null|
|**2024-06-20**|**GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models**|Shilong Li et.al.|[2406.14550v1](http://arxiv.org/abs/2406.14550v1)|null|
|**2024-06-20**|**medIKAL: Integrating Knowledge Graphs as Assistants of LLMs for Enhanced Clinical Diagnosis on EMRs**|Mingyi Jia et.al.|[2406.14326v1](http://arxiv.org/abs/2406.14326v1)|null|
|**2024-06-20**|**Learning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs**|Junjie Wang et.al.|[2406.14282v1](http://arxiv.org/abs/2406.14282v1)|[link](https://github.com/zjukg/lpkg)|
|**2024-06-20**|**ReaLHF: Optimized RLHF Training for Large Language Models through Parameter Reallocation**|Zhiyu Mei et.al.|[2406.14088v1](http://arxiv.org/abs/2406.14088v1)|[link](https://github.com/openpsi-project/realhf)|
|**2024-06-20**|**HIGHT: Hierarchical Graph Tokenization for Graph-Language Alignment**|Yongqiang Chen et.al.|[2406.14021v1](http://arxiv.org/abs/2406.14021v1)|null|
|**2024-06-19**|**A Pure Transformer Pretraining Framework on Text-attributed Graphs**|Yu Song et.al.|[2406.13873v1](http://arxiv.org/abs/2406.13873v1)|[link](https://github.com/songyyyy/gspt)|
|**2024-06-19**|**Knowledge Graph-Enhanced Large Language Models via Path Selection**|Haochen Liu et.al.|[2406.13862v1](http://arxiv.org/abs/2406.13862v1)|[link](https://github.com/haochenliu2000/kelp)|
|**2024-06-19**|**Few-shot Knowledge Graph Relational Reasoning via Subgraph Adaptation**|Haochen Liu et.al.|[2406.15507v1](http://arxiv.org/abs/2406.15507v1)|[link](https://github.com/HaochenLiu2000/SAFER)|
|**2024-06-19**|**Dr.E Bridges Graphs with Large Language Models through Words**|Zipeng Liu et.al.|[2406.15504v1](http://arxiv.org/abs/2406.15504v1)|null|
|**2024-06-19**|**Enhancing Distractor Generation for Multiple-Choice Questions with Retrieval Augmented Pretraining and Knowledge Graph Integration**|Han-Cheng Yu et.al.|[2406.13578v1](http://arxiv.org/abs/2406.13578v1)|null|
|**2024-06-19**|**LangTopo: Aligning Language Descriptions of Graphs with Tokenized Topological Modeling**|Zhong Guan et.al.|[2406.13250v1](http://arxiv.org/abs/2406.13250v1)|null|
|**2024-06-19**|**Enhancing Collaborative Semantics of Language Model-Driven Recommendations via Graph-Aware Learning**|Zhong Guan et.al.|[2406.13235v1](http://arxiv.org/abs/2406.13235v1)|null|
|**2024-06-19**|**Bridging Law and Data: Augmenting Reasoning via a Semi-Structured Dataset with IRAC methodology**|Xiaoxi Kang et.al.|[2406.13217v1](http://arxiv.org/abs/2406.13217v1)|null|
|**2024-06-19**|**PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes**|He Cao et.al.|[2406.13193v1](http://arxiv.org/abs/2406.13193v1)|[link](https://github.com/idea-xl/presto)|
|**2024-06-19**|**QRMeM: Unleash the Length Limitation through Question then Reflection Memory Mechanism**|Bo Wang et.al.|[2406.13167v1](http://arxiv.org/abs/2406.13167v1)|null|
|**2024-06-18**|**Bridging Local Details and Global Context in Text-Attributed Graphs**|Yaoke Wang et.al.|[2406.12608v1](http://arxiv.org/abs/2406.12608v1)|null|
|**2024-06-18**|**MolecularGPT: Open Large Language Model (LLM) for Few-Shot Molecular Property Prediction**|Yuyan Liu et.al.|[2406.12950v1](http://arxiv.org/abs/2406.12950v1)|[link](https://github.com/nyushcs/moleculargpt)|
|**2024-06-18**|**LightPAL: Lightweight Passage Retrieval for Open Domain Multi-Document Summarization**|Masafumi Enomoto et.al.|[2406.12494v1](http://arxiv.org/abs/2406.12494v1)|null|
|**2024-06-18**|**Interpretable Catastrophic Forgetting of Large Language Model Fine-tuning via Instruction Vector**|Gangwei Jiang et.al.|[2406.12227v2](http://arxiv.org/abs/2406.12227v2)|null|
|**2024-06-17**|**DTGB: A Comprehensive Benchmark for Dynamic Text-Attributed Graphs**|Jiasheng Zhang et.al.|[2406.12072v2](http://arxiv.org/abs/2406.12072v2)|[link](https://github.com/zjs123/DTGB)|
|**2024-06-17**|**UniGLM: Training One Unified Language Model for Text-Attributed Graphs**|Yi Fang et.al.|[2406.12052v1](http://arxiv.org/abs/2406.12052v1)|[link](https://github.com/nyushcs/uniglm)|
|**2024-06-17**|**GAugLLM: Improving Graph Contrastive Learning for Text-Attributed Graphs with Large Language Models**|Yi Fang et.al.|[2406.11945v1](http://arxiv.org/abs/2406.11945v1)|[link](https://github.com/nyushcs/gaugllm)|
|**2024-06-17**|**Input Conditioned Graph Generation for Language Agents**|Lukas Vierling et.al.|[2406.11555v1](http://arxiv.org/abs/2406.11555v1)|[link](https://github.com/lukasvierling/dynamicgptswarm)|
|**2024-06-17**|**Large Language Models and Knowledge Graphs for Astronomical Entity Disambiguation**|Golnaz Shapurian et.al.|[2406.11400v1](http://arxiv.org/abs/2406.11400v1)|null|
|**2024-06-17**|**How Good are LLMs at Relation Extraction under Low-Resource Scenario? Comprehensive Evaluation**|Dawulie Jinensibieke et.al.|[2406.11162v2](http://arxiv.org/abs/2406.11162v2)|[link](https://github.com/victor812-hub/entity_datasets)|
|**2024-06-17**|**Context Graph**|Chengjin Xu et.al.|[2406.11160v3](http://arxiv.org/abs/2406.11160v3)|null|
|**2024-06-17**|**Are Large Language Models a Good Replacement of Taxonomies?**|Yushi Sun et.al.|[2406.11131v2](http://arxiv.org/abs/2406.11131v2)|[link](https://github.com/ysunbp/taxoglimpse)|
|**2024-06-16**|**DocNet: Semantic Structure in Inductive Bias Detection Models**|Jessica Zhu et.al.|[2406.10965v1](http://arxiv.org/abs/2406.10965v1)|[link](https://github.com/nlpresearchanon/DocNet)|
|**2024-06-16**|**Light Up the Shadows: Enhance Long-Tailed Entity Grounding with Concept-Guided Vision-Language Models**|Yikai Zhang et.al.|[2406.10902v1](http://arxiv.org/abs/2406.10902v1)|[link](https://github.com/ykzhang721/COG)|
|**2024-06-16**|**KGPA: Robustness Evaluation for Large Language Models via Cross-Domain Knowledge Graphs**|Aihua Pei et.al.|[2406.10802v1](http://arxiv.org/abs/2406.10802v1)|[link](https://github.com/aika-wsd/KGPA)|
|**2024-06-15**|**A Comprehensive Survey of Foundation Models in Medicine**|Wasif Khan et.al.|[2406.10729v1](http://arxiv.org/abs/2406.10729v1)|null|
|**2024-06-15**|**SyntheT2C: Generating Synthetic Data for Fine-Tuning Large Language Models on the Text2Cypher Task**|Ziije Zhong et.al.|[2406.10710v1](http://arxiv.org/abs/2406.10710v1)|null|
|**2024-06-15**|**Large Language Models as Event Forecasters**|Libo Zhang et.al.|[2406.10492v1](http://arxiv.org/abs/2406.10492v1)|null|
|**2024-06-15**|**Unlocking Large Language Model's Planning Capabilities with Maximum Diversity Fine-tuning**|Wenjun Li et.al.|[2406.10479v1](http://arxiv.org/abs/2406.10479v1)|null|

#### Abstracts
##### **Cloud Atlas: Efficient Fault Localization for Cloud Systems using Language Models and Causal Insight**
2407.08694v1 by Zhiqiang Xie, Yujia Zheng, Lizi Ottens, Kun Zhang, Christos Kozyrakis, Jonathan Mace

Runtime failure and performance degradation is commonplace in modern cloud
systems. For cloud providers, automatically determining the root cause of
incidents is paramount to ensuring high reliability and availability as prompt
fault localization can enable faster diagnosis and triage for timely
resolution. A compelling solution explored in recent work is causal reasoning
using causal graphs to capture relationships between varied cloud system
performance metrics. To be effective, however, systems developers must
correctly define the causal graph of their system, which is a time-consuming,
brittle, and challenging task that increases in difficulty for large and
dynamic systems and requires domain expertise. Alternatively, automated
data-driven approaches have limited efficacy for cloud systems due to the
inherent rarity of incidents. In this work, we present Atlas, a novel approach
to automatically synthesizing causal graphs for cloud systems. Atlas leverages
large language models (LLMs) to generate causal graphs using system
documentation, telemetry, and deployment feedback. Atlas is complementary to
data-driven causal discovery techniques, and we further enhance Atlas with a
data-driven validation step. We evaluate Atlas across a range of fault
localization scenarios and demonstrate that Atlas is capable of generating
causal graphs in a scalable and generalizable manner, with performance that far
surpasses that of data-driven algorithms and is commensurate to the
ground-truth baseline.

摘要：在現代雲端系統中，執行時期故障和效能降低是司空見慣的事。對於雲端供應商而言，自動找出事件的根本原因對於確保高可靠性和可用性至關重要，因為及時的故障定位可以讓診斷和分類更快速，以利於及時解決問題。最近的工作中探討了一個引人注目的解決方案，即使用因果圖來擷取各種雲端系統效能指標之間關係的因果推理。然而，系統開發人員必須正確定義其系統的因果圖才能發揮效用，而這項任務耗時、脆弱且具有挑戰性，對於大型且動態的系統而言難度更高，而且需要領域專家知識。或者，由於事件的固有稀少性，自動化資料驅動方法對於雲端系統的效力有限。在這項工作中，我們提出 Atlas，一種自動合成雲端系統因果圖的新方法。Atlas 利用大型語言模型 (LLM) 使用系統文件、遙測和部署回饋來產生因果圖。Atlas 是資料驅動因果發現技術的補充，我們進一步使用資料驅動驗證步驟來增強 Atlas。我們在各種故障定位情境中評估 Atlas，並證明 Atlas 能夠以可擴充且可概化的方式產生因果圖，其效能遠遠超過資料驅動演算法，並且與真實基線相當。

##### **Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents**
2407.08516v1 by Haoyi Xiong, Zhiyuan Wang, Xuhong Li, Jiang Bian, Zeke Xie, Shahid Mumtaz, Laura E. Barnes

This article explores the convergence of connectionist and symbolic
artificial intelligence (AI), from historical debates to contemporary
advancements. Traditionally considered distinct paradigms, connectionist AI
focuses on neural networks, while symbolic AI emphasizes symbolic
representation and logic. Recent advancements in large language models (LLMs),
exemplified by ChatGPT and GPT-4, highlight the potential of connectionist
architectures in handling human language as a form of symbols. The study argues
that LLM-empowered Autonomous Agents (LAAs) embody this paradigm convergence.
By utilizing LLMs for text-based knowledge modeling and representation, LAAs
integrate neuro-symbolic AI principles, showcasing enhanced reasoning and
decision-making capabilities. Comparing LAAs with Knowledge Graphs within the
neuro-symbolic AI theme highlights the unique strengths of LAAs in mimicking
human-like reasoning processes, scaling effectively with large datasets, and
leveraging in-context samples without explicit re-training. The research
underscores promising avenues in neuro-vector-symbolic integration,
instructional encoding, and implicit reasoning, aimed at further enhancing LAA
capabilities. By exploring the progression of neuro-symbolic AI and proposing
future research trajectories, this work advances the understanding and
development of AI technologies.

摘要：這篇文章探討了連接主義與符號人工智慧 (AI) 的匯流，從歷史辯論到當代進展。傳統上被認為是不同的典範，連接主義 AI 專注於神經網路，而符號 AI 則強調符號表徵與邏輯。大型語言模型 (LLM) 的最新進展，以 ChatGPT 和 GPT-4 為例，突顯了連接主義架構在將人類語言視為符號形式處理的潛力。該研究論證，由 LLM 賦能的自主代理 (LAA) 體現了這種典範的匯流。透過利用 LLM 進行基於文字的知識建模與表徵，LAA 整合了神經符號 AI 原則，展示增強的推理和決策能力。在神經符號 AI 主題中將 LAA 與知識圖譜進行比較，突顯了 LAA 在模擬類人推理過程、有效擴充大型資料集以及在沒有明確重新訓練的情況下利用情境範例中的獨特優勢。該研究強調了神經向量符號整合、指令編碼和隱式推理中具有前景的途徑，旨在進一步增強 LAA 的能力。透過探討神經符號 AI 的進展並提出未來的研究軌跡，這項研究推動了對 AI 技術的理解和發展。

##### **A Comprehensive Survey on the Security of Smart Grid: Challenges, Mitigations, and Future Research Opportunities**
2407.07966v1 by Arastoo Zibaeirad, Farnoosh Koleini, Shengping Bi, Tao Hou, Tao Wang

In this study, we conduct a comprehensive review of smart grid security,
exploring system architectures, attack methodologies, defense strategies, and
future research opportunities. We provide an in-depth analysis of various
attack vectors, focusing on new attack surfaces introduced by advanced
components in smart grids. The review particularly includes an extensive
analysis of coordinated attacks that incorporate multiple attack strategies and
exploit vulnerabilities across various smart grid components to increase their
adverse impact, demonstrating the complexity and potential severity of these
threats. Following this, we examine innovative detection and mitigation
strategies, including game theory, graph theory, blockchain, and machine
learning, discussing their advancements in counteracting evolving threats and
associated research challenges. In particular, our review covers a thorough
examination of widely used machine learning-based mitigation strategies,
analyzing their applications and research challenges spanning across
supervised, unsupervised, semi-supervised, ensemble, and reinforcement
learning. Further, we outline future research directions and explore new
techniques and concerns. We first discuss the research opportunities for
existing and emerging strategies, and then explore the potential role of new
techniques, such as large language models (LLMs), and the emerging threat of
adversarial machine learning in the future of smart grid security.

摘要：在這項研究中，我們對智慧電網安全性進行全面檢視，探討系統架構、攻擊方法、防禦策略和未來的研究機會。我們深入分析各種攻擊媒介，專注於智慧電網中先進組件所引入的新攻擊面。本檢視特別包含對協調攻擊的廣泛分析，其中包含多種攻擊策略並利用各種智慧電網組件中的漏洞來增加其負面影響，展示這些威脅的複雜性和潛在嚴重性。在此之後，我們探討創新的偵測和緩解策略，包括博弈論、圖論、區塊鏈和機器學習，討論它們在對抗不斷演變的威脅和相關研究挑戰方面的進展。特別是，我們的檢視涵蓋對廣泛使用的基於機器學習的緩解策略的徹底檢驗，分析它們在監督式、非監督式、半監督式、整體式和強化學習中的應用和研究挑戰。此外，我們概述未來的研究方向並探討新技術和問題。我們首先討論現有和新興策略的研究機會，然後探討新技術的潛在作用，例如大型語言模型 (LLM)，以及對抗式機器學習在智慧電網安全未來的威脅。

##### **Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs**
2407.07775v1 by Hao-Tien Lewis Chiang, Zhuo Xu, Zipeng Fu, Mithun George Jacob, Tingnan Zhang, Tsang-Wei Edward Lee, Wenhao Yu, Connor Schenck, David Rendleman, Dhruv Shah, Fei Xia, Jasmine Hsu, Jonathan Hoech, Pete Florence, Sean Kirmani, Sumeet Singh, Vikas Sindhwani, Carolina Parada, Chelsea Finn, Peng Xu, Sergey Levine, Jie Tan

An elusive goal in navigation research is to build an intelligent agent that
can understand multimodal instructions including natural language and image,
and perform useful navigation. To achieve this, we study a widely useful
category of navigation tasks we call Multimodal Instruction Navigation with
demonstration Tours (MINT), in which the environment prior is provided through
a previously recorded demonstration video. Recent advances in Vision Language
Models (VLMs) have shown a promising path in achieving this goal as it
demonstrates capabilities in perceiving and reasoning about multimodal inputs.
However, VLMs are typically trained to predict textual output and it is an open
research question about how to best utilize them in navigation. To solve MINT,
we present Mobility VLA, a hierarchical Vision-Language-Action (VLA) navigation
policy that combines the environment understanding and common sense reasoning
power of long-context VLMs and a robust low-level navigation policy based on
topological graphs. The high-level policy consists of a long-context VLM that
takes the demonstration tour video and the multimodal user instruction as input
to find the goal frame in the tour video. Next, a low-level policy uses the
goal frame and an offline constructed topological graph to generate robot
actions at every timestep. We evaluated Mobility VLA in a 836m^2 real world
environment and show that Mobility VLA has a high end-to-end success rates on
previously unsolved multimodal instructions such as "Where should I return
this?" while holding a plastic bin.

摘要：<paragraph>導航研究中一個難以捉摸的目標是建立一個智慧代理，它
可以理解包含自然語言和影像的多模態指令，並執行有用的導航。為了達成這個目標，我們研究了一個廣泛有用的導航任務類別，我們稱之為示範導覽的多模態指令導航 (MINT)，其中環境先驗是透過先前錄製的示範影片提供的。視覺語言模型 (VLM) 的最新進展在實現這個目標方面展現了一條有希望的道路，因為它展示了感知和推理多模態輸入的能力。
然而，VLM 通常被訓練來預測文字輸出，而如何最佳地將它們用於導航是一個開放的研究問題。為了解決 MINT，我們提出了 Mobility VLA，這是一種分層的視覺-語言-動作 (VLA) 導航政策，它結合了長語境 VLM 的環境理解和常識推理能力，以及基於拓撲圖的強健低階導航政策。高階政策包含一個長語境 VLM，它將示範導覽影片和多模態使用者指令作為輸入，以在導覽影片中找到目標畫面。接下來，低階政策使用目標畫面和離線建構的拓撲圖在每個時間步產生機器人動作。我們在一個 836 平方公尺的真實世界環境中評估了 Mobility VLA，並顯示 Mobility VLA 在以前無法解決的多模態指令（例如「我應該把這個塑膠箱歸還到哪裡？」並拿著一個塑膠箱）上具有很高的端到端成功率。</paragraph>

##### **Teaching Transformers Causal Reasoning through Axiomatic Training**
2407.07612v1 by Aniket Vashishtha, Abhinav Kumar, Abbavaram Gowtham Reddy, Vineeth N Balasubramanian, Amit Sharma

For text-based AI systems to interact in the real world, causal reasoning is
an essential skill. Since interventional data is costly to generate, we study
to what extent an agent can learn causal reasoning from passive data.
Specifically, we consider an axiomatic training setup where an agent learns
from multiple demonstrations of a causal axiom (or rule), rather than
incorporating the axiom as an inductive bias or inferring it from data values.
A key question is whether the agent would learn to generalize from the axiom
demonstrations to new scenarios. For example, if a transformer model is trained
on demonstrations of the causal transitivity axiom over small graphs, would it
generalize to applying the transitivity axiom over large graphs? Our results,
based on a novel axiomatic training scheme, indicate that such generalization
is possible. We consider the task of inferring whether a variable causes
another variable, given a causal graph structure. We find that a 67 million
parameter transformer model, when trained on linear causal chains (along with
some noisy variations) can generalize well to new kinds of graphs, including
longer causal chains, causal chains with reversed order, and graphs with
branching; even when it is not explicitly trained for such settings. Our model
performs at par (or even better) than many larger language models such as
GPT-4, Gemini Pro, and Phi-3. Overall, our axiomatic training framework
provides a new paradigm of learning causal reasoning from passive data that can
be used to learn arbitrary axioms, as long as sufficient demonstrations can be
generated.

摘要：<paragraph>對於基於文字的人工智慧系統與真實世界互動來說，因果推理是一項必要的技能。由於介入資料的產生成本很高，我們研究一位代理人從被動資料中學習因果推理的程度。具體來說，我們考慮一個公理訓練設置，其中一位代理人從因果公理（或規則）的多個示範中學習，而不是將公理作為歸納偏誤或從資料值中推斷出來。一個關鍵問題是代理人是否會學會從公理示範推廣到新的場景。例如，如果一個Transformer模型在小圖表上因果傳遞性公理的示範中接受訓練，它是否會推廣到在大圖表上應用傳遞性公理？我們的結果基於一個新穎的公理訓練方案，表明這樣的概括是可能的。我們考慮推論一個變數是否導致另一個變數的任務，給定一個因果圖結構。我們發現一個 6700 萬個參數的Transformer模型，在線性因果鏈（以及一些雜訊變化）上訓練時，可以很好地概括到新類型的圖形，包括更長的因果鏈、順序相反的因果鏈和具有分支的圖形；即使它沒有針對此類設置進行明確訓練。我們的模型表現與許多較大的語言模型（例如 GPT-4、Gemini Pro 和 Phi-3）相當（甚至更好）。總體而言，我們的公理訓練框架提供了一個從被動資料中學習因果推理的新範例，只要可以產生足夠的示範，就可以用於學習任意公理。</paragraph>

##### **GLBench: A Comprehensive Benchmark for Graph with Large Language Models**
2407.07457v2 by Yuhan Li, Peisong Wang, Xiao Zhu, Aochuan Chen, Haiyun Jiang, Deng Cai, Victor Wai Kin Chan, Jia Li

The emergence of large language models (LLMs) has revolutionized the way we
interact with graphs, leading to a new paradigm called GraphLLM. Despite the
rapid development of GraphLLM methods in recent years, the progress and
understanding of this field remain unclear due to the lack of a benchmark with
consistent experimental protocols. To bridge this gap, we introduce GLBench,
the first comprehensive benchmark for evaluating GraphLLM methods in both
supervised and zero-shot scenarios. GLBench provides a fair and thorough
evaluation of different categories of GraphLLM methods, along with traditional
baselines such as graph neural networks. Through extensive experiments on a
collection of real-world datasets with consistent data processing and splitting
strategies, we have uncovered several key findings. Firstly, GraphLLM methods
outperform traditional baselines in supervised settings, with LLM-as-enhancers
showing the most robust performance. However, using LLMs as predictors is less
effective and often leads to uncontrollable output issues. We also notice that
no clear scaling laws exist for current GraphLLM methods. In addition, both
structures and semantics are crucial for effective zero-shot transfer, and our
proposed simple baseline can even outperform several models tailored for
zero-shot scenarios. The data and code of the benchmark can be found at
https://github.com/NineAbyss/GLBench.

摘要：大型語言模型 (LLM) 的出現徹底改變了我們與圖表互動的方式，進而產生一種稱為 GraphLLM 的新典範。儘管近年來 GraphLLM 方法快速發展，但由於缺乏具有一致實驗協定的基準，因此該領域的進展和理解仍不明確。為了彌補這個差距，我們引入了 GLBench，這是第一個用於評估 GraphLLM 方法在監督式和零次學習場景中的綜合基準。GLBench 提供對不同類別的 GraphLLM 方法進行公平且徹底的評估，以及傳統基準，例如圖神經網路。透過對一組真實世界資料集進行廣泛實驗，並採用一致的資料處理和分割策略，我們發現了幾個關鍵發現。首先，GraphLLM 方法在監督式設定中優於傳統基準，其中 LLM 作為增強器顯示出最穩健的效能。然而，使用 LLM 作為預測器較不有效，而且經常導致無法控制的輸出問題。我們還注意到，對於目前的 GraphLLM 方法並不存在明確的縮放定律。此外，結構和語義對於有效的零次學習傳輸至關重要，而我們提出的簡單基準甚至可以優於針對零次學習場景量身打造的幾個模型。基準的資料和程式碼可以在 https://github.com/NineAbyss/GLBench 中找到。

##### **Decoding Climate Disagreement: A Graph Neural Network-Based Approach to Understanding Social Media Dynamics**
2407.07038v1 by Ruiran Su, Janet B. Pierrehumbert

This work introduces the ClimateSent-GAT Model, an innovative method that
integrates Graph Attention Networks (GATs) with techniques from natural
language processing to accurately identify and predict disagreements within
Reddit comment-reply pairs. Our model classifies disagreements into three
categories: agree, disagree, and neutral. Leveraging the inherent graph
structure of Reddit comment-reply pairs, the model significantly outperforms
existing benchmarks by capturing complex interaction patterns and sentiment
dynamics. This research advances graph-based NLP methodologies and provides
actionable insights for policymakers and educators in climate science
communication.

摘要：本研究介紹 ClimateSent-GAT 模型，這是一種創新的方法，它將圖注意力網路 (GAT) 與自然語言處理技術整合，以準確識別並預測 Reddit 留言回覆對中的分歧。我們的模型將分歧分為三類：同意、不同意和中立。透過利用 Reddit 留言回覆對的內在圖形結構，此模型能大幅超越現有基準，捕捉複雜的互動模式和情緒動態。這項研究推動了基於圖形的 NLP 方法，並為氣候科學溝通中的政策制定者和教育工作者提供可行的見解。

##### **Graph-Based Captioning: Enhancing Visual Descriptions by Interconnecting Region Captions**
2407.06723v1 by Yu-Guan Hsieh, Cheng-Yu Hsieh, Shih-Ying Yeh, Louis Béthune, Hadi Pour Ansari, Pavan Kumar Anasosalu Vasu, Chun-Liang Li, Ranjay Krishna, Oncel Tuzel, Marco Cuturi

Humans describe complex scenes with compositionality, using simple text
descriptions enriched with links and relationships. While vision-language
research has aimed to develop models with compositional understanding
capabilities, this is not reflected yet in existing datasets which, for the
most part, still use plain text to describe images. In this work, we propose a
new annotation strategy, graph-based captioning (GBC) that describes an image
using a labelled graph structure, with nodes of various types. The nodes in GBC
are created using, in a first stage, object detection and dense captioning
tools nested recursively to uncover and describe entity nodes, further linked
together in a second stage by highlighting, using new types of nodes,
compositions and relations among entities. Since all GBC nodes hold plain text
descriptions, GBC retains the flexibility found in natural language, but can
also encode hierarchical information in its edges. We demonstrate that GBC can
be produced automatically, using off-the-shelf multimodal LLMs and
open-vocabulary detection models, by building a new dataset, GBC10M, gathering
GBC annotations for about 10M images of the CC12M dataset. We use GBC10M to
showcase the wealth of node captions uncovered by GBC, as measured with CLIP
training. We show that using GBC nodes' annotations -- notably those stored in
composition and relation nodes -- results in significant performance boost on
downstream models when compared to other dataset formats. To further explore
the opportunities provided by GBC, we also propose a new attention mechanism
that can leverage the entire GBC graph, with encouraging experimental results
that show the extra benefits of incorporating the graph structure. Our datasets
are released at \url{https://huggingface.co/graph-based-captions}.

摘要：<paragraph>人類使用簡單的文字描述，豐富的連結和關係，來描述複雜的場景。雖然視覺語言的研究旨在開發具有組合理解能力的模型，但現有的數據集尚未反映這一點，這些數據集在很大程度上仍使用純文本來描述圖像。在這項工作中，我們提出了一種新的註釋策略，基於圖表的標題 (GBC)，它使用標籤圖表結構來描述圖像，其中包含各種類型的節點。GBC 中的節點是使用物體檢測和密集標題工具在第一階段創建的，以遞迴嵌套的方式發現和描述實體節點，並在第二階段使用新類型的節點突出顯示，從而將它們進一步連結在一起，實體之間的組合和關係。由於所有 GBC 節點都包含純文本描述，因此 GBC 保留了自然語言中的靈活性，但也可以在其邊緣編碼分層信息。我們證明了 GBC 可以使用現成的多模態 LLM 和開放詞彙檢測模型自動生成，通過構建一個新的數據集 GBC10M，收集了大約 10M CC12M 數據集圖像的 GBC 註釋。我們使用 GBC10M 來展示 GBC 發現的豐富節點標題，並使用 CLIP 訓練進行測量。我們表明，與其他數據集格式相比，使用 GBC 節點的註釋——特別是存儲在組合和關係節點中的註釋——會顯著提升下游模型的性能。為了進一步探索 GBC 提供的機會，我們還提出了一種新的注意機制，它可以利用整個 GBC 圖表，並通過鼓勵性的實驗結果展示了結合圖表結構的額外好處。我們的數據集發布在 \url{https://huggingface.co/graph-based-captions}。</paragraph>

##### **Combining Knowledge Graphs and Large Language Models**
2407.06564v1 by Amanda Kau, Xuzeng He, Aishwarya Nambissan, Aland Astudillo, Hui Yin, Amir Aryani

In recent years, Natural Language Processing (NLP) has played a significant
role in various Artificial Intelligence (AI) applications such as chatbots,
text generation, and language translation. The emergence of large language
models (LLMs) has greatly improved the performance of these applications,
showing astonishing results in language understanding and generation. However,
they still show some disadvantages, such as hallucinations and lack of
domain-specific knowledge, that affect their performance in real-world tasks.
These issues can be effectively mitigated by incorporating knowledge graphs
(KGs), which organise information in structured formats that capture
relationships between entities in a versatile and interpretable fashion.
Likewise, the construction and validation of KGs present challenges that LLMs
can help resolve. The complementary relationship between LLMs and KGs has led
to a trend that combines these technologies to achieve trustworthy results.
This work collected 28 papers outlining methods for KG-powered LLMs, LLM-based
KGs, and LLM-KG hybrid approaches. We systematically analysed and compared
these approaches to provide a comprehensive overview highlighting key trends,
innovative techniques, and common challenges. This synthesis will benefit
researchers new to the field and those seeking to deepen their understanding of
how KGs and LLMs can be effectively combined to enhance AI applications
capabilities.

摘要：近年来，自然语言处理 (NLP) 在各种人工智能 (AI) 应用中发挥了重要作用，例如聊天机器人、文本生成和语言翻译。大语言模型 (LLM) 的出现极大地提高了这些应用程序的性能，在语言理解和生成方面显示出惊人的结果。然而，它们仍然表现出一些缺点，例如幻觉和缺乏特定领域的知识，这些缺点会影响它们在现实世界中的任务中的表现。通过纳入知识图谱 (KG) 可以有效地减轻这些问题，知识图谱以结构化格式组织信息，以多功能且可解释的方式捕获实体之间的关系。同样，KG 的构建和验证提出了 LLM 可以帮助解决的挑战。LLM 和 KG 之间的互补关系导致了一种将这些技术相结合以实现可信结果的趋势。这项工作收集了 28 篇概述了 KG 驱动的 LLM、基于 LLM 的 KG 和 LLM-KG 混合方法的方法的论文。我们系统地分析和比较了这些方法，以提供一个全面的概述，重点介绍关键趋势、创新技术和共同挑战。这种综合将使该领域的新研究人员和那些寻求加深对如何有效地将 KG 和 LLM 相结合以增强 AI 应用能力的理解的人受益。

##### **MST5 -- Multilingual Question Answering over Knowledge Graphs**
2407.06041v1 by Nikit Srivastava, Mengshi Ma, Daniel Vollmers, Hamada Zahera, Diego Moussallem, Axel-Cyrille Ngonga Ngomo

Knowledge Graph Question Answering (KGQA) simplifies querying vast amounts of
knowledge stored in a graph-based model using natural language. However, the
research has largely concentrated on English, putting non-English speakers at a
disadvantage. Meanwhile, existing multilingual KGQA systems face challenges in
achieving performance comparable to English systems, highlighting the
difficulty of generating SPARQL queries from diverse languages. In this
research, we propose a simplified approach to enhance multilingual KGQA systems
by incorporating linguistic context and entity information directly into the
processing pipeline of a language model. Unlike existing methods that rely on
separate encoders for integrating auxiliary information, our strategy leverages
a single, pretrained multilingual transformer-based language model to manage
both the primary input and the auxiliary data. Our methodology significantly
improves the language model's ability to accurately convert a natural language
query into a relevant SPARQL query. It demonstrates promising results on the
most recent QALD datasets, namely QALD-9-Plus and QALD-10. Furthermore, we
introduce and evaluate our approach on Chinese and Japanese, thereby expanding
the language diversity of the existing datasets.

摘要：知識圖表問答 (KGQA) 簡化了使用自然語言查詢儲存在圖形化模型中的大量知識。然而，研究主要集中在英文上，這對非英語使用者來說是不利的。同時，現有的多語言 KGQA 系統在達成與英文系統相媲美的效能方面面臨挑戰，突顯了從不同語言產生 SPARQL 查詢的困難性。在這項研究中，我們提出了一種簡化的方法，通過將語言學背景和實體資訊直接納入語言模型的處理管道，來增強多語言 KGQA 系統。與依賴於單獨編碼器來整合輔助資訊的現有方法不同，我們的策略利用單一的、預訓練的多語言轉換器語言模型來管理主要輸入和輔助資料。我們的技術顯著提升了語言模型準確地將自然語言查詢轉換為相關 SPARQL 查詢的能力。它在最新的 QALD 資料集，即 QALD-9-Plus 和 QALD-10 上展示了有希望的結果。此外，我們在中文和日文中引入並評估了我們的做法，從而擴展了現有資料集的語言多樣性。

##### **Enhancing Vision-Language Models with Scene Graphs for Traffic Accident Understanding**
2407.05910v1 by Aaron Lohner, Francesco Compagno, Jonathan Francis, Alessandro Oltramari

Recognizing a traffic accident is an essential part of any autonomous driving
or road monitoring system. An accident can appear in a wide variety of forms,
and understanding what type of accident is taking place may be useful to
prevent it from reoccurring. The task of being able to classify a traffic scene
as a specific type of accident is the focus of this work. We approach the
problem by likening a traffic scene to a graph, where objects such as cars can
be represented as nodes, and relative distances and directions between them as
edges. This representation of an accident can be referred to as a scene graph,
and is used as input for an accident classifier. Better results can be obtained
with a classifier that fuses the scene graph input with representations from
vision and language. This work introduces a multi-stage, multimodal pipeline to
pre-process videos of traffic accidents, encode them as scene graphs, and align
this representation with vision and language modalities for accident
classification. When trained on 4 classes, our method achieves a balanced
accuracy score of 57.77% on an (unbalanced) subset of the popular Detection of
Traffic Anomaly (DoTA) benchmark, representing an increase of close to 5
percentage points from the case where scene graph information is not taken into
account.

摘要：辨識交通事故是任何自動駕駛或道路監控系統的必要部分。事故可能以各種形式出現，了解事故類型可能有助於防止再次發生。將交通事故場景分類為特定事故類型的任務是這項工作的重點。我們將交通事故場景比喻為圖形來解決問題，其中汽車等物體可以表示為節點，而它們之間的相對距離和方向則表示為邊緣。這種事故表示可以稱為場景圖，並用作事故分類器的輸入。使用將場景圖輸入與視覺和語言表示融合的分類器可以獲得更好的結果。這項工作引入了一個多階段、多模態管道，用於預處理交通事故影片、將其編碼為場景圖，以及將此表示與視覺和語言模式對齊以進行事故分類。當在 4 個類別上進行訓練時，我們的模型在熱門交通異常檢測 (DoTA) 基準的（不平衡）子集上實現了 57.77% 的平衡準確率，比不考慮場景圖資訊的情況提高了接近 5 個百分點。

##### **Affordances-Oriented Planning using Foundation Models for Continuous Vision-Language Navigation**
2407.05890v1 by Jiaqi Chen, Bingqian Lin, Xinmin Liu, Xiaodan Liang, Kwan-Yee K. Wong

LLM-based agents have demonstrated impressive zero-shot performance in the
vision-language navigation (VLN) task. However, these zero-shot methods focus
only on solving high-level task planning by selecting nodes in predefined
navigation graphs for movements, overlooking low-level control in realistic
navigation scenarios. To bridge this gap, we propose AO-Planner, a novel
affordances-oriented planning framework for continuous VLN task. Our AO-Planner
integrates various foundation models to achieve affordances-oriented motion
planning and action decision-making, both performed in a zero-shot manner.
Specifically, we employ a visual affordances prompting (VAP) approach, where
visible ground is segmented utilizing SAM to provide navigational affordances,
based on which the LLM selects potential next waypoints and generates low-level
path planning towards selected waypoints. We further introduce a high-level
agent, PathAgent, to identify the most probable pixel-based path and convert it
into 3D coordinates to fulfill low-level motion. Experimental results on the
challenging R2R-CE benchmark demonstrate that AO-Planner achieves
state-of-the-art zero-shot performance (5.5% improvement in SPL). Our method
establishes an effective connection between LLM and 3D world to circumvent the
difficulty of directly predicting world coordinates, presenting novel prospects
for employing foundation models in low-level motion control.

摘要：基於 LLM 的代理已在視覺語言導航 (VLN) 任務中展示出令人印象深刻的零次學習效能。然而，這些零次學習方法僅專注於透過選擇預定義導航圖形中的節點來解決高階任務規劃，忽略了實際導航場景中的低階控制。為了彌合此差距，我們提出 AO-Planner，一個用於連續 VLN 任務的新型以可負擔性為導向的規劃架構。我們的 AO-Planner 整合各種基礎模型，以實現以可負擔性為導向的動作規劃和動作決策，兩者都以零次學習的方式執行。具體來說，我們採用視覺可負擔性提示 (VAP) 方法，其中利用 SAM 對可見地面進行分割，以提供導航可負擔性，LLM 根據這些可負擔性選擇潛在的下一個航點，並針對所選航點產生低階路徑規劃。我們進一步引入一個高階代理 PathAgent，以識別最可能的基於像素的路徑，並將其轉換為 3D 座標，以實現低階動作。在具有挑戰性的 R2R-CE 基準測試上的實驗結果表明，AO-Planner 達到了最先進的零次學習效能（SPL 提升 5.5%）。我們的模型在 LLM 和 3D 世界之間建立了一個有效的連結，以規避直接預測世界座標的難題，為在低階動作控制中採用基礎模型提供了新的前景。

##### **KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions**
2407.05868v1 by Yanxu Zhu, Jinlin Xiao, Yuhang Wang, Jitao Sang

Recent studies have demonstrated that large language models (LLMs) are
susceptible to being misled by false premise questions (FPQs), leading to
errors in factual knowledge, know as factuality hallucination. Existing
benchmarks that assess this vulnerability primarily rely on manual
construction, resulting in limited scale and lack of scalability. In this work,
we introduce an automated, scalable pipeline to create FPQs based on knowledge
graphs (KGs). The first step is modifying true triplets extracted from KGs to
create false premises. Subsequently, utilizing the state-of-the-art
capabilities of GPTs, we generate semantically rich FPQs. Based on the proposed
method, we present a comprehensive benchmark, the Knowledge Graph-based False
Premise Questions (KG-FPQ), which contains approximately 178k FPQs across three
knowledge domains, at six levels of confusability, and in two task formats.
Using KG-FPQ, we conduct extensive evaluations on several representative LLMs
and provide valuable insights. The KG-FPQ dataset and code are available
at~https://github.com/yanxuzhu/KG-FPQ.

摘要：最近的研究表明，大型语言模型 (LLM) 容易被错误前提问题 (FPQ) 误导，从而导致事实知识错误，即事实幻觉。用于评估此漏洞的现有基准主要依赖于手动构建，导致规模有限且缺乏可扩展性。在这项工作中，我们引入了一个基于知识图谱 (KG) 创建 FPQ 的自动化可扩展管道。第一步是修改从 KG 中提取的真三元组以创建错误前提。随后，利用 GPT 的最先进功能，我们生成了语义丰富的 FPQ。基于所提出的方法，我们提出了一个综合基准，即基于知识图谱的错误前提问题 (KG-FPQ)，它包含大约 178k 个 FPQ，涵盖三个知识域，六个混淆级别和两种任务格式。使用 KG-FPQ，我们对几个有代表性的 LLM 进行了广泛的评估，并提供了有价值的见解。KG-FPQ 数据集和代码可在~https://github.com/yanxuzhu/KG-FPQ 获得。

##### **Language Models Encode Collaborative Signals in Recommendation**
2407.05441v1 by Leheng Sheng, An Zhang, Yi Zhang, Yuxin Chen, Xiang Wang, Tat-Seng Chua

Recent studies empirically indicate that language models (LMs) encode rich
world knowledge beyond mere semantics, attracting significant attention across
various fields. However, in the recommendation domain, it remains uncertain
whether LMs implicitly encode user preference information. Contrary to the
prevailing understanding that LMs and traditional recommender models learn two
distinct representation spaces due to a huge gap in language and behavior
modeling objectives, this work rethinks such understanding and explores
extracting a recommendation space directly from the language representation
space. Surprisingly, our findings demonstrate that item representations, when
linearly mapped from advanced LM representations, yield superior recommendation
performance. This outcome suggests the homomorphism between the language
representation space and an effective recommendation space, implying that
collaborative signals may indeed be encoded within advanced LMs. Motivated by
these findings, we propose a simple yet effective collaborative filtering (CF)
model named AlphaRec, which utilizes language representations of item textual
metadata (e.g., titles) instead of traditional ID-based embeddings.
Specifically, AlphaRec is comprised of three main components: a multilayer
perceptron (MLP), graph convolution, and contrastive learning (CL) loss
function, making it extremely easy to implement and train. Our empirical
results show that AlphaRec outperforms leading ID-based CF models on multiple
datasets, marking the first instance of such a recommender with text embeddings
achieving this level of performance. Moreover, AlphaRec introduces a new
language-representation-based CF paradigm with several desirable advantages:
being easy to implement, lightweight, rapid convergence, superior zero-shot
recommendation abilities in new domains, and being aware of user intention.

摘要：<paragraph>最近的研究實證表明，語言模型 (LM) 編碼豐富的世界知識，超越了單純的語義，吸引了各個領域的極大關注。然而，在推薦領域中，LM 是否隱含編碼使用者偏好資訊仍不確定。與普遍認知相反，LM 和傳統推薦模型由於語言和行為建模目標的巨大差距而學習兩個不同的表示空間，這項工作重新思考這種理解，並探索直接從語言表示空間中提取推薦空間。令人驚訝的是，我們的研究結果表明，當從先進的 LM 表示中線性映射時，項目表示會產生優異的推薦效能。此結果表明語言表示空間和有效的推薦空間之間存在同態性，這意味著協作訊號確實可能編碼在先進的 LM 中。受這些研究結果的啟發，我們提出了一個簡單但有效的協同過濾 (CF) 模型，名為 AlphaRec，它利用項目文字元資料（例如標題）的語言表示，而不是傳統基於 ID 的嵌入。具體來說，AlphaRec 由三個主要組成部分組成：多層感知器 (MLP)、圖形卷積和對比學習 (CL) 損失函數，使其極易於實作和訓練。我們的實證結果表明，AlphaRec 在多個資料集上優於領先的基於 ID 的 CF 模型，標誌著這種具有文字嵌入的推薦系統首次達到此效能水準。此外，AlphaRec 引入了一個新的基於語言表示的 CF 典範，具有多項理想的優點：易於實作、輕量級、快速收斂、在新的領域中具有優異的零次學習推薦能力，並且可以了解使用者的意圖。</paragraph>

##### **LTLBench: Towards Benchmarks for Evaluating Temporal Logic Reasoning in Large Language Models**
2407.05434v1 by Weizhi Tang, Vaishak Belle

Temporal reasoning (TR) is a critical component of artificial intelligence,
encompassing understanding and processing temporal information and
relationships between events. To discover and study the TR ability in Large
Language Models (LLMs), various datasets have been constructed in different
ways for evaluating various aspects of TR ability. Our work proposes a novel
approach to design and develop a pipeline for constructing datasets to evaluate
the TR ability of LLMs by leveraging random directed graph generation, LTL
formula, and the NuSMV model checker. Based on the pipeline, we have also
constructed a dataset as a benchmark, namely LTLBench, consisting of 2,000 TR
challenges and evaluated six LLMs with it. Furthermore, we have conducted
additional experiments to discover the impact of increasing the number of
events and formula operators on the complexity of TR problems and the
performance of LLMs. We have demonstrated that although LLMs exhibit some
promise in handling TR challenges, they still struggle with complex TR. We
expect this work can offer insights into TR ability in LLMs while also
providing a valuable tool for future TR evaluations.

摘要：時間推理 (TR) 是人工智慧的一項關鍵組成部分，
涵蓋了對時間資訊和事件之間關係的理解和處理。為了發現和研究大型語言模型 (LLM) 中的 TR 能力，已透過各種方式建構各種資料集，用於評估 TR 能力的各個面向。我們的工作提出了一種新穎的方法，用於設計和開發一個建構資料集的管道，以評估 LLM 的 TR 能力，方法是利用隨機有向圖生成、LTL 公式和 NuSMV 模型檢查器。根據這個管道，我們還建構了一個資料集作為基準，即 LTLBench，其中包含 2,000 個 TR 挑戰，並用它評估了六個 LLM。此外，我們還進行了額外的實驗，以發現增加事件數量和公式運算子對 TR 問題複雜性和 LLM 效能的影響。我們已經證明，儘管 LLM 在處理 TR 挑戰方面表現出一些希望，但它們仍然難以處理複雜的 TR。我們預期這項工作可以提供對 LLM 中 TR 能力的見解，同時也為未來的 TR 評估提供一個有價值的工具。

##### **Leveraging Graph Structures to Detect Hallucinations in Large Language Models**
2407.04485v1 by Noa Nonkes, Sergei Agaronian, Evangelos Kanoulas, Roxana Petcu

Large language models are extensively applied across a wide range of tasks,
such as customer support, content creation, educational tutoring, and providing
financial guidance. However, a well-known drawback is their predisposition to
generate hallucinations. This damages the trustworthiness of the information
these models provide, impacting decision-making and user confidence. We propose
a method to detect hallucinations by looking at the structure of the latent
space and finding associations within hallucinated and non-hallucinated
generations. We create a graph structure that connects generations that lie
closely in the embedding space. Moreover, we employ a Graph Attention Network
which utilizes message passing to aggregate information from neighboring nodes
and assigns varying degrees of importance to each neighbor based on their
relevance. Our findings show that 1) there exists a structure in the latent
space that differentiates between hallucinated and non-hallucinated
generations, 2) Graph Attention Networks can learn this structure and
generalize it to unseen generations, and 3) the robustness of our method is
enhanced when incorporating contrastive learning. When evaluated against
evidence-based benchmarks, our model performs similarly without access to
search-based methods.

摘要：大型語言模型廣泛應用於各種任務中，例如客戶支援、內容創作、教育輔導和提供財務指導。然而，一個眾所周知的缺點是它們傾向於產生幻覺。這損害了這些模型所提供資訊的可信度，影響了決策制定和使用者信心。我們提出了一種透過觀察潛在空間的結構並找出幻覺和非幻覺生成中的關聯來偵測幻覺的方法。我們建立了一個圖形結構，連接在嵌入空間中緊密相連的生成。此外，我們採用了一個圖形注意力網路，它利用訊息傳遞來彙總來自相鄰節點的資訊，並根據每個相鄰節點的相關性為其指定不同程度的重要性。我們的研究結果顯示，1) 潛在空間中存在一個結構，可以區分幻覺和非幻覺生成，2) 圖形注意力網路可以學習這個結構並將其概括到未見的生成中，以及 3) 當納入對比學習時，我們方法的穩健性會得到增強。當根據基於證據的基準進行評估時，我們的模型在無法取得基於搜尋的方法的情況下，表現得類似。

##### **AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents**
2407.04363v1 by Petr Anokhin, Nikita Semenov, Artyom Sorokin, Dmitry Evseev, Mikhail Burtsev, Evgeny Burnaev

Advancements in generative AI have broadened the potential applications of
Large Language Models (LLMs) in the development of autonomous agents. Achieving
true autonomy requires accumulating and updating knowledge gained from
interactions with the environment and effectively utilizing it. Current
LLM-based approaches leverage past experiences using a full history of
observations, summarization or retrieval augmentation. However, these
unstructured memory representations do not facilitate the reasoning and
planning essential for complex decision-making. In our study, we introduce
AriGraph, a novel method wherein the agent constructs a memory graph that
integrates semantic and episodic memories while exploring the environment. This
graph structure facilitates efficient associative retrieval of interconnected
concepts, relevant to the agent's current state and goals, thus serving as an
effective environmental model that enhances the agent's exploratory and
planning capabilities. We demonstrate that our Ariadne LLM agent, equipped with
this proposed memory architecture augmented with planning and decision-making,
effectively handles complex tasks on a zero-shot basis in the TextWorld
environment. Our approach markedly outperforms established methods such as
full-history, summarization, and Retrieval-Augmented Generation in various
tasks, including the cooking challenge from the First TextWorld Problems
competition and novel tasks like house cleaning and puzzle Treasure Hunting.

摘要：生成式 AI 的進步擴展了大型語言模型 (LLM) 在自主代理開發中的潛在應用。實現真正的自主性需要累積和更新從與環境互動中獲得的知識，並有效利用它。當前的基於 LLM 的方法利用過去的經驗，使用完整的觀察、摘要或檢索擴充。然而，這些非結構化的記憶表徵並不能促進複雜決策制定中必不可少的推理和規劃。在我們的研究中，我們介紹了 AriGraph，這是一種新方法，其中代理構建了一個記憶圖，該圖在探索環境時整合了語義和情節記憶。這種圖形結構促進了相互聯繫的概念的有效關聯性檢索，與代理的當前狀態和目標相關，從而作為一個有效的環境模型，增強了代理的探索和規劃能力。我們展示了我們的 Ariadne LLM 代理，配備了這種提議的記憶架構，並增強了規劃和決策制定，有效地處理了 TextWorld 環境中零次學習的複雜任務。我們的做法顯著優於已建立的方法，例如完整歷史、摘要和檢索增強生成，在各種任務中，包括來自第一個 TextWorld 問題競賽的烹飪挑戰和房屋清潔和拼圖尋寶等新任務。

##### **Semantic Graphs for Syntactic Simplification: A Revisit from the Age of LLM**
2407.04067v1 by Peiran Yao, Kostyantyn Guzhva, Denilson Barbosa

Symbolic sentence meaning representations, such as AMR (Abstract Meaning
Representation) provide expressive and structured semantic graphs that act as
intermediates that simplify downstream NLP tasks. However, the
instruction-following capability of large language models (LLMs) offers a
shortcut to effectively solve NLP tasks, questioning the utility of semantic
graphs. Meanwhile, recent work has also shown the difficulty of using meaning
representations merely as a helpful auxiliary for LLMs. We revisit the position
of semantic graphs in syntactic simplification, the task of simplifying
sentence structures while preserving their meaning, which requires semantic
understanding, and evaluate it on a new complex and natural dataset. The
AMR-based method that we propose, AMRS$^3$, demonstrates that state-of-the-art
meaning representations can lead to easy-to-implement simplification methods
with competitive performance and unique advantages in cost, interpretability,
and generalization. With AMRS$^3$ as an anchor, we discover that syntactic
simplification is a task where semantic graphs are helpful in LLM prompting. We
propose AMRCoC prompting that guides LLMs to emulate graph algorithms for
explicit symbolic reasoning on AMR graphs, and show its potential for improving
LLM on semantic-centered tasks like syntactic simplification.

摘要：符號句子意義表徵，例如 AMR（抽象意義表徵），提供表達性和結構化的語義圖表，作為簡化下游 NLP 任務的中介。然而，大型語言模型 (LLM) 的指令遵循能力提供了一個捷徑來有效解決 NLP 任務，質疑語義圖表的效用。同時，最近的研究也表明僅將意義表徵用作 LLM 的輔助工具的難度。我們重新審視語義圖表在語法簡化中的位置，語法簡化的任務是在保留句子結構的同時簡化句子結構，這需要語義理解，並在一個新的複雜且自然的數據集上對其進行評估。我們提出的基於 AMR 的方法 AMRS$^3$ 證明了最先進的意義表徵可以導致易於實現的簡化方法，在成本、可解釋性和泛化方面具有競爭優勢和獨特優勢。以 AMRS$^3$ 為錨點，我們發現語法簡化是一項語義圖表有助於 LLM 提示的任務。我們提出 AMRCoC 提示，指導 LLM 模擬圖形演算法，對 AMR 圖形進行明確的符號推理，並展示其在改進 LLM 在以語義為中心的任務（如語法簡化）方面的潛力。

##### **Functional Faithfulness in the Wild: Circuit Discovery with Differentiable Computation Graph Pruning**
2407.03779v1 by Lei Yu, Jingcheng Niu, Zining Zhu, Gerald Penn

In this paper, we introduce a comprehensive reformulation of the task known
as Circuit Discovery, along with DiscoGP, a novel and effective algorithm based
on differentiable masking for discovering circuits. Circuit discovery is the
task of interpreting the computational mechanisms of language models (LMs) by
dissecting their functions and capabilities into sparse subnetworks (circuits).
We identified two major limitations in existing circuit discovery efforts: (1)
a dichotomy between weight-based and connection-edge-based approaches forces
researchers to choose between pruning connections or weights, thereby limiting
the scope of mechanistic interpretation of LMs; (2) algorithms based on
activation patching tend to identify circuits that are neither functionally
faithful nor complete. The performance of these identified circuits is
substantially reduced, often resulting in near-random performance in isolation.
Furthermore, the complement of the circuit -- i.e., the original LM with the
identified circuit removed -- still retains adequate performance, indicating
that essential components of a complete circuits are missed by existing
methods.
  DiscoGP successfully addresses the two aforementioned issues and demonstrates
state-of-the-art faithfulness, completeness, and sparsity. The effectiveness of
the algorithm and its novel structure open up new avenues of gathering new
insights into the internal workings of generative AI.

摘要：<paragraph>在本文中，我們介紹了對稱為電路發現任務的全面重新表述，以及 DiscoGP，一種基於可微遮罩的發現電路的新穎且有效的演算法。電路發現是透過將其功能和能力解剖成稀疏子網路（電路）來詮釋語言模型（LM）的運算機制的任務。我們在現有的電路發現工作中發現了兩個主要的限制：（1）基於權重和基於連接邊緣的方法之間的二分法迫使研究人員在修剪連接或權重之間進行選擇，從而限制了 LM 機制詮釋的範圍；（2）基於啟用修補的演算法傾向於識別在功能上既不忠實也不完整的電路。這些已識別電路的效能大幅降低，通常導致孤立的近乎隨機效能。此外，電路的補數——即移除已識別電路的原始 LM——仍保留了足夠的效能，這表示現有方法錯失了完整電路的基本組成部分。
DiscoGP 成功地解決了上述兩個問題，並展示了最先進的忠實度、完整性和稀疏性。該演算法的有效性和其新穎的結構為深入瞭解生成式 AI 的內部運作開闢了新的途徑。</paragraph>

##### **BACON: Supercharge Your VLM with Bag-of-Concept Graph to Mitigate Hallucinations**
2407.03314v1 by Zhantao Yang, Ruili Feng, Keyu Yan, Huangji Wang, Zhicai Wang, Shangwen Zhu, Han Zhang, Jie Xiao, Pingyu Wu, Kai Zhu, Jixuan Chen, Chen-Wei Xie, Chaojie Mao, Yue Yang, Hongyang Zhang, Yu Liu, Fan Cheng

This paper presents Bag-of-Concept Graph (BACON) to gift models with limited
linguistic abilities to taste the privilege of Vision Language Models (VLMs)
and boost downstream tasks such as detection, visual question answering (VQA),
and image generation. Since the visual scenes in physical worlds are structured
with complex relations between objects, BACON breaks down annotations into
basic minimum elements and presents them in a graph structure. Element-wise
style enables easy understanding, and structural composition liberates
difficult locating. Careful prompt design births the BACON captions with the
help of public-available VLMs and segmentation methods. In this way, we gather
a dataset with 100K annotated images, which endow VLMs with remarkable
capabilities, such as accurately generating BACON, transforming prompts into
BACON format, envisioning scenarios in the style of BACONr, and dynamically
modifying elements within BACON through interactive dialogue and more. Wide
representative experiments, including detection, VQA, and image generation
tasks, tell BACON as a lifeline to achieve previous out-of-reach tasks or excel
in their current cutting-edge solutions.

摘要：本文提出 Bag-of-Concept Graph (BACON)，赋予语言能力有限的模型品尝视觉语言模型 (VLM) 的特权，并提升下游任务，例如检测、视觉问答 (VQA) 和图像生成。由于物理世界中的视觉场景是由对象之间的复杂关系构建而成的，因此 BACON 将注释分解为基本的最小元素，并以图形结构呈现它们。基于元素的风格便于理解，结构化组合解放了困难的定位。在公共可用 VLM 和分割方法的帮助下，精心设计的提示生成了 BACON 标题。通过这种方式，我们收集了一个包含 100K 张注释图像的数据集，该数据集赋予 VLM 显著的能力，例如准确生成 BACON、将提示转换为 BACON 格式、以 BACONr 的风格设想场景，以及通过交互式对话动态修改 BACON 中的元素等等。广泛的代表性实验，包括检测、VQA 和图像生成任务，表明 BACON 作为一条生命线，可以实现以前无法实现的任务，或在当前的尖端解决方案中表现出色。

##### **GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models**
2407.02936v1 by Zike Yuan, Ming Liu, Hui Wang, Bing Qin

Evaluating the graph comprehension and reasoning abilities of Large Language
Models (LLMs) is challenging and often incomplete. Existing benchmarks focus
primarily on pure graph understanding, lacking a comprehensive evaluation
across all graph types and detailed capability definitions. This paper presents
GraCoRe, a benchmark for systematically assessing LLMs' graph comprehension and
reasoning. GraCoRe uses a three-tier hierarchical taxonomy to categorize and
test models on pure graph and heterogeneous graphs, subdividing capabilities
into 10 distinct areas tested through 19 tasks. Our benchmark includes 11
datasets with 5,140 graphs of varying complexity. We evaluated three
closed-source and seven open-source LLMs, conducting thorough analyses from
both ability and task perspectives. Key findings reveal that semantic
enrichment enhances reasoning performance, node ordering impacts task success,
and the ability to process longer texts does not necessarily improve graph
comprehension or reasoning. GraCoRe is open-sourced at
https://github.com/ZIKEYUAN/GraCoRe

摘要：評估大型語言模型 (LLM) 的圖形理解和推理能力具有挑戰性，且通常不完整。現有的基準主要著重於純粹的圖形理解，缺乏對所有圖形類型和詳細功能定義的全面評估。本文提出了 GraCoRe，一個用於系統評估 LLM 的圖形理解和推理的基準。GraCoRe 使用三層階層分類法對模型進行分類和測試，將功能細分為 10 個不同的領域，並通過 19 個任務進行測試。我們的基準包含 11 個數據集，其中包含 5,140 個不同複雜度的圖形。我們評估了三個閉源和七個開源 LLM，從能力和任務角度進行了徹底的分析。主要發現表明語義豐富化增強了推理性能，節點排序影響任務成功，而處理較長文本的能力並不一定能改善圖形理解或推理。GraCoRe 在 https://github.com/ZIKEYUAN/GraCoRe 開源

##### **Croppable Knowledge Graph Embedding**
2407.02779v1 by Yushan Zhu, Wen Zhang, Zhiqiang Liu, Mingyang Chen, Lei Liang, Huajun Chen

Knowledge Graph Embedding (KGE) is a common method for Knowledge Graphs (KGs)
to serve various artificial intelligence tasks. The suitable dimensions of the
embeddings depend on the storage and computing conditions of the specific
application scenarios. Once a new dimension is required, a new KGE model needs
to be trained from scratch, which greatly increases the training cost and
limits the efficiency and flexibility of KGE in serving various scenarios. In
this work, we propose a novel KGE training framework MED, through which we
could train once to get a croppable KGE model applicable to multiple scenarios
with different dimensional requirements, sub-models of the required dimensions
can be cropped out of it and used directly without any additional training. In
MED, we propose a mutual learning mechanism to improve the low-dimensional
sub-models performance and make the high-dimensional sub-models retain the
capacity that low-dimensional sub-models have, an evolutionary improvement
mechanism to promote the high-dimensional sub-models to master the knowledge
that the low-dimensional sub-models can not learn, and a dynamic loss weight to
balance the multiple losses adaptively. Experiments on 3 KGE models over 4
standard KG completion datasets, 3 real application scenarios over a real-world
large-scale KG, and the experiments of extending MED to the language model BERT
show the effectiveness, high efficiency, and flexible extensibility of MED.

摘要：知識圖嵌入 (KGE) 是知識圖 (KG) 用於服務各種人工智慧任務的常見方法。嵌入的適當維度取決於特定應用場景的儲存和運算條件。一旦需要新的維度，就需要從頭訓練新的 KGE 模型，這大大增加了訓練成本，並限制了 KGE 在服務各種場景中的效率和靈活性。在這項工作中，我們提出了一種新穎的 KGE 訓練框架 MED，通過它，我們可以訓練一次以獲得適用於具有不同維度需求的多個場景的可裁剪 KGE 模型，可以從中裁剪出所需維度的子模型並直接使用，而無需任何額外訓練。在 MED 中，我們提出了一種相互學習機制，以提高低維子模型的效能，並使高維子模型保留低維子模型具有的能力，一種進化改進機制，以促進高維子模型掌握低維子模型無法學習的知識，以及一種動態損失權重，以自適應地平衡多重損失。在 4 個標準 KG 完成資料集上的 3 個 KGE 模型、一個真實世界大規模 KG 上的 3 個實際應用場景以及將 MED 擴展到語言模型 BERT 的實驗中，展示了 MED 的有效性、高效率和靈活的可擴充性。

##### **Reasoning in Large Language Models: A Geometric Perspective**
2407.02678v1 by Romain Cosentino, Sarath Shekkizhar

The advancement of large language models (LLMs) for real-world applications
hinges critically on enhancing their reasoning capabilities. In this work, we
explore the reasoning abilities of large language models (LLMs) through their
geometrical understanding. We establish a connection between the expressive
power of LLMs and the density of their self-attention graphs. Our analysis
demonstrates that the density of these graphs defines the intrinsic dimension
of the inputs to the MLP blocks. We demonstrate through theoretical analysis
and toy examples that a higher intrinsic dimension implies a greater expressive
capacity of the LLM. We further provide empirical evidence linking this
geometric framework to recent advancements in methods aimed at enhancing the
reasoning capabilities of LLMs.

摘要：大型語言模型 (LLM) 在實際應用中的進展，關鍵在於提升其推理能力。在這項工作中，我們透過大型語言模型 (LLM) 的幾何理解，探討其推理能力。我們建立了 LLM 的表達能力與其自注意力圖密度之間的關聯。我們的分析證明，這些圖的密度定義了 MLP 塊輸入的內在維度。我們透過理論分析和玩具範例證明，較高的內在維度意味著 LLM 具有更大的表達能力。我們進一步提供經驗證據，將這個幾何框架連結到最近在旨在增強 LLM 推理能力的方法中取得的進展。

##### **Ensuring Responsible Sourcing of Large Language Model Training Data Through Knowledge Graph Comparison**
2407.02659v1 by Devam Mondal, Carlo Lipizzi

In light of recent plagiarism allegations Brough by publishers, newspapers,
and other creators of copyrighted corpora against large language model (LLM)
developers, we propose a novel system, a variant of a plagiarism detection
system, that assesses whether a knowledge source has been used in the training
or fine-tuning of a large language model. Unlike current methods, we utilize an
approach that uses Resource Description Framework (RDF) triples to create
knowledge graphs from both a source document and a LLM continuation of that
document. These graphs are then analyzed with respect to content using cosine
similarity and with respect to structure using a normalized version of graph
edit distance that shows the degree of isomorphism. Unlike traditional systems
that focus on content matching and keyword identification between a source and
target corpus, our approach enables a broader evaluation of similarity and thus
a more accurate comparison of the similarity between a source document and LLM
continuation by focusing on relationships between ideas and their organization
with regards to others. Additionally, our approach does not require access to
LLM metrics like perplexity that may be unavailable in closed large language
modeling "black-box" systems, as well as the training corpus. A prototype of
our system will be found on a hyperlinked GitHub repository.

摘要：鉴于出版商、报纸和其他受版权保护语料库的创造者最近对大型语言模型 (LLM) 开发者提出的剽窃指控，我们提出了一种新颖的系统，该系统是剽窃检测系统的一个变体，它评估知识源是否已用于大型语言模型的训练或微调。与当前方法不同，我们利用一种使用资源描述框架 (RDF) 三元组的方法从源文档和该文档的 LLM 延续中创建知识图谱。然后使用余弦相似性分析这些图谱的内容，并使用图编辑距离的标准化版本分析结构，该版本显示同构度。与专注于源语料库和目标语料库之间的内容匹配和关键词识别的传统系统不同，我们的方法能够对相似性进行更广泛的评估，从而更准确地比较源文档和 LLM 延续之间的相似性，方法是关注思想之间的关系以及它们与其他思想的关系。此外，我们的方法不需要访问 LLM 指标，例如困惑度，这些指标在封闭的大型语言建模“黑匣子”系统以及训练语料库中可能不可用。我们系统的原型将在超链接的 GitHub 存储库中找到。

##### **Multi-Peptide: Multimodality Leveraged Language-Graph Learning of Peptide Properties**
2407.03380v1 by Srivathsan Badrinarayanan, Chakradhar Guntuboina, Parisa Mollaei, Amir Barati Farimani

Peptides are essential in biological processes and therapeutics. In this
study, we introduce Multi-Peptide, an innovative approach that combines
transformer-based language models with Graph Neural Networks (GNNs) to predict
peptide properties. We combine PeptideBERT, a transformer model tailored for
peptide property prediction, with a GNN encoder to capture both sequence-based
and structural features. By employing Contrastive Language-Image Pre-training
(CLIP), Multi-Peptide aligns embeddings from both modalities into a shared
latent space, thereby enhancing the model's predictive accuracy. Evaluations on
hemolysis and nonfouling datasets demonstrate Multi-Peptide's robustness,
achieving state-of-the-art 86.185% accuracy in hemolysis prediction. This study
highlights the potential of multimodal learning in bioinformatics, paving the
way for accurate and reliable predictions in peptide-based research and
applications.

摘要：肽在生物過程和治療中至關重要。在此研究中，我們介紹了多肽，這是一種創新的方法，結合了基於轉換器的語言模型和圖神經網絡 (GNN) 來預測肽的性質。我們結合了專門用於肽性質預測的轉換器模型 PeptideBERT 和 GNN 編碼器，以捕獲基於序列和結構的特徵。通過採用對比語言圖像預訓練 (CLIP)，多肽將來自兩種模態的嵌入對齊到一個共享的潛在空間中，從而增強模型的預測準確度。對溶血和抗污數據集的評估證明了多肽的穩健性，在溶血預測中實現了最先進的 86.185% 準確率。本研究強調了生物信息學中多模態學習的潛力，為基於肽的研究和應用中的準確且可靠的預測鋪平了道路。

##### **Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification**
2407.02352v1 by Pritish Sahu, Karan Sikka, Ajay Divakaran

Large Visual Language Models (LVLMs) struggle with hallucinations in visual
instruction following task(s), limiting their trustworthiness and real-world
applicability. We propose Pelican -- a novel framework designed to detect and
mitigate hallucinations through claim verification. Pelican first decomposes
the visual claim into a chain of sub-claims based on first-order predicates.
These sub-claims consist of (predicate, question) pairs and can be
conceptualized as nodes of a computational graph. We then use
Program-of-Thought prompting to generate Python code for answering these
questions through flexible composition of external tools. Pelican improves over
prior work by introducing (1) intermediate variables for precise grounding of
object instances, and (2) shared computation for answering the sub-question to
enable adaptive corrections and inconsistency identification. We finally use
reasoning abilities of LLM to verify the correctness of the the claim by
considering the consistency and confidence of the (question, answer) pairs from
each sub-claim. Our experiments reveal a drop in hallucination rate by
$\sim$8%-32% across various baseline LVLMs and a 27% drop compared to
approaches proposed for hallucination mitigation on MMHal-Bench. Results on two
other benchmarks further corroborate our results.

摘要：大型视觉语言模型 (LVLMs) 在视觉指令遵循任务中会产生幻觉，这限制了它们的可靠性和现实世界的适用性。我们提出了 Pelican——一种旨在通过声明验证来检测和减轻幻觉的新型框架。Pelican 首先根据一阶谓词将视觉声明分解成一个子声明链。这些子声明由 (谓词、问题) 对组成，可以被概念化为计算图的节点。然后，我们使用思想计划提示来生成 Python 代码，通过外部工具的灵活组合来回答这些问题。Pelican 通过引入 (1) 用于对象实例精确接地的中间变量，以及 (2) 用于回答子问题以实现自适应校正和不一致性识别的共享计算，改进了之前的工作。我们最终使用 LLM 的推理能力，通过考虑每个子声明的 (问题、答案) 对的一致性和置信度来验证声明的正确性。我们的实验表明，在各种基线 LVLMs 中，幻觉率下降了约 8%-32%，与 MMHal-Bench 上提出的幻觉缓解方法相比，下降了 27%。在另外两个基准上的结果进一步证实了我们的结果。

##### **Is Your Large Language Model Knowledgeable or a Choices-Only Cheater?**
2407.01992v1 by Nishant Balepur, Rachel Rudinger

Recent work shows that large language models (LLMs) can answer
multiple-choice questions using only the choices, but does this mean that MCQA
leaderboard rankings of LLMs are largely influenced by abilities in
choices-only settings? To answer this, we use a contrast set that probes if
LLMs over-rely on choices-only shortcuts in MCQA. While previous works build
contrast sets via expensive human annotations or model-generated data which can
be biased, we employ graph mining to extract contrast sets from existing MCQA
datasets. We use our method on UnifiedQA, a group of six commonsense reasoning
datasets with high choices-only accuracy, to build an 820-question contrast
set. After validating our contrast set, we test 12 LLMs, finding that these
models do not exhibit reliance on choice-only shortcuts when given both the
question and choices. Thus, despite the susceptibility~of MCQA to high
choices-only accuracy, we argue that LLMs are not obtaining high ranks on MCQA
leaderboards just due to their ability to exploit choices-only shortcuts.

摘要：最近的研究表明，大型语言模型 (LLM) 仅使用选项就能回答多项选择题，但这是否表示多项选择问答 (MCQA) 排行榜上的 LLM 主要受限于仅选项设置中的能力？为了回答这个问题，我们使用对比集来探查 LLM 在 MCQA 中是否过度依赖仅选项捷径。虽然先前的研究通过昂贵的人工注释或可能存在偏差的模型生成数据来构建对比集，但我们采用图挖掘从现有 MCQA 数据集中提取对比集。我们使用我们的方法在 UnifiedQA 上，这是一个由六个具有高仅选项准确率的常识推理数据集组成的组，构建了一个 820 题的对比集。在验证我们的对比集后，我们测试了 12 个 LLM，发现当同时给出问题和选项时，这些模型不会表现出对仅选项捷径的依赖。因此，尽管 MCQA 容易受到高仅选项准确率的影响，但我们认为 LLM 在 MCQA 排行榜上获得高排名并非仅仅因为它们利用仅选项捷径的能力。

##### **CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents**
2407.01511v1 by Tianqi Xu, Linyao Chen, Dai-Jie Wu, Yanjun Chen, Zecheng Zhang, Xiang Yao, Zhiqiang Xie, Yongchao Chen, Shilong Liu, Bochen Qian, Philip Torr, Bernard Ghanem, Guohao Li

The development of autonomous agents increasingly relies on Multimodal
Language Models (MLMs) to perform tasks described in natural language with GUI
environments, such as websites, desktop computers, or mobile phones. Existing
benchmarks for MLM agents in interactive environments are limited by their
focus on a single environment, lack of detailed and generalized evaluation
methods, and the complexities of constructing tasks and evaluators. To overcome
these limitations, we introduce Crab, the first agent benchmark framework
designed to support cross-environment tasks, incorporating a graph-based
fine-grained evaluation method and an efficient mechanism for task and
evaluator construction. Our framework supports multiple devices and can be
easily extended to any environment with a Python interface. Leveraging Crab, we
developed a cross-platform Crab Benchmark-v0 comprising 100 tasks in computer
desktop and mobile phone environments. We evaluated four advanced MLMs using
different single and multi-agent system configurations on this benchmark. The
experimental results demonstrate that the single agent with GPT-4o achieves the
best completion ratio of 35.26%. All framework code, agent code, and task
datasets are publicly available at https://github.com/camel-ai/crab.

摘要：自主代理的開發越來越依賴多模態語言模型 (MLM)，以在具有 GUI 環境（例如網站、桌上型電腦或手機）的自然語言中執行任務。現有的互動環境中 MLM 代理的基準受到以下限制：它們專注於單一環境、缺乏詳細且通用的評估方法，以及建構任務和評估器的複雜性。為了克服這些限制，我們引入了 Crab，這是第一個代理基準架構，旨在支援跨環境任務，並結合了基於圖形的細粒度評估方法和任務與評估器建構的有效機制。我們的架構支援多種裝置，並且可以輕鬆地擴充到任何具有 Python 介面的環境。利用 Crab，我們開發了一個跨平台的 Crab Benchmark-v0，其中包含電腦桌上型電腦和手機環境中的 100 個任務。我們使用不同的單一和多代理系統配置，在這個基準上評估了四種先進的 MLM。實驗結果表明，具有 GPT-4o 的單一代理實現了 35.26% 的最佳完成率。所有架構程式碼、代理程式碼和任務資料集都公開於 https://github.com/camel-ai/crab。

##### **Dynamic Few-Shot Learning for Knowledge Graph Question Answering**
2407.01409v1 by Jacopo D'Abramo, Andrea Zugarini, Paolo Torroni

Large language models present opportunities for innovative Question Answering
over Knowledge Graphs (KGQA). However, they are not inherently designed for
query generation. To bridge this gap, solutions have been proposed that rely on
fine-tuning or ad-hoc architectures, achieving good results but limited
out-of-domain distribution generalization. In this study, we introduce a novel
approach called Dynamic Few-Shot Learning (DFSL). DFSL integrates the
efficiency of in-context learning and semantic similarity and provides a
generally applicable solution for KGQA with state-of-the-art performance. We
run an extensive evaluation across multiple benchmark datasets and architecture
configurations.

摘要：大型語言模型為知識圖譜（KGQA）的創新問答提供了機會。然而，它們並非天生就設計用於查詢生成。為了彌補這一差距，已提出依賴於微調或特定架構的解決方案，取得了良好的結果，但域外分佈泛化能力有限。在本研究中，我們引入了一種稱為動態小樣本學習（DFSL）的新方法。DFSL 集成了語境學習和語義相似性的效率，並為 KGQA 提供了一個普遍適用的解決方案，具有最先進的性能。我們對多個基準資料集和架構配置進行了廣泛的評估。

##### **Adapting Multilingual LLMs to Low-Resource Languages with Knowledge Graphs via Adapters**
2407.01406v1 by Daniil Gurgurov, Mareike Hartmann, Simon Ostermann

This paper explores the integration of graph knowledge from linguistic
ontologies into multilingual Large Language Models (LLMs) using adapters to
improve performance for low-resource languages (LRLs) in sentiment analysis
(SA) and named entity recognition (NER). Building upon successful
parameter-efficient fine-tuning techniques, such as K-ADAPTER and MAD-X, we
propose a similar approach for incorporating knowledge from multilingual
graphs, connecting concepts in various languages with each other through
linguistic relationships, into multilingual LLMs for LRLs. Specifically, we
focus on eight LRLs -- Maltese, Bulgarian, Indonesian, Nepali, Javanese,
Uyghur, Tibetan, and Sinhala -- and employ language-specific adapters
fine-tuned on data extracted from the language-specific section of ConceptNet,
aiming to enable knowledge transfer across the languages covered by the
knowledge graph. We compare various fine-tuning objectives, including standard
Masked Language Modeling (MLM), MLM with full-word masking, and MLM with
targeted masking, to analyse their effectiveness in learning and integrating
the extracted graph data. Through empirical evaluation on language-specific
tasks, we assess how structured graph knowledge affects the performance of
multilingual LLMs for LRLs in SA and NER, providing insights into the potential
benefits of adapting language models for low-resource scenarios.

摘要：這篇論文探討了使用適配器將語言本體論中的圖形知識整合到多語言大型語言模型 (LLM) 中，以改善低資源語言 (LRL) 在情緒分析 (SA) 和命名實體辨識 (NER) 中的效能。建立在成功的參數有效微調技術上，例如 K-ADAPTER 和 MAD-X，我們提出了一種類似的方法，用於將來自多語言圖形、透過語言關係將各種語言中的概念彼此連接的知識整合到 LRL 的多語言 LLM 中。具體來說，我們專注於八種 LRL——馬爾他語、保加利亞語、印尼語、尼泊爾語、爪哇語、維吾爾語、藏語和僧伽羅語——並使用針對從 ConceptNet 的語言特定部分中萃取的資料進行微調的語言特定適配器，旨在讓知識在知識圖形涵蓋的語言之間轉移。我們比較了各種微調目標，包括標準的遮罩語言模型 (MLM)、帶有全詞遮罩的 MLM 和帶有目標遮罩的 MLM，以分析它們在學習和整合萃取的圖形資料方面的有效性。透過對語言特定任務的經驗評估，我們評估了結構化的圖形知識如何影響多語言 LLM 在 SA 和 NER 中的效能，並深入了解了為低資源場景調整語言模型的潛在好處。

##### **SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model**
2407.01245v1 by Lingyue Fu, Hao Guan, Kounianhua Du, Jianghao Lin, Wei Xia, Weinan Zhang, Ruiming Tang, Yasheng Wang, Yong Yu

Knowledge Tracing (KT) aims to determine whether students will respond
correctly to the next question, which is a crucial task in intelligent tutoring
systems (ITS). In educational KT scenarios, transductive ID-based methods often
face severe data sparsity and cold start problems, where interactions between
individual students and questions are sparse, and new questions and concepts
consistently arrive in the database. In addition, existing KT models only
implicitly consider the correlation between concepts and questions, lacking
direct modeling of the more complex relationships in the heterogeneous graph of
concepts and questions. In this paper, we propose a Structure-aware Inductive
Knowledge Tracing model with large language model (dubbed SINKT), which, for
the first time, introduces large language models (LLMs) and realizes inductive
knowledge tracing. Firstly, SINKT utilizes LLMs to introduce structural
relationships between concepts and constructs a heterogeneous graph for
concepts and questions. Secondly, by encoding concepts and questions with LLMs,
SINKT incorporates semantic information to aid prediction. Finally, SINKT
predicts the student's response to the target question by interacting with the
student's knowledge state and the question representation. Experiments on four
real-world datasets demonstrate that SINKT achieves state-of-the-art
performance among 12 existing transductive KT models. Additionally, we explore
the performance of SINKT on the inductive KT task and provide insights into
various modules.

摘要：知識追蹤 (KT) 旨在判斷學生是否會正確回答下一個問題，這在智慧型教學系統 (ITS) 中是一項至關重要的任務。在教育 KT 場景中，基於轉導 ID 的方法通常會面臨嚴重的資料稀疏性和冷啟動問題，其中個別學生與問題之間的互動很稀少，而且新的問題和概念會持續出現在資料庫中。此外，現有的 KT 模型僅隱含地考慮概念和問題之間的關聯性，缺乏對概念和問題異質圖中更複雜關係的直接建模。在本文中，我們提出了一個具有大型語言模型的結構感知歸納知識追蹤模型 (稱為 SINKT)，該模型首次引入了大型語言模型 (LLM) 並實現了歸納知識追蹤。首先，SINKT 利用 LLM 來引入概念之間的結構關係，並為概念和問題構建一個異質圖。其次，透過使用 LLM 編碼概念和問題，SINKT 納入了語義資訊以協助預測。最後，SINKT 透過與學生的知識狀態和問題表示進行互動來預測學生對目標問題的回應。在四個真實世界資料集上的實驗表明，SINKT 在 12 個現有轉導 KT 模型中達到了最先進的效能。此外，我們探討了 SINKT 在歸納 KT 任務中的效能，並深入了解各種模組。

##### **Revisiting Random Walks for Learning on Graphs**
2407.01214v1 by Jinwoo Kim, Olga Zaghen, Ayhan Suleymanzade, Youngmin Ryou, Seunghoon Hong

We revisit a simple idea for machine learning on graphs, where a random walk
on a graph produces a machine-readable record, and this record is processed by
a deep neural network to directly make vertex-level or graph-level predictions.
We refer to these stochastic machines as random walk neural networks, and show
that we can design them to be isomorphism invariant while capable of universal
approximation of graph functions in probability. A useful finding is that
almost any kind of record of random walk guarantees probabilistic invariance as
long as the vertices are anonymized. This enables us to record random walks in
plain text and adopt a language model to read these text records to solve graph
tasks. We further establish a parallelism to message passing neural networks
using tools from Markov chain theory, and show that over-smoothing in message
passing is alleviated by construction in random walk neural networks, while
over-squashing manifests as probabilistic under-reaching. We show that random
walk neural networks based on pre-trained language models can solve several
hard problems on graphs, such as separating strongly regular graphs where the
3-WL test fails, counting substructures, and transductive classification on
arXiv citation network without training. Code is available at
https://github.com/jw9730/random-walk.

摘要：<paragraph>我們重新審視圖形機器學習的一個簡單想法，其中圖形上的隨機遊走會產生機器可讀的記錄，而這個記錄會由深度神經網路處理，以直接進行頂點層級或圖形層級的預測。我們將這些隨機機器稱為隨機遊走神經網路，並展示我們可以將它們設計成同構不變，同時具備機率中圖形函數的通用近似能力。一個有用的發現是，只要頂點是匿名的，幾乎任何類型的隨機遊走記錄都可以保證機率不變性。這使我們能夠以純文字記錄隨機遊走，並採用語言模型來讀取這些文字記錄，以解決圖形任務。我們進一步建立了一個與訊息傳遞神經網路的平行性，使用馬可夫鏈理論的工具，並展示訊息傳遞中的過度平滑會因隨機遊走神經網路中的構造而得到緩解，而過度壓縮則表現為機率性不足。我們展示了基於預先訓練語言模型的隨機遊走神經網路可以解決圖形上的幾個困難問題，例如分離 3-WL 測試失敗的強正則圖形、計算子結構，以及在 arXiv 引文網路中進行轉導分類，而無需訓練。程式碼可在 https://github.com/jw9730/random-walk 取得。</paragraph>

##### **LLM Uncertainty Quantification through Directional Entailment Graph and Claim Level Response Augmentation**
2407.00994v2 by Longchao Da, Tiejin Chen, Lu Cheng, Hua Wei

The Large language models (LLMs) have showcased superior capabilities in
sophisticated tasks across various domains, stemming from basic question-answer
(QA), they are nowadays used as decision assistants or explainers for
unfamiliar content. However, they are not always correct due to the data
sparsity in specific domain corpus, or the model's hallucination problems.
Given this, how much should we trust the responses from LLMs? This paper
presents a novel way to evaluate the uncertainty that captures the directional
instability, by constructing a directional graph from entailment probabilities,
and we innovatively conduct Random Walk Laplacian given the asymmetric property
of a constructed directed graph, then the uncertainty is aggregated by the
derived eigenvalues from the Laplacian process. We also provide a way to
incorporate the existing work's semantics uncertainty with our proposed layer.
Besides, this paper identifies the vagueness issues in the raw response set and
proposes an augmentation approach to mitigate such a problem, we conducted
extensive empirical experiments and demonstrated the superiority of our
proposed solutions.

摘要：大型語言模型 (LLM) 在各個領域的複雜任務中展現出卓越的能力，從基本的問答 (QA) 開始，它們現在被用作決策助理或不熟悉內容的說明者。然而，它們並不總是正確的，因為特定領域語料庫中的數據稀疏，或模型的幻覺問題。有鑑於此，我們應該多相信 LLM 的回應？本文提出了一種新的方法來評估捕捉方向不穩定性的不確定性，通過從蘊涵概率構造一個有向圖，並且我們創新地進行隨機遊走拉普拉斯算子，給定一個構造的有向圖的不對稱屬性，然後不確定性由拉普拉斯過程中的導出特徵值聚合。我們還提供了一種將現有工作的語義不確定性與我們提出的層結合起來的方法。此外，本文識別了原始回應集中模糊的問題，並提出了一種擴充方法來減輕這種問題，我們進行了廣泛的實證實驗，並展示了我們提出的解決方案的優越性。

##### **Actionable Cyber Threat Intelligence using Knowledge Graphs and Large Language Models**
2407.02528v1 by Romy Fieblinger, Md Tanvirul Alam, Nidhi Rastogi

Cyber threats are constantly evolving. Extracting actionable insights from
unstructured Cyber Threat Intelligence (CTI) data is essential to guide
cybersecurity decisions. Increasingly, organizations like Microsoft, Trend
Micro, and CrowdStrike are using generative AI to facilitate CTI extraction.
This paper addresses the challenge of automating the extraction of actionable
CTI using advancements in Large Language Models (LLMs) and Knowledge Graphs
(KGs). We explore the application of state-of-the-art open-source LLMs,
including the Llama 2 series, Mistral 7B Instruct, and Zephyr for extracting
meaningful triples from CTI texts. Our methodology evaluates techniques such as
prompt engineering, the guidance framework, and fine-tuning to optimize
information extraction and structuring. The extracted data is then utilized to
construct a KG, offering a structured and queryable representation of threat
intelligence. Experimental results demonstrate the effectiveness of our
approach in extracting relevant information, with guidance and fine-tuning
showing superior performance over prompt engineering. However, while our
methods prove effective in small-scale tests, applying LLMs to large-scale data
for KG construction and Link Prediction presents ongoing challenges.

摘要：網路威脅不斷演變。從非結構化的網路威脅情報 (CTI) 資料中萃取可採取行動的見解，對於引導網路安全決策至關重要。越來越多組織，例如 Microsoft、趨勢科技和 CrowdStrike，使用生成式 AI 來促進 CTI 萃取。本文探討了使用大型語言模型 (LLM) 和知識圖譜 (KG) 的進展，自動萃取可採取行動的 CTI 的挑戰。我們探討了最先進的開源 LLM 的應用，包括 Llama 2 系列、Mistral 7B Instruct 和 Zephyr，以從 CTI 文字中萃取有意義的三元組。我們的做法評估了提示工程、指導架構和微調等技術，以最佳化資訊萃取和結構化。然後，將萃取的資料用於建構 KG，提供威脅情報的結構化且可查詢的表示。實驗結果證明了我們方法在萃取相關資訊方面的有效性，指導和微調顯示出優於提示工程的效能。然而，雖然我們的做法在小規模測試中證明有效，但將 LLM 應用於大規模資料以進行 KG 建構和連結預測，仍存在持續的挑戰。

##### **Chain-of-Knowledge: Integrating Knowledge Reasoning into Large Language Models by Learning from Knowledge Graphs**
2407.00653v1 by Yifei Zhang, Xintao Wang, Jiaqing Liang, Sirui Xia, Lida Chen, Yanghua Xiao

Large Language Models (LLMs) have exhibited impressive proficiency in various
natural language processing (NLP) tasks, which involve increasingly complex
reasoning. Knowledge reasoning, a primary type of reasoning, aims at deriving
new knowledge from existing one.While it has been widely studied in the context
of knowledge graphs (KGs), knowledge reasoning in LLMs remains underexplored.
In this paper, we introduce Chain-of-Knowledge, a comprehensive framework for
knowledge reasoning, including methodologies for both dataset construction and
model learning. For dataset construction, we create KnowReason via rule mining
on KGs. For model learning, we observe rule overfitting induced by naive
training. Hence, we enhance CoK with a trial-and-error mechanism that simulates
the human process of internal knowledge exploration. We conduct extensive
experiments with KnowReason. Our results show the effectiveness of CoK in
refining LLMs in not only knowledge reasoning, but also general reasoning
benchmarkms.

摘要：大型語言模型 (LLM) 在各種自然語言處理 (NLP) 任務中展現出驚人的能力，這些任務涉及越來越複雜的推理。知識推理作為推理的主要類型，旨在從既有知識中推導出新知識。儘管知識推理已在知識圖譜 (KG) 的背景下得到廣泛研究，但 LLM 中的知識推理仍處於探索階段。在本文中，我們介紹了知識推理的綜合框架知識鏈，其中包括用於資料集構建和模型學習的方法。對於資料集構建，我們透過在 KG 中進行規則挖掘來建立 KnowReason。對於模型學習，我們觀察到由天真訓練引發的規則過度擬合。因此，我們使用模擬人類內部知識探索過程的試錯機制來增強 CoK。我們對 KnowReason 進行了廣泛的實驗。我們的結果顯示 CoK 在精煉 LLM 不僅在知識推理方面，還包括一般推理基準方面都非常有效。

##### **BioKGBench: A Knowledge Graph Checking Benchmark of AI Agent for Biomedical Science**
2407.00466v1 by Xinna Lin, Siqi Ma, Junjie Shan, Xiaojing Zhang, Shell Xu Hu, Tiannan Guo, Stan Z. Li, Kaicheng Yu

Pursuing artificial intelligence for biomedical science, a.k.a. AI Scientist,
draws increasing attention, where one common approach is to build a copilot
agent driven by Large Language Models (LLMs). However, to evaluate such
systems, people either rely on direct Question-Answering (QA) to the LLM
itself, or in a biomedical experimental manner. How to precisely benchmark
biomedical agents from an AI Scientist perspective remains largely unexplored.
To this end, we draw inspiration from one most important abilities of
scientists, understanding the literature, and introduce BioKGBench. In contrast
to traditional evaluation benchmark that only focuses on factual QA, where the
LLMs are known to have hallucination issues, we first disentangle
"Understanding Literature" into two atomic abilities, i) "Understanding" the
unstructured text from research papers by performing scientific claim
verification, and ii) Ability to interact with structured Knowledge-Graph
Question-Answering (KGQA) as a form of "Literature" grounding. We then
formulate a novel agent task, dubbed KGCheck, using KGQA and domain-based
Retrieval-Augmented Generation (RAG) to identify the factual errors of existing
large-scale knowledge graph databases. We collect over two thousand data for
two atomic tasks and 225 high-quality annotated data for the agent task.
Surprisingly, we discover that state-of-the-art agents, both daily scenarios
and biomedical ones, have either failed or inferior performance on our
benchmark. We then introduce a simple yet effective baseline, dubbed BKGAgent.
On the widely used popular knowledge graph, we discover over 90 factual errors
which provide scenarios for agents to make discoveries and demonstrate the
effectiveness of our approach. The code and data are available at
https://github.com/westlake-autolab/BioKGBench.

摘要：<paragraph>追求生物醫學科學的人工智慧，又稱 AI 科學家，
越來越受到關注，其中一種常見的方法是建立由大型語言模型 (LLM) 驅動的副駕駛代理。然而，要評估此類
系統，人們要么依賴 LLM 本身的直接問答 (QA)，要么依賴生物醫學實驗方式。如何從 AI 科學家的角度精確評量
生物醫學代理在很大程度上仍未探索。
為此，我們從科學家最重要的能力之一，即理解文獻中汲取靈感，並介紹 BioKGBench。與僅關注事實 QA 的傳統評量基準不同，已知 LLM 在事實 QA 中存在幻覺問題，我們首先將
「理解文獻」分解為兩種基本能力，i) 透過執行科學主張驗證來「理解」研究論文中的非結構化文字，以及 ii) 以「文獻」為基礎，與結構化的知識圖表問答 (KGQA) 互動的能力。然後
我們使用 KGQA 和基於網域的檢索擴充產生 (RAG) 制定了一項新穎的代理任務，稱為 KGCheck，以識別現有大型知識圖表資料庫的事實錯誤。我們為
兩個基本任務收集了兩千多個資料，以及 225 個高品質註解資料，以作為代理任務。令人驚訝的是，我們發現最先進的代理，無論是日常情境還是生物醫學，在我們的
基準上都表現不佳或表現較差。然後，我們引入了一個簡單但有效的基準，稱為 BKGAgent。在廣泛使用的熱門知識圖表上，我們發現超過 90 個事實錯誤，這些錯誤為代理提供了發現情境，並證明了我們方法的有效性。程式碼和資料可在
https://github.com/westlake-autolab/BioKGBench 取得。</paragraph>

##### **GraphArena: Benchmarking Large Language Models on Graph Computational Problems**
2407.00379v1 by Jianheng Tang, Qifan Zhang, Yuhan Li, Jia Li

The "arms race" of Large Language Models (LLMs) demands novel, challenging,
and diverse benchmarks to faithfully examine their progresses. We introduce
GraphArena, a benchmarking tool designed to evaluate LLMs on graph
computational problems using million-scale real-world graphs from diverse
scenarios such as knowledge graphs, social networks, and molecular structures.
GraphArena offers a suite of 10 computational tasks, encompassing four
polynomial-time (e.g., Shortest Distance) and six NP-complete challenges (e.g.,
Travelling Salesman Problem). It features a rigorous evaluation framework that
classifies LLM outputs as correct, suboptimal (feasible but not optimal), or
hallucinatory (properly formatted but infeasible). Evaluation of 10 leading
LLMs, including GPT-4o and LLaMA3-70B-Instruct, reveals that even
top-performing models struggle with larger, more complex graph problems and
exhibit hallucination issues. Despite the application of strategies such as
chain-of-thought prompting, these issues remain unresolved. GraphArena
contributes a valuable supplement to the existing LLM benchmarks and is
open-sourced at https://github.com/squareRoot3/GraphArena.

摘要：大型語言模型 (LLM) 的「軍備競賽」需要新穎、具挑戰性且多樣化的基準來忠實檢驗其進度。我們推出 GraphArena，這是一個基準工具，旨在使用來自知識圖譜、社交網路和分子結構等多樣化情境的數百萬個真實世界圖形，針對圖形計算問題評估 LLM。GraphArena 提供一系列 10 個計算任務，包含四個多項式時間（例如，最短距離）和六個 NP 完全挑戰（例如，旅行推銷員問題）。它具有一個嚴謹的評估架構，將 LLM 輸出分類為正確、次佳（可行但非最佳）或幻覺（格式正確但不可行）。對包括 GPT-4o 和 LLaMA3-70B-Instruct 在內的 10 個領先 LLM 的評估顯示，即使是效能最佳的模型在處理更大、更複雜的圖形問題時仍會遇到困難，並出現幻覺問題。儘管應用了一系列策略，例如思考鏈提示，這些問題仍未解決。GraphArena 為現有的 LLM 基準提供了有價值的補充，並在 https://github.com/squareRoot3/GraphArena 開源。

##### **Teola: Towards End-to-End Optimization of LLM-based Applications**
2407.00326v1 by Xin Tan, Yimin Jiang, Yitao Yang, Hong Xu

Large language model (LLM)-based applications consist of both LLM and non-LLM
components, each contributing to the end-to-end latency. Despite great efforts
to optimize LLM inference, end-to-end workflow optimization has been
overlooked. Existing frameworks employ coarse-grained orchestration with task
modules, which confines optimizations to within each module and yields
suboptimal scheduling decisions. We propose fine-grained end-to-end
orchestration, which utilizes task primitives as the basic units and represents
each query's workflow as a primitive-level dataflow graph. This explicitly
exposes a much larger design space, enables optimizations in parallelization
and pipelining across primitives of different modules, and enhances scheduling
to improve application-level performance. We build Teola, a novel orchestration
framework for LLM-based applications that implements this scheme. Comprehensive
experiments show that Teola can achieve up to 2.09x speedup over existing
systems across various popular LLM applications.

摘要：大型語言模型 (LLM) 應用程式由 LLM 和非 LLM 元件組成，每個元件都會影響端對端延遲。儘管已針對最佳化 LLM 推論做出許多努力，但端對端工作流程最佳化卻遭到忽略。現有架構採用粗略的編排與任務模組，將最佳化限制在每個模組內，並產生次佳的排程決策。我們提出細緻的端對端編排，它使用任務原語作為基本單位，並將每個查詢的工作流程表示為原語層級資料流圖。這明確地揭露了更大的設計空間，在不同模組的原語之間啟用平行化和管線最佳化，並加強排程以改善應用程式層級效能。我們建構 Teola，一個實作此架構的 LLM 應用程式創新編排架構。全面的實驗顯示，Teola 能在各種熱門 LLM 應用程式中，比現有系統快上 2.09 倍。

##### **Into the Unknown: Generating Geospatial Descriptions for New Environments**
2406.19967v1 by Tzuf Paz-Argaman, John Palowitch, Sayali Kulkarni, Reut Tsarfaty, Jason Baldridge

Similar to vision-and-language navigation (VLN) tasks that focus on bridging
the gap between vision and language for embodied navigation, the new Rendezvous
(RVS) task requires reasoning over allocentric spatial relationships
(independent of the observer's viewpoint) using non-sequential navigation
instructions and maps. However, performance substantially drops in new
environments with no training data. Using opensource descriptions paired with
coordinates (e.g., Wikipedia) provides training data but suffers from limited
spatially-oriented text resulting in low geolocation resolution. We propose a
large-scale augmentation method for generating high-quality synthetic data for
new environments using readily available geospatial data. Our method constructs
a grounded knowledge-graph, capturing entity relationships. Sampled entities
and relations (`shop north of school') generate navigation instructions via (i)
generating numerous templates using context-free grammar (CFG) to embed
specific entities and relations; (ii) feeding the entities and relation into a
large language model (LLM) for instruction generation. A comprehensive
evaluation on RVS, showed that our approach improves the 100-meter accuracy by
45.83% on unseen environments. Furthermore, we demonstrate that models trained
with CFG-based augmentation achieve superior performance compared with those
trained with LLM-based augmentation, both in unseen and seen environments.
These findings suggest that the potential advantages of explicitly structuring
spatial information for text-based geospatial reasoning in previously unknown,
can unlock data-scarce scenarios.

摘要：類似於專注於彌合具體導航中視覺與語言差距的視覺語言導航 (VLN) 任務，新的會面 (RVS) 任務需要使用非順序導航指令和地圖推理異中心空間關係（與觀察者的觀點無關）。然而，在沒有訓練資料的新環境中，效能會大幅下降。使用與座標配對的開源說明（例如，維基百科）提供了訓練資料，但由於空間導向文字有限，導致地理位置解析度低。我們提出了一種大規模擴充方法，使用現成的地理空間資料為新環境產生高品質的合成資料。我們的建構方法建立了一個基礎知識圖，擷取實體關係。取樣的實體和關係（「商店在學校北邊」）透過以下方式產生導航指令：(i) 使用無關乎語境的文法 (CFG) 產生許多範本來嵌入特定實體和關係；(ii) 將實體和關係輸入大型語言模型 (LLM) 以產生指令。在 RVS 上的全面評估顯示，我們的做法將未見過環境中的 100 公尺準確度提升了 45.83%。此外，我們證明使用基於 CFG 的擴充所訓練的模型，在未見過和見過環境中，都比使用基於 LLM 的擴充所訓練的模型獲得了更好的效能。這些發現表明，在以前未知的環境中，明確建構用於基於文字的地理空間推理的空間資訊的潛在優勢，可以解鎖資料稀少的場景。

##### **Investigating How Large Language Models Leverage Internal Knowledge to Perform Complex Reasoning**
2406.19502v1 by Miyoung Ko, Sue Hyun Park, Joonsuk Park, Minjoon Seo

Despite significant advancements, there is a limited understanding of how
large language models (LLMs) utilize knowledge for reasoning. To address this,
we propose a method that deconstructs complex real-world questions into a
graph, representing each question as a node with parent nodes of background
knowledge needed to solve the question. We develop the DepthQA dataset,
deconstructing questions into three depths: (i) recalling conceptual knowledge,
(ii) applying procedural knowledge, and (iii) analyzing strategic knowledge.
Based on a hierarchical graph, we quantify forward discrepancy, discrepancies
in LLMs' performance on simpler sub-problems versus complex questions. We also
measure backward discrepancy, where LLMs answer complex questions but struggle
with simpler ones. Our analysis shows that smaller models have more
discrepancies than larger models. Additionally, guiding models from simpler to
complex questions through multi-turn interactions improves performance across
model sizes, highlighting the importance of structured intermediate steps in
knowledge reasoning. This work enhances our understanding of LLM reasoning and
suggests ways to improve their problem-solving abilities.

摘要：儘管有顯著的進展，但對於大型語言模型 (LLM) 如何利用知識進行推理的理解仍然有限。為了解決這個問題，我們提出了一種方法，將複雜的真實世界問題解構成一個圖形，將每個問題表示為一個節點，其中包含解決問題所需的背景知識的父節點。我們開發了 DepthQA 資料集，將問題解構成三個深度：(i) 回憶概念知識，(ii) 應用程序知識，以及 (iii) 分析策略知識。基於一個階層圖形，我們量化了正向差異，LLM 在較簡單的子問題和複雜問題上的效能差異。我們也測量了反向差異，其中 LLM 能回答複雜問題，但在較簡單的問題上卻有困難。我們的分析顯示，較小的模型比較大的模型有更多的差異。此外，透過多回合互動引導模型從較簡單到複雜的問題，可以改善所有模型規模的效能，突顯了結構化中間步驟在知識推理中的重要性。這項工作增進了我們對 LLM 推理的理解，並提出了改善其問題解決能力的方法。

##### **Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment**
2406.19255v1 by Hao Fei, Shengqiong Wu, Meishan Zhang, Min Zhang, Tat-Seng Chua, Shuicheng Yan

While pre-training large-scale video-language models (VLMs) has shown
remarkable potential for various downstream video-language tasks, existing VLMs
can still suffer from certain commonly seen limitations, e.g., coarse-grained
cross-modal aligning , under-modeling of temporal dynamics, detached
video-language view. In this work, we target enhancing VLMs with a fine-grained
structural spatio-temporal alignment learning method (namely Finsta). First of
all, we represent the input texts and videos with fine-grained scene graph (SG)
structures, both of which are further unified into a holistic SG (HSG) for
bridging two modalities. Then, an SG-based framework is built, where the
textual SG (TSG) is encoded with a graph Transformer, while the video dynamic
SG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for
spatial and temporal feature propagation. A spatial-temporal Gaussian
differential graph Transformer is further devised to strengthen the sense of
the changes in objects across spatial and temporal dimensions. Next, based on
the fine-grained structural features of TSG and DSG, we perform object-centered
spatial alignment and predicate-centered temporal alignment respectively,
enhancing the video-language grounding in both the spatiality and temporality.
We design our method as a plug&play system, which can be integrated into
existing well-trained VLMs for further representation augmentation, without
training from scratch or relying on SG annotations in downstream applications.
On 6 representative VL modeling tasks over 12 datasets in both standard and
long-form video scenarios, Finsta consistently improves the existing 13
strong-performing VLMs persistently, and refreshes the current state-of-the-art
end task performance significantly in both the fine-tuning and zero-shot
settings.

摘要：<paragraph>雖然預訓練大型視訊語言模型 (VLM) 已展現出對各種下游視訊語言任務的顯著潛力，但現有的 VLM 仍可能受到某些常見限制的影響，例如粗粒度的跨模態對齊、對時間動態的建模不足、分離的視訊語言檢視。在這項工作中，我們以具備細粒度結構化時空對齊學習方法 (即 Finsta) 的增強 VLM 為目標。首先，我們以細粒度的場景圖 (SG) 結構表示輸入文字和視訊，兩者進一步統一到一個整體 SG (HSG) 中，以橋接兩個模態。然後，建立一個基於 SG 的框架，其中文字 SG (TSG) 使用圖形 Transformer 編碼，而視訊動態 SG (DSG) 和 HSG 則使用新穎的遞迴圖形 Transformer 建模，以進行空間和時間特徵傳播。進一步設計了一個時空高斯差分圖形 Transformer，以增強物體在時空維度中變化的感覺。接下來，根據 TSG 和 DSG 的細粒度結構特徵，我們分別執行以物件為中心的空間對齊和以謂詞為中心的時序對齊，增強視訊語言在空間和時間上的基礎。我們將方法設計為一個即插即用的系統，可以整合到現有的訓練良好的 VLM 中，以進一步擴充表示，而無需從頭開始訓練或依賴下游應用程式中的 SG 標註。在 12 個資料集上的 6 個代表性 VL 建模任務中，無論是在標準視訊場景還是長格式視訊場景中，Finsta 都持續改善現有的 13 個效能強大的 VLM，並在微調和零次學習設定中顯著更新目前的最新技術最終任務效能。</paragraph>

##### **TrustUQA: A Trustful Framework for Unified Structured Data Question Answering**
2406.18916v1 by Wen Zhang, Long Jin, Yushan Zhu, Jiaoyan Chen, Zhiwei Huang, Junjie Wang, Yin Hua, Lei Liang, Huajun Chen

Natural language question answering (QA) over structured data sources such as
tables and knowledge graphs (KGs) have been widely investigated, for example
with Large Language Models (LLMs). The main solutions include question to
formal query parsing and retrieval-based answer generation. However, current
methods of the former often suffer from weak generalization, failing to dealing
with multiple sources simultaneously, while the later is limited in
trustfulness. In this paper, we propose UnifiedTQA, a trustful QA framework
that can simultaneously support multiple types of structured data in a unified
way. To this end, it adopts an LLM-friendly and unified knowledge
representation method called Condition Graph (CG), and uses an LLM and
demonstration-based two-level method for CG querying. For enhancement, it is
also equipped with dynamic demonstration retrieval. We have evaluated
UnifiedTQA with 5 benchmarks covering 3 types of structured data. It
outperforms 2 existing unified structured data QA methods and in comparison
with the baselines that are specific to a data type, it achieves
state-of-the-art on 2 of them. Further more, we demonstrates potential of our
method for more general QA tasks, QA over mixed structured data and QA across
structured data.

摘要：自然語言問答 (QA) 透過結構化資料來源（例如表格和知識圖譜 (KGs)）已廣泛研究，例如使用大型語言模型 (LLM)。主要解決方案包括問題轉換成形式化查詢解析和基於檢索的答案產生。然而，前者的現行方法通常會產生弱泛化，無法同時處理多個來源，而後者則受到可信度的限制。在本文中，我們提出 UnifiedTQA，一個可信賴的 QA 框架，能夠以統一的方式同時支援多種類型的結構化資料。為此，它採用了一種 LLM 友善且統一的知識表示方法，稱為條件圖 (CG)，並使用 LLM 和基於示範的二階方法進行 CG 查詢。為了加強，它還配備了動態示範檢索。我們已經使用涵蓋 3 種類型結構化資料的 5 個基準評估 UnifiedTQA。它優於 2 種現有的統一結構化資料 QA 方法，並且與特定於資料類型的基線相比，它在其中 2 個基準上達到了最先進的水平。此外，我們展示了我們的方法在更通用的 QA 任務、混合結構化資料的 QA 和跨結構化資料的 QA 中的潛力。

##### **Fast Optimizer Benchmark**
2406.18701v1 by Simon Blauth, Tobias Bürger, Zacharias Häringer, Jörg Franke, Frank Hutter

In this paper, we present the Fast Optimizer Benchmark (FOB), a tool designed
for evaluating deep learning optimizers during their development. The benchmark
supports tasks from multiple domains such as computer vision, natural language
processing, and graph learning. The focus is on convenient usage, featuring
human-readable YAML configurations, SLURM integration, and plotting utilities.
FOB can be used together with existing hyperparameter optimization (HPO) tools
as it handles training and resuming of runs. The modular design enables
integration into custom pipelines, using it simply as a collection of tasks. We
showcase an optimizer comparison as a usage example of our tool. FOB can be
found on GitHub: https://github.com/automl/FOB.

摘要：在本文中，我們提出了快速優化器基準 (FOB)，這是一個用於在開發過程中評估深度學習優化器的工具。基準支持來自多個領域的任務，例如電腦視覺、自然語言處理和圖形學習。重點在於方便使用，具有人類可讀的 YAML 配置、SLURM 整合和繪圖程式。FOB 可以與現有的超參數優化 (HPO) 工具一起使用，因為它可以處理訓練和恢復運行。模組化設計能夠整合到自訂管線中，只需將其用作任務集合即可。我們展示了一個優化器比較作為我們工具的使用範例。FOB 可以從 GitHub 找到：https://github.com/automl/FOB。

##### **Cascading Large Language Models for Salient Event Graph Generation**
2406.18449v1 by Xingwei Tan, Yuxiang Zhou, Gabriele Pergola, Yulan He

Generating event graphs from long documents is challenging due to the
inherent complexity of multiple tasks involved such as detecting events,
identifying their relationships, and reconciling unstructured input with
structured graphs. Recent studies typically consider all events with equal
importance, failing to distinguish salient events crucial for understanding
narratives. This paper presents CALLMSAE, a CAscading Large Language Model
framework for SAlient Event graph generation, which leverages the capabilities
of LLMs and eliminates the need for costly human annotations. We first identify
salient events by prompting LLMs to generate summaries, from which salient
events are identified. Next, we develop an iterative code refinement prompting
strategy to generate event relation graphs, removing hallucinated relations and
recovering missing edges. Fine-tuning contextualised graph generation models on
the LLM-generated graphs outperforms the models trained on CAEVO-generated
data. Experimental results on a human-annotated test set show that the proposed
method generates salient and more accurate graphs, outperforming competitive
baselines.

摘要：由於涉及多項任務的內在複雜性，例如偵測事件、識別其關係，以及調和非結構化輸入與結構化圖表，因此從長篇文件產生事件圖表是一項挑戰。最近的研究通常將所有事件視為同等重要，未能區分對理解敘事至關重要的顯著事件。本文提出了 CALLMSAE，一個用於生成顯著事件圖表的層疊式大型語言模型框架，它利用了 LLM 的功能，並消除了對昂貴的人工標註的需求。我們首先透過提示 LLM 產生摘要來識別顯著事件，從中識別出顯著事件。接下來，我們開發了一種反覆的程式碼精煉提示策略來產生事件關係圖表，移除幻覺關係並恢復遺失的邊緣。在 LLM 生成的圖表上微調情境化圖表生成模型，其表現優於在 CAEVO 生成的資料上訓練的模型。在人工標註的測試集上的實驗結果顯示，所提出的方法產生了顯著且更準確的圖表，優於競爭性的基準。

##### **Sanskrit Knowledge-based Systems: Annotation and Computational Tools**
2406.18276v1 by Hrishikesh Terdalkar

We address the challenges and opportunities in the development of knowledge
systems for Sanskrit, with a focus on question answering. By proposing a
framework for the automated construction of knowledge graphs, introducing
annotation tools for ontology-driven and general-purpose tasks, and offering a
diverse collection of web-interfaces, tools, and software libraries, we have
made significant contributions to the field of computational Sanskrit. These
contributions not only enhance the accessibility and accuracy of Sanskrit text
analysis but also pave the way for further advancements in knowledge
representation and language processing. Ultimately, this research contributes
to the preservation, understanding, and utilization of the rich linguistic
information embodied in Sanskrit texts.

摘要：我們著手解決梵語知識系統開發中的挑戰和機會，重點在於問題解答。透過提出一個用於自動建構知識圖譜的架構，導入用於本體驅動和一般用途任務的註解工具，並提供多樣化的網路介面、工具和軟體函式庫，我們對計算梵語領域做出了重大貢獻。這些貢獻不僅增強了梵語文本分析的可存取性和準確性，也為知識表徵和語言處理的進一步進展鋪平了道路。最終，這項研究有助於保存、理解和利用梵語文本中蘊含的豐富語言資訊。

##### **Multilingual Knowledge Graph Completion from Pretrained Language Models with Knowledge Constraints**
2406.18085v1 by Ran Song, Shizhu He, Shengxiang Gao, Li Cai, Kang Liu, Zhengtao Yu, Jun Zhao

Multilingual Knowledge Graph Completion (mKGC) aim at solving queries like
(h, r, ?) in different languages by reasoning a tail entity t thus improving
multilingual knowledge graphs. Previous studies leverage multilingual
pretrained language models (PLMs) and the generative paradigm to achieve mKGC.
Although multilingual pretrained language models contain extensive knowledge of
different languages, its pretraining tasks cannot be directly aligned with the
mKGC tasks. Moreover, the majority of KGs and PLMs currently available exhibit
a pronounced English-centric bias. This makes it difficult for mKGC to achieve
good results, particularly in the context of low-resource languages. To
overcome previous problems, this paper introduces global and local knowledge
constraints for mKGC. The former is used to constrain the reasoning of answer
entities, while the latter is used to enhance the representation of query
contexts. The proposed method makes the pretrained model better adapt to the
mKGC task. Experimental results on public datasets demonstrate that our method
outperforms the previous SOTA on Hits@1 and Hits@10 by an average of 12.32% and
16.03%, which indicates that our proposed method has significant enhancement on
mKGC.

摘要：多語言知識圖譜完成 (mKGC) 旨在透過推理尾部實體 t 來解決不同語言中的查詢，例如 (h, r, ?)，進而改善多語言知識圖譜。先前的研究利用多語言預訓練語言模型 (PLM) 和生成範例來達成 mKGC。儘管多語言預訓練語言模型包含不同語言的廣泛知識，但其預訓練任務無法直接與 mKGC 任務對齊。此外，目前大多數的知識圖譜和 PLM 都展現出明顯的英語中心偏誤。這使得 mKGC 難以達成良好的結果，特別是在低資源語言的脈絡中。為了克服先前的問題，本文針對 mKGC 引入了全域與局部知識限制。前者用於限制答案實體的推理，而後者用於加強查詢脈絡的表示。所提出的方法使得預訓練模型能更好地適應 mKGC 任務。公開資料集上的實驗結果顯示，我們的模型在 Hits@1 和 Hits@10 上平均優於先前的 SOTA 12.32% 和 16.03%，這表示我們提出的方法顯著地增強了 mKGC。

##### **AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning**
2406.18060v1 by Yifan Yang, Kai Zhen, Ershad Banijamal, Athanasios Mouchtaris, Zheng Zhang

Fine-tuning large language models (LLMs) has achieved remarkable performance
across various natural language processing tasks, yet it demands more and more
memory as model sizes keep growing. To address this issue, the recently
proposed Memory-efficient Zeroth-order (MeZO) methods attempt to fine-tune LLMs
using only forward passes, thereby avoiding the need for a backpropagation
graph. However, significant performance drops and a high risk of divergence
have limited their widespread adoption. In this paper, we propose the Adaptive
Zeroth-order Tensor-Train Adaption (AdaZeta) framework, specifically designed
to improve the performance and convergence of the ZO methods. To enhance
dimension-dependent ZO estimation accuracy, we introduce a fast-forward,
low-parameter tensorized adapter. To tackle the frequently observed divergence
issue in large-scale ZO fine-tuning tasks, we propose an adaptive query number
schedule that guarantees convergence. Detailed theoretical analysis and
extensive experimental results on Roberta-Large and Llama-2-7B models
substantiate the efficacy of our AdaZeta framework in terms of accuracy, memory
efficiency, and convergence speed.

摘要：微调大型语言模型 (LLM) 在各种自然语言处理任务中取得了显著的性能，但随着模型规模的不断扩大，它对内存的需求也越来越大。为了解决这个问题，最近提出的内存高效零阶 (MeZO) 方法试图仅使用前向传递来微调 LLM，从而避免了对反向传播图的需求。然而，严重的性能下降和发散的高风险限制了它们的广泛采用。在本文中，我们提出了自适应零阶张量训练自适应 (AdaZeta) 框架，专门设计用于提高 ZO 方法的性能和收敛性。为了增强维度相关的 ZO 估计精度，我们引入了一个快速前向、低参数张量化适配器。为了解决在大规模 ZO 微调任务中经常观察到的发散问题，我们提出了一个自适应查询数量计划，以保证收敛性。对 Roberta-Large 和 Llama-2-7B 模型的详细理论分析和广泛的实验结果证明了我们的 AdaZeta 框架在准确性、内存效率和收敛速度方面的有效性。

##### **DARG: Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph**
2406.17271v1 by Zhehao Zhang, Jiaao Chen, Diyi Yang

The current paradigm of evaluating Large Language Models (LLMs) through
static benchmarks comes with significant limitations, such as vulnerability to
data contamination and a lack of adaptability to the evolving capabilities of
LLMs. Therefore, evaluation methods that can adapt and generate evaluation data
with controlled complexity are urgently needed. In this work, we introduce
Dynamic Evaluation of LLMs via Adaptive Reasoning Graph Evolvement (DARG) to
dynamically extend current benchmarks with controlled complexity and diversity.
Specifically, we first extract the reasoning graphs of data points in current
benchmarks and then perturb the reasoning graphs to generate novel testing
data. Such newly generated test samples can have different levels of complexity
while maintaining linguistic diversity similar to the original benchmarks. We
further use a code-augmented LLM to ensure the label correctness of newly
generated data. We apply our DARG framework to diverse reasoning tasks in four
domains with 15 state-of-the-art LLMs. Experimental results show that almost
all LLMs experience a performance decrease with increased complexity and
certain LLMs exhibit significant drops. Additionally, we find that LLMs exhibit
more biases when being evaluated via the data generated by DARG with higher
complexity levels. These observations provide useful insights into how to
dynamically and adaptively evaluate LLMs. The code is available at
https://github.com/SALT-NLP/DARG.

摘要：目前透過靜態基準評估大型語言模型 (LLM) 的範例伴隨著顯著的限制，例如容易受到資料污染，以及缺乏適應 LLM 不斷演進的能力。因此，迫切需要能夠適應並產生具有受控複雜性的評估資料的評估方法。在這項工作中，我們透過自適應推理圖形演化 (DARG) 引入 LLM 的動態評估，以動態延伸目前具有受控複雜性和多樣性的基準。具體來說，我們首先擷取目前基準中資料點的推理圖形，然後擾動推理圖形以產生新的測試資料。這些新產生的測試樣本可以有不同的複雜性層級，同時維持與原始基準類似的語言多樣性。我們進一步使用程式碼增強的 LLM 來確保新產生資料的標籤正確性。我們將 DARG 架構套用於四個領域中的各種推理任務，並使用 15 個最先進的 LLM。實驗結果顯示，幾乎所有 LLM 在複雜性增加的情況下都會出現效能下降，而某些 LLM 則表現出顯著的下降。此外，我們發現 LLM 在透過 DARG 產生具有較高複雜性層級的資料進行評估時，會表現出更多偏差。這些觀察結果提供了有用的見解，說明如何動態且自適應地評估 LLM。程式碼可在 https://github.com/SALT-NLP/DARG 取得。

##### **CogMG: Collaborative Augmentation Between Large Language Model and Knowledge Graph**
2406.17231v1 by Tong Zhou, Yubo Chen, Kang Liu, Jun Zhao

Large language models have become integral to question-answering applications
despite their propensity for generating hallucinations and factually inaccurate
content. Querying knowledge graphs to reduce hallucinations in LLM meets the
challenge of incomplete knowledge coverage in knowledge graphs. On the other
hand, updating knowledge graphs by information extraction and knowledge graph
completion faces the knowledge update misalignment issue. In this work, we
introduce a collaborative augmentation framework, CogMG, leveraging knowledge
graphs to address the limitations of LLMs in QA scenarios, explicitly targeting
the problems of incomplete knowledge coverage and knowledge update
misalignment. The LLMs identify and decompose required knowledge triples that
are not present in the KG, enriching them and aligning updates with real-world
demands. We demonstrate the efficacy of this approach through a supervised
fine-tuned LLM within an agent framework, showing significant improvements in
reducing hallucinations and enhancing factual accuracy in QA responses. Our
code and video are publicly available.

摘要：大型語言模型已成為問答應用程式中不可或缺的一部分，儘管它們傾向於產生幻覺和事實不正確的內容。查詢知識圖表以減少 LLM 中的幻覺會遇到知識圖表中知識覆蓋不完整的挑戰。另一方面，通過資訊萃取和知識圖表完成來更新知識圖表會面臨知識更新錯位問題。在這項工作中，我們引入了協作擴充架構 CogMG，利用知識圖表來解決 LLM 在 QA 場景中的限制，明確針對不完整的知識覆蓋和知識更新錯位問題。LLM 識別並分解 KG 中不存在的所需知識三元組，豐富它們並將更新與現實世界的需求保持一致。我們透過代理架構中監督微調的 LLM 展示了這種方法的功效，顯示出在減少幻覺和增強 QA 回應中的事實準確性方面有顯著的改進。我們的程式碼和影片公開提供。

##### **Link Prediction with Untrained Message Passing Layers**
2406.16687v1 by Lisi Qarkaxhija, Anatol E. Wegner, Ingo Scholtes

Message passing neural networks (MPNNs) operate on graphs by exchanging
information between neigbouring nodes. MPNNs have been successfully applied to
various node-, edge-, and graph-level tasks in areas like molecular science,
computer vision, natural language processing, and combinatorial optimization.
However, most MPNNs require training on large amounts of labeled data, which
can be costly and time-consuming. In this work, we explore the use of various
untrained message passing layers in graph neural networks, i.e. variants of
popular message passing architecture where we remove all trainable parameters
that are used to transform node features in the message passing step. Focusing
on link prediction, we find that untrained message passing layers can lead to
competitive and even superior performance compared to fully trained MPNNs,
especially in the presence of high-dimensional features. We provide a
theoretical analysis of untrained message passing by relating the inner
products of features implicitly produced by untrained message passing layers to
path-based topological node similarity measures. As such, untrained message
passing architectures can be viewed as a highly efficient and interpretable
approach to link prediction.

摘要：訊息傳遞神經網路 (MPNN) 透過交換鄰近節點之間的資訊來處理圖形。MPNN 已成功應用於各種節點、邊緣和圖形層級的任務，例如分子科學、電腦視覺、自然語言處理和組合最佳化。然而，大多數 MPNN 需要大量標籤資料才能進行訓練，這可能會很昂貴且耗時。在這項工作中，我們探討了在圖形神經網路中使用各種未訓練的訊息傳遞層，也就是說，我們移除了所有用於在訊息傳遞步驟中轉換節點特徵的可訓練參數，這是熱門訊息傳遞架構的變體。專注於連結預測，我們發現未訓練的訊息傳遞層可以產生具有競爭力，甚至優於完全訓練的 MPNN 的效能，尤其是在存在高維特徵的情況下。我們透過將未訓練的訊息傳遞層隱含產生的特徵的內積與基於路徑的拓撲節點相似度測量關聯，提供未訓練訊息傳遞的理論分析。因此，未訓練的訊息傳遞架構可以視為一種高度有效且可解釋的連結預測方法。

##### **CLEAR: Can Language Models Really Understand Causal Graphs?**
2406.16605v1 by Sirui Chen, Mengying Xu, Kun Wang, Xingyu Zeng, Rui Zhao, Shengjie Zhao, Chaochao Lu

Causal reasoning is a cornerstone of how humans interpret the world. To model
and reason about causality, causal graphs offer a concise yet effective
solution. Given the impressive advancements in language models, a crucial
question arises: can they really understand causal graphs? To this end, we
pioneer an investigation into language models' understanding of causal graphs.
Specifically, we develop a framework to define causal graph understanding, by
assessing language models' behaviors through four practical criteria derived
from diverse disciplines (e.g., philosophy and psychology). We then develop
CLEAR, a novel benchmark that defines three complexity levels and encompasses
20 causal graph-based tasks across these levels. Finally, based on our
framework and benchmark, we conduct extensive experiments on six leading
language models and summarize five empirical findings. Our results indicate
that while language models demonstrate a preliminary understanding of causal
graphs, significant potential for improvement remains. Our project website is
at https://github.com/OpenCausaLab/CLEAR.

摘要：因果推理是人類詮釋世界的基石。為了對因果關係建模和推理，因果圖提供了一個簡潔而有效的解決方案。鑑於語言模型的驚人進步，一個關鍵問題出現了：它們真的能理解因果圖嗎？為此，我們率先對語言模型對因果圖的理解進行了調查。具體來說，我們開發了一個框架來定義因果圖理解，通過從不同學科（例如哲學和心理學）衍生的四個實用標準來評估語言模型的行為。然後，我們開發了 CLEAR，一個新的基準，它定義了三個複雜性級別，並涵蓋了這些級別中的 20 個基於因果圖的任務。最後，基於我們的框架和基準，我們對六個領先的語言模型進行了廣泛的實驗，並總結了五項實證發現。我們的結果表明，儘管語言模型展示了對因果圖的初步理解，但仍有很大的改進潛力。我們的項目網站位於 https://github.com/OpenCausaLab/CLEAR。

##### **KEHRL: Learning Knowledge-Enhanced Language Representations with Hierarchical Reinforcement Learning**
2406.16374v1 by Dongyang Li, Taolin Zhang, Longtao Huang, Chengyu Wang, Xiaofeng He, Hui Xue

Knowledge-enhanced pre-trained language models (KEPLMs) leverage relation
triples from knowledge graphs (KGs) and integrate these external data sources
into language models via self-supervised learning. Previous works treat
knowledge enhancement as two independent operations, i.e., knowledge injection
and knowledge integration. In this paper, we propose to learn
Knowledge-Enhanced language representations with Hierarchical Reinforcement
Learning (KEHRL), which jointly addresses the problems of detecting positions
for knowledge injection and integrating external knowledge into the model in
order to avoid injecting inaccurate or irrelevant knowledge. Specifically, a
high-level reinforcement learning (RL) agent utilizes both internal and prior
knowledge to iteratively detect essential positions in texts for knowledge
injection, which filters out less meaningful entities to avoid diverting the
knowledge learning direction. Once the entity positions are selected, a
relevant triple filtration module is triggered to perform low-level RL to
dynamically refine the triples associated with polysemic entities through
binary-valued actions. Experiments validate KEHRL's effectiveness in probing
factual knowledge and enhancing the model's performance on various natural
language understanding tasks.

摘要：知識增強預訓練語言模型 (KEPLM) 利用知識圖譜 (KG) 中的關聯三元組，並透過自我監督式學習將這些外部資料來源整合到語言模型中。先前的研究將知識增強視為兩個獨立的操作，即知識注入和知識整合。在本文中，我們建議使用分層強化學習 (KEHRL) 學習知識增強語言表徵，這共同解決了偵測知識注入位置和將外部知識整合到模型中的問題，以避免注入不準確或不相關的知識。具體來說，高階強化學習 (RL) 代理使用內部和先驗知識，反覆偵測文字中知識注入的重要位置，這會過濾掉較不重要的實體，以避免轉移知識學習方向。一旦選定實體位置，就會觸發相關的三元組過濾模組，透過二進制動作動態精煉與多義實體相關的三元組。實驗驗證了 KEHRL 在探查事實知識和增強模型在各種自然語言理解任務上的效能。

##### **Prompt-Consistency Image Generation (PCIG): A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models**
2406.16333v1 by Yichen Sun, Zhixuan Chu, Zhan Qin, Kui Ren

The rapid advancement of Text-to-Image(T2I) generative models has enabled the
synthesis of high-quality images guided by textual descriptions. Despite this
significant progress, these models are often susceptible in generating contents
that contradict the input text, which poses a challenge to their reliability
and practical deployment. To address this problem, we introduce a novel
diffusion-based framework to significantly enhance the alignment of generated
images with their corresponding descriptions, addressing the inconsistency
between visual output and textual input. Our framework is built upon a
comprehensive analysis of inconsistency phenomena, categorizing them based on
their manifestation in the image. Leveraging a state-of-the-art large language
module, we first extract objects and construct a knowledge graph to predict the
locations of these objects in potentially generated images. We then integrate a
state-of-the-art controllable image generation model with a visual text
generation module to generate an image that is consistent with the original
prompt, guided by the predicted object locations. Through extensive experiments
on an advanced multimodal hallucination benchmark, we demonstrate the efficacy
of our approach in accurately generating the images without the inconsistency
with the original prompt. The code can be accessed via
https://github.com/TruthAI-Lab/PCIG.

摘要：文本到图像 (T2I) 生成模型的快速进步使得合成由文本描述引导的高质量图像成为可能。尽管取得了这些重大进展，但这些模型在生成与输入文本相矛盾的内容方面通常很敏感，这对它们的可靠性和实际部署提出了挑战。为了解决这个问题，我们引入了一个新颖的基于扩散的框架，以显着增强生成图像与其相应描述的一致性，解决视觉输出和文本输入之间的不一致性。我们的框架建立在对不一致现象的全面分析之上，根据它们在图像中的表现对它们进行分类。利用最先进的大型语言模块，我们首先提取对象并构建知识图谱来预测这些对象在潜在生成的图像中的位置。然后，我们将最先进的可控图像生成模型与视觉文本生成模块集成在一起，以生成与原始提示一致的图像，并由预测的对象位置引导。通过在高级多模态幻觉基准上进行广泛的实验，我们展示了我们的方法在准确生成图像方面的有效性，而不会与原始提示不一致。可以通过 https://github.com/TruthAI-Lab/PCIG 访问代码。

##### **Graph-Augmented LLMs for Personalized Health Insights: A Case Study in Sleep Analysis**
2406.16252v2 by Ajan Subramanian, Zhongqi Yang, Iman Azimi, Amir M. Rahmani

Health monitoring systems have revolutionized modern healthcare by enabling
the continuous capture of physiological and behavioral data, essential for
preventive measures and early health intervention. While integrating this data
with Large Language Models (LLMs) has shown promise in delivering interactive
health advice, traditional methods like Retrieval-Augmented Generation (RAG)
and fine-tuning often fail to fully utilize the complex, multi-dimensional, and
temporally relevant data from wearable devices. These conventional approaches
typically provide limited actionable and personalized health insights due to
their inadequate capacity to dynamically integrate and interpret diverse health
data streams. In response, this paper introduces a graph-augmented LLM
framework designed to significantly enhance the personalization and clarity of
health insights. Utilizing a hierarchical graph structure, the framework
captures inter and intra-patient relationships, enriching LLM prompts with
dynamic feature importance scores derived from a Random Forest Model. The
effectiveness of this approach is demonstrated through a sleep analysis case
study involving 20 college students during the COVID-19 lockdown, highlighting
the potential of our model to generate actionable and personalized health
insights efficiently. We leverage another LLM to evaluate the insights for
relevance, comprehensiveness, actionability, and personalization, addressing
the critical need for models that process and interpret complex health data
effectively. Our findings show that augmenting prompts with our framework
yields significant improvements in all 4 criteria. Through our framework, we
can elicit well-crafted, more thoughtful responses tailored to a specific
patient.

摘要：健康監控系統透過持續收集生理和行為資料，徹底改變了現代醫療保健，這些資料對於預防措施和早期健康干預至關重要。雖然將這些資料與大型語言模型 (LLM) 整合，已展現出提供互動式健康建議的潛力，但傳統方法（例如檢索擴充生成 (RAG) 和微調）通常無法充分利用穿戴式裝置中複雜、多面向且與時間相關的資料。這些傳統方法通常會提供有限的可行且個人化的健康見解，因為它們無法動態整合和詮釋不同的健康資料串流。為了解決這個問題，本文介紹了一個圖形擴充 LLM 架構，旨在大幅提升健康見解的個人化和清晰度。這個架構利用階層式圖形結構，擷取患者之間和患者內部的關係，並使用從 Random Forest 模型衍生的動態特徵重要性評分，豐富 LLM 提示。透過一項睡眠分析案例研究（在 COVID-19 封鎖期間針對 20 名大學生進行）證明了這個方法的有效性，突顯了我們的模型在有效產生可行且個人化的健康見解方面的潛力。我們利用另一個 LLM 評估見解的相關性、全面性、可行性和個人化，滿足了模型有效處理和詮釋複雜健康資料的關鍵需求。我們的研究結果顯示，使用我們的架構擴充提示，可以在所有 4 個標準中大幅改善。透過我們的架構，我們可以引發精心設計、更周全的回應，針對特定患者量身打造。

##### **GraphEval2000: Benchmarking and Improving Large Language Models on Graph Datasets**
2406.16176v1 by Qiming Wu, Zichen Chen, Will Corcoran, Misha Sra, Ambuj K. Singh

Large language models (LLMs) have achieved remarkable success in natural
language processing (NLP), demonstrating significant capabilities in processing
and understanding text data. However, recent studies have identified
limitations in LLMs' ability to reason about graph-structured data. To address
this gap, we introduce GraphEval2000, the first comprehensive graph dataset,
comprising 40 graph data structure problems along with 2000 test cases.
Additionally, we introduce an evaluation framework based on GraphEval2000,
designed to assess the graph reasoning abilities of LLMs through coding
challenges. Our dataset categorizes test cases into four primary and four
sub-categories, ensuring a comprehensive evaluation. We evaluate eight popular
LLMs on GraphEval2000, revealing that LLMs exhibit a better understanding of
directed graphs compared to undirected ones. While private LLMs consistently
outperform open-source models, the performance gap is narrowing. Furthermore,
to improve the usability of our evaluation framework, we propose Structured
Symbolic Decomposition (SSD), an instruction-based method designed to enhance
LLM performance on GraphEval2000. Results show that SSD improves the
performance of GPT-3.5, GPT-4, and GPT-4o on complex graph problems, with an
increase of 11.11\%, 33.37\%, and 33.37\%, respectively.

摘要：大型語言模型 (LLM) 在自然語言處理 (NLP) 中取得了顯著的成功，在處理和理解文本數據方面表現出顯著的能力。然而，最近的研究發現 LLM 在推理圖形結構數據的能力方面存在局限性。為了解決這個差距，我們引入了 GraphEval2000，第一個全面的圖形數據集，包含 40 個圖形數據結構問題以及 2000 個測試用例。此外，我們還引入了基於 GraphEval2000 的評估框架，旨在通過編碼挑戰評估 LLM 的圖形推理能力。我們的數據集將測試用例分為四個主要類別和四個子類別，確保進行全面的評估。我們在 GraphEval2000 上評估了八個流行的 LLM，結果表明，與無向圖相比，LLM 對有向圖的理解更好。雖然私有 LLM 持續優於開源模型，但性能差距正在縮小。此外，為了提高我們評估框架的可用性，我們提出了結構化符號分解 (SSD)，一種基於指令的方法，旨在增強 LLM 在 GraphEval2000 上的性能。結果表明，SSD 分別提高了 GPT-3.5、GPT-4 和 GPT-4o 在複雜圖形問題上的性能，分別增加了 11.11%、33.37% 和 33.37%。

##### **Can LLM Graph Reasoning Generalize beyond Pattern Memorization?**
2406.15992v1 by Yizhuo Zhang, Heng Wang, Shangbin Feng, Zhaoxuan Tan, Xiaochuang Han, Tianxing He, Yulia Tsvetkov

Large language models (LLMs) demonstrate great potential for problems with
implicit graphical structures, while recent works seek to enhance the graph
reasoning capabilities of LLMs through specialized instruction tuning. The
resulting 'graph LLMs' are evaluated with in-distribution settings only, thus
it remains underexplored whether LLMs are learning generalizable graph
reasoning skills or merely memorizing patterns in the synthetic training data.
To this end, we propose the NLGift benchmark, an evaluation suite of LLM graph
reasoning generalization: whether LLMs could go beyond semantic, numeric,
structural, reasoning patterns in the synthetic training data and improve
utility on real-world graph-based tasks. Extensive experiments with two LLMs
across four graph reasoning tasks demonstrate that while generalization on
simple patterns (semantic, numeric) is somewhat satisfactory, LLMs struggle to
generalize across reasoning and real-world patterns, casting doubt on the
benefit of synthetic graph tuning for real-world tasks with underlying network
structures. We explore three strategies to improve LLM graph reasoning
generalization, and we find that while post-training alignment is most
promising for real-world tasks, empowering LLM graph reasoning to go beyond
pattern memorization remains an open research question.

摘要：大型語言模型 (LLM) 對於具有隱式圖形結構的問題展現出巨大的潛力，而近期研究則透過專業指令調整來增強 LLM 的圖形推理能力。由此產生的「圖形 LLM」僅在分布內設定中進行評估，因此 LLM 是否學習到可概括的圖形推理技能，或僅僅記憶合成訓練資料中的模式，仍未獲得充分探討。為此，我們提出 NLGift 基準，這是一個 LLM 圖形推理概括評估套件：LLM 是否可以超越合成訓練資料中的語義、數值、結構推理模式，並提升在真實世界基於圖形的任務中的效用。透過兩個 LLM 在四個圖形推理任務中的廣泛實驗證明，儘管在簡單模式（語義、數值）上的概括令人滿意，但 LLM 難以在推理和真實世界模式中概括，對合成圖形調整對於具有基礎網路結構的真實世界任務的益處提出質疑。我們探討了三種策略來改善 LLM 圖形推理概括，我們發現，儘管訓練後對齊對真實世界任務最有希望，但賦能 LLM 圖形推理以超越模式記憶仍然是一個開放的研究問題。

##### **LLM-Powered Explanations: Unraveling Recommendations Through Subgraph Reasoning**
2406.15859v2 by Guangsi Shi, Xiaofeng Deng, Linhao Luo, Lijuan Xia, Lei Bao, Bei Ye, Fei Du, Shirui Pan, Yuxiao Li

Recommender systems are pivotal in enhancing user experiences across various
web applications by analyzing the complicated relationships between users and
items. Knowledge graphs(KGs) have been widely used to enhance the performance
of recommender systems. However, KGs are known to be noisy and incomplete,
which are hard to provide reliable explanations for recommendation results. An
explainable recommender system is crucial for the product development and
subsequent decision-making. To address these challenges, we introduce a novel
recommender that synergies Large Language Models (LLMs) and KGs to enhance the
recommendation and provide interpretable results. Specifically, we first
harness the power of LLMs to augment KG reconstruction. LLMs comprehend and
decompose user reviews into new triples that are added into KG. In this way, we
can enrich KGs with explainable paths that express user preferences. To enhance
the recommendation on augmented KGs, we introduce a novel subgraph reasoning
module that effectively measures the importance of nodes and discovers
reasoning for recommendation. Finally, these reasoning paths are fed into the
LLMs to generate interpretable explanations of the recommendation results. Our
approach significantly enhances both the effectiveness and interpretability of
recommender systems, especially in cross-selling scenarios where traditional
methods falter. The effectiveness of our approach has been rigorously tested on
four open real-world datasets, with our methods demonstrating a superior
performance over contemporary state-of-the-art techniques by an average
improvement of 12%. The application of our model in a multinational engineering
and technology company cross-selling recommendation system further underscores
its practical utility and potential to redefine recommendation practices
through improved accuracy and user trust.

摘要：推薦系統在分析使用者與項目之間複雜的關係，提升各種網路應用程式的使用者體驗中扮演著關鍵角色。知識圖譜 (KG) 已被廣泛用於提升推薦系統的效能。然而，KG 眾所周知是有雜訊且不完整的，這使得難以提供可靠的推薦結果說明。一個可解釋的推薦系統對於產品開發和後續決策至關重要。為了應對這些挑戰，我們引入了一個新穎的推薦系統，它結合了大型語言模型 (LLM) 和 KG 來加強推薦並提供可解釋的結果。具體來說，我們首先利用 LLM 的力量來擴充 KG 重建。LLM 理解並將使用者評論分解成新的三元組，並將其新增到 KG 中。透過這種方式，我們可以用表達使用者偏好的可解釋路徑來豐富 KG。為了增強在擴充 KG 上的推薦，我們引入了一個新穎的子圖推理模組，它可以有效地衡量節點的重要性，並找出推薦的理由。最後，這些推理路徑被輸入到 LLM 中，以產生推薦結果的可解釋說明。我們的做法大幅提升了推薦系統的有效性和可解釋性，特別是在傳統方法失效的交叉銷售情境中。我們的做法的有效性已在四個開放的真實世界資料集上經過嚴格測試，我們的做法展示出比當代最先進技術更卓越的效能，平均提升了 12%。我們的模型在一家跨國工程和技術公司交叉銷售推薦系統中的應用進一步突顯了它的實用性，以及透過提升準確性和使用者信任來重新定義推薦實務的潛力。

##### **Large Language Models for Link Stealing Attacks Against Graph Neural Networks**
2406.16963v1 by Faqian Guan, Tianqing Zhu, Hui Sun, Wanlei Zhou, Philip S. Yu

Graph data contains rich node features and unique edge information, which
have been applied across various domains, such as citation networks or
recommendation systems. Graph Neural Networks (GNNs) are specialized for
handling such data and have shown impressive performance in many applications.
However, GNNs may contain of sensitive information and susceptible to privacy
attacks. For example, link stealing is a type of attack in which attackers
infer whether two nodes are linked or not. Previous link stealing attacks
primarily relied on posterior probabilities from the target GNN model,
neglecting the significance of node features. Additionally, variations in node
classes across different datasets lead to different dimensions of posterior
probabilities. The handling of these varying data dimensions posed a challenge
in using a single model to effectively conduct link stealing attacks on
different datasets. To address these challenges, we introduce Large Language
Models (LLMs) to perform link stealing attacks on GNNs. LLMs can effectively
integrate textual features and exhibit strong generalizability, enabling
attacks to handle diverse data dimensions across various datasets. We design
two distinct LLM prompts to effectively combine textual features and posterior
probabilities of graph nodes. Through these designed prompts, we fine-tune the
LLM to adapt to the link stealing attack task. Furthermore, we fine-tune the
LLM using multiple datasets and enable the LLM to learn features from different
datasets simultaneously. Experimental results show that our approach
significantly enhances the performance of existing link stealing attack tasks
in both white-box and black-box scenarios. Our method can execute link stealing
attacks across different datasets using only a single model, making link
stealing attacks more applicable to real-world scenarios.

摘要：圖形數據包含豐富的節點特徵和獨特的邊緣資訊，已應用於各種領域，例如引文網路或推薦系統。圖形神經網路 (GNN) 專門用於處理此類數據，並在許多應用中展現出令人印象深刻的效能。然而，GNN 可能包含敏感資訊，且容易受到隱私攻擊。例如，連結竊取是一種攻擊，攻擊者推斷兩個節點是否連結。先前的連結竊取攻擊主要依賴於目標 GNN 模型的後驗機率，忽略節點特徵的重要性。此外，不同資料集中的節點類別變化導致後驗機率的不同維度。處理這些不同的資料維度在使用單一模型對不同資料集執行連結竊取攻擊時構成一項挑戰。為了應對這些挑戰，我們引入了大型語言模型 (LLM) 來對 GNN 執行連結竊取攻擊。LLM 可以有效整合文字特徵並展現強大的泛化能力，使攻擊能夠處理不同資料集中的不同資料維度。我們設計了兩個不同的 LLM 提示，以有效結合文字特徵和圖形節點的後驗機率。透過這些設計的提示，我們微調 LLM 以適應連結竊取攻擊任務。此外，我們使用多個資料集微調 LLM，並使 LLM 能夠同時從不同的資料集中學習特徵。實驗結果顯示，我們的做法顯著提升了現有連結竊取攻擊任務在白盒和黑盒場景中的效能。我們的模型僅使用單一模型就能跨不同資料集執行連結竊取攻擊，使連結竊取攻擊更適用於實際場景。

##### **Inferring Pluggable Types with Machine Learning**
2406.15676v1 by Kazi Amanul Islam Siddiqui, Martin Kellogg

Pluggable type systems allow programmers to extend the type system of a
programming language to enforce semantic properties defined by the programmer.
Pluggable type systems are difficult to deploy in legacy codebases because they
require programmers to write type annotations manually. This paper investigates
how to use machine learning to infer type qualifiers automatically. We propose
a novel representation, NaP-AST, that encodes minimal dataflow hints for the
effective inference of type qualifiers. We evaluate several model architectures
for inferring type qualifiers, including Graph Transformer Network, Graph
Convolutional Network and Large Language Model. We further validated these
models by applying them to 12 open-source programs from a prior evaluation of
the NullAway pluggable typechecker, lowering warnings in all but one
unannotated project. We discovered that GTN shows the best performance, with a
recall of .89 and precision of 0.6. Furthermore, we conduct a study to estimate
the number of Java classes needed for good performance of the trained model.
For our feasibility study, performance improved around 16k classes, and
deteriorated due to overfitting around 22k classes.

摘要：可插拔类型系统允许程序员扩展编程语言的类型系统，以执行程序员定义的语义属性。可插拔类型系统难以部署在遗留代码库中，因为它们要求程序员手动编写类型注释。本文研究如何使用机器学习自动推断类型限定符。我们提出了一种新颖的表示形式 NaP-AST，它对类型限定符的有效推断编码了最小的数据流提示。我们评估了用于推断类型限定符的几种模型架构，包括图转换器网络、图卷积网络和大语言模型。我们通过将这些模型应用于 NullAway 可插拔类型检查器的先前评估中的 12 个开源程序，进一步验证了这些模型，除了一个未注释的项目外，降低了所有项目的警告。我们发现 GTN 表现最佳，召回率为 0.89，精确率为 0.6。此外，我们进行了一项研究，以估计训练模型良好性能所需的 Java 类数量。对于我们的可行性研究，性能提高了约 16k 个类，并且由于在 22k 个类左右过度拟合而恶化。

##### **NLP-KG: A System for Exploratory Search of Scientific Literature in Natural Language Processing**
2406.15294v2 by Tim Schopf, Florian Matthes

Scientific literature searches are often exploratory, whereby users are not
yet familiar with a particular field or concept but are interested in learning
more about it. However, existing systems for scientific literature search are
typically tailored to keyword-based lookup searches, limiting the possibilities
for exploration. We propose NLP-KG, a feature-rich system designed to support
the exploration of research literature in unfamiliar natural language
processing (NLP) fields. In addition to a semantic search, NLP-KG allows users
to easily find survey papers that provide a quick introduction to a field of
interest. Further, a Fields of Study hierarchy graph enables users to
familiarize themselves with a field and its related areas. Finally, a chat
interface allows users to ask questions about unfamiliar concepts or specific
articles in NLP and obtain answers grounded in knowledge retrieved from
scientific publications. Our system provides users with comprehensive
exploration possibilities, supporting them in investigating the relationships
between different fields, understanding unfamiliar concepts in NLP, and finding
relevant research literature. Demo, video, and code are available at:
https://github.com/NLP-Knowledge-Graph/NLP-KG-WebApp.

摘要：科學文獻的搜尋通常是探索性的，使用者可能還不熟悉某個特定領域或概念，但有興趣進一步了解它。然而，現有的科學文獻搜尋系統通常專門針對基於關鍵字的查詢搜尋，限制了探索的可能性。我們提出 NLP-KG，這是一個功能豐富的系統，旨在支援在不熟悉的自然語言處理 (NLP) 領域中探索研究文獻。除了語意搜尋之外，NLP-KG 使用者可以輕鬆找到提供對感興趣領域的快速介紹的綜述論文。此外，研究領域階層圖讓使用者能夠熟悉一個領域及其相關領域。最後，聊天介面允許使用者詢問有關不熟悉的概念或 NLP 中特定文章的問題，並獲得從科學出版物中擷取的知識為基礎的答案。我們的系統為使用者提供全面的探索可能性，協助他們調查不同領域之間的關係，理解 NLP 中不熟悉的概念，並找到相關的研究文獻。示範、影片和程式碼可在以下網址取得：
https://github.com/NLP-Knowledge-Graph/NLP-KG-WebApp。

##### **Unsupervised Extraction of Dialogue Policies from Conversations**
2406.15214v1 by Makesh Narsimhan Sreedhar, Traian Rebedea, Christopher Parisien

Dialogue policies play a crucial role in developing task-oriented dialogue
systems, yet their development and maintenance are challenging and typically
require substantial effort from experts in dialogue modeling. While in many
situations, large amounts of conversational data are available for the task at
hand, people lack an effective solution able to extract dialogue policies from
this data. In this paper, we address this gap by first illustrating how Large
Language Models (LLMs) can be instrumental in extracting dialogue policies from
datasets, through the conversion of conversations into a unified intermediate
representation consisting of canonical forms. We then propose a novel method
for generating dialogue policies utilizing a controllable and interpretable
graph-based methodology. By combining canonical forms across conversations into
a flow network, we find that running graph traversal algorithms helps in
extracting dialogue flows. These flows are a better representation of the
underlying interactions than flows extracted by prompting LLMs. Our technique
focuses on giving conversation designers greater control, offering a
productivity tool to improve the process of developing dialogue policies.

摘要：對話政策在開發任務導向對話系統中扮演著至關重要的角色，然而它們的開發和維護具有挑戰性，且通常需要對話建模專家的大量工作。雖然在許多情況下，大量對話資料可用於手邊的工作，但人們缺乏一種有效的解決方案，無法從這些資料中提取對話政策。在本文中，我們透過首先說明大型語言模型 (LLM) 如何透過將對話轉換成由規範形式組成的統一中間表示，從資料集中提取對話政策，來說明如何解決這個差距。然後，我們提出了一種利用可控且可解釋的基於圖形的方法來產生對話政策的新方法。透過將對話中的規範形式組合成流網路，我們發現執行圖形遍歷演算法有助於提取對話流。這些流比透過提示 LLM 提取的流更能代表底層互動。我們的技術專注於讓對話設計師擁有更大的控制權，提供一種生產力工具來改善開發對話政策的過程。

##### **Uni-Mol2: Exploring Molecular Pretraining Model at Scale**
2406.14969v2 by Xiaohong Ji, Zhen Wang, Zhifeng Gao, Hang Zheng, Linfeng Zhang, Guolin Ke, Weinan E

In recent years, pretraining models have made significant advancements in the
fields of natural language processing (NLP), computer vision (CV), and life
sciences. The significant advancements in NLP and CV are predominantly driven
by the expansion of model parameters and data size, a phenomenon now recognized
as the scaling laws. However, research exploring scaling law in molecular
pretraining models remains unexplored. In this work, we present Uni-Mol2 , an
innovative molecular pretraining model that leverages a two-track transformer
to effectively integrate features at the atomic level, graph level, and
geometry structure level. Along with this, we systematically investigate the
scaling law within molecular pretraining models, characterizing the power-law
correlations between validation loss and model size, dataset size, and
computational resources. Consequently, we successfully scale Uni-Mol2 to 1.1
billion parameters through pretraining on 800 million conformations, making it
the largest molecular pretraining model to date. Extensive experiments show
consistent improvement in the downstream tasks as the model size grows. The
Uni-Mol2 with 1.1B parameters also outperforms existing methods, achieving an
average 27% improvement on the QM9 and 14% on COMPAS-1D dataset.

摘要：近年来，预训练模型在自然语言处理 (NLP)、计算机视觉 (CV) 和生命科学领域取得了重大进展。NLP 和 CV 的重大进步主要由模型参数和数据量的扩展推动，这一现象现在被认为是缩放定律。然而，探索分子预训练模型中缩放定律的研究仍未得到探索。在这项工作中，我们提出了 Uni-Mol2，一种创新的分子预训练模型，它利用双轨转换器有效地整合原子级、图级和几何结构级的特征。除此之外，我们系统地研究了分子预训练模型中的缩放定律，描述了验证损失与模型大小、数据集大小和计算资源之间的幂律相关性。因此，我们成功地将 Uni-Mol2 扩展到 11 亿个参数，通过对 8 亿个构象进行预训练，使其成为迄今为止最大的分子预训练模型。大量的实验表明，随着模型大小的增长，下游任务持续得到改善。具有 1.1B 参数的 Uni-Mol2 也优于现有方法，在 QM9 上实现了平均 27% 的改进，在 COMPAS-1D 数据集上实现了 14% 的改进。

##### **Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks**
2406.14745v2 by Sefika Efeoglu, Adrian Paschke

Information Extraction (IE) is crucial for converting unstructured data into
structured formats like Knowledge Graphs (KGs). A key task within IE is
Relation Extraction (RE), which identifies relationships between entities in
text. Various RE methods exist, including supervised, unsupervised, weakly
supervised, and rule-based approaches. Recent studies leveraging pre-trained
language models (PLMs) have shown significant success in this area. In the
current era dominated by Large Language Models (LLMs), fine-tuning these models
can overcome limitations associated with zero-shot LLM prompting-based RE
methods, especially regarding domain adaptation challenges and identifying
implicit relations between entities in sentences. These implicit relations,
which cannot be easily extracted from a sentence's dependency tree, require
logical inference for accurate identification. This work explores the
performance of fine-tuned LLMs and their integration into the Retrieval
Augmented-based (RAG) RE approach to address the challenges of identifying
implicit relations at the sentence level, particularly when LLMs act as
generators within the RAG framework. Empirical evaluations on the TACRED,
TACRED-Revisited (TACREV), Re-TACRED, and SemEVAL datasets show significant
performance improvements with fine-tuned LLMs, including Llama2-7B, Mistral-7B,
and T5 (Large). Notably, our approach achieves substantial gains on SemEVAL,
where implicit relations are common, surpassing previous results on this
dataset. Additionally, our method outperforms previous works on TACRED, TACREV,
and Re-TACRED, demonstrating exceptional performance across diverse evaluation
scenarios.

摘要：資訊萃取（IE）對於將非結構化資料轉換成知識圖譜（KG）等結構化格式至關重要。IE 中的一項關鍵任務是關係萃取（RE），用於識別文字中實體之間的關係。RE 方法多種多樣，包括監督式、非監督式、弱監督式和基於規則的方法。最近利用預訓練語言模型（PLM）的研究已在此領域展現顯著成果。在大型語言模型（LLM）主導的當前時代，微調這些模型可以克服與零次學習 LLM 提示式 RE 方法相關的限制，特別是在領域適應挑戰和識別句子中實體之間的隱含關係方面。這些隱含關係無法輕易從句子的依賴樹中萃取，需要邏輯推論才能準確識別。這項工作探討了微調後的 LLM 的效能，以及它們整合到檢索增強式（RAG）RE 方法中以解決在句子層級識別隱含關係的挑戰，特別是在 LLM 在 RAG 框架中充當生成器的時後。在 TACRED、TACRED-Revisited（TACREV）、Re-TACRED 和 SemEVAL 資料集上的經驗評估顯示，微調後的 LLM，包括 Llama2-7B、Mistral-7B 和 T5（大型），大幅提升了效能。值得注意的是，我們的做法在 SemEVAL 上取得了顯著的進展，因為隱含關係很常見，超越了這個資料集上的先前結果。此外，我們的做法在 TACRED、TACREV 和 Re-TACRED 上優於先前的工作，證明了在不同的評估場景中表現出色的效能。

##### **Do LLMs Have Distinct and Consistent Personality? TRAIT: Personality Testset designed for LLMs with Psychometrics**
2406.14703v1 by Seungbeen Lee, Seungwon Lim, Seungju Han, Giyeong Oh, Hyungjoo Chae, Jiwan Chung, Minju Kim, Beong-woo Kwak, Yeonsoo Lee, Dongha Lee, Jinyoung Yeo, Youngjae Yu

The idea of personality in descriptive psychology, traditionally defined
through observable behavior, has now been extended to Large Language Models
(LLMs) to better understand their behavior. This raises a question: do LLMs
exhibit distinct and consistent personality traits, similar to humans? Existing
self-assessment personality tests, while applicable, lack the necessary
validity and reliability for precise personality measurements. To address this,
we introduce TRAIT, a new tool consisting of 8K multi-choice questions designed
to assess the personality of LLMs with validity and reliability. TRAIT is built
on the psychometrically validated human questionnaire, Big Five Inventory (BFI)
and Short Dark Triad (SD-3), enhanced with the ATOMIC10X knowledge graph for
testing personality in a variety of real scenarios. TRAIT overcomes the
reliability and validity issues when measuring personality of LLM with
self-assessment, showing the highest scores across three metrics: refusal rate,
prompt sensitivity, and option order sensitivity. It reveals notable insights
into personality of LLM: 1) LLMs exhibit distinct and consistent personality,
which is highly influenced by their training data (i.e., data used for
alignment tuning), and 2) current prompting techniques have limited
effectiveness in eliciting certain traits, such as high psychopathy or low
conscientiousness, suggesting the need for further research in this direction.

摘要：在傳統心理學中，人格的概念是透過可觀察的行為來定義的，現在已擴展到大型語言模型 (LLM)，以更了解其行為。這引發了一個問題：LLM 是否像人類一樣表現出獨特且一致的人格特質？現有的自我評量人格測驗雖然適用，但缺乏精確人格測量所需的效度和信度。為了解決這個問題，我們引入了 TRAIT，這是一個由 8K 個多重選擇題組成的全新工具，旨在評估 LLM 的人格，並具備效度和信度。TRAIT 建構於經過心理測量驗證的人類問卷，大五人格量表 (BFI) 和簡短黑暗三元組 (SD-3)，並增強了 ATOMIC10X 知識圖譜，以便在各種實際場景中測試人格。TRAIT 克服了使用自我評量測量 LLM 人格時的信度和效度問題，在三項指標（拒絕率、提示敏感度和選項順序敏感度）中顯示出最高分。它揭示了 LLM 人格的重要見解：1) LLM 表現出獨特且一致的人格，這深受其訓練資料（即用於對齊調整的資料）影響，以及 2) 目前的提示技術在引發某些特質（例如高精神病質或低盡責性）方面效果有限，這表示需要進一步研究這個方向。

##### **TAGLAS: An atlas of text-attributed graph datasets in the era of large graph and language models**
2406.14683v1 by Jiarui Feng, Hao Liu, Lecheng Kong, Yixin Chen, Muhan Zhang

In this report, we present TAGLAS, an atlas of text-attributed graph (TAG)
datasets and benchmarks. TAGs are graphs with node and edge features
represented in text, which have recently gained wide applicability in training
graph-language or graph foundation models. In TAGLAS, we collect and integrate
more than 23 TAG datasets with domains ranging from citation graphs to molecule
graphs and tasks from node classification to graph question-answering. Unlike
previous graph datasets and benchmarks, all datasets in TAGLAS have a unified
node and edge text feature format, which allows a graph model to be
simultaneously trained and evaluated on multiple datasets from various domains.
Further, we provide a standardized, efficient, and simplified way to load all
datasets and tasks. We also provide useful utils like text-to-embedding
conversion, and graph-to-text conversion, which can facilitate different
evaluation scenarios. Finally, we also provide standard and easy-to-use
evaluation utils. The project is open-sourced at
https://github.com/JiaruiFeng/TAGLAS and is still under construction. Please
expect more datasets/features in the future.

摘要：<paragraph>在本文中，我们提出了 TAGLAS，一个文本属性图 (TAG)
数据集和基准的图集。TAG 是具有以文本表示的节点和边特征的图，最近在训练
图语言或图基础模型中获得了广泛的应用。在 TAGLAS 中，我们收集并整合
了 23 个以上的 TAG 数据集，其领域从引文图到分子
图和任务，从节点分类到图问答。与
以前的图数据集和基准不同，TAGLAS 中的所有数据集都具有统一的
节点和边文本特征格式，这允许图模型在来自不同领域的多个数据集上同时训练和评估。
此外，我们提供了一种标准化、高效且简化的方式来加载所有
数据集和任务。我们还提供有用的实用程序，如文本到嵌入
转换，以及图到文本转换，这可以促进不同的
评估场景。最后，我们还提供标准且易于使用的
评估实用程序。该项目在
https://github.com/JiaruiFeng/TAGLAS 开源，并且仍在建设中。请
期待未来有更多的数据集/功能。</paragraph>

##### **HYPERmotion: Learning Hybrid Behavior Planning for Autonomous Loco-manipulation**
2406.14655v1 by Jin Wang, Rui Dai, Weijie Wang, Luca Rossini, Francesco Ruscelli, Nikos Tsagarakis

Enabling robots to autonomously perform hybrid motions in diverse
environments can be beneficial for long-horizon tasks such as material
handling, household chores, and work assistance. This requires extensive
exploitation of intrinsic motion capabilities, extraction of affordances from
rich environmental information, and planning of physical interaction behaviors.
Despite recent progress has demonstrated impressive humanoid whole-body control
abilities, they struggle to achieve versatility and adaptability for new tasks.
In this work, we propose HYPERmotion, a framework that learns, selects and
plans behaviors based on tasks in different scenarios. We combine reinforcement
learning with whole-body optimization to generate motion for 38 actuated joints
and create a motion library to store the learned skills. We apply the planning
and reasoning features of the large language models (LLMs) to complex
loco-manipulation tasks, constructing a hierarchical task graph that comprises
a series of primitive behaviors to bridge lower-level execution with
higher-level planning. By leveraging the interaction of distilled spatial
geometry and 2D observation with a visual language model (VLM) to ground
knowledge into a robotic morphology selector to choose appropriate actions in
single- or dual-arm, legged or wheeled locomotion. Experiments in simulation
and real-world show that learned motions can efficiently adapt to new tasks,
demonstrating high autonomy from free-text commands in unstructured scenes.
Videos and website: hy-motion.github.io/

摘要：<paragraph>讓機器人能夠在不同環境中自主執行混合動作，對於材料搬運、家務和工作協助等長期任務可能是有益的。這需要廣泛利用內在運動能力，從豐富的環境資訊中提取可負擔性，以及規劃物理互動行為。儘管最近的進展已證明令人印象深刻的人形全身控制能力，但它們仍難以實現新任務的多功能性和適應性。在這項工作中，我們提出 HYPERmotion，一個基於不同場景中的任務來學習、選擇和規劃行為的框架。我們結合強化學習與全身最佳化，為 38 個動作關節產生動作，並建立一個動作庫來儲存學習到的技能。我們將大型語言模型 (LLM) 的規劃和推理功能應用於複雜的運動操縱任務，構建一個階層式任務圖，其中包含一系列基本行為，以橋接低階執行與高階規劃。透過利用蒸餾空間幾何和 2D 觀測與視覺語言模型 (VLM) 的互動，將知識基礎化為機器人形態選擇器，以在單臂或雙臂、腿部或輪式運動中選擇適當的動作。模擬和現實世界的實驗表明，學習到的動作可以有效適應新任務，證明了在非結構化場景中從自由文字指令中獲得高度自主性。影片和網站：hy-motion.github.io/</paragraph>

##### **GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models**
2406.14550v1 by Shilong Li, Yancheng He, Hangyu Guo, Xingyuan Bu, Ge Bai, Jie Liu, Jiaheng Liu, Xingwei Qu, Yangguang Li, Wanli Ouyang, Wenbo Su, Bo Zheng

Long-context capabilities are essential for large language models (LLMs) to
tackle complex and long-input tasks. Despite numerous efforts made to optimize
LLMs for long contexts, challenges persist in robustly processing long inputs.
In this paper, we introduce GraphReader, a graph-based agent system designed to
handle long texts by structuring them into a graph and employing an agent to
explore this graph autonomously. Upon receiving a question, the agent first
undertakes a step-by-step analysis and devises a rational plan. It then invokes
a set of predefined functions to read node content and neighbors, facilitating
a coarse-to-fine exploration of the graph. Throughout the exploration, the
agent continuously records new insights and reflects on current circumstances
to optimize the process until it has gathered sufficient information to
generate an answer. Experimental results on the LV-Eval dataset reveal that
GraphReader, using a 4k context window, consistently outperforms GPT-4-128k
across context lengths from 16k to 256k by a large margin. Additionally, our
approach demonstrates superior performance on four challenging single-hop and
multi-hop benchmarks.

摘要：長語境能力對於大型語言模型 (LLM) 來說至關重要，可應對複雜且輸入長度較長的任務。儘管已針對 LLM 進行許多最佳化工作以應對長語境，但強健地處理長輸入仍存在挑戰。在本文中，我們介紹 GraphReader，一個基於圖表的代理系統，旨在透過將長文本結構化成一個圖表，並使用代理程式自主探索此圖表，來處理長文本。在收到問題後，代理程式首先進行逐步分析，並擬定一個合理計畫。然後，它會呼叫一組預定義的函式來讀取節點內容和鄰近節點，促進對圖表的粗略到精細探索。在整個探索過程中，代理程式會持續記錄新的見解，並反思當前情況，以最佳化處理程序，直到收集到足夠的資訊來產生答案。在 LV-Eval 資料集上的實驗結果顯示，GraphReader 使用 4k 語境視窗，在 16k 到 256k 的語境長度中，始終大幅優於 GPT-4-128k。此外，我們的做法在四個具有挑戰性的單跳和多跳基準測試中展現出卓越的效能。

##### **medIKAL: Integrating Knowledge Graphs as Assistants of LLMs for Enhanced Clinical Diagnosis on EMRs**
2406.14326v1 by Mingyi Jia, Junwen Duan, Yan Song, Jianxin Wang

Electronic Medical Records (EMRs), while integral to modern healthcare,
present challenges for clinical reasoning and diagnosis due to their complexity
and information redundancy. To address this, we proposed medIKAL (Integrating
Knowledge Graphs as Assistants of LLMs), a framework that combines Large
Language Models (LLMs) with knowledge graphs (KGs) to enhance diagnostic
capabilities. medIKAL assigns weighted importance to entities in medical
records based on their type, enabling precise localization of candidate
diseases within KGs. It innovatively employs a residual network-like approach,
allowing initial diagnosis by the LLM to be merged into KG search results.
Through a path-based reranking algorithm and a fill-in-the-blank style prompt
template, it further refined the diagnostic process. We validated medIKAL's
effectiveness through extensive experiments on a newly introduced open-sourced
Chinese EMR dataset, demonstrating its potential to improve clinical diagnosis
in real-world settings.

摘要：電子病歷 (EMR) 雖然是現代醫療保健不可或缺的一部分，但由於其複雜性和資訊冗餘，對臨床推理和診斷提出了挑戰。為了解決這個問題，我們提出了 medIKAL（將知識圖譜整合為 LLM 的助理），一個將大型語言模型 (LLM) 與知識圖譜 (KG) 結合的框架，以增強診斷能力。medIKAL 根據醫療記錄中實體的類型為其分配加權重要性，從而能夠精確定位 KG 中的候選疾病。它創新地採用了類似殘差網路的方法，允許 LLM 的初步診斷與 KG 搜尋結果合併。透過基於路徑的重新排序演算法和填空式提示範本，進一步優化了診斷過程。我們透過對新推出的開源中文 EMR 資料集進行廣泛的實驗，驗證了 medIKAL 的有效性，證明了其在現實世界中改善臨床診斷的潛力。

##### **Learning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs**
2406.14282v1 by Junjie Wang, Mingyang Chen, Binbin Hu, Dan Yang, Ziqi Liu, Yue Shen, Peng Wei, Zhiqiang Zhang, Jinjie Gu, Jun Zhou, Jeff Z. Pan, Wen Zhang, Huajun Chen

Improving the performance of large language models (LLMs) in complex
question-answering (QA) scenarios has always been a research focal point.
Recent studies have attempted to enhance LLMs' performance by combining
step-wise planning with external retrieval. While effective for advanced models
like GPT-3.5, smaller LLMs face challenges in decomposing complex questions,
necessitating supervised fine-tuning. Previous work has relied on manual
annotation and knowledge distillation from teacher LLMs, which are
time-consuming and not accurate enough. In this paper, we introduce a novel
framework for enhancing LLMs' planning capabilities by using planning data
derived from knowledge graphs (KGs). LLMs fine-tuned with this data have
improved planning capabilities, better equipping them to handle complex QA
tasks that involve retrieval. Evaluations on multiple datasets, including our
newly proposed benchmark, highlight the effectiveness of our framework and the
benefits of KG-derived planning data.

摘要：<paragraph>改善大型語言模型 (LLM) 在複雜問答 (QA) 情境中的效能一直是研究重點。最近的研究嘗試透過結合逐步規劃與外部擷取來增強 LLM 的效能。雖然對於 GPT-3.5 等進階模型來說很有效，但較小的 LLM 在分解複雜問題時會面臨挑戰，因此需要監督微調。先前的研究仰賴人工標註和教師 LLM 的知識萃取，這耗時且不夠精確。在本文中，我們介紹一個創新的架構，透過使用從知識圖譜 (KG) 中衍生的規劃資料來增強 LLM 的規劃能力。使用此資料微調的 LLM 改善了規劃能力，讓它們更能處理涉及擷取的複雜 QA 任務。在多個資料集（包括我們新提出的基準）上的評估突顯了我們架構的有效性，以及 KG 衍生規劃資料的好處。</paragraph>

##### **ReaLHF: Optimized RLHF Training for Large Language Models through Parameter Reallocation**
2406.14088v1 by Zhiyu Mei, Wei Fu, Kaiwei Li, Guangju Wang, Huanchen Zhang, Yi Wu

Reinforcement Learning from Human Feedback (RLHF) stands as a pivotal
technique in empowering large language model (LLM) applications. Since RLHF
involves diverse computational workloads and intricate dependencies among
multiple LLMs, directly adopting parallelization techniques from supervised
training can result in sub-optimal performance. To overcome this limitation, we
propose a novel approach named parameter ReaLlocation, which dynamically
redistributes LLM parameters in the cluster and adapts parallelization
strategies during training. Building upon this idea, we introduce ReaLHF, a
pioneering system capable of automatically discovering and running efficient
execution plans for RLHF training given the desired algorithmic and hardware
configurations. ReaLHF formulates the execution plan for RLHF as an augmented
dataflow graph. Based on this formulation, ReaLHF employs a tailored search
algorithm with a lightweight cost estimator to discover an efficient execution
plan. Subsequently, the runtime engine deploys the selected plan by effectively
parallelizing computations and redistributing parameters. We evaluate ReaLHF on
the LLaMA-2 models with up to $4\times70$ billion parameters and 128 GPUs. The
experiment results showcase ReaLHF's substantial speedups of $2.0-10.6\times$
compared to baselines. Furthermore, the execution plans generated by ReaLHF
exhibit an average of $26\%$ performance improvement over heuristic approaches
based on Megatron-LM. The source code of ReaLHF is publicly available at
https://github.com/openpsi-project/ReaLHF .

摘要：強化學習來自人類回饋 (RLHF) 是一種關鍵技術，用於賦能大型語言模型 (LLM) 應用程式。由於 RLHF 涉及多種運算工作負載和多個 LLM 之間的複雜依賴關係，直接採用監督式訓練的平行化技術可能會導致次佳效能。為了克服這個限制，我們提出了一種名為參數重新配置的新方法，它會動態重新分配叢集中的 LLM 參數，並在訓練期間調整平行化策略。在此概念的基礎上，我們引入了 ReaLHF，這是一個開創性的系統，能夠自動發現並執行 RLHF 訓練的高效執行計畫，並考量所需的演算法和硬體組態。ReaLHF 將 RLHF 的執行計畫制定為一個擴增資料流圖。基於此制定，ReaLHF 採用量身打造的搜尋演算法，搭配輕量級成本估計器，以發現高效的執行計畫。隨後，執行時間引擎透過有效平行化運算和重新分配參數，來部署所選的計畫。我們在 LLaMA-2 模型上評估 ReaLHF，該模型最多有 $4\times70$0 億個參數和 128 個 GPU。實驗結果顯示，與基準相比，ReaLHF 的速度提升了 $2.0-10.6\times$。此外，ReaLHF 生成的執行計畫比基於 Megatron-LM 的啟發式方法，平均效能提升了 $26\%$。ReaLHF 的原始程式碼公開於 https://github.com/openpsi-project/ReaLHF。

##### **HIGHT: Hierarchical Graph Tokenization for Graph-Language Alignment**
2406.14021v1 by Yongqiang Chen, Quanming Yao, Juzheng Zhang, James Cheng, Yatao Bian

Recently there has been a surge of interest in extending the success of large
language models (LLMs) to graph modality, such as social networks and
molecules. As LLMs are predominantly trained with 1D text data, most existing
approaches adopt a graph neural network to represent a graph as a series of
node tokens and feed these tokens to LLMs for graph-language alignment. Despite
achieving some successes, existing approaches have overlooked the hierarchical
structures that are inherent in graph data. Especially, in molecular graphs,
the high-order structural information contains rich semantics of molecular
functional groups, which encode crucial biochemical functionalities of the
molecules. We establish a simple benchmark showing that neglecting the
hierarchical information in graph tokenization will lead to subpar
graph-language alignment and severe hallucination in generated outputs. To
address this problem, we propose a novel strategy called HIerarchical GrapH
Tokenization (HIGHT). HIGHT employs a hierarchical graph tokenizer that
extracts and encodes the hierarchy of node, motif, and graph levels of
informative tokens to improve the graph perception of LLMs. HIGHT also adopts
an augmented graph-language supervised fine-tuning dataset, enriched with the
hierarchical graph information, to further enhance the graph-language
alignment. Extensive experiments on 7 molecule-centric benchmarks confirm the
effectiveness of HIGHT in reducing hallucination by 40%, as well as significant
improvements in various molecule-language downstream tasks.

摘要：<paragraph>最近，人们对将大型语言模型 (LLM) 的成功扩展到图模式（例如社交网络和分子）产生了浓厚的兴趣。由于 LLM 主要使用一维文本数据进行训练，因此大多数现有方法采用图神经网络将图表示为一系列节点标记，并将这些标记馈送至 LLM 以进行图语言对齐。尽管取得了一些成功，但现有方法却忽视了图数据中固有的层次结构。特别是在分子图中，高阶结构信息包含丰富的分子官能团语义，它对分子的关键生化功能进行编码。我们建立了一个简单的基准，表明在图标记化中忽略层次信息会导致次优的图语言对齐，并在生成的输出中出现严重的幻觉。为了解决这个问题，我们提出了一种称为分层图标记化 (HIGHT) 的新策略。HIGHT 采用分层图标记器，该标记器提取和编码信息标记的节点、主题和图级别层次结构，以改善 LLM 的图感知。HIGHT 还采用了一个经过扩充的图语言监督微调数据集，该数据集包含分层图信息，以进一步增强图语言对齐。在 7 个以分子为中心的基准上的大量实验证实了 HIGHT 在将幻觉减少 40% 方面的有效性，以及在各种分子语言下游任务中的显著改进。</paragraph>

##### **A Pure Transformer Pretraining Framework on Text-attributed Graphs**
2406.13873v1 by Yu Song, Haitao Mao, Jiachen Xiao, Jingzhe Liu, Zhikai Chen, Wei Jin, Carl Yang, Jiliang Tang, Hui Liu

Pretraining plays a pivotal role in acquiring generalized knowledge from
large-scale data, achieving remarkable successes as evidenced by large models
in CV and NLP. However, progress in the graph domain remains limited due to
fundamental challenges such as feature heterogeneity and structural
heterogeneity. Recently, increasing efforts have been made to enhance node
feature quality with Large Language Models (LLMs) on text-attributed graphs
(TAGs), demonstrating superiority to traditional bag-of-words or word2vec
techniques. These high-quality node features reduce the previously critical
role of graph structure, resulting in a modest performance gap between Graph
Neural Networks (GNNs) and structure-agnostic Multi-Layer Perceptrons (MLPs).
Motivated by this, we introduce a feature-centric pretraining perspective by
treating graph structure as a prior and leveraging the rich, unified feature
space to learn refined interaction patterns that generalizes across graphs. Our
framework, Graph Sequence Pretraining with Transformer (GSPT), samples node
contexts through random walks and employs masked feature reconstruction to
capture pairwise proximity in the LLM-unified feature space using a standard
Transformer. By utilizing unified text representations rather than varying
structures, our framework achieves significantly better transferability among
graphs within the same domain. GSPT can be easily adapted to both node
classification and link prediction, demonstrating promising empirical success
on various datasets.

摘要：預訓練在從大型資料中獲取廣泛知識方面發揮了關鍵作用，從 CV 和 NLP 中的大型模型所證明的顯著成功中即可見一斑。然而，由於特徵異質性和結構異質性等基本挑戰，圖形領域的進展仍然有限。最近，人們在文本屬性圖 (TAG) 上使用大型語言模型 (LLM) 來增強節點特徵品質，並已做出越來越多努力，證明其優於傳統的詞袋或 word2vec 技術。這些高品質節點特徵降低了圖形結構先前至關重要的作用，導致圖形神經網路 (GNN) 和與結構無關的多層感知器 (MLP) 之間的效能差距縮小。受到此啟發，我們透過將圖形結構視為先驗，並利用豐富的統一特徵空間來學習在圖形中概括的精緻互動模式，引入了以特徵為中心的預訓練觀點。我們的架構圖形序列預訓練與 Transformer (GSPT)，透過隨機遊走取樣節點脈絡，並採用遮蔽特徵重建，以使用標準 Transformer 在 LLM 統一特徵空間中擷取成對接近度。透過利用統一的文字表徵，而非變化的結構，我們的架構在同一個網域中的圖形之間達到了顯著更好的可傳遞性。GSPT 可以輕鬆地調整到節點分類和連結預測，在各種資料集上展現出有希望的實證成功。

##### **Knowledge Graph-Enhanced Large Language Models via Path Selection**
2406.13862v1 by Haochen Liu, Song Wang, Yaochen Zhu, Yushun Dong, Jundong Li

Large Language Models (LLMs) have shown unprecedented performance in various
real-world applications. However, they are known to generate factually
inaccurate outputs, a.k.a. the hallucination problem. In recent years,
incorporating external knowledge extracted from Knowledge Graphs (KGs) has
become a promising strategy to improve the factual accuracy of LLM-generated
outputs. Nevertheless, most existing explorations rely on LLMs themselves to
perform KG knowledge extraction, which is highly inflexible as LLMs can only
provide binary judgment on whether a certain knowledge (e.g., a knowledge path
in KG) should be used. In addition, LLMs tend to pick only knowledge with
direct semantic relationship with the input text, while potentially useful
knowledge with indirect semantics can be ignored. In this work, we propose a
principled framework KELP with three stages to handle the above problems.
Specifically, KELP is able to achieve finer granularity of flexible knowledge
extraction by generating scores for knowledge paths with input texts via latent
semantic matching. Meanwhile, knowledge paths with indirect semantic
relationships with the input text can also be considered via trained encoding
between the selected paths in KG and the input text. Experiments on real-world
datasets validate the effectiveness of KELP.

摘要：大型語言模型 (LLM) 在各種實際應用中展現了前所未有的效能。然而，它們會產生事實上不準確的輸出，也就是所謂的幻覺問題。近年來，納入從知識圖譜 (KG) 中萃取的外部知識已成為改善 LLM 生成的輸出事實準確性的有前途策略。儘管如此，現有的探索大多依賴 LLM 本身來執行 KG 知識萃取，這非常不靈活，因為 LLM 只會對特定知識（例如，KG 中的知識路徑）是否應該使用提供二元判斷。此外，LLM 傾向僅挑選與輸入文字有直接語義關係的知識，而可能對語意有間接關聯的有用知識可能會被忽略。在這項工作中，我們提出一個有原則的 KELP 架構，包含三個階段來處理上述問題。具體來說，KELP 能夠透過隱含語義比對為知識路徑與輸入文字產生分數，進而達成更細緻的彈性知識萃取。同時，也可以透過在 KG 中選定的路徑與輸入文字之間訓練編碼的方式，考量與輸入文字有間接語義關係的知識路徑。在實際資料集上的實驗驗證了 KELP 的有效性。

##### **Few-shot Knowledge Graph Relational Reasoning via Subgraph Adaptation**
2406.15507v1 by Haochen Liu, Song Wang, Chen Chen, Jundong Li

Few-shot Knowledge Graph (KG) Relational Reasoning aims to predict unseen
triplets (i.e., query triplets) for rare relations in KGs, given only several
triplets of these relations as references (i.e., support triplets). This task
has gained significant traction due to the widespread use of knowledge graphs
in various natural language processing applications. Previous approaches have
utilized meta-training methods and manually constructed meta-relation sets to
tackle this task. Recent efforts have focused on edge-mask-based methods, which
exploit the structure of the contextualized graphs of target triplets (i.e., a
subgraph containing relevant triplets in the KG). However, existing
edge-mask-based methods have limitations in extracting insufficient information
from KG and are highly influenced by spurious information in KG. To overcome
these challenges, we propose SAFER (Subgraph Adaptation for Few-shot Relational
Reasoning), a novel approach that effectively adapts the information in
contextualized graphs to various subgraphs generated from support and query
triplets to perform the prediction. Specifically, SAFER enables the extraction
of more comprehensive information from support triplets while minimizing the
impact of spurious information when predicting query triplets. Experimental
results on three prevalent datasets demonstrate the superiority of our proposed
framework SAFER.

摘要：小样本知识图谱 (KG) 关系推理旨在预测 KG 中罕见关系的看不见三元组（即查询三元组），而仅给出几个三元组作为参考（即支持三元组）。由于知识图谱在各种自然语言处理应用程序中的广泛使用，这项任务获得了显著的关注。以前的方法利用元训练方法和手动构建的元关系集来解决此任务。最近的努力集中在基于边缘掩码的方法上，该方法利用目标三元组的上下文化图的结构（即包含 KG 中相关三元组的子图）。然而，现有的基于边缘掩码的方法在从 KG 中提取不足信息方面存在局限性，并且受 KG 中虚假信息的极大影响。为了克服这些挑战，我们提出了 SAFER（用于小样本关系推理的子图自适应），一种新颖的方法，它有效地将上下文化图中的信息适应从支持和查询三元组生成的不同子图以执行预测。具体来说，SAFER 能够从支持三元组中提取更全面的信息，同时在预测查询三元组时最大程度地减少虚假信息的影响。在三个流行数据集上的实验结果证明了我们提出的 SAFER 框架的优越性。

##### **Dr.E Bridges Graphs with Large Language Models through Words**
2406.15504v1 by Zipeng Liu, Likang Wu, Ming He, Zhong Guan, Hongke Zhao, Nan Feng

Significant efforts have been directed toward integrating powerful Large
Language Models (LLMs) with diverse modalities, particularly focusing on the
fusion of vision, language, and audio data. However, the graph-structured data,
inherently rich in structural and domain-specific knowledge, have not yet been
gracefully adapted to LLMs. Existing methods either describe the graph with raw
text, suffering the loss of graph structural information, or feed Graph Neural
Network (GNN) embeddings directly into LLM at the cost of losing semantic
representation. To bridge this gap, we introduce an innovative, end-to-end
modality-aligning framework, equipped with a pretrained Dual-Residual Vector
Quantized-Variational AutoEncoder (Dr.E). This framework is specifically
designed to facilitate token-level alignment with LLMs, enabling an effective
translation of the intrinsic `language' of graphs into comprehensible natural
language. Our experimental evaluations on standard GNN node classification
tasks demonstrate competitive performance against other state-of-the-art
approaches. Additionally, our framework ensures interpretability, efficiency,
and robustness, with its effectiveness further validated under both fine-tuning
and few-shot settings. This study marks the first successful endeavor to
achieve token-level alignment between GNNs and LLMs.

摘要：大量的努力已投入到將強大的大型語言模型 (LLM) 與不同的模態整合，特別是專注於視覺、語言和音訊資料的融合。然而，圖形結構化的資料本質上富含結構和領域特定的知識，但尚未優雅地適應 LLM。現有方法不是用原始文字描述圖形，導致圖形結構資訊遺失，就是將圖形神經網路 (GNN) 的嵌入直接饋入 LLM，代價是失去語義表示。為了彌補這個差距，我們引入了一個創新的端到端模態對齊框架，配備了一個預先訓練的雙殘差向量量化變分自編碼器 (Dr.E)。此框架特別設計用於促進與 LLM 的標記層級對齊，讓圖形的內在「語言」能有效轉換成易於理解的自然語言。我們在標準 GNN 節點分類任務上的實驗評估顯示，與其他最先進的方法相比，我們的表現具有競爭力。此外，我們的框架確保了解釋性、效率和穩健性，在微調和少樣本設定下進一步驗證其有效性。這項研究標誌著在 GNN 和 LLM 之間實現標記層級對齊的首次成功嘗試。

##### **Enhancing Distractor Generation for Multiple-Choice Questions with Retrieval Augmented Pretraining and Knowledge Graph Integration**
2406.13578v1 by Han-Cheng Yu, Yu-An Shih, Kin-Man Law, Kai-Yu Hsieh, Yu-Chen Cheng, Hsin-Chih Ho, Zih-An Lin, Wen-Chuan Hsu, Yao-Chung Fan

In this paper, we tackle the task of distractor generation (DG) for
multiple-choice questions. Our study introduces two key designs. First, we
propose \textit{retrieval augmented pretraining}, which involves refining the
language model pretraining to align it more closely with the downstream task of
DG. Second, we explore the integration of knowledge graphs to enhance the
performance of DG. Through experiments with benchmarking datasets, we show that
our models significantly outperform the state-of-the-art results. Our
best-performing model advances the F1@3 score from 14.80 to 16.47 in MCQ
dataset and from 15.92 to 16.50 in Sciq dataset.

摘要：在本文中，我们處理多選題的干擾器生成 (DG) 任務。我們的研究引入了兩個關鍵設計。首先，我們提出「檢索增強預訓練」，其中包含優化語言模型預訓練，使其與 DG 的下游任務更緊密地對齊。其次，我們探討知識圖表的整合，以增強 DG 的效能。透過基準資料集的實驗，我們證明我們的模型明顯優於最先進的結果。我們效能最佳的模型將 MCQ 資料集中的 F1@3 分數從 14.80 提升到 16.47，在 Sciq 資料集中從 15.92 提升到 16.50。

##### **LangTopo: Aligning Language Descriptions of Graphs with Tokenized Topological Modeling**
2406.13250v1 by Zhong Guan, Hongke Zhao, Likang Wu, Ming He, Jianpin Fan

Recently, large language models (LLMs) have been widely researched in the
field of graph machine learning due to their outstanding abilities in language
comprehension and learning. However, the significant gap between natural
language tasks and topological structure modeling poses a nonnegligible
challenge. Specifically, since natural language descriptions are not sufficient
for LLMs to understand and process graph-structured data, fine-tuned LLMs
perform even worse than some traditional GNN models on graph tasks, lacking
inherent modeling capabilities for graph structures. Existing research overly
emphasizes LLMs' understanding of semantic information captured by external
models, while inadequately exploring graph topological structure modeling,
thereby overlooking the genuine capabilities that LLMs lack. Consequently, in
this paper, we introduce a new framework, LangTopo, which aligns graph
structure modeling with natural language understanding at the token level.
LangTopo quantifies the graph structure modeling capabilities of GNNs and LLMs
by constructing a codebook for the graph modality and performs consistency
maximization. This process aligns the text description of LLM with the
topological modeling of GNN, allowing LLM to learn the ability of GNN to
capture graph structures, enabling LLM to handle graph-structured data
independently. We demonstrate the effectiveness of our proposed method on
multiple datasets.

摘要：<paragraph>最近，大语言模型 (LLM) 由于其在语言理解和学习方面的出色能力而在图机器学习领域受到广泛研究。然而，自然语言任务和拓扑结构建模之间的巨大差距构成了不可忽视的挑战。具体来说，由于自然语言描述不足以让 LLM 理解和处理图结构化数据，因此经过微调的 LLM 在图任务上的表现甚至比一些传统的 GNN 模型还要差，缺乏对图结构的固有建模能力。现有研究过分强调 LLM 对外部模型捕获的语义信息的理解，而对图拓扑结构建模的探索不足，从而忽视了 LLM 所缺乏的真正能力。因此，在本文中，我们引入了一个新的框架 LangTopo，它在标记级别将图结构建模与自然语言理解相结合。LangTopo 通过为图模态构建码本并执行一致性最大化来量化 GNN 和 LLM 的图结构建模能力。此过程将 LLM 的文本描述与 GNN 的拓扑建模相结合，使 LLM 能够学习 GNN 捕获图结构的能力，从而使 LLM 能够独立处理图结构化数据。我们在多个数据集上展示了我们提出的方法的有效性。</paragraph>

##### **Enhancing Collaborative Semantics of Language Model-Driven Recommendations via Graph-Aware Learning**
2406.13235v1 by Zhong Guan, Likang Wu, Hongke Zhao, Ming He, Jianpin Fan

Large Language Models (LLMs) are increasingly prominent in the recommendation
systems domain. Existing studies usually utilize in-context learning or
supervised fine-tuning on task-specific data to align LLMs into
recommendations. However, the substantial bias in semantic spaces between
language processing tasks and recommendation tasks poses a nonnegligible
challenge. Specifically, without the adequate capturing ability of
collaborative information, existing modeling paradigms struggle to capture
behavior patterns within community groups, leading to LLMs' ineffectiveness in
discerning implicit interaction semantic in recommendation scenarios. To
address this, we consider enhancing the learning capability of language
model-driven recommendation models for structured data, specifically by
utilizing interaction graphs rich in collaborative semantics. We propose a
Graph-Aware Learning for Language Model-Driven Recommendations (GAL-Rec).
GAL-Rec enhances the understanding of user-item collaborative semantics by
imitating the intent of Graph Neural Networks (GNNs) to aggregate multi-hop
information, thereby fully exploiting the substantial learning capacity of LLMs
to independently address the complex graphs in the recommendation system.
Sufficient experimental results on three real-world datasets demonstrate that
GAL-Rec significantly enhances the comprehension of collaborative semantics,
and improves recommendation performance.

摘要：大型語言模型（LLM）在推薦系統領域中越來越突出。現有研究通常利用情境學習或在特定任務數據上進行監督微調，以將 LLM 調整為建議。然而，語言處理任務和推薦任務之間語義空間的實質性偏差構成了不可忽視的挑戰。具體來說，現有的建模範例在缺乏協作信息的充分捕獲能力的情況下，難以捕捉社群群組內的行為模式，導致 LLM 無法在推薦場景中辨識隱含的互動語義。為了解決這個問題，我們考慮增強語言模型驅動推薦模型對結構化數據的學習能力，特別是通過利用富含協作語義的交互圖。我們提出了一個圖感知語言模型驅動推薦學習（GAL-Rec）。GAL-Rec 通過模仿圖神經網路（GNN）聚合多跳信息的意圖來增強對使用者項目協作語義的理解，從而充分利用 LLM 的實質性學習能力來獨立處理推薦系統中的複雜圖。在三個真實世界數據集上進行的充分實驗結果表明，GAL-Rec 大大增強了對協作語義的理解，並改善了推薦性能。

##### **Bridging Law and Data: Augmenting Reasoning via a Semi-Structured Dataset with IRAC methodology**
2406.13217v1 by Xiaoxi Kang, Lizhen Qu, Lay-Ki Soon, Zhuang Li, Adnan Trakic

The effectiveness of Large Language Models (LLMs) in legal reasoning is often
limited due to the unique legal terminologies and the necessity for highly
specialized knowledge. These limitations highlight the need for high-quality
data tailored for complex legal reasoning tasks. This paper introduces
LEGALSEMI, a benchmark specifically curated for legal scenario analysis.
LEGALSEMI comprises 54 legal scenarios, each rigorously annotated by legal
experts, based on the comprehensive IRAC (Issue, Rule, Application, Conclusion)
framework. In addition, LEGALSEMI is accompanied by a structured knowledge
graph (SKG). A series of experiments were conducted to assess the usefulness of
LEGALSEMI for IRAC analysis. The experimental results demonstrate the
effectiveness of incorporating the SKG for issue identification, rule
retrieval, application and conclusion generation using four different LLMs.
LEGALSEMI will be publicly available upon acceptance of this paper.

摘要：大型語言模型 (LLM) 在法律推理中的有效性通常受到獨特的法律術語和高度專業知識的必要性的限制。這些限制突顯了針對複雜法律推理任務量身打造的高品質資料的需求。本文介紹 LEGALSEMI，這是一個專門為法律情境分析策劃的基準。LEGALSEMI 包含 54 個法律情境，每個情境都經過法律專家根據全面的 IRAC（問題、規則、應用、結論）架構嚴格註解。此外，LEGALSEMI 還附帶一個結構化的知識圖譜 (SKG)。進行了一系列實驗來評估 LEGALSEMI 對 IRAC 分析的有用性。實驗結果證明了將 SKG 納入問題識別、規則檢索、應用和結論生成中的有效性，使用了四種不同的 LLM。LEGALSEMI 將在本文獲接受後公開。

##### **PRESTO: Progressive Pretraining Enhances Synthetic Chemistry Outcomes**
2406.13193v1 by He Cao, Yanjun Shao, Zhiyuan Liu, Zijing Liu, Xiangru Tang, Yuan Yao, Yu Li

Multimodal Large Language Models (MLLMs) have seen growing adoption across
various scientific disciplines. These advancements encourage the investigation
of molecule-text modeling within synthetic chemistry, a field dedicated to
designing and conducting chemical reactions to synthesize new compounds with
desired properties and applications. Current approaches, however, often neglect
the critical role of multiple molecule graph interaction in understanding
chemical reactions, leading to suboptimal performance in synthetic chemistry
tasks. This study introduces PRESTO(Progressive Pretraining Enhances Synthetic
Chemistry Outcomes), a new framework that bridges the molecule-text modality
gap by integrating a comprehensive benchmark of pretraining strategies and
dataset configurations. It progressively improves multimodal LLMs through
cross-modal alignment and multi-graph understanding. Our extensive experiments
demonstrate that PRESTO offers competitive results in downstream synthetic
chemistry tasks. The code can be found at https://github.com/IDEA-XL/PRESTO.

摘要：多模态大型语言模型（MLLM）在各个科学学科中逐渐被采用。这些进步促进了合成化学中分子文本建模的研究，合成化学致力于设计和进行化学反应以合成具有所需性质和应用的新化合物。然而，当前的方法通常忽略了多个分子图相互作用在理解化学反应中的关键作用，导致在合成化学任务中的性能不佳。本研究介绍了 PRESTO（渐进式预训练增强合成化学成果），这是一个新的框架，通过整合预训练策略和数据集配置的综合基准来弥合理分子文本模态差距。它通过跨模态对齐和多图理解逐步改进多模态 LLM。我们的广泛实验表明，PRESTO 在下游合成化学任务中提供了有竞争力的结果。代码可在 https://github.com/IDEA-XL/PRESTO 中找到。

##### **QRMeM: Unleash the Length Limitation through Question then Reflection Memory Mechanism**
2406.13167v1 by Bo Wang, Heyan Huang, Yixin Cao, Jiahao Ying, Wei Tang, Chong Feng

While large language models (LLMs) have made notable advancements in natural
language processing, they continue to struggle with processing extensive text.
Memory mechanism offers a flexible solution for managing long contexts,
utilizing techniques such as compression, summarization, and structuring to
facilitate nuanced and efficient handling of large volumes of text. However,
existing techniques face challenges with static knowledge integration, leading
to insufficient adaptation to task-specific needs and missing
multi-segmentation relationships, which hinders the dynamic reorganization and
logical combination of relevant segments during the response process. To
address these issues, we introduce a novel strategy, Question then Reflection
Memory Mechanism (QRMeM), incorporating a dual-structured memory pool. This
pool synergizes static textual content with structured graph guidance,
fostering a reflective trial-and-error approach for navigating and identifying
relevant segments. Our evaluation across multiple-choice questions (MCQ) and
multi-document question answering (Multi-doc QA) benchmarks showcases QRMeM
enhanced performance compared to existing approaches.

摘要：儘管大型語言模型 (LLM) 在自然語言處理方面取得顯著進展，但它們在處理大量文字時仍面臨困難。記憶機制提供了一個靈活的解決方案，用於管理長篇脈絡，利用壓縮、摘要和結構化等技術，以促進對大量文字的細緻且有效率的處理。然而，現有技術在靜態知識整合方面面臨挑戰，導致無法充分適應特定任務的需求，且缺少多重分段關係，這阻礙了回應過程中相關區段的動態重組和邏輯組合。為了解決這些問題，我們引入了一種新策略，即問答反思記憶機制 (QRMeM)，並結合了雙結構化記憶池。此記憶池將靜態文本內容與結構化圖形指導結合起來，促進了一種反思性的試錯方法，用於導航和識別相關區段。我們在多選題 (MCQ) 和多文件問答 (Multi-doc QA) 基準上的評估顯示，與現有方法相比，QRMeM 增強了效能。

##### **Bridging Local Details and Global Context in Text-Attributed Graphs**
2406.12608v1 by Yaoke Wang, Yun Zhu, Wenqiao Zhang, Yueting Zhuang, Yunfei Li, Siliang Tang

Representation learning on text-attributed graphs (TAGs) is vital for
real-world applications, as they combine semantic textual and contextual
structural information. Research in this field generally consist of two main
perspectives: local-level encoding and global-level aggregating, respectively
refer to textual node information unification (e.g., using Language Models) and
structure-augmented modeling (e.g., using Graph Neural Networks). Most existing
works focus on combining different information levels but overlook the
interconnections, i.e., the contextual textual information among nodes, which
provides semantic insights to bridge local and global levels. In this paper, we
propose GraphBridge, a multi-granularity integration framework that bridges
local and global perspectives by leveraging contextual textual information,
enhancing fine-grained understanding of TAGs. Besides, to tackle scalability
and efficiency challenges, we introduce a graphaware token reduction module.
Extensive experiments across various models and datasets show that our method
achieves state-of-theart performance, while our graph-aware token reduction
module significantly enhances efficiency and solves scalability issues.

摘要：文本属性图 (TAG) 上的表征学习对于实际应用至关重要，因为它们结合了语义文本和上下文结构信息。该领域的研究所涉及的两个主要观点：局部编码和全局聚合，分别指文本节点信息统一（例如，使用语言模型）和结构增强建模（例如，使用图神经网络）。大多数现有工作侧重于结合不同的信息级别，但忽略了相互联系，即节点之间的上下文文本信息，它提供了语义见解以桥接局部和全局级别。在本文中，我们提出了 GraphBridge，这是一个多粒度集成框架，它通过利用上下文文本信息来桥接局部和全局视角，增强了对 TAG 的细粒度理解。此外，为了解决可扩展性和效率挑战，我们引入了一个图感知令牌缩减模块。跨各种模型和数据集的广泛实验表明，我们的方法实现了最先进的性能，而我们的图感知令牌缩减模块显着提高了效率并解决了可扩展性问题。

##### **MolecularGPT: Open Large Language Model (LLM) for Few-Shot Molecular Property Prediction**
2406.12950v1 by Yuyan Liu, Sirui Ding, Sheng Zhou, Wenqi Fan, Qiaoyu Tan

Molecular property prediction (MPP) is a fundamental and crucial task in drug
discovery. However, prior methods are limited by the requirement for a large
number of labeled molecules and their restricted ability to generalize for
unseen and new tasks, both of which are essential for real-world applications.
To address these challenges, we present MolecularGPT for few-shot MPP. From a
perspective on instruction tuning, we fine-tune large language models (LLMs)
based on curated molecular instructions spanning over 1000 property prediction
tasks. This enables building a versatile and specialized LLM that can be
adapted to novel MPP tasks without any fine-tuning through zero- and few-shot
in-context learning (ICL). MolecularGPT exhibits competitive in-context
reasoning capabilities across 10 downstream evaluation datasets, setting new
benchmarks for few-shot molecular prediction tasks. More importantly, with just
two-shot examples, MolecularGPT can outperform standard supervised graph neural
network methods on 4 out of 7 datasets. It also excels state-of-the-art LLM
baselines by up to 16.6% increase on classification accuracy and decrease of
199.17 on regression metrics (e.g., RMSE) under zero-shot. This study
demonstrates the potential of LLMs as effective few-shot molecular property
predictors. The code is available at https://github.com/NYUSHCS/MolecularGPT.

摘要：分子特性預測 (MPP) 是藥物發現中的一項基本且至關重要的任務。然而，先前的研究方法受到大量標記分子需求和概化到未見和新任務的能力受限的限制，這兩者對於實際應用都是必不可少的。為了應對這些挑戰，我們提出用於少樣本 MPP 的 MolecularGPT。從指令微調的角度來看，我們根據涵蓋 1000 多項特性預測任務的策劃分子指令微調大型語言模型 (LLM)。這使得構建一個多功能且專業的 LLM 成為可能，該 LLM 可以通過零樣本和少樣本情境學習 (ICL) 適應新的 MPP 任務，而無需任何微調。MolecularGPT 在 10 個下游評估資料集上展示了具有競爭力的情境推理能力，為少樣本分子預測任務設定了新的基準。更重要的是，僅使用兩樣本範例，MolecularGPT 就可以在 7 個資料集中的 4 個資料集上優於標準監督圖神經網路方法。它還在零樣本下，通過分類準確度提高了 16.6% 和回歸指標（例如 RMSE）減少了 199.17，從而優於最先進的 LLM 基準。這項研究證明了 LLM 作為有效少樣本分子特性預測器的潛力。程式碼可在 https://github.com/NYUSHCS/MolecularGPT 獲得。

##### **LightPAL: Lightweight Passage Retrieval for Open Domain Multi-Document Summarization**
2406.12494v1 by Masafumi Enomoto, Kunihiro Takeoka, Kosuke Akimoto, Kiril Gashteovski, Masafumi Oyamada

Open-Domain Multi-Document Summarization (ODMDS) is crucial for addressing
diverse information needs, which aims to generate a summary as answer to user's
query, synthesizing relevant content from multiple documents in a large
collection. Existing approaches that first find relevant passages and then
generate a summary using a language model are inadequate for ODMDS. This is
because open-ended queries often require additional context for the retrieved
passages to cover the topic comprehensively, making it challenging to retrieve
all relevant passages initially. While iterative retrieval methods have been
explored for multi-hop question answering (MQA), they are impractical for ODMDS
due to high latency from repeated large language model (LLM) inference for
reasoning. To address this issue, we propose LightPAL, a lightweight passage
retrieval method for ODMDS that constructs a graph representing passage
relationships using an LLM during indexing and employs random walk instead of
iterative reasoning and retrieval at inference time. Experiments on ODMDS
benchmarks show that LightPAL outperforms baseline retrievers in summary
quality while being significantly more efficient than an iterative MQA
approach.

摘要：開放領域多文件摘要 (ODMDS) 對於解決不同的資訊需求至關重要，其目的是根據使用者的查詢產生摘要作為答案，綜合來自大型集合中多個文件的相關內容。現有的方法是先找到相關段落，然後使用語言模型產生摘要，對於 ODMDS 來說是不夠的。這是因為開放式查詢通常需要額外的內容，才能讓擷取的段落全面涵蓋主題，這使得一開始就擷取所有相關段落具有挑戰性。雖然已經探索了反覆擷取的方法用於多跳問題解答 (MQA)，但由於反覆進行大型語言模型 (LLM) 推論以進行推理，因此它們不適用於 ODMDS，因為這會導致高延遲。為了解決這個問題，我們提出了 LightPAL，這是一種針對 ODMDS 的輕量級段落擷取方法，它在索引時使用 LLM 建立表示段落關係的圖，並在推論時使用隨機遊走，而不是反覆推理和擷取。在 ODMDS 基準測試中的實驗顯示，LightPAL 在摘要品質上優於基線擷取器，同時比反覆 MQA 方法有效率得多。

##### **Interpretable Catastrophic Forgetting of Large Language Model Fine-tuning via Instruction Vector**
2406.12227v2 by Gangwei Jiang, Caigao Jiang, Zhaoyi Li, Siqiao Xue, Jun Zhou, Linqi Song, Defu Lian, Ying Wei

Fine-tuning large language models (LLMs) can cause them to lose their general
capabilities. However, the intrinsic mechanisms behind such forgetting remain
unexplored. In this paper, we begin by examining this phenomenon by focusing on
knowledge understanding and instruction following, with the latter identified
as the main contributor to forgetting during fine-tuning. Consequently, we
propose the Instruction Vector (IV) framework to capture model representations
highly related to specific instruction-following capabilities, thereby making
it possible to understand model-intrinsic forgetting. Through the analysis of
IV dynamics pre and post-training, we suggest that fine-tuning mostly adds
specialized reasoning patterns instead of erasing previous skills, which may
appear as forgetting. Building on this insight, we develop IV-guided training,
which aims to preserve original computation graph, thereby mitigating
catastrophic forgetting. Empirical tests on three benchmarks confirm the
efficacy of this new approach, supporting the relationship between IVs and
forgetting. Our code will be made available soon.

摘要：微调大型语言模型 (LLM) 可能导致它们丧失一般能力。然而，这种遗忘背后的内在机制仍未得到探索。在本文中，我们首先通过关注知识理解和指令遵循来检验这种现象，其中后者被认为是微调过程中遗忘的主要原因。因此，我们提出了指令向量 (IV) 框架来捕获与特定指令遵循能力高度相关的模型表示，从而可以理解模型内在的遗忘。通过对训练前后的 IV 动态进行分析，我们认为微调主要添加了专门的推理模式，而不是抹除先前的技能，这可能表现为遗忘。基于这一见解，我们开发了 IV 指导训练，其目标是保留原始计算图，从而减轻灾难性遗忘。在三个基准上的经验测试证实了这种新方法的有效性，支持了 IV 和遗忘之间的关系。我们的代码将很快提供。

##### **DTGB: A Comprehensive Benchmark for Dynamic Text-Attributed Graphs**
2406.12072v2 by Jiasheng Zhang, Jialin Chen, Menglin Yang, Aosong Feng, Shuang Liang, Jie Shao, Rex Ying

Dynamic text-attributed graphs (DyTAGs) are prevalent in various real-world
scenarios, where each node and edge are associated with text descriptions, and
both the graph structure and text descriptions evolve over time. Despite their
broad applicability, there is a notable scarcity of benchmark datasets tailored
to DyTAGs, which hinders the potential advancement in many research fields. To
address this gap, we introduce Dynamic Text-attributed Graph Benchmark (DTGB),
a collection of large-scale, time-evolving graphs from diverse domains, with
nodes and edges enriched by dynamically changing text attributes and
categories. To facilitate the use of DTGB, we design standardized evaluation
procedures based on four real-world use cases: future link prediction,
destination node retrieval, edge classification, and textual relation
generation. These tasks require models to understand both dynamic graph
structures and natural language, highlighting the unique challenges posed by
DyTAGs. Moreover, we conduct extensive benchmark experiments on DTGB,
evaluating 7 popular dynamic graph learning algorithms and their variants of
adapting to text attributes with LLM embeddings, along with 6 powerful large
language models (LLMs). Our results show the limitations of existing models in
handling DyTAGs. Our analysis also demonstrates the utility of DTGB in
investigating the incorporation of structural and textual dynamics. The
proposed DTGB fosters research on DyTAGs and their broad applications. It
offers a comprehensive benchmark for evaluating and advancing models to handle
the interplay between dynamic graph structures and natural language. The
dataset and source code are available at https://github.com/zjs123/DTGB.

摘要：<paragraph>動態文字屬性圖表 (DyTAGs) 普遍存在於各種真實世界的場景中，其中每個節點和邊緣都與文字描述相關聯，且圖表結構和文字描述會隨著時間演變。儘管其廣泛的適用性，但專門針對 DyTAGs 的基準資料集卻十分稀少，這阻礙了許多研究領域的潛在進展。為了解決這個差距，我們引入了動態文字屬性圖表基準 (DTGB)，它是一個來自不同領域的大型、時變圖表的集合，其節點和邊緣由動態變化的文字屬性和類別豐富化。為了便於使用 DTGB，我們根據四個真實世界的用例設計了標準化的評估程序：未來連結預測、目的地節點檢索、邊緣分類和文字關係生成。這些任務要求模型同時理解動態圖表結構和自然語言，突顯了 DyTAGs 帶來的獨特挑戰。此外，我們對 DTGB 進行了廣泛的基準實驗，評估了 7 種流行的動態圖表學習演算法及其使用 LLM 嵌入適應文字屬性的變體，以及 6 種強大的大型語言模型 (LLM)。我們的結果顯示了現有模型在處理 DyTAGs 方面的局限性。我們的分析也證明了 DTGB 在研究結構和文字動態的結合方面的效用。所提出的 DTGB 促進了對 DyTAGs 及其廣泛應用的研究。它為評估和推進模型以處理動態圖表結構和自然語言之間的交互作用提供了一個全面的基準。資料集和原始碼可在 https://github.com/zjs123/DTGB 取得。</paragraph>

##### **UniGLM: Training One Unified Language Model for Text-Attributed Graphs**
2406.12052v1 by Yi Fang, Dongzhe Fan, Sirui Ding, Ninghao Liu, Qiaoyu Tan

Representation learning on text-attributed graphs (TAGs), where nodes are
represented by textual descriptions, is crucial for textual and relational
knowledge systems and recommendation systems. Currently, state-of-the-art
embedding methods for TAGs primarily focus on fine-tuning language models
(e.g., BERT) using structure-aware training signals. While effective, these
methods are tailored for individual TAG and cannot generalize across various
graph scenarios. Given the shared textual space, leveraging multiple TAGs for
joint fine-tuning, aligning text and graph structure from different aspects,
would be more beneficial. Motivated by this, we introduce a novel Unified Graph
Language Model (UniGLM) framework, the first graph embedding model that
generalizes well to both in-domain and cross-domain TAGs. Specifically, UniGLM
is trained over multiple TAGs with different domains and scales using
self-supervised contrastive learning. UniGLM includes an adaptive positive
sample selection technique for identifying structurally similar nodes and a
lazy contrastive module that is devised to accelerate training by minimizing
repetitive encoding calculations. Extensive empirical results across 9
benchmark TAGs demonstrate UniGLM's efficacy against leading embedding
baselines in terms of generalization (various downstream tasks and backbones)
and transfer learning (in and out of domain scenarios). The code is available
at https://github.com/NYUSHCS/UniGLM.

摘要：在文字属性图 (TAG) 上的表征学习，其中节点由文字描述表示，对于文字和关系知识系统以及推荐系统至关重要。目前，TAG 的最先进嵌入方法主要集中于使用结构感知训练信号微调语言模型（例如，BERT）。虽然有效，但这些方法是针对单个 TAG 量身定制的，并且无法概括到各种图场景。鉴于共享的文本空间，利用多个 TAG 进行联合微调，从不同方面调整文本和图结构，将更有益。受此启发，我们引入了一种新颖的统一图语言模型 (UniGLM) 框架，这是第一个在域内和跨域 TAG 中都能很好地概括的图嵌入模型。具体来说，UniGLM 使用自监督对比学习在具有不同域和规模的多个 TAG 上进行训练。UniGLM 包括一种自适应正样本选择技术，用于识别结构相似的节点，以及一个延迟对比模块，该模块旨在通过最小化重复编码计算来加速训练。跨 9 个基准 TAG 的广泛实证结果证明了 UniGLM 在泛化（各种下游任务和主干）和迁移学习（域内和域外场景）方面相对于领先嵌入基准的功效。代码可在 https://github.com/NYUSHCS/UniGLM 获得。

##### **GAugLLM: Improving Graph Contrastive Learning for Text-Attributed Graphs with Large Language Models**
2406.11945v1 by Yi Fang, Dongzhe Fan, Daochen Zha, Qiaoyu Tan

This work studies self-supervised graph learning for text-attributed graphs
(TAGs) where nodes are represented by textual attributes. Unlike traditional
graph contrastive methods that perturb the numerical feature space and alter
the graph's topological structure, we aim to improve view generation through
language supervision. This is driven by the prevalence of textual attributes in
real applications, which complement graph structures with rich semantic
information. However, this presents challenges because of two major reasons.
First, text attributes often vary in length and quality, making it difficulty
to perturb raw text descriptions without altering their original semantic
meanings. Second, although text attributes complement graph structures, they
are not inherently well-aligned. To bridge the gap, we introduce GAugLLM, a
novel framework for augmenting TAGs. It leverages advanced large language
models like Mistral to enhance self-supervised graph learning. Specifically, we
introduce a mixture-of-prompt-expert technique to generate augmented node
features. This approach adaptively maps multiple prompt experts, each of which
modifies raw text attributes using prompt engineering, into numerical feature
space. Additionally, we devise a collaborative edge modifier to leverage
structural and textual commonalities, enhancing edge augmentation by examining
or building connections between nodes. Empirical results across five benchmark
datasets spanning various domains underscore our framework's ability to enhance
the performance of leading contrastive methods as a plug-in tool. Notably, we
observe that the augmented features and graph structure can also enhance the
performance of standard generative methods, as well as popular graph neural
networks. The open-sourced implementation of our GAugLLM is available at
Github.

摘要：<paragraph>本研究探討了文字屬性圖 (TAG) 的自我監督圖學習，其中節點由文字屬性表示。與擾動數值特徵空間和改變圖形拓撲結構的傳統圖形對比方法不同，我們旨在透過語言監督來改善視圖生成。這是因為文字屬性在實際應用中很普遍，它以豐富的語義資訊補充圖形結構。然而，這會帶來挑戰，原因有兩個。首先，文字屬性通常長度和品質不同，這使得在不改變原始語義意義的情況下擾動原始文字描述變得困難。其次，儘管文字屬性補充了圖形結構，但它們並非天生就很好地對齊。為了彌合差距，我們引入了 GAugLLM，這是一個用於擴充 TAG 的新框架。它利用了 Mistral 等先進的大型語言模型來增強自我監督圖形學習。具體來說，我們引入了一種混合提示專家的技術來生成擴充的節點特徵。這種方法自適應地將多個提示專家映射到數值特徵空間，每個提示專家都使用提示工程修改原始文字屬性。此外，我們設計了一個協作邊緣修改器來利用結構和文字的共性，通過檢查或建立節點之間的連接來增強邊緣擴充。跨越各種領域的五個基準資料集的經驗結果強調了我們的框架作為外掛工具增強領先對比方法效能的能力。值得注意的是，我們觀察到擴充的特徵和圖形結構也可以增強標準生成方法以及流行的圖形神經網路的效能。我們的 GAugLLM 的開源實現可以在 Github 上找到。</paragraph>

##### **Input Conditioned Graph Generation for Language Agents**
2406.11555v1 by Lukas Vierling, Jie Fu, Kai Chen

Recent progress in Large Language Models (LLMs) and language agents has
demonstrated significant promise for various future applications across
multiple disciplines. While traditional approaches to language agents often
rely on fixed, handcrafted designs, our research aims to develop both learnable
and dynamic agents. Our method uses an existing framework that abstracts
language agents as graphs. Within this graph framework, we aim to learn a model
that can generate edges for every given input to the language agent. This
allows us to generate edges that represent the flow of communication within the
graph based on the given input, thereby adjusting the internal communication of
a language agent. We learn to generate these edges using a pretrained LLM that
is fine-tuned with reinforcement learning. This LLM can be fine-tuned on
several datasets simultaneously, and we hypothesize that the model learns to
adapt to these different domains during training, achieving good overall
performance when encountering data from different domains during deployment. We
demonstrate that our approach surpasses the previous static approach by nearly
6% accuracy on a combined dataset of MMLU and CMMLU, and by more than 10% when
trained with a sparsity-inducing loss. It also performs superior in additional
experiments conducted with the MMLU and Mini Crossword Puzzles datasets. The
code is available at https://github.com/lukasVierling/DynamicGPTSwarm.

摘要：大型语言模型 (LLM) 和语言代理最近的进展已展示出对跨多个学科的各种未来应用的重大前景。虽然传统的语言代理方法通常依赖于固定的手工设计，但我们的研究旨在开发可学习和动态的代理。我们的方法使用了一个现有的框架，将语言代理抽象为图。在这个图框架内，我们旨在学习一个模型，该模型可以为语言代理的每个给定输入生成边。这使我们能够生成代表图中基于给定输入的通信流的边，从而调整语言代理的内部通信。我们学习使用经过强化学习微调的预训练 LLM 来生成这些边。该 LLM 可以同时在多个数据集上进行微调，我们假设该模型在训练期间学习适应这些不同的域，在部署期间遇到来自不同域的数据时实现良好的整体性能。我们证明，我们的方法在 MMLU 和 CMMLU 的组合数据集上比先前的静态方法高出近 6% 的准确度，并且在使用稀疏性诱导损失进行训练时高出 10% 以上。它还在使用 MMLU 和迷你填字游戏数据集进行的其他实验中表现出色。代码可在 https://github.com/lukasVierling/DynamicGPTSwarm 获得。

##### **Large Language Models and Knowledge Graphs for Astronomical Entity Disambiguation**
2406.11400v1 by Golnaz Shapurian

This paper presents an experiment conducted during a hackathon, focusing on
using large language models (LLMs) and knowledge graph clustering to extract
entities and relationships from astronomical text. The study demonstrates an
approach to disambiguate entities that can appear in various contexts within
the astronomical domain. By collecting excerpts around specific entities and
leveraging the GPT-4 language model, relevant entities and relationships are
extracted. The extracted information is then used to construct a knowledge
graph, which is clustered using the Leiden algorithm. The resulting Leiden
communities are utilized to identify the percentage of association of unknown
excerpts to each community, thereby enabling disambiguation. The experiment
showcases the potential of combining LLMs and knowledge graph clustering
techniques for information extraction in astronomical research. The results
highlight the effectiveness of the approach in identifying and disambiguating
entities, as well as grouping them into meaningful clusters based on their
relationships.

摘要：本文介紹了在黑客馬拉松中進行的實驗，重點在於使用大型語言模型 (LLM) 和知識圖譜聚類，從天文文本中提取實體和關係。這項研究展示了一種方法，可以消除在天文領域中各種語境中出現的實體歧義性。透過收集特定實體周圍的摘錄，並利用 GPT-4 語言模型，可以提取相關實體和關係。然後使用提取的資訊來建構知識圖譜，並使用 Leiden 演算法進行聚類。結果產生的 Leiden 社群用於識別未知摘錄與每個社群的關聯百分比，從而消除歧義性。該實驗展示了結合 LLM 和知識圖譜聚類技術在天文研究中進行資訊提取的潛力。結果突顯了該方法在識別和消除實體歧義性方面的有效性，以及根據實體之間的關係將實體分組到有意義的群集中。

##### **How Good are LLMs at Relation Extraction under Low-Resource Scenario? Comprehensive Evaluation**
2406.11162v2 by Dawulie Jinensibieke, Mieradilijiang Maimaiti, Wentao Xiao, Yuanhang Zheng, Xiaobo Wang

Relation Extraction (RE) serves as a crucial technology for transforming
unstructured text into structured information, especially within the framework
of Knowledge Graph development. Its importance is emphasized by its essential
role in various downstream tasks. Besides the conventional RE methods which are
based on neural networks and pre-trained language models, large language models
(LLMs) are also utilized in the research field of RE. However, on low-resource
languages (LRLs), both conventional RE methods and LLM-based methods perform
poorly on RE due to the data scarcity issues. To this end, this paper
constructs low-resource relation extraction datasets in 10 LRLs in three
regions (Central Asia, Southeast Asia and Middle East). The corpora are
constructed by translating the original publicly available English RE datasets
(NYT10, FewRel and CrossRE) using an effective multilingual machine
translation. Then, we use the language perplexity (PPL) to filter out the
low-quality data from the translated datasets. Finally, we conduct an empirical
study and validate the performance of several open-source LLMs on these
generated LRL RE datasets.

摘要：關係抽取 (RE) 是一種將非結構化文字轉換為結構化資訊的關鍵技術，特別是在知識圖譜開發的架構中。其重要性在於它在各種下游任務中扮演著不可或缺的角色。除了基於神經網路和預訓練語言模型的傳統 RE 方法之外，大型語言模型 (LLM) 也被用於 RE 的研究領域。然而，在低資源語言 (LRL) 中，由於資料稀少的問題，傳統的 RE 方法和基於 LLM 的方法在 RE 上的表現都很差。有鑑於此，本文在三個地區（中亞、東南亞和中東）的 10 種 LRL 中建構了低資源關係抽取資料集。這些語料庫是透過使用一種有效的多語言機器翻譯來翻譯原始公開的英文 RE 資料集（NYT10、FewRel 和 CrossRE）而建構的。然後，我們使用語言困惑度 (PPL) 從翻譯後的資料集中篩選出低品質的資料。最後，我們進行一項實證研究，並驗證了幾個開源 LLM 在這些生成的 LRL RE 資料集上的效能。

##### **Context Graph**
2406.11160v3 by Chengjin Xu, Muzhi Li, Cehao Yang, Xuhui Jiang, Lumingyuan Tang, Yiyan Qi, Jian Guo

Knowledge Graphs (KGs) are foundational structures in many AI applications,
representing entities and their interrelations through triples. However,
triple-based KGs lack the contextual information of relational knowledge, like
temporal dynamics and provenance details, which are crucial for comprehensive
knowledge representation and effective reasoning. Instead, \textbf{Context
Graphs} (CGs) expand upon the conventional structure by incorporating
additional information such as time validity, geographic location, and source
provenance. This integration provides a more nuanced and accurate understanding
of knowledge, enabling KGs to offer richer insights and support more
sophisticated reasoning processes. In this work, we first discuss the inherent
limitations of triple-based KGs and introduce the concept of CGs, highlighting
their advantages in knowledge representation and reasoning. We then present a
context graph reasoning \textbf{CGR$^3$} paradigm that leverages large language
models (LLMs) to retrieve candidate entities and related contexts, rank them
based on the retrieved information, and reason whether sufficient information
has been obtained to answer a query. Our experimental results demonstrate that
CGR$^3$ significantly improves performance on KG completion (KGC) and KG
question answering (KGQA) tasks, validating the effectiveness of incorporating
contextual information on KG representation and reasoning.

摘要：知識圖譜 (KG) 是許多 AI 應用中的基礎結構，透過三元組來表示實體及其相互關係。然而，基於三元組的 KG 缺乏關係知識的脈絡資訊，例如時間動態和來源細節，這些資訊對於全面的知識表示和有效推理至關重要。取而代之的是，**脈絡圖譜** (CG) 透過納入時間有效性、地理位置和來源出處等額外資訊，擴展了傳統結構。這種整合提供了對知識更細緻且準確的理解，使 KG 能夠提供更豐富的見解，並支援更精密的推理過程。在這項工作中，我們首先討論了基於三元組的 KG 的內在限制，並介紹 CG 的概念，強調它們在知識表示和推理方面的優勢。接下來，我們提出一個脈絡圖譜推理**CGR$^3$**範例，它利用大型語言模型 (LLM) 來擷取候選實體和相關脈絡，根據擷取的資訊對它們進行排序，並推論是否已取得足夠的資訊來回答查詢。我們的實驗結果證明，CGR$^3$ 在 KG 完成 (KGC) 和 KG 問答 (KGQA) 任務上顯著提升了效能，驗證了在 KG 表示和推理中納入脈絡資訊的有效性。

##### **Are Large Language Models a Good Replacement of Taxonomies?**
2406.11131v2 by Yushi Sun, Hao Xin, Kai Sun, Yifan Ethan Xu, Xiao Yang, Xin Luna Dong, Nan Tang, Lei Chen

Large language models (LLMs) demonstrate an impressive ability to internalize
knowledge and answer natural language questions. Although previous studies
validate that LLMs perform well on general knowledge while presenting poor
performance on long-tail nuanced knowledge, the community is still doubtful
about whether the traditional knowledge graphs should be replaced by LLMs. In
this paper, we ask if the schema of knowledge graph (i.e., taxonomy) is made
obsolete by LLMs. Intuitively, LLMs should perform well on common taxonomies
and at taxonomy levels that are common to people. Unfortunately, there lacks a
comprehensive benchmark that evaluates the LLMs over a wide range of taxonomies
from common to specialized domains and at levels from root to leaf so that we
can draw a confident conclusion. To narrow the research gap, we constructed a
novel taxonomy hierarchical structure discovery benchmark named TaxoGlimpse to
evaluate the performance of LLMs over taxonomies. TaxoGlimpse covers ten
representative taxonomies from common to specialized domains with in-depth
experiments of different levels of entities in this taxonomy from root to leaf.
Our comprehensive experiments of eighteen state-of-the-art LLMs under three
prompting settings validate that LLMs can still not well capture the knowledge
of specialized taxonomies and leaf-level entities.

摘要：大型語言模型 (LLM) 展示了將知識內化並回答自然語言問題的驚人能力。儘管先前的研究驗證了 LLM 在一般知識上表現良好，但在長尾細微知識上表現不佳，但社群仍然懷疑傳統知識圖譜是否應被 LLM 取代。在本文中，我們探討知識圖譜的架構 (即分類法) 是否被 LLM 取代。直觀上，LLM 應在常見分類法和對人們來說常見的分類法層級中表現良好。不幸的是，缺乏一個綜合基準來評估 LLM 在從一般到專業領域的廣泛分類法以及從根到葉的層級，以便我們可以得出確信的結論。為了縮小研究差距，我們構建了一個名為 TaxoGlimpse 的新分類法層級結構發現基準，以評估 LLM 在分類法上的表現。TaxoGlimpse 涵蓋了從一般到專業領域的十個代表性分類法，並對該分類法中從根到葉的不同層級實體進行深入實驗。我們對 18 個最先進的 LLM 在三種提示設定下的綜合實驗驗證了 LLM 仍然無法很好地掌握專業分類法和葉級實體的知識。

##### **DocNet: Semantic Structure in Inductive Bias Detection Models**
2406.10965v1 by Jessica Zhu, Iain Cruickshank, Michel Cukier

News will have biases so long as people have opinions. However, as social
media becomes the primary entry point for news and partisan gaps increase, it
is increasingly important for informed citizens to be able to identify bias.
People will be able to take action to avoid polarizing echo chambers if they
know how the news they are consuming is biased. In this paper, we explore an
often overlooked aspect of bias detection in documents: the semantic structure
of news articles. We present DocNet, a novel, inductive, and low-resource
document embedding and bias detection model that outperforms large language
models. We also demonstrate that the semantic structure of news articles from
opposing partisan sides, as represented in document-level graph embeddings,
have significant similarities. These results can be used to advance bias
detection in low-resource environments. Our code and data are made available at
https://github.com/nlpresearchanon.

摘要：新聞會存在偏見，只要人們有意見。然而，由於社群媒體成為新聞的主要入口，且黨派差距擴大，對於有知識的公民來說，能夠辨識偏見變得愈來愈重要。如果人們知道他們所接收的新聞如何偏頗，他們就能採取行動來避免兩極化的同溫層。在本文中，我們探討文件偏見偵測中經常被忽略的一面：新聞文章的語意結構。我們提出 DocNet，一個新穎、歸納且低資源的文件嵌入和偏見偵測模型，其表現優於大型語言模型。我們也證明，來自對立黨派陣營的新聞文章的語意結構，如文件層級圖嵌入中所呈現的，具有顯著的相似性。這些結果可用於推進低資源環境中的偏見偵測。我們的程式碼和資料可在 https://github.com/nlpresearchanon 取得。

##### **Light Up the Shadows: Enhance Long-Tailed Entity Grounding with Concept-Guided Vision-Language Models**
2406.10902v1 by Yikai Zhang, Qianyu He, Xintao Wang, Siyu Yuan, Jiaqing Liang, Yanghua Xiao

Multi-Modal Knowledge Graphs (MMKGs) have proven valuable for various
downstream tasks. However, scaling them up is challenging because building
large-scale MMKGs often introduces mismatched images (i.e., noise). Most
entities in KGs belong to the long tail, meaning there are few images of them
available online. This scarcity makes it difficult to determine whether a found
image matches the entity. To address this, we draw on the Triangle of Reference
Theory and suggest enhancing vision-language models with concept guidance.
Specifically, we introduce COG, a two-stage framework with COncept-Guided
vision-language models. The framework comprises a Concept Integration module,
which effectively identifies image-text pairs of long-tailed entities, and an
Evidence Fusion module, which offers explainability and enables human
verification. To demonstrate the effectiveness of COG, we create a dataset of
25k image-text pairs of long-tailed entities. Our comprehensive experiments
show that COG not only improves the accuracy of recognizing long-tailed
image-text pairs compared to baselines but also offers flexibility and
explainability.

摘要：多模态知识图谱 (MMKG) 已被证明对各种下游任务很有价值。然而，扩展它们具有挑战性，因为构建大规模 MMKG 经常会引入不匹配的图像（即噪声）。知识图谱中的大多数实体都属于长尾，这意味着网上很少有它们的图像。这种稀缺性使得难以确定找到的图像是否与实体匹配。为了解决这个问题，我们借鉴了三角参照理论，并建议用概念指导来增强视觉语言模型。具体来说，我们引入了 COG，这是一个带有概念指导视觉语言模型的两阶段框架。该框架包含一个概念集成模块，该模块有效地识别长尾实体的图像文本对，以及一个证据融合模块，该模块提供可解释性并支持人工验证。为了证明 COG 的有效性，我们创建了一个由 25k 个长尾实体的图像文本对组成的数据集。我们的综合实验表明，与基线相比，COG 不仅提高了识别长尾图像文本对的准确性，还提供了灵活性和可解释性。

##### **KGPA: Robustness Evaluation for Large Language Models via Cross-Domain Knowledge Graphs**
2406.10802v1 by Aihua Pei, Zehua Yang, Shunan Zhu, Ruoxi Cheng, Ju Jia, Lina Wang

Existing frameworks for assessing robustness of large language models (LLMs)
overly depend on specific benchmarks, increasing costs and failing to evaluate
performance of LLMs in professional domains due to dataset limitations. This
paper proposes a framework that systematically evaluates the robustness of LLMs
under adversarial attack scenarios by leveraging knowledge graphs (KGs). Our
framework generates original prompts from the triplets of knowledge graphs and
creates adversarial prompts by poisoning, assessing the robustness of LLMs
through the results of these adversarial attacks. We systematically evaluate
the effectiveness of this framework and its modules. Experiments show that
adversarial robustness of the ChatGPT family ranks as GPT-4-turbo > GPT-4o >
GPT-3.5-turbo, and the robustness of large language models is influenced by the
professional domains in which they operate.

摘要：現有的用於評估大型語言模型 (LLM) 穩健性的框架過於依賴特定基準，這會增加成本，而且由於資料集的限制，無法評估 LLM 在專業領域的效能。本文提出了一個框架，利用知識圖譜 (KG) 系統性地評估 LLM 在對抗攻擊場景下的穩健性。我們的框架從知識圖譜的三元組中產生原始提示，並透過投毒建立對抗提示，透過這些對抗攻擊的結果來評估 LLM 的穩健性。我們系統性地評估了此框架及其模組的有效性。實驗顯示，ChatGPT 家族的對抗穩健性排名為 GPT-4-turbo > GPT-4o > GPT-3.5-turbo，而且大型語言模型的穩健性會受到其運作的專業領域影響。

##### **A Comprehensive Survey of Foundation Models in Medicine**
2406.10729v1 by Wasif Khan, Seowung Leem, Kyle B. See, Joshua K. Wong, Shaoting Zhang, Ruogu Fang

Foundation models (FMs) are large-scale deep-learning models trained on
extensive datasets using self-supervised techniques. These models serve as a
base for various downstream tasks, including healthcare. FMs have been adopted
with great success across various domains within healthcare, including natural
language processing (NLP), computer vision, graph learning, biology, and omics.
Existing healthcare-based surveys have not yet included all of these domains.
Therefore, this survey provides a comprehensive overview of FMs in healthcare.
We focus on the history, learning strategies, flagship models, applications,
and challenges of FMs. We explore how FMs such as the BERT and GPT families are
reshaping various healthcare domains, including clinical large language models,
medical image analysis, and omics data. Furthermore, we provide a detailed
taxonomy of healthcare applications facilitated by FMs, such as clinical NLP,
medical computer vision, graph learning, and other biology-related tasks.
Despite the promising opportunities FMs provide, they also have several
associated challenges, which are explained in detail. We also outline potential
future directions to provide researchers and practitioners with insights into
the potential and limitations of FMs in healthcare to advance their deployment
and mitigate associated risks.

摘要：基礎模型 (FM) 是使用自我監督技術在廣泛數據集上訓練的大規模深度學習模型。這些模型作為各種下游任務的基礎，包括醫療保健。FM 已在醫療保健的各種領域中被廣泛採用，包括自然語言處理 (NLP)、電腦視覺、圖形學習、生物學和組學。現有的基於醫療保健的調查尚未涵蓋所有這些領域。因此，本調查提供了 FM 在醫療保健中的全面概述。我們專注於 FM 的歷史、學習策略、旗艦模型、應用和挑戰。我們探討了 BERT 和 GPT 家族等 FM 如何重塑各種醫療保健領域，包括臨床大型語言模型、醫學影像分析和組學數據。此外，我們提供了由 FM 促進的醫療保健應用詳細分類法，例如臨床 NLP、醫學電腦視覺、圖形學習和其他與生物相關的任務。儘管 FM 提供了有希望的機會，但它們也面臨著一些相關的挑戰，這些挑戰在文中都有詳細說明。我們還概述了潛在的未來方向，為研究人員和從業者提供有關 FM 在醫療保健中的潛力和局限性的見解，以推進其部署並減輕相關風險。

##### **SyntheT2C: Generating Synthetic Data for Fine-Tuning Large Language Models on the Text2Cypher Task**
2406.10710v1 by Ziije Zhong, Linqing Zhong, Zhaoze Sun, Qingyun Jin, Zengchang Qin, Xiaofan Zhang

Integrating Large Language Models (LLMs) with existing Knowledge Graph (KG)
databases presents a promising avenue for enhancing LLMs' efficacy and
mitigating their "hallucinations". Given that most KGs reside in graph
databases accessible solely through specialized query languages (e.g., Cypher),
there exists a critical need to bridge the divide between LLMs and KG databases
by automating the translation of natural language into Cypher queries (commonly
termed the "Text2Cypher" task). Prior efforts tried to bolster LLMs'
proficiency in Cypher generation through Supervised Fine-Tuning. However, these
explorations are hindered by the lack of annotated datasets of Query-Cypher
pairs, resulting from the labor-intensive and domain-specific nature of
annotating such datasets. In this study, we propose SyntheT2C, a methodology
for constructing a synthetic Query-Cypher pair dataset, comprising two distinct
pipelines: (1) LLM-based prompting and (2) template-filling. SyntheT2C
facilitates the generation of extensive Query-Cypher pairs with values sampled
from an underlying Neo4j graph database. Subsequently, SyntheT2C is applied to
two medical databases, culminating in the creation of a synthetic dataset,
MedT2C. Comprehensive experiments demonstrate that the MedT2C dataset
effectively enhances the performance of backbone LLMs on the Text2Cypher task.
Both the SyntheT2C codebase and the MedT2C dataset will be released soon.

摘要：<paragraph>將大型語言模型 (LLM) 與現有的知識圖譜 (KG) 資料庫整合，提供了一個提升 LLM 效能並減輕其「幻覺」的途徑。由於大多數 KG 都存在於僅能透過專用查詢語言（例如 Cypher）存取的圖形資料庫中，因此迫切需要自動化將自然語言轉換為 Cypher 查詢，以彌合 LLM 與 KG 資料庫之間的鴻溝（通常稱為「Text2Cypher」任務）。先前的努力嘗試透過監督微調來提升 LLM 在 Cypher 生成方面的能力。然而，這些探索受到缺乏查詢-Cypher 配對的註解資料集的阻礙，這是因為此類資料集的註解需要大量人力且具有特定領域的性質。在本研究中，我們提出了 SyntheT2C，這是一種用於建構合成查詢-Cypher 配對資料集的方法，包含兩個不同的管道：(1) 基於 LLM 的提示和 (2) 範本填寫。SyntheT2C 促進了大量查詢-Cypher 配對的產生，其值取樣自基礎的 Neo4j 圖形資料庫。隨後，將 SyntheT2C 應用於兩個醫療資料庫，最終建立了一個合成資料集 MedT2C。全面的實驗證明，MedT2C 資料集有效提升了主幹 LLM 在 Text2Cypher 任務上的效能。SyntheT2C 程式碼庫和 MedT2C 資料集都將很快釋出。</paragraph>

##### **Large Language Models as Event Forecasters**
2406.10492v1 by Libo Zhang, Yue Ning

Key elements of human events are extracted as quadruples that consist of
subject, relation, object, and timestamp. This representation can be extended
to a quintuple by adding a fifth element: a textual summary that briefly
describes the event. These quadruples or quintuples, when organized within a
specific domain, form a temporal knowledge graph (TKG). Current learning
frameworks focus on a few TKG-related tasks, such as predicting an object given
a subject and a relation or forecasting the occurrences of multiple types of
events (i.e., relation) in the next time window. They typically rely on complex
structural and sequential models like graph neural networks (GNNs) and
recurrent neural networks (RNNs) to update intermediate embeddings. However,
these methods often neglect the contextual information inherent in each
quintuple, which can be effectively captured through concise textual
descriptions. In this paper, we investigate how large language models (LLMs)
can streamline the design of TKG learning frameworks while maintaining
competitive accuracy in prediction and forecasting tasks. We develop multiple
prompt templates to frame the object prediction (OP) task as a standard
question-answering (QA) task, suitable for instruction fine-tuning with an
encoder-decoder generative LLM. For multi-event forecasting (MEF), we design
simple yet effective prompt templates for each TKG quintuple. This novel
approach removes the need for GNNs and RNNs, instead utilizing an encoder-only
LLM to generate fixed intermediate embeddings, which are subsequently processed
by a prediction head with a self-attention mechanism to forecast potential
future relations. Extensive experiments on multiple real-world datasets using
various evaluation metrics validate the effectiveness and robustness of our
approach.

摘要：<paragraph>人類事件的主要元素被萃取為由主詞、關係、受詞和時間戳組成的四元組。此表示法可透過新增第五個元素來延伸為五元組：簡要描述事件的文字摘要。這些四元組或五元組在特定領域中組織時，會形成時序知識圖譜 (TKG)。目前的學習架構專注於一些與 TKG 相關的任務，例如在給定主詞和關係的情況下預測受詞，或預測下一個時間視窗中多種類型事件（即關係）的發生。它們通常依賴於複雜的結構和序列模型，例如圖形神經網路 (GNN) 和遞迴神經網路 (RNN)，來更新中間嵌入。然而，這些方法經常忽略每個五元組中固有的脈絡資訊，而這些資訊可透過簡潔的文字描述有效擷取。在本文中，我們探討大型語言模型 (LLM) 如何簡化 TKG 學習架構的設計，同時在預測和預測任務中維持具競爭力的準確度。我們開發多個提示範本，將物件預測 (OP) 任務設定為標準問答 (QA) 任務，適用於使用編碼器-解碼器生成式 LLM 進行指令微調。對於多事件預測 (MEF)，我們為每個 TKG 五元組設計簡單但有效的提示範本。這種新穎的方法消除了對 GNN 和 RNN 的需求，而是利用僅編碼器 LLM 來產生固定的中間嵌入，然後由具有自注意力機制的預測頭處理這些嵌入，以預測潛在的未來關係。使用各種評估指標對多個真實世界資料集進行的廣泛實驗驗證了我們方法的有效性和穩健性。</paragraph>

##### **Unlocking Large Language Model's Planning Capabilities with Maximum Diversity Fine-tuning**
2406.10479v1 by Wenjun Li, Changyu Chen, Pradeep Varakantham

Large language models (LLMs) have demonstrated impressive task-solving
capabilities, achieved through either prompting techniques or system designs.
However, concerns have arisen regarding their proficiency in planning tasks, as
they often struggle to generate valid plans. This paper investigates the impact
of fine-tuning on LLMs' planning capabilities. Our findings indicate that LLMs
can achieve good performance in planning through substantial (thousands of
specific examples) fine-tuning. However, fine-tuning is associated with
significant economic and computational costs. To address this challenge, we
propose the Maximum Diversity Fine-Tuning (MDFT) strategy to improve the sample
efficiency of fine-tuning in the planning domain. Specifically, our algorithm,
referred to as MDFT-g, encodes the planning task instances with their graph
representations and selects a subset of samples in the vector space that
maximizes data diversity. We empirically demonstrate that MDFT-g consistently
outperforms existing baselines at various scales across multiple benchmark
domains.

摘要：大型語言模型 (LLM) 已展現出令人印象深刻的任務解決能力，這是透過提示技術或系統設計來達成。然而，對於 LLM 在規劃任務中的能力，已產生疑慮，因為它們經常難以產生有效的計畫。本文探討微調對 LLM 規劃能力的影響。我們的研究結果顯示，LLM 可以透過大量的微調（數千個具體範例）在規劃中獲得良好的表現。然而，微調與顯著的經濟和運算成本相關。為了應對此挑戰，我們提出最大多樣性微調 (MDFT) 策略，以提升規劃領域微調的樣本效率。具體來說，我們稱為 MDFT-g 的演算法，以圖形表示對規劃任務實例進行編碼，並在向量空間中選擇一個樣本子集，以最大化資料多樣性。我們實證證明，MDFT-g 在多個基準領域的不同規模中，始終優於現有的基準。


### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-11**|**Uncertainty Estimation of Large Language Models in Medical Question Answering**|Jiaxin Wu et.al.|[2407.08662v1](http://arxiv.org/abs/2407.08662v1)|null|
|**2024-07-11**|**Establishing Rigorous and Cost-effective Clinical Trials for Artificial Intelligence Models**|Wanling Gao et.al.|[2407.08554v1](http://arxiv.org/abs/2407.08554v1)|[link](https://github.com/benchcouncil/vc-medai)|
|**2024-07-11**|**How Deep is your Guess? A Fresh Perspective on Deep Learning for Medical Time-Series Imputation**|Linglong Qian et.al.|[2407.08442v1](http://arxiv.org/abs/2407.08442v1)|null|
|**2024-07-11**|**Specialist vision-language models for clinical ophthalmology**|Robbie Holland et.al.|[2407.08410v1](http://arxiv.org/abs/2407.08410v1)|null|
|**2024-07-11**|**Unveiling Disparities in Maternity Care: A Topic Modelling Approach to Analysing Maternity Incident Investigation Reports**|Georgina Cosma et.al.|[2407.08328v1](http://arxiv.org/abs/2407.08328v1)|null|
|**2024-07-11**|**Predicting Heart Failure with Attention Learning Techniques Utilizing Cardiovascular Data**|Ershadul Haque et.al.|[2407.08289v1](http://arxiv.org/abs/2407.08289v1)|null|
|**2024-07-11**|**Leveraging LLMs to Predict Affective States via Smartphone Sensor Features**|Tianyi Zhang et.al.|[2407.08240v1](http://arxiv.org/abs/2407.08240v1)|null|
|**2024-07-11**|**DALL-M: Context-Aware Clinical Data Augmentation with LLMs**|Chihcheng Hsieh et.al.|[2407.08227v1](http://arxiv.org/abs/2407.08227v1)|[link](https://github.com/chihchenghsieh/dall-m)|
|**2024-07-11**|**Synthetic Electroretinogram Signal Generation Using Conditional Generative Adversarial Network for Enhancing Classification of Autism Spectrum Disorder**|Mikhail Kulyabin et.al.|[2407.08166v1](http://arxiv.org/abs/2407.08166v1)|null|
|**2024-07-11**|**Highway Networks for Improved Surface Reconstruction: The Role of Residuals and Weight Updates**|A. Noorizadegan et.al.|[2407.08134v1](http://arxiv.org/abs/2407.08134v1)|[link](https://github.com/cmmai/resnet_for_pinn)|
|**2024-07-10**|**Machine Learning for ALSFRS-R Score Prediction: Making Sense of the Sensor Data**|Ritesh Mehta et.al.|[2407.08003v1](http://arxiv.org/abs/2407.08003v1)|null|
|**2024-07-10**|**The Human Factor in AI Red Teaming: Perspectives from Social and Collaborative Computing**|Alice Qian Zhang et.al.|[2407.07786v1](http://arxiv.org/abs/2407.07786v1)|null|
|**2024-07-10**|**A Proposed S.C.O.R.E. Evaluation Framework for Large Language Models : Safety, Consensus, Objectivity, Reproducibility and Explainability**|Ting Fang Tan et.al.|[2407.07666v1](http://arxiv.org/abs/2407.07666v1)|null|
|**2024-07-10**|**Boosting Medical Image Synthesis via Registration-guided Consistency and Disentanglement Learning**|Chuanpu Li et.al.|[2407.07660v1](http://arxiv.org/abs/2407.07660v1)|null|
|**2024-07-10**|**H-FCBFormer Hierarchical Fully Convolutional Branch Transformer for Occlusal Contact Segmentation with Articulating Paper**|Ryan Banks et.al.|[2407.07604v1](http://arxiv.org/abs/2407.07604v1)|[link](https://github.com/banksylel/h-fcbformer)|
|**2024-07-10**|**FLAIR: Feeding via Long-horizon AcquIsition of Realistic dishes**|Rajat Kumar Jenamani et.al.|[2407.07561v1](http://arxiv.org/abs/2407.07561v1)|null|
|**2024-07-10**|**Arabic Automatic Story Generation with Large Language Models**|Ahmed Oumar El-Shangiti et.al.|[2407.07551v1](http://arxiv.org/abs/2407.07551v1)|null|
|**2024-07-10**|**Weakly-supervised Medical Image Segmentation with Gaze Annotations**|Yuan Zhong et.al.|[2407.07406v1](http://arxiv.org/abs/2407.07406v1)|[link](https://github.com/med-air/gazemedseg)|
|**2024-07-10**|**Interpretable Differential Diagnosis with Dual-Inference Large Language Models**|Shuang Zhou et.al.|[2407.07330v1](http://arxiv.org/abs/2407.07330v1)|null|
|**2024-07-10**|**Large Language Model-Augmented Auto-Delineation of Treatment Target Volume in Radiation Therapy**|Praveenbalaji Rajendran et.al.|[2407.07296v1](http://arxiv.org/abs/2407.07296v1)|null|
|**2024-07-10**|**Causal Discovery in Semi-Stationary Time Series**|Shanyun Gao et.al.|[2407.07291v1](http://arxiv.org/abs/2407.07291v1)|[link](https://github.com/causalml-lab/pcmci-omega)|
|**2024-07-10**|**Causal Discovery-Driven Change Point Detection in Time Series**|Shanyun Gao et.al.|[2407.07290v1](http://arxiv.org/abs/2407.07290v1)|null|
|**2024-07-09**|**Lifestyle-Informed Personalized Blood Biomarker Prediction via Novel Representation Learning**|A. Ali Heydari et.al.|[2407.07277v1](http://arxiv.org/abs/2407.07277v1)|null|
|**2024-07-09**|**ProtoSAM -- One Shot Medical Image Segmentation With Foundational Models**|Lev Ayzenberg et.al.|[2407.07042v1](http://arxiv.org/abs/2407.07042v1)|null|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-09**|**Microsoft Cloud-based Digitization Workflow with Rich Metadata Acquisition for Cultural Heritage Objects**|Krzysztof Kutt et.al.|[2407.06972v1](http://arxiv.org/abs/2407.06972v1)|null|
|**2024-07-09**|**TE-SSL: Time and Event-aware Self Supervised Learning for Alzheimer's Disease Progression Analysis**|Jacob Thrasher et.al.|[2407.06852v1](http://arxiv.org/abs/2407.06852v1)|[link](https://github.com/jacob-thrasher/te-ssl)|
|**2024-07-09**|**VRDSynth: Synthesizing Programs for Multilingual Visually Rich Document Information Extraction**|Thanh-Dat Nguyen et.al.|[2407.06826v1](http://arxiv.org/abs/2407.06826v1)|null|
|**2024-07-09**|**iASiS: Towards Heterogeneous Big Data Analysis for Personalized Medicine**|Anastasia Krithara et.al.|[2407.06748v1](http://arxiv.org/abs/2407.06748v1)|null|
|**2024-07-09**|**TCKIN: A Novel Integrated Network Model for Predicting Mortality Risk in Sepsis Patients**|Fanglin Dong et.al.|[2407.06560v1](http://arxiv.org/abs/2407.06560v1)|null|
|**2024-07-08**|**AI-driven multi-omics integration for multi-scale predictive modeling of causal genotype-environment-phenotype relationships**|You Wu et.al.|[2407.06405v1](http://arxiv.org/abs/2407.06405v1)|null|
|**2024-07-08**|**Multimodal Chain-of-Thought Reasoning via ChatGPT to Protect Children from Age-Inappropriate Apps**|Chuanbo Hu et.al.|[2407.06309v1](http://arxiv.org/abs/2407.06309v1)|null|
|**2024-07-08**|**Hybrid X-Linker: Automated Data Generation and Extreme Multi-label Ranking for Biomedical Entity Linking**|Pedro Ruas et.al.|[2407.06292v1](http://arxiv.org/abs/2407.06292v1)|null|
|**2024-07-08**|**Depression Detection and Analysis using Large Language Models on Textual and Audio-Visual Modalities**|Avinash Anand et.al.|[2407.06125v1](http://arxiv.org/abs/2407.06125v1)|null|
|**2024-07-08**|**Igea: a Decoder-Only Language Model for Biomedical Text Generation in Italian**|Tommaso Mario Buonocore et.al.|[2407.06011v1](http://arxiv.org/abs/2407.06011v1)|null|
|**2024-07-08**|**Generation and De-Identification of Indian Clinical Discharge Summaries using LLMs**|Sanjeet Singh et.al.|[2407.05887v1](http://arxiv.org/abs/2407.05887v1)|null|
|**2024-07-08**|**Integrating AI in College Education: Positive yet Mixed Experiences with ChatGPT**|Xinrui Song et.al.|[2407.05810v1](http://arxiv.org/abs/2407.05810v1)|null|
|**2024-07-08**|**FedMRL: Data Heterogeneity Aware Federated Multi-agent Deep Reinforcement Learning for Medical Imaging**|Pranab Sahoo et.al.|[2407.05800v1](http://arxiv.org/abs/2407.05800v1)|[link](https://github.com/pranabiitp/fedmrl)|
|**2024-07-08**|**Large Language Models for Judicial Entity Extraction: A Comparative Study**|Atin Sakkeer Hussain et.al.|[2407.05786v1](http://arxiv.org/abs/2407.05786v1)|null|
|**2024-07-08**|**Potential of Multimodal Large Language Models for Data Mining of Medical Images and Free-text Reports**|Yutong Zhang et.al.|[2407.05758v1](http://arxiv.org/abs/2407.05758v1)|null|
|**2024-07-08**|**RadiomicsFill-Mammo: Synthetic Mammogram Mass Manipulation with Radiomics Features**|Inye Na et.al.|[2407.05683v1](http://arxiv.org/abs/2407.05683v1)|[link](https://github.com/nainye/radiomicsfill)|
|**2024-07-08**|**WSI-VQA: Interpreting Whole Slide Images by Generative Visual Question Answering**|Pingyi Chen et.al.|[2407.05603v1](http://arxiv.org/abs/2407.05603v1)|[link](https://github.com/cpystan/wsi-vqa)|
|**2024-07-07**|**Accelerating MRI Uncertainty Estimation with Mask-based Bayesian Neural Network**|Zehuan Zhang et.al.|[2407.05521v1](http://arxiv.org/abs/2407.05521v1)|null|
|**2024-07-07**|**A Survey of Models for Cognitive Diagnosis: New Developments and Future Directions**|Fei Wang et.al.|[2407.05458v1](http://arxiv.org/abs/2407.05458v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v1](http://arxiv.org/abs/2407.05440v1)|null|
|**2024-07-07**|**FM-OSD: Foundation Model-Enabled One-Shot Detection of Anatomical Landmarks**|Juzheng Miao et.al.|[2407.05412v1](http://arxiv.org/abs/2407.05412v1)|[link](https://github.com/juzhengmiao/fm-osd)|
|**2024-07-06**|**BadCLM: Backdoor Attack in Clinical Language Models for Electronic Health Records**|Weimin Lyu et.al.|[2407.05213v1](http://arxiv.org/abs/2407.05213v1)|null|
|**2024-07-06**|**RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models**|Peng Xia et.al.|[2407.05131v1](http://arxiv.org/abs/2407.05131v1)|[link](https://github.com/richard-peng-xia/rule)|
|**2024-07-06**|**Linear Attention Based Deep Nonlocal Means Filtering for Multiplicative Noise Removal**|Xiao Siyao et.al.|[2407.05087v1](http://arxiv.org/abs/2407.05087v1)|null|
|**2024-07-05**|**Brain Age Estimation with a Greedy Dual-Stream Model for Limited Datasets**|Iman Kianian et.al.|[2407.04808v1](http://arxiv.org/abs/2407.04808v1)|[link](https://github.com/iman2693/gdsm)|
|**2024-07-05**|**Entity Decomposition with Filtering: A Zero-Shot Clinical Named Entity Recognition Framework**|Reza Averly et.al.|[2407.04629v1](http://arxiv.org/abs/2407.04629v1)|null|
|**2024-07-05**|**Variational and Explanatory Neural Networks for Encoding Cancer Profiles and Predicting Drug Responses**|Tianshu Feng et.al.|[2407.04486v1](http://arxiv.org/abs/2407.04486v1)|null|
|**2024-07-05**|**Multi-modal Masked Siamese Network Improves Chest X-Ray Representation Learning**|Saeed Shurrab et.al.|[2407.04449v1](http://arxiv.org/abs/2407.04449v1)|[link](https://github.com/nyuad-cai/cxr-ehr-msn)|
|**2024-07-04**|**Query-Guided Self-Supervised Summarization of Nursing Notes**|Ya Gao et.al.|[2407.04125v1](http://arxiv.org/abs/2407.04125v1)|null|
|**2024-07-04**|**MiniGPT-Med: Large Language Model as a General Interface for Radiology Diagnosis**|Asma Alkhaldi et.al.|[2407.04106v1](http://arxiv.org/abs/2407.04106v1)|[link](https://github.com/vision-cair/minigpt-med)|
|**2024-07-04**|**Unsupervised Analysis of Alzheimer's Disease Signatures using 3D Deformable Autoencoders**|Mehmet Yigit Avci et.al.|[2407.03863v1](http://arxiv.org/abs/2407.03863v1)|[link](https://github.com/ci-ber/morphade)|
|**2024-07-04**|**CaseGPT: a case reasoning framework based on language models and retrieval-augmented generation**|Rui Yang et.al.|[2407.07913v1](http://arxiv.org/abs/2407.07913v1)|null|
|**2024-07-04**|**Integrating Randomness in Large Language Models: A Linear Congruential Generator Approach for Generating Clinically Relevant Content**|Andrew Bouras et.al.|[2407.03582v1](http://arxiv.org/abs/2407.03582v1)|[link](https://github.com/andrewbouras/randomnesspaper)|
|**2024-07-03**|**Accelerated Proton Resonance Frequency-based Magnetic Resonance Thermometry by Optimized Deep Learning Method**|Sijie Xu et.al.|[2407.03308v1](http://arxiv.org/abs/2407.03308v1)|[link](https://github.com/minipuding/fastmrt)|
|**2024-07-03**|**MVGT: A Multi-view Graph Transformer Based on Spatial Relations for EEG Emotion Recognition**|Yanjie Cui et.al.|[2407.03131v2](http://arxiv.org/abs/2407.03131v2)|null|
|**2024-07-03**|**Effective Heterogeneous Federated Learning via Efficient Hypernetwork-based Weight Generation**|Yujin Shin et.al.|[2407.03086v1](http://arxiv.org/abs/2407.03086v1)|null|
|**2024-07-03**|**Attention Incorporated Network for Sharing Low-rank, Image and K-space Information during MR Image Reconstruction to Achieve Single Breath-hold Cardiac Cine Imaging**|Siying Xu et.al.|[2407.03034v1](http://arxiv.org/abs/2407.03034v1)|[link](https://github.com/midas-tum/a-liknet)|
|**2024-07-03**|**SemioLLM: Assessing Large Language Models for Semiological Analysis in Epilepsy Research**|Meghal Dani et.al.|[2407.03004v1](http://arxiv.org/abs/2407.03004v1)|null|
|**2024-07-03**|**MedPix 2.0: A Comprehensive Multimodal Biomedical Dataset for Advanced AI Applications**|Irene Siragusa et.al.|[2407.02994v1](http://arxiv.org/abs/2407.02994v1)|[link](https://github.com/chilab1/medpix-2.0)|
|**2024-07-03**|**Membership Inference Attacks Against Time-Series Models**|Noam Koren et.al.|[2407.02870v1](http://arxiv.org/abs/2407.02870v1)|null|
|**2024-07-03**|**Effect of a Process Mining based Pre-processing Step in Prediction of the Critical Health Outcomes**|Negin Ashrafi et.al.|[2407.02821v1](http://arxiv.org/abs/2407.02821v1)|null|
|**2024-07-03**|**MedVH: Towards Systematic Evaluation of Hallucination for Large Vision Language Models in the Medical Context**|Zishan Gu et.al.|[2407.02730v1](http://arxiv.org/abs/2407.02730v1)|[link](https://github.com/dongzizhu/medvh)|
|**2024-07-02**|**D-Rax: Domain-specific Radiologic assistant leveraging multi-modal data and eXpert model predictions**|Hareem Nisar et.al.|[2407.02604v1](http://arxiv.org/abs/2407.02604v1)|null|
|**2024-07-02**|**MMedAgent: Learning to Use Medical Tools with Multi-modal Agent**|Binxu Li et.al.|[2407.02483v1](http://arxiv.org/abs/2407.02483v1)|null|
|**2024-07-02**|**CALICO: Confident Active Learning with Integrated Calibration**|Lorenzo S. Querol et.al.|[2407.02335v1](http://arxiv.org/abs/2407.02335v1)|null|
|**2024-07-02**|**A Refreshed Similarity-based Upsampler for Direct High-Ratio Feature Upsampling**|Minghao Zhou et.al.|[2407.02283v1](http://arxiv.org/abs/2407.02283v1)|[link](https://github.com/zmhhmz/resfu)|
|**2024-07-02**|**FedIA: Federated Medical Image Segmentation with Heterogeneous Annotation Completeness**|Yangyang Xiang et.al.|[2407.02280v2](http://arxiv.org/abs/2407.02280v2)|[link](https://github.com/hustxyy/fedia)|
|**2024-07-02**|**Generative Monoculture in Large Language Models**|Fan Wu et.al.|[2407.02209v1](http://arxiv.org/abs/2407.02209v1)|[link](https://github.com/GeMoLLM/GeMO)|
|**2024-07-02**|**Abstract Dialectical Frameworks are Boolean Networks (full version)**|Jesse Heyninck et.al.|[2407.02055v1](http://arxiv.org/abs/2407.02055v1)|null|
|**2024-07-02**|**A Method to Facilitate Membership Inference Attacks in Deep Learning Models**|Zitao Chen et.al.|[2407.01919v1](http://arxiv.org/abs/2407.01919v1)|[link](https://github.com/DependableSystemsLab/code_poison_MIA)|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-07-01**|**Optimized Learning for X-Ray Image Classification for Multi-Class Disease Diagnoses with Accelerated Computing Strategies**|Sebastian A. Cruz Romero et.al.|[2407.01705v1](http://arxiv.org/abs/2407.01705v1)|null|
|**2024-07-01**|**Deep Dive into MRI: Exploring Deep Learning Applications in 0.55T and 7T MRI**|Ana Carolina Alves et.al.|[2407.01318v1](http://arxiv.org/abs/2407.01318v1)|null|
|**2024-07-01**|**MIRAI: Evaluating LLM Agents for Event Forecasting**|Chenchen Ye et.al.|[2407.01231v1](http://arxiv.org/abs/2407.01231v1)|null|
|**2024-07-01**|**Integrated feature analysis for deep learning interpretation and class activation maps**|Yanli Li et.al.|[2407.01142v1](http://arxiv.org/abs/2407.01142v1)|[link](https://github.com/yanlili27/ifa)|
|**2024-07-01**|**An Outline of Prognostics and Health Management Large Model: Concepts, Paradigms, and Challenges**|Laifa Tao et.al.|[2407.03374v1](http://arxiv.org/abs/2407.03374v1)|null|
|**2024-07-01**|**Embedded Prompt Tuning: Towards Enhanced Calibration of Pretrained Models for Medical Images**|Wenqiang Zu et.al.|[2407.01003v2](http://arxiv.org/abs/2407.01003v2)|[link](https://github.com/zuwenqiang/ept)|
|**2024-07-01**|**Individual brain parcellation: Review of methods, validations and applications**|Chengyi Li et.al.|[2407.00984v1](http://arxiv.org/abs/2407.00984v1)|null|
|**2024-07-01**|**Hybrid RAG-empowered Multi-modal LLM for Secure Healthcare Data Management: A Diffusion-based Contract Theory Approach**|Cheng Su et.al.|[2407.00978v1](http://arxiv.org/abs/2407.00978v1)|null|
|**2024-07-01**|**Optimizing PM2.5 Forecasting Accuracy with Hybrid Meta-Heuristic and Machine Learning Models**|Parviz Ghafariasl et.al.|[2407.01647v1](http://arxiv.org/abs/2407.01647v1)|null|
|**2024-07-01**|**Deep learning for automated detection of breast cancer in deep ultraviolet fluorescence images with diffusion probabilistic model**|Sepehr Salem Ghahfarokhi et.al.|[2407.00967v1](http://arxiv.org/abs/2407.00967v1)|null|
|**2024-06-30**|**Characterizing Stereotypical Bias from Privacy-preserving Pre-Training**|Stefan Arnold et.al.|[2407.00764v1](http://arxiv.org/abs/2407.00764v1)|null|
|**2024-06-30**|**Chest-Diffusion: A Light-Weight Text-to-Image Model for Report-to-CXR Generation**|Peng Huang et.al.|[2407.00752v1](http://arxiv.org/abs/2407.00752v1)|null|
|**2024-06-30**|**Large Language Models Struggle in Token-Level Clinical Named Entity Recognition**|Qiuhao Lu et.al.|[2407.00731v1](http://arxiv.org/abs/2407.00731v1)|null|
|**2024-06-30**|**SCMIL: Sparse Context-aware Multiple Instance Learning for Predicting Cancer Survival Probability Distribution in Whole Slide Images**|Zekang Yang et.al.|[2407.00664v1](http://arxiv.org/abs/2407.00664v1)|[link](https://github.com/yang-ze-kang/scmil)|
|**2024-06-30**|**TrialBench: Multi-Modal Artificial Intelligence-Ready Clinical Trial Datasets**|Jintai Chen et.al.|[2407.00631v1](http://arxiv.org/abs/2407.00631v1)|[link](https://github.com/ml2health/ml2clinicaltrials)|
|**2024-06-29**|**Answering real-world clinical questions using large language model based systems**|Yen Sia Low et.al.|[2407.00541v1](http://arxiv.org/abs/2407.00541v1)|null|
|**2024-06-29**|**Privacy-Preserving and Trustworthy Deep Learning for Medical Imaging**|Kiarash Sedghighadikolaei et.al.|[2407.00538v1](http://arxiv.org/abs/2407.00538v1)|null|
|**2024-06-29**|**Interpreting Pretrained Speech Models for Automatic Speech Assessment of Voice Disorders**|Hok-Shing Lau et.al.|[2407.00531v1](http://arxiv.org/abs/2407.00531v1)|null|
|**2024-06-29**|**ConU: Conformal Uncertainty in Large Language Models with Correctness Coverage Guarantees**|Zhiyuan Wang et.al.|[2407.00499v1](http://arxiv.org/abs/2407.00499v1)|null|
|**2024-06-29**|**MH-pFLGB: Model Heterogeneous personalized Federated Learning via Global Bypass for Medical Image Analysis**|Luyuan Xie et.al.|[2407.00474v1](http://arxiv.org/abs/2407.00474v1)|null|
|**2024-06-29**|**pFLFE: Cross-silo Personalized Federated Learning via Feature Enhancement on Medical Image Segmentation**|Luyuan Xie et.al.|[2407.00462v1](http://arxiv.org/abs/2407.00462v1)|null|
|**2024-06-29**|**Is It Really Long Context if All You Need Is Retrieval? Towards Genuinely Difficult Long Context NLP**|Omer Goldman et.al.|[2407.00402v2](http://arxiv.org/abs/2407.00402v2)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-28**|**Predicting Elevated Risk of Hospitalization Following Emergency Department Discharges**|Dat Hong et.al.|[2407.00147v1](http://arxiv.org/abs/2407.00147v1)|null|

#### Abstracts
##### **Uncertainty Estimation of Large Language Models in Medical Question Answering**
2407.08662v1 by Jiaxin Wu, Yizhou Yu, Hong-Yu Zhou

Large Language Models (LLMs) show promise for natural language generation in
healthcare, but risk hallucinating factually incorrect information. Deploying
LLMs for medical question answering necessitates reliable uncertainty
estimation (UE) methods to detect hallucinations. In this work, we benchmark
popular UE methods with different model sizes on medical question-answering
datasets. Our results show that current approaches generally perform poorly in
this domain, highlighting the challenge of UE for medical applications. We also
observe that larger models tend to yield better results, suggesting a
correlation between model size and the reliability of UE. To address these
challenges, we propose Two-phase Verification, a probability-free Uncertainty
Estimation approach. First, an LLM generates a step-by-step explanation
alongside its initial answer, followed by formulating verification questions to
check the factual claims in the explanation. The model then answers these
questions twice: first independently, and then referencing the explanation.
Inconsistencies between the two sets of answers measure the uncertainty in the
original response. We evaluate our approach on three biomedical
question-answering datasets using Llama 2 Chat models and compare it against
the benchmarked baseline methods. The results show that our Two-phase
Verification method achieves the best overall accuracy and stability across
various datasets and model sizes, and its performance scales as the model size
increases.

摘要：大型語言模型 (LLM) 在醫療保健領域的自然語言生成方面顯示出前景，但存在虛構事實不正確資訊的風險。部署 LLM 來回答醫療問題需要可靠的不確定性估計 (UE) 方法來偵測虛構。在這項工作中，我們使用不同模型大小對熱門 UE 方法進行基準測試，針對醫療問題回答資料集。我們的結果顯示，目前的作法在這方面通常表現不佳，突顯了 UE 在醫療應用中的挑戰。我們還觀察到，較大的模型往往會產生更好的結果，這表明模型大小與 UE 的可靠性之間存在相關性。為了應對這些挑戰，我們提出了兩階段驗證，一種無機率的不確定性估計方法。首先，LLM 會在其初始答案旁邊產生逐步說明，然後制定驗證問題來檢查說明中的事實聲明。然後，模型回答這些問題兩次：第一次獨立回答，然後參考說明。兩組答案之間的不一致性衡量原始回應中的不確定性。我們使用 Llama 2 Chat 模型在三個生物醫學問題回答資料集上評估我們的作法，並將其與基準基準方法進行比較。結果顯示，我們的兩階段驗證方法在各種資料集和模型大小中實現了最佳的整體準確性和穩定性，並且其效能隨著模型大小的增加而擴展。

##### **Establishing Rigorous and Cost-effective Clinical Trials for Artificial Intelligence Models**
2407.08554v1 by Wanling Gao, Yunyou Huang, Dandan Cui, Zhuoming Yu, Wenjing Liu, Xiaoshuang Liang, Jiahui Zhao, Jiyue Xie, Hao Li, Li Ma, Ning Ye, Yumiao Kang, Dingfeng Luo, Peng Pan, Wei Huang, Zhongmou Liu, Jizhong Hu, Gangyuan Zhao, Chongrong Jiang, Fan Huang, Tianyi Wei, Suqin Tang, Bingjie Xia, Zhifei Zhang, Jianfeng Zhan

A profound gap persists between artificial intelligence (AI) and clinical
practice in medicine, primarily due to the lack of rigorous and cost-effective
evaluation methodologies. State-of-the-art and state-of-the-practice AI model
evaluations are limited to laboratory studies on medical datasets or direct
clinical trials with no or solely patient-centered controls. Moreover, the
crucial role of clinicians in collaborating with AI, pivotal for determining
its impact on clinical practice, is often overlooked. For the first time, we
emphasize the critical necessity for rigorous and cost-effective evaluation
methodologies for AI models in clinical practice, featuring
patient/clinician-centered (dual-centered) AI randomized controlled trials
(DC-AI RCTs) and virtual clinician-based in-silico trials (VC-MedAI) as an
effective proxy for DC-AI RCTs. Leveraging 7500 diagnosis records from
two-phase inaugural DC-AI RCTs across 14 medical centers with 125 clinicians,
our results demonstrate the necessity of DC-AI RCTs and the effectiveness of
VC-MedAI. Notably, VC-MedAI performs comparably to human clinicians,
replicating insights and conclusions from prospective DC-AI RCTs. We envision
DC-AI RCTs and VC-MedAI as pivotal advancements, presenting innovative and
transformative evaluation methodologies for AI models in clinical practice,
offering a preclinical-like setting mirroring conventional medicine, and
reshaping development paradigms in a cost-effective and fast-iterative manner.
Chinese Clinical Trial Registration: ChiCTR2400086816.

摘要：<paragraph>人工智慧（AI）與臨床醫療實務之間存在著巨大的鴻溝，其主要原因在於缺乏嚴謹且具成本效益的評估方法。最先進且符合實務的 AI 模型評估僅限於針對醫學資料集進行的實驗室研究，或僅有患者為中心的對照組的直接臨床試驗。此外，臨床醫師在與 AI 合作中所扮演的關鍵角色，對於決定其對臨床實務的影響至關重要，卻經常被忽視。我們首度強調在臨床實務中採用嚴謹且具成本效益的 AI 模型評估方法至關重要，其特色在於以患者／臨床醫師為中心的（雙中心）AI 隨機對照試驗（DC-AI RCT）和虛擬臨床醫師為基礎的電腦模擬試驗（VC-MedAI），做為 DC-AI RCT 的有效替代方案。利用來自 14 個醫療中心、125 位臨床醫師的兩階段首次 DC-AI RCT 中的 7500 筆診斷紀錄，我們的結果證明了 DC-AI RCT 的必要性與 VC-MedAI 的有效性。值得注意的是，VC-MedAI 的表現與人類臨床醫師相當，複製了前瞻性 DC-AI RCT 的見解和結論。我們將 DC-AI RCT 和 VC-MedAI 視為關鍵的進展，它們提出了創新且具有變革性的 AI 模型評估方法，在臨床實務中提供類似於臨床前設定的環境，反映傳統醫學，並以具成本效益且快速反覆運算的方式重新塑造開發模式。中國臨床試驗註冊：ChiCTR2400086816。</paragraph>

##### **How Deep is your Guess? A Fresh Perspective on Deep Learning for Medical Time-Series Imputation**
2407.08442v1 by Linglong Qian, Tao Wang, Jun Wang, Hugh Logan Ellis, Robin Mitra, Richard Dobson, Zina Ibrahim

We introduce a novel classification framework for time-series imputation
using deep learning, with a particular focus on clinical data. By identifying
conceptual gaps in the literature and existing reviews, we devise a taxonomy
grounded on the inductive bias of neural imputation frameworks, resulting in a
classification of existing deep imputation strategies based on their
suitability for specific imputation scenarios and data-specific properties. Our
review further examines the existing methodologies employed to benchmark deep
imputation models, evaluating their effectiveness in capturing the missingness
scenarios found in clinical data and emphasising the importance of reconciling
mathematical abstraction with clinical insights. Our classification aims to
serve as a guide for researchers to facilitate the selection of appropriate
deep learning imputation techniques tailored to their specific clinical data.
Our novel perspective also highlights the significance of bridging the gap
between computational methodologies and medical insights to achieve clinically
sound imputation models.

摘要：我們提出了一個新的時間序列插補分類架構，使用深度學習，特別關注臨床數據。通過找出文獻和現有評論中的概念差距，我們設計了一個分類法，該分類法基於神經插補框架的歸納偏誤，從而對現有的深度插補策略進行分類，基於它們對特定插補場景和數據特定屬性的適用性。我們的回顧進一步檢驗了用於對深度插補模型進行基準測試的現有方法，評估了它們在捕捉臨床數據中發現的缺失場景方面的有效性，並強調了調和數學抽象與臨床見解的重要性。我們的分類旨在作為研究人員的指南，以促進根據其特定臨床數據選擇適當的深度學習插補技術。我們的新觀點還強調了彌合計算方法和醫學見解之間差距以實現臨床合理插補模型的重要性。

##### **Specialist vision-language models for clinical ophthalmology**
2407.08410v1 by Robbie Holland, Thomas R. P. Taylor, Christopher Holmes, Sophie Riedl, Julia Mai, Maria Patsiamanidi, Dimitra Mitsopoulou, Paul Hager, Philip Müller, Hendrik P. N. Scholl, Hrvoje Bogunović, Ursula Schmidt-Erfurth, Daniel Rueckert, Sobha Sivaprasad, Andrew J. Lotery, Martin J. Menten

Clinicians spend a significant amount of time reviewing medical images and
transcribing their findings regarding patient diagnosis, referral and treatment
in text form. Vision-language models (VLMs), which automatically interpret
images and summarize their findings as text, have enormous potential to
alleviate clinical workloads and increase patient access to high-quality
medical care. While foundational models have stirred considerable interest in
the medical community, it is unclear whether their general capabilities
translate to real-world clinical utility. In this work, we show that foundation
VLMs markedly underperform compared to practicing ophthalmologists on
specialist tasks crucial to the care of patients with age-related macular
degeneration (AMD). To address this, we initially identified the essential
capabilities required for image-based clinical decision-making, and then
developed a curriculum to selectively train VLMs in these skills. The resulting
model, RetinaVLM, can be instructed to write reports that significantly
outperform those written by leading foundation medical VLMs in disease staging
(F1 score of 0.63 vs. 0.11) and patient referral (0.67 vs. 0.39), and
approaches the diagnostic performance of junior ophthalmologists (who achieve
0.77 and 0.78 on the respective tasks). Furthermore, in a reader study
involving two senior ophthalmologists with up to 32 years of experience,
RetinaVLM's reports were found to be similarly correct (78.6% vs. 82.1%) and
complete (both 78.6%) as reports written by junior ophthalmologists with up to
10 years of experience. These results demonstrate that our curriculum-based
approach provides a blueprint for specializing generalist foundation medical
VLMs to handle real-world clinical tasks.

摘要：<paragraph>臨床醫生花費大量時間檢閱醫療影像，並以文字形式記錄他們關於患者診斷、轉診和治療的發現。視覺語言模型 (VLM) 會自動解讀影像並將其發現摘要成文字，具有減輕臨床工作負載和增加患者獲得優質醫療保健的機會的巨大潛力。雖然基礎模型在醫療界引起了相當大的興趣，但尚不清楚它們的一般能力是否能轉化為實際的臨床效用。在這項工作中，我們表明基礎 VLM 在與年齡相關性黃斑部病變 (AMD) 患者照護至關重要的專門任務上，表現明顯不如執業眼科醫生。為了解決這個問題，我們最初找出影像式臨床決策所需的必要能力，然後制定課程來選擇性地訓練 VLM 這些技能。所產生的模型 RetinaVLM 可以被指示撰寫報告，其在疾病分期（F1 分數為 0.63 對 0.11）和患者轉診（0.67 對 0.39）方面明顯優於領先的基礎醫療 VLM 所撰寫的報告，並接近初級眼科醫生的診斷表現（在各項任務中分別達到 0.77 和 0.78）。此外，在涉及兩位擁有長達 32 年經驗的高級眼科醫生的讀者研究中，發現 RetinaVLM 的報告正確性（78.6% 對 82.1%）和完整性（均為 78.6%）與擁有長達 10 年經驗的初級眼科醫生所撰寫的報告相似。這些結果表明，我們基於課程的方法提供了將通才基礎醫療 VLM 專門化以處理實際臨床任務的藍圖。</paragraph>

##### **Unveiling Disparities in Maternity Care: A Topic Modelling Approach to Analysing Maternity Incident Investigation Reports**
2407.08328v1 by Georgina Cosma, Mohit Kumar Singh, Patrick Waterson, Gyuchan Thomas Jun, Jonathan Back

This study applies Natural Language Processing techniques, including Latent
Dirichlet Allocation, to analyse anonymised maternity incident investigation
reports from the Healthcare Safety Investigation Branch. The reports underwent
preprocessing, annotation using the Safety Intelligence Research taxonomy, and
topic modelling to uncover prevalent topics and detect differences in maternity
care across ethnic groups. A combination of offline and online methods was
utilised to ensure data protection whilst enabling advanced analysis, with
offline processing for sensitive data and online processing for non-sensitive
data using the `Claude 3 Opus' language model. Interactive topic analysis and
semantic network visualisation were employed to extract and display thematic
topics and visualise semantic relationships among keywords. The analysis
revealed disparities in care among different ethnic groups, with distinct focus
areas for the Black, Asian, and White British ethnic groups. The study
demonstrates the effectiveness of topic modelling and NLP techniques in
analysing maternity incident investigation reports and highlighting disparities
in care. The findings emphasise the crucial role of advanced data analysis in
improving maternity care quality and equity.

摘要：本研究應用自然語言處理技術，包括潛在狄利克雷分配，分析醫療保健安全調查局的匿名產婦事件調查報告。這些報告經過預處理、使用安全情報研究分類法註解，以及主題建模，以找出普遍的主題並找出不同族群在產前照護的差異。結合離線和線上方法，以確保資料保護，同時進行進階分析，使用 Claude 3 Opus 語言模型對敏感資料進行離線處理，對非敏感資料進行線上處理。採用互動主題分析和語意網路視覺化，以萃取和顯示主題主題，並視覺化關鍵字之間的語意關係。分析顯示不同族群之間的照護差異，黑人、亞洲人和白人英國人族群的關注領域不同。本研究證明了主題建模和自然語言處理技術在分析產婦事件調查報告和強調照護差異方面的有效性。研究結果強調了進階資料分析在提升產前照護品質和公平性方面的關鍵角色。

##### **Predicting Heart Failure with Attention Learning Techniques Utilizing Cardiovascular Data**
2407.08289v1 by Ershadul Haque, Manoranjan Paul, Faranak Tohidi

Cardiovascular diseases (CVDs) encompass a group of disorders affecting the
heart and blood vessels, including conditions such as coronary artery disease,
heart failure, stroke, and hypertension. In cardiovascular diseases, heart
failure is one of the main causes of death and also long-term suffering in
patients worldwide. Prediction is one of the risk factors that is highly
valuable for treatment and intervention to minimize heart failure. In this
work, an attention learning-based heart failure prediction approach is proposed
on EHR(electronic health record) cardiovascular data such as ejection fraction
and serum creatinine. Moreover, different optimizers with various learning rate
approaches are applied to fine-tune the proposed approach. Serum creatinine and
ejection fraction are the two most important features to predict the patient's
heart failure. The computational result shows that the RMSProp optimizer with
0.001 learning rate has a better prediction based on serum creatinine. On the
other hand, the combination of SGD optimizer with 0.01 learning rate exhibits
optimum performance based on ejection fraction features. Overall, the proposed
attention learning-based approach performs very efficiently in predicting heart
failure compared to the existing state-of-the-art such as LSTM approach.

摘要：心血管疾病 (CVD) 包含一組影響心臟和血管的疾病，包括冠狀動脈疾病、心衰竭、中風和高血壓等疾病。在心血管疾病中，心衰竭是全球患者死亡的主要原因之一，也是長期痛苦的來源。預測是對治療和干預以最大程度減少心衰竭極有價值的風險因素之一。在這項工作中，提出了一種基於注意力學習的心衰竭預測方法，該方法基於 EHR（電子健康記錄）心血管數據，例如射血分數和血清肌酐。此外，應用具有各種學習率方法的不同優化器對所提出的方法進行微調。血清肌酐和射血分數是預測患者心衰竭的兩個最重要的特徵。計算結果表明，學習率為 0.001 的 RMSProp 優化器基於血清肌酐具有更好的預測。另一方面，學習率為 0.01 的 SGD 優化器與射血分數特徵相結合，表現出最佳性能。總體而言，與 LSTM 方法等現有技術相比，所提出的基於注意力學習的方法在預測心衰竭方面表現得非常有效。

##### **Leveraging LLMs to Predict Affective States via Smartphone Sensor Features**
2407.08240v1 by Tianyi Zhang, Songyan Teng, Hong Jia, Simon D'Alfonso

As mental health issues for young adults present a pressing public health
concern, daily digital mood monitoring for early detection has become an
important prospect. An active research area, digital phenotyping, involves
collecting and analysing data from personal digital devices such as smartphones
(usage and sensors) and wearables to infer behaviours and mental health. Whilst
this data is standardly analysed using statistical and machine learning
approaches, the emergence of large language models (LLMs) offers a new approach
to make sense of smartphone sensing data. Despite their effectiveness across
various domains, LLMs remain relatively unexplored in digital mental health,
particularly in integrating mobile sensor data. Our study aims to bridge this
gap by employing LLMs to predict affect outcomes based on smartphone sensing
data from university students. We demonstrate the efficacy of zero-shot and
few-shot embedding LLMs in inferring general wellbeing. Our findings reveal
that LLMs can make promising predictions of affect measures using solely
smartphone sensing data. This research sheds light on the potential of LLMs for
affective state prediction, emphasizing the intricate link between smartphone
behavioral patterns and affective states. To our knowledge, this is the first
work to leverage LLMs for affective state prediction and digital phenotyping
tasks.

摘要：隨著年輕人的心理健康問題成為迫切的公共衛生問題，每日數位情緒監控已成為早期偵測的重要前景。數位表型化是一個積極的研究領域，涉及收集和分析來自個人數位裝置（例如智慧型手機（使用和感測器）和可穿戴裝置）的資料，以推論行為和心理健康。雖然這些資料通常使用統計和機器學習方法進行分析，但大型語言模型 (LLM) 的出現提供了一種新的方法來理解智慧型手機感測資料。儘管 LLM 在各種領域都非常有效，但其在數位心理健康領域仍相對未被探索，特別是在整合行動感測器資料方面。我們的研究旨在透過使用 LLM 來根據大學生的智慧型手機感測資料預測影響結果，以彌合這一差距。我們展示了零次學習和少次學習嵌入式 LLM 在推論一般幸福感方面的效能。我們的研究結果顯示，LLM 可以僅使用智慧型手機感測資料對影響測量進行有希望的預測。本研究揭示了 LLM 在情感狀態預測方面的潛力，強調了智慧型手機行為模式和情感狀態之間的複雜聯繫。據我們所知，這是第一個利用 LLM 進行情感狀態預測和數位表型化任務的研究。

##### **DALL-M: Context-Aware Clinical Data Augmentation with LLMs**
2407.08227v1 by Chihcheng Hsieh, Catarina Moreira, Isabel Blanco Nobre, Sandra Costa Sousa, Chun Ouyang, Margot Brereton, Joaquim Jorge, Jacinto C. Nascimento

X-ray images are vital in medical diagnostics, but their effectiveness is
limited without clinical context. Radiologists often find chest X-rays
insufficient for diagnosing underlying diseases, necessitating comprehensive
clinical features and data integration. We present a novel technique to enhance
the clinical context through augmentation techniques with clinical tabular
data, thereby improving its applicability and reliability in AI medical
diagnostics. To address this, we introduce a pioneering approach to clinical
data augmentation that employs large language models (LLMs) to generate patient
contextual synthetic data. This methodology is crucial for training more robust
deep learning models in healthcare. It preserves the integrity of real patient
data while enriching the dataset with contextually relevant synthetic features,
significantly enhancing model performance. DALL-M uses a three-phase feature
generation process: (i) clinical context storage, (ii) expert query generation,
and (iii) context-aware feature augmentation. DALL-M generates new, clinically
relevant features by synthesizing chest X-ray images and reports. Applied to
799 cases using nine features from the MIMIC-IV dataset, it created an
augmented set of 91 features. This is the first work to generate contextual
values for existing and new features based on patients' X-ray reports, gender,
and age and to produce new contextual knowledge during data augmentation.
Empirical validation with machine learning models, including Decision Trees,
Random Forests, XGBoost, and TabNET, showed significant performance
improvements. Incorporating augmented features increased the F1 score by 16.5%
and Precision and Recall by approximately 25%. DALL-M addresses a critical gap
in clinical data augmentation, offering a robust framework for generating
contextually enriched datasets.

摘要：<paragraph>X 光影像在医学诊断中至关重要，但如果没有临床背景，其有效性会受到限制。放射科医生经常发现胸部 X 光影像不足以诊断潜在疾病，因此需要全面的临床特征和数据整合。我们提出了一种新技术，通过使用临床表格数据进行增强技术来增强临床背景，从而提高其在 AI 医学诊断中的适用性和可靠性。为了解决这个问题，我们引入了一种开创性的临床数据增强方法，该方法采用大型语言模型 (LLM) 来生成患者背景合成数据。这种方法对于在医疗保健领域训练更强大的深度学习模型至关重要。它保留了真实患者数据的完整性，同时使用与上下文相关的合成特征丰富了数据集，从而显著提高了模型性能。DALL-M 使用了一个三阶段特征生成过程：(i) 临床背景存储，(ii) 专家查询生成，(iii) 上下文感知特征增强。DALL-M 通过合成胸部 X 光影像和报告来生成新的、与临床相关的特征。将其应用于 MIMIC-IV 数据集中的 799 个案例，使用九个特征，它创建了一个包含 91 个特征的增强集合。这是第一项基于患者的 X 光报告、性别和年龄为现有和新特征生成上下文值的著作，并在数据增强期间产生新的上下文知识。使用包括决策树、随机森林、XGBoost 和 TabNET 在内的机器学习模型进行的经验验证显示出显著的性能改进。合并增强功能将 F1 分数提高了 16.5%，并将精确度和召回率提高了大约 25%。DALL-M 解决了一个临床数据增强中的关键空白，提供了一个用于生成上下文丰富的数据集的稳健框架。</paragraph>

##### **Synthetic Electroretinogram Signal Generation Using Conditional Generative Adversarial Network for Enhancing Classification of Autism Spectrum Disorder**
2407.08166v1 by Mikhail Kulyabin, Paul A. Constable, Aleksei Zhdanov, Irene O. Lee, David H. Skuse, Dorothy A. Thompson, Andreas Maier

The electroretinogram (ERG) is a clinical test that records the retina's
electrical response to light. The ERG is a promising way to study different
neurodevelopmental and neurodegenerative disorders, including autism spectrum
disorder (ASD) - a neurodevelopmental condition that impacts language,
communication, and reciprocal social interactions. However, in heterogeneous
populations, such as ASD, where the ability to collect large datasets is
limited, the application of artificial intelligence (AI) is complicated.
Synthetic ERG signals generated from real ERG recordings carry similar
information as natural ERGs and, therefore, could be used as an extension for
natural data to increase datasets so that AI applications can be fully
utilized. As proof of principle, this study presents a Generative Adversarial
Network capable of generating synthetic ERG signals of children with ASD and
typically developing control individuals. We applied a Time Series Transformer
and Visual Transformer with Continuous Wavelet Transform to enhance
classification results on the extended synthetic signals dataset. This approach
may support classification models in related psychiatric conditions where the
ERG may help classify disorders.

摘要：視網膜電圖 (ERG) 是一種臨床測試，用於記錄視網膜對光的電氣反應。ERG 是一種很有前途的研究不同神經發育和神經退化性疾病的方法，包括自閉症譜系障礙 (ASD) - 一種影響語言、溝通和社交互動的神經發育狀況。然而，在異質人群中，例如 ASD，收集大型數據集的能力有限，人工智能 (AI) 的應用很複雜。從真實 ERG 記錄中產生的合成 ERG 信號攜帶與自然 ERG 相似的信息，因此可用作自然數據的擴展，以增加數據集，以便 AI 應用程序可以得到充分利用。作為原理證明，本研究提出了一個生成對抗網路，能夠產生自閉症兒童和正常發育對照個人的合成 ERG 信號。我們應用時序轉換器和具有連續小波轉換的視覺轉換器來增強擴展合成信號數據集上的分類結果。這種方法可以支持相關精神疾病的分類模型，在這些疾病中，ERG 可能有助於對疾病進行分類。

##### **Highway Networks for Improved Surface Reconstruction: The Role of Residuals and Weight Updates**
2407.08134v1 by A. Noorizadegan, Y. C. Hon, D. L. Young, C. S. Chen

Surface reconstruction from point clouds is a fundamental challenge in
computer graphics and medical imaging. In this paper, we explore the
application of advanced neural network architectures for the accurate and
efficient reconstruction of surfaces from data points. We introduce a novel
variant of the Highway network (Hw) called Square-Highway (SqrHw) within the
context of multilayer perceptrons and investigate its performance alongside
plain neural networks and a simplified Hw in various numerical examples. These
examples include the reconstruction of simple and complex surfaces, such as
spheres, human hands, and intricate models like the Stanford Bunny. We analyze
the impact of factors such as the number of hidden layers, interior and
exterior points, and data distribution on surface reconstruction quality. Our
results show that the proposed SqrHw architecture outperforms other neural
network configurations, achieving faster convergence and higher-quality surface
reconstructions. Additionally, we demonstrate the SqrHw's ability to predict
surfaces over missing data, a valuable feature for challenging applications
like medical imaging. Furthermore, our study delves into further details,
demonstrating that the proposed method based on highway networks yields more
stable weight norms and backpropagation gradients compared to the Plain Network
architecture. This research not only advances the field of computer graphics
but also holds utility for other purposes such as function interpolation and
physics-informed neural networks, which integrate multilayer perceptrons into
their algorithms.

摘要：從點雲進行曲面重建是電腦圖學和醫學影像中的一項基本挑戰。在本文中，我們探討了先進神經網路架構在從資料點精確且有效重建曲面中的應用。我們在多層感知器的架構中，引入了高速公路網路（Hw）的一種新變體，稱為 Square-Highway（SqrHw），並在各種數值範例中探討其效能，以及與一般神經網路和簡化的 Hw 的效能。這些範例包括重建簡單和複雜的曲面，例如球體、人手和像 Stanford Bunny 那樣複雜的模型。我們分析了隱藏層數、內部和外部點以及資料分佈等因素對曲面重建品質的影響。我們的結果顯示，所提出的 SqrHw 架構優於其他神經網路組態，能達成更快的收斂速度和更高品質的曲面重建。此外，我們展示了 SqrHw 能夠預測遺失資料上的曲面，這對於像醫學影像那樣具有挑戰性的應用來說，是一個有價值的功能。此外，我們的研究深入探討了更多細節，證明了基於高速公路網路的所提出方法，與一般網路架構相比，產生了更穩定的權重範數和反向傳播梯度。這項研究不僅推動了電腦圖學領域，也對其他用途有幫助，例如函數內插和物理資訊神經網路，將多層感知器整合到其演算法中。

##### **Machine Learning for ALSFRS-R Score Prediction: Making Sense of the Sensor Data**
2407.08003v1 by Ritesh Mehta, Aleksandar Pramov, Shashank Verma

Amyotrophic Lateral Sclerosis (ALS) is characterized as a rapidly progressive
neurodegenerative disease that presents individuals with limited treatment
options in the realm of medical interventions and therapies. The disease
showcases a diverse range of onset patterns and progression trajectories,
emphasizing the critical importance of early detection of functional decline to
enable tailored care strategies and timely therapeutic interventions. The
present investigation, spearheaded by the iDPP@CLEF 2024 challenge, focuses on
utilizing sensor-derived data obtained through an app. This data is used to
construct various machine learning models specifically designed to forecast the
advancement of the ALS Functional Rating Scale-Revised (ALSFRS-R) score,
leveraging the dataset provided by the organizers. In our analysis, multiple
predictive models were evaluated to determine their efficacy in handling ALS
sensor data. The temporal aspect of the sensor data was compressed and
amalgamated using statistical methods, thereby augmenting the interpretability
and applicability of the gathered information for predictive modeling
objectives. The models that demonstrated optimal performance were a naive
baseline and ElasticNet regression. The naive model achieved a Mean Absolute
Error (MAE) of 0.20 and a Root Mean Square Error (RMSE) of 0.49, slightly
outperforming the ElasticNet model, which recorded an MAE of 0.22 and an RMSE
of 0.50. Our comparative analysis suggests that while the naive approach
yielded marginally better predictive accuracy, the ElasticNet model provides a
robust framework for understanding feature contributions.

摘要：肌萎縮性脊髓側索硬化症 (ALS) 的特徵為快速進展的神經退化性疾病，在醫療介入和治療領域中，患者的治療選擇有限。此疾病展示出多樣化的發病模式和進展軌跡，強調早期偵測功能衰退至關重要，以制定客製化的照護策略和及時的治療介入。本研究由 iDPP@CLEF 2024 挑戰帶頭，專注於利用透過應用程式取得的感測器衍生資料。這些資料用於建構各種機器學習模型，特別設計用於預測 ALS 功能評分量表修訂版 (ALSFRS-R) 分數的進展，並利用主辦單位提供的資料集。在我們的分析中，評估了多種預測模型，以確定它們在處理 ALS 感測器資料方面的效能。感測器資料的時間面向使用統計方法進行壓縮和合併，從而增強收集資訊在預測建模目標方面的可解釋性和適用性。表現最佳的模型是樸素基準和 ElasticNet 回歸。樸素模型達到了平均絕對誤差 (MAE) 為 0.20 和均方根誤差 (RMSE) 為 0.49，略勝於 ElasticNet 模型，後者的 MAE 為 0.22，RMSE 為 0.50。我們的比較分析表明，雖然樸素方法產生的預測準確度略高，但 ElasticNet 模型提供了一個穩健的架構，用於瞭解特徵貢獻。

##### **The Human Factor in AI Red Teaming: Perspectives from Social and Collaborative Computing**
2407.07786v1 by Alice Qian Zhang, Ryland Shaw, Jacy Reese Anthis, Ashlee Milton, Emily Tseng, Jina Suh, Lama Ahmad, Ram Shankar Siva Kumar, Julian Posada, Benjamin Shestakofsky, Sarah T. Roberts, Mary L. Gray

Rapid progress in general-purpose AI has sparked significant interest in "red
teaming," a practice of adversarial testing originating in military and
cybersecurity applications. AI red teaming raises many questions about the
human factor, such as how red teamers are selected, biases and blindspots in
how tests are conducted, and harmful content's psychological effects on red
teamers. A growing body of HCI and CSCW literature examines related
practices-including data labeling, content moderation, and algorithmic
auditing. However, few, if any, have investigated red teaming itself. This
workshop seeks to consider the conceptual and empirical challenges associated
with this practice, often rendered opaque by non-disclosure agreements. Future
studies may explore topics ranging from fairness to mental health and other
areas of potential harm. We aim to facilitate a community of researchers and
practitioners who can begin to meet these challenges with creativity,
innovation, and thoughtful reflection.

摘要：一般用途 AI 的快速進展引發了對「紅隊」的濃厚興趣，紅隊是一種源自軍事和網路安全應用中的對抗性測試實務。AI 紅隊對人類因素提出了許多問題，例如紅隊成員如何選拔、測試執行方式中的偏見和盲點，以及有害內容對紅隊成員的心理影響。越來越多的人機互動和 CSCW 文獻探討了相關實務，包括資料標記、內容審核和演算法稽核。然而，鮮少有人探討紅隊本身。本工作坊旨在探討與此實務相關的概念和經驗挑戰，這些挑戰通常因保密協議而變得模糊不清。未來的研究可能會探討從公平性到心理健康和其他潛在危害領域的主題。我們的目標是促進研究人員和實務工作者的社群，他們可以開始運用創意、創新和深思熟慮的反思來應對這些挑戰。

##### **A Proposed S.C.O.R.E. Evaluation Framework for Large Language Models : Safety, Consensus, Objectivity, Reproducibility and Explainability**
2407.07666v1 by Ting Fang Tan, Kabilan Elangovan, Jasmine Ong, Nigam Shah, Joseph Sung, Tien Yin Wong, Lan Xue, Nan Liu, Haibo Wang, Chang Fu Kuo, Simon Chesterman, Zee Kin Yeong, Daniel SW Ting

A comprehensive qualitative evaluation framework for large language models
(LLM) in healthcare that expands beyond traditional accuracy and quantitative
metrics needed. We propose 5 key aspects for evaluation of LLMs: Safety,
Consensus, Objectivity, Reproducibility and Explainability (S.C.O.R.E.). We
suggest that S.C.O.R.E. may form the basis for an evaluation framework for
future LLM-based models that are safe, reliable, trustworthy, and ethical for
healthcare and clinical applications.

摘要：一個全面的定性評估架構，適用於醫療保健領域的大型語言模型 (LLM)，其範圍超越傳統的準確度和定量指標。我們提出用於評估 LLM 的 5 個關鍵面向：安全性、共識、客觀性、可複製性和可解釋性 (S.C.O.R.E.)。我們建議 S.C.O.R.E. 可以作為評估架構的基礎，適用於未來的基於 LLM 的模型，這些模型對於醫療保健和臨床應用來說是安全、可靠、值得信賴且合乎道德的。

##### **Boosting Medical Image Synthesis via Registration-guided Consistency and Disentanglement Learning**
2407.07660v1 by Chuanpu Li, Zeli Chen, Yiwen Zhang, Liming Zhong, Wei Yang

Medical image synthesis remains challenging due to misalignment noise during
training. Existing methods have attempted to address this challenge by
incorporating a registration-guided module. However, these methods tend to
overlook the task-specific constraints on the synthetic and registration
modules, which may cause the synthetic module to still generate spatially
aligned images with misaligned target images during training, regardless of the
registration module's function. Therefore, this paper proposes
registration-guided consistency and incorporates disentanglement learning for
medical image synthesis. The proposed registration-guided consistency
architecture fosters task-specificity within the synthetic and registration
modules by applying identical deformation fields before and after synthesis,
while enforcing output consistency through an alignment loss. Moreover, the
synthetic module is designed to possess the capability of disentangling
anatomical structures and specific styles across various modalities. An anatomy
consistency loss is introduced to further compel the synthetic module to
preserve geometrical integrity within latent spaces. Experiments conducted on
both an in-house abdominal CECT-CT dataset and a publicly available pelvic
MR-CT dataset have demonstrated the superiority of the proposed method.

摘要：由於訓練期間的錯位雜訊，醫學影像合成仍然具有挑戰性。現有方法已嘗試透過納入註冊導引模組來解決此挑戰。然而，這些方法往往忽略合成與註冊模組的特定任務約束，這可能會導致合成模組在訓練期間仍產生與錯位目標影像空間對齊的影像，而與註冊模組的功能無關。因此，本文提出註冊導引一致性，並結合解糾纏學習用於醫學影像合成。所提出的註冊導引一致性架構透過在合成前後應用相同的變形場，並透過對齊損失來強制執行輸出一致性，來促進合成與註冊模組中的任務特異性。此外，合成模組被設計為具備在各種模態中解開解剖結構和特定樣式的能力。引入了解剖一致性損失，以進一步強制合成模組在潛在空間中保留幾何完整性。在內部腹部 CECT-CT 資料集和公開可用的骨盆 MR-CT 資料集上進行的實驗已證明了所提出方法的優越性。

##### **H-FCBFormer Hierarchical Fully Convolutional Branch Transformer for Occlusal Contact Segmentation with Articulating Paper**
2407.07604v1 by Ryan Banks, Bernat Rovira-Lastra, Jordi Martinez-Gomis, Akhilanand Chaurasia, Yunpeng Li

Occlusal contacts are the locations at which the occluding surfaces of the
maxilla and the mandible posterior teeth meet. Occlusal contact detection is a
vital tool for restoring the loss of masticatory function and is a mandatory
assessment in the field of dentistry, with particular importance in
prosthodontics and restorative dentistry. The most common method for occlusal
contact detection is articulating paper. However, this method can indicate
significant medically false positive and medically false negative contact
areas, leaving the identification of true occlusal indications to clinicians.
To address this, we propose a multiclass Vision Transformer and Fully
Convolutional Network ensemble semantic segmentation model with a combination
hierarchical loss function, which we name as Hierarchical Fully Convolutional
Branch Transformer (H-FCBFormer). We also propose a method of generating
medically true positive semantic segmentation masks derived from expert
annotated articulating paper masks and gold standard masks. The proposed model
outperforms other machine learning methods evaluated at detecting medically
true positive contacts and performs better than dentists in terms of accurately
identifying object-wise occlusal contact areas while taking significantly less
time to identify them. Code is available at
https://github.com/Banksylel/H-FCBFormer.

摘要：咬合接觸是上顎和下顎後牙咬合面相遇的位置。咬合接觸偵測是恢復咀嚼功能喪失的必要工具，也是牙科領域中的一項強制性評估，特別是在贋復牙科和修復牙科中具有重要意義。最常見的咬合接觸偵測方法是使用咬合紙。然而，此方法可能會顯示出顯著的醫學假陽性和醫學假陰性接觸區域，讓臨床醫師難以找出真正的咬合跡象。為了解決這個問題，我們提出一個多類別的 Vision Transformer 和全卷積網路集合語意分割模型，並結合分層損失函數，我們將其命名為分層全卷積分支轉換器 (H-FCBFormer)。我們還提出了一種生成醫學真陽性語意分割遮罩的方法，該方法源自專家註解的咬合紙遮罩和金標準遮罩。所提出的模型在偵測醫學真陽性接觸方面優於其他機器學習方法，並且在準確識別物件式咬合接觸區域方面優於牙醫師，同時識別所需時間卻顯著減少。程式碼可在 https://github.com/Banksylel/H-FCBFormer 取得。

##### **FLAIR: Feeding via Long-horizon AcquIsition of Realistic dishes**
2407.07561v1 by Rajat Kumar Jenamani, Priya Sundaresan, Maram Sakr, Tapomayukh Bhattacharjee, Dorsa Sadigh

Robot-assisted feeding has the potential to improve the quality of life for
individuals with mobility limitations who are unable to feed themselves
independently. However, there exists a large gap between the homogeneous,
curated plates existing feeding systems can handle, and truly in-the-wild
meals. Feeding realistic plates is immensely challenging due to the sheer range
of food items that a robot may encounter, each requiring specialized
manipulation strategies which must be sequenced over a long horizon to feed an
entire meal. An assistive feeding system should not only be able to sequence
different strategies efficiently in order to feed an entire meal, but also be
mindful of user preferences given the personalized nature of the task. We
address this with FLAIR, a system for long-horizon feeding which leverages the
commonsense and few-shot reasoning capabilities of foundation models, along
with a library of parameterized skills, to plan and execute user-preferred and
efficient bite sequences. In real-world evaluations across 6 realistic plates,
we find that FLAIR can effectively tap into a varied library of skills for
efficient food pickup, while adhering to the diverse preferences of 42
participants without mobility limitations as evaluated in a user study. We
demonstrate the seamless integration of FLAIR with existing bite transfer
methods [19, 28], and deploy it across 2 institutions and 3 robots,
illustrating its adaptability. Finally, we illustrate the real-world efficacy
of our system by successfully feeding a care recipient with severe mobility
limitations. Supplementary materials and videos can be found at:
https://emprise.cs.cornell.edu/flair .

摘要：機器人輔助進食有潛力改善行動不便、無法自行進食的個人生活品質。然而，現有的進食系統所能處理的均質、精選餐盤與實際的餐點之間存在著很大的差距。進食實際的餐點極具挑戰性，因為機器人可能遇到的食物種類繁多，每種食物都需要特定的操作策略，而這些策略必須在一個長期的範圍內進行排序，才能進食一整餐。一個輔助進食系統不僅應該能夠有效地對不同的策略進行排序，以便進食一整餐，還應該在任務的個性化性質下，考量使用者的偏好。我們透過 FLAIR 來解決這個問題，FLAIR 是針對長時程進食的系統，它利用基礎模型的常識和少量推理能力，以及一個參數化技能庫，來規劃和執行使用者偏好且有效的進食順序。在 6 個實際餐盤的真實世界評估中，我們發現 FLAIR 可以有效地利用各種技能庫進行有效的食物取用，同時遵守 42 位行動不便參與者的不同偏好，這是在使用者研究中評估的。我們展示了 FLAIR 與現有進食轉移方法 [19, 28] 的無縫整合，並在 2 個機構和 3 個機器人中部署它，說明了它的適應性。最後，我們透過成功餵食一位行動不便的受照護者來說明我們系統在真實世界中的功效。補充材料和影片可以在這裡找到：https://emprise.cs.cornell.edu/flair。

##### **Arabic Automatic Story Generation with Large Language Models**
2407.07551v1 by Ahmed Oumar El-Shangiti, Fakhraddin Alwajih, Muhammad Abdul-Mageed

Large language models (LLMs) have recently emerged as a powerful tool for a
wide range of language generation tasks. Nevertheless, this progress has been
slower in Arabic. In this work, we focus on the task of generating stories from
LLMs. For our training, we use stories acquired through machine translation
(MT) as well as GPT-4. For the MT data, we develop a careful pipeline that
ensures we acquire high-quality stories. For our GPT-41 data, we introduce
crafted prompts that allow us to generate data well-suited to the Arabic
context in both Modern Standard Arabic (MSA) and two Arabic dialects (Egyptian
and Moroccan). For example, we generate stories tailored to various Arab
countries on a wide host of topics. Our manual evaluation shows that our model
fine-tuned on these training datasets can generate coherent stories that adhere
to our instructions. We also conduct an extensive automatic and human
evaluation comparing our models against state-of-the-art proprietary and
open-source models. Our datasets and models will be made publicly available at
https: //github.com/UBC-NLP/arastories.

摘要：大型語言模型（LLM）最近已成為各種語言生成任務的強大工具。儘管如此，這項進展在阿拉伯語中較為緩慢。在這項工作中，我們專注於從 LLM 生成故事的任務。對於我們的訓練，我們使用通過機器翻譯（MT）以及 GPT-4 獲得的故事。對於 MT 資料，我們開發了一個仔細的管道，以確保我們獲得高品質的故事。對於我們的 GPT-41 資料，我們引入了精心製作的提示，使我們能夠生成非常適合阿拉伯語環境的資料，包括現代標準阿拉伯語（MSA）和兩種阿拉伯語方言（埃及語和摩洛哥語）。例如，我們生成針對各種阿拉伯國家的故事，主題廣泛。我們的評估顯示，我們針對這些訓練資料集進行微調的模型可以生成符合我們指示的連貫故事。我們還進行了廣泛的自動和人工評估，將我們的模型與最先進的專有和開放原始碼模型進行比較。我們的資料集和模型將在 https: //github.com/UBC-NLP/arastories 公開。

##### **Weakly-supervised Medical Image Segmentation with Gaze Annotations**
2407.07406v1 by Yuan Zhong, Chenhui Tang, Yumeng Yang, Ruoxi Qi, Kang Zhou, Yuqi Gong, Pheng Ann Heng, Janet H. Hsiao, Qi Dou

Eye gaze that reveals human observational patterns has increasingly been
incorporated into solutions for vision tasks. Despite recent explorations on
leveraging gaze to aid deep networks, few studies exploit gaze as an efficient
annotation approach for medical image segmentation which typically entails
heavy annotating costs. In this paper, we propose to collect dense weak
supervision for medical image segmentation with a gaze annotation scheme. To
train with gaze, we propose a multi-level framework that trains multiple
networks from discriminative human attention, simulated with a set of
pseudo-masks derived by applying hierarchical thresholds on gaze heatmaps.
Furthermore, to mitigate gaze noise, a cross-level consistency is exploited to
regularize overfitting noisy labels, steering models toward clean patterns
learned by peer networks. The proposed method is validated on two public
medical datasets of polyp and prostate segmentation tasks. We contribute a
high-quality gaze dataset entitled GazeMedSeg as an extension to the popular
medical segmentation datasets. To the best of our knowledge, this is the first
gaze dataset for medical image segmentation. Our experiments demonstrate that
gaze annotation outperforms previous label-efficient annotation schemes in
terms of both performance and annotation time. Our collected gaze data and code
are available at: https://github.com/med-air/GazeMedSeg.

摘要：人类观察模式的眼球注视已越来越多地融入视觉任务的解决方案中。尽管最近探索了利用注视来辅助深度网络，但很少有研究利用注视作为医学图像分割的有效注释方法，这通常需要大量的注释成本。在本文中，我们提出收集密集的弱监督，用于具有凝视注释方案的医学图像分割。为了用注视进行训练，我们提出了一个多级框架，该框架从区分性人类注意力训练多个网络，并通过在凝视热图上应用分层阈值来模拟一组伪掩码。此外，为了减轻注视噪声，利用跨级一致性来正则化过度拟合的噪声标签，将模型引导至由对等网络学习的干净模式。所提出的方法已在两个公共医学数据集的多息肉和前列腺分割任务上得到验证。我们贡献了一个名为 GazeMedSeg 的高质量凝视数据集，作为流行医学分割数据集的扩展。据我们所知，这是医学图像分割的第一个凝视数据集。我们的实验表明，在性能和注释时间方面，凝视注释优于以前的标签高效注释方案。我们收集的凝视数据和代码可在以下位置获得：https://github.com/med-air/GazeMedSeg。

##### **Interpretable Differential Diagnosis with Dual-Inference Large Language Models**
2407.07330v1 by Shuang Zhou, Sirui Ding, Jiashuo Wang, Mingquan Lin, Genevieve B. Melton, Rui Zhang

Methodological advancements to automate the generation of differential
diagnosis (DDx) to predict a list of potential diseases as differentials given
patients' symptom descriptions are critical to clinical reasoning and
applications such as decision support. However, providing reasoning or
interpretation for these differential diagnoses is more meaningful.
Fortunately, large language models (LLMs) possess powerful language processing
abilities and have been proven effective in various related tasks. Motivated by
this potential, we investigate the use of LLMs for interpretable DDx. First, we
develop a new DDx dataset with expert-derived interpretation on 570 public
clinical notes. Second, we propose a novel framework, named Dual-Inf, that
enables LLMs to conduct bidirectional inference for interpretation. Both human
and automated evaluation demonstrate the effectiveness of Dual-Inf in
predicting differentials and diagnosis explanations. Specifically, the
performance improvement of Dual-Inf over the baseline methods exceeds 32%
w.r.t. BERTScore in DDx interpretation. Furthermore, experiments verify that
Dual-Inf (1) makes fewer errors in interpretation, (2) has great
generalizability, (3) is promising for rare disease diagnosis and explanation.

摘要：方法學的進展自動化生成差異診斷 (DDx)，以預測給定患者症狀描述的潛在疾病清單，對於臨床推理和決策支援等應用至關重要。然而，提供這些差異診斷的推理或解釋更有意義。幸運的是，大型語言模型 (LLM) 擁有強大的語言處理能力，並已被證明在各種相關任務中有效。受此潛力的激勵，我們研究了 LLM 在可解釋的 DDx 中的應用。首先，我們開發了一個新的 DDx 數據集，其中包含專家對 570 個公共臨床筆記的解釋。其次，我們提出了一個名為 Dual-Inf 的新框架，它使 LLM 能夠進行雙向推理以進行解釋。人類和自動化評估都證明了 Dual-Inf 在預測差異和診斷解釋方面的有效性。具體來說，Dual-Inf 在 DDx 解釋中超過基線方法的性能改進超過 32% w.r.t. BERTScore。此外，實驗驗證了 Dual-Inf (1) 在解釋中產生較少的錯誤，(2) 具有很好的概括性，(3) 對罕見疾病的診斷和解釋很有前景。

##### **Large Language Model-Augmented Auto-Delineation of Treatment Target Volume in Radiation Therapy**
2407.07296v1 by Praveenbalaji Rajendran, Yong Yang, Thomas R. Niedermayr, Michael Gensheimer, Beth Beadle, Quynh-Thu Le, Lei Xing, Xianjin Dai

Radiation therapy (RT) is one of the most effective treatments for cancer,
and its success relies on the accurate delineation of targets. However, target
delineation is a comprehensive medical decision that currently relies purely on
manual processes by human experts. Manual delineation is time-consuming,
laborious, and subject to interobserver variations. Although the advancements
in artificial intelligence (AI) techniques have significantly enhanced the
auto-contouring of normal tissues, accurate delineation of RT target volumes
remains a challenge. In this study, we propose a visual language model-based RT
target volume auto-delineation network termed Radformer. The Radformer utilizes
a hierarichal vision transformer as the backbone and incorporates large
language models to extract text-rich features from clinical data. We introduce
a visual language attention module (VLAM) for integrating visual and linguistic
features for language-aware visual encoding (LAVE). The Radformer has been
evaluated on a dataset comprising 2985 patients with head-and-neck cancer who
underwent RT. Metrics, including the Dice similarity coefficient (DSC),
intersection over union (IOU), and 95th percentile Hausdorff distance (HD95),
were used to evaluate the performance of the model quantitatively. Our results
demonstrate that the Radformer has superior segmentation performance compared
to other state-of-the-art models, validating its potential for adoption in RT
practice.

摘要：放射治療 (RT) 是最有效的癌症治療方法之一，其成功有賴於目標的準確描繪。然而，目標描繪是一項全面的醫療決策，目前完全依賴人類專家的手動程序。手動描繪耗時、費力，且受觀察者間差異影響。儘管人工智慧 (AI) 技術的進步已顯著增強正常組織的自動輪廓描繪，但 RT 目標體積的準確描繪仍是一項挑戰。在本研究中，我們提出一個基於視覺語言模型的 RT 目標體積自動描繪網路，稱為 Radformer。Radformer 利用階層式視覺Transformer作為主幹，並整合大型語言模型從臨床資料中提取豐富文字特徵。我們引入一個視覺語言注意力模組 (VLAM)，用於整合視覺和語言特徵，以進行語言感知視覺編碼 (LAVE)。Radformer 已在一個包含 2985 名接受 RT 治療的頭頸癌患者的資料集上進行評估。指標，包括 Dice 相似係數 (DSC)、聯集比 (IOU) 和第 95 個百分位數 Hausdorff 距離 (HD95)，用於定量評估模型的效能。我們的結果表明，與其他最先進的模型相比，Radformer 具有優異的分割效能，驗證了其在 RT 實務中應用的潛力。

##### **Causal Discovery in Semi-Stationary Time Series**
2407.07291v1 by Shanyun Gao, Raghavendra Addanki, Tong Yu, Ryan A. Rossi, Murat Kocaoglu

Discovering causal relations from observational time series without making
the stationary assumption is a significant challenge. In practice, this
challenge is common in many areas, such as retail sales, transportation
systems, and medical science. Here, we consider this problem for a class of
non-stationary time series. The structural causal model (SCM) of this type of
time series, called the semi-stationary time series, exhibits that a finite
number of different causal mechanisms occur sequentially and periodically
across time. This model holds considerable practical utility because it can
represent periodicity, including common occurrences such as seasonality and
diurnal variation. We propose a constraint-based, non-parametric algorithm for
discovering causal relations in this setting. The resulting algorithm,
PCMCI$_{\Omega}$, can capture the alternating and recurring changes in the
causal mechanisms and then identify the underlying causal graph with
conditional independence (CI) tests. We show that this algorithm is sound in
identifying causal relations on discrete time series. We validate the algorithm
with extensive experiments on continuous and discrete simulated data. We also
apply our algorithm to a real-world climate dataset.

摘要：在不作平穩假設的情況下從觀測時間序列中發現因果關係是一項重大挑戰。在實務中，這個挑戰在許多領域中很常見，例如零售銷售、運輸系統和醫學科學。在此，我們考慮非平穩時間序列類別的這個問題。這種類型的時間序列的結構因果模型 (SCM)，稱為半平穩時間序列，展示了有限數量的不同因果機制會隨著時間順序且週期性地發生。這個模型具有相當大的實用性，因為它可以表示週期性，包括季節性和晝夜變化等常見現象。我們提出了一個基於約束的非參數演算法，用於發現這個設定中的因果關係。產生的演算法 PCMCI$_{\Omega}$ 可以捕捉因果機制中的交替和重複變化，然後藉由條件獨立 (CI) 檢定來識別基礎因果圖。我們證明這個演算法在識別離散時間序列上的因果關係時是合理的。我們使用連續和離散模擬資料進行廣泛的實驗，以驗證演算法。我們也將我們的演算法應用於真實世界的氣候資料集。

##### **Causal Discovery-Driven Change Point Detection in Time Series**
2407.07290v1 by Shanyun Gao, Raghavendra Addanki, Tong Yu, Ryan A. Rossi, Murat Kocaoglu

Change point detection in time series seeks to identify times when the
probability distribution of time series changes. It is widely applied in many
areas, such as human-activity sensing and medical science. In the context of
multivariate time series, this typically involves examining the joint
distribution of high-dimensional data: If any one variable changes, the whole
time series is assumed to have changed. However, in practical applications, we
may be interested only in certain components of the time series, exploring
abrupt changes in their distributions in the presence of other time series.
Here, assuming an underlying structural causal model that governs the
time-series data generation, we address this problem by proposing a two-stage
non-parametric algorithm that first learns parts of the causal structure
through constraint-based discovery methods. The algorithm then uses conditional
relative Pearson divergence estimation to identify the change points. The
conditional relative Pearson divergence quantifies the distribution disparity
between consecutive segments in the time series, while the causal discovery
method enables a focus on the causal mechanism, facilitating access to
independent and identically distributed (IID) samples. Theoretically, the
typical assumption of samples being IID in conventional change point detection
methods can be relaxed based on the Causal Markov Condition. Through
experiments on both synthetic and real-world datasets, we validate the
correctness and utility of our approach.

摘要：時間序列的變異點偵測旨在找出時間序列的機率分佈改變的時間。它廣泛應用於許多領域，例如人類活動感測與醫學科學。在多變量時間序列的背景中，這通常涉及檢視高維度資料的聯合分佈：如果任何一個變數改變，則假設整個時間序列已經改變。然而，在實際應用中，我們可能只對時間序列的特定組成部分感興趣，探索它們的分佈在其他時間序列存在的情況下突然改變。在這裡，假設一個基礎的結構因果模型支配著時間序列資料的生成，我們透過提出一個兩階段非參數演算法來解決這個問題，該演算法首先透過基於約束的發現方法來學習因果結構的部分。然後，該演算法使用條件相對 Pearson 差異估計來找出變異點。條件相對 Pearson 差異量化時間序列中連續區段之間的分佈差異，而因果發現方法可以專注於因果機制，促進取得獨立且同分布 (IID) 的樣本。理論上，樣本為 IID 的典型假設在傳統變異點偵測方法中可以根據因果馬可夫條件放寬。透過在合成和真實世界資料集上進行實驗，我們驗證了我們方法的正確性和實用性。

##### **Lifestyle-Informed Personalized Blood Biomarker Prediction via Novel Representation Learning**
2407.07277v1 by A. Ali Heydari, Naghmeh Rezaei, Javier L. Prieto, Shwetak N. Patel, Ahmed A. Metwally

Blood biomarkers are an essential tool for healthcare providers to diagnose,
monitor, and treat a wide range of medical conditions. Current reference values
and recommended ranges often rely on population-level statistics, which may not
adequately account for the influence of inter-individual variability driven by
factors such as lifestyle and genetics. In this work, we introduce a novel
framework for predicting future blood biomarker values and define personalized
references through learned representations from lifestyle data (physical
activity and sleep) and blood biomarkers. Our proposed method learns a
similarity-based embedding space that captures the complex relationship between
biomarkers and lifestyle factors. Using the UK Biobank (257K participants), our
results show that our deep-learned embeddings outperform traditional and
current state-of-the-art representation learning techniques in predicting
clinical diagnosis. Using a subset of UK Biobank of 6440 participants who have
follow-up visits, we validate that the inclusion of these embeddings and
lifestyle factors directly in blood biomarker models improves the prediction of
future lab values from a single lab visit. This personalized modeling approach
provides a foundation for developing more accurate risk stratification tools
and tailoring preventative care strategies. In clinical settings, this
translates to the potential for earlier disease detection, more timely
interventions, and ultimately, a shift towards personalized healthcare.

摘要：血液生物標記是醫療保健提供者用於診斷、監測和治療各種疾病的重要工具。目前的參考值和建議範圍通常依賴於人群統計數據，而這些數據可能無法充分說明由生活方式和基因等因素驅動的個體間變異的影響。在這項工作中，我們引入了一個新的框架來預測未來的血液生物標記值，並通過從生活方式數據（身體活動和睡眠）和血液生物標記中學習到的表徵來定義個性化參考。我們提出的方法學習了一個基於相似性的嵌入空間，該空間捕捉了生物標記和生活方式因素之間的複雜關係。使用英國生物銀行（257K 參與者），我們的結果表明，我們深度學習的嵌入優於傳統和當前最先進的表徵學習技術，可以預測臨床診斷。使用擁有後續訪視的 6440 名參與者的英國生物銀行子集，我們驗證了在血液生物標記模型中直接包含這些嵌入和生活方式因素可以改善從單次實驗室訪問中預測未來實驗室值。這種個性化建模方法為開發更準確的風險分層工具和定制預防保健策略提供了基礎。在臨床環境中，這轉化為早期疾病檢測、更及時的干預，最終轉向個性化醫療保健的潛力。

##### **ProtoSAM -- One Shot Medical Image Segmentation With Foundational Models**
2407.07042v1 by Lev Ayzenberg, Raja Giryes, Hayit Greenspan

This work introduces a new framework, ProtoSAM, for one-shot medical image
segmentation. It combines the use of prototypical networks, known for few-shot
segmentation, with SAM - a natural image foundation model. The method proposed
creates an initial coarse segmentation mask using the ALPnet prototypical
network, augmented with a DINOv2 encoder. Following the extraction of an
initial mask, prompts are extracted, such as points and bounding boxes, which
are then input into the Segment Anything Model (SAM). State-of-the-art results
are shown on several medical image datasets and demonstrate automated
segmentation capabilities using a single image example (one shot) with no need
for fine-tuning of the foundation model.

摘要：本研究提出一個新的架構，ProtoSAM，用於一次性醫學影像分割。它結合了原型網路的使用，以進行少次分割，以及 SAM - 一個自然影像基礎模型。所提出的方法使用 ALPnet 原型網路建立一個初始的粗略分割遮罩，並使用 DINOv2 編碼器進行擴充。在提取初始遮罩後，會提取提示，例如點和邊界框，然後將其輸入到 Segment Anything Model (SAM) 中。在多個醫學影像資料集上顯示了最先進的結果，並展示了使用單一影像範例（一次性）的自動分割功能，無需微調基礎模型。

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

摘要：人工智能 (AI) 支持的決策制定是未來 6G 網路中的關鍵元素，其中將引入原生 AI 的概念。此外，AI 廣泛用於不同的關鍵應用中，例如自動駕駛和醫療診斷。在這些應用中，使用 AI 作為黑盒模型是有風險且具有挑戰性的。因此，理解和信任這些模型做出的決策至關重要。解決此問題的方法是開發可解釋 AI (XAI) 架構，旨在解釋黑盒模型行為背後的邏輯，從而確保其有效且安全的部署。最近，我們提出了一個新的基於擾動的 XAI-CHEST 框架，該框架面向無線通信中的信道估計。XAI-CHEST 框架的核心思想是通過在無關輸入上引入高噪聲來識別相關模型輸入。這份手稿提供了 XAI-CHEST 框架的詳細理論基礎。特別是，我們推導了 XAI-CHEST 損失函數和噪聲閾值微調優化問題的解析表達式。因此，設計的 XAI-CHEST 提供了一種智能輸入特徵選擇方法，可以在優化所用模型的架構的同時進一步提高整體性能。模擬結果表明，XAI-CHEST 框架提供了有效的解釋，在降低所需的計算複雜度的同時，提供了改進的比特錯誤率性能，而這與基於傳統 DL 的信道估計相比。

##### **Microsoft Cloud-based Digitization Workflow with Rich Metadata Acquisition for Cultural Heritage Objects**
2407.06972v1 by Krzysztof Kutt, Jakub Gomułka, Luiz do Valle Miranda, Grzegorz J. Nalepa

In response to several cultural heritage initiatives at the Jagiellonian
University, we have developed a new digitization workflow in collaboration with
the Jagiellonian Library (JL). The solution is based on easy-to-access
technological solutions -- Microsoft 365 cloud with MS Excel files as metadata
acquisition interfaces, Office Script for validation, and MS Sharepoint for
storage -- that allows metadata acquisition by domain experts (philologists,
historians, philosophers, librarians, archivists, curators, etc.) regardless of
their experience with information systems. The ultimate goal is to create a
knowledge graph that describes the analyzed holdings, linked to general
knowledge bases, as well as to other cultural heritage collections, so careful
attention is paid to the high accuracy of metadata and proper links to external
sources. The workflow has already been evaluated in two pilots in the DiHeLib
project focused on digitizing the so-called "Berlin Collection" and in two
workshops with international guests, which allowed for its refinement and
confirmation of its correctness and usability for JL. As the proposed workflow
does not interfere with existing systems or domain guidelines regarding
digitization and basic metadata collection in a given institution (e.g., file
type, image quality, use of Dublin Core/MARC-21), but extends them in order to
enable rich metadata collection, not previously possible, we believe that it
could be of interest to all GLAMs (galleries, libraries, archives, and
museums).

摘要：<paragraph>為回應 Jagiello 大學的數個文化遺產倡議，我們與 Jagiello 圖書館 (JL) 合作開發一個新的數位化工作流程。此解決方案基於易於存取的技術解決方案，包括：作為元資料擷取介面的 Microsoft 365 雲端與 MS Excel 檔案、用於驗證的 Office Script，以及用於儲存的 MS Sharepoint，它允許領域專家（語言學家、歷史學家、哲學家、圖書館員、檔案管理員、策展人等）擷取元資料，而無須具備資訊系統方面的經驗。最終目標是建立一個知識圖譜，用以描述所分析的館藏，並連結至一般知識庫，以及其他文化遺產館藏，因此我們非常重視元資料的高準確性，以及與外部來源的適當連結。此工作流程已在 DiHeLib 專案中兩個試點計畫中進行評估，該專案專注於數位化所謂的「柏林館藏」，以及與國際訪客進行的兩個工作坊，這讓我們得以改善工作流程，並確認其正確性，以及對 JL 的可用性。由於所提出的工作流程不會干擾既有系統或關於數位化和基本元資料蒐集的領域指南（例如，檔案類型、影像品質、使用 Dublin Core/MARC-21），而是擴充這些系統，以支援以前無法進行的豐富元資料蒐集，因此我們相信它可能會引起所有 GLAM（畫廊、圖書館、檔案館和博物館）的興趣。</paragraph>

##### **TE-SSL: Time and Event-aware Self Supervised Learning for Alzheimer's Disease Progression Analysis**
2407.06852v1 by Jacob Thrasher, Alina Devkota, Ahmed Tafti, Binod Bhattarai, Prashnna Gyawali

Alzheimer's Dementia (AD) represents one of the most pressing challenges in
the field of neurodegenerative disorders, with its progression analysis being
crucial for understanding disease dynamics and developing targeted
interventions. Recent advancements in deep learning and various representation
learning strategies, including self-supervised learning (SSL), have shown
significant promise in enhancing medical image analysis, providing innovative
ways to extract meaningful patterns from complex data. Notably, the computer
vision literature has demonstrated that incorporating supervisory signals into
SSL can further augment model performance by guiding the learning process with
additional relevant information. However, the application of such supervisory
signals in the context of disease progression analysis remains largely
unexplored. This gap is particularly pronounced given the inherent challenges
of incorporating both event and time-to-event information into the learning
paradigm. Addressing this, we propose a novel framework, Time and Even-aware
SSL (TE-SSL), which integrates time-to-event and event data as supervisory
signals to refine the learning process. Our comparative analysis with existing
SSL-based methods in the downstream task of survival analysis shows superior
performance across standard metrics.

摘要：阿茲海默症失智症 (AD) 是神經退化性疾病領域中最迫切的挑戰之一，其進程分析對於了解疾病動態和開發目標性干預措施至關重要。深度學習和各種表示學習策略（包括自監督學習 (SSL)）的最新進展，已在增強醫學影像分析方面展現顯著前景，提供從複雜資料中提取有意義模式的創新方法。值得注意的是，電腦視覺文獻已證明將監督訊號納入 SSL 可以透過提供額外相關資訊來指導學習過程，進一步增強模型效能。然而，此類監督訊號在疾病進程分析中的應用仍未得到充分探討。由於將事件和事件時間資訊納入學習範例的固有挑戰，此差距特別明顯。針對此問題，我們提出一個創新的架構，時間和事件感知 SSL (TE-SSL)，它整合事件時間和事件資料作為監督訊號，以優化學習過程。我們在生存分析的下游任務中，對其與現有基於 SSL 的方法進行比較分析，顯示其在標準指標上的效能優異。

##### **VRDSynth: Synthesizing Programs for Multilingual Visually Rich Document Information Extraction**
2407.06826v1 by Thanh-Dat Nguyen, Tung Do-Viet, Hung Nguyen-Duy, Tuan-Hai Luu, Hung Le, Bach Le, Patanamon, Thongtanunam

Businesses need to query visually rich documents (VRDs) like receipts,
medical records, and insurance forms to make decisions. Existing techniques for
extracting entities from VRDs struggle with new layouts or require extensive
pre-training data. We introduce VRDSynth, a program synthesis method to
automatically extract entity relations from multilingual VRDs without
pre-training data. To capture the complexity of VRD domain, we design a
domain-specific language (DSL) to capture spatial and textual relations to
describe the synthesized programs. Along with this, we also derive a new
synthesis algorithm utilizing frequent spatial relations, search space pruning,
and a combination of positive, negative, and exclusive programs to improve
coverage.
  We evaluate VRDSynth on the FUNSD and XFUND benchmarks for semantic entity
linking, consisting of 1,592 forms in 8 languages. VRDSynth outperforms
state-of-the-art pre-trained models (LayoutXLM, InfoXLMBase, and
XLMRobertaBase) in 5, 6, and 7 out of 8 languages, respectively, improving the
F1 score by 42% over LayoutXLM in English. To test the extensibility of the
model, we further improve VRDSynth with automated table recognition, creating
VRDSynth(Table), and compare it with extended versions of the pre-trained
models, InfoXLM(Large) and XLMRoberta(Large). VRDSynth(Table) outperforms these
baselines in 4 out of 8 languages and in average F1 score. VRDSynth also
significantly reduces memory footprint (1M and 380MB vs. 1.48GB and 3GB for
LayoutXLM) while maintaining similar time efficiency.

摘要：<paragraph>企業需要查詢視覺豐富的文件 (VRD)，例如收據、醫療記錄和保險單據，才能做出決策。現有的技術用於從 VRD 中提取實體，會遇到新的版面問題，或者需要大量的預訓練數據。我們介紹 VRDSynth，這是一種程式合成方法，可以在沒有預訓練數據的情況下自動從多語言 VRD 中提取實體關係。為了捕捉 VRD 領域的複雜性，我們設計了一個特定領域語言 (DSL)，用於捕捉空間和文字關係，以描述合成的程式。除此之外，我們還推導出一個新的合成演算法，利用頻繁的空間關係、搜尋空間剪枝，以及正、負和排他程式的組合，以改善涵蓋範圍。
我們在 FUNSD 和 XFUND 基準上評估 VRDSynth，用於語義實體連結，包含 8 種語言的 1,592 個表單。VRDSynth 在 8 種語言中的 5、6 和 7 種語言中優於最先進的預訓練模型 (LayoutXLM、InfoXLMBase 和 XLMRobertaBase)，分別將英文中的 F1 分數提高了 42%，高於 LayoutXLM。為了測試模型的可擴充性，我們進一步改進 VRDSynth，採用自動化表格識別，建立 VRDSynth(Table)，並將其與預訓練模型 InfoXLM(Large) 和 XLMRoberta(Large) 的延伸版本進行比較。VRDSynth(Table) 在 8 種語言中的 4 種語言和平均 F1 分數中優於這些基準。VRDSynth 還顯著減少了記憶體使用量 (1M 和 380MB，而 LayoutXLM 為 1.48GB 和 3GB)，同時維持類似的時間效率。</paragraph>

##### **iASiS: Towards Heterogeneous Big Data Analysis for Personalized Medicine**
2407.06748v1 by Anastasia Krithara, Fotis Aisopos, Vassiliki Rentoumi, Anastasios Nentidis, Konstantinos Bougatiotis, Maria-Esther Vidal, Ernestina Menasalvas, Alejandro Rodriguez-Gonzalez, Eleftherios G. Samaras, Peter Garrard, Maria Torrente, Mariano Provencio Pulla, Nikos Dimakopoulos, Rui Mauricio, Jordi Rambla De Argila, Gian Gaetano Tartaglia, George Paliouras

The vision of IASIS project is to turn the wave of big biomedical data
heading our way into actionable knowledge for decision makers. This is achieved
by integrating data from disparate sources, including genomics, electronic
health records and bibliography, and applying advanced analytics methods to
discover useful patterns. The goal is to turn large amounts of available data
into actionable information to authorities for planning public health
activities and policies. The integration and analysis of these heterogeneous
sources of information will enable the best decisions to be made, allowing for
diagnosis and treatment to be personalised to each individual. The project
offers a common representation schema for the heterogeneous data sources. The
iASiS infrastructure is able to convert clinical notes into usable data,
combine them with genomic data, related bibliography, image data and more, and
create a global knowledge base. This facilitates the use of intelligent methods
in order to discover useful patterns across different resources. Using semantic
integration of data gives the opportunity to generate information that is rich,
auditable and reliable. This information can be used to provide better care,
reduce errors and create more confidence in sharing data, thus providing more
insights and opportunities. Data resources for two different disease categories
are explored within the iASiS use cases, dementia and lung cancer.

摘要：IASIS 項目的願景是將朝我們而來的龐大生物醫學數據浪潮轉變為決策者的可行知識。這是透過整合來自不同來源的數據（包括基因組學、電子健康記錄和書目），並應用先進的分析方法來發現有用的模式來實現的。目標是將大量可用數據轉化為可行的資訊，供當局規劃公共衛生活動和政策。整合和分析這些異質的資訊來源將使最佳決策得以制定，並允許對每個人的診斷和治療進行個人化。該專案為異質數據來源提供了一個共同的表示架構。iASiS 基礎設施能夠將臨床筆記轉換為可用數據，將其與基因組數據、相關書目、影像數據等結合起來，並建立一個全球知識庫。這有助於使用智慧方法來發現不同資源之間的有用模式。使用數據的語義整合提供了產生豐富、可稽核且可靠資訊的機會。這些資訊可用於提供更好的照護、減少錯誤，並對資料共享建立更多信心，從而提供更多見解和機會。在 iASiS 的使用案例中，探討了兩種不同疾病類別的數據資源，即失智症和肺癌。

##### **TCKIN: A Novel Integrated Network Model for Predicting Mortality Risk in Sepsis Patients**
2407.06560v1 by Fanglin Dong

Sepsis poses a major global health threat, accounting for millions of deaths
annually and significant economic costs. Accurate predictions of mortality risk
in sepsis patients facilitate the efficient allocation of medical resources,
thereby enhancing patient survival and quality of life. Through precise risk
assessments, healthcare facilities can effectively distribute intensive care
beds, medical equipment, and staff, ensuring high-risk patients receive timely
and appropriate care. Early identification and intervention significantly
decrease mortality rates and improve patient outcomes. Current methods
typically utilize only one type of data--either constant, temporal, or ICD
codes. This study introduces the Time-Constant KAN Integrated Network(TCKIN),
an innovative model that enhances the accuracy of sepsis mortality risk
predictions by integrating both temporal and constant data from electronic
health records and ICD codes. Validated against the MIMIC-III and MIMIC-IV
datasets, TCKIN surpasses existing machine learning and deep learning methods
in accuracy, sensitivity, and specificity. Notably, TCKIN achieved AUCs of
87.76% and 88.07%, demonstrating superior capability in identifying high-risk
patients. Additionally, TCKIN effectively combats the prevalent issue of data
imbalance in clinical settings, improving the detection of patients at elevated
risk of mortality and facilitating timely interventions. These results confirm
the model's effectiveness and its potential to transform patient management and
treatment optimization in clinical practice. With this advanced risk assessment
tool, healthcare providers can devise more tailored treatment plans, optimize
resource utilization, and ultimately enhance survival rates and quality of life
for sepsis patients.

摘要：<paragraph>敗血症構成全球主要的健康威脅，每年造成數百萬人死亡，並帶來龐大的經濟成本。準確預測敗血症患者的死亡風險，有助於有效分配醫療資源，從而提升患者存活率和生活品質。透過精確的風險評估，醫療機構可以有效分配加護病房病床、醫療設備和人員，確保高風險患者能及時獲得適當的照護。早期發現和介入可以顯著降低死亡率，並改善患者預後。目前的方法通常僅使用一種類型的資料，例如常數、時間或 ICD 編碼。本研究引入了時間常數 KAN 整合網路 (TCKIN)，這是一個創新的模型，透過整合電子健康紀錄和 ICD 編碼中的時間和常數資料，來提升敗血症死亡風險預測的準確性。在 MIMIC-III 和 MIMIC-IV 資料集驗證下，TCKIN 在準確性、敏感性和特異性方面都超越了現有的機器學習和深度學習方法。值得注意的是，TCKIN 達到了 87.76% 和 88.07% 的 AUC，顯示出優異的識別高風險患者能力。此外，TCKIN 有效地解決了臨床環境中普遍存在的資料不平衡問題，改善了對死亡風險較高的患者的檢測，並促進及時介入。這些結果證實了該模型的有效性，以及其在臨床實務中轉化患者管理和優化治療的潛力。有了這個進階的風險評估工具，醫療保健提供者可以制定更客製化的治療計畫，最佳化資源利用，並最終提升敗血症患者的存活率和生活品質。</paragraph>

##### **AI-driven multi-omics integration for multi-scale predictive modeling of causal genotype-environment-phenotype relationships**
2407.06405v1 by You Wu, Lei Xie

Despite the wealth of single-cell multi-omics data, it remains challenging to
predict the consequences of novel genetic and chemical perturbations in the
human body. It requires knowledge of molecular interactions at all biological
levels, encompassing disease models and humans. Current machine learning
methods primarily establish statistical correlations between genotypes and
phenotypes but struggle to identify physiologically significant causal factors,
limiting their predictive power. Key challenges in predictive modeling include
scarcity of labeled data, generalization across different domains, and
disentangling causation from correlation. In light of recent advances in
multi-omics data integration, we propose a new artificial intelligence
(AI)-powered biology-inspired multi-scale modeling framework to tackle these
issues. This framework will integrate multi-omics data across biological
levels, organism hierarchies, and species to predict causal
genotype-environment-phenotype relationships under various conditions. AI
models inspired by biology may identify novel molecular targets, biomarkers,
pharmaceutical agents, and personalized medicines for presently unmet medical
needs.

摘要：儘管有豐富的單細胞多組學資料，但預測人體中新的遺傳和化學擾動的後果仍然具有挑戰性。這需要了解所有生物層級的分子交互作用，包括疾病模型和人類。目前的機器學習方法主要建立基因型和表型之間的統計相關性，但難以識別生理上重要的因果因素，從而限制了其預測能力。預測建模中的主要挑戰包括標記資料的稀缺性、跨不同領域的概化，以及將因果關係從相關性中解開。鑑於多組學資料整合的最新進展，我們提出了一個新的由人工智慧 (AI) 驅動的、受生物啟發的多尺度建模框架來解決這些問題。此框架將整合跨生物層級、生物體層級和物種的多組學資料，以預測在各種條件下的因果基因型-環境-表型關係。受生物啟發的 AI 模型可能會識別出新的分子靶標、生物標記、藥物和個性化藥物，以滿足目前尚未滿足的醫療需求。

##### **Multimodal Chain-of-Thought Reasoning via ChatGPT to Protect Children from Age-Inappropriate Apps**
2407.06309v1 by Chuanbo Hu, Bin Liu, Minglei Yin, Yilu Zhou, Xin Li

Mobile applications (Apps) could expose children to inappropriate themes such
as sexual content, violence, and drug use. Maturity rating offers a quick and
effective method for potential users, particularly guardians, to assess the
maturity levels of apps. Determining accurate maturity ratings for mobile apps
is essential to protect children's health in today's saturated digital
marketplace. Existing approaches to maturity rating are either inaccurate
(e.g., self-reported rating by developers) or costly (e.g., manual
examination). In the literature, there are few text-mining-based approaches to
maturity rating. However, each app typically involves multiple modalities,
namely app description in the text, and screenshots in the image. In this
paper, we present a framework for determining app maturity levels that utilize
multimodal large language models (MLLMs), specifically ChatGPT-4 Vision.
Powered by Chain-of-Thought (CoT) reasoning, our framework systematically
leverages ChatGPT-4 to process multimodal app data (i.e., textual descriptions
and screenshots) and guide the MLLM model through a step-by-step reasoning
pathway from initial content analysis to final maturity rating determination.
As a result, through explicitly incorporating CoT reasoning, our framework
enables ChatGPT to understand better and apply maturity policies to facilitate
maturity rating. Experimental results indicate that the proposed method
outperforms all baseline models and other fusion strategies.

摘要：行動應用程式 (App) 可能讓兒童接觸到不適當的主題，例如性內容、暴力和藥物使用。成熟度評分提供一種快速且有效的方法，讓潛在使用者，尤其是監護人，評估應用程式的成熟度等級。在當今飽和的數位市場中，為行動應用程式確定準確的成熟度評分對於保護兒童健康至關重要。現有的成熟度評分方法不是不準確（例如，開發人員自行報告的評分），就是成本高昂（例如，人工審查）。在文獻中，很少有基於文字探勘的方法來評估成熟度。然而，每個應用程式通常涉及多種模式，即文字中的應用程式說明和影像中的螢幕截圖。在本文中，我們提出一個框架，用於確定應用程式的成熟度等級，該框架利用多模態大型語言模型 (MLLM)，特別是 ChatGPT-4 Vision。我們的框架採用思維鏈 (CoT) 推理為基礎，系統性地利用 ChatGPT-4 處理多模態應用程式資料（即文字說明和螢幕截圖），並引導 MLLM 模型逐步進行推理路徑，從初始內容分析到最終成熟度評分確定。因此，透過明確納入 CoT 推理，我們的框架使 ChatGPT 能夠更深入地了解並應用成熟度政策來促進成熟度評分。實驗結果表明，所提出的方法優於所有基線模型和其他融合策略。

##### **Hybrid X-Linker: Automated Data Generation and Extreme Multi-label Ranking for Biomedical Entity Linking**
2407.06292v1 by Pedro Ruas, Fernando Gallego, Francisco J. Veredas, Francisco M. Couto

State-of-the-art deep learning entity linking methods rely on extensive
human-labelled data, which is costly to acquire. Current datasets are limited
in size, leading to inadequate coverage of biomedical concepts and diminished
performance when applied to new data. In this work, we propose to automatically
generate data to create large-scale training datasets, which allows the
exploration of approaches originally developed for the task of extreme
multi-label ranking in the biomedical entity linking task. We propose the
hybrid X-Linker pipeline that includes different modules to link disease and
chemical entity mentions to concepts in the MEDIC and the CTD-Chemical
vocabularies, respectively. X-Linker was evaluated on several biomedical
datasets: BC5CDR-Disease, BioRED-Disease, NCBI-Disease, BC5CDR-Chemical,
BioRED-Chemical, and NLM-Chem, achieving top-1 accuracies of 0.8307, 0.7969,
0.8271, 0.9511, 0.9248, and 0.7895, respectively. X-Linker demonstrated
superior performance in three datasets: BC5CDR-Disease, NCBI-Disease, and
BioRED-Chemical. In contrast, SapBERT outperformed X-Linker in the remaining
three datasets. Both models rely only on the mention string for their
operations. The source code of X-Linker and its associated data are publicly
available for performing biomedical entity linking without requiring
pre-labelled entities with identifiers from specific knowledge organization
systems.

摘要：最先進的深度學習實體連結方法依賴於大量的
人工標籤資料，而這類資料的取得成本很高。目前的資料集
大小有限，導致生物醫學概念涵蓋不足，在應用於新資料時效能降低。在這項工作中，我們提議自動
產生資料，以建立大規模的訓練資料集，這允許探索原本是為生物醫學實體連結任務中極端多標籤排名任務而開發的方法。我們提議混合 X-Linker 管線，其中包含不同的模組，分別將疾病和化學實體提及連結到 MEDIC 和 CTD-Chemical 字彙中的概念。X-Linker 已在多個生物醫學資料集上進行評估：BC5CDR-Disease、BioRED-Disease、NCBI-Disease、BC5CDR-Chemical、BioRED-Chemical 和 NLM-Chem，分別達到 0.8307、0.7969、0.8271、0.9511、0.9248 和 0.7895 的 top-1 準確度。X-Linker 在三個資料集：BC5CDR-Disease、NCBI-Disease 和 BioRED-Chemical 中表現出優異的效能。相反地，SapBERT 在其餘三個資料集中優於 X-Linker。兩個模型僅依賴於它們操作的提及字串。X-Linker 和其相關資料的原始程式碼公開提供，可執行生物醫學實體連結，而無需特定知識組織系統中識別符號的預先標籤實體。

##### **Depression Detection and Analysis using Large Language Models on Textual and Audio-Visual Modalities**
2407.06125v1 by Avinash Anand, Chayan Tank, Sarthak Pol, Vinayak Katoch, Shaina Mehta, Rajiv Ratn Shah

Depression has proven to be a significant public health issue, profoundly
affecting the psychological well-being of individuals. If it remains
undiagnosed, depression can lead to severe health issues, which can manifest
physically and even lead to suicide. Generally, Diagnosing depression or any
other mental disorder involves conducting semi-structured interviews alongside
supplementary questionnaires, including variants of the Patient Health
Questionnaire (PHQ) by Clinicians and mental health professionals. This
approach places significant reliance on the experience and judgment of trained
physicians, making the diagnosis susceptible to personal biases. Given that the
underlying mechanisms causing depression are still being actively researched,
physicians often face challenges in diagnosing and treating the condition,
particularly in its early stages of clinical presentation. Recently,
significant strides have been made in Artificial neural computing to solve
problems involving text, image, and speech in various domains. Our analysis has
aimed to leverage these state-of-the-art (SOTA) models in our experiments to
achieve optimal outcomes leveraging multiple modalities. The experiments were
performed on the Extended Distress Analysis Interview Corpus Wizard of Oz
dataset (E-DAIC) corpus presented in the Audio/Visual Emotion Challenge (AVEC)
2019 Challenge. The proposed solutions demonstrate better results achieved by
Proprietary and Open-source Large Language Models (LLMs), which achieved a Root
Mean Square Error (RMSE) score of 3.98 on Textual Modality, beating the AVEC
2019 challenge baseline results and current SOTA regression analysis
architectures. Additionally, the proposed solution achieved an accuracy of
71.43% in the classification task. The paper also includes a novel audio-visual
multi-modal network that predicts PHQ-8 scores with an RMSE of 6.51.

摘要：憂鬱症已被證實是一個重大的公共衛生議題，深刻影響個人心理健康。如果憂鬱症未經診斷，可能會導致嚴重的健康問題，這些問題可能在生理上顯現，甚至導致自殺。通常，診斷憂鬱症或任何其他精神疾病都涉及進行半結構化訪談，以及補充問卷，包括臨床醫生和心理健康專業人員所使用的患者健康問卷 (PHQ) 變體。這種方法非常依賴受過訓練的醫師的經驗和判斷，使診斷容易受到個人偏見的影響。由於導致憂鬱症的潛在機制仍在積極研究中，因此醫師在診斷和治療這種疾病時經常面臨挑戰，尤其是在臨床表現的早期階段。最近，人工神經運算在解決涉及文本、影像和語言的各種領域問題方面取得了重大進展。我們的分析旨在利用這些最先進 (SOTA) 模型在我們的實驗中，透過利用多種模式來達成最佳結果。這些實驗是在 Audio/Visual Emotion Challenge (AVEC) 2019 Challenge 中提出的 Extended Distress Analysis Interview Corpus Wizard of Oz 資料集 (E-DAIC) 語料庫上進行的。所提出的解決方案證明了專有和開放原始碼大型語言模型 (LLM) 所取得的較佳結果，這些模型在文本模式上達到了 3.98 的均方根誤差 (RMSE) 分數，優於 AVEC 2019 挑戰基準結果和目前的 SOTA 回歸分析架構。此外，所提出的解決方案在分類任務中達到了 71.43% 的準確率。本文還包括一個新穎的音訊視覺多模式網路，其使用 6.51 的 RMSE 預測 PHQ-8 分數。

##### **Igea: a Decoder-Only Language Model for Biomedical Text Generation in Italian**
2407.06011v1 by Tommaso Mario Buonocore, Simone Rancati, Enea Parimbelli

The development of domain-specific language models has significantly advanced
natural language processing applications in various specialized fields,
particularly in biomedicine. However, the focus has largely been on
English-language models, leaving a gap for less-resourced languages such as
Italian. This paper introduces Igea, the first decoder-only language model
designed explicitly for biomedical text generation in Italian. Built on the
Minerva model and continually pretrained on a diverse corpus of Italian medical
texts, Igea is available in three model sizes: 350 million, 1 billion, and 3
billion parameters. The models aim to balance computational efficiency and
performance, addressing the challenges of managing the peculiarities of medical
terminology in Italian. We evaluate Igea using a mix of in-domain biomedical
corpora and general-purpose benchmarks, highlighting its efficacy and retention
of general knowledge even after the domain-specific training. This paper
discusses the model's development and evaluation, providing a foundation for
future advancements in Italian biomedical NLP.

摘要：特定領域語言模型的發展已大幅提升了各種專業領域的自然語言處理應用，特別是在生物醫學領域。然而，目前的研究重點主要放在英語語言模型上，這對義大利語等資源較少的語言來說是一大缺憾。本文介紹了 Igea，這是第一個專門設計用於義大利語生物醫學文本生成的僅解碼器語言模型。Igea 建構在 Minerva 模型上，並持續在大量義大利醫學文本語料庫上進行預訓練，提供三種模型大小：3.5 億、10 億和 30 億個參數。這些模型旨在平衡運算效率和效能，解決處理義大利語醫學術語特性的挑戰。我們使用混合領域生物醫學語料庫和通用基準對 Igea 進行評估，強調了其功效和在特定領域訓練後仍能保留一般知識。本文探討了模型的開發和評估，為義大利語生物醫學自然語言處理的未來進展奠定了基礎。

##### **Generation and De-Identification of Indian Clinical Discharge Summaries using LLMs**
2407.05887v1 by Sanjeet Singh, Shreya Gupta, Niralee Gupta, Naimish Sharma, Lokesh Srivastava, Vibhu Agarwal, Ashutosh Modi

The consequences of a healthcare data breach can be devastating for the
patients, providers, and payers. The average financial impact of a data breach
in recent months has been estimated to be close to USD 10 million. This is
especially significant for healthcare organizations in India that are managing
rapid digitization while still establishing data governance procedures that
align with the letter and spirit of the law. Computer-based systems for
de-identification of personal information are vulnerable to data drift, often
rendering them ineffective in cross-institution settings. Therefore, a rigorous
assessment of existing de-identification against local health datasets is
imperative to support the safe adoption of digital health initiatives in India.
Using a small set of de-identified patient discharge summaries provided by an
Indian healthcare institution, in this paper, we report the nominal performance
of de-identification algorithms (based on language models) trained on publicly
available non-Indian datasets, pointing towards a lack of cross-institutional
generalization. Similarly, experimentation with off-the-shelf de-identification
systems reveals potential risks associated with the approach. To overcome data
scarcity, we explore generating synthetic clinical reports (using publicly
available and Indian summaries) by performing in-context learning over Large
Language Models (LLMs). Our experiments demonstrate the use of generated
reports as an effective strategy for creating high-performing de-identification
systems with good generalization capabilities.

摘要：醫療保健資料外洩的後果對患者、提供者和付款者來說可能是毀滅性的。最近幾個月資料外洩的平均財務影響估計接近 1,000 萬美元。這對印度的醫療保健組織來說尤其重要，這些組織在管理快速數位化的同時，仍在建立符合法律條文和精神的資料治理程序。用於去識別個人資訊的電腦系統容易受到資料漂移的影響，通常導致它們在跨機構設定中無效。因此，必須嚴格評估現有的去識別與當地健康資料集，才能支援印度安全採用數位健康計畫。本文使用印度醫療保健機構提供的一小組去識別患者出院摘要，報告了在公開可用的非印度資料集上訓練的去識別演算法（基於語言模型）的標稱效能，指出缺乏跨機構概化。同樣地，對現成的去識別系統進行實驗揭示了與該方法相關的潛在風險。為了克服資料稀少的問題，我們探討透過在大語言模型 (LLM) 上執行情境學習來產生合成臨床報告（使用公開可用的印度摘要）。我們的實驗證明了使用產生的報告作為建立具有良好概化能力的高效能去識別系統的有效策略。

##### **Integrating AI in College Education: Positive yet Mixed Experiences with ChatGPT**
2407.05810v1 by Xinrui Song, Jiajin Zhang, Pingkun Yan, Juergen Hahn, Uwe Kruger, Hisham Mohamed, Ge Wang

The integration of artificial intelligence (AI) chatbots into higher
education marks a shift towards a new generation of pedagogical tools,
mirroring the arrival of milestones like the internet. With the launch of
ChatGPT-4 Turbo in November 2023, we developed a ChatGPT-based teaching
application (https://chat.openai.com/g/g-1imx1py4K-chatge-medical-imaging) and
integrated it into our undergraduate medical imaging course in the Spring 2024
semester. This study investigates the use of ChatGPT throughout a semester-long
trial, providing insights into students' engagement, perception, and the
overall educational effectiveness of the technology. We systematically
collected and analyzed data concerning students' interaction with ChatGPT,
focusing on their attitudes, concerns, and usage patterns. The findings
indicate that ChatGPT offers significant advantages such as improved
information access and increased interactivity, but its adoption is accompanied
by concerns about the accuracy of the information provided and the necessity
for well-defined guidelines to optimize its use.

摘要：人工智能（AI）聊天機器人整合到高等教育中，標誌著新一代教學工具的轉變，反映了網路等里程碑的到來。隨著 ChatGPT-4 Turbo 在 2023 年 11 月推出，我們開發了一個基於 ChatGPT 的教學應用程式（https://chat.openai.com/g/g-1imx1py4K-chatge-medical-imaging），並在 2024 年春季學期將其整合到我們的醫學影像學本科課程中。本研究調查了在一個學期長的試驗中使用 ChatGPT 的情況，深入了解學生的參與度、看法和技術的整體教育效果。我們系統地收集和分析了有關學生與 ChatGPT 互動的資料，重點關注他們的態度、疑慮和使用模式。研究結果表明，ChatGPT 提供了顯著的優勢，例如改進資訊的取得和增加互動性，但其採用也伴隨著對所提供資訊準確性的疑慮，以及最佳化其使用的明確準則的必要性。

##### **FedMRL: Data Heterogeneity Aware Federated Multi-agent Deep Reinforcement Learning for Medical Imaging**
2407.05800v1 by Pranab Sahoo, Ashutosh Tripathi, Sriparna Saha, Samrat Mondal

Despite recent advancements in federated learning (FL) for medical image
diagnosis, addressing data heterogeneity among clients remains a significant
challenge for practical implementation. A primary hurdle in FL arises from the
non-IID nature of data samples across clients, which typically results in a
decline in the performance of the aggregated global model. In this study, we
introduce FedMRL, a novel federated multi-agent deep reinforcement learning
framework designed to address data heterogeneity. FedMRL incorporates a novel
loss function to facilitate fairness among clients, preventing bias in the
final global model. Additionally, it employs a multi-agent reinforcement
learning (MARL) approach to calculate the proximal term $(\mu)$ for the
personalized local objective function, ensuring convergence to the global
optimum. Furthermore, FedMRL integrates an adaptive weight adjustment method
using a Self-organizing map (SOM) on the server side to counteract distribution
shifts among clients' local data distributions. We assess our approach using
two publicly available real-world medical datasets, and the results demonstrate
that FedMRL significantly outperforms state-of-the-art techniques, showing its
efficacy in addressing data heterogeneity in federated learning. The code can
be found here~{\url{https://github.com/Pranabiitp/FedMRL}}.

摘要：儘管在用於醫學影像診斷的聯邦學習 (FL) 方面有近期的進展，但解決客戶端之間的資料異質性仍然是實際執行的重大挑戰。聯邦學習的主要障礙來自於客戶端之間資料樣本的非獨立同分布 (non-IID) 特性，這通常會導致彙總的全球模型效能下降。在本研究中，我們引入了 FedMRL，一個新穎的聯邦多智能體深度強化學習框架，旨在解決資料異質性。FedMRL 結合了一個新穎的損失函數，以促進客戶端之間的公平性，防止最終全球模型中的偏差。此外，它採用多智能體強化學習 (MARL) 方法來計算個性化局部目標函數的近端項 (μ)，確保收斂到全局最優值。此外，FedMRL 整合了一種自適應權重調整方法，在伺服器端使用自組織化對應 (SOM)，以抵消客戶端本地資料分佈之間的分布轉移。我們使用兩個公開可用的真實世界醫學資料集評估我們的做法，結果表明 FedMRL 明顯優於最先進的技術，顯示其在解決聯邦學習中資料異質性方面的效能。程式碼可以在這裡找到~{\url{https://github.com/Pranabiitp/FedMRL}}。

##### **Large Language Models for Judicial Entity Extraction: A Comparative Study**
2407.05786v1 by Atin Sakkeer Hussain, Anu Thomas

Domain-specific Entity Recognition holds significant importance in legal
contexts, serving as a fundamental task that supports various applications such
as question-answering systems, text summarization, machine translation,
sentiment analysis, and information retrieval specifically within case law
documents. Recent advancements have highlighted the efficacy of Large Language
Models in natural language processing tasks, demonstrating their capability to
accurately detect and classify domain-specific facts (entities) from
specialized texts like clinical and financial documents. This research
investigates the application of Large Language Models in identifying
domain-specific entities (e.g., courts, petitioner, judge, lawyer, respondents,
FIR nos.) within case law documents, with a specific focus on their aptitude
for handling domain-specific language complexity and contextual variations. The
study evaluates the performance of state-of-the-art Large Language Model
architectures, including Large Language Model Meta AI 3, Mistral, and Gemma, in
the context of extracting judicial facts tailored to Indian judicial texts.
Mistral and Gemma emerged as the top-performing models, showcasing balanced
precision and recall crucial for accurate entity identification. These findings
confirm the value of Large Language Models in judicial documents and
demonstrate how they can facilitate and quicken scientific research by
producing precise, organised data outputs that are appropriate for in-depth
examination.

摘要：領域特定實體辨識在法律脈絡中至關重要，作為支援各種應用程式的基礎任務，例如在案例法文件中進行問答系統、文字摘要、機器翻譯、情緒分析和資訊檢索。最近的進展突顯了大型語言模型在自然語言處理任務中的效能，展示了它們準確偵測和分類來自專業文本（例如臨床和財務文件）的領域特定事實（實體）的能力。本研究探討了大型語言模型在案例法文件中辨識領域特定實體（例如法院、請願人、法官、律師、答辯人、FIR 編號）的應用，特別關注它們處理領域特定語言複雜性和脈絡變化的能力。本研究評估了最先進的大型語言模型架構（包括 Large Language Model Meta AI 3、Mistral 和 Gemma）在提取針對印度司法文本量身打造的司法事實方面的效能。Mistral 和 Gemma 成為表現最佳的模型，展示了準確實體辨識至關重要的平衡精確度和召回率。這些發現證實了大型語言模型在司法文件中的價值，並展示了它們如何透過產生適用於深入檢驗的精確、有組織的資料輸出，來促進和加速科學研究。

##### **Potential of Multimodal Large Language Models for Data Mining of Medical Images and Free-text Reports**
2407.05758v1 by Yutong Zhang, Yi Pan, Tianyang Zhong, Peixin Dong, Kangni Xie, Yuxiao Liu, Hanqi Jiang, Zhengliang Liu, Shijie Zhao, Tuo Zhang, Xi Jiang, Dinggang Shen, Tianming Liu, Xin Zhang

Medical images and radiology reports are crucial for diagnosing medical
conditions, highlighting the importance of quantitative analysis for clinical
decision-making. However, the diversity and cross-source heterogeneity of these
data challenge the generalizability of current data-mining methods. Multimodal
large language models (MLLMs) have recently transformed many domains,
significantly affecting the medical field. Notably, Gemini-Vision-series
(Gemini) and GPT-4-series (GPT-4) models have epitomized a paradigm shift in
Artificial General Intelligence (AGI) for computer vision, showcasing their
potential in the biomedical domain. In this study, we evaluated the performance
of the Gemini, GPT-4, and 4 popular large models for an exhaustive evaluation
across 14 medical imaging datasets, including 5 medical imaging categories
(dermatology, radiology, dentistry, ophthalmology, and endoscopy), and 3
radiology report datasets. The investigated tasks encompass disease
classification, lesion segmentation, anatomical localization, disease
diagnosis, report generation, and lesion detection. Our experimental results
demonstrated that Gemini-series models excelled in report generation and lesion
detection but faces challenges in disease classification and anatomical
localization. Conversely, GPT-series models exhibited proficiency in lesion
segmentation and anatomical localization but encountered difficulties in
disease diagnosis and lesion detection. Additionally, both the Gemini series
and GPT series contain models that have demonstrated commendable generation
efficiency. While both models hold promise in reducing physician workload,
alleviating pressure on limited healthcare resources, and fostering
collaboration between clinical practitioners and artificial intelligence
technologies, substantial enhancements and comprehensive validations remain
imperative before clinical deployment.

摘要：<paragraph>醫學影像和放射科報告對診斷醫療狀況至關重要，突顯了定量分析在臨床決策中的重要性。然而，這些數據的多樣性和跨來源異質性挑戰了當前數據挖掘方法的概括性。多模態大型語言模型 (MLLM) 近來已轉變許多領域，對醫學領域影響重大。值得注意的是，Gemini-Vision 系列 (Gemini) 和 GPT-4 系列 (GPT-4) 模型已成為電腦視覺中人工通用智慧 (AGI) 的典範轉移，展示了它們在生物醫學領域的潛力。在這項研究中，我們評估了 Gemini、GPT-4 和 4 個熱門大型模型在 14 個醫療影像數據集上的廣泛評估表現，包括 5 個醫療影像類別（皮膚科、放射科、牙科、眼科和內視鏡檢查），以及 3 個放射科報告數據集。所調查的任務包括疾病分類、病灶分割、解剖定位、疾病診斷、報告生成和病灶檢測。我們的實驗結果表明，Gemini 系列模型在報告生成和病灶檢測方面表現出色，但在疾病分類和解剖定位方面面臨挑戰。相反，GPT 系列模型在病灶分割和解剖定位方面表現出熟練度，但在疾病診斷和病灶檢測方面遇到困難。此外，Gemini 系列和 GPT 系列都包含已證明具有可取生成效率的模型。儘管這兩種模型都有望減少醫師的工作量，減輕有限醫療保健資源的壓力，並促進臨床從業人員與人工智慧技術之間的合作，但在臨床部署之前，實質性的增強和全面的驗證仍然勢在必行。</paragraph>

##### **RadiomicsFill-Mammo: Synthetic Mammogram Mass Manipulation with Radiomics Features**
2407.05683v1 by Inye Na, Jonghun Kim, Eun Sook Ko, Hyunjin Park

Motivated by the question, "Can we generate tumors with desired attributes?''
this study leverages radiomics features to explore the feasibility of
generating synthetic tumor images. Characterized by its low-dimensional yet
biologically meaningful markers, radiomics bridges the gap between complex
medical imaging data and actionable clinical insights. We present
RadiomicsFill-Mammo, the first of the RadiomicsFill series, an innovative
technique that generates realistic mammogram mass images mirroring specific
radiomics attributes using masked images and opposite breast images, leveraging
a recent stable diffusion model. This approach also allows for the
incorporation of essential clinical variables, such as BI-RADS and breast
density, alongside radiomics features as conditions for mass generation.
Results indicate that RadiomicsFill-Mammo effectively generates diverse and
realistic tumor images based on various radiomics conditions. Results also
demonstrate a significant improvement in mass detection capabilities,
leveraging RadiomicsFill-Mammo as a strategy to generate simulated samples.
Furthermore, RadiomicsFill-Mammo not only advances medical imaging research but
also opens new avenues for enhancing treatment planning and tumor simulation.
Our code is available at https://github.com/nainye/RadiomicsFill.

摘要：<paragraph>本研究以「我們能生成具有所需屬性的腫瘤嗎？」這個問題為動機，利用放射特徵來探討生成合成腫瘤影像的可行性。放射特徵以其低維度且具有生物意義的標記為特徵，彌補了複雜醫學影像資料與可操作臨床見解之間的差距。我們提出 RadiomicsFill-Mammo，RadiomicsFill 系列的第一個，這是一種創新的技術，利用遮罩影像和對側乳房影像，並利用最近的穩定擴散模型，生成反映特定放射特徵屬性的逼真乳房攝影腫塊影像。這種方法還允許將基本臨床變數，例如 BI-RADS 和乳房密度，與放射特徵一起作為生成腫塊的條件。結果表明，RadiomicsFill-Mammo 能有效地根據各種放射條件生成多樣化且逼真的腫瘤影像。結果還證明了腫塊檢測能力的顯著提升，利用 RadiomicsFill-Mammo 作為生成模擬樣本的策略。此外，RadiomicsFill-Mammo 不僅推動了醫學影像研究，還為增強治療規劃和腫瘤模擬開闢了新途徑。我們的程式碼可在 https://github.com/nainye/RadiomicsFill 取得。</paragraph>

##### **WSI-VQA: Interpreting Whole Slide Images by Generative Visual Question Answering**
2407.05603v1 by Pingyi Chen, Chenglu Zhu, Sunyi Zheng, Honglin Li, Lin Yang

Whole slide imaging is routinely adopted for carcinoma diagnosis and
prognosis. Abundant experience is required for pathologists to achieve accurate
and reliable diagnostic results of whole slide images (WSI). The huge size and
heterogeneous features of WSIs make the workflow of pathological reading
extremely time-consuming. In this paper, we propose a novel framework (WSI-VQA)
to interpret WSIs by generative visual question answering. WSI-VQA shows
universality by reframing various kinds of slide-level tasks in a
question-answering pattern, in which pathologists can achieve
immunohistochemical grading, survival prediction, and tumor subtyping following
human-machine interaction. Furthermore, we establish a WSI-VQA dataset which
contains 8672 slide-level question-answering pairs with 977 WSIs. Besides the
ability to deal with different slide-level tasks, our generative model which is
named Wsi2Text Transformer (W2T) outperforms existing discriminative models in
medical correctness, which reveals the potential of our model to be applied in
the clinical scenario. Additionally, we also visualize the co-attention mapping
between word embeddings and WSIs as an intuitive explanation for diagnostic
results. The dataset and related code are available at
https://github.com/cpystan/WSI-VQA.

摘要：全切片影像通常用於癌症的診斷和預後。病理學家需要有豐富的經驗才能對全切片影像 (WSI) 做出準確且可靠的診斷結果。WSI 的尺寸龐大且特徵異質，使得病理學判讀的工作流程極為耗時。在本文中，我們提出了一個新的框架 (WSI-VQA)，透過生成式視覺問答來詮釋 WSI。WSI-VQA 透過在問答模式中重新定義各種切片層級任務，展現其通用性，病理學家可以在人機互動後，完成免疫組織化學分級、存活預測和腫瘤亞型分類。此外，我們建立了一個 WSI-VQA 資料集，其中包含 8672 個切片層級問答對，以及 977 個 WSI。除了能夠處理不同的切片層級任務外，我們名為 Wsi2Text Transformer (W2T) 的生成模型在醫學正確性方面優於現有的判別模型，這揭示了我們的模型在臨床場景中應用的潛力。此外，我們還將詞嵌入和 WSI 之間的共同注意映射視覺化，作為診斷結果的直觀解釋。資料集和相關程式碼可在 https://github.com/cpystan/WSI-VQA 取得。

##### **Accelerating MRI Uncertainty Estimation with Mask-based Bayesian Neural Network**
2407.05521v1 by Zehuan Zhang, Matej Genci, Hongxiang Fan, Andreas Wetscherek, Wayne Luk

Accurate and reliable Magnetic Resonance Imaging (MRI) analysis is
particularly important for adaptive radiotherapy, a recent medical advance
capable of improving cancer diagnosis and treatment. Recent studies have shown
that IVIM-NET, a deep neural network (DNN), can achieve high accuracy in MRI
analysis, indicating the potential of deep learning to enhance diagnostic
capabilities in healthcare. However, IVIM-NET does not provide calibrated
uncertainty information needed for reliable and trustworthy predictions in
healthcare. Moreover, the expensive computation and memory demands of IVIM-NET
reduce hardware performance, hindering widespread adoption in realistic
scenarios. To address these challenges, this paper proposes an
algorithm-hardware co-optimization flow for high-performance and reliable MRI
analysis. At the algorithm level, a transformation design flow is introduced to
convert IVIM-NET to a mask-based Bayesian Neural Network (BayesNN),
facilitating reliable and efficient uncertainty estimation. At the hardware
level, we propose an FPGA-based accelerator with several hardware
optimizations, such as mask-zero skipping and operation reordering.
Experimental results demonstrate that our co-design approach can satisfy the
uncertainty requirements of MRI analysis, while achieving 7.5 times and 32.5
times speedup on an Xilinx VU13P FPGA compared to GPU and CPU implementations
with reduced power consumption.

摘要：精準可靠的磁振造影 (MRI) 分析對於適應性放射治療特別重要，這是一種近期醫療進展，能夠改善癌症診斷和治療。最近的研究顯示，深度神經網路 (DNN) 的 IVIM-NET 能在 MRI 分析中達到高準確度，顯示深度學習有潛力增強醫療保健中的診斷能力。然而，IVIM-NET 沒有提供在醫療保健中進行可靠且值得信賴的預測所需的校準不確定性資訊。此外，IVIM-NET 昂貴的運算和記憶體需求降低了硬體效能，阻礙了在實際場景中的廣泛採用。為了解決這些挑戰，本文提出了一種演算法與硬體共同最佳化的流程，以進行高性能且可靠的 MRI 分析。在演算法層級，引入了轉換設計流程，將 IVIM-NET 轉換為基於遮罩的貝氏神經網路 (BayesNN)，促進可靠且有效的非確定性估計。在硬體層級，我們提出了一種基於 FPGA 的加速器，具備多項硬體最佳化，例如遮罩零跳過和運算重新排序。實驗結果證明，我們的共同設計方法可以滿足 MRI 分析的不確定性需求，同時在 Xilinx VU13P FPGA 上實現比 GPU 和 CPU 實作快上 7.5 倍和 32.5 倍的速度，且功耗降低。

##### **A Survey of Models for Cognitive Diagnosis: New Developments and Future Directions**
2407.05458v1 by Fei Wang, Weibo Gao, Qi Liu, Jiatong Li, Guanhao Zhao, Zheng Zhang, Zhenya Huang, Mengxiao Zhu, Shijin Wang, Wei Tong, Enhong Chen

Cognitive diagnosis has been developed for decades as an effective
measurement tool to evaluate human cognitive status such as ability level and
knowledge mastery. It has been applied to a wide range of fields including
education, sport, psychological diagnosis, etc. By providing better awareness
of cognitive status, it can serve as the basis for personalized services such
as well-designed medical treatment, teaching strategy and vocational training.
This paper aims to provide a survey of current models for cognitive diagnosis,
with more attention on new developments using machine learning-based methods.
By comparing the model structures, parameter estimation algorithms, model
evaluation methods and applications, we provide a relatively comprehensive
review of the recent trends in cognitive diagnosis models. Further, we discuss
future directions that are worthy of exploration. In addition, we release two
Python libraries: EduData for easy access to some relevant public datasets we
have collected, and EduCDM that implements popular CDMs to facilitate both
applications and research purposes.

摘要：認知診斷已發展數十年，作為評估人類認知狀態（例如能力水平和知識掌握）的有效測量工具。它已被應用於廣泛的領域，包括教育、體育、心理診斷等。透過提供對認知狀態的更好認識，它可以作為個人化服務的基礎，例如精心設計的醫療治療、教學策略和職業訓練。本文旨在提供認知診斷當前模型的綜述，並更關注使用基於機器學習的方法的新發展。透過比較模型結構、參數估計演算法、模型評估方法和應用，我們對認知診斷模型的最新趨勢提供了相對全面的回顧。此外，我們討論了值得探索的未來方向。此外，我們發布了兩個 Python 程式庫：EduData，用於輕鬆存取我們收集的一些相關公開資料集，以及 EduCDM，用於實作熱門的 CDM，以促進應用和研究目的。

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v1 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

摘要：<paragraph>本文提出了用于视网膜眼底图像疾病分类的扩张残差网络 (ResNet) 模型。扩张卷积滤波器用于替换 ResNet 模型较高层中的正常卷积滤波器（扩张 ResNet），以改善与用于疾病分类的正常 ResNet 模型相比的感受野。本研究介绍了采用深度学习的计算机辅助诊断工具，并通过可解释的 AI 技术进行了增强。这些技术旨在使该工具的决策过程透明化，从而使医疗专业人员能够理解和信任 AI 的诊断决策。它们在当今医疗保健领域尤为重要，因为对 AI 应用程序的透明度需求不断增长，以确保其可靠性和道德使用。扩张 ResNet 用作正常 ResNet 的替代品，以提高视网膜眼病的分类准确性并减少所需的计算时间。本工作中使用的数据集是 Ocular Disease Intelligent Recognition (ODIR) 数据集，这是一个结构化的眼科数据库，包含八类涵盖大多数常见视网膜眼病。本工作中使用的评估指标包括精确度、召回率、准确度和 F1 分数。在这项工作中，对正常 ResNet 模型和扩张 ResNet 模型在五个变体（即 ResNet-18、ResNet-34、ResNet-50、ResNet-101 和 ResNet-152）之间进行了比较研究。与正常 ResNet 相比，扩张 ResNet 模型显示出有希望的结果，在 ODIR 多类疾病分类中，上述各个变体的平均 F1 分数分别为 0.71、0.70、0.69、0.67 和 0.70。</paragraph>

##### **FM-OSD: Foundation Model-Enabled One-Shot Detection of Anatomical Landmarks**
2407.05412v1 by Juzheng Miao, Cheng Chen, Keli Zhang, Jie Chuai, Quanzheng Li, Pheng-Ann Heng

One-shot detection of anatomical landmarks is gaining significant attention
for its efficiency in using minimal labeled data to produce promising results.
However, the success of current methods heavily relies on the employment of
extensive unlabeled data to pre-train an effective feature extractor, which
limits their applicability in scenarios where a substantial amount of unlabeled
data is unavailable. In this paper, we propose the first foundation
model-enabled one-shot landmark detection (FM-OSD) framework for accurate
landmark detection in medical images by utilizing solely a single template
image without any additional unlabeled data. Specifically, we use the frozen
image encoder of visual foundation models as the feature extractor, and
introduce dual-branch global and local feature decoders to increase the
resolution of extracted features in a coarse to fine manner. The introduced
feature decoders are efficiently trained with a distance-aware similarity
learning loss to incorporate domain knowledge from the single template image.
Moreover, a novel bidirectional matching strategy is developed to improve both
robustness and accuracy of landmark detection in the case of scattered
similarity map obtained by foundation models. We validate our method on two
public anatomical landmark detection datasets. By using solely a single
template image, our method demonstrates significant superiority over strong
state-of-the-art one-shot landmark detection methods.

摘要：解剖標誌的一發偵測因其使用最少標籤資料產生有前景結果的效率而獲得顯著關注。然而，目前方法的成功極度依賴運用廣泛的未標籤資料來預先訓練一個有效特徵萃取器，這限制了其在大量未標籤資料不可用的情況下的適用性。在本文中，我們提出第一個基礎模型啟用的單發標誌偵測 (FM-OSD) 架構，藉由僅僅利用單一範本影像而無任何其他未標籤資料，在醫學影像中進行精確標誌偵測。具體來說，我們使用視覺基礎模型的凍結影像編碼器作為特徵萃取器，並引入雙分支全局和局部特徵解碼器，以粗到細的方式增加萃取特徵的分辨率。引入的特徵解碼器利用距離感知相似性學習損失函數進行有效訓練，以納入單一範本影像的領域知識。此外，開發了一種新穎的雙向匹配策略，以提高基礎模型取得的散佈相似性圖在標誌偵測中的穩健性和準確性。我們在兩個公開的解剖標誌偵測資料集驗證我們的模型。我們的模型僅使用單一範本影像，證明其優於現有技術中強大的單發標誌偵測方法。

##### **BadCLM: Backdoor Attack in Clinical Language Models for Electronic Health Records**
2407.05213v1 by Weimin Lyu, Zexin Bi, Fusheng Wang, Chao Chen

The advent of clinical language models integrated into electronic health
records (EHR) for clinical decision support has marked a significant
advancement, leveraging the depth of clinical notes for improved
decision-making. Despite their success, the potential vulnerabilities of these
models remain largely unexplored. This paper delves into the realm of backdoor
attacks on clinical language models, introducing an innovative attention-based
backdoor attack method, BadCLM (Bad Clinical Language Models). This technique
clandestinely embeds a backdoor within the models, causing them to produce
incorrect predictions when a pre-defined trigger is present in inputs, while
functioning accurately otherwise. We demonstrate the efficacy of BadCLM through
an in-hospital mortality prediction task with MIMIC III dataset, showcasing its
potential to compromise model integrity. Our findings illuminate a significant
security risk in clinical decision support systems and pave the way for future
endeavors in fortifying clinical language models against such vulnerabilities.

摘要：臨床語言模型整合到電子健康紀錄 (EHR) 中以進行臨床決策支援，標誌著一項重大的進展，利用臨床筆記的深度來改善決策制定。儘管這些模型取得了成功，但它們的潛在漏洞在很大程度上仍未得到探索。本文深入探討了針對臨床語言模型的後門攻擊領域，介紹了一種創新的基於注意力的後門攻擊方法 BadCLM（不良臨床語言模型）。這種技術秘密地在模型中嵌入了一個後門，導致它們在輸入中存在預定義觸發器時產生不正確的預測，而其他情況下則準確運作。我們通過使用 MIMIC III 資料集進行院內死亡率預測任務來證明 BadCLM 的效力，展示了其損害模型完整性的潛力。我們的發現揭示了臨床決策支援系統中的一個重大安全風險，並為未來加強臨床語言模型以應對此類漏洞的努力鋪平了道路。

##### **RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models**
2407.05131v1 by Peng Xia, Kangyu Zhu, Haoran Li, Hongtu Zhu, Yun Li, Gang Li, Linjun Zhang, Huaxiu Yao

The recent emergence of Medical Large Vision Language Models (Med-LVLMs) has
enhanced medical diagnosis. However, current Med-LVLMs frequently encounter
factual issues, often generating responses that do not align with established
medical facts. Retrieval-Augmented Generation (RAG), which utilizes external
knowledge, can improve the factual accuracy of these models but introduces two
major challenges. First, limited retrieved contexts might not cover all
necessary information, while excessive retrieval can introduce irrelevant and
inaccurate references, interfering with the model's generation. Second, in
cases where the model originally responds correctly, applying RAG can lead to
an over-reliance on retrieved contexts, resulting in incorrect answers. To
address these issues, we propose RULE, which consists of two components. First,
we introduce a provably effective strategy for controlling factuality risk
through the calibrated selection of the number of retrieved contexts. Second,
based on samples where over-reliance on retrieved contexts led to errors, we
curate a preference dataset to fine-tune the model, balancing its dependence on
inherent knowledge and retrieved contexts for generation. We demonstrate the
effectiveness of RULE on three medical VQA datasets, achieving an average
improvement of 20.8% in factual accuracy. We publicly release our benchmark and
code in https://github.com/richard-peng-xia/RULE.

摘要：最近出現的醫療大型語言模型 (Med-LVLMs) 提升了醫療診斷。然而，目前的 Med-LVLMs 經常遇到事實問題，通常會產生與已確立的醫療事實不符的回應。利用外部知識的檢索增強生成 (RAG) 可以改善這些模型的事實準確性，但引入了兩個主要挑戰。首先，有限的檢索內容可能無法涵蓋所有必要的資訊，而過度的檢索可能會引入不相關和不準確的參考，干擾模型的生成。其次，在模型原本正確回應的情況下，應用 RAG 可能會過度依賴檢索到的內容，導致不正確的答案。為了解決這些問題，我們提出了 RULE，它包含兩個組成部分。首先，我們引入了一種可證明有效的策略，透過校準檢索到的內容數量來控制事實風險。其次，根據過度依賴檢索到的內容導致錯誤的範例，我們策劃了一個偏好資料集來微調模型，平衡其在生成時對內在知識和檢索到的內容的依賴性。我們在三個醫療 VQA 資料集上展示了 RULE 的有效性，在事實準確性方面平均提升了 20.8%。我們在 https://github.com/richard-peng-xia/RULE 中公開發布我們的基準和程式碼。

##### **Linear Attention Based Deep Nonlocal Means Filtering for Multiplicative Noise Removal**
2407.05087v1 by Xiao Siyao, Huang Libing, Zhang Shunsheng

Multiplicative noise widely exists in radar images, medical images and other
important fields' images. Compared to normal noises, multiplicative noise has a
generally stronger effect on the visual expression of images. Aiming at the
denoising problem of multiplicative noise, we linearize the nonlocal means
algorithm with deep learning and propose a linear attention mechanism based
deep nonlocal means filtering (LDNLM). Starting from the traditional nonlocal
means filtering, we employ deep channel convolution neural networks to extract
the information of the neighborhood matrix and obtain representation vectors of
every pixel. Then we replace the similarity calculation and weighted averaging
processes with the inner operations of the attention mechanism. To reduce the
computational overhead, through the formula of similarity calculation and
weighted averaging, we derive a nonlocal filter with linear complexity.
Experiments on both simulated and real multiplicative noise demonstrate that
the LDNLM is more competitive compared with the state-of-the-art methods.
Additionally, we prove that the LDNLM possesses interpretability close to
traditional NLM.

摘要：乘性雜訊廣泛存在於雷達影像、醫學影像等重要領域的影像中。相較於一般雜訊，乘性雜訊對影像的視覺表現具有普遍更強的影響。針對乘性雜訊的去雜訊問題，我們以深度學習線性化非局部均值演算法，並提出基於線性注意力機制的深度非局部均值濾波（LDNLM）。從傳統非局部均值濾波出發，我們採用深度通道卷積神經網路提取鄰域矩陣的資訊，並取得每個畫素的表示向量。接著，我們以注意力機制的內部運算取代相似度計算與加權平均的程序。為了降低運算負擔，我們透過相似度計算與加權平均的公式，推導出具有線性複雜度的非局部濾波器。在模擬與真實乘性雜訊上的實驗均證實，LDNLM 與目前最先進的方法相比更具競爭力。此外，我們證明 LDNLM 具備接近傳統 NLM 的可解釋性。

##### **Brain Age Estimation with a Greedy Dual-Stream Model for Limited Datasets**
2407.04808v1 by Iman Kianian, Hedieh Sajedi

Brain age estimation involves predicting the biological age of individuals
from their brain images, which offers valuable insights into the aging process
and the progression of neurodegenerative diseases. Conducting large-scale
datasets for medical image analysis is a challenging and time-consuming task.
Existing approaches mostly depend on large datasets, which are hard to come by
and expensive. These approaches also require sophisticated, resource-intensive
models with a large number of parameters, necessitating a considerable amount
of processing power. As a result, there is a vital need to develop innovative
methods that can achieve robust performance with limited datasets and efficient
use of computational resources. This paper proposes a novel slice-based
dual-stream method called GDSM (Greedy Dual-Stream Model) for brain age
estimation. This method addresses the limitations of large dataset requirements
and computational resource intensiveness. The proposed method incorporates
local and global aspects of the brain, thereby refining the focus on specific
target regions. The approach employs four backbones to predict ages based on
local and global features, complemented by a final model for age correction.
Our method demonstrates a Mean Absolute Error (MAE) of 3.25 years on the test
set of IBID, which only contains 289 subjects. To demonstrate the robustness of
our approach for any small dataset, we analyzed the proposed method with the
IXI dataset and achieved an MAE of 4.18 years on the test set of IXI. By
leveraging dual-stream and greedy strategies, this approach achieves efficiency
and robust performance, making it comparable with other state-of-the-art
methods. The code for the GDSM model is available at
https://github.com/iman2693/GDSM.

摘要：大腦年齡估計涉及從大腦影像預測個體的生物年齡，這對老化過程和神經退化性疾病的進展提供了寶貴的見解。對醫學影像分析進行大規模的數據集處理是一項具有挑戰性且耗時的任務。現有的方法大多依賴於大型數據集，而這些數據集難以獲得且昂貴。這些方法還需要複雜的、資源密集型的模型，這些模型具有大量的參數，需要大量的處理能力。因此，迫切需要開發創新的方法，這些方法可以在有限的數據集和高效利用計算資源的情況下實現穩健的性能。本文提出了一種稱為 GDSM（貪婪雙流模型）的新型基於切片的雙流方法，用於大腦年齡估計。這種方法解決了對大型數據集需求和計算資源密集性的限制。所提出的方法結合了大腦的局部和全局方面，從而精確關注具體的目標區域。該方法採用四個主幹根據局部和全局特徵預測年齡，並輔以一個最終模型進行年齡校正。我們的模型在僅包含 289 個受試者的 IBID 測試集中展示了 3.25 年的平均絕對誤差 (MAE)。為了證明我們的模型對任何小型數據集的穩健性，我們使用 IXI 數據集分析了所提出的方法，並在 IXI 的測試集中實現了 4.18 年的 MAE。通過利用雙流和貪婪策略，這種方法實現了高效和穩健的性能，使其與其他最先進的方法相當。GDSM 模型的代碼可在 https://github.com/iman2693/GDSM 上獲得。

##### **Entity Decomposition with Filtering: A Zero-Shot Clinical Named Entity Recognition Framework**
2407.04629v1 by Reza Averly, Xia Ning

Clinical named entity recognition (NER) aims to retrieve important entities
within clinical narratives. Recent works have demonstrated that large language
models (LLMs) can achieve strong performance in this task. While previous works
focus on proprietary LLMs, we investigate how open NER LLMs, trained
specifically for entity recognition, perform in clinical NER. In this paper, we
aim to improve them through a novel framework, entity decomposition with
filtering, or EDF. Our key idea is to decompose the entity recognition task
into several retrievals of sub-entity types. We also introduce a filtering
mechanism to remove incorrect entities. Our experimental results demonstrate
the efficacy of our framework across all metrics, models, datasets, and entity
types. Our analysis reveals that entity decomposition can recognize previously
missed entities with substantial improvement. We further provide a
comprehensive evaluation of our framework and an in-depth error analysis to
pave future works.

摘要：臨床命名實體識別 (NER) 旨在擷取臨床敘述中的重要實體。最近的研究表明，大型語言模型 (LLM) 可以在此任務中實現強大的效能。雖然先前的研究專注於專有的 LLM，但我們探討了專門針對實體識別訓練的開放式 NER LLM 在臨床 NER 中的表現。在本文中，我們旨在透過一個新穎的架構來改善它們，即帶有過濾的實體分解，或 EDF。我們的關鍵想法是將實體識別任務分解為多個子實體類型的擷取。我們還引入了一個過濾機制來移除不正確的實體。我們的實驗結果證明了我們架構在所有指標、模型、資料集和實體類型中的效能。我們的分析顯示，實體分解可以識別先前遺漏的實體，並有顯著的改善。我們進一步提供了我們架構的全面評估和深入的錯誤分析，為未來的研究鋪路。

##### **Variational and Explanatory Neural Networks for Encoding Cancer Profiles and Predicting Drug Responses**
2407.04486v1 by Tianshu Feng, Rohan Gnanaolivu, Abolfazl Safikhani, Yuanhang Liu, Jun Jiang, Nicholas Chia, Alexander Partin, Priyanka Vasanthakumari, Yitan Zhu, Chen Wang

Human cancers present a significant public health challenge and require the
discovery of novel drugs through translational research. Transcriptomics
profiling data that describes molecular activities in tumors and cancer cell
lines are widely utilized for predicting anti-cancer drug responses. However,
existing AI models face challenges due to noise in transcriptomics data and
lack of biological interpretability. To overcome these limitations, we
introduce VETE (Variational and Explanatory Transcriptomics Encoder), a novel
neural network framework that incorporates a variational component to mitigate
noise effects and integrates traceable gene ontology into the neural network
architecture for encoding cancer transcriptomics data. Key innovations include
a local interpretability-guided method for identifying ontology paths, a
visualization tool to elucidate biological mechanisms of drug responses, and
the application of centralized large scale hyperparameter optimization. VETE
demonstrated robust accuracy in cancer cell line classification and drug
response prediction. Additionally, it provided traceable biological
explanations for both tasks and offers insights into the mechanisms underlying
its predictions. VETE bridges the gap between AI-driven predictions and
biologically meaningful insights in cancer research, which represents a
promising advancement in the field.

摘要：人類癌症對公共衛生構成重大挑戰，需要透過轉譯研究發現新藥物。描述腫瘤和癌細胞株分子活動的轉錄組學分析資料廣泛用於預測抗癌藥物反應。然而，現有的 AI 模型因轉錄組學資料中的雜訊和缺乏生物學可解釋性而面臨挑戰。為了克服這些限制，我們引入了 VETE（變異和解釋性轉錄組學編碼器），這是一種新穎的神經網路架構，它結合了變異組成以減輕雜訊效應，並將可追蹤的基因本體整合到神經網路架構中以編碼癌症轉錄組學資料。關鍵創新包括一種局部可解釋性引導方法，用於識別本體路徑，一種用於闡明藥物反應的生物機制的視覺化工具，以及集中式大規模超參數最佳化的應用。VETE 在癌細胞株分類和藥物反應預測方面表現出穩健的準確性。此外，它為這兩個任務提供了可追蹤的生物學解釋，並提供了對其預測背後機制的見解。VETE 彌合了 AI 驅動預測與癌症研究中具有生物學意義的見解之間的差距，這代表了該領域的一項有前途的進展。

##### **Multi-modal Masked Siamese Network Improves Chest X-Ray Representation Learning**
2407.04449v1 by Saeed Shurrab, Alejandro Guerra-Manzanares, Farah E. Shamout

Self-supervised learning methods for medical images primarily rely on the
imaging modality during pretraining. While such approaches deliver promising
results, they do not leverage associated patient or scan information collected
within Electronic Health Records (EHR). Here, we propose to incorporate EHR
data during self-supervised pretraining with a Masked Siamese Network (MSN) to
enhance the quality of chest X-ray representations. We investigate three types
of EHR data, including demographic, scan metadata, and inpatient stay
information. We evaluate our approach on three publicly available chest X-ray
datasets, MIMIC-CXR, CheXpert, and NIH-14, using two vision transformer (ViT)
backbones, specifically ViT-Tiny and ViT-Small. In assessing the quality of the
representations via linear evaluation, our proposed method demonstrates
significant improvement compared to vanilla MSN and state-of-the-art
self-supervised learning baselines. Our work highlights the potential of
EHR-enhanced self-supervised pre-training for medical imaging. The code is
publicly available at: https://github.com/nyuad-cai/CXR-EHR-MSN

摘要：用於醫學影像的自監督式學習方法主要依賴於預訓練期間的影像模式。雖然此類方法提供了有前景的結果，但它們並未利用電子健康記錄 (EHR) 中收集的相關患者或掃描資訊。在此，我們建議在使用蒙面連體網路 (MSN) 進行自監督預訓練期間納入 EHR 資料，以提升胸部 X 光片表徵的品質。我們探討三種類型的 EHR 資料，包括人口統計資料、掃描元資料和住院期間資訊。我們在三個公開的胸部 X 光片資料集（MIMIC-CXR、CheXpert 和 NIH-14）上評估我們的做法，使用兩個視覺轉換器 (ViT) 主幹，特別是 ViT-Tiny 和 ViT-Small。在透過線性評估來評量表徵的品質時，我們提出的方法與傳統 MSN 和最先進的自監督式學習基準相比，表現出顯著的進步。我們的研究重點說明了 EHR 增強的自監督預訓練在醫學影像方面的潛力。此程式碼可於以下網址公開取得：https://github.com/nyuad-cai/CXR-EHR-MSN

##### **Query-Guided Self-Supervised Summarization of Nursing Notes**
2407.04125v1 by Ya Gao, Hans Moen, Saila Koivusalo, Miika Koskinen, Pekka Marttinen

Nursing notes, an important component of Electronic Health Records (EHRs),
keep track of the progression of a patient's health status during a care
episode. Distilling the key information in nursing notes through text
summarization techniques can improve clinicians' efficiency in understanding
patients' conditions when reviewing nursing notes. However, existing
abstractive summarization methods in the clinical setting have often overlooked
nursing notes and require the creation of reference summaries for supervision
signals, which is time-consuming. In this work, we introduce QGSumm, a
query-guided self-supervised domain adaptation framework for nursing note
summarization. Using patient-related clinical queries as guidance, our approach
generates high-quality, patient-centered summaries without relying on reference
summaries for training. Through automatic and manual evaluation by an expert
clinician, we demonstrate the strengths of our approach compared to the
state-of-the-art Large Language Models (LLMs) in both zero-shot and few-shot
settings. Ultimately, our approach provides a new perspective on conditional
text summarization, tailored to the specific interests of clinical personnel.

摘要：護理記錄是電子健康紀錄 (EHR) 的重要組成部分，
在照護過程中追蹤病患的健康狀態進展。利用文字摘要技術提煉護理記錄中的關鍵資訊，可以提升臨床醫師在檢視護理記錄時了解病患狀況的效率。然而，現有的臨床摘要方法常常忽略護理記錄，且需要建立參考摘要作為監督訊號，這非常耗時。在這項工作中，我們提出 QGSumm，一個用於護理記錄摘要的查詢引導式自我監督領域適應架構。我們的做法使用與病患相關的臨床查詢作為指引，在訓練中不依賴參考摘要，就能產生高品質、以病患為中心的摘要。透過專家臨床醫師的自動和手動評估，我們展示了我們的方法與最先進的大語言模型 (LLM) 相比在零次學習和少次學習設定中的優勢。最終，我們的做法為條件式文字摘要提供了新的觀點，專門針對臨床人員的特定興趣量身打造。

##### **MiniGPT-Med: Large Language Model as a General Interface for Radiology Diagnosis**
2407.04106v1 by Asma Alkhaldi, Raneem Alnajim, Layan Alabdullatef, Rawan Alyahya, Jun Chen, Deyao Zhu, Ahmed Alsinan, Mohamed Elhoseiny

Recent advancements in artificial intelligence (AI) have precipitated
significant breakthroughs in healthcare, particularly in refining diagnostic
procedures. However, previous studies have often been constrained to limited
functionalities. This study introduces MiniGPT-Med, a vision-language model
derived from large-scale language models and tailored for medical applications.
MiniGPT-Med demonstrates remarkable versatility across various imaging
modalities, including X-rays, CT scans, and MRIs, enhancing its utility. The
model is capable of performing tasks such as medical report generation, visual
question answering (VQA), and disease identification within medical imagery.
Its integrated processing of both image and textual clinical data markedly
improves diagnostic accuracy. Our empirical assessments confirm MiniGPT-Med's
superior performance in disease grounding, medical report generation, and VQA
benchmarks, representing a significant step towards reducing the gap in
assisting radiology practice. Furthermore, it achieves state-of-the-art
performance on medical report generation, higher than the previous best model
by 19\% accuracy. MiniGPT-Med promises to become a general interface for
radiology diagnoses, enhancing diagnostic efficiency across a wide range of
medical imaging applications.

摘要：隨著人工智慧 (AI) 的最新進展，醫療保健領域出現了顯著的突破，特別是在改善診斷程序方面。然而，先前的研究通常僅限於有限的功能。這項研究引入了 MiniGPT-Med，這是一種源自大規模語言模型且專為醫療應用而設計的視覺語言模型。MiniGPT-Med 在各種影像模式中展現出非凡的多功能性，包括 X 光、電腦斷層掃描和 MRI，進而增強其效用。該模型能夠執行諸如醫療報告生成、視覺問答 (VQA) 和醫療影像中的疾病識別等任務。它將影像和文字臨床資料整合處理，顯著提高了診斷準確性。我們的實證評估證實了 MiniGPT-Med 在疾病基礎、醫療報告生成和 VQA 基準上的優異表現，這代表了縮小協助放射診斷實務差距的重要一步。此外，它在醫療報告生成方面達到了最先進的表現，比先前的最佳模型高出 19% 的準確度。MiniGPT-Med 有望成為放射診斷的通用介面，進而提升各種醫療影像應用中的診斷效率。

##### **Unsupervised Analysis of Alzheimer's Disease Signatures using 3D Deformable Autoencoders**
2407.03863v1 by Mehmet Yigit Avci, Emily Chan, Veronika Zimmer, Daniel Rueckert, Benedikt Wiestler, Julia A. Schnabel, Cosmin I. Bercea

With the increasing incidence of neurodegenerative diseases such as
Alzheimer's Disease (AD), there is a need for further research that enhances
detection and monitoring of the diseases. We present MORPHADE (Morphological
Autoencoders for Alzheimer's Disease Detection), a novel unsupervised learning
approach which uses deformations to allow the analysis of 3D T1-weighted brain
images. To the best of our knowledge, this is the first use of deformations
with deep unsupervised learning to not only detect, but also localize and
assess the severity of structural changes in the brain due to AD. We obtain
markedly higher anomaly scores in clinically important areas of the brain in
subjects with AD compared to healthy controls, showcasing that our method is
able to effectively locate AD-related atrophy. We additionally observe a visual
correlation between the severity of atrophy highlighted in our anomaly maps and
medial temporal lobe atrophy scores evaluated by a clinical expert. Finally,
our method achieves an AUROC of 0.80 in detecting AD, out-performing several
supervised and unsupervised baselines. We believe our framework shows promise
as a tool towards improved understanding, monitoring and detection of AD. To
support further research and application, we have made our code publicly
available at github.com/ci-ber/MORPHADE.

摘要：隨著神經退行性疾病（例如阿茲海默症）的發生率增加，需要進一步的研究來加強對這些疾病的偵測和監控。我們提出 MORPHADE（阿茲海默症偵測的形態自動編碼器），這是一種新穎的無監督學習方法，它使用變形來分析 3D T1 加權腦部影像。據我們所知，這是首次將變形與深度無監督學習結合使用，不僅可以偵測，還可以定位和評估阿茲海默症導致的腦部結構變化嚴重程度。我們在阿茲海默症受試者的腦部臨床上重要區域獲得顯著更高的異常分數，與健康對照組相比，顯示我們的模型能夠有效定位與阿茲海默症相關的萎縮。此外，我們觀察到異常圖中突出的萎縮嚴重程度與臨床專家評估的內側顳葉萎縮分數之間存在視覺相關性。最後，我們的模型在偵測阿茲海默症方面達到了 0.80 的 AUROC，優於多個監督式和無監督式基準。我們相信我們的架構顯示出有望成為改善阿茲海默症理解、監控和偵測的工具。為了支持進一步的研究和應用，我們已在 github.com/ci-ber/MORPHADE 公開我們的程式碼。

##### **CaseGPT: a case reasoning framework based on language models and retrieval-augmented generation**
2407.07913v1 by Rui Yang

This paper presents CaseGPT, an innovative approach that combines Large
Language Models (LLMs) and Retrieval-Augmented Generation (RAG) technology to
enhance case-based reasoning in the healthcare and legal sectors. The system
addresses the challenges of traditional database queries by enabling fuzzy
searches based on imprecise descriptions, thereby improving data searchability
and usability. CaseGPT not only retrieves relevant case data but also generates
insightful suggestions and recommendations based on patterns discerned from
existing case data. This functionality proves especially valuable for tasks
such as medical diagnostics, legal precedent research, and case strategy
formulation. The paper includes an in-depth discussion of the system's
methodology, its performance in both medical and legal domains, and its
potential for future applications. Our experiments demonstrate that CaseGPT
significantly outperforms traditional keyword-based and simple LLM-based
systems in terms of precision, recall, and efficiency.

摘要：本文介紹 CaseGPT，這是一種創新的方法，結合大型語言模型 (LLM) 和檢索增強生成 (RAG) 技術，以增強醫療保健和法律領域的案例推理。此系統透過基於不精確描述啟用模糊搜尋，來解決傳統資料庫查詢的挑戰，進而改善資料的可搜尋性和可用性。CaseGPT 不僅會擷取相關的案例資料，還會根據從現有案例資料中辨識出的模式，產生有見地的建議和建議。此功能對於醫療診斷、法律先例研究和案例策略制定等任務特別有價值。本文包含對系統方法論、其在醫療和法律領域的效能，以及其未來應用潛力的深入探討。我們的實驗證明，CaseGPT 在準確度、召回率和效率方面，明顯優於傳統的基於關鍵字和基於簡單 LLM 的系統。

##### **Integrating Randomness in Large Language Models: A Linear Congruential Generator Approach for Generating Clinically Relevant Content**
2407.03582v1 by Andrew Bouras

Generating diverse, high-quality outputs from language models is crucial for
applications in education and content creation. Achieving true randomness and
avoiding repetition remains a significant challenge. This study uses the Linear
Congruential Generator method for systematic fact selection, combined with
AI-powered content generation. We ensured unique combinations of
gastrointestinal physiology and pathology facts across multiple rounds,
integrating these facts into prompts for GPT-4o to create clinically relevant,
vignette-style outputs. Over 14 rounds, 98 unique outputs were generated,
demonstrating LCG's effectiveness in producing diverse and high-quality
content. This method addresses key issues of randomness and repetition,
enhancing the quality and efficiency of language model-generated content for
various applications.

摘要：在教育和內容創作的應用中，從語言模型產生多樣化、高品質的輸出至關重要。實現真正的隨機性和避免重複仍然是一項重大的挑戰。本研究使用線性同餘產生器方法進行系統性事實選擇，並結合 AI 驅動的內容生成。我們確保了在多輪中胃腸生理和病理事實的獨特組合，將這些事實整合到 GPT-4o 的提示中，以創建具有臨床相關性的短篇故事風格輸出。在 14 輪中，生成了 98 個獨特輸出，證明了 LCG 在產生多樣化和高品質內容方面的有效性。此方法解決了隨機性和重複性的關鍵問題，提高了語言模型生成的內容在各種應用中的品質和效率。

##### **Accelerated Proton Resonance Frequency-based Magnetic Resonance Thermometry by Optimized Deep Learning Method**
2407.03308v1 by Sijie Xu, Shenyan Zong, Chang-Sheng Mei, Guofeng Shen, Yueran Zhao, He Wang

Proton resonance frequency (PRF) based MR thermometry is essential for
focused ultrasound (FUS) thermal ablation therapies. This work aims to enhance
temporal resolution in dynamic MR temperature map reconstruction using an
improved deep learning method. The training-optimized methods and five
classical neural networks were applied on the 2-fold and 4-fold under-sampling
k-space data to reconstruct the temperature maps. The enhanced training modules
included offline/online data augmentations, knowledge distillation, and the
amplitude-phase decoupling loss function. The heating experiments were
performed by a FUS transducer on phantom and ex vivo tissues, respectively.
These data were manually under-sampled to imitate acceleration procedures and
trained in our method to get the reconstruction model. The additional dozen or
so testing datasets were separately obtained for evaluating the real-time
performance and temperature accuracy. Acceleration factors of 1.9 and 3.7 were
found for 2 times and 4 times k-space under-sampling strategies and the
ResUNet-based deep learning reconstruction performed exceptionally well. In
2-fold acceleration scenario, the RMSE of temperature map patches provided the
values of 0.888 degree centigrade and 1.145 degree centigrade on phantom and ex
vivo testing datasets. The DICE value of temperature areas enclosed by 43
degree centigrade isotherm was 0.809, and the Bland-Altman analysis showed a
bias of -0.253 degree centigrade with the apart of plus or minus 2.16 degree
centigrade. In 4 times under-sampling case, these evaluating values decreased
by approximately 10%. This study demonstrates that deep learning-based
reconstruction can significantly enhance the accuracy and efficiency of MR
thermometry for clinical FUS thermal therapies.

摘要：基於質子共振頻率 (PRF) 的 MR 溫度測量對於聚焦超音波 (FUS) 熱消融療法至關重要。這項研究旨在透過改善深度學習方法，提升動態 MR 溫度圖重建中的時間解析度。在 2 倍和 4 倍的 k-space 資料不足採樣中，將訓練最佳化方法和五個傳統神經網路應用於重建溫度圖。增強的訓練模組包括離線/線上資料擴充、知識萃取，以及振幅相位解耦損失函數。加熱實驗分別由 FUS 換能器在模擬人體和離體組織上執行。這些資料經過手動不足採樣以模擬加速程序，並在我們的模型中進行訓練以取得重建模型。額外的十幾個測試資料集則另外取得，用於評估即時效能和溫度準確度。在 2 倍和 4 倍 k-space 不足採樣策略中，發現加速因子為 1.9 和 3.7，而基於 ResUNet 的深度學習重建表現得非常好。在 2 倍加速情境中，溫度圖區塊的 RMSE 在模擬人體和離體測試資料集上提供 0.888 度攝氏和 1.145 度攝氏的值。溫度區域的 DICE 值，以 43 度攝氏等溫線包覆，為 0.809，而 Bland-Altman 分析顯示偏差為 -0.253 度攝氏，加上或減去 2.16 度攝氏。在 4 倍不足採樣案例中，這些評估值減少了大約 10%。這項研究證明，基於深度學習的重建可以大幅提升臨床 FUS 熱療中 MR 溫度測量的準確度和效率。

##### **MVGT: A Multi-view Graph Transformer Based on Spatial Relations for EEG Emotion Recognition**
2407.03131v2 by Yanjie Cui, Xiaohong Liu, Jing Liang, Yamin Fu

Electroencephalography (EEG), a medical imaging technique that captures scalp
electrical activity of brain structures via electrodes, has been widely used in
affective computing. The spatial domain of EEG is rich in affective
information. However, few of the existing studies have simultaneously analyzed
EEG signals from multiple perspectives of geometric and anatomical structures
in spatial domain. In this paper, we propose a multi-view Graph Transformer
(MVGT) based on spatial relations, which integrates information from the
temporal, frequency and spatial domains, including geometric and anatomical
structures, so as to enhance the expressive power of the model comprehensively.
We incorporate the spatial information of EEG channels into the model as
encoding, thereby improving its ability to perceive the spatial structure of
the channels. Meanwhile, experimental results based on publicly available
datasets demonstrate that our proposed model outperforms state-of-the-art
methods in recent years. In addition, the results also show that the MVGT could
extract information from multiple domains and capture inter-channel
relationships in EEG emotion recognition tasks effectively.

摘要：腦電圖（EEG）是一種醫學影像技術，透過電極擷取頭皮上腦部結構的電氣活動，已廣泛用於情感運算中。EEG 的空間域蘊藏豐富的情感資訊。然而，現有的研究鮮少同時從空間域中的幾何結構和解剖結構等多重面向分析 EEG 訊號。本文提出一個基於空間關係的多視圖圖形轉換器（MVGT），它整合了時間、頻率和空間域（包括幾何結構和解剖結構）的資訊，以全面提升模型的表現力。我們將 EEG 通道的空間資訊編碼後納入模型中，進而提升其感知通道空間結構的能力。同時，基於公開資料集的實驗結果顯示，我們提出的模型優於近年來的現有技術。此外，結果也顯示 MVGT 能有效從多重域中擷取資訊，並在 EEG 情緒辨識任務中捕捉到通道間的關係。

##### **Effective Heterogeneous Federated Learning via Efficient Hypernetwork-based Weight Generation**
2407.03086v1 by Yujin Shin, Kichang Lee, Sungmin Lee, You Rim Choi, Hyung-Sin Kim, JeongGil Ko

While federated learning leverages distributed client resources, it faces
challenges due to heterogeneous client capabilities. This necessitates
allocating models suited to clients' resources and careful parameter
aggregation to accommodate this heterogeneity. We propose HypeMeFed, a novel
federated learning framework for supporting client heterogeneity by combining a
multi-exit network architecture with hypernetwork-based model weight
generation. This approach aligns the feature spaces of heterogeneous model
layers and resolves per-layer information disparity during weight aggregation.
To practically realize HypeMeFed, we also propose a low-rank factorization
approach to minimize computation and memory overhead associated with
hypernetworks. Our evaluations on a real-world heterogeneous device testbed
indicate that HypeMeFed enhances accuracy by 5.12% over FedAvg, reduces the
hypernetwork memory requirements by 98.22%, and accelerates its operations by
1.86 times compared to a naive hypernetwork approach. These results demonstrate
HypeMeFed's effectiveness in leveraging and engaging heterogeneous clients for
federated learning.

摘要：雖然聯合學習利用分散式用戶端資源，但由於用戶端能力異質，因此面臨挑戰。這需要分配適合用戶端資源的模型，並仔細參數聚合以容納這種異質性。我們提出 HypeMeFed，一種新的聯合學習框架，通過將多出口網路架構與基於超網路的模型權重生成相結合來支援用戶端異質性。此方法對齊異質模型層的特徵空間，並在權重聚合期間解決逐層資訊差異。為了實際實現 HypeMeFed，我們還提出了一種低秩分解方法，以最大限度地減少與超網路相關的計算和記憶體開銷。我們在真實世界異質設備測試平台上的評估表明，與 FedAvg 相比，HypeMeFed 將準確率提高了 5.12%，將超網路記憶體需求減少了 98.22%，並且與天真的超網路方法相比，其運算速度提高了 1.86 倍。這些結果證明了 HypeMeFed 在利用和吸引異質用戶端進行聯合學習方面的有效性。

##### **Attention Incorporated Network for Sharing Low-rank, Image and K-space Information during MR Image Reconstruction to Achieve Single Breath-hold Cardiac Cine Imaging**
2407.03034v1 by Siying Xu, Kerstin Hammernik, Andreas Lingg, Jens Kuebler, Patrick Krumm, Daniel Rueckert, Sergios Gatidis, Thomas Kuestner

Cardiac Cine Magnetic Resonance Imaging (MRI) provides an accurate assessment
of heart morphology and function in clinical practice. However, MRI requires
long acquisition times, with recent deep learning-based methods showing great
promise to accelerate imaging and enhance reconstruction quality. Existing
networks exhibit some common limitations that constrain further acceleration
possibilities, including single-domain learning, reliance on a single
regularization term, and equal feature contribution. To address these
limitations, we propose to embed information from multiple domains, including
low-rank, image, and k-space, in a novel deep learning network for MRI
reconstruction, which we denote as A-LIKNet. A-LIKNet adopts a parallel-branch
structure, enabling independent learning in the k-space and image domain.
Coupled information sharing layers realize the information exchange between
domains. Furthermore, we introduce attention mechanisms into the network to
assign greater weights to more critical coils or important temporal frames.
Training and testing were conducted on an in-house dataset, including 91
cardiovascular patients and 38 healthy subjects scanned with 2D cardiac Cine
using retrospective undersampling. Additionally, we evaluated A-LIKNet on the
real-time 8x prospectively undersampled data from the OCMR dataset. The results
demonstrate that our proposed A-LIKNet outperforms existing methods and
provides high-quality reconstructions. The network can effectively reconstruct
highly retrospectively undersampled dynamic MR images up to 24x accelerations,
indicating its potential for single breath-hold imaging.

摘要：<paragraph>心臟動態磁共振影像 (MRI) 提供了心臟形態和功能在臨床實務上的精準評估。然而，MRI 需要較長的擷取時間，而最近基於深度學習的方法顯示出極佳的潛力，用於加速影像並增強重建品質。現有的網路展現了一些常見的限制，限制了進一步的加速可能性，包括單一領域學習、依賴單一正則化項，以及相等的特徵貢獻。為了解決這些限制，我們提議將來自多個領域的資訊嵌入一個用於 MRI 重建的新穎深度學習網路中，包括低秩、影像，以及 k 空間，我們將其表示為 A-LIKNet。A-LIKNet 採用平行分支結構，在 k 空間和影像領域中實現獨立學習。耦合資訊共享層實現了領域之間的資訊交換。此外，我們將注意力機制引入網路中，以將較大的權重分配給更重要的線圈或重要的時間幀。訓練和測試是在內部資料集上進行的，其中包括 91 位心血管疾病患者和 38 位健康受試者，他們使用 2D 心臟動態影像進行掃描，並使用回溯式欠採樣。此外，我們在 OCMR 資料集中的即時 8 倍前瞻性欠採樣資料上評估了 A-LIKNet。結果證明，我們提出的 A-LIKNet 優於現有方法，並提供了高品質的重建。該網路可以有效重建高回溯性欠採樣的動態 MR 影像，加速率高達 24 倍，這表示其具有單次閉氣影像的潛力。</paragraph>

##### **SemioLLM: Assessing Large Language Models for Semiological Analysis in Epilepsy Research**
2407.03004v1 by Meghal Dani, Muthu Jeyanthi Prakash, Zeynep Akata, Stefanie Liebe

Large Language Models have shown promising results in their ability to encode
general medical knowledge in standard medical question-answering datasets.
However, their potential application in clinical practice requires evaluation
in domain-specific tasks, where benchmarks are largely missing. In this study
semioLLM, we test the ability of state-of-the-art LLMs (GPT-3.5, GPT-4, Mixtral
8x7B, and Qwen-72chat) to leverage their internal knowledge and reasoning for
epilepsy diagnosis. Specifically, we obtain likelihood estimates linking
unstructured text descriptions of seizures to seizure-generating brain regions,
using an annotated clinical database containing 1269 entries. We evaluate the
LLM's performance, confidence, reasoning, and citation abilities in comparison
to clinical evaluation. Models achieve above-chance classification performance
with prompt engineering significantly improving their outcome, with some models
achieving close-to-clinical performance and reasoning. However, our analyses
also reveal significant pitfalls with several models being overly confident
while showing poor performance, as well as exhibiting citation errors and
hallucinations. In summary, our work provides the first extensive benchmark
comparing current SOTA LLMs in the medical domain of epilepsy and highlights
their ability to leverage unstructured texts from patients' medical history to
aid diagnostic processes in health care.

摘要：大型語言模型在標準醫療問答資料集中編碼一般醫療知識的能力方面已展現出可觀的成果。然而，它們在臨床實務中的潛在應用需要在特定領域任務中進行評估，而基準量測在很大程度上仍付之闕如。在本研究 semioLLM 中，我們測試了最先進的 LLM（GPT-3.5、GPT-4、Mixtral 8x7B 和 Qwen-72chat）利用其內部知識和推理進行癲癇診斷的能力。具體來說，我們取得了連結癲癇發作非結構化文字描述至癲癇發作生成腦區的可能性估計值，使用包含 1269 個條目的註解式臨床資料庫。我們評估了 LLM 的表現、信心、推理和引述能力，並與臨床評估進行比較。模型達到了高於機率的分類表現，提示工程顯著改善了其結果，有些模型達到了接近臨床表現和推理。然而，我們的分析也揭露了幾個模型的重大缺陷，它們過度自信，同時表現不佳，並出現引述錯誤和幻覺。總之，我們的研究提供了第一個廣泛的基準，比較了癲癇醫療領域中目前的 SOTA LLM，並突出了它們利用患者病史中的非結構化文字來協助醫療保健中的診斷程序的能力。

##### **MedPix 2.0: A Comprehensive Multimodal Biomedical Dataset for Advanced AI Applications**
2407.02994v1 by Irene Siragusa, Salvatore Contino, Massimo La Ciura, Rosario Alicata, Roberto Pirrone

The increasing interest in developing Artificial Intelligence applications in
the medical domain, suffers from the lack of high-quality dataset, mainly due
to privacy-related issues. Moreover, the recent rising of Multimodal Large
Language Models (MLLM) leads to a need for multimodal medical datasets, where
clinical reports and findings are attached to the corresponding CT or MR scans.
This paper illustrates the entire workflow for building the data set MedPix
2.0. Starting from the well-known multimodal dataset
MedPix\textsuperscript{\textregistered}, mainly used by physicians, nurses and
healthcare students for Continuing Medical Education purposes, a semi-automatic
pipeline was developed to extract visual and textual data followed by a manual
curing procedure where noisy samples were removed, thus creating a MongoDB
database. Along with the dataset, we developed a GUI aimed at navigating
efficiently the MongoDB instance, and obtaining the raw data that can be easily
used for training and/or fine-tuning MLLMs. To enforce this point, we also
propose a CLIP-based model trained on MedPix 2.0 for scan classification tasks.

摘要：隨著在醫療領域開發人工智慧應用程式的興趣日益增加，但由於隱私相關問題，導致缺乏高品質的資料集。此外，多模態大型語言模型 (MLLM) 的興起，需要建立多模態醫療資料集，其中臨床報告和發現會附加到對應的電腦斷層掃描或核磁共振掃描。本文說明建立資料集 MedPix 2.0 的完整工作流程。從廣為人知的由醫師、護理師和醫療保健學生主要用於持續醫療教育目的的多模態資料集 MedPix\textsuperscript{\textregistered} 開始，開發了一個半自動化管道來萃取視覺和文字資料，接著進行手動清理程序移除雜訊樣本，進而建立一個 MongoDB 資料庫。隨著資料集，我們開發了一個 GUI，旨在有效率地瀏覽 MongoDB 執行個體，並取得可用於訓練和/或微調 MLLM 的原始資料。為了強調這一點，我們也提出一個在 MedPix 2.0 上訓練的基於 CLIP 的模型，用於掃描分類任務。

##### **Membership Inference Attacks Against Time-Series Models**
2407.02870v1 by Noam Koren, Abigail Goldsteen, Ariel Farkash, Guy Amit

Analyzing time-series data that may contain personal information,
particularly in the medical field, presents serious privacy concerns. Sensitive
health data from patients is often used to train machine-learning models for
diagnostics and ongoing care. Assessing the privacy risk of such models is
crucial to making knowledgeable decisions on whether to use a model in
production, share it with third parties, or deploy it in patients homes.
Membership Inference Attacks (MIA) are a key method for this kind of
evaluation, however time-series prediction models have not been thoroughly
studied in this context. We explore existing MIA techniques on time-series
models, and introduce new features, focusing on the seasonality and trend
components of the data. Seasonality is estimated using a multivariate Fourier
transform, and a low-degree polynomial is used to approximate trends. We
applied these techniques to various types of time-series models, using datasets
from the health domain. Our results demonstrate that these new features enhance
the effectiveness of MIAs in identifying membership, improving the
understanding of privacy risks in medical data applications.

摘要：分析可能包含个人信息的時間序列資料，特別是在醫療領域，會引發嚴重的隱私問題。病患的敏感健康資料經常被用於訓練機器學習模型，以進行診斷和持續照護。評估此類模型的隱私風險，對於在生產中使用模型、與第三方分享，或在病患家中部署模型時做出明智的決定至關重要。成員推論攻擊 (MIA) 是進行此類評估的一種關鍵方法，然而，在此背景下尚未徹底研究時序預測模型。我們探討了時序模型上現有的 MIA 技術，並引入了新的功能，重點關注資料的季節性和趨勢組成。季節性使用多變數傅立葉轉換來估計，低次多項式用於近似趨勢。我們將這些技術應用於各種類型的時序模型，使用來自健康領域的資料集。我們的結果表明，這些新功能增強了 MIA 在識別成員資格方面的效能，進而提升了對醫療資料應用中隱私風險的理解。

##### **Effect of a Process Mining based Pre-processing Step in Prediction of the Critical Health Outcomes**
2407.02821v1 by Negin Ashrafi, Armin Abdollahi, Greg Placencia, Maryam Pishgar

Predicting critical health outcomes such as patient mortality and hospital
readmission is essential for improving survivability. However, healthcare
datasets have many concurrences that create complexities, leading to poor
predictions. Consequently, pre-processing the data is crucial to improve its
quality. In this study, we use an existing pre-processing algorithm,
concatenation, to improve data quality by decreasing the complexity of
datasets. Sixteen healthcare datasets were extracted from two databases - MIMIC
III and University of Illinois Hospital - converted to the event logs, they
were then fed into the concatenation algorithm. The pre-processed event logs
were then fed to the Split Miner (SM) algorithm to produce a process model.
Process model quality was evaluated before and after concatenation using the
following metrics: fitness, precision, F-Measure, and complexity. The
pre-processed event logs were also used as inputs to the Decay Replay Mining
(DREAM) algorithm to predict critical outcomes. We compared predicted results
before and after applying the concatenation algorithm using Area Under the
Curve (AUC) and Confidence Intervals (CI). Results indicated that the
concatenation algorithm improved the quality of the process models and
predictions of the critical health outcomes.

摘要：預測病患死亡率和醫院再入院等重大的健康結果，對於提升存活率至關重要。然而，醫療保健資料集有許多同時發生的事件，會造成複雜性，導致預測不佳。因此，預先處理資料對於提升資料品質至關重要。在本研究中，我們使用現有的預先處理演算法，連接，藉由降低資料集的複雜性來提升資料品質。從兩個資料庫中萃取出十六個醫療保健資料集 - MIMIC III 和伊利諾大學醫院 - 轉換成事件記錄，然後將其輸入連接演算法。接著將預先處理的事件記錄輸入 Split Miner (SM) 演算法，以產生流程模型。使用以下指標評估連接前後的流程模型品質：適用性、精確度、F-量測和複雜性。預先處理的事件記錄也用作衰減重播探勘 (DREAM) 演算法的輸入，以預測重大的結果。我們使用曲線下面積 (AUC) 和信心區間 (CI) 比較套用連接演算法前後的預測結果。結果顯示連接演算法提升了流程模型的品質和對重大健康結果的預測。

##### **MedVH: Towards Systematic Evaluation of Hallucination for Large Vision Language Models in the Medical Context**
2407.02730v1 by Zishan Gu, Changchang Yin, Fenglin Liu, Ping Zhang

Large Vision Language Models (LVLMs) have recently achieved superior
performance in various tasks on natural image and text data, which inspires a
large amount of studies for LVLMs fine-tuning and training. Despite their
advancements, there has been scant research on the robustness of these models
against hallucination when fine-tuned on smaller datasets. In this study, we
introduce a new benchmark dataset, the Medical Visual Hallucination Test
(MedVH), to evaluate the hallucination of domain-specific LVLMs. MedVH
comprises five tasks to evaluate hallucinations in LVLMs within the medical
context, which includes tasks for comprehensive understanding of textual and
visual input, as well as long textual response generation. Our extensive
experiments with both general and medical LVLMs reveal that, although medical
LVLMs demonstrate promising performance on standard medical tasks, they are
particularly susceptible to hallucinations, often more so than the general
models, raising significant concerns about the reliability of these
domain-specific models. For medical LVLMs to be truly valuable in real-world
applications, they must not only accurately integrate medical knowledge but
also maintain robust reasoning abilities to prevent hallucination. Our work
paves the way for future evaluations of these studies.

摘要：大型視覺語言模型 (LVLMs) 最近在自然影像和文字資料的各種任務中取得了卓越的表現，這激勵了大量的研究進行 LVLMs 的微調和訓練。儘管它們進步了，但對於在較小的資料集上微調時，這些模型對幻覺的魯棒性卻鮮有研究。在這項研究中，我們引入了新的基準資料集，即醫學視覺幻覺測試 (MedVH)，以評估特定領域 LVLMs 的幻覺。MedVH 包含五項任務，用於評估醫學背景下 LVLMs 中的幻覺，其中包括全面理解文字和視覺輸入的任務，以及長文字回應生成。我們對一般和醫學 LVLMs 進行的廣泛實驗表明，儘管醫學 LVLMs 在標準醫學任務上表現出令人滿意的表現，但它們特別容易產生幻覺，通常比一般模型更容易產生幻覺，這引起了對這些特定領域模型的可靠性的重大疑慮。為了讓醫學 LVLMs 在現實世界的應用中真正有價值，它們不僅必須準確整合醫學知識，還必須具備強大的推理能力以防止幻覺。我們的研究為未來對這些研究的評估鋪平了道路。

##### **D-Rax: Domain-specific Radiologic assistant leveraging multi-modal data and eXpert model predictions**
2407.02604v1 by Hareem Nisar, Syed Muhammad Anwar, Zhifan Jiang, Abhijeet Parida, Vishwesh Nath, Holger R. Roth, Marius George Linguraru

Large vision language models (VLMs) have progressed incredibly from research
to applicability for general-purpose use cases. LLaVA-Med, a pioneering large
language and vision assistant for biomedicine, can perform multi-modal
biomedical image and data analysis to provide a natural language interface for
radiologists. While it is highly generalizable and works with multi-modal data,
it is currently limited by well-known challenges that exist in the large
language model space. Hallucinations and imprecision in responses can lead to
misdiagnosis which currently hinder the clinical adaptability of VLMs. To
create precise, user-friendly models in healthcare, we propose D-Rax -- a
domain-specific, conversational, radiologic assistance tool that can be used to
gain insights about a particular radiologic image. In this study, we enhance
the conversational analysis of chest X-ray (CXR) images to support radiological
reporting, offering comprehensive insights from medical imaging and aiding in
the formulation of accurate diagnosis. D-Rax is achieved by fine-tuning the
LLaVA-Med architecture on our curated enhanced instruction-following data,
comprising of images, instructions, as well as disease diagnosis and
demographic predictions derived from MIMIC-CXR imaging data, CXR-related visual
question answer (VQA) pairs, and predictive outcomes from multiple expert AI
models. We observe statistically significant improvement in responses when
evaluated for both open and close-ended conversations. Leveraging the power of
state-of-the-art diagnostic models combined with VLMs, D-Rax empowers
clinicians to interact with medical images using natural language, which could
potentially streamline their decision-making process, enhance diagnostic
accuracy, and conserve their time.

摘要：大型視覺語言模型（VLM）已從研究進展到可適用於一般用途案例。LLaVA-Med 是一個開創性的生物醫學大型語言和視覺助理，可以執行多模態生物醫學影像和資料分析，為放射科醫師提供自然語言介面。儘管它具有高度的概括性，並且適用於多模態資料，但目前受到大型語言模型空間中眾所周知挑戰的限制。回應中的幻覺和不精確可能會導致誤診，這會阻礙 VLM 的臨床適應性。為了在醫療保健中建立精確、使用者友善的模型，我們提出了 D-Rax——一種特定於領域的對話式放射協助工具，可用於深入了解特定放射影像。在這項研究中，我們增強了胸部 X 光（CXR）影像的對話式分析，以支援放射報告，從醫學影像中提供全面的見解，並協助制定準確的診斷。D-Rax 是透過微調 LLaVA-Med 架構在我們整理的增強式指令遵循資料上實現的，包括影像、指令，以及從 MIMIC-CXR 影像資料、CXR 相關視覺問答（VQA）配對和多個專家 AI 模型的預測結果中得出的疾病診斷和人口統計預測。我們觀察到，在針對開放式和封閉式對話進行評估時，回應有顯著的統計改善。透過結合最先進的診斷模型和 VLM 的力量，D-Rax 使臨床醫生能夠使用自然語言與醫學影像互動，這可能會簡化他們的決策過程、提高診斷準確性並節省他們的時間。

##### **MMedAgent: Learning to Use Medical Tools with Multi-modal Agent**
2407.02483v1 by Binxu Li, Tiankai Yan, Yuanting Pan, Zhe Xu, Jie Luo, Ruiyang Ji, Shilong Liu, Haoyu Dong, Zihao Lin, Yixin Wang

Multi-Modal Large Language Models (MLLMs), despite being successful, exhibit
limited generality and often fall short when compared to specialized models.
Recently, LLM-based agents have been developed to address these challenges by
selecting appropriate specialized models as tools based on user inputs.
However, such advancements have not been extensively explored within the
medical domain. To bridge this gap, this paper introduces the first agent
explicitly designed for the medical field, named \textbf{M}ulti-modal
\textbf{Med}ical \textbf{Agent} (MMedAgent). We curate an instruction-tuning
dataset comprising six medical tools solving seven tasks, enabling the agent to
choose the most suitable tools for a given task. Comprehensive experiments
demonstrate that MMedAgent achieves superior performance across a variety of
medical tasks compared to state-of-the-art open-source methods and even the
closed-source model, GPT-4o. Furthermore, MMedAgent exhibits efficiency in
updating and integrating new medical tools.

摘要：儘管多模態大型語言模型 (MLLM) 成功，但其普遍性有限，與專用模型相比時常有所不足。
最近，基於 LLM 的代理已被開發出來，以透過根據使用者輸入選擇適當的專用模型作為工具來解決這些挑戰。
然而，此類進展尚未在醫療領域中廣泛探討。為了彌補此差距，本文介紹了第一個專門為醫療領域設計的代理，名為**M**ulti-modal **Med**ical **Agent** (MMedAgent)。我們整理了一個由六種解決七項任務的醫療工具組成的指令調整資料集，讓代理能夠為特定任務選擇最合適的工具。全面的實驗證明，與最先進的開源方法，甚至閉源模型 GPT-4o 相比，MMedAgent 在各種醫療任務中都取得了優異的表現。此外，MMedAgent 在更新和整合新的醫療工具方面展現出效率。

##### **CALICO: Confident Active Learning with Integrated Calibration**
2407.02335v1 by Lorenzo S. Querol, Hajime Nagahara, Hideaki Hayashi

The growing use of deep learning in safety-critical applications, such as
medical imaging, has raised concerns about limited labeled data, where this
demand is amplified as model complexity increases, posing hurdles for domain
experts to annotate data. In response to this, active learning (AL) is used to
efficiently train models with limited annotation costs. In the context of deep
neural networks (DNNs), AL often uses confidence or probability outputs as a
score for selecting the most informative samples. However, modern DNNs exhibit
unreliable confidence outputs, making calibration essential. We propose an AL
framework that self-calibrates the confidence used for sample selection during
the training process, referred to as Confident Active Learning with Integrated
CalibratiOn (CALICO). CALICO incorporates the joint training of a classifier
and an energy-based model, instead of the standard softmax-based classifier.
This approach allows for simultaneous estimation of the input data distribution
and the class probabilities during training, improving calibration without
needing an additional labeled dataset. Experimental results showcase improved
classification performance compared to a softmax-based classifier with fewer
labeled samples. Furthermore, the calibration stability of the model is
observed to depend on the prior class distribution of the data.

摘要：深度學習在安全關鍵應用中使用日益廣泛，例如醫學影像，這引發了對標籤數據有限的擔憂，隨著模型複雜性的增加，這種需求會被放大，這對領域專家註解數據構成了障礙。為了應對這一問題，主動學習 (AL) 被用於以有限的註解成本有效地訓練模型。在深度神經網路 (DNN) 的背景下，AL 經常使用置信度或機率輸出作為選擇最有資訊性的樣本的分數。然而，現代 DNN 表現出不可靠的置信度輸出，這使得校準至關重要。我們提出了一個 AL 框架，它會在訓練過程中自行校準用於樣本選擇的置信度，稱為具有整合校準的自信主動學習 (CALICO)。CALICO 結合了分類器和基於能量的模型的聯合訓練，而不是標準的基於 softmax 的分類器。這種方法允許在訓練期間同時估計輸入數據分佈和類別機率，從而改進校準，而無需額外的標籤數據集。實驗結果表明，與基於 softmax 的分類器相比，在標籤樣本較少的情況下，分類性能得到了改善。此外，觀察到模型的校準穩定性取決於數據的先驗類別分佈。

##### **A Refreshed Similarity-based Upsampler for Direct High-Ratio Feature Upsampling**
2407.02283v1 by Minghao Zhou, Hong Wang, Yefeng Zheng, Deyu Meng

Feature upsampling is a fundamental and indispensable ingredient of almost
all current network structures for image segmentation tasks. Recently, a
popular similarity-based feature upsampling pipeline has been proposed, which
utilizes a high-resolution feature as guidance to help upsample the
low-resolution deep feature based on their local similarity. Albeit achieving
promising performance, this pipeline has specific limitations: 1) HR query and
LR key features are not well aligned; 2) the similarity between query-key
features is computed based on the fixed inner product form; 3) neighbor
selection is coarsely operated on LR features, resulting in mosaic artifacts.
These shortcomings make the existing methods along this pipeline primarily
applicable to hierarchical network architectures with iterative features as
guidance and they are not readily extended to a broader range of structures,
especially for a direct high-ratio upsampling. Against the issues, we
meticulously optimize every methodological design. Specifically, we firstly
propose an explicitly controllable query-key feature alignment from both
semantic-aware and detail-aware perspectives, and then construct a
parameterized paired central difference convolution block for flexibly
calculating the similarity between the well-aligned query-key features.
Besides, we develop a fine-grained neighbor selection strategy on HR features,
which is simple yet effective for alleviating mosaic artifacts. Based on these
careful designs, we systematically construct a refreshed similarity-based
feature upsampling framework named ReSFU. Extensive experiments substantiate
that our proposed ReSFU is finely applicable to various types of architectures
in a direct high-ratio upsampling manner, and consistently achieves
satisfactory performance on different segmentation applications, showing
superior generality and ease of deployment.

摘要：特徵上採樣是目前幾乎所有用於影像分割任務的網路結構中不可或缺的基本要素。最近，有人提出了一種基於相似度的特徵上採樣管道，它利用高解析度特徵作為指引，根據其局部相似度幫助上採樣低解析度深度特徵。儘管取得了有希望的效能，但此管道有特定的限制：1）HR 查詢和 LR 關鍵特徵未對齊；2）查詢鍵特徵之間的相似度是根據固定的內積形式計算的；3）鄰居選擇是粗略地對 LR 特徵進行操作，導致馬賽克偽影。這些缺點使得沿著此管道的現有方法主要適用於具有迭代特徵作為指引的分層網路架構，並且它們不容易擴充套件到更廣泛的結構，特別是對於直接的高比率上採樣。針對這些問題，我們仔細優化了每一個方法論設計。具體來說，我們首先提出了從語義感知和細節感知的角度進行明確可控的查詢鍵特徵對齊，然後構建一個參數化的配對中心差分卷積塊，以靈活地計算對齊良好的查詢鍵特徵之間的相似度。此外，我們在 HR 特徵上開發了一個細粒度的鄰居選擇策略，它對於減輕馬賽克偽影既簡單又有效。根據這些仔細的設計，我們系統地構建了一個名為 ReSFU 的更新的基於相似度的特徵上採樣框架。大量的實驗證實，我們提出的 ReSFU 精細地適用於各種類型的架構，採用直接的高比率上採樣方式，並且在不同的分割應用中始終如一地取得令人滿意的效能，展現出優越的通用性和易於部署性。

##### **FedIA: Federated Medical Image Segmentation with Heterogeneous Annotation Completeness**
2407.02280v2 by Yangyang Xiang, Nannan Wu, Li Yu, Xin Yang, Kwang-Ting Cheng, Zengqiang Yan

Federated learning has emerged as a compelling paradigm for medical image
segmentation, particularly in light of increasing privacy concerns. However,
most of the existing research relies on relatively stringent assumptions
regarding the uniformity and completeness of annotations across clients.
Contrary to this, this paper highlights a prevalent challenge in medical
practice: incomplete annotations. Such annotations can introduce incorrectly
labeled pixels, potentially undermining the performance of neural networks in
supervised learning. To tackle this issue, we introduce a novel solution, named
FedIA. Our insight is to conceptualize incomplete annotations as noisy data
(i.e., low-quality data), with a focus on mitigating their adverse effects. We
begin by evaluating the completeness of annotations at the client level using a
designed indicator. Subsequently, we enhance the influence of clients with more
comprehensive annotations and implement corrections for incomplete ones,
thereby ensuring that models are trained on accurate data. Our method's
effectiveness is validated through its superior performance on two extensively
used medical image segmentation datasets, outperforming existing solutions. The
code is available at https://github.com/HUSTxyy/FedIA.

摘要：联邦学习已成为医学图像分割中一种引人注目的范例，尤其是在隐私问题日益受到关注的情况下。然而，现有的大多数研究都依赖于关于跨客户端注释一致性和完整性的相对严格的假设。与此相反，本文重点介绍了医学实践中普遍存在的挑战：不完整的注释。此类注释可能会引入错误标记的像素，从而可能损害神经网络在监督学习中的性能。为了解决这个问题，我们引入了一种名为 FedIA 的新颖解决方案。我们的见解是将不完整的注释概念化为噪声数据（即低质量数据），重点在于减轻其不利影响。我们首先使用设计的指标评估客户端级别的注释完整性。随后，我们增强了具有更全面注释的客户端的影响力，并对不完整的注释实施了更正，从而确保模型在准确的数据上进行训练。我们方法的有效性通过其在两个广泛使用的医学图像分割数据集上的卓越性能得到验证，优于现有的解决方案。代码可在 https://github.com/HUSTxyy/FedIA 获得。

##### **Generative Monoculture in Large Language Models**
2407.02209v1 by Fan Wu, Emily Black, Varun Chandrasekaran

We introduce {\em generative monoculture}, a behavior observed in large
language models (LLMs) characterized by a significant narrowing of model output
diversity relative to available training data for a given task: for example,
generating only positive book reviews for books with a mixed reception. While
in some cases, generative monoculture enhances performance (e.g., LLMs more
often produce efficient code), the dangers are exacerbated in others (e.g.,
LLMs refuse to share diverse opinions). As LLMs are increasingly used in
high-impact settings such as education and web search, careful maintenance of
LLM output diversity is essential to ensure a variety of facts and perspectives
are preserved over time. We experimentally demonstrate the prevalence of
generative monoculture through analysis of book review and code generation
tasks, and find that simple countermeasures such as altering sampling or
prompting strategies are insufficient to mitigate the behavior. Moreover, our
results suggest that the root causes of generative monoculture are likely
embedded within the LLM's alignment processes, suggesting a need for developing
fine-tuning paradigms that preserve or promote diversity.

摘要：<paragraph>我們介紹了「生成單一文化」，這是一種在大型語言模型 (LLM) 中觀察到的行為，其特徵是模型輸出多樣性相對於給定任務的可用訓練資料顯著變窄：例如，只為評價褒貶不一的書籍生成正面的書評。雖然在某些情況下，生成單一文化會增強效能（例如，LLM 更常產生高效的程式碼），但其危險性在其他情況下會加劇（例如，LLM 拒絕分享不同的意見）。由於 LLM 愈來愈多地用於教育和網路搜尋等高影響力的環境中，仔細維護 LLM 輸出的多樣性對於確保隨著時間推移，各種事實和觀點都能被保留下來至關重要。我們透過分析書評和程式碼生成任務，以實驗方式證明了生成單一文化的普遍性，並發現簡單的對策，例如改變抽樣或提示策略，不足以減輕這種行為。此外，我們的結果表明，生成單一文化的根本原因可能存在於 LLM 的比對過程中，這表明需要開發能保留或促進多樣性的微調範例。</paragraph>

##### **Abstract Dialectical Frameworks are Boolean Networks (full version)**
2407.02055v1 by Jesse Heyninck, Matthias Knorr, João Leite

Dialectical frameworks are a unifying model of formal argumentation, where
argumentative relations between arguments are represented by assigning
acceptance conditions to atomic arguments. Their generality allow them to cover
a number of different approaches with varying forms of representing the
argumentation structure. Boolean regulatory networks are used to model the
dynamics of complex biological processes, taking into account the interactions
of biological compounds, such as proteins or genes. These models have proven
highly useful for comprehending such biological processes, allowing to
reproduce known behaviour and testing new hypotheses and predictions in silico,
for example in the context of new medical treatments. While both these
approaches stem from entirely different communities, it turns out that there
are striking similarities in their appearence. In this paper, we study the
relation between these two formalisms revealing their communalities as well as
their differences, and introducing a correspondence that allows to establish
novel results for the individual formalisms.

摘要：辯證框架是形式論證的統一模型，其中論證之間的論證關係是透過指派接受條件給原子論證來表示。它們的普遍性允許它們涵蓋許多不同的方法，並以不同的形式表示論證結構。布林法規網路用於模擬複雜生物過程的動態，考量生物化合物（例如蛋白質或基因）的交互作用。這些模型已被證明對於理解此類生物過程非常有用，允許複製已知的行為並在電腦模擬中測試新的假設和預測，例如在新的醫療治療的背景下。儘管這兩種方法完全來自不同的社群，但事實證明它們的外觀有驚人的相似性。在本文中，我們研究這兩種形式主義之間的關係，揭示它們的共性以及它們的差異，並引入一種對應關係，允許為個別形式主義建立新的結果。

##### **A Method to Facilitate Membership Inference Attacks in Deep Learning Models**
2407.01919v1 by Zitao Chen, Karthik Pattabiraman

Modern machine learning (ML) ecosystems offer a surging number of ML
frameworks and code repositories that can greatly facilitate the development of
ML models. Today, even ordinary data holders who are not ML experts can apply
off-the-shelf codebase to build high-performance ML models on their data, many
of which are sensitive in nature (e.g., clinical records).
  In this work, we consider a malicious ML provider who supplies model-training
code to the data holders, does not have access to the training process, and has
only black-box query access to the resulting model. In this setting, we
demonstrate a new form of membership inference attack that is strictly more
powerful than prior art. Our attack empowers the adversary to reliably
de-identify all the training samples (average >99% attack TPR@0.1% FPR), and
the compromised models still maintain competitive performance as their
uncorrupted counterparts (average <1% accuracy drop). Moreover, we show that
the poisoned models can effectively disguise the amplified membership leakage
under common membership privacy auditing, which can only be revealed by a set
of secret samples known by the adversary.
  Overall, our study not only points to the worst-case membership privacy
leakage, but also unveils a common pitfall underlying existing privacy auditing
methods, which calls for future efforts to rethink the current practice of
auditing membership privacy in machine learning models.

摘要：現代機器學習 (ML) 生態系統提供了大量的 ML 框架和程式碼儲存庫，可以極大地促進 ML 模型的開發。如今，即使不是 ML 專家的普通資料持有者也可以套用現成的程式碼庫，根據其資料建立高性能 ML 模型，其中許多資料本質上很敏感（例如：臨床紀錄）。
  在這項工作中，我們考慮了一個惡意的 ML 提供者，他向資料持有者提供模型訓練程式碼，無法存取訓練程序，而且只能透過黑盒子查詢存取產生的模型。在此設定中，我們展示了一種新的成員推論攻擊形式，它比先前的技術更強大。我們的攻擊讓對手能夠可靠地取消識別所有訓練範例（平均 >99% 攻擊 TPR@0.1% FPR），而且受損的模型仍然保持與未受損的模型一樣的競爭力（平均 <1% 準確度下降）。此外，我們展示了中毒的模型可以有效地隱藏在常見成員隱私稽核下的擴增成員洩漏，這只能由對手知道的秘密範例集揭露。
  總的來說，我們的研究不僅指出最壞情況的成員隱私洩漏，還揭示了現有隱私稽核方法中的一個常見陷阱，這需要未來的努力來重新思考目前在機器學習模型中稽核成員隱私的做法。

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

摘要：床邊超音波 (POCUS) 是臨床醫師在患者床邊進行和解讀超音波掃描的實務。然而，解讀這些影像所需的專業知識相當可觀，而且在緊急情況下可能並非隨時具備。這種現實情況使得機器學習分類器等演算法對於加強人類決策變得極為有價值。POCUS 裝置正以合理成本推出，尺寸為手機大小。將 POCUS 裝置轉變為救生工具的挑戰在於，解讀超音波影像需要專門訓練和經驗。不幸的是，取得正向訓練影像的困難度代表著建置有效率且準確的分類器的一大障礙。因此，我們嘗試探討的問題是如何探索策略，以提高使用稀疏資料訓練的分類器的準確度。我們假設使用少數資料實例進行訓練可能不足以讓分類器概括，導致它們過度擬合。我們的做法使用可解釋 AI 增強方法，以協助演算法從較少的資料中學習更多，並潛在協助分類器更好地概括。

##### **Optimized Learning for X-Ray Image Classification for Multi-Class Disease Diagnoses with Accelerated Computing Strategies**
2407.01705v1 by Sebastian A. Cruz Romero, Ivanelyz Rivera de Jesus, Dariana J. Troche Quinones, Wilson Rivera Gallego

X-ray image-based disease diagnosis lies in ensuring the precision of
identifying afflictions within the sample, a task fraught with challenges
stemming from the occurrence of false positives and false negatives. False
positives introduce the risk of erroneously identifying non-existent
conditions, leading to misdiagnosis and a decline in patient care quality.
Conversely, false negatives pose the threat of overlooking genuine
abnormalities, potentially causing delays in treatment and interventions,
thereby resulting in adverse patient outcomes. The urgency to overcome these
challenges compels ongoing efforts to elevate the precision and reliability of
X-ray image analysis algorithms within the computational framework. This study
introduces modified pre-trained ResNet models tailored for multi-class disease
diagnosis of X-ray images, incorporating advanced optimization strategies to
reduce the execution runtime of training and inference tasks. The primary
objective is to achieve tangible performance improvements through accelerated
implementations of PyTorch, CUDA, Mixed- Precision Training, and Learning Rate
Scheduler. While outcomes demonstrate substantial improvements in execution
runtimes between normal training and CUDA-accelerated training, negligible
differences emerge between various training optimization modalities. This
research marks a significant advancement in optimizing computational approaches
to reduce training execution time for larger models. Additionally, we explore
the potential of effective parallel data processing using MPI4Py for the
distribution of gradient descent optimization across multiple nodes and
leverage multiprocessing to expedite data preprocessing for larger datasets.

摘要：X 光影像疾病診斷在於確保識別樣本中疾病的精確性，這項任務充滿了挑戰，源自於假陽性和假陰性的發生。假陽性會帶來錯誤識別不存在的疾病的風險，導致誤診和患者照護品質下降。相反地，假陰性會帶來忽略真正異常的威脅，可能會導致治療和介入延誤，從而導致患者預後不良。克服這些挑戰的迫切性促使持續努力提升計算架構中 X 光影像分析演算法的精確度和可靠性。本研究引入了針對 X 光影像的多類疾病診斷量身打造的修改後預先訓練的 ResNet 模型，並結合先進的最佳化策略以減少訓練和推論任務的執行執行時間。主要目標是透過加速實作 PyTorch、CUDA、混合精度訓練和學習率排程器，來達成具體的效能提升。雖然結果顯示正常訓練和 CUDA 加速訓練之間的執行執行時間有大幅改善，但各種訓練最佳化模式之間的差異可以忽略不計。這項研究標誌著最佳化計算方法以減少較大型模型訓練執行時間的重大進展。此外，我們探索使用 MPI4Py 進行有效平行資料處理的可能性，以在多個節點上進行梯度下降最佳化，並利用多處理來加速較大型資料集的資料前處理。

##### **Deep Dive into MRI: Exploring Deep Learning Applications in 0.55T and 7T MRI**
2407.01318v1 by Ana Carolina Alves, André Ferreira, Behrus Puladi, Jan Egger, Victor Alves

The development of magnetic resonance imaging (MRI) for medical imaging has
provided a leap forward in diagnosis, providing a safe, non-invasive
alternative to techniques involving ionising radiation exposure for diagnostic
purposes. It was described by Block and Purcel in 1946, and it was not until
1980 that the first clinical application of MRI became available. Since that
time the MRI has gone through many advances and has altered the way diagnosing
procedures are performed. Due to its ability to improve constantly, MRI has
become a commonly used practice among several specialisations in medicine.
Particularly starting 0.55T and 7T MRI technologies have pointed out enhanced
preservation of image detail and advanced tissue characterisation. This review
examines the integration of deep learning (DL) techniques into these MRI
modalities, disseminating and exploring the study applications. It highlights
how DL contributes to 0.55T and 7T MRI data, showcasing the potential of DL in
improving and refining these technologies. The review ends with a brief
overview of how MRI technology will evolve in the coming years.

摘要：磁共振成像 (MRI) 在医学影像上的發展，為診斷技術帶來重大進展，提供一種安全、非侵入性的替代方案，以取代使用電離輻射進行診斷的技術。此技術由布洛克與珀塞爾於 1946 年提出，直到 1980 年，MRI 才首次應用於臨床。自那時起，MRI 經歷了許多進步，並改變了診斷程序的執行方式。由於 MRI 能持續改進，因此已成為醫學中多種專科的常用技術。特別是從 0.55T 和 7T MRI 技術開始，已指出增強影像細節的保存和進階組織表徵。本篇評論探討深度學習 (DL) 技術整合到這些 MRI 模式中，傳播並探討研究應用。它強調 DL 如何貢獻於 0.55T 和 7T MRI 資料，展示 DL 在改善和精進這些技術的潛力。本評論最後簡要概述 MRI 技術在未來幾年的發展方式。

##### **MIRAI: Evaluating LLM Agents for Event Forecasting**
2407.01231v1 by Chenchen Ye, Ziniu Hu, Yihe Deng, Zijie Huang, Mingyu Derek Ma, Yanqiao Zhu, Wei Wang

Recent advancements in Large Language Models (LLMs) have empowered LLM agents
to autonomously collect world information, over which to conduct reasoning to
solve complex problems. Given this capability, increasing interests have been
put into employing LLM agents for predicting international events, which can
influence decision-making and shape policy development on an international
scale. Despite such a growing interest, there is a lack of a rigorous benchmark
of LLM agents' forecasting capability and reliability. To address this gap, we
introduce MIRAI, a novel benchmark designed to systematically evaluate LLM
agents as temporal forecasters in the context of international events. Our
benchmark features an agentic environment with tools for accessing an extensive
database of historical, structured events and textual news articles. We refine
the GDELT event database with careful cleaning and parsing to curate a series
of relational prediction tasks with varying forecasting horizons, assessing LLM
agents' abilities from short-term to long-term forecasting. We further
implement APIs to enable LLM agents to utilize different tools via a code-based
interface. In summary, MIRAI comprehensively evaluates the agents' capabilities
in three dimensions: 1) autonomously source and integrate critical information
from large global databases; 2) write codes using domain-specific APIs and
libraries for tool-use; and 3) jointly reason over historical knowledge from
diverse formats and time to accurately predict future events. Through
comprehensive benchmarking, we aim to establish a reliable framework for
assessing the capabilities of LLM agents in forecasting international events,
thereby contributing to the development of more accurate and trustworthy models
for international relation analysis.

摘要：<paragraph>大型語言模型 (LLM) 的最新進展賦予了 LLM 代理自主收集世界資訊的能力，並基於這些資訊進行推理以解決複雜問題。鑑於此功能，將 LLM 代理用於預測國際事件的興趣日益濃厚，這可能會影響決策制定並在國際層面上塑造政策發展。儘管有如此濃厚的興趣，但缺乏對 LLM 代理預測能力和可靠性的嚴格基準。為了解決這一差距，我們引入了 MIRAI，這是一個新基準，旨在系統地評估 LLM 代理作為國際事件時間預測者的能力。我們的基準特點是提供一個代理環境，其中包含訪問大量歷史結構化事件和文字新聞文章的工具。我們通過仔細清理和解析 GDELT 事件資料庫，策劃了一系列具有不同預測範圍的關係預測任務，評估 LLM 代理從短期到長期預測的能力。我們進一步實作 API，使 LLM 代理能夠透過基於程式碼的介面使用不同的工具。總之，MIRAI 全面評估了代理在三個維度上的能力：1) 自主地從大型全球資料庫中獲取和整合關鍵資訊；2) 使用特定領域的 API 和程式庫編寫程式碼以使用工具；3) 共同推理來自不同格式和時間的歷史知識，以準確預測未來事件。透過全面的基準測試，我們旨在建立一個可靠的框架，用於評估 LLM 代理在預測國際事件方面的能力，從而為國際關係分析的更準確和值得信賴的模型的開發做出貢獻。</paragraph>

##### **Integrated feature analysis for deep learning interpretation and class activation maps**
2407.01142v1 by Yanli Li, Tahereh Hassanzadeh, Denis P. Shamonin, Monique Reijnierse, Annette H. M. van der Helm-van Mil, Berend C. Stoel

Understanding the decisions of deep learning (DL) models is essential for the
acceptance of DL to risk-sensitive applications. Although methods, like class
activation maps (CAMs), give a glimpse into the black box, they do miss some
crucial information, thereby limiting its interpretability and merely providing
the considered locations of objects. To provide more insight into the models
and the influence of datasets, we propose an integrated feature analysis
method, which consists of feature distribution analysis and feature
decomposition, to look closer into the intermediate features extracted by DL
models. This integrated feature analysis could provide information on
overfitting, confounders, outliers in datasets, model redundancies and
principal features extracted by the models, and provide distribution
information to form a common intensity scale, which are missing in current CAM
algorithms. The integrated feature analysis was applied to eight different
datasets for general validation: photographs of handwritten digits, two
datasets of natural images and five medical datasets, including skin
photography, ultrasound, CT, X-rays and MRIs. The method was evaluated by
calculating the consistency between the CAMs average class activation levels
and the logits of the model. Based on the eight datasets, the correlation
coefficients through our method were all very close to 100%, and based on the
feature decomposition, 5%-25% of features could generate equally informative
saliency maps and obtain the same model performances as using all features.
This proves the reliability of the integrated feature analysis. As the proposed
methods rely on very few assumptions, this is a step towards better model
interpretation and a useful extension to existing CAM algorithms. Codes:
https://github.com/YanliLi27/IFA

摘要：<paragraph>了解深度學習（DL）模型的決策對於風險敏感應用程式接受 DL 至關重要。儘管方法（如類別激勵映射 (CAM)）讓黑盒子得以一窺究竟，但它們仍遺漏了一些關鍵資訊，因而限制了解釋能力，僅提供物件被考慮的位置。為了更深入瞭解模型和資料集的影響，我們提出了一種整合特徵分析方法，包括特徵分佈分析和特徵分解，以更仔細地檢視 DL 模型提取的中間特徵。這種整合特徵分析可以提供有關過度擬合、混淆變數、資料集中的異常值、模型冗餘和模型提取的主要特徵的資訊，並提供分佈資訊以形成共同的強度量表，這是目前 CAM 演算法所缺少的。整合特徵分析已應用於八個不同的資料集以進行一般驗證：手寫數字照片、兩個自然影像資料集和五個醫學資料集，包括皮膚攝影、超音波、電腦斷層掃描、X 光和 MRI。該方法透過計算 CAM 平均類別激勵層級與模型的 logit 值之間的一致性來評估。根據這八個資料集，我們的方法得出的相關係數都非常接近 100%，根據特徵分解，5%-25% 的特徵可以產生同樣具有資訊性的顯著性圖，並獲得與使用所有特徵相同的模型效能。這證明了整合特徵分析的可靠性。由於所提出的方法依賴的假設很少，因此這是朝向更好的模型解釋邁出的一步，也是對現有 CAM 演算法有用的延伸。程式碼：https://github.com/YanliLi27/IFA</paragraph>

##### **An Outline of Prognostics and Health Management Large Model: Concepts, Paradigms, and Challenges**
2407.03374v1 by Laifa Tao, Shangyu Li, Haifei Liu, Qixuan Huang, Liang Ma, Guoao Ning, Yiling Chen, Yunlong Wu, Bin Li, Weiwei Zhang, Zhengduo Zhao, Wenchao Zhan, Wenyan Cao, Chao Wang, Hongmei Liu, Jian Ma, Mingliang Suo, Yujie Cheng, Yu Ding, Dengwei Song, Chen Lu

Prognosis and Health Management (PHM), critical for ensuring task completion
by complex systems and preventing unexpected failures, is widely adopted in
aerospace, manufacturing, maritime, rail, energy, etc. However, PHM's
development is constrained by bottlenecks like generalization, interpretation
and verification abilities. Presently, generative artificial intelligence (AI),
represented by Large Model, heralds a technological revolution with the
potential to fundamentally reshape traditional technological fields and human
production methods. Its capabilities, including strong generalization,
reasoning, and generative attributes, present opportunities to address PHM's
bottlenecks. To this end, based on a systematic analysis of the current
challenges and bottlenecks in PHM, as well as the research status and
advantages of Large Model, we propose a novel concept and three progressive
paradigms of Prognosis and Health Management Large Model (PHM-LM) through the
integration of the Large Model with PHM. Subsequently, we provide feasible
technical approaches for PHM-LM to bolster PHM's core capabilities within the
framework of the three paradigms. Moreover, to address core issues confronting
PHM, we discuss a series of technical challenges of PHM-LM throughout the
entire process of construction and application. This comprehensive effort
offers a holistic PHM-LM technical framework, and provides avenues for new PHM
technologies, methodologies, tools, platforms and applications, which also
potentially innovates design, research & development, verification and
application mode of PHM. And furthermore, a new generation of PHM with AI will
also capably be realized, i.e., from custom to generalized, from discriminative
to generative, and from theoretical conditions to practical applications.

摘要：預測與健康管理 (PHM) 對於確保複雜系統任務完成和防止意外故障至關重要，廣泛應用於航空、製造、海事、鐵路、能源等領域。然而，PHM 的發展受到泛化、解釋和驗證能力等瓶頸的制約。目前，以大模型為代表的生成式人工智慧 (AI) 預示著一場技術革命，有潛力從根本上重塑傳統技術領域和人類生產方式。其包括強泛化、推理和生成屬性在內的能力，為解決 PHM 的瓶頸提供了機會。為此，我們基於對 PHM 現有挑戰和瓶頸的系統分析，以及大模型的研究現狀和優勢，通過將大模型與 PHM 相結合，提出了預測與健康管理大模型 (PHM-LM) 的新概念和三個進步範例。隨後，我們在三個範例的框架內為 PHM-LM 提供了可行的技術方法，以加強 PHM 的核心能力。此外，為了解決 PHM 面臨的核心問題，我們在整個構建和應用過程中討論了 PHM-LM 的一系列技術挑戰。這項綜合工作提供了一個整體的 PHM-LM 技術框架，並為新的 PHM 技術、方法、工具、平台和應用程式提供了途徑，也可能創新 PHM 的設計、研發、驗證和應用模式。此外，還將能夠實現新一代具備 AI 的 PHM，即從客製化到泛化、從判別式到生成式，以及從理論條件到實際應用。

##### **Embedded Prompt Tuning: Towards Enhanced Calibration of Pretrained Models for Medical Images**
2407.01003v2 by Wenqiang Zu, Shenghao Xie, Qing Zhao, Guoqi Li, Lei Ma

Foundation models pre-trained on large-scale data have been widely witnessed
to achieve success in various natural imaging downstream tasks.
Parameter-efficient fine-tuning (PEFT) methods aim to adapt foundation models
to new domains by updating only a small portion of parameters in order to
reduce computational overhead. However, the effectiveness of these PEFT
methods, especially in cross-domain few-shot scenarios, e.g., medical image
analysis, has not been fully explored. In this work, we facilitate the study of
the performance of PEFT when adapting foundation models to medical image
classification tasks. Furthermore, to alleviate the limitations of prompt
introducing ways and approximation capabilities on Transformer architectures of
mainstream prompt tuning methods, we propose the Embedded Prompt Tuning (EPT)
method by embedding prompt tokens into the expanded channels. We also find that
there are anomalies in the feature space distribution of foundation models
during pre-training process, and prompt tuning can help mitigate this negative
impact. To explain this phenomenon, we also introduce a novel perspective to
understand prompt tuning: Prompt tuning is a distribution calibrator. And we
support it by analyzing patch-wise scaling and feature separation operations
contained in EPT. Our experiments show that EPT outperforms several
state-of-the-art fine-tuning methods by a significant margin on few-shot
medical image classification tasks, and completes the fine-tuning process
within highly competitive time, indicating EPT is an effective PEFT method. The
source code is available at github.com/zuwenqiang/EPT.

摘要：<paragraph>在大規模資料上預先訓練的基礎模型已被廣泛證明
在各種自然影像下游任務中取得成功。
參數有效微調 (PEFT) 方法旨在通過僅更新一小部分參數來適應基礎模型
到新網域，以減少運算開銷。然而，這些 PEFT 的有效性
方法，特別是在跨網域少次拍攝場景中，例如醫學影像
分析尚未得到充分探討。在這項工作中，我們促進了
研究 PEFT 在適應基礎模型到醫學影像時的效果
分類任務。此外，為了緩解提示的限制
在主流提示調整方法的 Transformer 架構上引入方式和近似能力，我們提出了嵌入式提示調整 (EPT)
方法是將提示代幣嵌入到擴展的通道中。我們還發現
在預訓練過程中，基礎模型的特徵空間分佈存在異常，並且提示調整可以幫助減輕這種負面
影響。為了解釋這種現象，我們還引入了一個新穎的觀點來
了解提示調整：提示調整是一個分佈校準器。我們
通過分析 EPT 中包含的補丁式縮放和特徵分離操作來支持它。我們的實驗表明，EPT 在少次拍攝中優於幾種最先進的微調方法
醫學影像分類任務的邊際，並在極具競爭力的時間內完成微調過程，表明 EPT 是一種有效的 PEFT 方法。
源代碼可在 github.com/zuwenqiang/EPT 中獲得。</paragraph>

##### **Individual brain parcellation: Review of methods, validations and applications**
2407.00984v1 by Chengyi Li, Shan Yu, Yue Cui

Individual brains vary greatly in morphology, connectivity and organization.
The applicability of group-level parcellations is limited by the rapid
development of precision medicine today because they do not take into account
the variation of parcels at the individual level. Accurate mapping of brain
functional regions at the individual level is pivotal for a comprehensive
understanding of the variations in brain function and behaviors, early and
precise identification of brain abnormalities, as well as personalized
treatments for neuropsychiatric disorders. With the development of neuroimaging
and machine learning techniques, studies on individual brain parcellation are
booming. In this paper, we offer an overview of recent advances in the
methodologies of individual brain parcellation, including optimization- and
learning-based methods. Comprehensive evaluation metrics to validate individual
brain mapping have been introduced. We also review the studies of how
individual brain mapping promotes neuroscience research and clinical medicine.
Finally, we summarize the major challenges and important future directions of
individualized brain parcellation. Collectively, we intend to offer a thorough
overview of individual brain parcellation methods, validations, and
applications, along with highlighting the current challenges that call for an
urgent demand for integrated platforms that integrate datasets, methods, and
validations.

摘要：各個大腦在形態、連接性和組織上差異極大。
群體層級的區塊化適用性受到當今精準醫療的快速發展所限制，因為它們沒有考慮到個體層級的區塊變異。在個體層級準確繪製大腦功能區域對於全面了解大腦功能和行為的變異、早期且精確地識別大腦異常，以及神經精神疾病的個人化治療至關重要。隨著神經影像和機器學習技術的發展，關於個別大腦區塊化的研究正在蓬勃發展。在本文中，我們概述了個別大腦區塊化方法學的最新進展，包括基於最佳化和學習的方法。已經引入了全面的評估指標來驗證個別大腦對應。我們還回顧了個別大腦對應如何促進神經科學研究和臨床醫學的研究。最後，我們總結了個別化大腦區塊化的主要挑戰和重要的未來方向。總的來說，我們打算對個別大腦區塊化方法、驗證和應用提供全面的概述，同時強調當前挑戰，這些挑戰迫切需要整合數據集、方法和驗證的整合平台。

##### **Hybrid RAG-empowered Multi-modal LLM for Secure Healthcare Data Management: A Diffusion-based Contract Theory Approach**
2407.00978v1 by Cheng Su, Jinbo Wen, Jiawen Kang, Yonghua Wang, Hudan Pan, M. Shamim Hossain

Secure data management and effective data sharing have become paramount in
the rapidly evolving healthcare landscape. The advancement of generative
artificial intelligence has positioned Multi-modal Large Language Models
(MLLMs) as crucial tools for managing healthcare data. MLLMs can support
multi-modal inputs and generate diverse types of content by leveraging
large-scale training on vast amounts of multi-modal data. However, critical
challenges persist in developing medical MLLMs, including healthcare data
security and freshness issues, affecting the output quality of MLLMs. In this
paper, we propose a hybrid Retrieval-Augmented Generation (RAG)-empowered
medical MLLMs framework for healthcare data management. This framework
leverages a hierarchical cross-chain architecture to facilitate secure data
training. Moreover, it enhances the output quality of MLLMs through hybrid RAG,
which employs multi-modal metrics to filter various unimodal RAG results and
incorporates these retrieval results as additional inputs to MLLMs.
Additionally, we employ age of information to indirectly evaluate the data
freshness impact of MLLMs and utilize contract theory to incentivize healthcare
data holders to share fresh data, mitigating information asymmetry in data
sharing. Finally, we utilize a generative diffusion model-based reinforcement
learning algorithm to identify the optimal contract for efficient data sharing.
Numerical results demonstrate the effectiveness of the proposed schemes, which
achieve secure and efficient healthcare data management.

摘要：在快速變化的醫療保健領域中，安全數據管理和有效數據共享已變得至關重要。生成式人工智慧的進步已將多模態大型語言模型 (MLLM) 定位為管理醫療保健數據的關鍵工具。MLLM 可支援多模態輸入，並透過利用大量多模態數據進行大規模訓練來產生各種類型的內容。然而，在開發醫療 MLLM 時仍存在關鍵挑戰，包括醫療保健數據安全性與新穎性問題，影響 MLLM 的輸出品質。在本文中，我們提出一個由檢索增強生成 (RAG) 賦能的混合醫療 MLLM 框架，用於醫療保健數據管理。此框架利用階層式跨鏈架構，以利於安全數據訓練。此外，它透過混合 RAG 來提升 MLLM 的輸出品質，此方法採用多模態指標來過濾各種單模態 RAG 結果，並將這些檢索結果作為額外輸入納入 MLLM。此外，我們採用資訊年齡來間接評估 MLLM 的數據新穎性影響，並利用契約理論來激勵醫療保健數據持有者共享新穎數據，從而減輕數據共享中的資訊不對稱。最後，我們利用生成擴散模型為基礎的強化學習演算法，以找出最佳契約，以進行有效率的數據共享。數值結果證明所提出的架構有效，可達成安全且有效率的醫療保健數據管理。

##### **Optimizing PM2.5 Forecasting Accuracy with Hybrid Meta-Heuristic and Machine Learning Models**
2407.01647v1 by Parviz Ghafariasl, Masoomeh Zeinalnezhad, Amir Ahmadishokooh

Timely alerts about hazardous air pollutants are crucial for public health.
However, existing forecasting models often overlook key factors like baseline
parameters and missing data, limiting their accuracy. This study introduces a
hybrid approach to address these issues, focusing on forecasting hourly PM2.5
concentrations using Support Vector Regression (SVR). Meta-heuristic
algorithms, Grey Wolf Optimization (GWO) and Particle Swarm Optimization (PSO),
optimize SVR Hyper-parameters "C" and "Gamma" to enhance prediction accuracy.
Evaluation metrics include R-squared (R2), Root Mean Square Error (RMSE), and
Mean Absolute Error (MAE). Results show significant improvements with PSO-SVR
(R2: 0.9401, RMSE: 0.2390, MAE: 0.1368) and GWO-SVR (R2: 0.9408, RMSE: 0.2376,
MAE: 0.1373), indicating robust and accurate models suitable for similar
research applications.

摘要：及時發布有關有害空氣污染物的警報對公共衛生至關重要。
然而，現有的預測模型通常會忽略基線參數和缺失資料等關鍵因素，從而限制了其準確性。本研究引入了一種混合方法來解決這些問題，重點關注使用支持向量回歸 (SVR) 預測每小時 PM2.5 濃度。元啟發式演算法、灰狼優化 (GWO) 和粒子群優化 (PSO) 優化 SVR 超參數「C」和「Gamma」以提高預測準確度。評估指標包括 R 平方 (R2)、均方根誤差 (RMSE) 和平均絕對誤差 (MAE)。結果顯示 PSO-SVR (R2：0.9401、RMSE：0.2390、MAE：0.1368) 和 GWO-SVR (R2：0.9408、RMSE：0.2376、MAE：0.1373) 有顯著改善，表明適用於類似研究應用程式的穩健且準確的模型。

##### **Deep learning for automated detection of breast cancer in deep ultraviolet fluorescence images with diffusion probabilistic model**
2407.00967v1 by Sepehr Salem Ghahfarokhi, Tyrell To, Julie Jorns, Tina Yen, Bing Yu, Dong Hye Ye

Data limitation is a significant challenge in applying deep learning to
medical images. Recently, the diffusion probabilistic model (DPM) has shown the
potential to generate high-quality images by converting Gaussian random noise
into realistic images. In this paper, we apply the DPM to augment the deep
ultraviolet fluorescence (DUV) image dataset with an aim to improve breast
cancer classification for intraoperative margin assessment. For classification,
we divide the whole surface DUV image into small patches and extract
convolutional features for each patch by utilizing the pre-trained ResNet.
Then, we feed them into an XGBoost classifier for patch-level decisions and
then fuse them with a regional importance map computed by Grad-CAM++ for whole
surface-level prediction. Our experimental results show that augmenting the
training dataset with the DPM significantly improves breast cancer detection
performance in DUV images, increasing accuracy from 93% to 97%, compared to
using Affine transformations and ProGAN.

摘要：資料限制是應用深度學習於醫學影像的一大挑戰。最近，擴散機率模型 (DPM) 已展現將高斯隨機雜訊轉換為逼真影像的潛力，用以產生高品質影像。在本文中，我們將 DPM 應用於擴充深度紫外螢光 (DUV) 影像資料集，目標是改善乳癌分類，用於術中邊緣評估。對於分類，我們將整個表面 DUV 影像分割成小區塊，並利用預訓練的 ResNet 為每個區塊萃取卷積特徵。接著，我們將它們輸入 XGBoost 分類器，用於區塊層級的決策，然後將它們與 Grad-CAM++ 計算出的區域重要性圖融合，用於整個表面層級的預測。我們的實驗結果顯示，使用 DPM 擴充訓練資料集可顯著提升 DUV 影像的乳癌偵測效能，與使用仿射轉換和 ProGAN 相比，準確率從 93% 提升至 97%。

##### **Characterizing Stereotypical Bias from Privacy-preserving Pre-Training**
2407.00764v1 by Stefan Arnold, Rene Gröbner, Annika Schreiner

Differential Privacy (DP) can be applied to raw text by exploiting the
spatial arrangement of words in an embedding space. We investigate the
implications of such text privatization on Language Models (LMs) and their
tendency towards stereotypical associations. Since previous studies documented
that linguistic proficiency correlates with stereotypical bias, one could
assume that techniques for text privatization, which are known to degrade
language modeling capabilities, would cancel out undesirable biases. By testing
BERT models trained on texts containing biased statements primed with varying
degrees of privacy, our study reveals that while stereotypical bias generally
diminishes when privacy is tightened, text privatization does not uniformly
equate to diminishing bias across all social domains. This highlights the need
for careful diagnosis of bias in LMs that undergo text privatization.

摘要：差分隱私 (DP) 可透過利用嵌入空間中字詞的空間排列來應用於原始文字。我們探討這種文字私有化對語言模型 (LM) 及其對刻板印象關聯的傾向所造成的影響。由於先前的研究記錄語言能力與刻板印象偏誤相關，因此可以假設已知會降低語言建模能力的文字私有化技術會消除不良偏誤。透過測試在包含以不同程度隱私為前提的偏見陳述的文字上訓練的 BERT 模型，我們的研究顯示，雖然在加強隱私時刻板印象偏誤通常會減少，但文字私有化並非在所有社會領域都等於減少偏誤。這突顯了在經過文字私有化的 LM 中仔細診斷偏誤的必要性。

##### **Chest-Diffusion: A Light-Weight Text-to-Image Model for Report-to-CXR Generation**
2407.00752v1 by Peng Huang, Xue Gao, Lihong Huang, Jing Jiao, Xiaokang Li, Yuanyuan Wang, Yi Guo

Text-to-image generation has important implications for generation of diverse
and controllable images. Several attempts have been made to adapt Stable
Diffusion (SD) to the medical domain. However, the large distribution
difference between medical reports and natural texts, as well as high
computational complexity in common stable diffusion limit the authenticity and
feasibility of the generated medical images. To solve above problems, we
propose a novel light-weight transformer-based diffusion model learning
framework, Chest-Diffusion, for report-to-CXR generation. Chest-Diffusion
employs a domain-specific text encoder to obtain accurate and expressive text
features to guide image generation, improving the authenticity of the generated
images. Meanwhile, we introduce a light-weight transformer architecture as the
denoising model, reducing the computational complexity of the diffusion model.
Experiments demonstrate that our Chest-Diffusion achieves the lowest FID score
24.456, under the computation budget of 118.918 GFLOPs, which is nearly
one-third of the computational complexity of SD.

摘要：文本到图像生成对于生成多样且可控的图像具有重要意义。已经做出了一些尝试来将 Stable Diffusion (SD) 调整到医学领域。然而，医学报告和自然文本之间存在较大的分布差异，以及常见的稳定扩散中的高计算复杂度限制了生成医学图像的真实性和可行性。为了解决上述问题，我们提出了一种新颖的轻量级基于 transformer 的扩散模型学习框架 Chest-Diffusion，用于报告到 CXR 生成。Chest-Diffusion 使用特定于领域的文本编码器来获取准确且富有表现力的文本特征以指导图像生成，从而提高生成图像的真实性。同时，我们引入了一个轻量级的 transformer 架构作为去噪模型，降低了扩散模型的计算复杂度。实验表明，我们的 Chest-Diffusion 在 118.918 GFLOP 的计算预算下实现了最低的 FID 分数 24.456，这几乎是 SD 计算复杂度的三分之一。

##### **Large Language Models Struggle in Token-Level Clinical Named Entity Recognition**
2407.00731v1 by Qiuhao Lu, Rui Li, Andrew Wen, Jinlian Wang, Liwei Wang, Hongfang Liu

Large Language Models (LLMs) have revolutionized various sectors, including
healthcare where they are employed in diverse applications. Their utility is
particularly significant in the context of rare diseases, where data scarcity,
complexity, and specificity pose considerable challenges. In the clinical
domain, Named Entity Recognition (NER) stands out as an essential task and it
plays a crucial role in extracting relevant information from clinical texts.
Despite the promise of LLMs, current research mostly concentrates on
document-level NER, identifying entities in a more general context across
entire documents, without extracting their precise location. Additionally,
efforts have been directed towards adapting ChatGPT for token-level NER.
However, there is a significant research gap when it comes to employing
token-level NER for clinical texts, especially with the use of local
open-source LLMs. This study aims to bridge this gap by investigating the
effectiveness of both proprietary and local LLMs in token-level clinical NER.
Essentially, we delve into the capabilities of these models through a series of
experiments involving zero-shot prompting, few-shot prompting,
retrieval-augmented generation (RAG), and instruction-fine-tuning. Our
exploration reveals the inherent challenges LLMs face in token-level NER,
particularly in the context of rare diseases, and suggests possible
improvements for their application in healthcare. This research contributes to
narrowing a significant gap in healthcare informatics and offers insights that
could lead to a more refined application of LLMs in the healthcare sector.

摘要：大型語言模型 (LLM) 已徹底改變了各個領域，包括醫療保健，它們在其中被用於各種應用程式。它們的實用性在罕見疾病的背景下尤其重要，因為資料稀少、複雜且具特異性，對此構成相當大的挑戰。在臨床領域中，命名實體識別 (NER) 是一個重要的任務，在從臨床文本中擷取相關資訊方面扮演至關重要的角色。儘管 LLM 前景看好，但目前的研究大多集中在文件層級的 NER，在整個文件中識別更通用的背景中的實體，而不會擷取它們精確的位置。此外，已將精力投入於調整 ChatGPT 以進行代幣層級的 NER。然而，在使用代幣層級的 NER 來處理臨床文本時，特別是在使用本地的開源 LLM 時，存在重大的研究差距。本研究旨在透過探討專有和本地 LLM 在代幣層級臨床 NER 中的有效性來彌補此差距。基本上，我們透過一系列涉及零次提示、少次提示、檢索增強生成 (RAG) 和指令微調的實驗，深入探討這些模型的能力。我們的探索揭示了 LLM 在代幣層級 NER 中面臨的固有挑戰，特別是在罕見疾病的背景下，並建議了它們在醫療保健應用中可能的改進。本研究有助於縮小醫療保健資訊學中的一個重大差距，並提供可望導致在醫療保健領域更精緻地應用 LLM 的見解。

##### **SCMIL: Sparse Context-aware Multiple Instance Learning for Predicting Cancer Survival Probability Distribution in Whole Slide Images**
2407.00664v1 by Zekang Yang, Hong Liu, Xiangdong Wang

Cancer survival prediction is a challenging task that involves analyzing of
the tumor microenvironment within Whole Slide Image (WSI). Previous methods
cannot effectively capture the intricate interaction features among instances
within the local area of WSI. Moreover, existing methods for cancer survival
prediction based on WSI often fail to provide better clinically meaningful
predictions. To overcome these challenges, we propose a Sparse Context-aware
Multiple Instance Learning (SCMIL) framework for predicting cancer survival
probability distributions. SCMIL innovatively segments patches into various
clusters based on their morphological features and spatial location
information, subsequently leveraging sparse self-attention to discern the
relationships between these patches with a context-aware perspective.
Considering many patches are irrelevant to the task, we introduce a learnable
patch filtering module called SoftFilter, which ensures that only interactions
between task-relevant patches are considered. To enhance the clinical relevance
of our prediction, we propose a register-based mixture density network to
forecast the survival probability distribution for individual patients. We
evaluate SCMIL on two public WSI datasets from the The Cancer Genome Atlas
(TCGA) specifically focusing on lung adenocarcinom (LUAD) and kidney renal
clear cell carcinoma (KIRC). Our experimental results indicate that SCMIL
outperforms current state-of-the-art methods for survival prediction, offering
more clinically meaningful and interpretable outcomes. Our code is accessible
at https://github.com/yang-ze-kang/SCMIL.

摘要：癌症存活預測是一項艱鉅的任務，涉及分析全幻燈片影像 (WSI) 中的腫瘤微環境。先前的研究方法無法有效擷取 WSI 局部區域內實例之間的複雜互動特徵。此外，現有的基於 WSI 的癌症存活預測方法通常無法提供更有意義的臨床預測。為了克服這些挑戰，我們提出了一個稀疏上下文感知多實例學習 (SCMIL) 框架，用於預測癌症存活機率分佈。SCMIL 創新地根據形態特徵和空間位置資訊將區塊分割成各種叢集，隨後利用稀疏自注意力來辨別這些區塊之間的關係，並具備上下文感知觀點。考量到許多區塊與任務無關，我們引入了一個可學習的區塊過濾模組 SoftFilter，以確保僅考慮與任務相關區塊之間的互動。為了增強我們預測的臨床相關性，我們提出了一個基於註冊的混合密度網路，以預測個別患者的存活機率分佈。我們在兩個來自癌症基因圖譜 (TCGA) 的公共 WSI 資料集上評估 SCMIL，特別關注肺腺癌 (LUAD) 和腎透明細胞癌 (KIRC)。我們的實驗結果表明，SCMIL 在存活預測方面優於當前最先進的方法，提供了更有意義且可解釋的臨床結果。我們的程式碼可在 https://github.com/yang-ze-kang/SCMIL 取得。

##### **TrialBench: Multi-Modal Artificial Intelligence-Ready Clinical Trial Datasets**
2407.00631v1 by Jintai Chen, Yaojun Hu, Yue Wang, Yingzhou Lu, Xu Cao, Miao Lin, Hongxia Xu, Jian Wu, Cao Xiao, Jimeng Sun, Lucas Glass, Kexin Huang, Marinka Zitnik, Tianfan Fu

Clinical trials are pivotal for developing new medical treatments, yet they
typically pose some risks such as patient mortality, adverse events, and
enrollment failure that waste immense efforts spanning over a decade. Applying
artificial intelligence (AI) to forecast or simulate key events in clinical
trials holds great potential for providing insights to guide trial designs.
However, complex data collection and question definition requiring medical
expertise and a deep understanding of trial designs have hindered the
involvement of AI thus far. This paper tackles these challenges by presenting a
comprehensive suite of meticulously curated AIready datasets covering
multi-modal data (e.g., drug molecule, disease code, text,
categorical/numerical features) and 8 crucial prediction challenges in clinical
trial design, encompassing prediction of trial duration, patient dropout rate,
serious adverse event, mortality rate, trial approval outcome, trial failure
reason, drug dose finding, design of eligibility criteria. Furthermore, we
provide basic validation methods for each task to ensure the datasets'
usability and reliability. We anticipate that the availability of such
open-access datasets will catalyze the development of advanced AI approaches
for clinical trial design, ultimately advancing clinical trial research and
accelerating medical solution development. The curated dataset, metrics, and
basic models are publicly available at
https://github.com/ML2Health/ML2ClinicalTrials/tree/main/AI4Trial.

摘要：臨床試驗對於開發新的醫療療法至關重要，但它們通常會帶來一些風險，例如患者死亡率、不良事件和註冊失敗，這些風險會浪費長達十年的巨大努力。將人工智慧 (AI) 應用於預測或模擬臨床試驗中的關鍵事件，對於提供見解以指導試驗設計具有巨大的潛力。然而，需要醫學專業知識和對試驗設計的深入了解的複雜數據收集和問題定義，迄今為止阻礙了 AI 的參與。本文通過提供一套全面的精心策劃的 AIready 數據集來應對這些挑戰，涵蓋多模式數據（例如，藥物分子、疾病代碼、文本、分類/數值特徵）和臨床試驗設計中的 8 項關鍵預測挑戰，包括預測試驗持續時間、患者輟學率、嚴重不良事件、死亡率、試驗批准結果、試驗失敗原因、藥物劑量發現、資格標準的設計。此外，我們為每個任務提供基本的驗證方法，以確保數據集的可用性和可靠性。我們預計這些開放訪問數據集的可用性將催化先進 AI 方法在臨床試驗設計中的開發，最終推進臨床試驗研究並加速醫療解決方案的開發。策展的數據集、指標和基本模型在 https://github.com/ML2Health/ML2ClinicalTrials/tree/main/AI4Trial 上公開提供。

##### **Answering real-world clinical questions using large language model based systems**
2407.00541v1 by Yen Sia Low, Michael L. Jackson, Rebecca J. Hyde, Robert E. Brown, Neil M. Sanghavi, Julian D. Baldwin, C. William Pike, Jananee Muralidharan, Gavin Hui, Natasha Alexander, Hadeel Hassan, Rahul V. Nene, Morgan Pike, Courtney J. Pokrzywa, Shivam Vedak, Adam Paul Yan, Dong-han Yao, Amy R. Zipursky, Christina Dinh, Philip Ballentine, Dan C. Derieg, Vladimir Polony, Rehan N. Chawdry, Jordan Davies, Brigham B. Hyde, Nigam H. Shah, Saurabh Gombar

Evidence to guide healthcare decisions is often limited by a lack of relevant
and trustworthy literature as well as difficulty in contextualizing existing
research for a specific patient. Large language models (LLMs) could potentially
address both challenges by either summarizing published literature or
generating new studies based on real-world data (RWD). We evaluated the ability
of five LLM-based systems in answering 50 clinical questions and had nine
independent physicians review the responses for relevance, reliability, and
actionability. As it stands, general-purpose LLMs (ChatGPT-4, Claude 3 Opus,
Gemini Pro 1.5) rarely produced answers that were deemed relevant and
evidence-based (2% - 10%). In contrast, retrieval augmented generation
(RAG)-based and agentic LLM systems produced relevant and evidence-based
answers for 24% (OpenEvidence) to 58% (ChatRWD) of questions. Only the agentic
ChatRWD was able to answer novel questions compared to other LLMs (65% vs.
0-9%). These results suggest that while general-purpose LLMs should not be used
as-is, a purpose-built system for evidence summarization based on RAG and one
for generating novel evidence working synergistically would improve
availability of pertinent evidence for patient care.

摘要：醫療保健決策的指導證據通常受到缺乏相關且可信賴文獻的限制，以及難以將現有研究背景化以適用於特定患者。大型語言模型 (LLM) 潛在可透過摘要已發表的文獻或根據真實世界資料 (RWD) 產生新的研究來解決這兩個挑戰。我們評估了五個基於 LLM 的系統回答 50 個臨床問題的能力，並讓九位獨立的醫師檢視回應的相關性、可靠性，以及可行性。目前，通用 LLM（ChatGPT-4、Claude 3 Opus、Gemini Pro 1.5）很少產生被認為相關且基於證據的答案（2% - 10%）。相反地，基於檢索增強生成（RAG）和代理 LLM 系統產生的答案，有 24%（OpenEvidence）至 58%（ChatRWD）的問題是相關且基於證據的。與其他 LLM 相比，只有代理 ChatRWD 能夠回答新問題（65% 對 0-9%）。這些結果表明，雖然不應按原樣使用通用 LLM，但一個基於 RAG 的專門建置系統，用於證據摘要，以及一個用於產生新證據的系統，協同運作，將可改善與患者照護相關證據的可用性。

##### **Privacy-Preserving and Trustworthy Deep Learning for Medical Imaging**
2407.00538v1 by Kiarash Sedghighadikolaei, Attila A Yavuz

The shift towards efficient and automated data analysis through Machine
Learning (ML) has notably impacted healthcare systems, particularly Radiomics.
Radiomics leverages ML to analyze medical images accurately and efficiently for
precision medicine. Current methods rely on Deep Learning (DL) to improve
performance and accuracy (Deep Radiomics). Given the sensitivity of medical
images, ensuring privacy throughout the Deep Radiomics pipeline-from data
generation and collection to model training and inference-is essential,
especially when outsourced. Thus, Privacy-Enhancing Technologies (PETs) are
crucial tools for Deep Radiomics. Previous studies and systematization efforts
have either broadly overviewed PETs and their applications or mainly focused on
subsets of PETs for ML algorithms. In Deep Radiomics, where efficiency,
accuracy, and privacy are crucial, many PETs, while theoretically applicable,
may not be practical without specialized optimizations or hybrid designs.
Additionally, not all DL models are suitable for Radiomics. Consequently, there
is a need for specialized studies that investigate and systematize the
effective and practical integration of PETs into the Deep Radiomics pipeline.
This work addresses this research gap by (1) classifying existing PETs,
presenting practical hybrid PETS constructions, and a taxonomy illustrating
their potential integration with the Deep Radiomics pipeline, with comparative
analyses detailing assumptions, architectural suitability, and security, (2)
Offering technical insights, describing potential challenges and means of
combining PETs into the Deep Radiomics pipeline, including integration
strategies, subtilities, and potential challenges, (3) Proposing potential
research directions, identifying challenges, and suggesting solutions to
enhance the PETs in Deep Radiomics.

摘要：機器學習（ML）朝向高效且自動化的資料分析轉變，顯著影響了醫療保健系統，尤其是放射組學。放射組學利用機器學習精準且有效地分析醫學影像，以進行精準醫療。目前的技術仰賴深度學習（DL）來提升效能和準確度（深度放射組學）。考量到醫學影像的敏感性，確保在深度放射組學流程中（從資料產生和收集到模型訓練和推論）的隱私至關重要，特別是在外包時。因此，隱私強化技術（PET）是深度放射組學的關鍵工具。先前的研究和系統化工作，不是廣泛概述 PET 和其應用，就是主要關注 PET 在機器學習演算法中的子集。在深度放射組學中，效率、準確度和隱私至關重要，許多 PET 雖然理論上適用，但若沒有專門的最佳化或混合設計，可能不切實際。此外，並非所有深度學習模型都適合放射組學。因此，需要專門的研究，調查和系統化 PET 在深度放射組學流程中的有效且實際整合。這項工作透過（1）分類現有的 PET，提出實際的混合 PET 建構，以及一個說明其與深度放射組學流程潛在整合的分類法，並提供詳細說明假設、架構適用性和安全性，（2）提供技術見解，說明將 PET 整合到深度放射組學流程中的潛在挑戰和方法，包括整合策略、細微差別和潛在挑戰，（3）提出潛在的研究方向，找出挑戰，並建議解決方案，以強化深度放射組學中的 PET。

##### **Interpreting Pretrained Speech Models for Automatic Speech Assessment of Voice Disorders**
2407.00531v1 by Hok-Shing Lau, Mark Huntly, Nathon Morgan, Adesua Iyenoma, Biao Zeng, Tim Bashford

Speech contains information that is clinically relevant to some diseases,
which has the potential to be used for health assessment. Recent work shows an
interest in applying deep learning algorithms, especially pretrained large
speech models to the applications of Automatic Speech Assessment. One question
that has not been explored is how these models output the results based on
their inputs. In this work, we train and compare two configurations of Audio
Spectrogram Transformer in the context of Voice Disorder Detection and apply
the attention rollout method to produce model relevance maps, the computed
relevance of the spectrogram regions when the model makes predictions. We use
these maps to analyse how models make predictions in different conditions and
to show that the spread of attention is reduced as a model is finetuned, and
the model attention is concentrated on specific phoneme regions.

摘要：语音包含一些疾病的临床相关信息，
这有潜力用于健康评估。最近的研究表明有兴趣应用深度学习算法，尤其是预训练的大型
语音模型用于自动语音评估的应用。一个尚未探索的问题是这些模型如何根据
其输入输出结果。在这项工作中，我们在语音障碍检测的背景下训练和比较了两个音频
频谱图转换器的配置，并应用注意力展开方法来生成模型相关性图，即模型做出预测时频谱图区域的计算相关性。我们使用
这些图来分析模型如何在不同条件下做出预测，并表明随着模型的微调，注意力的分布会减少，并且
模型注意力集中在特定的音素区域。

##### **ConU: Conformal Uncertainty in Large Language Models with Correctness Coverage Guarantees**
2407.00499v1 by Zhiyuan Wang, Jinhao Duan, Lu Cheng, Yue Zhang, Qingni Wang, Hengtao Shen, Xiaofeng Zhu, Xiaoshuang Shi, Kaidi Xu

Uncertainty quantification (UQ) in natural language generation (NLG) tasks
remains an open challenge, exacerbated by the intricate nature of the recent
large language models (LLMs). This study investigates adapting conformal
prediction (CP), which can convert any heuristic measure of uncertainty into
rigorous theoretical guarantees by constructing prediction sets, for black-box
LLMs in open-ended NLG tasks. We propose a sampling-based uncertainty measure
leveraging self-consistency and develop a conformal uncertainty criterion by
integrating the uncertainty condition aligned with correctness into the design
of the CP algorithm. Experimental results indicate that our uncertainty measure
generally surpasses prior state-of-the-art methods. Furthermore, we calibrate
the prediction sets within the model's unfixed answer distribution and achieve
strict control over the correctness coverage rate across 6 LLMs on 4 free-form
NLG datasets, spanning general-purpose and medical domains, while the small
average set size further highlights the efficiency of our method in providing
trustworthy guarantees for practical open-ended NLG applications.

摘要：自然語言生成 (NLG) 任務中的不確定性量化 (UQ) 仍然是一個開放性的挑戰，最近大型語言模型 (LLM) 的複雜性質加劇了這一挑戰。本研究探討了適應共形預測 (CP)，它可以通過構造預測集將任何不確定性的啟發式測量轉換為嚴格的理論保證，用於開放式 NLG 任務中的黑盒 LLM。我們提出了一種基於抽樣的測量不確定性的方法，利用了自洽性，並通過將與正確性一致的不確定性條件整合到 CP 演算法的設計中，開發了一個共形不確定性準則。實驗結果表明，我們的測量不確定性的方法通常優於先前的最先進方法。此外，我們在模型的未固定答案分佈內校正了預測集，並在 4 個自由形式 NLG 資料集上對 6 個 LLM 的正確性覆蓋率進行了嚴格控制，涵蓋了通用和醫療領域，而較小的平均集合大小進一步突出了我們的方法在為實用的開放式 NLG 應用提供可信保證方面的效率。

##### **MH-pFLGB: Model Heterogeneous personalized Federated Learning via Global Bypass for Medical Image Analysis**
2407.00474v1 by Luyuan Xie, Manqing Lin, ChenMing Xu, Tianyu Luan, Zhipeng Zeng, Wenjun Qian, Cong Li, Yuejian Fang, Qingni Shen, Zhonghai Wu

In the evolving application of medical artificial intelligence, federated
learning is notable for its ability to protect training data privacy. Federated
learning facilitates collaborative model development without the need to share
local data from healthcare institutions. Yet, the statistical and system
heterogeneity among these institutions poses substantial challenges, which
affects the effectiveness of federated learning and hampers the exchange of
information between clients. To address these issues, we introduce a novel
approach, MH-pFLGB, which employs a global bypass strategy to mitigate the
reliance on public datasets and navigate the complexities of non-IID data
distributions. Our method enhances traditional federated learning by
integrating a global bypass model, which would share the information among the
clients, but also serves as part of the network to enhance the performance on
each client. Additionally, MH-pFLGB provides a feature fusion module to better
combine the local and global features. We validate \model{}'s effectiveness and
adaptability through extensive testing on different medical tasks,
demonstrating superior performance compared to existing state-of-the-art
methods.

摘要：在醫療人工智慧的應用演進中，聯邦學習因其保護訓練資料隱私的能力而備受矚目。聯邦學習促進協作模型開發，無需分享醫療保健機構的本地資料。然而，這些機構之間的統計和系統異質性帶來了重大的挑戰，影響了聯邦學習的有效性，並阻礙了客戶端之間的資訊交換。為了解決這些問題，我們提出了一種新的方法 MH-pFLGB，它採用全球旁路策略來減輕對公共資料集的依賴，並應對非 IID 資料分佈的複雜性。我們的模型透過整合一個全球旁路模型來增強傳統的聯邦學習，該模型將在客戶端之間共享資訊，但也作為網路的一部分來增強每個客戶端的效能。此外，MH-pFLGB 提供了一個特徵融合模組，以更好地結合本地和全球特徵。我們透過在不同的醫療任務上進行廣泛的測試來驗證模型的有效性和適應性，證明其效能優於現有的最先進方法。

##### **pFLFE: Cross-silo Personalized Federated Learning via Feature Enhancement on Medical Image Segmentation**
2407.00462v1 by Luyuan Xie, Manqing Lin, Siyuan Liu, ChenMing Xu, Tianyu Luan, Cong Li, Yuejian Fang, Qingni Shen, Zhonghai Wu

In medical image segmentation, personalized cross-silo federated learning
(FL) is becoming popular for utilizing varied data across healthcare settings
to overcome data scarcity and privacy concerns. However, existing methods often
suffer from client drift, leading to inconsistent performance and delayed
training. We propose a new framework, Personalized Federated Learning via
Feature Enhancement (pFLFE), designed to mitigate these challenges. pFLFE
consists of two main stages: feature enhancement and supervised learning. The
first stage improves differentiation between foreground and background
features, and the second uses these enhanced features for learning from
segmentation masks. We also design an alternative training approach that
requires fewer communication rounds without compromising segmentation quality,
even with limited communication resources. Through experiments on three medical
segmentation tasks, we demonstrate that pFLFE outperforms the state-of-the-art
methods.

摘要：在醫學影像分割中，個人化跨資料孤島的聯邦學習 (FL) 逐漸盛行，用於利用醫療保健環境中的各種資料來克服資料稀少和隱私問題。然而，現有方法經常會出現客戶端偏移，導致效能不一致且訓練延遲。我們提出一個新的架構，透過功能增強 (pFLFE) 進行個人化聯邦學習，旨在減輕這些挑戰。pFLFE 包含兩個主要階段：功能增強和監督式學習。第一個階段改善前景和背景功能之間的差異，而第二個階段使用這些增強的功能從分割遮罩中學習。我們還設計了一個備用訓練方法，即使在通訊資源有限的情況下，也不影響分割品質，只需要較少的通訊回合。透過在三個醫學分割任務中進行實驗，我們證明 pFLFE 優於最先進的方法。

##### **Is It Really Long Context if All You Need Is Retrieval? Towards Genuinely Difficult Long Context NLP**
2407.00402v2 by Omer Goldman, Alon Jacovi, Aviv Slobodkin, Aviya Maimon, Ido Dagan, Reut Tsarfaty

Improvements in language models' capabilities have pushed their applications
towards longer contexts, making long-context evaluation and development an
active research area. However, many disparate use-cases are grouped together
under the umbrella term of "long-context", defined simply by the total length
of the model's input, including - for example - Needle-in-a-Haystack tasks,
book summarization, and information aggregation. Given their varied difficulty,
in this position paper we argue that conflating different tasks by their
context length is unproductive. As a community, we require a more precise
vocabulary to understand what makes long-context tasks similar or different. We
propose to unpack the taxonomy of long-context based on the properties that
make them more difficult with longer contexts. We propose two orthogonal axes
of difficulty: (I) Diffusion: How hard is it to find the necessary information
in the context? (II) Scope: How much necessary information is there to find? We
survey the literature on long-context, provide justification for this taxonomy
as an informative descriptor, and situate the literature with respect to it. We
conclude that the most difficult and interesting settings, whose necessary
information is very long and highly diffused within the input, is severely
under-explored. By using a descriptive vocabulary and discussing the relevant
properties of difficulty in long-context, we can implement more informed
research in this area. We call for a careful design of tasks and benchmarks
with distinctly long context, taking into account the characteristics that make
it qualitatively different from shorter context.

摘要：語言模型能力的進步已將其應用推向更長的脈絡，使得長脈絡評估和開發成為一個活躍的研究領域。然而，許多不同的用例被歸類在「長脈絡」這個總稱之下，僅以模型輸入的總長度定義，包括例如大海撈針任務、書籍摘要和資訊彙整。鑑於它們的難度差異，我們在這篇立場文件中主張，將不同任務混為一談是沒有建設性的。作為一個社群，我們需要更精確的詞彙來理解是什麼讓長脈絡任務相似或不同。我們提議根據讓它們在較長脈絡中更困難的特性來解開長脈絡的分類法。我們提出兩個正交的難度軸：(I) 擴散：在脈絡中找到必要資訊有多困難？(II) 範圍：有多少必要的資訊需要找到？我們調查了關於長脈絡的文獻，為這個分類法作為一個有意義的描述符提供依據，並根據它來定位文獻。我們得出結論，最困難且最有趣的設定，其必要資訊在輸入中非常長且高度分散，嚴重地未被探索。透過使用描述性詞彙並討論長脈絡中困難的相關特性，我們可以在這個領域實施更明智的研究。我們呼籲仔細設計具有明顯長脈絡的任務和基準，並考量讓它在質量上不同於較短脈絡的特性。

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

摘要：近年來，美國見證了電子煙或電子香菸使用率大幅激增，導致電子煙和電子煙使用相關肺損傷 (EVALI) 病例顯著增加，在 2019 年 EVALI 爆發期間造成住院和死亡，凸顯了理解電子煙行為和制定有效戒菸策略的迫切性。由於社群媒體平台的普及，全球超過 47 億使用者使用它們進行連結、溝通、新聞和娛樂，其中很大一部分與健康相關，因此將社群媒體資料建立為公共衛生研究中無價的有機資料資源。在本研究中，我們從 Reddit 上一個電子煙子社群中提取一個範例資料集，以分析使用者的戒電子煙意圖。利用 OpenAI 最新的大型語言模型 GPT-4 進行句子層級的戒電子煙意圖偵測，本研究比較了此模型的結果與外行人和臨床專家註解。使用不同的提示策略，例如零次學習、一次學習、少次學習和思考鏈提示，我們開發了 8 個提示，詳細程度不同，向 GPT-4 解釋任務，並評估這些策略彼此之間的效能。這些初步發現強調了 GPT-4 在社群媒體資料分析中的潛力，特別是在識別人類偵測可能無法察覺的使用者微妙意圖方面。

##### **Predicting Elevated Risk of Hospitalization Following Emergency Department Discharges**
2407.00147v1 by Dat Hong, Philip M. Polgreen, Alberto Maria Segre

Hospitalizations that follow closely on the heels of one or more emergency
department visits are often symptoms of missed opportunities to form a proper
diagnosis. These diagnostic errors imply a failure to recognize the need for
hospitalization and deliver appropriate care, and thus also bear important
connotations for patient safety. In this paper, we show how data mining
techniques can be applied to a large existing hospitalization data set to learn
useful models that predict these upcoming hospitalizations with high accuracy.
Specifically, we use an ensemble of logistics regression, na\"ive Bayes and
association rule classifiers to successfully predict hospitalization within 3,
7 and 14 days of an emergency department discharge. Aside from high accuracy,
one of the advantages of the techniques proposed here is that the resulting
classifier is easily inspected and interpreted by humans so that the learned
rules can be readily operationalized. These rules can then be easily
distributed and applied directly by physicians in emergency department settings
to predict the risk of early admission prior to discharging their emergency
department patients.

摘要：緊接在一次或多次急診科就診後住院，通常是錯失適當診斷機會的徵兆。這些診斷錯誤意味著未能察覺住院需求並提供適當照護，因此也對病患安全造成重大影響。在本文中，我們將展示資料探勘技術如何應用於現有的大型住院資料集，以學習預測這些即將到來的住院事件且準確度極高的有用模型。具體來說，我們使用邏輯迴歸、樸素貝氏和關聯規則分類器的組合，成功預測急診科出院後 3、7 和 14 天內的住院。除了高準確度之外，本文提出的技術優勢之一是，產生的分類器容易被人類檢查和解讀，因此可以輕鬆地將學習到的規則付諸實行。然後，這些規則可以輕易地被分發，並由急診科的醫師直接應用，以在出院前預測急診科病患早期入院的風險。

