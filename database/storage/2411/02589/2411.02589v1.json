{"2411.02589": {"publish_time": "2024-11-04", "title": "Context-Informed Machine Translation of Manga using Multimodal Large Language Models", "paper_summary": "Due to the significant time and effort required for handcrafting\ntranslations, most manga never leave the domestic Japanese market. Automatic\nmanga translation is a promising potential solution. However, it is a budding\nand underdeveloped field and presents complexities even greater than those\nfound in standard translation due to the need to effectively incorporate visual\nelements into the translation process to resolve ambiguities. In this work, we\ninvestigate to what extent multimodal large language models (LLMs) can provide\neffective manga translation, thereby assisting manga authors and publishers in\nreaching wider audiences. Specifically, we propose a methodology that leverages\nthe vision component of multimodal LLMs to improve translation quality and\nevaluate the impact of translation unit size, context length, and propose a\ntoken efficient approach for manga translation. Moreover, we introduce a new\nevaluation dataset -- the first parallel Japanese-Polish manga translation\ndataset -- as part of a benchmark to be used in future research. Finally, we\ncontribute an open-source software suite, enabling others to benchmark LLMs for\nmanga translation. Our findings demonstrate that our proposed methods achieve\nstate-of-the-art results for Japanese-English translation and set a new\nstandard for Japanese-Polish.", "paper_summary_zh": "\u7531\u65bc\u624b\u5de5\u7ffb\u8b6f\u9700\u8981\u5927\u91cf\u6642\u9593\u548c\u7cbe\u529b\uff0c\u5927\u591a\u6578\u6f2b\u756b\u5f9e\u672a\u96e2\u958b\u65e5\u672c\u570b\u5167\u5e02\u5834\u3002\u81ea\u52d5\u6f2b\u756b\u7ffb\u8b6f\u662f\u4e00\u500b\u5f88\u6709\u524d\u666f\u7684\u6f5b\u5728\u89e3\u6c7a\u65b9\u6848\u3002\u7136\u800c\uff0c\u5b83\u662f\u4e00\u500b\u65b0\u8208\u4e14\u4e0d\u767c\u9054\u7684\u9818\u57df\uff0c\u4e26\u4e14\u7531\u65bc\u9700\u8981\u6709\u6548\u5730\u5c07\u8996\u89ba\u5143\u7d20\u7d0d\u5165\u7ffb\u8b6f\u904e\u7a0b\u4e2d\u4ee5\u89e3\u6c7a\u6b67\u7fa9\uff0c\u56e0\u6b64\u6bd4\u6a19\u6e96\u7ffb\u8b6f\u4e2d\u7684\u8907\u96dc\u6027\u66f4\u5927\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u591a\u5927\u7a0b\u5ea6\u4e0a\u53ef\u4ee5\u63d0\u4f9b\u6709\u6548\u7684\u6f2b\u756b\u7ffb\u8b6f\uff0c\u5f9e\u800c\u5354\u52a9\u6f2b\u756b\u4f5c\u8005\u548c\u51fa\u7248\u5546\u63a5\u89f8\u66f4\u5ee3\u6cdb\u7684\u53d7\u773e\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u5229\u7528\u591a\u6a21\u614b LLM \u7684\u8996\u89ba\u7d44\u6210\u90e8\u5206\u7684\u65b9\u6cd5\u4f86\u63d0\u9ad8\u7ffb\u8b6f\u54c1\u8cea\uff0c\u4e26\u8a55\u4f30\u7ffb\u8b6f\u55ae\u5143\u5927\u5c0f\u3001\u4e0a\u4e0b\u6587\u9577\u5ea6\u548c\u63d0\u51fa\u6f2b\u756b\u7ffb\u8b6f\u7684\u4ee3\u5e63\u6709\u6548\u65b9\u6cd5\u7684\u5f71\u97ff\u3002\u6b64\u5916\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u65b0\u7684\u8a55\u4f30\u8cc7\u6599\u96c6\u2014\u2014\u7b2c\u4e00\u500b\u65e5\u8a9e-\u6ce2\u862d\u8a9e\u6f2b\u756b\u7ffb\u8b6f\u5e73\u884c\u8cc7\u6599\u96c6\u2014\u2014\u4f5c\u70ba\u672a\u4f86\u7814\u7a76\u4e2d\u4f7f\u7528\u7684\u57fa\u6e96\u7684\u4e00\u90e8\u5206\u3002\u6700\u5f8c\uff0c\u6211\u5011\u8ca2\u737b\u4e86\u4e00\u500b\u958b\u6e90\u8edf\u9ad4\u5957\u4ef6\uff0c\u8b93\u5176\u4ed6\u4eba\u53ef\u4ee5\u5c0d LLM \u9032\u884c\u6f2b\u756b\u7ffb\u8b6f\u57fa\u6e96\u6e2c\u8a66\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u8868\u660e\uff0c\u6211\u5011\u63d0\u51fa\u7684\u65b9\u6cd5\u9054\u5230\u4e86\u65e5\u8a9e-\u82f1\u8a9e\u7ffb\u8b6f\u7684\u6700\u65b0\u7d50\u679c\uff0c\u4e26\u70ba\u65e5\u8a9e-\u6ce2\u862d\u8a9e\u8a2d\u5b9a\u4e86\u65b0\u7684\u6a19\u6e96\u3002", "author": "Philip Lippmann et.al.", "authors": "Philip Lippmann, Konrad Skublicki, Joshua Tanner, Shonosuke Ishiwatari, Jie Yang", "id": "2411.02589v1", "paper_url": "http://arxiv.org/abs/2411.02589v1", "repo": "null"}}