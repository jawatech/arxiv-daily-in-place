{"2405.16879": {"publish_time": "2024-05-27", "title": "Unsupervised Generative Feature Transformation via Graph Contrastive Pre-training and Multi-objective Fine-tuning", "paper_summary": "Feature transformation is to derive a new feature set from original features\nto augment the AI power of data. In many science domains such as material\nperformance screening, while feature transformation can model material formula\ninteractions and compositions and discover performance drivers, supervised\nlabels are collected from expensive and lengthy experiments. This issue\nmotivates an Unsupervised Feature Transformation Learning (UFTL) problem. Prior\nliterature, such as manual transformation, supervised feedback guided search,\nand PCA, either relies on domain knowledge or expensive supervised feedback, or\nsuffers from large search space, or overlooks non-linear feature-feature\ninteractions. UFTL imposes a major challenge on existing methods: how to design\na new unsupervised paradigm that captures complex feature interactions and\navoids large search space? To fill this gap, we connect graph, contrastive, and\ngenerative learning to develop a measurement-pretrain-finetune paradigm for\nUFTL. For unsupervised feature set utility measurement, we propose a feature\nvalue consistency preservation perspective and develop a mean discounted\ncumulative gain like unsupervised metric to evaluate feature set utility. For\nunsupervised feature set representation pretraining, we regard a feature set as\na feature-feature interaction graph, and develop an unsupervised graph\ncontrastive learning encoder to embed feature sets into vectors. For generative\ntransformation finetuning, we regard a feature set as a feature cross sequence\nand feature transformation as sequential generation. We develop a deep\ngenerative feature transformation model that coordinates the pretrained feature\nset encoder and the gradient information extracted from a feature set utility\nevaluator to optimize a transformed feature generator.", "paper_summary_zh": "\u7279\u5fb5\u8f49\u63db\u662f\u5f9e\u539f\u59cb\u7279\u5fb5\u4e2d\u884d\u751f\u4e00\u5957\u65b0\u7684\u7279\u5fb5\uff0c\u4ee5\u589e\u5f37\u8cc7\u6599\u7684 AI \u80fd\u529b\u3002\u5728\u8a31\u591a\u79d1\u5b78\u9818\u57df\u4e2d\uff0c\u4f8b\u5982\u6750\u6599\u6548\u80fd\u7be9\u9078\uff0c\u7279\u5fb5\u8f49\u63db\u53ef\u4ee5\u5efa\u6a21\u6750\u6599\u914d\u65b9\u4ea4\u4e92\u4f5c\u7528\u548c\u7d44\u6210\uff0c\u4e26\u627e\u51fa\u6548\u80fd\u9a45\u52d5\u56e0\u7d20\uff0c\u4f46\u76e3\u7763\u6a19\u7c64\u662f\u5f9e\u6602\u8cb4\u4e14\u6f2b\u9577\u7684\u5be6\u9a57\u4e2d\u6536\u96c6\u800c\u4f86\u7684\u3002\u6b64\u554f\u984c\u4fc3\u6210\u4e86\u7121\u76e3\u7763\u7279\u5fb5\u8f49\u63db\u5b78\u7fd2 (UFTL) \u554f\u984c\u3002\u5148\u524d\u7684\u6587\u737b\uff0c\u4f8b\u5982\u624b\u52d5\u8f49\u63db\u3001\u76e3\u7763\u56de\u994b\u5f15\u5c0e\u641c\u5c0b\u548c PCA\uff0c\u4f9d\u8cf4\u65bc\u9818\u57df\u77e5\u8b58\u6216\u6602\u8cb4\u7684\u76e3\u7763\u56de\u994b\uff0c\u6216\u56e0\u641c\u5c0b\u7a7a\u9593\u904e\u5927\u800c\u53d7\u82e6\uff0c\u6216\u5ffd\u7565\u975e\u7dda\u6027\u7279\u5fb5\u8207\u7279\u5fb5\u4e4b\u9593\u7684\u4ea4\u4e92\u4f5c\u7528\u3002UFTL \u5c0d\u73fe\u6709\u65b9\u6cd5\u63d0\u51fa\u4e86\u91cd\u5927\u6311\u6230\uff1a\u5982\u4f55\u8a2d\u8a08\u4e00\u500b\u65b0\u7684\u7121\u76e3\u7763\u7bc4\u4f8b\uff0c\u4ee5\u6355\u6349\u8907\u96dc\u7684\u7279\u5fb5\u4ea4\u4e92\u4f5c\u7528\u4e26\u907f\u514d\u5927\u7684\u641c\u5c0b\u7a7a\u9593\uff1f\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u5c07\u5716\u5f62\u3001\u5c0d\u6bd4\u548c\u751f\u6210\u5f0f\u5b78\u7fd2\u806f\u7e6b\u8d77\u4f86\uff0c\u70ba UFTL \u958b\u767c\u4e00\u500b\u6e2c\u91cf\u9810\u8a13\u7df4\u5fae\u8abf\u7bc4\u4f8b\u3002\u5c0d\u65bc\u7121\u76e3\u7763\u7279\u5fb5\u96c6\u6548\u7528\u6e2c\u91cf\uff0c\u6211\u5011\u63d0\u51fa\u7279\u5fb5\u503c\u4e00\u81f4\u6027\u4fdd\u5b58\u89c0\u9ede\uff0c\u4e26\u958b\u767c\u4e00\u500b\u985e\u4f3c\u65bc\u7121\u76e3\u7763\u6307\u6a19\u7684\u5e73\u5747\u6298\u73fe\u7d2f\u7a4d\u589e\u76ca\uff0c\u4ee5\u8a55\u4f30\u7279\u5fb5\u96c6\u6548\u7528\u3002\u5c0d\u65bc\u7121\u76e3\u7763\u7279\u5fb5\u96c6\u8868\u793a\u9810\u8a13\u7df4\uff0c\u6211\u5011\u5c07\u7279\u5fb5\u96c6\u8996\u70ba\u7279\u5fb5\u8207\u7279\u5fb5\u4ea4\u4e92\u4f5c\u7528\u5716\uff0c\u4e26\u958b\u767c\u4e00\u500b\u7121\u76e3\u7763\u5716\u5f62\u5c0d\u6bd4\u5b78\u7fd2\u7de8\u78bc\u5668\uff0c\u5c07\u7279\u5fb5\u96c6\u5d4c\u5165\u5230\u5411\u91cf\u4e2d\u3002\u5c0d\u65bc\u751f\u6210\u5f0f\u8f49\u63db\u5fae\u8abf\uff0c\u6211\u5011\u5c07\u7279\u5fb5\u96c6\u8996\u70ba\u7279\u5fb5\u4ea4\u53c9\u5e8f\u5217\uff0c\u4e26\u5c07\u7279\u5fb5\u8f49\u63db\u8996\u70ba\u5e8f\u5217\u751f\u6210\u3002\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b\u6df1\u5ea6\u751f\u6210\u5f0f\u7279\u5fb5\u8f49\u63db\u6a21\u578b\uff0c\u8a72\u6a21\u578b\u5354\u8abf\u9810\u8a13\u7df4\u7684\u7279\u5fb5\u96c6\u7de8\u78bc\u5668\u548c\u5f9e\u7279\u5fb5\u96c6\u6548\u7528\u8a55\u4f30\u5668\u4e2d\u63d0\u53d6\u7684\u68af\u5ea6\u8cc7\u8a0a\uff0c\u4ee5\u6700\u4f73\u5316\u8f49\u63db\u7684\u7279\u5fb5\u7522\u751f\u5668\u3002", "author": "Wangyang Ying et.al.", "authors": "Wangyang Ying, Dongjie Wang, Xuanming Hu, Yuanchun Zhou, Charu C. Aggarwal, Yanjie Fu", "id": "2405.16879v1", "paper_url": "http://arxiv.org/abs/2405.16879v1", "repo": "null"}}