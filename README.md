# arxiv-daily
 Automated deployment @ 2024-05-08 12:50:13 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-05-07**|**QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving**|Yujun Lin et.al.|[2405.04532v1](http://arxiv.org/abs/2405.04532v1)|[link](https://github.com/mit-han-lab/qserve)|
|**2024-05-07**|**NaturalCodeBench: Examining Coding Performance Mismatch on HumanEval and Natural User Prompts**|Shudan Zhang et.al.|[2405.04520v1](http://arxiv.org/abs/2405.04520v1)|null|
|**2024-05-07**|**xLSTM: Extended Long Short-Term Memory**|Maximilian Beck et.al.|[2405.04517v1](http://arxiv.org/abs/2405.04517v1)|null|
|**2024-05-07**|**A Transformer with Stack Attention**|Jiaoda Li et.al.|[2405.04515v1](http://arxiv.org/abs/2405.04515v1)|[link](https://github.com/rycolab/stack-transformer)|
|**2024-05-07**|**Switchable Decision: Dynamic Neural Generation Networks**|Shujian Zhang et.al.|[2405.04513v1](http://arxiv.org/abs/2405.04513v1)|null|
|**2024-05-07**|**Toward In-Context Teaching: Adapting Examples to Students' Misconceptions**|Alexis Ross et.al.|[2405.04495v1](http://arxiv.org/abs/2405.04495v1)|null|
|**2024-05-07**|**TorchDriveEnv: A Reinforcement Learning Benchmark for Autonomous Driving with Reactive, Realistic, and Diverse Non-Playable Characters**|Jonathan Wilder Lavington et.al.|[2405.04491v1](http://arxiv.org/abs/2405.04491v1)|null|
|**2024-05-07**|**Towards Continual Knowledge Graph Embedding via Incremental Distillation**|Jiajun Liu et.al.|[2405.04453v1](http://arxiv.org/abs/2405.04453v1)|[link](https://github.com/seukgcode/incde)|
|**2024-05-07**|**POV Learning: Individual Alignment of Multimodal Models using Human Perception**|Simon Werner et.al.|[2405.04443v1](http://arxiv.org/abs/2405.04443v1)|null|
|**2024-05-07**|**AugmenTory: A Fast and Flexible Polygon Augmentation Library**|Tanaz Ghahremani et.al.|[2405.04442v1](http://arxiv.org/abs/2405.04442v1)|null|
|**2024-05-07**|**DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model**|DeepSeek-AI et.al.|[2405.04434v1](http://arxiv.org/abs/2405.04434v1)|[link](https://github.com/deepseek-ai/deepseek-v2)|
|**2024-05-07**|**Vision Mamba: A Comprehensive Survey and Taxonomy**|Xiao Liu et.al.|[2405.04404v1](http://arxiv.org/abs/2405.04404v1)|[link](https://github.com/lx6c78/vision-mamba-a-comprehensive-survey-and-taxonomy)|
|**2024-05-07**|**Pragmatist Intelligence: Where the Principle of Usefulness Can Take ANNs**|Antonio Bikić et.al.|[2405.04386v1](http://arxiv.org/abs/2405.04386v1)|null|
|**2024-05-07**|**Leveraging LSTM and GAN for Modern Malware Detection**|Ishita Gupta et.al.|[2405.04373v1](http://arxiv.org/abs/2405.04373v1)|null|
|**2024-05-07**|**Explainable machine learning for predicting shellfish toxicity in the Adriatic Sea using long-term monitoring data of HABs**|Martin Marzidovšek et.al.|[2405.04372v1](http://arxiv.org/abs/2405.04372v1)|null|
|**2024-05-07**|**Global Scale Self-Supervised Channel Charting with Sensor Fusion**|Omid Esrafilian et.al.|[2405.04357v1](http://arxiv.org/abs/2405.04357v1)|null|
|**2024-05-07**|**Revisiting character-level adversarial attacks**|Elias Abad Rocamora et.al.|[2405.04346v1](http://arxiv.org/abs/2405.04346v1)|[link](https://github.com/lions-epfl/charmer)|
|**2024-05-07**|**Temporal and Heterogeneous Graph Neural Network for Remaining Useful Life Prediction**|Zhihao Wen et.al.|[2405.04336v1](http://arxiv.org/abs/2405.04336v1)|null|
|**2024-05-07**|**A Fourth Wave of Open Data? Exploring the Spectrum of Scenarios for Open Data and Generative AI**|Hannah Chafetz et.al.|[2405.04333v1](http://arxiv.org/abs/2405.04333v1)|null|
|**2024-05-07**|**Deception in Reinforced Autonomous Agents: The Unconventional Rabbit Hat Trick in Legislation**|Atharvan Dogra et.al.|[2405.04325v1](http://arxiv.org/abs/2405.04325v1)|null|
|**2024-05-07**|**Granite Code Models: A Family of Open Foundation Models for Code Intelligence**|Mayank Mishra et.al.|[2405.04324v1](http://arxiv.org/abs/2405.04324v1)|[link](https://github.com/ibm-granite/granite-code-models)|
|**2024-05-07**|**Beyond human subjectivity and error: a novel AI grading system**|Alexandra Gobrecht et.al.|[2405.04323v1](http://arxiv.org/abs/2405.04323v1)|null|
|**2024-05-07**|**Cross-IQA: Unsupervised Learning for Image Quality Assessment**|Zhen Zhang et.al.|[2405.04311v1](http://arxiv.org/abs/2405.04311v1)|null|
|**2024-05-07**|**Improving Offline Reinforcement Learning with Inaccurate Simulators**|Yiwen Hou et.al.|[2405.04307v1](http://arxiv.org/abs/2405.04307v1)|null|
|**2024-05-07**|**A New Dataset and Comparative Study for Aphid Cluster Detection and Segmentation in Sorghum Fields**|Raiyan Rahman et.al.|[2405.04305v1](http://arxiv.org/abs/2405.04305v1)|null|
|**2024-05-07**|**Accelerating Speculative Decoding using Dynamic Speculation Length**|Jonathan Mamou et.al.|[2405.04304v1](http://arxiv.org/abs/2405.04304v1)|null|
|**2024-05-07**|**Behaviour Planning: A Toolkit for Diverse Planning**|Mustafa F Abdelwahed et.al.|[2405.04300v1](http://arxiv.org/abs/2405.04300v1)|null|
|**2024-05-07**|**Enhancing the Efficiency and Accuracy of Underlying Asset Reviews in Structured Finance: The Application of Multi-agent Framework**|Xiangpeng Wan et.al.|[2405.04294v1](http://arxiv.org/abs/2405.04294v1)|null|
|**2024-05-07**|**Mitigating Clickbait: An Approach to Spoiler Generation Using Multitask Learning**|Sayantan Pal et.al.|[2405.04292v1](http://arxiv.org/abs/2405.04292v1)|null|
|**2024-05-07**|**Who Wrote This? The Key to Zero-Shot LLM-Generated Text Detection Is GECScore**|Junchao Wu et.al.|[2405.04286v1](http://arxiv.org/abs/2405.04286v1)|null|
|**2024-05-07**|**On the Foundations of Earth and Climate Foundation Models**|Xiao Xiang Zhu et.al.|[2405.04285v1](http://arxiv.org/abs/2405.04285v1)|null|
|**2024-05-07**|**Generating Feature Vectors from Phonetic Transcriptions in Cross-Linguistic Data Formats**|Arne Rubehn et.al.|[2405.04271v1](http://arxiv.org/abs/2405.04271v1)|null|
|**2024-05-07**|**VAEneu: A New Avenue for VAE Application on Probabilistic Forecasting**|Alireza Koochali et.al.|[2405.04252v1](http://arxiv.org/abs/2405.04252v1)|null|
|**2024-05-07**|**Federated Learning for Cooperative Inference Systems: The Case of Early Exit Networks**|Caelin Kaplan et.al.|[2405.04249v1](http://arxiv.org/abs/2405.04249v1)|null|
|**2024-05-07**|**Exploring Correlations of Self-supervised Tasks for Graphs**|Taoran Fang et.al.|[2405.04245v1](http://arxiv.org/abs/2405.04245v1)|null|
|**2024-05-07**|**Iterative Experience Refinement of Software-Developing Agents**|Chen Qian et.al.|[2405.04219v1](http://arxiv.org/abs/2405.04219v1)|null|
|**2024-05-07**|**NL2Plan: Robust LLM-Driven Planning from Minimal Text Descriptions**|Elliot Gestrin et.al.|[2405.04215v1](http://arxiv.org/abs/2405.04215v1)|null|
|**2024-05-07**|**Green Tsetlin Redefining Efficiency in Tsetlin Machine Frameworks**|Sondre Glimsdal et.al.|[2405.04212v1](http://arxiv.org/abs/2405.04212v1)|null|
|**2024-05-07**|**NOVA: NoC-based Vector Unit for Mapping Attention Layers on a CNN Accelerator**|Mohit Upadhyay et.al.|[2405.04206v1](http://arxiv.org/abs/2405.04206v1)|null|
|**2024-05-07**|**FedStale: leveraging stale client updates in federated learning**|Angelo Rodio et.al.|[2405.04171v1](http://arxiv.org/abs/2405.04171v1)|null|
|**2024-05-07**|**D-NLP at SemEval-2024 Task 2: Evaluating Clinical Inference Capabilities of Large Language Models**|Duygu Altinok et.al.|[2405.04170v1](http://arxiv.org/abs/2405.04170v1)|null|
|**2024-05-07**|**LingML: Linguistic-Informed Machine Learning for Enhanced Fake News Detection**|Jasraj Singh et.al.|[2405.04165v1](http://arxiv.org/abs/2405.04165v1)|null|
|**2024-05-07**|**MEDVOC: Vocabulary Adaptation for Fine-tuning Pre-trained Language Models on Medical Text Summarization**|Gunjan Balde et.al.|[2405.04163v1](http://arxiv.org/abs/2405.04163v1)|[link](https://github.com/gb-kgp/medvoc)|
|**2024-05-07**|**A Causal Explainable Guardrails for Large Language Models**|Zhixuan Chu et.al.|[2405.04160v1](http://arxiv.org/abs/2405.04160v1)|null|
|**2024-05-07**|**GPT-Enabled Cybersecurity Training: A Tailored Approach for Effective Awareness**|Nabil Al-Dhamari et.al.|[2405.04138v1](http://arxiv.org/abs/2405.04138v1)|null|
|**2024-05-07**|**Enriched BERT Embeddings for Scholarly Publication Classification**|Benjamin Wolff et.al.|[2405.04136v1](http://arxiv.org/abs/2405.04136v1)|null|
|**2024-05-07**|**In-context Learning for Automated Driving Scenarios**|Ziqi Zhou et.al.|[2405.04135v1](http://arxiv.org/abs/2405.04135v1)|null|
|**2024-05-07**|**Fine-grained Speech Sentiment Analysis in Chinese Psychological Support Hotlines Based on Large-scale Pre-trained Model**|Zhonglong Chen et.al.|[2405.04128v1](http://arxiv.org/abs/2405.04128v1)|[link](https://github.com/czl0914/psy_hotline_analysis)|
|**2024-05-07**|**Comparative Study of Recurrent Neural Networks for Virtual Analog Audio Effects Modeling**|Riccardo Simionato et.al.|[2405.04124v1](http://arxiv.org/abs/2405.04124v1)|null|
|**2024-05-07**|**Policy Learning with a Language Bottleneck**|Megha Srivastava et.al.|[2405.04118v1](http://arxiv.org/abs/2405.04118v1)|[link](https://github.com/meghabyte/bottleneck)|
|**2024-05-07**|**A2-DIDM: Privacy-preserving Accumulator-enabled Auditing for Distributed Identity of DNN Model**|Tianxiu Xie et.al.|[2405.04108v1](http://arxiv.org/abs/2405.04108v1)|null|
|**2024-05-07**|**Continual Learning in the Presence of Repetition**|Hamed Hemati et.al.|[2405.04101v1](http://arxiv.org/abs/2405.04101v1)|null|
|**2024-05-07**|**Unmasking Illusions: Understanding Human Perception of Audiovisual Deepfakes**|Ammarah Hashmi et.al.|[2405.04097v1](http://arxiv.org/abs/2405.04097v1)|null|
|**2024-05-07**|**Going Proactive and Explanatory Against Malware Concept Drift**|Yiling He et.al.|[2405.04095v1](http://arxiv.org/abs/2405.04095v1)|null|
|**2024-05-07**|**DCNN: Dual Cross-current Neural Networks Realized Using An Interactive Deep Learning Discriminator for Fine-grained Objects**|Da Fu et.al.|[2405.04093v1](http://arxiv.org/abs/2405.04093v1)|null|
|**2024-05-07**|**Optimizing Language Model's Reasoning Abilities with Weak Supervision**|Yongqi Tong et.al.|[2405.04086v1](http://arxiv.org/abs/2405.04086v1)|null|
|**2024-05-07**|**Counterfactual and Semifactual Explanations in Abstract Argumentation: Formal Foundations, Complexity and Computation**|Gianvincenzo Alfano et.al.|[2405.04081v1](http://arxiv.org/abs/2405.04081v1)|null|
|**2024-05-07**|**WISER: Weak supervISion and supErvised Representation learning to improve drug response prediction in cancer**|Kumar Shubham et.al.|[2405.04078v1](http://arxiv.org/abs/2405.04078v1)|null|
|**2024-05-07**|**A simple theory for training response of deep neural networks**|Kenichi Nakazato et.al.|[2405.04074v1](http://arxiv.org/abs/2405.04074v1)|null|
|**2024-05-07**|**FlashBack:Efficient Retrieval-Augmented Language Modeling for Long Context Inference**|Runheng Liu et.al.|[2405.04065v1](http://arxiv.org/abs/2405.04065v1)|null|
|**2024-05-07**|**Evaluating Text Summaries Generated by Large Language Models Using OpenAI's GPT**|Hassan Shakil et.al.|[2405.04053v1](http://arxiv.org/abs/2405.04053v1)|null|
|**2024-05-07**|**Learning Linear Block Error Correction Codes**|Yoni Choukroun et.al.|[2405.04050v1](http://arxiv.org/abs/2405.04050v1)|[link](https://github.com/yonilc/e2e_dc_ecct)|
|**2024-05-07**|**Philosophy of Cognitive Science in the Age of Deep Learning**|Raphaël Millière et.al.|[2405.04048v1](http://arxiv.org/abs/2405.04048v1)|null|
|**2024-05-07**|**Feature Map Convergence Evaluation for Functional Module**|Ludan Zhang et.al.|[2405.04041v1](http://arxiv.org/abs/2405.04041v1)|null|
|**2024-05-07**|**Utilizing GPT to Enhance Text Summarization: A Strategy to Minimize Hallucinations**|Hassan Shakil et.al.|[2405.04039v1](http://arxiv.org/abs/2405.04039v1)|null|
|**2024-05-07**|**Locally Differentially Private In-Context Learning**|Chunyan Zheng et.al.|[2405.04032v1](http://arxiv.org/abs/2405.04032v1)|null|
|**2024-05-07**|**Certified Policy Verification and Synthesis for MDPs under Distributional Reach-avoidance Properties**|S. Akshay et.al.|[2405.04015v1](http://arxiv.org/abs/2405.04015v1)|null|
|**2024-05-07**|**Structured Click Control in Transformer-based Interactive Segmentation**|Long Xu et.al.|[2405.04009v1](http://arxiv.org/abs/2405.04009v1)|[link](https://github.com/hahamyt/scc)|
|**2024-05-07**|**Sketch Then Generate: Providing Incremental User Feedback and Guiding LLM Code Generation through Language-Oriented Code Sketches**|Chen Zhu-Tian et.al.|[2405.03998v1](http://arxiv.org/abs/2405.03998v1)|null|
|**2024-05-07**|**TrimCaching: Parameter-sharing AI Model Caching in Wireless Edge Networks**|Guanqiao Qu et.al.|[2405.03990v1](http://arxiv.org/abs/2405.03990v1)|null|
|**2024-05-07**|**Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application**|Jian Jia et.al.|[2405.03988v1](http://arxiv.org/abs/2405.03988v1)|null|
|**2024-05-07**|**Factors Influencing User Willingness To Use SORA**|Gustave Florentin Nkoulou Mvondo et.al.|[2405.03986v1](http://arxiv.org/abs/2405.03986v1)|null|
|**2024-05-07**|**TBNet: A Neural Architectural Defense Framework Facilitating DNN Model Protection in Trusted Execution Environments**|Ziyu Liu et.al.|[2405.03974v1](http://arxiv.org/abs/2405.03974v1)|null|
|**2024-05-07**|**ERATTA: Extreme RAG for Table To Answers with Large Language Models**|Sohini Roychowdhury et.al.|[2405.03963v1](http://arxiv.org/abs/2405.03963v1)|null|
|**2024-05-07**|**ESIHGNN: Event-State Interactions Infused Heterogeneous Graph Neural Network for Conversational Emotion Recognition**|Xupeng Zha et.al.|[2405.03960v1](http://arxiv.org/abs/2405.03960v1)|null|
|**2024-05-07**|**Simple Drop-in LoRA Conditioning on Attention Layers Will Improve Your Diffusion Model**|Joo Young Choi et.al.|[2405.03958v1](http://arxiv.org/abs/2405.03958v1)|null|
|**2024-05-07**|**HAFFormer: A Hierarchical Attention-Free Framework for Alzheimer's Disease Detection From Spontaneous Speech**|Zhongren Dong et.al.|[2405.03952v1](http://arxiv.org/abs/2405.03952v1)|null|
|**2024-05-07**|**Predictive Modeling with Temporal Graphical Representation on Electronic Health Records**|Jiayuan Chen et.al.|[2405.03943v1](http://arxiv.org/abs/2405.03943v1)|[link](https://github.com/the-real-jerrychen/trans)|
|**2024-05-07**|**Long Context Alignment with Short Instructions and Synthesized Positions**|Wenhao Wu et.al.|[2405.03939v1](http://arxiv.org/abs/2405.03939v1)|null|
|**2024-05-07**|**CleanGraph: Human-in-the-loop Knowledge Graph Refinement and Completion**|Tyler Bikaun et.al.|[2405.03932v1](http://arxiv.org/abs/2405.03932v1)|[link](https://github.com/nlp-tlp/cleangraph)|
|**2024-05-07**|**Unicorn: U-Net for Sea Ice Forecasting with Convolutional Neural Ordinary Differential Equations**|Jaesung Park et.al.|[2405.03929v1](http://arxiv.org/abs/2405.03929v1)|null|
|**2024-05-07**|**A Roadmap for Multilingual, Multimodal Domain Independent Deception Detection**|Dainis Boumber et.al.|[2405.03920v1](http://arxiv.org/abs/2405.03920v1)|null|
|**2024-05-06**|**OmniActions: Predicting Digital Actions in Response to Real-World Multimodal Sensory Inputs with LLMs**|Jiahao Nick Li et.al.|[2405.03901v1](http://arxiv.org/abs/2405.03901v1)|null|
|**2024-05-06**|**Out-of-Distribution Adaptation in Offline RL: Counterfactual Reasoning via Causal Normalizing Flows**|Minjae Cho et.al.|[2405.03892v1](http://arxiv.org/abs/2405.03892v1)|null|
|**2024-05-06**|**Enhancing O-RAN Security: Evasion Attacks and Robust Defenses for Graph Reinforcement Learning-based Connection Management**|Ravikumar Balakrishnan et.al.|[2405.03891v1](http://arxiv.org/abs/2405.03891v1)|null|
|**2024-05-06**|**Trio-ViT: Post-Training Quantization and Acceleration for Softmax-Free Efficient Vision Transformer**|Huihong Shi et.al.|[2405.03882v1](http://arxiv.org/abs/2405.03882v1)|null|
|**2024-05-06**|**Investigating Personalized Driving Behaviors in Dilemma Zones: Analysis and Prediction of Stop-or-Go Decisions**|Ziye Qin et.al.|[2405.03873v1](http://arxiv.org/abs/2405.03873v1)|null|
|**2024-05-06**|**AI-Driven Frameworks for Enhancing Data Quality in Big Data Ecosystems: Error_Detection, Correction, and Metadata Integration**|Widad Elouataoui et.al.|[2405.03870v1](http://arxiv.org/abs/2405.03870v1)|null|
|**2024-05-06**|**Outlier Gradient Analysis: Efficiently Improving Deep Learning Model Performance via Hessian-Free Influence Functions**|Anshuman Chhabra et.al.|[2405.03869v1](http://arxiv.org/abs/2405.03869v1)|null|
|**2024-05-06**|**Learning Planning Abstractions from Language**|Weiyu Liu et.al.|[2405.03864v1](http://arxiv.org/abs/2405.03864v1)|null|
|**2024-05-06**|**Conformity, Confabulation, and Impersonation: Persona Inconstancy in Multi-Agent LLM Collaboration**|Razan Baltaji et.al.|[2405.03862v1](http://arxiv.org/abs/2405.03862v1)|null|
|**2024-05-06**|**VSA4VQA: Scaling a Vector Symbolic Architecture to Visual Question Answering on Natural Images**|Anna Penzkofer et.al.|[2405.03852v1](http://arxiv.org/abs/2405.03852v1)|null|
|**2024-05-06**|**Self-Improving Customer Review Response Generation Based on LLMs**|Guy Azov et.al.|[2405.03845v1](http://arxiv.org/abs/2405.03845v1)|null|
|**2024-05-06**|**A Novel Cross-band CSI Prediction Scheme for Multi-band Fingerprint based Localization**|Yuan Ruihao et.al.|[2405.03842v1](http://arxiv.org/abs/2405.03842v1)|null|
|**2024-05-06**|**Guylingo: The Republic of Guyana Creole Corpora**|Christopher Clarke et.al.|[2405.03832v1](http://arxiv.org/abs/2405.03832v1)|null|
|**2024-05-06**|**Organizing a Society of Language Models: Structures and Mechanisms for Enhanced Collective Intelligence**|Silvan Ferreira et.al.|[2405.03825v1](http://arxiv.org/abs/2405.03825v1)|null|
|**2024-05-06**|**Thoughtful Things: Building Human-Centric Smart Devices with Small Language Models**|Evan King et.al.|[2405.03821v1](http://arxiv.org/abs/2405.03821v1)|null|
|**2024-05-06**|**SocialFormer: Social Interaction Modeling with Edge-enhanced Heterogeneous Graph Transformers for Trajectory Prediction**|Zixu Wang et.al.|[2405.03809v1](http://arxiv.org/abs/2405.03809v1)|null|
|**2024-05-06**|**Synthetic Data from Diffusion Models Improve Drug Discovery Prediction**|Bing Hu et.al.|[2405.03799v1](http://arxiv.org/abs/2405.03799v1)|null|
|**2024-05-06**|**Detecting Anti-Semitic Hate Speech using Transformer-based Large Language Models**|Dengyi Liu et.al.|[2405.03794v1](http://arxiv.org/abs/2405.03794v1)|null|

#### Abstracts
##### **QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving**
2405.04532v1 by Yujun Lin, Haotian Tang, Shang Yang, Zhekai Zhang, Guangxuan Xiao, Chuang Gan, Song Han

Quantization can accelerate large language model (LLM) inference. Going
beyond INT8 quantization, the research community is actively exploring even
lower precision, such as INT4. Nonetheless, state-of-the-art INT4 quantization
techniques only accelerate low-batch, edge LLM inference, failing to deliver
performance gains in large-batch, cloud-based LLM serving. We uncover a
critical issue: existing INT4 quantization methods suffer from significant
runtime overhead (20-90%) when dequantizing either weights or partial sums on
GPUs. To address this challenge, we introduce QoQ, a W4A8KV4 quantization
algorithm with 4-bit weight, 8-bit activation, and 4-bit KV cache. QoQ stands
for quattuor-octo-quattuor, which represents 4-8-4 in Latin. QoQ is implemented
by the QServe inference library that achieves measured speedup. The key insight
driving QServe is that the efficiency of LLM serving on GPUs is critically
influenced by operations on low-throughput CUDA cores. Building upon this
insight, in QoQ algorithm, we introduce progressive quantization that can allow
low dequantization overhead in W4A8 GEMM. Additionally, we develop
SmoothAttention to effectively mitigate the accuracy degradation incurred by
4-bit KV quantization. In the QServe system, we perform compute-aware weight
reordering and take advantage of register-level parallelism to reduce
dequantization latency. We also make fused attention memory-bound, harnessing
the performance gain brought by KV4 quantization. As a result, QServe improves
the maximum achievable serving throughput of Llama-3-8B by 1.2x on A100, 1.4x
on L40S; and Qwen1.5-72B by 2.4x on A100, 3.5x on L40S, compared to
TensorRT-LLM. Remarkably, QServe on L40S GPU can achieve even higher throughput
than TensorRT-LLM on A100. Thus, QServe effectively reduces the dollar cost of
LLM serving by 3x. Code is available at https://github.com/mit-han-lab/qserve.

摘要：量化可以加速大型语言模型 (LLM) 推论。超越 INT8 量化，研究界正在积极探索更低精度，例如 INT4。尽管如此，最先进的 INT4 量化技术仅加速小批量边缘 LLM 推论，无法在大批量基于云的 LLM 服务中提供性能提升。我们发现了一个关键问题：现有的 INT4 量化方法在 GPU 上对权重或部分和进行去量化时会产生大量的运行时开销 (20-90%)。为了应对这一挑战，我们引入了 QoQ，一种具有 4 位权重、8 位激活和 4 位 KV 缓存的 W4A8KV4 量化算法。QoQ 代表 quattuor-octo-quattuor，在拉丁语中表示 4-8-4。QoQ 由 QServe 推论库实现，该库实现了已测量的加速。推动 QServe 的关键见解是，GPU 上的 LLM 服务的效率受到低吞吐量 CUDA 核心上的操作的严重影响。基于此见解，在 QoQ 算法中，我们引入了渐进式量化，可以在 W4A8 GEMM 中允许较低的去量化开销。此外，我们开发了 SmoothAttention 以有效减轻 4 位 KV 量化带来的精度下降。在 QServe 系统中，我们执行计算感知权重重新排序并利用寄存器级并行性来减少去量化延迟。我们还使融合注意内存受限，利用 KV4 量化带来的性能提升。结果，QServe 将 Llama-3-8B 的最大可实现服务吞吐量提高了 1.2 倍（A100 上），1.4 倍（L40S 上）；与 TensorRT-LLM 相比，Qwen1.5-72B 在 A100 上提高了 2.4 倍，在 L40S 上提高了 3.5 倍。值得注意的是，L40S GPU 上的 QServe 甚至可以实现比 A100 上的 TensorRT-LLM 更高的吞吐量。因此，QServe 有效地将 LLM 服务的美元成本降低了 3 倍。代码可在 https://github.com/mit-han-lab/qserve 获得。

##### **NaturalCodeBench: Examining Coding Performance Mismatch on HumanEval and Natural User Prompts**
2405.04520v1 by Shudan Zhang, Hanlin Zhao, Xiao Liu, Qinkai Zheng, Zehan Qi, Xiaotao Gu, Xiaohan Zhang, Yuxiao Dong, Jie Tang

Large language models (LLMs) have manifested strong ability to generate codes
for productive activities. However, current benchmarks for code synthesis, such
as HumanEval, MBPP, and DS-1000, are predominantly oriented towards
introductory tasks on algorithm and data science, insufficiently satisfying
challenging requirements prevalent in real-world coding. To fill this gap, we
propose NaturalCodeBench (NCB), a challenging code benchmark designed to mirror
the complexity and variety of scenarios in real coding tasks. NCB comprises 402
high-quality problems in Python and Java, meticulously selected from natural
user queries from online coding services, covering 6 different domains. Noting
the extraordinary difficulty in creating testing cases for real-world queries,
we also introduce a semi-automated pipeline to enhance the efficiency of test
case construction. Comparing with manual solutions, it achieves an efficiency
increase of more than 4 times. Our systematic experiments on 39 LLMs find that
performance gaps on NCB between models with close HumanEval scores could still
be significant, indicating a lack of focus on practical code synthesis
scenarios or over-specified optimization on HumanEval. On the other hand, even
the best-performing GPT-4 is still far from satisfying on NCB. The evaluation
toolkit and development set are available at
https://github.com/THUDM/NaturalCodeBench.

摘要：大型語言模型 (LLM) 已展現出產生代碼以進行生產活動的強大能力。然而，目前的程式碼合成基準，例如 HumanEval、MBPP 和 DS-1000，主要針對演算法和資料科學的入門任務，無法充分滿足現實世界編碼中普遍存在的挑戰性需求。為了填補這個空白，我們提出 NaturalCodeBench (NCB)，一個具有挑戰性的程式碼基準，旨在反映真實編碼任務中各種場景的複雜性和多樣性。NCB 包含 402 個高品質的 Python 和 Java 問題，從線上編碼服務的自然使用者查詢中仔細挑選，涵蓋 6 個不同的領域。注意到為現實世界的查詢建立測試案例的難度極高，我們還引入了一個半自動化管道來提高測試案例建構的效率。與手動解決方案相比，它的效率提升了 4 倍以上。我們對 39 個 LLM 進行的系統性實驗發現，在 HumanEval 得分接近的模型之間，NCB 上的效能差距仍然可能很大，這表示缺乏對實際程式碼合成場景的關注或對 HumanEval 的過度特定最佳化。另一方面，即使效能最佳的 GPT-4 在 NCB 上仍遠未令人滿意。評估工具包和開發組可以在 https://github.com/THUDM/NaturalCodeBench 取得。

##### **xLSTM: Extended Long Short-Term Memory**
2405.04517v1 by Maximilian Beck, Korbinian Pöppel, Markus Spanring, Andreas Auer, Oleksandra Prudnikova, Michael Kopp, Günter Klambauer, Johannes Brandstetter, Sepp Hochreiter

In the 1990s, the constant error carousel and gating were introduced as the
central ideas of the Long Short-Term Memory (LSTM). Since then, LSTMs have
stood the test of time and contributed to numerous deep learning success
stories, in particular they constituted the first Large Language Models (LLMs).
However, the advent of the Transformer technology with parallelizable
self-attention at its core marked the dawn of a new era, outpacing LSTMs at
scale. We now raise a simple question: How far do we get in language modeling
when scaling LSTMs to billions of parameters, leveraging the latest techniques
from modern LLMs, but mitigating known limitations of LSTMs? Firstly, we
introduce exponential gating with appropriate normalization and stabilization
techniques. Secondly, we modify the LSTM memory structure, obtaining: (i) sLSTM
with a scalar memory, a scalar update, and new memory mixing, (ii) mLSTM that
is fully parallelizable with a matrix memory and a covariance update rule.
Integrating these LSTM extensions into residual block backbones yields xLSTM
blocks that are then residually stacked into xLSTM architectures. Exponential
gating and modified memory structures boost xLSTM capabilities to perform
favorably when compared to state-of-the-art Transformers and State Space
Models, both in performance and scaling.

摘要：在 1990 年代，恆定錯誤迴旋木馬和閘控被引入為長期短期記憶 (LSTM) 的核心概念。從那時起，LSTM 經受住了時間的考驗，並為許多深度學習的成功案例做出了貢獻，特別是它們構成了第一批大型語言模型 (LLM)。然而，以可並行化自注意力為核心的 Transformer 技術的出現標誌著一個新時代的到來，其規模超過了 LSTM。我們現在提出一個簡單的問題：當我們將 LSTM 擴展到數十億個參數、利用現代 LLM 的最新技術，但減輕 LSTM 的已知限制時，我們在語言建模中能走多遠？首先，我們引入具有適當正規化和穩定技術的指數閘控。其次，我們修改 LSTM 記憶結構，獲得：(i) 帶有標量記憶體、標量更新和新記憶體混合的 sLSTM，(ii) mLSTM，它使用矩陣記憶體和協方差更新規則完全可並行化。將這些 LSTM 擴充整合到殘差塊主幹中會產生 xLSTM 塊，然後將它們殘差堆疊到 xLSTM 架構中。與最先進的 Transformer 和狀態空間模型相比，指數閘控和修改的記憶體結構提升了 xLSTM 的能力，在效能和擴充性方面表現出色。

##### **A Transformer with Stack Attention**
2405.04515v1 by Jiaoda Li, Jennifer C. White, Mrinmaya Sachan, Ryan Cotterell

Natural languages are believed to be (mildly) context-sensitive. Despite
underpinning remarkably capable large language models, transformers are unable
to model many context-free language tasks. In an attempt to address this
limitation in the modeling power of transformer-based language models, we
propose augmenting them with a differentiable, stack-based attention mechanism.
Our stack-based attention mechanism can be incorporated into any
transformer-based language model and adds a level of interpretability to the
model. We show that the addition of our stack-based attention mechanism enables
the transformer to model some, but not all, deterministic context-free
languages.

摘要：自然語言被認為是（輕微地）上下文相關的。儘管支撐著非常有能力的大型語言模型，但Transformer無法模擬許多無上下文語言任務。為了解決Transformer語言模型建模能力中的這個限制，我們建議使用可微分堆疊式注意力機制對它們進行擴充。我們的堆疊式注意力機制可以整合到任何基於Transformer的語言模型中，並為模型增加一層可解釋性。我們展示了加入我們的堆疊式注意力機制使Transformer能夠模擬一些，但不是全部，確定性的無上下文語言。

##### **Switchable Decision: Dynamic Neural Generation Networks**
2405.04513v1 by Shujian Zhang, Korawat Tanwisuth, Chengyue Gong, Pengcheng He, Mingyuan Zhou

Auto-regressive generation models achieve competitive performance across many
different NLP tasks such as summarization, question answering, and
classifications. However, they are also known for being slow in inference,
which makes them challenging to deploy in real-time applications. We propose a
switchable decision to accelerate inference by dynamically assigning
computation resources for each data instance. Automatically making decisions on
where to skip and how to balance quality and computation cost with constrained
optimization, our dynamic neural generation networks enforce the efficient
inference path and determine the optimized trade-off. Experiments across
question answering, summarization, and classification benchmarks show that our
method benefits from less computation cost during inference while keeping the
same accuracy. Extensive experiments and ablation studies demonstrate that our
method can be general, effective, and beneficial for many NLP tasks.

摘要：自動回歸生成模型在許多不同的 NLP 任務中實現了競爭效能，例如摘要、問答和分類。然而，它們也以推理緩慢而聞名，這使得它們難以部署在即時應用程式中。我們提出了一個可切換的決策，透過動態分配每個資料實例的運算資源來加速推理。我們的動態神經生成網路自動做出決策，決定在哪裡跳過以及如何平衡品質和運算成本與受限最佳化，強制執行有效的推理路徑並確定最佳化的權衡。在問答、摘要和分類基準上的實驗顯示，我們的模型在推理期間受益於較低的運算成本，同時保持相同的準確度。廣泛的實驗和消融研究表明，我們的模型可以適用於許多 NLP 任務，並對其有效且有益。

##### **Toward In-Context Teaching: Adapting Examples to Students' Misconceptions**
2405.04495v1 by Alexis Ross, Jacob Andreas

When a teacher provides examples for a student to study, these examples must
be informative, enabling a student to progress from their current state toward
a target concept or skill. Good teachers must therefore simultaneously infer
what students already know and adapt their teaching to students' changing state
of knowledge. There is increasing interest in using computational models,
particularly large language models, as pedagogical tools. As students, language
models in particular have shown a remarkable ability to adapt to new tasks
given small numbers of examples. But how effectively can these models adapt as
teachers to students of different types? To study this question, we introduce a
suite of models and evaluation methods we call AdapT. AdapT has two components:
(1) a collection of simulated Bayesian student models that can be used for
evaluation of automated teaching methods; (2) a platform for evaluation with
human students, to characterize the real-world effectiveness of these methods.
We additionally introduce (3) AToM, a new probabilistic model for adaptive
teaching that jointly infers students' past beliefs and optimizes for the
correctness of future beliefs. In evaluations of simulated students across
three learning domains (fraction arithmetic, English morphology, function
learning), AToM systematically outperforms LLM-based and standard Bayesian
teaching models. In human experiments, both AToM and LLMs outperform
non-adaptive random example selection. Our results highlight both the
difficulty of the adaptive teaching task and the potential of learned adaptive
models for solving it.

摘要：當老師提供範例供學生學習時，這些範例必須提供資訊，讓學生能從目前的狀態進步到目標概念或技能。因此，好老師必須同時推論出學生已經知道什麼，並根據學生知識的變化調整教學。使用計算模型（尤其是大型語言模型）作為教學工具的興趣與日俱增。特別是作為學生的語言模型，已經展現出驚人的能力，可以在給予少量範例的情況下適應新任務。但這些模型作為老師，能多有效地適應不同類型的學生？為了研究這個問題，我們提出了一套模型和評量方法，我們稱之為 AdapT。AdapT 有兩個組成部分：(1) 一組模擬 Bayesian 學生模型，可用於評量自動化教學方法；(2) 一個與真人學生一起評量的平台，用於描述這些方法的實際世界效能。我們另外提出 (3) AToM，一個新的機率模型，用於適應性教學，它會同時推論學生的過去信念，並針對未來信念的正確性進行最佳化。在三個學習領域（分數算術、英文形態學、函數學習）的模擬學生評量中，AToM 系統性地優於基於 LLM 和標準 Bayesian 的教學模型。在人體實驗中，AToM 和 LLM 都優於非適應性隨機範例選擇。我們的結果突顯了適應性教學任務的難度，以及學習適應性模型在解決此任務上的潛力。

##### **TorchDriveEnv: A Reinforcement Learning Benchmark for Autonomous Driving with Reactive, Realistic, and Diverse Non-Playable Characters**
2405.04491v1 by Jonathan Wilder Lavington, Ke Zhang, Vasileios Lioutas, Matthew Niedoba, Yunpeng Liu, Dylan Green, Saeid Naderiparizi, Xiaoxuan Liang, Setareh Dabiri, Adam Ścibior, Berend Zwartsenberg, Frank Wood

The training, testing, and deployment, of autonomous vehicles requires
realistic and efficient simulators. Moreover, because of the high variability
between different problems presented in different autonomous systems, these
simulators need to be easy to use, and easy to modify. To address these
problems we introduce TorchDriveSim and its benchmark extension TorchDriveEnv.
TorchDriveEnv is a lightweight reinforcement learning benchmark programmed
entirely in Python, which can be modified to test a number of different factors
in learned vehicle behavior, including the effect of varying kinematic models,
agent types, and traffic control patterns. Most importantly unlike many replay
based simulation approaches, TorchDriveEnv is fully integrated with a state of
the art behavioral simulation API. This allows users to train and evaluate
driving models alongside data driven Non-Playable Characters (NPC) whose
initializations and driving behavior are reactive, realistic, and diverse. We
illustrate the efficiency and simplicity of TorchDriveEnv by evaluating common
reinforcement learning baselines in both training and validation environments.
Our experiments show that TorchDriveEnv is easy to use, but difficult to solve.

摘要：自動駕駛車輛的訓練、測試和部署需要逼真且高效的模擬器。此外，由於不同自動系統中出現的不同問題之間存在高度可變性，因此這些模擬器需要易於使用且易於修改。為了解決這些問題，我們引入了 TorchDriveSim 及其基準延伸 TorchDriveEnv。TorchDriveEnv 是一個輕量級強化學習基準，完全使用 Python 編寫，可以修改以測試學習車輛行為中的許多不同因素，包括不同運動模型、代理類型和交通控制模式的影響。最重要的是，與許多基於重播的模擬方法不同，TorchDriveEnv 與最先進的行為模擬 API 完全整合。這使用戶能夠訓練和評估駕駛模型，同時使用數據驅動的非玩家角色 (NPC)，其初始化和駕駛行為具有反應性、真實性和多樣性。我們通過在訓練和驗證環境中評估常見的強化學習基準，來說明 TorchDriveEnv 的效率和簡潔性。我們的實驗表明，TorchDriveEnv 易於使用，但難以解決。

##### **Towards Continual Knowledge Graph Embedding via Incremental Distillation**
2405.04453v1 by Jiajun Liu, Wenjun Ke, Peng Wang, Ziyu Shang, Jinhua Gao, Guozheng Li, Ke Ji, Yanhe Liu

Traditional knowledge graph embedding (KGE) methods typically require
preserving the entire knowledge graph (KG) with significant training costs when
new knowledge emerges. To address this issue, the continual knowledge graph
embedding (CKGE) task has been proposed to train the KGE model by learning
emerging knowledge efficiently while simultaneously preserving decent old
knowledge. However, the explicit graph structure in KGs, which is critical for
the above goal, has been heavily ignored by existing CKGE methods. On the one
hand, existing methods usually learn new triples in a random order, destroying
the inner structure of new KGs. On the other hand, old triples are preserved
with equal priority, failing to alleviate catastrophic forgetting effectively.
In this paper, we propose a competitive method for CKGE based on incremental
distillation (IncDE), which considers the full use of the explicit graph
structure in KGs. First, to optimize the learning order, we introduce a
hierarchical strategy, ranking new triples for layer-by-layer learning. By
employing the inter- and intra-hierarchical orders together, new triples are
grouped into layers based on the graph structure features. Secondly, to
preserve the old knowledge effectively, we devise a novel incremental
distillation mechanism, which facilitates the seamless transfer of entity
representations from the previous layer to the next one, promoting old
knowledge preservation. Finally, we adopt a two-stage training paradigm to
avoid the over-corruption of old knowledge influenced by under-trained new
knowledge. Experimental results demonstrate the superiority of IncDE over
state-of-the-art baselines. Notably, the incremental distillation mechanism
contributes to improvements of 0.2%-6.5% in the mean reciprocal rank (MRR)
score.

摘要：<paragraph>傳統知識圖表嵌入 (KGE) 方法通常需要在出現新知識時保留整個知識圖表 (KG)，這會產生大量的訓練成本。為了解決這個問題，已經提出持續知識圖表嵌入 (CKGE) 任務，透過有效率地學習新興知識並同時保留良好的舊知識，來訓練 KGE 模型。然而，現有的 CKGE 方法嚴重忽略了 KG 中對上述目標至關重要的明確圖表結構。一方面，現有方法通常以隨機順序學習新的三元組，破壞了新 KG 的內部結構。另一方面，舊的三元組以同等的優先順序被保留，無法有效減輕災難性遺忘。在本文中，我們提出了一個基於增量蒸餾 (IncDE) 的 CKGE 競爭方法，它考慮了 KG 中明確圖表結構的充分利用。首先，為了優化學習順序，我們引入了一種分層策略，對新的三元組進行分層學習的排序。透過同時使用層間和層內順序，新的三元組會根據圖表結構特徵分組到不同的層中。其次，為了有效保留舊知識，我們設計了一種新的增量蒸餾機制，它促進了實體表示從前一層到下一層的無縫傳遞，促進了舊知識的保留。最後，我們採用兩階段訓練範例，以避免受訓練不足的新知識影響而導致舊知識過度損壞。實驗結果證明了 IncDE 優於最先進的基準。值得注意的是，增量蒸餾機制有助於平均倒數排名 (MRR) 分數提高 0.2%-6.5%。</paragraph>

##### **POV Learning: Individual Alignment of Multimodal Models using Human Perception**
2405.04443v1 by Simon Werner, Katharina Christ, Laura Bernardy, Marion G. Müller, Achim Rettinger

Aligning machine learning systems with human expectations is mostly attempted
by training with manually vetted human behavioral samples, typically explicit
feedback. This is done on a population level since the context that is
capturing the subjective Point-Of-View (POV) of a concrete person in a specific
situational context is not retained in the data. However, we argue that
alignment on an individual level can boost the subjective predictive
performance for the individual user interacting with the system considerably.
Since perception differs for each person, the same situation is observed
differently. Consequently, the basis for decision making and the subsequent
reasoning processes and observable reactions differ. We hypothesize that
individual perception patterns can be used for improving the alignment on an
individual level. We test this, by integrating perception information into
machine learning systems and measuring their predictive performance
wrt.~individual subjective assessments. For our empirical study, we collect a
novel data set of multimodal stimuli and corresponding eye tracking sequences
for the novel task of Perception-Guided Crossmodal Entailment and tackle it
with our Perception-Guided Multimodal Transformer. Our findings suggest that
exploiting individual perception signals for the machine learning of subjective
human assessments provides a valuable cue for individual alignment. It does not
only improve the overall predictive performance from the point-of-view of the
individual user but might also contribute to steering AI systems towards every
person's individual expectations and values.

摘要：機器學習系統與人類預期的對齊，大多數是透過手動審查人類行為範例進行訓練，通常是明確的回饋。這是在人口層級進行的，因為在資料中並未保留捕捉具體個人在特定情境脈絡中的主觀觀點 (POV) 的脈絡。然而，我們主張在個人層級上的對齊可以大幅提升與系統互動的個別使用者主觀預測效能。由於每個人的感知不同，因此觀察到相同的情況時會有不同的看法。因此，決策制定的基礎和後續的推理程序和可觀察到的反應也會有所不同。我們假設可以利用個別的感知模式來改善個人層級上的對齊。我們透過將感知資訊整合到機器學習系統中並衡量其相對於個別主觀評估的預測效能，來測試這一點。對於我們的實證研究，我們收集了一組新穎的多模態刺激和對應的眼睛追蹤序列資料，用於感知導向的跨模態蘊涵的新穎任務，並使用我們的感知導向多模態轉換器來處理它。我們的研究結果表明，利用個別感知訊號進行主觀人類評估的機器學習，可提供有價值的個人對齊線索。它不僅可以從個別使用者的觀點改善整體預測效能，還可能有助於引導 AI 系統朝向每個人的個別期望和價值觀。

##### **AugmenTory: A Fast and Flexible Polygon Augmentation Library**
2405.04442v1 by Tanaz Ghahremani, Mohammad Hoseyni, Mohammad Javad Ahmadi, Pouria Mehrabi, Amirhossein Nikoofard

Data augmentation is a key technique for addressing the challenge of limited
datasets, which have become a major component in the training procedures of
image processing. Techniques such as geometric transformations and color space
adjustments have been thoroughly tested for their ability to artificially
expand training datasets and generate semi-realistic data for training
purposes. Data augmentation is the most important key to addressing the
challenge of limited datasets, which have become a major component of image
processing training procedures. Data augmentation techniques, such as geometric
transformations and color space adjustments, are thoroughly tested for their
ability to artificially expand training datasets and generate semi-realistic
data for training purposes. Polygons play a crucial role in instance
segmentation and have seen a surge in use across advanced models, such as
YOLOv8. Despite their growing popularity, the lack of specialized libraries
hampers the polygon-augmentation process. This paper introduces a novel
solution to this challenge, embodied in the newly developed AugmenTory library.
Notably, AugmenTory offers reduced computational demands in both time and space
compared to existing methods. Additionally, the library includes a
postprocessing thresholding feature. The AugmenTory package is publicly
available on GitHub, where interested users can access the source code:
https://github.com/Smartory/AugmenTory

摘要：資料擴充是解決有限資料集挑戰的一項關鍵技術，這已成為影像處理訓練程序中的主要組成部分。幾何轉換和色彩空間調整等技術已徹底測試其人工擴充訓練資料集和產生半擬真資料以進行訓練目的的能力。資料擴充是解決有限資料集挑戰最重要的關鍵，這已成為影像處理訓練程序的主要組成部分。資料擴充技術，例如幾何轉換和色彩空間調整，已徹底測試其人工擴充訓練資料集和產生半擬真資料以進行訓練目的的能力。多邊形在實例分割中扮演至關重要的角色，並已在 YOLOv8 等進階模型中廣泛使用。儘管它們越來越受歡迎，但缺乏專門的函式庫會阻礙多邊形擴充程序。本文介紹了解決此挑戰的一項創新方案，體現在新開發的 AugmenTory 函式庫中。值得注意的是，與現有方法相比，AugmenTory 在時間和空間上都降低了運算需求。此外，該函式庫還包含後處理閾值功能。AugmenTory 套件已在 GitHub 上公開，有興趣的使用者可以在其中存取原始程式碼：
https://github.com/Smartory/AugmenTory

##### **DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model**
2405.04434v1 by DeepSeek-AI

We present DeepSeek-V2, a strong Mixture-of-Experts (MoE) language model
characterized by economical training and efficient inference. It comprises 236B
total parameters, of which 21B are activated for each token, and supports a
context length of 128K tokens. DeepSeek-V2 adopts innovative architectures
including Multi-head Latent Attention (MLA) and DeepSeekMoE. MLA guarantees
efficient inference through significantly compressing the Key-Value (KV) cache
into a latent vector, while DeepSeekMoE enables training strong models at an
economical cost through sparse computation. Compared with DeepSeek 67B,
DeepSeek-V2 achieves significantly stronger performance, and meanwhile saves
42.5% of training costs, reduces the KV cache by 93.3%, and boosts the maximum
generation throughput to 5.76 times. We pretrain DeepSeek-V2 on a high-quality
and multi-source corpus consisting of 8.1T tokens, and further perform
Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) to fully unlock
its potential. Evaluation results show that, even with only 21B activated
parameters, DeepSeek-V2 and its chat versions still achieve top-tier
performance among open-source models. The model checkpoints are available at
"https://github.com/deepseek-ai/DeepSeek-V2".

摘要：我們提出 DeepSeek-V2，一種強大的混合專家 (MoE) 語言模型，其特點是經濟訓練和高效推論。它包含 236B 個總參數，其中 21B 個被激活用於每個符號，並支援 128K 個符號的上下文長度。DeepSeek-V2 採用創新的架構，包括多頭潛在注意力 (MLA) 和 DeepSeekMoE。MLA 透過將鍵值 (KV) 快取大幅壓縮到潛在向量中，來保證高效推論，而 DeepSeekMoE 透過稀疏計算，以經濟成本訓練強大的模型。與 DeepSeek 67B 相比，DeepSeek-V2 達到了顯著更強的效能，同時節省了 42.5% 的訓練成本，將 KV 快取減少了 93.3%，並將最大生成量提升至 5.76 倍。我們在一個由 8.1T 個符號組成的高品質和多來源語料庫上預訓練 DeepSeek-V2，並進一步執行監督微調 (SFT) 和強化學習 (RL) 以充分發揮其潛力。評估結果顯示，即使只有 21B 個已啟用的參數，DeepSeek-V2 及其聊天版本仍可在開源模型中達到頂級效能。模型檢查點可在「https://github.com/deepseek-ai/DeepSeek-V2」取得。

##### **Vision Mamba: A Comprehensive Survey and Taxonomy**
2405.04404v1 by Xiao Liu, Chenxu Zhang, Lei Zhang

State Space Model (SSM) is a mathematical model used to describe and analyze
the behavior of dynamic systems. This model has witnessed numerous applications
in several fields, including control theory, signal processing, economics and
machine learning. In the field of deep learning, state space models are used to
process sequence data, such as time series analysis, natural language
processing (NLP) and video understanding. By mapping sequence data to state
space, long-term dependencies in the data can be better captured. In
particular, modern SSMs have shown strong representational capabilities in NLP,
especially in long sequence modeling, while maintaining linear time complexity.
Notably, based on the latest state-space models, Mamba merges time-varying
parameters into SSMs and formulates a hardware-aware algorithm for efficient
training and inference. Given its impressive efficiency and strong long-range
dependency modeling capability, Mamba is expected to become a new AI
architecture that may outperform Transformer. Recently, a number of works have
attempted to study the potential of Mamba in various fields, such as general
vision, multi-modal, medical image analysis and remote sensing image analysis,
by extending Mamba from natural language domain to visual domain. To fully
understand Mamba in the visual domain, we conduct a comprehensive survey and
present a taxonomy study. This survey focuses on Mamba's application to a
variety of visual tasks and data types, and discusses its predecessors, recent
advances and far-reaching impact on a wide range of domains. Since Mamba is now
on an upward trend, please actively notice us if you have new findings, and new
progress on Mamba will be included in this survey in a timely manner and
updated on the Mamba project at
https://github.com/lx6c78/Vision-Mamba-A-Comprehensive-Survey-and-Taxonomy.

摘要：

##### **Pragmatist Intelligence: Where the Principle of Usefulness Can Take ANNs**
2405.04386v1 by Antonio Bikić, Sayan Mukherjee

Artificial neural networks (ANNs) perform extraordinarily on numerous tasks
including classification or prediction, e.g., speech processing and image
classification. These new functions are based on a computational model that is
enabled to select freely all necessary internal model parameters as long as it
eventually delivers the functionality it is supposed to exhibit. Here, we
review the connection between the model parameter selection in machine learning
(ML) algorithms running on ANNs and the epistemological theory of neopragmatism
focusing on the theory's utility and anti-representationalist aspects. To
understand the consequences of the model parameter selection of an ANN, we
suggest using neopragmatist theories whose implications are well studied.
Incidentally, neopragmatism's notion of optimization is also based on utility
considerations. This means that applying this approach elegantly reveals the
inherent connections between optimization in ML, using a numerical method
during the learning phase, and optimization in the ethical theory of
consequentialism, where it occurs as a maxim of action. We suggest that these
connections originate from the way relevance is calculated in ML systems. This
could ultimately reveal a tendency for specific actions in ML systems.

摘要：人工神經網路 (ANN) 在許多任務上表現得非常好，包括分類或預測，例如語音處理和影像分類。這些新功能基於一個計算模型，只要它最終提供它應該展示的功能，就能自由選擇所有必要的內部模型參數。在這裡，我們回顧機器學習 (ML) 演算法中模型參數選擇與人工神經網路執行的運作，以及新實用主義的認識論，重點在於該理論的效用和反表象方面。為了了解人工神經網路模型參數選擇的後果，我們建議使用新實用主義理論，其含義已得到充分的研究。順便一提，新實用主義的最佳化概念也基於效用考量。這表示應用這種方法優雅地揭示了機器學習中最佳化的內在關聯，在學習階段使用數值方法，以及後果主義的倫理理論中的最佳化，在其中它作為行動格言出現。我們建議這些關聯源自機器學習系統中計算相關性的方式。這最終可能會揭示機器學習系統中特定動作的趨勢。

##### **Leveraging LSTM and GAN for Modern Malware Detection**
2405.04373v1 by Ishita Gupta, Sneha Kumari, Priya Jha, Mohona Ghosh

The malware booming is a cyberspace equal to the effect of climate change to
ecosystems in terms of danger. In the case of significant investments in
cybersecurity technologies and staff training, the global community has become
locked up in the eternal war with cyber security threats. The multi-form and
changing faces of malware are continuously pushing the boundaries of the
cybersecurity practitioners employ various approaches like detection and
mitigate in coping with this issue. Some old mannerisms like signature-based
detection and behavioral analysis are slow to adapt to the speedy evolution of
malware types. Consequently, this paper proposes the utilization of the Deep
Learning Model, LSTM networks, and GANs to amplify malware detection accuracy
and speed. A fast-growing, state-of-the-art technology that leverages raw
bytestream-based data and deep learning architectures, the AI technology
provides better accuracy and performance than the traditional methods.
Integration of LSTM and GAN model is the technique that is used for the
synthetic generation of data, leading to the expansion of the training
datasets, and as a result, the detection accuracy is improved. The paper uses
the VirusShare dataset which has more than one million unique samples of the
malware as the training and evaluation set for the presented models. Through
thorough data preparation including tokenization, augmentation, as well as
model training, the LSTM and GAN models convey the better performance in the
tasks compared to straight classifiers. The research outcomes come out with 98%
accuracy that shows the efficiency of deep learning plays a decisive role in
proactive cybersecurity defense. Aside from that, the paper studies the output
of ensemble learning and model fusion methods as a way to reduce biases and
lift model complexity.

摘要：惡意軟體的蓬勃發展對網路空間的影響，等同於氣候變遷對生態系統的危害。在對網路安全技術和員工訓練進行大量投資的情況下，全球社群已陷入與網路安全威脅的永恆戰爭中。惡意軟體的多樣化形式和不斷變化的面貌，持續挑戰網路安全從業人員的界限，他們採用各種方法來應對此問題，例如偵測和緩解。一些舊有的方式，例如基於特徵碼的偵測和行為分析，適應惡意軟體類型快速演變的速度較慢。因此，本文提出利用深度學習模型、LSTM 網路和 GAN 來提升惡意軟體偵測的準確度和速度。人工智慧技術是一種快速發展的尖端技術，它利用基於原始位元組串流的資料和深度學習架構，提供比傳統方法更好的準確度和效能。LSTM 和 GAN 模型的整合是一種用於資料合成產生的技術，可擴充訓練資料集，進而提升偵測準確度。本文使用 VirusShare 資料集，其中包含一百萬個以上的獨特惡意軟體樣本，作為所提出模型的訓練和評估集。透過包含代幣化、擴充和模型訓練在內的徹底資料準備，LSTM 和 GAN 模型在任務中的表現優於直接分類器。研究結果達到了 98% 的準確度，顯示深度學習的效率在主動網路安全防禦中扮演決定性的角色。除此之外，本文探討整體學習和模型融合方法的輸出，作為減少偏差和提升模型複雜度的方法。

##### **Explainable machine learning for predicting shellfish toxicity in the Adriatic Sea using long-term monitoring data of HABs**
2405.04372v1 by Martin Marzidovšek, Janja Francé, Vid Podpečan, Stanka Vadnjal, Jožica Dolenc, Patricija Mozetič

In this study, explainable machine learning techniques are applied to predict
the toxicity of mussels in the Gulf of Trieste (Adriatic Sea) caused by harmful
algal blooms. By analysing a newly created 28-year dataset containing records
of toxic phytoplankton in mussel farming areas and toxin concentrations in
mussels (Mytilus galloprovincialis), we train and evaluate the performance of
ML models to accurately predict diarrhetic shellfish poisoning (DSP) events.
The random forest model provided the best prediction of positive toxicity
results based on the F1 score. Explainability methods such as permutation
importance and SHAP identified key species (Dinophysis fortii and D. caudata)
and environmental factors (salinity, river discharge and precipitation) as the
best predictors of DSP outbreaks. These findings are important for improving
early warning systems and supporting sustainable aquaculture practices.

摘要：本研究應用可解釋機器學習技術，預測由有害藻類大量繁殖造成的的里雅斯特灣（亞得里亞海）貽貝毒性。透過分析一個新建立的 28 年資料集，其中包含貽貝養殖區有毒浮游植物的記錄和貽貝（地中海貽貝）中的毒素濃度，我們訓練並評估機器學習模型的效能，以準確預測腹瀉性貝類中毒 (DSP) 事件。隨機森林模型根據 F1 分數提供了最佳的毒性結果預測。可解釋性方法，例如置換重要性和 SHAP，將關鍵物種（Dinophysis fortii 和 D. caudata）和環境因素（鹽度、河流流量和降水）列為 DSP 爆發的最佳預測指標。這些發現對於改進預警系統和支持永續水產養殖實務非常重要。

##### **Global Scale Self-Supervised Channel Charting with Sensor Fusion**
2405.04357v1 by Omid Esrafilian, Mohsen Ahadi, Florian Kaltenberger, David Gesbert

The sensing and positioning capabilities foreseen in 6G have great potential
for technology advancements in various domains, such as future smart cities and
industrial use cases. Channel charting has emerged as a promising technology in
recent years for radio frequency-based sensing and localization. However, the
accuracy of these techniques is yet far behind the numbers envisioned in 6G. To
reduce this gap, in this paper, we propose a novel channel charting technique
capitalizing on the time of arrival measurements from surrounding Transmission
Reception Points (TRPs) along with their locations and leveraging sensor fusion
in channel charting by incorporating laser scanner data during the training
phase of our algorithm. The proposed algorithm remains self-supervised during
training and test phases, requiring no geometrical models or user position
ground truth. Simulation results validate the achievement of a sub-meter level
localization accuracy using our algorithm 90% of the time, outperforming the
state-of-the-art channel charting techniques and the traditional
triangulation-based approaches.

摘要：6G 中預見的感測和定位能力對於各種領域的技術進展具有極大的潛力，例如未來智慧城市和工業用例。頻道繪製近年來已成為一種很有前景的技術，用於基於無線電頻率的感測和定位。然而，這些技術的準確性遠遠落後於 6G 中預期的數字。為了縮小這個差距，在本文中，我們提出了一種新穎的頻道繪製技術，利用來自周圍傳輸接收點 (TRP) 的到達時間測量值以及它們的位置，並在演算法訓練階段透過納入雷射掃描儀資料來利用頻道繪製中的感測器融合。所提出的演算法在訓練和測試階段仍然是自我監督的，不需要幾何模型或使用者位置真實值。模擬結果驗證了使用我們的演算法在 90% 的時間內達成次公尺等級的定位準確度，優於最先進的頻道繪製技術和傳統的基於三角測量的途徑。

##### **Revisiting character-level adversarial attacks**
2405.04346v1 by Elias Abad Rocamora, Yongtao Wu, Fanghui Liu, Grigorios G. Chrysos, Volkan Cevher

Adversarial attacks in Natural Language Processing apply perturbations in the
character or token levels. Token-level attacks, gaining prominence for their
use of gradient-based methods, are susceptible to altering sentence semantics,
leading to invalid adversarial examples. While character-level attacks easily
maintain semantics, they have received less attention as they cannot easily
adopt popular gradient-based methods, and are thought to be easy to defend.
Challenging these beliefs, we introduce Charmer, an efficient query-based
adversarial attack capable of achieving high attack success rate (ASR) while
generating highly similar adversarial examples. Our method successfully targets
both small (BERT) and large (Llama 2) models. Specifically, on BERT with SST-2,
Charmer improves the ASR in 4.84% points and the USE similarity in 8% points
with respect to the previous art. Our implementation is available in
https://github.com/LIONS-EPFL/Charmer.

摘要：自然語言處理中的對抗性攻擊在字元或標記層級套用擾動。標記層級攻擊因使用基於梯度的技術而聲名大噪，容易改變句子語義，導致無效的對抗性範例。雖然字元層級攻擊容易維持語義，但由於它們無法輕易採用熱門的基於梯度的技術，而且被認為容易防禦，因此較不受重視。為了挑戰這些觀念，我們引入了 Charmer，一種有效率的基於查詢的對抗性攻擊，能夠在產生高度相似的對抗性範例的同時，達成高攻擊成功率 (ASR)。我們的技術成功地針對小型 (BERT) 和大型 (Llama 2) 模型。具體來說，在使用 SST-2 的 BERT 上，Charmer 將 ASR 提高了 4.84%，將 USE 相似性提高了 8%，優於先前的技術。我們的實作可在 https://github.com/LIONS-EPFL/Charmer 中取得。

##### **Temporal and Heterogeneous Graph Neural Network for Remaining Useful Life Prediction**
2405.04336v1 by Zhihao Wen, Yuan Fang, Pengcheng Wei, Fayao Liu, Zhenghua Chen, Min Wu

Predicting Remaining Useful Life (RUL) plays a crucial role in the
prognostics and health management of industrial systems that involve a variety
of interrelated sensors. Given a constant stream of time series sensory data
from such systems, deep learning models have risen to prominence at identifying
complex, nonlinear temporal dependencies in these data. In addition to the
temporal dependencies of individual sensors, spatial dependencies emerge as
important correlations among these sensors, which can be naturally modelled by
a temporal graph that describes time-varying spatial relationships. However,
the majority of existing studies have relied on capturing discrete snapshots of
this temporal graph, a coarse-grained approach that leads to loss of temporal
information. Moreover, given the variety of heterogeneous sensors, it becomes
vital that such inherent heterogeneity is leveraged for RUL prediction in
temporal sensor graphs. To capture the nuances of the temporal and spatial
relationships and heterogeneous characteristics in an interconnected graph of
sensors, we introduce a novel model named Temporal and Heterogeneous Graph
Neural Networks (THGNN). Specifically, THGNN aggregates historical data from
neighboring nodes to accurately capture the temporal dynamics and spatial
correlations within the stream of sensor data in a fine-grained manner.
Moreover, the model leverages Feature-wise Linear Modulation (FiLM) to address
the diversity of sensor types, significantly improving the model's capacity to
learn the heterogeneity in the data sources. Finally, we have validated the
effectiveness of our approach through comprehensive experiments. Our empirical
findings demonstrate significant advancements on the N-CMAPSS dataset,
achieving improvements of up to 19.2% and 31.6% in terms of two different
evaluation metrics over state-of-the-art methods.

摘要：

##### **A Fourth Wave of Open Data? Exploring the Spectrum of Scenarios for Open Data and Generative AI**
2405.04333v1 by Hannah Chafetz, Sampriti Saxena, Stefaan G. Verhulst

Since late 2022, generative AI has taken the world by storm, with widespread
use of tools including ChatGPT, Gemini, and Claude. Generative AI and large
language model (LLM) applications are transforming how individuals find and
access data and knowledge. However, the intricate relationship between open
data and generative AI, and the vast potential it holds for driving innovation
in this field remain underexplored areas. This white paper seeks to unpack the
relationship between open data and generative AI and explore possible
components of a new Fourth Wave of Open Data: Is open data becoming AI ready?
Is open data moving towards a data commons approach? Is generative AI making
open data more conversational? Will generative AI improve open data quality and
provenance? Towards this end, we provide a new Spectrum of Scenarios framework.
This framework outlines a range of scenarios in which open data and generative
AI could intersect and what is required from a data quality and provenance
perspective to make open data ready for those specific scenarios. These
scenarios include: pertaining, adaptation, inference and insight generation,
data augmentation, and open-ended exploration. Through this process, we found
that in order for data holders to embrace generative AI to improve open data
access and develop greater insights from open data, they first must make
progress around five key areas: enhance transparency and documentation, uphold
quality and integrity, promote interoperability and standards, improve
accessibility and useability, and address ethical considerations.

摘要：自 2022 年底以來，生成式 AI 已席捲全球，ChatGPT、Gemini 和 Claude 等工具廣泛使用。生成式 AI 和大型語言模型 (LLM) 應用程式正在改變個人尋找和存取資料與知識的方式。然而，開放資料和生成式 AI 之間的複雜關係，以及它在推動此領域創新的巨大潛力，仍然是尚未充分探索的領域。本白皮書旨在解開開放資料和生成式 AI 之間的關係，並探討開放資料第四波的可能組成部分：開放資料是否準備好迎接 AI？開放資料是否朝向資料共用方法邁進？生成式 AI 是否讓開放資料更具對話性？生成式 AI 是否會改善開放資料的品質和來源？為此，我們提供了一個新的情境光譜架構。此架構概述了一系列開放資料和生成式 AI 可能相交的情境，以及從資料品質和來源的角度來看，讓開放資料為這些特定情境做好準備所需的條件。這些情境包括：關聯、改編、推論和見解產生、資料擴充和開放式探索。透過此流程，我們發現資料持有者若要採用生成式 AI 來改善開放資料存取並從開放資料中發展出更深入的見解，他們必須先在五個關鍵領域取得進展：加強透明度和文件化、維護品質和完整性、促進互操作性和標準化、改善可存取性和可用性，以及解決倫理考量。

##### **Deception in Reinforced Autonomous Agents: The Unconventional Rabbit Hat Trick in Legislation**
2405.04325v1 by Atharvan Dogra, Ameet Deshpande, John Nay, Tanmay Rajpurohit, Ashwin Kalyan, Balaraman Ravindran

Recent developments in large language models (LLMs), while offering a
powerful foundation for developing natural language agents, raise safety
concerns about them and the autonomous agents built upon them. Deception is one
potential capability of AI agents of particular concern, which we refer to as
an act or statement that misleads, hides the truth, or promotes a belief that
is not true in its entirety or in part. We move away from the conventional
understanding of deception through straight-out lying, making objective selfish
decisions, or giving false information, as seen in previous AI safety research.
We target a specific category of deception achieved through obfuscation and
equivocation. We broadly explain the two types of deception by analogizing them
with the rabbit-out-of-hat magic trick, where (i) the rabbit either comes out
of a hidden trap door or (ii) (our focus) the audience is completely distracted
to see the magician bring out the rabbit right in front of them using sleight
of hand or misdirection. Our novel testbed framework displays intrinsic
deception capabilities of LLM agents in a goal-driven environment when directed
to be deceptive in their natural language generations in a two-agent
adversarial dialogue system built upon the legislative task of "lobbying" for a
bill. Along the lines of a goal-driven environment, we show developing
deceptive capacity through a reinforcement learning setup, building it around
the theories of language philosophy and cognitive psychology. We find that the
lobbyist agent increases its deceptive capabilities by ~ 40% (relative) through
subsequent reinforcement trials of adversarial interactions, and our deception
detection mechanism shows a detection capability of up to 92%. Our results
highlight potential issues in agent-human interaction, with agents potentially
manipulating humans towards its programmed end-goal.

摘要：大型語言模型 (LLM) 的最新進展，雖然為開發自然語言代理提供了強大的基礎，但對它們以及建立在它們之上的自主代理提出了安全方面的擔憂。欺騙是人工智能代理特別關注的潛在能力之一，我們將其稱為誤導、隱瞞真相或宣傳部分或全部不真實信念的行為或陳述。我們遠離通過直接撒謊、做出客觀自私的決定或提供虛假信息來理解欺騙的傳統觀念，正如在先前的 AI 安全研究中所見。我們針對通過混淆和模稜兩可實現的特定類別的欺騙行為。我們通過將它們比作魔術師從帽子中變出兔子的戲法來廣泛解釋這兩種欺騙行為，其中 (i) 兔子要麼從隱藏的活門中出來，或者 (ii) (我們的重點) 觀眾完全被分散注意力，看到魔術師使用障眼法或誤導手法在他們面前變出兔子。我們新穎的測試框架在目標驅動環境中展示了 LLM 代理的內在欺騙能力，當指示它們在建立在「遊說」法案的立法任務之上的雙代理對抗對話系統中以自然語言生成方式進行欺騙時。沿著目標驅動環境的思路，我們展示了通過強化學習設置來發展欺騙能力，並圍繞語言哲學和認知心理學的理論來構建它。我們發現，遊說代理通過後續的對抗互動強化試驗，將其欺騙能力提高了約 40%（相對值），而我們的欺騙檢測機制顯示出高達 92% 的檢測能力。我們的結果突出了代理人與人之間互動中的潛在問題，代理人可能會操縱人類朝著其規劃的最終目標前進。

##### **Granite Code Models: A Family of Open Foundation Models for Code Intelligence**
2405.04324v1 by Mayank Mishra, Matt Stallone, Gaoyuan Zhang, Yikang Shen, Aditya Prasad, Adriana Meza Soria, Michele Merler, Parameswaran Selvam, Saptha Surendran, Shivdeep Singh, Manish Sethi, Xuan-Hong Dang, Pengyuan Li, Kun-Lung Wu, Syed Zawad, Andrew Coleman, Matthew White, Mark Lewis, Raju Pavuluri, Yan Koyfman, Boris Lublinsky, Maximilien de Bayser, Ibrahim Abdelaziz, Kinjal Basu, Mayank Agarwal, Yi Zhou, Chris Johnson, Aanchal Goyal, Hima Patel, Yousaf Shah, Petros Zerfos, Heiko Ludwig, Asim Munawar, Maxwell Crouse, Pavan Kapanipathi, Shweta Salaria, Bob Calio, Sophia Wen, Seetharami Seelam, Brian Belgodere, Carlos Fonseca, Amith Singhee, Nirmit Desai, David D. Cox, Ruchir Puri, Rameswar Panda

Large Language Models (LLMs) trained on code are revolutionizing the software
development process. Increasingly, code LLMs are being integrated into software
development environments to improve the productivity of human programmers, and
LLM-based agents are beginning to show promise for handling complex tasks
autonomously. Realizing the full potential of code LLMs requires a wide range
of capabilities, including code generation, fixing bugs, explaining and
documenting code, maintaining repositories, and more. In this work, we
introduce the Granite series of decoder-only code models for code generative
tasks, trained with code written in 116 programming languages. The Granite Code
models family consists of models ranging in size from 3 to 34 billion
parameters, suitable for applications ranging from complex application
modernization tasks to on-device memory-constrained use cases. Evaluation on a
comprehensive set of tasks demonstrates that Granite Code models consistently
reaches state-of-the-art performance among available open-source code LLMs. The
Granite Code model family was optimized for enterprise software development
workflows and performs well across a range of coding tasks (e.g. code
generation, fixing and explanation), making it a versatile all around code
model. We release all our Granite Code models under an Apache 2.0 license for
both research and commercial use.

摘要：大型語言模型 (LLM) 接受過程式碼訓練，正在革新軟體開發流程。程式碼 LLM 愈來愈多地整合到軟體開發環境中，以提升人類程式設計師的生產力，而基於 LLM 的代理程式也開始展現出自主處理複雜任務的希望。要實現程式碼 LLM 的全部潛力，需要廣泛的功能，包括產生程式碼、修正錯誤、說明和記錄程式碼、維護儲存庫等等。在這項工作中，我們引入了 Granite 系列的僅解碼器程式碼模型，用於程式碼產生任務，並使用 116 種程式語言編寫的程式碼進行訓練。Granite Code 模型系列包含大小從 30 億到 340 億個參數不等的模型，適用於從複雜的應用程式現代化任務到裝置記憶體受限使用案例的各種應用程式。對一組全面的任務進行評估，證明 Granite Code 模型在現有的開源程式碼 LLM 中始終達到最先進的效能。Granite Code 模型系列經過最佳化，適用於企業軟體開發工作流程，並且在各種編碼任務（例如產生程式碼、修正和說明）中表現良好，使其成為一款功能強大的全方位程式碼模型。我們根據 Apache 2.0 授權釋出所有 Granite Code 模型，供研究和商業用途。

##### **Beyond human subjectivity and error: a novel AI grading system**
2405.04323v1 by Alexandra Gobrecht, Felix Tuma, Moritz Möller, Thomas Zöller, Mark Zakhvatkin, Alexandra Wuttig, Holger Sommerfeldt, Sven Schütt

The grading of open-ended questions is a high-effort, high-impact task in
education. Automating this task promises a significant reduction in workload
for education professionals, as well as more consistent grading outcomes for
students, by circumventing human subjectivity and error. While recent
breakthroughs in AI technology might facilitate such automation, this has not
been demonstrated at scale. It this paper, we introduce a novel automatic short
answer grading (ASAG) system. The system is based on a fine-tuned open-source
transformer model which we trained on large set of exam data from university
courses across a large range of disciplines. We evaluated the trained model's
performance against held-out test data in a first experiment and found high
accuracy levels across a broad spectrum of unseen questions, even in unseen
courses. We further compared the performance of our model with that of
certified human domain experts in a second experiment: we first assembled
another test dataset from real historical exams - the historic grades contained
in that data were awarded to students in a regulated, legally binding
examination process; we therefore considered them as ground truth for our
experiment. We then asked certified human domain experts and our model to grade
the historic student answers again without disclosing the historic grades.
Finally, we compared the hence obtained grades with the historic grades (our
ground truth). We found that for the courses examined, the model deviated less
from the official historic grades than the human re-graders - the model's
median absolute error was 44 % smaller than the human re-graders', implying
that the model is more consistent than humans in grading. These results suggest
that leveraging AI enhanced grading can reduce human subjectivity, improve
consistency and thus ultimately increase fairness.

摘要：開放式問題的評分是教育中高投入、高影響力的任務。自動化這項任務承諾大幅減少教育專業人員的工作量，並透過規避人為的主觀和錯誤，為學生提供更一致的評分結果。雖然 AI 技術的最新突破可能有助於這種自動化，但這尚未大規模示範。在本文中，我們介紹了一種新穎的自動簡答評分 (ASAG) 系統。該系統基於一個經過微調的開源轉換器模型，我們在來自各個學科的大學課程的大量考試數據上對其進行了訓練。我們在第一次實驗中評估了訓練模型對保留測試數據的效能，並發現即使在未見過的課程中，在廣泛的未見過問題中也具有很高的準確度。在第二次實驗中，我們進一步比較了我們模型的效能與經過認證的人類領域專家的效能：我們首先從真實的歷史考試中收集了另一個測試數據集 - 該數據中包含的歷史成績是在受監管的、具有法律約束力的考試過程中授予學生的；因此，我們將其視為我們實驗的真實情況。然後，我們要求經過認證的人類領域專家和我們的模型在不透露歷史成績的情況下再次評分歷史學生的答案。最後，我們將因此獲得的成績與歷史成績（我們的真實情況）進行比較。我們發現，對於所檢查的課程，該模型比人類重新評分者偏離官方歷史成績的程度更小 - 該模型的中值絕對誤差比人類重新評分者小 44%，這意味著該模型在評分方面比人類更一致。這些結果表明，利用 AI 增強評分可以減少人為的主觀性，提高一致性，從而最終提高公平性。

##### **Cross-IQA: Unsupervised Learning for Image Quality Assessment**
2405.04311v1 by Zhen Zhang

Automatic perception of image quality is a challenging problem that impacts
billions of Internet and social media users daily. To advance research in this
field, we propose a no-reference image quality assessment (NR-IQA) method
termed Cross-IQA based on vision transformer(ViT) model. The proposed Cross-IQA
method can learn image quality features from unlabeled image data. We construct
the pretext task of synthesized image reconstruction to unsupervised extract
the image quality information based ViT block. The pretrained encoder of
Cross-IQA is used to fine-tune a linear regression model for score prediction.
Experimental results show that Cross-IQA can achieve state-of-the-art
performance in assessing the low-frequency degradation information (e.g., color
change, blurring, etc.) of images compared with the classical full-reference
IQA and NR-IQA under the same datasets.

摘要：影像品質的自動感知是一項具有挑戰性的問題，它每天都會影響數十億的網際網路和社群媒體使用者。為了推進此領域的研究，我們提出了一種基於視覺轉換器 (ViT) 模型的無參考影像品質評估 (NR-IQA) 方法，稱為 Cross-IQA。所提出的 Cross-IQA 方法可以從未標籤的影像資料中學習影像品質特徵。我們建構了合成影像重建的預設任務，以非監督的方式根據 ViT 區塊萃取影像品質資訊。Cross-IQA 的預訓練編碼器用於微調線性回歸模型以進行分數預測。實驗結果顯示，與在相同資料集下的傳統全參考 IQA 和 NR-IQA 相比，Cross-IQA 可以達成評估影像低頻劣化資訊（例如，色彩變化、模糊等）的最新技術效能。

##### **Improving Offline Reinforcement Learning with Inaccurate Simulators**
2405.04307v1 by Yiwen Hou, Haoyuan Sun, Jinming Ma, Feng Wu

Offline reinforcement learning (RL) provides a promising approach to avoid
costly online interaction with the real environment. However, the performance
of offline RL highly depends on the quality of the datasets, which may cause
extrapolation error in the learning process. In many robotic applications, an
inaccurate simulator is often available. However, the data directly collected
from the inaccurate simulator cannot be directly used in offline RL due to the
well-known exploration-exploitation dilemma and the dynamic gap between
inaccurate simulation and the real environment. To address these issues, we
propose a novel approach to combine the offline dataset and the inaccurate
simulation data in a better manner. Specifically, we pre-train a generative
adversarial network (GAN) model to fit the state distribution of the offline
dataset. Given this, we collect data from the inaccurate simulator starting
from the distribution provided by the generator and reweight the simulated data
using the discriminator. Our experimental results in the D4RL benchmark and a
real-world manipulation task confirm that our method can benefit more from both
inaccurate simulator and limited offline datasets to achieve better performance
than the state-of-the-art methods.

摘要：離線強化學習 (RL) 提供一種有前途的方法來避免與真實環境進行代價高昂的線上互動。然而，離線 RL 的效能高度依賴於資料集的品質，這可能會在學習過程中導致外推誤差。在許多機器人應用中，通常可以使用不準確的模擬器。然而，由於眾所周知的探索開發兩難困境和不準確的模擬與真實環境之間的動態差距，無法直接在離線 RL 中使用從不準確的模擬器直接收集的資料。為了解決這些問題，我們提出了一種新方法，以更好的方式結合離線資料集和不準確的模擬資料。具體來說，我們預先訓練一個生成對抗網路 (GAN) 模型來擬合離線資料集的狀態分佈。有鑑於此，我們從產生器提供的分佈開始，從不準確的模擬器收集資料，並使用辨別器重新加權模擬資料。我們在 D4RL 基準和真實世界操作任務中的實驗結果證實，與最先進的方法相比，我們的模型可以從不準確的模擬器和有限的離線資料集中受益更多，以實現更好的效能。

##### **A New Dataset and Comparative Study for Aphid Cluster Detection and Segmentation in Sorghum Fields**
2405.04305v1 by Raiyan Rahman, Christopher Indris, Goetz Bramesfeld, Tianxiao Zhang, Kaidong Li, Xiangyu Chen, Ivan Grijalva, Brian McCornack, Daniel Flippo, Ajay Sharda, Guanghui Wang

Aphid infestations are one of the primary causes of extensive damage to wheat
and sorghum fields and are one of the most common vectors for plant viruses,
resulting in significant agricultural yield losses. To address this problem,
farmers often employ the inefficient use of harmful chemical pesticides that
have negative health and environmental impacts. As a result, a large amount of
pesticide is wasted on areas without significant pest infestation. This brings
to attention the urgent need for an intelligent autonomous system that can
locate and spray sufficiently large infestations selectively within the complex
crop canopies. We have developed a large multi-scale dataset for aphid cluster
detection and segmentation, collected from actual sorghum fields and
meticulously annotated to include clusters of aphids. Our dataset comprises a
total of 54,742 image patches, showcasing a variety of viewpoints, diverse
lighting conditions, and multiple scales, highlighting its effectiveness for
real-world applications. In this study, we trained and evaluated four real-time
semantic segmentation models and three object detection models specifically for
aphid cluster segmentation and detection. Considering the balance between
accuracy and efficiency, Fast-SCNN delivered the most effective segmentation
results, achieving 80.46% mean precision, 81.21% mean recall, and 91.66 frames
per second (FPS). For object detection, RT-DETR exhibited the best overall
performance with a 61.63% mean average precision (mAP), 92.6% mean recall, and
72.55 on an NVIDIA V100 GPU. Our experiments further indicate that aphid
cluster segmentation is more suitable for assessing aphid infestations than
using detection models.

摘要：

##### **Accelerating Speculative Decoding using Dynamic Speculation Length**
2405.04304v1 by Jonathan Mamou, Oren Pereg, Daniel Korat, Moshe Berchansky, Nadav Timor, Moshe Wasserblat, Roy Schwartz

Speculative decoding is a promising method for reducing the inference latency
of large language models. The effectiveness of the method depends on the
speculation length (SL) - the number of tokens generated by the draft model at
each iteration. The vast majority of speculative decoding approaches use the
same SL for all iterations. In this work, we show that this practice is
suboptimal. We introduce DISCO, a DynamIc SpeCulation length Optimization
method that uses a classifier to dynamically adjust the SL at each iteration,
while provably preserving the decoding quality. Experiments with four
benchmarks demonstrate average speedup gains of 10.3% relative to our best
baselines.

摘要：推測解碼是一種有望降低大型語言模型推論延遲的方法。此方法的有效性取決於推測長度 (SL)，也就是草稿模型在每個反覆運算中產生的符號數量。絕大多數的推測解碼方法對所有反覆運算使用相同的 SL。在這項工作中，我們證明這種做法次於最佳。我們推出 DISCO，一種動態推測長度最佳化方法，它使用分類器在每次反覆運算中動態調整 SL，同時可證明保留解碼品質。使用四個基準進行的實驗顯示，相較於我們最佳的基準，平均加速增益為 10.3%。

##### **Behaviour Planning: A Toolkit for Diverse Planning**
2405.04300v1 by Mustafa F Abdelwahed, Joan Espasa, Alice Toniolo, Ian P. Gent

Diverse planning is the problem of generating plans with distinct
characteristics. This is valuable for many real-world scenarios, including
applications related to plan recognition and business process automation. In
this work, we introduce \emph{Behaviour Planning}, a diverse planning toolkit
that can characterise and generate diverse plans based on modular diversity
models. We present a qualitative framework for describing diversity models, a
planning approach for generating plans aligned with any given diversity model,
and provide a practical implementation of an SMT-based behaviour planner. We
showcase how the qualitative approach offered by Behaviour Planning allows it
to overcome various challenges faced by previous approaches. Finally, the
experimental evaluation shows the effectiveness of Behaviour Planning in
generating diverse plans compared to state-of-the-art approaches.

摘要：多樣化規劃是產生具有不同特性的計劃的問題。這對於許多真實世界的場景很有價值，包括與計劃識別和業務流程自動化相關的應用。在這項工作中，我們介紹了「行為規劃」，這是一個多樣化的規劃工具包，可以根據模組化多樣性模型來表徵和產生多樣化的計劃。我們提出了描述多樣性模型的定性框架，一種用於產生與任何給定多樣性模型一致的計劃的規劃方法，並提供了基於 SMT 的行為規劃器的實際實現。我們展示了行為規劃所提供的定性方法如何讓它克服先前方法所面臨的各種挑戰。最後，實驗評估顯示了行為規劃在產生多樣化計劃方面與最先進的方法相比的有效性。

##### **Enhancing the Efficiency and Accuracy of Underlying Asset Reviews in Structured Finance: The Application of Multi-agent Framework**
2405.04294v1 by Xiangpeng Wan, Haicheng Deng, Kai Zou, Shiqi Xu

Structured finance, which involves restructuring diverse assets into
securities like MBS, ABS, and CDOs, enhances capital market efficiency but
presents significant due diligence challenges. This study explores the
integration of artificial intelligence (AI) with traditional asset review
processes to improve efficiency and accuracy in structured finance. Using both
open-sourced and close-sourced large language models (LLMs), we demonstrate
that AI can automate the verification of information between loan applications
and bank statements effectively. While close-sourced models such as GPT-4 show
superior performance, open-sourced models like LLAMA3 offer a cost-effective
alternative. Dual-agent systems further increase accuracy, though this comes
with higher operational costs. This research highlights AI's potential to
minimize manual errors and streamline due diligence, suggesting a broader
application of AI in financial document analysis and risk management.

摘要：結構性融資涉及將不同資產重組為證券，例如 MBS、ABS 和 CDO，它提高了資本市場效率，但也帶來了重大的盡職調查挑戰。本研究探討了將人工智慧 (AI) 與傳統資產審查流程整合，以提高結構性融資的效率和準確性。我們使用開源和閉源大型語言模型 (LLM)，證明 AI 能夠有效自動化貸款申請和銀行對帳單之間的資訊驗證。雖然 GPT-4 等閉源模型表現優異，但 LLAMA3 等開源模型提供了具有成本效益的替代方案。雙代理系統進一步提高了準確性，儘管這會帶來更高的營運成本。本研究強調了 AI 在最大限度減少人為錯誤和簡化盡職調查方面的潛力，並表明 AI 在財務文件分析和風險管理中具有更廣泛的應用。

##### **Mitigating Clickbait: An Approach to Spoiler Generation Using Multitask Learning**
2405.04292v1 by Sayantan Pal, Souvik Das, Rohini K. Srihari

This study introduces 'clickbait spoiling', a novel technique designed to
detect, categorize, and generate spoilers as succinct text responses,
countering the curiosity induced by clickbait content. By leveraging a
multi-task learning framework, our model's generalization capabilities are
significantly enhanced, effectively addressing the pervasive issue of
clickbait. The crux of our research lies in generating appropriate spoilers, be
it a phrase, an extended passage, or multiple, depending on the spoiler type
required. Our methodology integrates two crucial techniques: a refined spoiler
categorization method and a modified version of the Question Answering (QA)
mechanism, incorporated within a multi-task learning paradigm for optimized
spoiler extraction from context. Notably, we have included fine-tuning methods
for models capable of handling longer sequences to accommodate the generation
of extended spoilers. This research highlights the potential of sophisticated
text processing techniques in tackling the omnipresent issue of clickbait,
promising an enhanced user experience in the digital realm.

摘要：本研究介紹「誘餌破壞」，一種新技術，旨在偵測、分類和產生簡潔文字回應的破壞內容，對抗誘餌內容引發的好奇心。透過利用多任務學習架構，我們模型的概化能力獲得顯著提升，有效解決誘餌的普遍問題。我們研究的重點在於產生適當的破壞內容，無論是片語、延伸段落或多重內容，視所需的破壞類型而定。我們的技術整合兩項重要的技術：精緻的破壞分類方法和問答 (QA) 機制的修改版本，在多任務學習範例中納入，以從脈絡中最佳化擷取破壞內容。值得注意的是，我們已納入微調方法，以供模型處理較長的序列，以容納延伸破壞內容的產生。本研究強調進階文字處理技術在解決無所不在的誘餌問題上的潛力，並承諾在數位領域中提升使用者體驗。

##### **Who Wrote This? The Key to Zero-Shot LLM-Generated Text Detection Is GECScore**
2405.04286v1 by Junchao Wu, Runzhe Zhan, Derek F. Wong, Shu Yang, Xuebo Liu, Lidia S. Chao, Min Zhang

The efficacy of an large language model (LLM) generated text detector depends
substantially on the availability of sizable training data. White-box zero-shot
detectors, which require no such data, are nonetheless limited by the
accessibility of the source model of the LLM-generated text. In this paper, we
propose an simple but effective black-box zero-shot detection approach,
predicated on the observation that human-written texts typically contain more
grammatical errors than LLM-generated texts. This approach entails computing
the Grammar Error Correction Score (GECScore) for the given text to distinguish
between human-written and LLM-generated text. Extensive experimental results
show that our method outperforms current state-of-the-art (SOTA) zero-shot and
supervised methods, achieving an average AUROC of 98.7% and showing strong
robustness against paraphrase and adversarial perturbation attacks.

摘要：大型語言模型 (LLM) 生成的文字偵測器的效能，在很大程度上取決於可取得大量訓練資料。白盒零次學習偵測器不需要此類資料，但仍受到 LLM 生成的文字原始模型的可取得性限制。在本文中，我們提出一個簡單但有效的黑盒零次學習偵測方法，其預設人類撰寫的文字通常包含比 LLM 生成的文字更多的語法錯誤。此方法需要計算給定文字的語法錯誤修正分數 (GECScore)，以區分人類撰寫的文字和 LLM 生成的文字。廣泛的實驗結果顯示，我們的模型優於目前最先進 (SOTA) 的零次學習和監督式方法，平均 AUROC 達到 98.7%，並在面對同義詞替換和對抗性擾動攻擊時展現出強大的穩健性。

##### **On the Foundations of Earth and Climate Foundation Models**
2405.04285v1 by Xiao Xiang Zhu, Zhitong Xiong, Yi Wang, Adam J. Stewart, Konrad Heidler, Yuanyuan Wang, Zhenghang Yuan, Thomas Dujardin, Qingsong Xu, Yilei Shi

Foundation models have enormous potential in advancing Earth and climate
sciences, however, current approaches may not be optimal as they focus on a few
basic features of a desirable Earth and climate foundation model. Crafting the
ideal Earth foundation model, we define eleven features which would allow such
a foundation model to be beneficial for any geoscientific downstream
application in an environmental- and human-centric manner.We further shed light
on the way forward to achieve the ideal model and to evaluate Earth foundation
models. What comes after foundation models? Energy efficient adaptation,
adversarial defenses, and interpretability are among the emerging directions.

摘要：基礎模型在推進地球和氣候科學方面具有巨大的潛力，然而，當前的途徑可能並非最佳，因為它們專注於理想地球和氣候基礎模型的幾個基本特徵。在制定理想的地球基礎模型時，我們定義了 11 個特徵，這些特徵將允許此類基礎模型以以環境和人類為中心的方式，對任何地球科學下游應用產生有益影響。我們進一步闡明了實現理想模型和評估地球基礎模型的途徑。基礎模型之後是什麼？節能適應、對抗性防禦和可解釋性是新興的方向。

##### **Generating Feature Vectors from Phonetic Transcriptions in Cross-Linguistic Data Formats**
2405.04271v1 by Arne Rubehn, Jessica Nieder, Robert Forkel, Johann-Mattis List

When comparing speech sounds across languages, scholars often make use of
feature representations of individual sounds in order to determine fine-grained
sound similarities. Although binary feature systems for large numbers of speech
sounds have been proposed, large-scale computational applications often face
the challenges that the proposed feature systems -- even if they list features
for several thousand sounds -- only cover a smaller part of the numerous speech
sounds reflected in actual cross-linguistic data. In order to address the
problem of missing data for attested speech sounds, we propose a new approach
that can create binary feature vectors dynamically for all sounds that can be
represented in the the standardized version of the International Phonetic
Alphabet proposed by the Cross-Linguistic Transcription Systems (CLTS)
reference catalog. Since CLTS is actively used in large data collections,
covering more than 2,000 distinct language varieties, our procedure for the
generation of binary feature vectors provides immediate access to a very large
collection of multilingual wordlists. Testing our feature system in different
ways on different datasets proves that the system is not only useful to provide
a straightforward means to compare the similarity of speech sounds, but also
illustrates its potential to be used in future cross-linguistic machine
learning applications.

摘要：在比較各語言的語音時，學者通常會使用個別語音的特徵表示，以確定細微的語音相似性。雖然已經提出了許多語音特徵的二元系統，但大規模的計算應用程式通常會面臨挑戰，即所提出的特徵系統——即使它們列出了數千個語音的特徵——僅涵蓋實際跨語言資料中反映的眾多語音特徵的一小部分。為了解決已證實語音特徵遺失資料的問題，我們提出了一種新方法，可以動態建立所有語音的二元特徵向量，這些語音可以在跨語言轉錄系統 (CLTS) 參考目錄所提出的國際音標標準版本中表示。由於 CLTS 積極用於大型資料收集，涵蓋超過 2,000 種不同的語言變體，因此我們生成二元特徵向量的程序可立即存取非常大量的多語言字詞表。在不同的資料集上以不同的方式測試我們的特徵系統，證明該系統不僅有助於提供一種直接的方法來比較語音的相似性，而且還說明了它在未來跨語言機器學習應用程式中使用的潛力。

##### **VAEneu: A New Avenue for VAE Application on Probabilistic Forecasting**
2405.04252v1 by Alireza Koochali, Ensiye Tahaei, Andreas Dengel, Sheraz Ahmed

This paper presents VAEneu, an innovative autoregressive method for multistep
ahead univariate probabilistic time series forecasting. We employ the
conditional VAE framework and optimize the lower bound of the predictive
distribution likelihood function by adopting the Continuous Ranked Probability
Score (CRPS), a strictly proper scoring rule, as the loss function. This novel
pipeline results in forecasting sharp and well-calibrated predictive
distribution. Through a comprehensive empirical study, VAEneu is rigorously
benchmarked against 12 baseline models across 12 datasets. The results
unequivocally demonstrate VAEneu's remarkable forecasting performance. VAEneu
provides a valuable tool for quantifying future uncertainties, and our
extensive empirical study lays the foundation for future comparative studies
for univariate multistep ahead probabilistic forecasting.

摘要：本文提出了 VAEneu，這是一種創新的自迴歸方法，用於多步單變數機率時間序列預測。我們採用條件 VAE 框架，並透過採用連續排名機率評分 (CRPS)（一種嚴格適當的評分規則）作為損失函數，來最佳化預測分佈似然函數的下限。這個新穎的管道會產生銳利且校準良好的預測分佈。透過全面的實證研究，VAEneu 與 12 個基線模型在 12 個資料集上進行嚴格的基準測試。結果明確證明了 VAEneu 出色的預測效能。VAEneu 提供了一個有價值的工具，用於量化未來的變動，而我們廣泛的實證研究為未來單變數多步機率預測的比較研究奠定了基礎。

##### **Federated Learning for Cooperative Inference Systems: The Case of Early Exit Networks**
2405.04249v1 by Caelin Kaplan, Tareq Si Salem, Angelo Rodio, Chuan Xu, Giovanni Neglia

As Internet of Things (IoT) technology advances, end devices like sensors and
smartphones are progressively equipped with AI models tailored to their local
memory and computational constraints. Local inference reduces communication
costs and latency; however, these smaller models typically underperform
compared to more sophisticated models deployed on edge servers or in the cloud.
Cooperative Inference Systems (CISs) address this performance trade-off by
enabling smaller devices to offload part of their inference tasks to more
capable devices. These systems often deploy hierarchical models that share
numerous parameters, exemplified by Deep Neural Networks (DNNs) that utilize
strategies like early exits or ordered dropout. In such instances, Federated
Learning (FL) may be employed to jointly train the models within a CIS. Yet,
traditional training methods have overlooked the operational dynamics of CISs
during inference, particularly the potential high heterogeneity in serving
rates across clients. To address this gap, we propose a novel FL approach
designed explicitly for use in CISs that accounts for these variations in
serving rates. Our framework not only offers rigorous theoretical guarantees,
but also surpasses state-of-the-art (SOTA) training algorithms for CISs,
especially in scenarios where inference request rates or data availability are
uneven among clients.

摘要：隨著物聯網 (IoT) 技術的進步，感測器和智慧型手機等終端裝置逐漸配備了針對其本地記憶體和運算限制量身打造的 AI 模型。本地推論可降低通訊成本和延遲；然而，這些較小的模型通常表現不如部署在邊緣伺服器或雲端上更精密的模型。協作推論系統 (CIS) 透過讓較小的裝置卸載部分推論任務至功能更強大的裝置，來解決此效能權衡問題。這些系統經常部署共用大量參數的階層模型，例如利用早期退出或有序中斷等策略的深度神經網路 (DNN) 就是一個例子。在這種情況下，聯合學習 (FL) 可用於在 CIS 內聯合訓練模型。然而，傳統的訓練方法在推論過程中忽略了 CIS 的運作動態，特別是客戶端之間服務速率潛在的高異質性。為了解決此差距，我們提出了一種新穎的 FL 方法，專門設計用於 CIS 中，並考量到服務速率的這些變化。我們的架構不僅提供了嚴謹的理論保證，而且超越了 CIS 的最先進 (SOTA) 訓練演算法，特別是在客戶端之間的推論請求速率或資料可用性不均的情況下。

##### **Exploring Correlations of Self-supervised Tasks for Graphs**
2405.04245v1 by Taoran Fang, Wei Zhou, Yifei Sun, Kaiqiao Han, Lvbin Ma, Yang Yang

Graph self-supervised learning has sparked a research surge in training
informative representations without accessing any labeled data. However, our
understanding of graph self-supervised learning remains limited, and the
inherent relationships between various self-supervised tasks are still
unexplored. Our paper aims to provide a fresh understanding of graph
self-supervised learning based on task correlations. Specifically, we evaluate
the performance of the representations trained by one specific task on other
tasks and define correlation values to quantify task correlations. Through this
process, we unveil the task correlations between various self-supervised tasks
and can measure their expressive capabilities, which are closely related to
downstream performance. By analyzing the correlation values between tasks
across various datasets, we reveal the complexity of task correlations and the
limitations of existing multi-task learning methods. To obtain more capable
representations, we propose Graph Task Correlation Modeling (GraphTCM) to
illustrate the task correlations and utilize it to enhance graph
self-supervised training. The experimental results indicate that our method
significantly outperforms existing methods across various downstream tasks.

摘要：圖形自我監督學習激發了在不存取任何標籤資料的情況下訓練資訊表徵的研究熱潮。然而，我們對圖形自我監督學習的理解仍然有限，而且各種自我監督任務之間的內在關係仍然未被探索。我們的論文旨在根據任務相關性提供對圖形自我監督學習的新理解。具體來說，我們評估由特定任務訓練的表徵在其他任務上的效能，並定義相關性值以量化任務相關性。透過這個過程，我們揭示了各種自我監督任務之間的任務相關性，並可以衡量它們的表達能力，這與下游效能密切相關。透過分析跨各種資料集的任務之間的相關性值，我們揭示了任務相關性的複雜性以及現有多任務學習方法的限制。為了獲得更強大的表徵，我們提出了圖形任務相關性建模 (GraphTCM) 來說明任務相關性，並利用它來增強圖形自我監督訓練。實驗結果表明，我們的模型在各種下游任務中都顯著優於現有模型。

##### **Iterative Experience Refinement of Software-Developing Agents**
2405.04219v1 by Chen Qian, Jiahao Li, Yufan Dang, Wei Liu, YiFei Wang, Zihao Xie, Weize Chen, Cheng Yang, Yingli Zhang, Zhiyuan Liu, Maosong Sun

Autonomous agents powered by large language models (LLMs) show significant
potential for achieving high autonomy in various scenarios such as software
development. Recent research has shown that LLM agents can leverage past
experiences to reduce errors and enhance efficiency. However, the static
experience paradigm, reliant on a fixed collection of past experiences acquired
heuristically, lacks iterative refinement and thus hampers agents'
adaptability. In this paper, we introduce the Iterative Experience Refinement
framework, enabling LLM agents to refine experiences iteratively during task
execution. We propose two fundamental patterns: the successive pattern,
refining based on nearest experiences within a task batch, and the cumulative
pattern, acquiring experiences across all previous task batches. Augmented with
our heuristic experience elimination, the method prioritizes high-quality and
frequently-used experiences, effectively managing the experience space and
enhancing efficiency. Extensive experiments show that while the successive
pattern may yield superior results, the cumulative pattern provides more stable
performance. Moreover, experience elimination facilitates achieving better
performance using just 11.54% of a high-quality subset.

摘要：由大型語言模型 (LLM) 驅動的自主代理顯示出在各種情境中（例如軟體開發）實現高度自主性的顯著潛力。最近的研究顯示，LLM 代理可以利用過去的經驗來減少錯誤並提高效率。然而，靜態經驗範例依賴於透過啟發法獲得的固定過往經驗集合，缺乏反覆修正，因此阻礙了代理的適應性。在本文中，我們介紹了反覆經驗修正架構，使 LLM 代理能夠在任務執行期間反覆修正經驗。我們提出了兩個基本模式：連續模式，根據任務批次內最近的經驗進行修正，以及累積模式，獲得所有先前任務批次的經驗。透過我們的啟發式經驗消除方法，該方法優先考慮高品質且經常使用的經驗，有效管理經驗空間並提高效率。廣泛的實驗表明，雖然連續模式可能會產生更好的結果，但累積模式提供了更穩定的效能。此外，經驗消除有助於僅使用 11.54% 的高品質子集來實現更好的效能。

##### **NL2Plan: Robust LLM-Driven Planning from Minimal Text Descriptions**
2405.04215v1 by Elliot Gestrin, Marco Kuhlmann, Jendrik Seipp

Today's classical planners are powerful, but modeling input tasks in formats
such as PDDL is tedious and error-prone. In contrast, planning with Large
Language Models (LLMs) allows for almost any input text, but offers no
guarantees on plan quality or even soundness. In an attempt to merge the best
of these two approaches, some work has begun to use LLMs to automate parts of
the PDDL creation process. However, these methods still require various degrees
of expert input. We present NL2Plan, the first domain-agnostic offline
LLM-driven planning system. NL2Plan uses an LLM to incrementally extract the
necessary information from a short text prompt before creating a complete PDDL
description of both the domain and the problem, which is finally solved by a
classical planner. We evaluate NL2Plan on four planning domains and find that
it solves 10 out of 15 tasks - a clear improvement over a plain
chain-of-thought reasoning LLM approach, which only solves 2 tasks. Moreover,
in two out of the five failure cases, instead of returning an invalid plan,
NL2Plan reports that it failed to solve the task. In addition to using NL2Plan
in end-to-end mode, users can inspect and correct all of its intermediate
results, such as the PDDL representation, increasing explainability and making
it an assistive tool for PDDL creation.

摘要：現今的經典規劃器很強大，但以 PDDL 等格式建模輸入任務很繁瑣且容易出錯。相反地，使用大型語言模型 (LLM) 規劃允許幾乎任何輸入文字，但不能保證計畫品質或甚至健全性。為了合併這兩種方法的優點，一些工作已開始使用 LLM 自動化 PDDL 建立過程的一部分。然而，這些方法仍然需要不同程度的專家輸入。我們提出 NL2Plan，這是第一個與網域無關的離線 LLM 驅動計畫系統。NL2Plan 使用 LLM 從簡短的文字提示中逐步提取必要的資訊，然後建立網域和問題的完整 PDDL 說明，最後由經典規劃器解決。我們在四個規劃網域中評估 NL2Plan，發現它解決了 15 個任務中的 10 個，明顯優於僅解決 2 個任務的純粹思考鏈推理 LLM 方法。此外，在五個失敗案例中的兩個案例中，NL2Plan 並未傳回無效計畫，而是報告它無法解決任務。除了在端對端模式中使用 NL2Plan 外，使用者還可以檢查和更正其所有中間結果，例如 PDDL 表示，增加可解釋性並使其成為 PDDL 建立的輔助工具。

##### **Green Tsetlin Redefining Efficiency in Tsetlin Machine Frameworks**
2405.04212v1 by Sondre Glimsdal, Sebastian Østby, Tobias M. Brambo, Eirik M. Vinje

Green Tsetlin (GT) is a Tsetlin Machine (TM) framework developed to solve
real-world problems using TMs. Several frameworks already exist that provide
access to TM implementations. However, these either lack features or have a
research-first focus. GT is an easy-to-use framework that aims to lower the
complexity and provide a production-ready TM implementation that is great for
experienced practitioners and beginners. To this end, GT establishes a clear
separation between training and inference. A C++ backend with a Python
interface provides competitive training and inference performance, with the
option of running in pure Python. It also integrates support for critical
components such as exporting trained models, hyper-parameter search, and
cross-validation out-of-the-box.

摘要：Green Tsetlin (GT) 是一個 Tsetlin Machine (TM) 框架，用於使用 TM 解決實際問題。已經存在多個框架，提供對 TM 實作的存取。然而，這些框架不是缺少功能，就是以研究為優先。GT 是一個易於使用的框架，旨在降低複雜性，並提供一個對經驗豐富的從業者和初學者都很棒的生產就緒 TM 實作。為此，GT 在訓練和推論之間建立了明確的分離。具有 Python 介面的 C++ 後端提供具有競爭力的訓練和推論效能，並可選擇以純 Python 執行。它還整合了對關鍵元件的支援，例如匯出訓練過的模型、超參數搜尋和交叉驗證開箱即用。

##### **NOVA: NoC-based Vector Unit for Mapping Attention Layers on a CNN Accelerator**
2405.04206v1 by Mohit Upadhyay, Rohan Juneja, Weng-Fai Wong, Li-Shiuan Peh

Attention mechanisms are becoming increasingly popular, being used in neural
network models in multiple domains such as natural language processing (NLP)
and vision applications, especially at the edge. However, attention layers are
difficult to map onto existing neuro accelerators since they have a much higher
density of non-linear operations, which lead to inefficient utilization of
today's vector units. This work introduces NOVA, a NoC-based Vector Unit that
can perform non-linear operations within the NoC of the accelerators, and can
be overlaid onto existing neuro accelerators to map attention layers at the
edge. Our results show that the NOVA architecture is up to 37.8x more
power-efficient than state-of-the-art hardware approximators when running
existing attention-based neural networks.

摘要：注意力机制正变得越来越流行，用于自然语言处理 (NLP) 和视觉应用等多个领域的深度神经网络模型，尤其是在边缘领域。然而，注意力层难以映射到现有的神经加速器上，因为它们具有更高的非线性操作密度，从而导致对当今矢量单元的利用率低下。这项工作引入了 NOVA，一种基于 NoC 的矢量单元，它可以在加速器的 NoC 内执行非线性操作，并且可以叠加到现有的神经加速器上，以映射边缘的注意力层。我们的结果表明，在运行基于注意力的神经网络时，NOVA 架构的能效比最先进的硬件逼近器高出 37.8 倍。

##### **FedStale: leveraging stale client updates in federated learning**
2405.04171v1 by Angelo Rodio, Giovanni Neglia

Federated learning algorithms, such as FedAvg, are negatively affected by
data heterogeneity and partial client participation. To mitigate the latter
problem, global variance reduction methods, like FedVARP, leverage stale model
updates for non-participating clients. These methods are effective under
homogeneous client participation. Yet, this paper shows that, when some clients
participate much less than others, aggregating updates with different levels of
staleness can detrimentally affect the training process. Motivated by this
observation, we introduce FedStale, a novel algorithm that updates the global
model in each round through a convex combination of "fresh" updates from
participating clients and "stale" updates from non-participating ones. By
adjusting the weight in the convex combination, FedStale interpolates between
FedAvg, which only uses fresh updates, and FedVARP, which treats fresh and
stale updates equally. Our analysis of FedStale convergence yields the
following novel findings: i) it integrates and extends previous FedAvg and
FedVARP analyses to heterogeneous client participation; ii) it underscores how
the least participating client influences convergence error; iii) it provides
practical guidelines to best exploit stale updates, showing that their
usefulness diminishes as data heterogeneity decreases and participation
heterogeneity increases. Extensive experiments featuring diverse levels of
client data and participation heterogeneity not only confirm these findings but
also show that FedStale outperforms both FedAvg and FedVARP in many settings.

摘要：聯邦學習演算法（例如 FedAvg）會受到資料異質性與部分用戶參與的負面影響。為了減輕後者問題，全球變異數減少方法（例如 FedVARP）會利用過時模型更新來應付未參與用戶。這些方法在用戶參與度均勻的情況下有效。然而，本文顯示，當某些用戶參與度遠低於其他用戶時，彙總具有不同過時程度的更新可能會對訓練流程造成負面影響。基於此觀察，我們引進 FedStale，一種新演算法，它會透過參與用戶的「最新」更新與未參與用戶的「過時」更新的凸組合，在每一輪更新全球模型。透過調整凸組合中的權重，FedStale 會在僅使用最新更新的 FedAvg 與將最新和過時更新視為同等的 FedVARP 之間進行插補。我們對 FedStale 收斂性的分析產生以下新發現：i) 它整合並延伸先前的 FedAvg 和 FedVARP 分析到異質用戶參與；ii) 它強調參與度最低的用戶如何影響收斂誤差；iii) 它提供實務準則，以最佳利用過時更新，顯示它們的效用會隨著資料異質性降低和參與異質性增加而遞減。大量實驗具備不同程度的用戶資料和參與異質性，不僅證實這些發現，也顯示 FedStale 在許多設定中都優於 FedAvg 和 FedVARP。

##### **D-NLP at SemEval-2024 Task 2: Evaluating Clinical Inference Capabilities of Large Language Models**
2405.04170v1 by Duygu Altinok

Large language models (LLMs) have garnered significant attention and
widespread usage due to their impressive performance in various tasks. However,
they are not without their own set of challenges, including issues such as
hallucinations, factual inconsistencies, and limitations in
numerical-quantitative reasoning. Evaluating LLMs in miscellaneous reasoning
tasks remains an active area of research. Prior to the breakthrough of LLMs,
Transformers had already proven successful in the medical domain, effectively
employed for various natural language understanding (NLU) tasks. Following this
trend, LLMs have also been trained and utilized in the medical domain, raising
concerns regarding factual accuracy, adherence to safety protocols, and
inherent limitations. In this paper, we focus on evaluating the natural
language inference capabilities of popular open-source and closed-source LLMs
using clinical trial reports as the dataset. We present the performance results
of each LLM and further analyze their performance on a development set,
particularly focusing on challenging instances that involve medical
abbreviations and require numerical-quantitative reasoning. Gemini, our leading
LLM, achieved a test set F1-score of 0.748, securing the ninth position on the
task scoreboard. Our work is the first of its kind, offering a thorough
examination of the inference capabilities of LLMs within the medical domain.

摘要：大型語言模型（LLM）因其在各種任務中的出色表現而備受關注和廣泛使用。然而，它們並非沒有自己的挑戰，包括幻覺、事實不一致以及數字定量推理中的局限性等問題。在各種推理任務中評估 LLM 仍然是一個活躍的研究領域。在 LLM 取得突破之前，Transformers 已在醫療領域證明了其成功，有效地用於各種自然語言理解 (NLU) 任務。遵循這一趨勢，LLM 也已在醫療領域接受訓練和使用，引發了對事實準確性、遵守安全協議和固有局限性的擔憂。在本文中，我們專注於使用臨床試驗報告作為數據集來評估流行的開源和閉源 LLM 的自然語言推理能力。我們展示了每個 LLM 的性能結果，並進一步分析了它們在開發集上的性能，特別關注涉及醫療縮寫和需要數字定量推理的具有挑戰性的實例。我們的領先 LLM——Gemini 在測試集上實現了 0.748 的 F1 分數，在任務排行榜上獲得了第九名。我們的這項工作是同類工作中的第一個，提供了對 LLM 在醫療領域內推理能力的全面檢驗。

##### **LingML: Linguistic-Informed Machine Learning for Enhanced Fake News Detection**
2405.04165v1 by Jasraj Singh, Fang Liu, Hong Xu, Bee Chin Ng, Wei Zhang

Nowadays, Information spreads at an unprecedented pace in social media and
discerning truth from misinformation and fake news has become an acute societal
challenge. Machine learning (ML) models have been employed to identify fake
news but are far from perfect with challenging problems like limited accuracy,
interpretability, and generalizability. In this paper, we enhance ML-based
solutions with linguistics input and we propose LingML, linguistic-informed ML,
for fake news detection. We conducted an experimental study with a popular
dataset on fake news during the pandemic. The experiment results show that our
proposed solution is highly effective. There are fewer than two errors out of
every ten attempts with only linguistic input used in ML and the knowledge is
highly explainable. When linguistics input is integrated with advanced
large-scale ML models for natural language processing, our solution outperforms
existing ones with 1.8% average error rate. LingML creates a new path with
linguistics to push the frontier of effective and efficient fake news
detection. It also sheds light on real-world multi-disciplinary applications
requiring both ML and domain expertise to achieve optimal performance.

摘要：現今，資訊於社群媒體上以空前速度傳播，而從錯誤資訊和假新聞中辨識出真相已成為嚴峻的社會挑戰。機器學習 (ML) 模型已被用於辨識假新聞，但對於有限的準確度、可解釋性和概括性等具有挑戰性的問題來說，還遠遠稱不上完美。在本文中，我們透過語言學輸入來增強基於 ML 的解決方案，並提出語言學資訊 ML (LingML) 來偵測假新聞。我們對流行的疫情假新聞資料集進行了一項實驗研究。實驗結果顯示，我們提出的解決方案非常有效。僅使用 ML 中的語言學輸入，每十次嘗試中錯誤少於兩次，且知識具有高度可解釋性。當語言學輸入與用於自然語言處理的高階大型 ML 模型整合時，我們的解決方案以 1.8% 的平均錯誤率優於現有解決方案。LingML 透過語言學創造了一條新路徑，以推動有效且高效的假新聞偵測。它也為需要 ML 和領域專業知識才能達到最佳效能的實際多領域應用提供了見解。

##### **MEDVOC: Vocabulary Adaptation for Fine-tuning Pre-trained Language Models on Medical Text Summarization**
2405.04163v1 by Gunjan Balde, Soumyadeep Roy, Mainack Mondal, Niloy Ganguly

This work presents a dynamic vocabulary adaptation strategy, MEDVOC, for
fine-tuning pre-trained language models (PLMs) like BertSumAbs, BART, and
PEGASUS for improved medical text summarization. In contrast to existing domain
adaptation approaches in summarization, MEDVOC treats vocabulary as an
optimizable parameter and optimizes the PLM vocabulary based on fragment score
conditioned only on the downstream task's reference summaries. Unlike previous
works on vocabulary adaptation (limited only to classification tasks),
optimizing vocabulary based on summarization tasks requires an extremely costly
intermediate fine-tuning step on large summarization datasets. To that end, our
novel fragment score-based hyperparameter search very significantly reduces
this fine-tuning time -- from 450 days to less than 2 days on average.
Furthermore, while previous works on vocabulary adaptation are often primarily
tied to single PLMs, MEDVOC is designed to be deployable across multiple PLMs
(with varying model vocabulary sizes, pre-training objectives, and model sizes)
-- bridging the limited vocabulary overlap between the biomedical literature
domain and PLMs. MEDVOC outperforms baselines by 15.74% in terms of Rouge-L in
zero-shot setting and shows gains of 17.29% in high Out-Of-Vocabulary (OOV)
concentrations. Our human evaluation shows MEDVOC generates more faithful
medical summaries (88% compared to 59% in baselines). We make the codebase
publicly available at https://github.com/gb-kgp/MEDVOC.

摘要：此研究提出了一種動態詞彙適應策略 MEDVOC，用於微調預先訓練的語言模型 (PLM)，例如 BertSumAbs、BART 和 Pegasus，以改善醫療文本摘要。與摘要中現有的領域適應方法不同，MEDVOC 將詞彙視為可最佳化的參數，並根據僅以下游任務的參考摘要為條件的片段分數最佳化 PLM 詞彙。與之前關於詞彙適應的研究（僅限於分類任務）不同，根據摘要任務最佳化詞彙需要對大型摘要資料集進行極其昂貴的中間微調步驟。為此，我們新穎的基於片段分數的超參數搜尋大幅減少了此微調時間——從平均 450 天減少到不到 2 天。此外，雖然之前關於詞彙適應的研究通常主要與單一 PLM 相關，但 MEDVOC 被設計為可部署於多個 PLM（具有不同的模型詞彙大小、預訓練目標和模型大小）——彌合了生物醫學文獻領域與 PLM 之間有限的詞彙重疊。MEDVOC 在零次學習設定中，以 Rouge-L 的方式優於基準 15.74%，並在高 Out-Of-Vocabulary (OOV) 濃度中顯示出 17.29% 的增益。我們的人類評估顯示，MEDVOC 生成了更忠實的醫療摘要（88%，而基準為 59%）。我們將程式碼庫公開於 https://github.com/gb-kgp/MEDVOC。

##### **A Causal Explainable Guardrails for Large Language Models**
2405.04160v1 by Zhixuan Chu, Yan Wang, Longfei Li, Zhibo Wang, Zhan Qin, Kui Ren

Large Language Models (LLMs) have shown impressive performance in natural
language tasks, but their outputs can exhibit undesirable attributes or biases.
Existing methods for steering LLMs towards desired attributes often assume
unbiased representations and rely solely on steering prompts. However, the
representations learned from pre-training can introduce semantic biases that
influence the steering process, leading to suboptimal results. We propose
LLMGuardaril, a novel framework that incorporates causal analysis and
adversarial learning to obtain unbiased steering representations in LLMs.
LLMGuardaril systematically identifies and blocks the confounding effects of
biases, enabling the extraction of unbiased steering representations.
Additionally, it includes an explainable component that provides insights into
the alignment between the generated output and the desired direction.
Experiments demonstrate LLMGuardaril's effectiveness in steering LLMs towards
desired attributes while mitigating biases. Our work contributes to the
development of safe and reliable LLMs that align with desired attributes. We
discuss the limitations and future research directions, highlighting the need
for ongoing research to address the ethical implications of large language
models.

摘要：大型語言模型 (LLM) 已展現出在自然語言任務中令人印象深刻的表現，但其輸出可能表現出不良的屬性或偏見。現有的引導 LLM 朝向所需屬性的方法通常假設無偏見的表徵，並僅依賴於引導提示。然而，從預訓練中學習到的表徵可能會引入影響引導過程的語義偏見，導致次佳結果。我們提出 LLMGuardaril，一種新的框架，它結合因果分析和對抗學習，以在 LLM 中獲得無偏見的引導表徵。LLMGuardaril 系統性地識別並阻擋偏見的混淆效應，從而能夠提取無偏見的引導表徵。此外，它還包含一個可解釋的組件，可提供對生成輸出與所需方向之間對齊的見解。實驗證明了 LLMGuardaril 在引導 LLM 朝向所需屬性的同時減輕偏見方面的有效性。我們的研究有助於開發與所需屬性對齊的安全且可靠的 LLM。我們討論了限制和未來的研究方向，強調需要持續研究以解決大型語言模型的倫理影響。

##### **GPT-Enabled Cybersecurity Training: A Tailored Approach for Effective Awareness**
2405.04138v1 by Nabil Al-Dhamari, Nathan Clarke

This study explores the limitations of traditional Cybersecurity Awareness
and Training (CSAT) programs and proposes an innovative solution using
Generative Pre-Trained Transformers (GPT) to address these shortcomings.
Traditional approaches lack personalization and adaptability to individual
learning styles. To overcome these challenges, the study integrates GPT models
to deliver highly tailored and dynamic cybersecurity learning expe-riences.
Leveraging natural language processing capabilities, the proposed approach
personalizes training modules based on individual trainee pro-files, helping to
ensure engagement and effectiveness. An experiment using a GPT model to provide
a real-time and adaptive CSAT experience through generating customized training
content. The findings have demonstrated a significant improvement over
traditional programs, addressing issues of en-gagement, dynamicity, and
relevance. GPT-powered CSAT programs offer a scalable and effective solution to
enhance cybersecurity awareness, provid-ing personalized training content that
better prepares individuals to miti-gate cybersecurity risks in their specific
roles within the organization.

摘要：本研究探討傳統的網路安全意識和訓練 (CSAT) 計畫的限制，並提出一個創新的解決方案，使用生成式預訓練轉換器 (GPT) 來解決這些缺點。傳統的方法缺乏個人化和適應個人學習風格的能力。為了克服這些挑戰，本研究整合 GPT 模型，以提供高度客製化和動態的網路安全學習體驗。利用自然語言處理功能，提出的方法根據個人受訓者的檔案個人化訓練模組，有助於確保參與度和有效性。一個使用 GPT 模型的實驗，透過產生客製化的訓練內容，提供即時且適應性的 CSAT 體驗。研究結果顯示，與傳統的計畫相比有顯著的進步，解決了參與度、動態性和相關性的問題。由 GPT 驅動的 CSAT 計畫提供了一個可擴充且有效的解決方案，以增強網路安全意識，提供個人化的訓練內容，讓個人在組織中的特定角色中更好地準備減輕網路安全風險。

##### **Enriched BERT Embeddings for Scholarly Publication Classification**
2405.04136v1 by Benjamin Wolff, Eva Seidlmayer, Konrad U. Förstner

With the rapid expansion of academic literature and the proliferation of
preprints, researchers face growing challenges in manually organizing and
labeling large volumes of articles. The NSLP 2024 FoRC Shared Task I addresses
this challenge organized as a competition. The goal is to develop a classifier
capable of predicting one of 123 predefined classes from the Open Research
Knowledge Graph (ORKG) taxonomy of research fields for a given article.This
paper presents our results. Initially, we enrich the dataset (containing
English scholarly articles sourced from ORKG and arXiv), then leverage
different pre-trained language Models (PLMs), specifically BERT, and explore
their efficacy in transfer learning for this downstream task. Our experiments
encompass feature-based and fine-tuned transfer learning approaches using
diverse PLMs, optimized for scientific tasks, including SciBERT, SciNCL, and
SPECTER2. We conduct hyperparameter tuning and investigate the impact of data
augmentation from bibliographic databases such as OpenAlex, Semantic Scholar,
and Crossref. Our results demonstrate that fine-tuning pre-trained models
substantially enhances classification performance, with SPECTER2 emerging as
the most accurate model. Moreover, enriching the dataset with additional
metadata improves classification outcomes significantly, especially when
integrating information from S2AG, OpenAlex and Crossref. Our best-performing
approach achieves a weighted F1-score of 0.7415. Overall, our study contributes
to the advancement of reliable automated systems for scholarly publication
categorization, offering a potential solution to the laborious manual curation
process, thereby facilitating researchers in efficiently locating relevant
resources.

摘要：<paragraph>隨著學術文獻的快速擴展和預印本的激增，研究人員在手動組織和標記大量文章時面臨著越來越大的挑戰。NSLP 2024 FoRC 共享任務一以競賽的形式解決了這一挑戰。目標是開發一個分類器，能夠從給定文章的研究領域的開放研究知識圖譜 (ORKG) 分類法中預測 123 個預定義類別之一。本文展示了我們的成果。最初，我們豐富了數據集（包含來自 ORKG 和 arXiv 的英文學術文章），然後利用不同的預訓練語言模型 (PLM)，特別是 BERT，並探索它們在用於此下游任務的遷移學習中的功效。我們的實驗包括使用針對科學任務進行優化的各種 PLM 的基於特徵和微調的遷移學習方法，包括 SciBERT、SciNCL 和 SPECTER2。我們進行超參數調整，並研究來自 OpenAlex、Semantic Scholar 和 Crossref 等書目數據庫的數據增強的影響。我們的結果表明，微調預訓練模型可以顯著提高分類性能，而 SPECTER2 成為最準確的模型。此外，使用額外的元數據豐富數據集可以顯著改善分類結果，特別是在整合來自 S2AG、OpenAlex 和 Crossref 的信息時。我們性能最好的方法實現了 0.7415 的加權 F1 分數。總的來說，我們的研究有助於推進用於學術出版物分類的可靠自動化系統，為繁瑣的手動策展過程提供了一個潛在的解決方案，從而幫助研究人員有效地找到相關資源。</paragraph>

##### **In-context Learning for Automated Driving Scenarios**
2405.04135v1 by Ziqi Zhou, Jingyue Zhang, Jingyuan Zhang, Boyue Wang, Tianyu Shi, Alaa Khamis

One of the key challenges in current Reinforcement Learning (RL)-based
Automated Driving (AD) agents is achieving flexible, precise, and human-like
behavior cost-effectively. This paper introduces an innovative approach
utilizing Large Language Models (LLMs) to intuitively and effectively optimize
RL reward functions in a human-centric way. We developed a framework where
instructions and dynamic environment descriptions are input into the LLM. The
LLM then utilizes this information to assist in generating rewards, thereby
steering the behavior of RL agents towards patterns that more closely resemble
human driving. The experimental results demonstrate that this approach not only
makes RL agents more anthropomorphic but also reaches better performance.
Additionally, various strategies for reward-proxy and reward-shaping are
investigated, revealing the significant impact of prompt design on shaping an
AD vehicle's behavior. These findings offer a promising direction for the
development of more advanced and human-like automated driving systems. Our
experimental data and source code can be found here.

摘要：在當前基於強化學習 (RL) 的自動駕駛 (AD) 代理中，關鍵挑戰之一是以具有成本效益的方式實現靈活、精確且類人的行為。本文介紹了一種創新的方法，利用大型語言模型 (LLM) 以直觀且有效的方式以人為中心的方式最佳化 RL 獎勵函數。我們開發了一個框架，其中將指令和動態環境描述輸入到 LLM 中。然後，LLM 利用這些資訊來協助產生獎勵，從而引導 RL 代理的行為朝更接近人類駕駛的模式。實驗結果表明，這種方法不僅使 RL 代理更擬人化，而且還達到了更好的性能。此外，研究了各種獎勵代理和獎勵塑造策略，揭示了提示設計對塑造 AD 車輛行為的重大影響。這些發現為開發更先進、更類人的自動駕駛系統提供了有希望的方向。我們的實驗數據和源代碼可以在這裡找到。

##### **Fine-grained Speech Sentiment Analysis in Chinese Psychological Support Hotlines Based on Large-scale Pre-trained Model**
2405.04128v1 by Zhonglong Chen, Changwei Song, Yining Chen, Jianqiang Li, Guanghui Fu, Yongsheng Tong, Qing Zhao

Suicide and suicidal behaviors remain significant challenges for public
policy and healthcare. In response, psychological support hotlines have been
established worldwide to provide immediate help to individuals in mental
crises. The effectiveness of these hotlines largely depends on accurately
identifying callers' emotional states, particularly underlying negative
emotions indicative of increased suicide risk. However, the high demand for
psychological interventions often results in a shortage of professional
operators, highlighting the need for an effective speech emotion recognition
model. This model would automatically detect and analyze callers' emotions,
facilitating integration into hotline services. Additionally, it would enable
large-scale data analysis of psychological support hotline interactions to
explore psychological phenomena and behaviors across populations. Our study
utilizes data from the Beijing psychological support hotline, the largest
suicide hotline in China. We analyzed speech data from 105 callers containing
20,630 segments and categorized them into 11 types of negative emotions. We
developed a negative emotion recognition model and a fine-grained multi-label
classification model using a large-scale pre-trained model. Our experiments
indicate that the negative emotion recognition model achieves a maximum
F1-score of 76.96%. However, it shows limited efficacy in the fine-grained
multi-label classification task, with the best model achieving only a 41.74%
weighted F1-score. We conducted an error analysis for this task, discussed
potential future improvements, and considered the clinical application
possibilities of our study. All the codes are public available.

摘要：<paragraph>自殺和自殺行為仍然是公共政策和醫療保健的重大挑戰。為此，全球各地已建立心理支持熱線，為精神危機中的人們提供即時幫助。這些熱線的有效性在很大程度上取決於準確識別來電者的情緒狀態，特別是表示自殺風險增加的潛在負面情緒。然而，對心理干預措施的高度需求常常導致專業運營人員短缺，這凸顯了對有效的語音情緒識別模型的需求。此模型將自動檢測和分析來電者的情緒，促進與熱線服務的整合。此外，它將能夠對心理支持熱線互動進行大規模數據分析，以探索人群中的心理現象和行為。我們的研究利用了北京心理支持熱線的數據，這是中國最大的自殺熱線。我們分析了來自 105 位來電者的語音數據，其中包含 20,630 個片段，並將其歸類為 11 種類型的負面情緒。我們使用大規模預訓練模型開發了一個負面情緒識別模型和一個細粒度多標籤分類模型。我們的實驗表明，負面情緒識別模型達到了 76.96% 的最高 F1 分數。然而，它在細粒度多標籤分類任務中顯示出有限的功效，最好的模型僅達到 41.74% 的加權 F1 分數。我們對此任務進行了錯誤分析，討論了潛在的未來改進，並考慮了我們研究的臨床應用可能性。所有代碼均公開可用。</paragraph>

##### **Comparative Study of Recurrent Neural Networks for Virtual Analog Audio Effects Modeling**
2405.04124v1 by Riccardo Simionato, Stefano Fasciani

Analog electronic circuits are at the core of an important category of
musical devices. The nonlinear features of their electronic components give
analog musical devices a distinctive timbre and sound quality, making them
highly desirable. Artificial neural networks have rapidly gained popularity for
the emulation of analog audio effects circuits, particularly recurrent
networks. While neural approaches have been successful in accurately modeling
distortion circuits, they require architectural improvements that account for
parameter conditioning and low latency response. In this article, we explore
the application of recent machine learning advancements for virtual analog
modeling. We compare State Space models and Linear Recurrent Units against the
more common Long Short Term Memory networks. These have shown promising ability
in sequence to sequence modeling tasks, showing a notable improvement in signal
history encoding. Our comparative study uses these black box neural modeling
techniques with a variety of audio effects. We evaluate the performance and
limitations using multiple metrics aiming to assess the models' ability to
accurately replicate energy envelopes, frequency contents, and transients in
the audio signal. To incorporate control parameters we employ the Feature wise
Linear Modulation method. Long Short Term Memory networks exhibit better
accuracy in emulating distortions and equalizers, while the State Space model,
followed by Long Short Term Memory networks when integrated in an encoder
decoder structure, outperforms others in emulating saturation and compression.
When considering long time variant characteristics, the State Space model
demonstrates the greatest accuracy. The Long Short Term Memory and, in
particular, Linear Recurrent Unit networks present more tendency to introduce
audio artifacts.

摘要：類比電子電路是重要音樂裝置類別的核心。其電子元件的非線性特性賦予類比音樂裝置獨特的音色和音質，讓它們極具吸引力。人工神經網路迅速流行起來，用於模擬類比音訊效果電路，尤其是遞迴網路。雖然神經方法已成功精確建模失真電路，但它們需要考量參數調整和低延遲回應的架構改進。在本文中，我們探討了近期機器學習進展在虛擬類比建模中的應用。我們將狀態空間模型和線性遞迴單元與更常見的長短期記憶網路進行比較。這些模型在序列到序列建模任務中展現出令人滿意的能力，在訊號歷程編碼中展現出顯著的改進。我們的比較研究使用這些黑盒神經建模技術，並搭配各種音訊效果。我們使用多種指標評估效能和限制，旨在評估模型精確複製音訊訊號中的能量包絡、頻率內容和瞬態的能力。為了納入控制參數，我們採用特徵線性調變方法。長短期記憶網路在模擬失真和均衡器方面展現出更好的準確度，而狀態空間模型在整合到編碼器解碼器結構時，其次是長短期記憶網路，在模擬飽和度和壓縮方面優於其他模型。在考慮長時間變異特性時，狀態空間模型展現出最高的準確度。長短期記憶網路，尤其是線性遞迴單元網路，呈現出引入音訊偽像的更大傾向。

##### **Policy Learning with a Language Bottleneck**
2405.04118v1 by Megha Srivastava, Cedric Colas, Dorsa Sadigh, Jacob Andreas

Modern AI systems such as self-driving cars and game-playing agents achieve
superhuman performance, but often lack human-like features such as
generalization, interpretability and human inter-operability. Inspired by the
rich interactions between language and decision-making in humans, we introduce
Policy Learning with a Language Bottleneck (PLLB), a framework enabling AI
agents to generate linguistic rules that capture the strategies underlying
their most rewarding behaviors. PLLB alternates between a rule generation step
guided by language models, and an update step where agents learn new policies
guided by rules. In a two-player communication game, a maze solving task, and
two image reconstruction tasks, we show that PLLB agents are not only able to
learn more interpretable and generalizable behaviors, but can also share the
learned rules with human users, enabling more effective human-AI coordination.

摘要：現代 AI 系統，例如自動駕駛汽車和遊戲代理，已達到超越人類的表現，但通常缺乏人類特質，例如概括、可解釋和人類互操作性。受到人類語言和決策制定之間豐富互動的啟發，我們引入了帶有語言瓶頸的策略學習 (PLLB)，一個使 AI 代理能夠生成語言規則的框架，以捕捉其最具回報行為背後的策略。PLLB 在由語言模型引導的規則生成步驟和代理學習由規則引導的新策略的更新步驟之間交替。在雙人溝通遊戲、迷宮求解任務和兩個圖像重建任務中，我們展示了 PLLB 代理不僅能夠學習更具可解釋性和概括性的行為，而且還能與人類使用者分享學習到的規則，從而實現更有效的人機協調。

##### **A2-DIDM: Privacy-preserving Accumulator-enabled Auditing for Distributed Identity of DNN Model**
2405.04108v1 by Tianxiu Xie, Keke Gai, Jing Yu, Liehuang Zhu, Kim-Kwang Raymond Choo

Recent booming development of Generative Artificial Intelligence (GenAI) has
facilitated an emerging model commercialization for the purpose of
reinforcement on model performance, such as licensing or trading Deep Neural
Network (DNN) models. However, DNN model trading may trigger concerns of the
unauthorized replications or misuses over the model, so that the benefit of the
model ownership will be violated. Model identity auditing is a challenging
issue in protecting intellectual property of DNN models and verifying the
integrity and ownership of models for guaranteeing trusts in transactions is
one of the critical obstacles. In this paper, we focus on the above issue and
propose a novel Accumulator-enabled Auditing for Distributed Identity of DNN
Model (A2-DIDM) that utilizes blockchain and zero-knowledge techniques to
protect data and function privacy while ensuring the lightweight on-chain
ownership verification. The proposed model presents a scheme of identity
records via configuring model weight checkpoints with corresponding
zero-knowledge proofs, which incorporates predicates to capture incremental
state changes in model weight checkpoints. Our scheme ensures both
computational integrity of DNN training process and programmability, so that
the uniqueness of the weight checkpoint sequence in a DNN model is preserved,
ensuring the correctness of the model identity auditing. In addition, A2-DIDM
also addresses privacy protections in distributed identity via a proposed
method of accumulators. We systematically analyze the security and robustness
of our proposed model and further evaluate the effectiveness and usability of
auditing DNN model identities.

摘要：最近生成式人工智能 (GenAI) 的蓬勃發展
促進了新興模式商業化，以加強模型效能，例如授權或交易深度神經網路 (DNN) 模型。然而，DNN 模型交易可能會引發對未經授權複製或濫用模型的擔憂，因此模型所有權的好處將會受到侵犯。模型身分稽核是保護 DNN 模型智慧財產權的一項挑戰，而驗證模型的完整性和所有權以保證交易中的信任是關鍵障礙之一。在本文中，我們專注於上述問題，並提出一個新的累加器啟用 DNN 模型分佈式身分稽核 (A2-DIDM)，利用區塊鏈和零知識技術來保護資料和功能隱私，同時確保輕量級的鏈上所有權驗證。所提出的模型提出了一個身分記錄方案，通過使用對應的零知識證明配置模型權重檢查點，其中包含了用於擷取模型權重檢查點中增量狀態變化的謂詞。我們的方案確保了 DNN 訓練過程的計算完整性和可程式性，從而保留了 DNN 模型中權重檢查點序列的唯一性，確保了模型身分稽核的正確性。此外，A2-DIDM 還通過提出的累加器方法來解決分佈式身分中的隱私保護。我們系統地分析了我們所提出的模型的安全性與穩健性，並進一步評估了稽核 DNN 模型身分的有效性和可用性。

##### **Continual Learning in the Presence of Repetition**
2405.04101v1 by Hamed Hemati, Lorenzo Pellegrini, Xiaotian Duan, Zixuan Zhao, Fangfang Xia, Marc Masana, Benedikt Tscheschner, Eduardo Veas, Yuxiang Zheng, Shiji Zhao, Shao-Yuan Li, Sheng-Jun Huang, Vincenzo Lomonaco, Gido M. van de Ven

Continual learning (CL) provides a framework for training models in
ever-evolving environments. Although re-occurrence of previously seen objects
or tasks is common in real-world problems, the concept of repetition in the
data stream is not often considered in standard benchmarks for CL. Unlike with
the rehearsal mechanism in buffer-based strategies, where sample repetition is
controlled by the strategy, repetition in the data stream naturally stems from
the environment. This report provides a summary of the CLVision challenge at
CVPR 2023, which focused on the topic of repetition in class-incremental
learning. The report initially outlines the challenge objective and then
describes three solutions proposed by finalist teams that aim to effectively
exploit the repetition in the stream to learn continually. The experimental
results from the challenge highlight the effectiveness of ensemble-based
solutions that employ multiple versions of similar modules, each trained on
different but overlapping subsets of classes. This report underscores the
transformative potential of taking a different perspective in CL by employing
repetition in the data stream to foster innovative strategy design.

摘要：持續學習 (CL) 提供了一個在不斷演化的環境中訓練模型的架構。儘管在現實世界的問題中，先前看過的物件或任務會再次出現，但 CL 標準基準測試中並不常考慮資料串流中的重複概念。與基於緩衝區策略的排練機制不同，其中樣本重複是由策略控制的，資料串流中的重複自然而然地來自環境。本報告提供了 CVPR 2023 中 CLVision 挑戰的摘要，重點在於類別增量學習中的重複主題。本報告最初概述了挑戰目標，然後描述了決賽團隊提出的三種解決方案，旨在有效利用串流中的重複來持續學習。挑戰中的實驗結果突顯了採用多個類似模組版本的基於集合的解決方案的有效性，每個模組都訓練於不同但重疊的類別子集。本報告強調了透過採用資料串流中的重複來促進創新策略設計，從而改變 CL 視角的轉化潛力。

##### **Unmasking Illusions: Understanding Human Perception of Audiovisual Deepfakes**
2405.04097v1 by Ammarah Hashmi, Sahibzada Adil Shahzad, Chia-Wen Lin, Yu Tsao, Hsin-Min Wang

The emergence of contemporary deepfakes has attracted significant attention
in machine learning research, as artificial intelligence (AI) generated
synthetic media increases the incidence of misinterpretation and is difficult
to distinguish from genuine content. Currently, machine learning techniques
have been extensively studied for automatically detecting deepfakes. However,
human perception has been less explored. Malicious deepfakes could ultimately
cause public and social problems. Can we humans correctly perceive the
authenticity of the content of the videos we watch? The answer is obviously
uncertain; therefore, this paper aims to evaluate the human ability to discern
deepfake videos through a subjective study. We present our findings by
comparing human observers to five state-ofthe-art audiovisual deepfake
detection models. To this end, we used gamification concepts to provide 110
participants (55 native English speakers and 55 non-native English speakers)
with a webbased platform where they could access a series of 40 videos (20 real
and 20 fake) to determine their authenticity. Each participant performed the
experiment twice with the same 40 videos in different random orders. The videos
are manually selected from the FakeAVCeleb dataset. We found that all AI models
performed better than humans when evaluated on the same 40 videos. The study
also reveals that while deception is not impossible, humans tend to
overestimate their detection capabilities. Our experimental results may help
benchmark human versus machine performance, advance forensics analysis, and
enable adaptive countermeasures.

摘要：<paragraph>當代深度造假的出現，在機器學習研究中引起了極大的關注，因為人工智慧 (AI) 所生成的合成媒體增加了誤解的發生率，並且難以與真實內容區分。目前，機器學習技術已經被廣泛研究，用於自動檢測深度造假。然而，人類的感知卻較少被探索。惡意的深度造假最終可能造成公眾和社會問題。我們人類是否能正確感知我們觀看影片內容的真實性？答案顯然是不確定的；因此，本文旨在透過主觀研究評估人類辨別深度造假影片的能力。我們透過將人類觀察者與五種最先進的視聽深度造假檢測模型進行比較，來呈現我們的研究結果。為此，我們使用了遊戲化概念，為 110 位參與者（55 位英語母語人士和 55 位非英語母語人士）提供了一個網路平台，他們可以在該平台上存取一系列 40 個影片（20 個真實影片和 20 個假影片）以確定其真實性。每位參與者都使用相同的 40 個影片，以不同的隨機順序進行了兩次實驗。這些影片是從 FakeAVCeleb 資料集手動選取的。我們發現，在對相同的 40 個影片進行評估時，所有 AI 模型的表現都優於人類。研究還表明，雖然欺騙並非不可能，但人類傾向於高估他們的檢測能力。我們的實驗結果可能有助於比較人類與機器效能、推進法醫分析，並啟用適應性對策。</paragraph>

##### **Going Proactive and Explanatory Against Malware Concept Drift**
2405.04095v1 by Yiling He, Junchi Lei, Zhan Qin, Kui Ren

Deep learning-based malware classifiers face significant challenges due to
concept drift. The rapid evolution of malware, especially with new families,
can depress classification accuracy to near-random levels. Previous research
has primarily focused on detecting drift samples, relying on expert-led
analysis and labeling for model retraining. However, these methods often lack a
comprehensive understanding of malware concepts and provide limited guidance
for effective drift adaptation, leading to unstable detection performance and
high human labeling costs.
  To address these limitations, we introduce DREAM, a novel system designed to
surpass the capabilities of existing drift detectors and to establish an
explanatory drift adaptation process. DREAM enhances drift detection through
model sensitivity and data autonomy. The detector, trained in a semi-supervised
approach, proactively captures malware behavior concepts through classifier
feedback. During testing, it utilizes samples generated by the detector itself,
eliminating reliance on extensive training data. For drift adaptation, DREAM
enlarges human intervention, enabling revisions of malware labels and concept
explanations embedded within the detector's latent space. To ensure a
comprehensive response to concept drift, it facilitates a coordinated update
process for both the classifier and the detector. Our evaluation shows that
DREAM can effectively improve the drift detection accuracy and reduce the
expert analysis effort in adaptation across different malware datasets and
classifiers.

摘要：深度學習惡意軟體分類器會因概念漂移而面臨重大挑戰。惡意軟體的快速演變，尤其是新系列的惡意軟體，可能會將分類準確度降低到接近隨機的程度。先前的研究主要專注於偵測漂移樣本，依賴於專家主導的分析和標記進行模型再訓練。然而，這些方法通常缺乏對惡意軟體概念的全面理解，且僅提供有限的指導方針來有效適應漂移，導致不穩定的偵測效能和高昂的人工標記成本。
為了解決這些限制，我們引進 DREAM，這是一個新穎的系統，旨在超越現有漂移偵測器的功能，並建立一個解釋性的漂移適應流程。DREAM 透過模型敏感度和資料自主性來增強漂移偵測。偵測器以半監督式方法訓練，透過分類器回饋主動擷取惡意軟體行為概念。在測試期間，它利用偵測器本身產生的樣本，消除了對大量訓練資料的依賴。對於漂移適應，DREAM 擴大了人工介入，讓標記和概念解釋可以嵌入偵測器的潛在空間中。為了確保對概念漂移做出全面回應，它促進了分類器和偵測器的協調更新流程。我們的評估顯示，DREAM 可以有效地提高漂移偵測準確度，並減少不同惡意軟體資料集和分類器在適應中的專家分析工作。

##### **DCNN: Dual Cross-current Neural Networks Realized Using An Interactive Deep Learning Discriminator for Fine-grained Objects**
2405.04093v1 by Da Fu, Mingfei Rong, Eun-Hu Kim, Hao Huang, Witold Pedrycz

Accurate classification of fine-grained images remains a challenge in
backbones based on convolutional operations or self-attention mechanisms. This
study proposes novel dual-current neural networks (DCNN), which combine the
advantages of convolutional operations and self-attention mechanisms to improve
the accuracy of fine-grained image classification. The main novel design
features for constructing a weakly supervised learning backbone model DCNN
include (a) extracting heterogeneous data, (b) keeping the feature map
resolution unchanged, (c) expanding the receptive field, and (d) fusing global
representations and local features. Experimental results demonstrated that
using DCNN as the backbone network for classifying certain fine-grained
benchmark datasets achieved performance advantage improvements of 13.5--19.5%
and 2.2--12.9%, respectively, compared to other advanced convolution or
attention-based fine-grained backbones.

摘要：精細影像的準確分類在基於卷積運算或自注意力機制的骨幹網路中仍是一項挑戰。本研究提出新穎的雙流神經網路 (DCNN)，它結合了卷積運算和自注意力機制的優點，以提升精細影像分類的準確度。用於建構弱監督學習骨幹模型 DCNN 的主要新穎設計特點包括：(a) 萃取異質資料、(b) 保持特徵圖解析度不變、(c) 擴展感受野，以及 (d) 融合全域表徵和局部特徵。實驗結果證明，使用 DCNN 作為骨幹網路來分類特定精細基準資料集，在效能優勢方面分別比其他進階的基於卷積或注意力的精細骨幹網路提升了 13.5--19.5% 和 2.2--12.9%。

##### **Optimizing Language Model's Reasoning Abilities with Weak Supervision**
2405.04086v1 by Yongqi Tong, Sizhe Wang, Dawei Li, Yifan Wang, Simeng Han, Zi Lin, Chengsong Huang, Jiaxin Huang, Jingbo Shang

While Large Language Models (LLMs) have demonstrated proficiency in handling
complex queries, much of the past work has depended on extensively annotated
datasets by human experts. However, this reliance on fully-supervised
annotations poses scalability challenges, particularly as models and data
requirements grow. To mitigate this, we explore the potential of enhancing
LLMs' reasoning abilities with minimal human supervision. In this work, we
introduce self-reinforcement, which begins with Supervised Fine-Tuning (SFT) of
the model using a small collection of annotated questions. Then it iteratively
improves LLMs by learning from the differences in responses from the SFT and
unfinetuned models on unlabeled questions. Our approach provides an efficient
approach without relying heavily on extensive human-annotated explanations.
However, current reasoning benchmarks typically only include golden-reference
answers or rationales. Therefore, we present \textsc{PuzzleBen}, a weakly
supervised benchmark that comprises 25,147 complex questions, answers, and
human-generated rationales across various domains, such as brainteasers,
puzzles, riddles, parajumbles, and critical reasoning tasks. A unique aspect of
our dataset is the inclusion of 10,000 unannotated questions, enabling us to
explore utilizing fewer supersized data to boost LLMs' inference capabilities.
Our experiments underscore the significance of \textsc{PuzzleBen}, as well as
the effectiveness of our methodology as a promising direction in future
endeavors. Our dataset and code will be published soon on \texttt{Anonymity
Link}.

摘要：<paragraph>儘管大型語言模型 (LLM) 已展現出處理複雜查詢的能力，但過去許多工作都依賴人類專家廣泛註解的資料集。然而，這種依賴於完全監督的註解會造成可擴充性的挑戰，特別是在模型和資料需求增加的情況下。為了減輕這個問題，我們探索了透過最少的人類監督來增強 LLM 推理能力的可能性。在這項工作中，我們引入了自我強化，它從使用一小部分註解問題對模型進行監督微調 (SFT) 開始。然後，它透過從 SFT 和未微調模型在未標記問題上的回應差異中學習，反覆改進 LLM。我們的做法提供了一個有效的方法，而無需過度依賴廣泛的人工註解說明。然而，目前的推理基準通常只包含黃金參考答案或依據。因此，我們提出了 \textsc{PuzzleBen}，一個弱監督基準，它包含了 25,147 個複雜的問題、答案和人類產生的依據，涵蓋各種領域，例如腦筋急轉彎、謎語、謎題、跳字謎和批判性推理任務。我們資料集的一個獨特方面是包含了 10,000 個未註解的問題，使我們能夠探索利用更少的超大型資料來提升 LLM 的推理能力。我們的實驗強調了 \textsc{PuzzleBen} 的重要性，以及我們的方法作為未來努力中一個有前途的方向的有效性。我們的資料集和程式碼將很快在 \texttt{Anonymity Link} 上發布。</paragraph>

##### **Counterfactual and Semifactual Explanations in Abstract Argumentation: Formal Foundations, Complexity and Computation**
2405.04081v1 by Gianvincenzo Alfano, Sergio Greco, Francesco Parisi, Irina Trubitsyna

Explainable Artificial Intelligence and Formal Argumentation have received
significant attention in recent years. Argumentation-based systems often lack
explainability while supporting decision-making processes. Counterfactual and
semifactual explanations are interpretability techniques that provide insights
into the outcome of a model by generating alternative hypothetical instances.
While there has been important work on counterfactual and semifactual
explanations for Machine Learning models, less attention has been devoted to
these kinds of problems in argumentation. In this paper, we explore
counterfactual and semifactual reasoning in abstract Argumentation Framework.
We investigate the computational complexity of counterfactual- and
semifactual-based reasoning problems, showing that they are generally harder
than classical argumentation problems such as credulous and skeptical
acceptance. Finally, we show that counterfactual and semifactual queries can be
encoded in weak-constrained Argumentation Framework, and provide a
computational strategy through ASP solvers.

摘要：可解釋人工智慧與形式論證在近年獲得極大的關注。基於論證的系統在支援決策過程中，往往缺乏可解釋性。反事實與半事實解釋是可解釋性技術，透過產生替代的假設實例，提供模型結果的見解。儘管機器學習模型的反事實與半事實解釋已有重要的研究，但論證中這類問題較少受到關注。在本文中，我們探討抽象論證框架中的反事實與半事實推理。我們研究反事實與半事實推理問題的計算複雜度，證明它們通常比經典的論證問題（例如輕信與懷疑接受）更難。最後，我們證明反事實與半事實查詢可以編碼在弱約束論證框架中，並透過 ASP 求解器提供計算策略。

##### **WISER: Weak supervISion and supErvised Representation learning to improve drug response prediction in cancer**
2405.04078v1 by Kumar Shubham, Aishwarya Jayagopal, Syed Mohammed Danish, Prathosh AP, Vaibhav Rajan

Cancer, a leading cause of death globally, occurs due to genomic changes and
manifests heterogeneously across patients. To advance research on personalized
treatment strategies, the effectiveness of various drugs on cells derived from
cancers (`cell lines') is experimentally determined in laboratory settings.
Nevertheless, variations in the distribution of genomic data and drug responses
between cell lines and humans arise due to biological and environmental
differences. Moreover, while genomic profiles of many cancer patients are
readily available, the scarcity of corresponding drug response data limits the
ability to train machine learning models that can predict drug response in
patients effectively. Recent cancer drug response prediction methods have
largely followed the paradigm of unsupervised domain-invariant representation
learning followed by a downstream drug response classification step.
Introducing supervision in both stages is challenging due to heterogeneous
patient response to drugs and limited drug response data. This paper addresses
these challenges through a novel representation learning method in the first
phase and weak supervision in the second. Experimental results on real patient
data demonstrate the efficacy of our method (WISER) over state-of-the-art
alternatives on predicting personalized drug response.

摘要：癌症是全球主要的死亡原因，其發生是由於基因體改變，並在不同患者間表現出異質性。為了推進個人化治療策略的研究，實驗室環境中會根據源自癌症的細胞（「細胞株」）來確定各種藥物對細胞的有效性。儘管如此，由於生物學和環境差異，導致細胞株與人類之間的基因體數據分佈和藥物反應有所不同。此外，雖然許多癌症患者的基因體特徵很容易取得，但相應藥物反應數據的稀少性限制了訓練機器學習模型的能力，而這些模型可以有效預測患者的藥物反應。最近的癌症藥物反應預測方法在很大程度上遵循了無監督域不變表示學習的範例，然後再進行下游藥物反應分類步驟。由於患者對藥物的反應不同，且藥物反應數據有限，因此在兩個階段中引入監督是具有挑戰性的。本文透過第一階段的新穎表示學習方法和第二階段的弱監督來解決這些挑戰。真實患者數據的實驗結果證明了我們的方法（WISER）在預測個人化藥物反應方面優於最先進的替代方案。

##### **A simple theory for training response of deep neural networks**
2405.04074v1 by Kenichi Nakazato

Deep neural networks give us a powerful method to model the training
dataset's relationship between input and output. We can regard that as a
complex adaptive system consisting of many artificial neurons that work as an
adaptive memory as a whole. The network's behavior is training dynamics with a
feedback loop from the evaluation of the loss function. We already know the
training response can be constant or shows power law-like aging in some ideal
situations. However, we still have gaps between those findings and other
complex phenomena, like network fragility. To fill the gap, we introduce a very
simple network and analyze it. We show the training response consists of some
different factors based on training stages, activation functions, or training
methods. In addition, we show feature space reduction as an effect of
stochastic training dynamics, which can result in network fragility. Finally,
we discuss some complex phenomena of deep networks.

摘要：深度神經網路提供我們一個強大的方法，可以模擬訓練資料集輸入與輸出的關係。我們可以將其視為一個複雜的適應系統，由許多人工神經元組成，而這些神經元整體上作為一個適應記憶體運作。網路的行為是透過損失函數評估的回饋迴路進行訓練動態。我們已經知道，在某些理想情況下，訓練反應可以是常數，或顯示類似冪律的老化。然而，我們仍然在這些發現與其他複雜現象（例如網路脆弱性）之間存在差距。為了填補這個差距，我們引入了一個非常簡單的網路並對其進行分析。我們展示了訓練反應包含一些不同的因素，這些因素取決於訓練階段、啟用函數或訓練方法。此外，我們展示了特徵空間簡約化作為隨機訓練動態的影響，這可能會導致網路脆弱性。最後，我們討論了深度網路的一些複雜現象。

##### **FlashBack:Efficient Retrieval-Augmented Language Modeling for Long Context Inference**
2405.04065v1 by Runheng Liu, Xingchen Xiao, Heyan Huang, Zewen Chi, Zhijing Wu

Retrieval-Augmented Language Modeling (RALM) by integrating large language
models (LLM) with relevant documents from an external corpus is a proven method
for enabling the LLM to generate information beyond the scope of its
pre-training corpus. Previous work using utilizing retrieved content by simply
prepending retrieved contents to the input poses a high runtime issue, which
degrades the inference efficiency of the LLMs because they fail to use the
Key-Value (KV) cache efficiently. In this paper, we propose \textsc{FlashBack},
a modular RALM designed to improve the inference efficiency of RALM with
appending context pattern while maintaining decent performance after specific
fine-tuning without heavily destruct the knowledge integrity of the LLM.
\textsc{FlashBack} appends retrieved documents at the end of the context for
efficiently utilizing the KV cache instead of prepending them. Our experiment
shows that the inference speed of \textsc{FlashBack} is up to $4\times$ faster
than the prepending method on a 7B LLM (Llama 2). Via bypassing unnecessary
re-computation, it demonstrates an advancement by achieving significantly
faster inference speed, and this heightened efficiency will substantially
reduce inferential cost. Our code will be publicly available.

摘要：檢索擴充語言模型 (RALM) 透過整合大型語言模型 (LLM) 與外部語料庫中的相關文件，是一種已證實的方法，可讓 LLM 產生超出其預訓練語料庫範圍的資訊。先前利用檢索內容的工作，僅透過將檢索內容預先附加至輸入，會造成高執行時間問題，進而降低 LLM 推論效率，因為他們無法有效使用鍵值 (KV) 快取。在本文中，我們提出 \textsc{FlashBack}，一個模組化 RALM，旨在透過附加脈絡模式來改善 RALM 的推論效率，同時在特定微調後維持良好的效能，而不會嚴重破壞 LLM 的知識完整性。\textsc{FlashBack} 將檢索到的文件附加在脈絡的結尾，以有效利用 KV 快取，而非將其預先附加。我們的實驗顯示，\textsc{FlashBack} 的推論速度在 7B LLM (Llama 2) 上比預先附加方法快 $4\times$ 以上。透過繞過不必要的重新運算，它透過達成顯著更快的推論速度來展現進展，而這種更高的效率將大幅降低推論成本。我們的程式碼將公開提供。

##### **Evaluating Text Summaries Generated by Large Language Models Using OpenAI's GPT**
2405.04053v1 by Hassan Shakil, Atqiya Munawara Mahi, Phuoc Nguyen, Zeydy Ortiz, Mamoun T. Mardini

This research examines the effectiveness of OpenAI's GPT models as
independent evaluators of text summaries generated by six transformer-based
models from Hugging Face: DistilBART, BERT, ProphetNet, T5, BART, and PEGASUS.
We evaluated these summaries based on essential properties of high-quality
summary - conciseness, relevance, coherence, and readability - using
traditional metrics such as ROUGE and Latent Semantic Analysis (LSA). Uniquely,
we also employed GPT not as a summarizer but as an evaluator, allowing it to
independently assess summary quality without predefined metrics. Our analysis
revealed significant correlations between GPT evaluations and traditional
metrics, particularly in assessing relevance and coherence. The results
demonstrate GPT's potential as a robust tool for evaluating text summaries,
offering insights that complement established metrics and providing a basis for
comparative analysis of transformer-based models in natural language processing
tasks.

摘要：本研究檢視了 OpenAI 的 GPT 模型作為 Hugging Face 中六個Transformer模型（DistilBART、BERT、ProphetNet、T5、BART 和 PEGASUS）所產生文字摘要的獨立評估員的有效性。我們根據高品質摘要的基本屬性（簡潔性、相關性、一致性和可讀性）來評估這些摘要，並使用傳統指標，例如 ROUGE 和潛在語義分析 (LSA)。獨特的是，我們不僅將 GPT 用作摘要工具，還用作評估工具，讓它能夠在沒有預定義指標的情況下獨立評估摘要品質。我們的分析顯示 GPT 評估與傳統指標之間存在顯著相關性，特別是在評估相關性和一致性方面。結果證明了 GPT 作為評估文字摘要的強大工具的潛力，它提供的見解補充了既定的指標，並為自然語言處理任務中Transformer模型的比較分析提供了基礎。

##### **Learning Linear Block Error Correction Codes**
2405.04050v1 by Yoni Choukroun, Lior Wolf

Error correction codes are a crucial part of the physical communication
layer, ensuring the reliable transfer of data over noisy channels. The design
of optimal linear block codes capable of being efficiently decoded is of major
concern, especially for short block lengths. While neural decoders have
recently demonstrated their advantage over classical decoding techniques, the
neural design of the codes remains a challenge. In this work, we propose for
the first time a unified encoder-decoder training of binary linear block codes.
To this end, we adapt the coding setting to support efficient and
differentiable training of the code for end-to-end optimization over the order
two Galois field. We also propose a novel Transformer model in which the
self-attention masking is performed in a differentiable fashion for the
efficient backpropagation of the code gradient. Our results show that (i) the
proposed decoder outperforms existing neural decoding on conventional codes,
(ii) the suggested framework generates codes that outperform the {analogous}
conventional codes, and (iii) the codes we developed not only excel with our
decoder but also show enhanced performance with traditional decoding
techniques.

摘要：錯誤修正碼是物理通訊層中至關重要的一部分，確保資料在雜訊通道中可靠傳輸。設計出能夠被有效解碼的最佳線性區塊碼是一項主要關注點，特別是對於短區塊長度而言。雖然神經解碼器最近證明了它們相較於傳統解碼技術的優勢，但神經碼設計仍然是一個挑戰。在這項工作中，我們首次提出二進制線性區塊碼的統一編碼器-解碼器訓練。為此，我們調整編碼設定以支援對應於二元伽羅瓦域的端對端最佳化的有效且可微分的碼訓練。我們還提出了一個新穎的 Transformer 模型，其中自注意力遮罩以可微分的方式執行，以進行碼梯度的有效反向傳播。我們的結果表明 (i) 提出的解碼器優於現有神經解碼在傳統碼上的表現，(ii) 建議的框架生成的碼優於{類比}傳統碼，以及 (iii) 我們開發的碼不僅在我們的解碼器中表現出色，而且在傳統解碼技術中也表現出增強的效能。

##### **Philosophy of Cognitive Science in the Age of Deep Learning**
2405.04048v1 by Raphaël Millière

Deep learning has enabled major advances across most areas of artificial
intelligence research. This remarkable progress extends beyond mere engineering
achievements and holds significant relevance for the philosophy of cognitive
science. Deep neural networks have made significant strides in overcoming the
limitations of older connectionist models that once occupied the centre stage
of philosophical debates about cognition. This development is directly relevant
to long-standing theoretical debates in the philosophy of cognitive science.
Furthermore, ongoing methodological challenges related to the comparative
evaluation of deep neural networks stand to benefit greatly from
interdisciplinary collaboration with philosophy and cognitive science. The time
is ripe for philosophers to explore foundational issues related to deep
learning and cognition; this perspective paper surveys key areas where their
contributions can be especially fruitful.

摘要：深度學習已在人工智慧研究的大部分領域中實現重大進展。這項顯著的進展不僅超越了工程方面的成就，對於認知科學哲學也具有重大意義。深度神經網路在克服舊連接模型的限制方面取得了重大進展，而這些模型曾經是認知哲學辯論的中心舞台。此項發展與認知科學哲學中長期的理論辯論直接相關。此外，與哲學和認知科學的跨領域合作將極大地有利於克服與深度神經網路比較評估相關的持續方法挑戰。哲學家探索與深度學習和認知相關的基本問題的時機已經成熟；這篇觀點論文調查了他們的貢獻可以特別富有成果的主要領域。

##### **Feature Map Convergence Evaluation for Functional Module**
2405.04041v1 by Ludan Zhang, Chaoyi Chen, Lei He, Keqiang Li

Autonomous driving perception models are typically composed of multiple
functional modules that interact through complex relationships to accomplish
environment understanding. However, perception models are predominantly
optimized as a black box through end-to-end training, lacking independent
evaluation of functional modules, which poses difficulties for interpretability
and optimization. Pioneering in the issue, we propose an evaluation method
based on feature map analysis to gauge the convergence of model, thereby
assessing functional modules' training maturity. We construct a quantitative
metric named as the Feature Map Convergence Score (FMCS) and develop Feature
Map Convergence Evaluation Network (FMCE-Net) to measure and predict the
convergence degree of models respectively. FMCE-Net achieves remarkable
predictive accuracy for FMCS across multiple image classification experiments,
validating the efficacy and robustness of the introduced approach. To the best
of our knowledge, this is the first independent evaluation method for
functional modules, offering a new paradigm for the training assessment towards
perception models.

摘要：自動駕駛感知模型通常由多個功能模組組成，這些模組透過複雜的關係進行互動，以完成環境理解。然而，感知模型主要透過端到端訓練，以黑盒的方式進行最佳化，缺乏對功能模組的獨立評估，這對可解釋性和最佳化造成困難。針對此問題，我們提出一個基於特徵圖分析的評估方法，來評估模型的收斂性，進而評估功能模組的訓練成熟度。我們建構一個稱為特徵圖收斂評分 (FMCS) 的量化指標，並開發特徵圖收斂評估網路 (FMCE-Net) 來分別測量和預測模型的收斂程度。FMCE-Net 在多個影像分類實驗中，對 FMCS 達到了顯著的預測準確度，驗證了所提出方法的效能和健壯性。據我們所知，這是第一個針對功能模組的獨立評估方法，為感知模型的訓練評估提供了新的典範。

##### **Utilizing GPT to Enhance Text Summarization: A Strategy to Minimize Hallucinations**
2405.04039v1 by Hassan Shakil, Zeydy Ortiz, Grant C. Forbes

In this research, we uses the DistilBERT model to generate extractive summary
and the T5 model to generate abstractive summaries. Also, we generate hybrid
summaries by combining both DistilBERT and T5 models. Central to our research
is the implementation of GPT-based refining process to minimize the common
problem of hallucinations that happens in AI-generated summaries. We evaluate
unrefined summaries and, after refining, we also assess refined summaries using
a range of traditional and novel metrics, demonstrating marked improvements in
the accuracy and reliability of the summaries. Results highlight significant
improvements in reducing hallucinatory content, thereby increasing the factual
integrity of the summaries.

摘要：在本研究中，我們使用 DistilBERT 模型來產生萃取式摘要，並使用 T5 模型來產生抽象式摘要。此外，我們透過結合 DistilBERT 和 T5 模型來產生混合式摘要。我們的研究核心是實作基於 GPT 的精煉流程，以將 AI 產生的摘要中常見的幻覺問題降至最低。我們評估未精煉的摘要，並在精煉後，我們也使用一系列傳統和新穎的指標評估精煉後的摘要，證明摘要的準確性和可靠性有顯著的提升。結果強調在減少幻覺內容方面有顯著的進步，進而提升摘要的事實完整性。

##### **Locally Differentially Private In-Context Learning**
2405.04032v1 by Chunyan Zheng, Keke Sun, Wenhao Zhao, Haibo Zhou, Lixin Jiang, Shaoyang Song, Chunlai Zhou

Large pretrained language models (LLMs) have shown surprising In-Context
Learning (ICL) ability. An important application in deploying large language
models is to augment LLMs with a private database for some specific task. The
main problem with this promising commercial use is that LLMs have been shown to
memorize their training data and their prompt data are vulnerable to membership
inference attacks (MIA) and prompt leaking attacks. In order to deal with this
problem, we treat LLMs as untrusted in privacy and propose a locally
differentially private framework of in-context learning(LDP-ICL) in the
settings where labels are sensitive. Considering the mechanisms of in-context
learning in Transformers by gradient descent, we provide an analysis of the
trade-off between privacy and utility in such LDP-ICL for classification.
Moreover, we apply LDP-ICL to the discrete distribution estimation problem. In
the end, we perform several experiments to demonstrate our analysis results.

摘要：大型预训练语言模型 (LLM) 已展现出惊人的情境学习 (ICL) 能力。部署大型语言模型的一项重要应用是为某些特定任务使用私有数据库增强 LLM。这种有前景的商业用途的主要问题在于，LLM 已被证明会记住其训练数据，并且其提示数据容易受到成员推断攻击 (MIA) 和提示泄露攻击。为了解决这个问题，我们把 LLM 视为隐私不可信，并提出了情境学习的局部差分隐私框架 (LDP-ICL)，用于标签敏感的情况。通过梯度下降考虑 Transformer 中情境学习的机制，我们分析了这种 LDP-ICL 在分类中隐私和效用之间的权衡。此外，我们将 LDP-ICL 应用于离散分布估计问题。最后，我们执行多项实验来证明我们的分析结果。

##### **Certified Policy Verification and Synthesis for MDPs under Distributional Reach-avoidance Properties**
2405.04015v1 by S. Akshay, Krishnendu Chatterjee, Tobias Meggendorfer, Đorđe Žikelić

Markov Decision Processes (MDPs) are a classical model for decision making in
the presence of uncertainty. Often they are viewed as state transformers with
planning objectives defined with respect to paths over MDP states. An
increasingly popular alternative is to view them as distribution transformers,
giving rise to a sequence of probability distributions over MDP states. For
instance, reachability and safety properties in modeling robot swarms or
chemical reaction networks are naturally defined in terms of probability
distributions over states. Verifying such distributional properties is known to
be hard and often beyond the reach of classical state-based verification
techniques.
  In this work, we consider the problems of certified policy (i.e. controller)
verification and synthesis in MDPs under distributional reach-avoidance
specifications. By certified we mean that, along with a policy, we also aim to
synthesize a (checkable) certificate ensuring that the MDP indeed satisfies the
property. Thus, given the target set of distributions and an unsafe set of
distributions over MDP states, our goal is to either synthesize a certificate
for a given policy or synthesize a policy along with a certificate, proving
that the target distribution can be reached while avoiding unsafe
distributions. To solve this problem, we introduce the novel notion of
distributional reach-avoid certificates and present automated procedures for
(1) synthesizing a certificate for a given policy, and (2) synthesizing a
policy together with the certificate, both providing formal guarantees on
certificate correctness. Our experimental evaluation demonstrates the ability
of our method to solve several non-trivial examples, including a multi-agent
robot-swarm model, to synthesize certified policies and to certify existing
policies.

摘要：馬可夫決策過程 (MDP) 是在不確定性存在下進行決策的經典模型。它們通常被視為狀態轉換器，其規劃目標是根據 MDP 狀態上的路徑定義的。越來越流行的替代方案是將它們視為分佈轉換器，從而產生一系列關於 MDP 狀態的機率分佈。例如，在對機器人蜂群或化學反應網路進行建模時，可達性和安全性屬性自然會根據狀態的機率分佈進行定義。驗證此類分佈屬性已知很困難，而且通常超出了基於狀態的經典驗證技術的範圍。
在這項工作中，我們考慮了在分佈到達避免規範下 MDP 中認證策略（即控制器）驗證和合成的問題。通過認證，我們的含義是，除了策略之外，我們還旨在合成一個（可檢查的）證書，以確保 MDP 確實滿足屬性。因此，給定目標分佈集和 MDP 狀態上的不安全分佈集，我們的目標是要么為給定的策略合成證書，要么合成策略和證書，證明可以在避免不安全分佈的同時達到目標分佈。為了解決這個問題，我們引入了分佈到達避免證書的新概念，並提出了自動化程序，用於 (1) 為給定的策略合成證書，以及 (2) 合成策略和證書，兩者都提供證書正確性的正式保證。我們的實驗評估證明了我們的方法解決若干非平凡範例的能力，包括多代理機器人蜂群模型，以合成認證策略和認證現有策略。

##### **Structured Click Control in Transformer-based Interactive Segmentation**
2405.04009v1 by Long Xu, Yongquan Chen, Rui Huang, Feng Wu, Shiwu Lai

Click-point-based interactive segmentation has received widespread attention
due to its efficiency. However, it's hard for existing algorithms to obtain
precise and robust responses after multiple clicks. In this case, the
segmentation results tend to have little change or are even worse than before.
To improve the robustness of the response, we propose a structured click intent
model based on graph neural networks, which adaptively obtains graph nodes via
the global similarity of user-clicked Transformer tokens. Then the graph nodes
will be aggregated to obtain structured interaction features. Finally, the dual
cross-attention will be used to inject structured interaction features into
vision Transformer features, thereby enhancing the control of clicks over
segmentation results. Extensive experiments demonstrated the proposed algorithm
can serve as a general structure in improving Transformer-based interactive
segmenta?tion performance. The code and data will be released at
https://github.com/hahamyt/scc.

摘要：基於點擊點的互動式分割由於其效率而受到廣泛關注。然而，現有的演算法在多次點擊後難以獲得精確且穩健的回應。在這種情況下，分割結果往往變化不大，甚至比以前更糟。為了提高回應的穩健性，我們提出了一個基於圖神經網路的結構化點擊意圖模型，它通過使用者點擊的 Transformer 標記的全局相似性自適應地獲取圖節點。然後將圖節點聚合以獲取結構化的互動特徵。最後，將使用雙重交叉注意力將結構化的互動特徵注入到視覺 Transformer 特徵中，從而增強點擊對分割結果的控制。大量的實驗表明，所提出的演算法可以用作改善基於 Transformer 的互動式分割效能的一般結構。程式碼和資料將在 https://github.com/hahamyt/scc 發布。

##### **Sketch Then Generate: Providing Incremental User Feedback and Guiding LLM Code Generation through Language-Oriented Code Sketches**
2405.03998v1 by Chen Zhu-Tian, Zeyu Xiong, Xiaoshuo Yao, Elena Glassman

Crafting effective prompts for code generation or editing with Large Language
Models (LLMs) is not an easy task. Particularly, the absence of immediate,
stable feedback during prompt crafting hinders effective interaction, as users
are left to mentally imagine possible outcomes until the code is generated. In
response, we introduce Language-Oriented Code Sketching, an interactive
approach that provides instant, incremental feedback in the form of code
sketches (i.e., incomplete code outlines) during prompt crafting. This approach
converts a prompt into a code sketch by leveraging the inherent linguistic
structures within the prompt and applying classic natural language processing
techniques. The sketch then serves as an intermediate placeholder that not only
previews the intended code structure but also guides the LLM towards the
desired code, thereby enhancing human-LLM interaction. We conclude by
discussing the approach's applicability and future plans.

摘要：為大型語言模型 (LLM) 編寫用於產生或編輯程式碼的有效提示並非易事。特別是，在提示編寫過程中缺乏立即且穩定的回饋會阻礙有效的互動，因為使用者只能在程式碼產生之前在腦海中想像可能的結果。為了解決此問題，我們引入了以語言為導向的程式碼草圖，這是一種互動式方法，可在提示編寫過程中提供即時、遞增的回饋，形式為程式碼草圖（即不完整的程式碼大綱）。此方法透過利用提示中的內在語言結構，並套用經典的自然語言處理技術，將提示轉換為程式碼草圖。然後，草圖會作為一個中間占位符，它不僅預覽預期的程式碼結構，還能引導 LLM 朝向所需的程式碼，進而增強人類與 LLM 的互動。我們最後討論此方法的適用性與未來計畫。

##### **TrimCaching: Parameter-sharing AI Model Caching in Wireless Edge Networks**
2405.03990v1 by Guanqiao Qu, Zheng Lin, Fangming Liu, Xianhao Chen, Kaibin Huang

Next-generation mobile networks are expected to facilitate fast AI model
downloading to end users. By caching models on edge servers, mobile networks
can deliver models to end users with low latency, resulting in a paradigm
called edge model caching. In this paper, we develop a novel model placement
scheme, called parameter-sharing model caching (TrimCaching). TrimCaching
exploits the key observation that a wide range of AI models, such as
convolutional neural networks or large language models, can share a significant
proportion of parameter blocks containing reusable knowledge, thereby improving
storage efficiency. To this end, we formulate a parameter-sharing model
placement problem to maximize the cache hit ratio in multi-edge wireless
networks by balancing the fundamental tradeoff between storage efficiency and
service latency. We show that the formulated problem is a submodular
maximization problem with submodular constraints, for which no polynomial-time
approximation algorithm exists. To overcome this challenge, we study an
important special case, where a small fixed number of parameter blocks are
shared across models, which often holds in practice. In such a case, a
polynomial-time algorithm with $\left(1-\epsilon\right)/2$-approximation
guarantee is developed. Subsequently, we address the original problem for the
general case by developing a greedy algorithm. Simulation results demonstrate
that the proposed TrimCaching framework significantly improves the cache hit
ratio compared with state-of-the-art content caching without exploiting shared
parameters in AI models.

摘要：預計下一代行動網路將會促進快速的 AI 模型下載給終端使用者。行動網路透過將模型快取在邊緣伺服器上，可以低延遲地將模型傳遞給終端使用者，進而產生一種稱為邊緣模型快取的典範。在本文中，我們開發了一個新穎的模型配置方案，稱為參數共享模型快取 (TrimCaching)。TrimCaching 利用了一個關鍵觀察，即廣泛的 AI 模型，例如卷積神經網路或大型語言模型，可以共享包含可重複使用知識的顯著比例的參數區塊，從而提高儲存效率。為此，我們制定了一個參數共享模型配置問題，以平衡儲存效率和服務延遲之間的基本權衡，進而最大化多邊緣無線網路中的快取命中率。我們證明了所制定的問題是一個具有次模約束的次模最大化問題，不存在多項式時間近似演算法。為了克服這個挑戰，我們研究了一個重要的特例，其中模型之間共享少量固定的參數區塊，這在實務上經常成立。在這種情況下，開發了一個具有 $\left(1-\epsilon\right)/2$ 近似保證的多項式時間演算法。隨後，我們透過開發貪婪演算法來解決一般情況下的原始問題。模擬結果證明，與不利用 AI 模型中共享參數的最新內容快取相比，所提出的 TrimCaching 架構顯著提高了快取命中率。

##### **Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application**
2405.03988v1 by Jian Jia, Yipei Wang, Yan Li, Honggang Chen, Xuehan Bai, Zhaocheng Liu, Jian Liang, Quan Chen, Han Li, Peng Jiang, Kun Gai

Contemporary recommender systems predominantly rely on collaborative
filtering techniques, employing ID-embedding to capture latent associations
among users and items. However, this approach overlooks the wealth of semantic
information embedded within textual descriptions of items, leading to
suboptimal performance in cold-start scenarios and long-tail user
recommendations. Leveraging the capabilities of Large Language Models (LLMs)
pretrained on massive text corpus presents a promising avenue for enhancing
recommender systems by integrating open-world domain knowledge. In this paper,
we propose an Llm-driven knowlEdge Adaptive RecommeNdation (LEARN) framework
that synergizes open-world knowledge with collaborative knowledge. We address
computational complexity concerns by utilizing pretrained LLMs as item encoders
and freezing LLM parameters to avoid catastrophic forgetting and preserve
open-world knowledge. To bridge the gap between the open-world and
collaborative domains, we design a twin-tower structure supervised by the
recommendation task and tailored for practical industrial application. Through
offline experiments on the large-scale industrial dataset and online
experiments on A/B tests, we demonstrate the efficacy of our approach.

摘要：當代推薦系統主要依賴協作過濾技術，採用 ID 嵌入來擷取使用者與項目之間的潛在關聯。然而，此方法忽略了項目文字描述中嵌入的豐富語義資訊，導致在冷啟動情境和長尾使用者推薦中效能不佳。利用在大量文字語料庫上預訓練的大型語言模型 (LLM) 的功能，提供了一個透過整合開放世界領域知識來增強推薦系統的途徑。在本文中，我們提出一個由 LLM 驅動的知識自適應推薦 (LEARN) 架構，它將開放世界知識與協作知識結合在一起。我們透過利用預訓練的 LLM 作為項目編碼器，並凍結 LLM 參數以避免災難性遺忘和保留開放世界知識，來解決運算複雜性的問題。為了彌合開放世界和協作領域之間的差距，我們設計了一個雙塔結構，由推薦任務監督，並針對實際的產業應用進行調整。透過在大型產業資料集上的離線實驗和 A/B 測試中的線上實驗，我們證明了我們方法的有效性。

##### **Factors Influencing User Willingness To Use SORA**
2405.03986v1 by Gustave Florentin Nkoulou Mvondo, Ben Niu

Sora promises to redefine the way visual content is created. Despite its
numerous forecasted benefits, the drivers of user willingness to use the
text-to-video (T2V) model are unknown. This study extends the extended unified
theory of acceptance and use of technology (UTAUT2) with perceived realism and
novelty value. Using a purposive sampling method, we collected data from 940
respondents in the US and analyzed the sample using covariance-based structural
equation modeling and fuzzy set qualitative comparative analysis (fsQCA). The
findings reveal that all hypothesized relationships are supported, with
perceived realism emerging as the most influential driver, followed by novelty
value. Moreover, fsQCA identifies five configurations leading to high and low
willingness to use, and the model demonstrates high predictive validity,
contributing to theory advancement. Our study provides valuable insights for
developers and marketers, offering guidance for strategic decisions to promote
the widespread adoption of T2V models.

摘要：Sora 承諾重新定義視覺內容的創作方式。儘管其預測的優點眾多，但使用者願意使用文字轉影片 (T2V) 模型的驅動力仍不得而知。本研究擴充了技術接受與使用統一理論 (UTAUT2) 的範圍，納入了感知真實性與新穎價值。我們使用目的性抽樣法，從美國收集了 940 位受訪者的資料，並使用基於共變數的結構方程模型和模糊集合定性比較分析 (fsQCA) 分析樣本。研究結果顯示，所有假設的關係均獲得支持，其中感知真實性為影響力最大的驅動力，其次為新穎價值。此外，fsQCA 找出五種導致高低使用意願的配置，且該模型展現出很高的預測效度，有助於理論進展。本研究為開發人員和行銷人員提供寶貴的見解，提供策略決策指引，以促進 T2V 模型的廣泛採用。

##### **TBNet: A Neural Architectural Defense Framework Facilitating DNN Model Protection in Trusted Execution Environments**
2405.03974v1 by Ziyu Liu, Tong Zhou, Yukui Luo, Xiaolin Xu

Trusted Execution Environments (TEEs) have become a promising solution to
secure DNN models on edge devices. However, the existing solutions either
provide inadequate protection or introduce large performance overhead. Taking
both security and performance into consideration, this paper presents TBNet, a
TEE-based defense framework that protects DNN model from a neural architectural
perspective. Specifically, TBNet generates a novel Two-Branch substitution
model, to respectively exploit (1) the computational resources in the untrusted
Rich Execution Environment (REE) for latency reduction and (2) the
physically-isolated TEE for model protection. Experimental results on a
Raspberry Pi across diverse DNN model architectures and datasets demonstrate
that TBNet achieves efficient model protection at a low cost.

摘要：可信執行環境 (TEE) 已成為邊緣裝置上安全 DNN 模型的理想解決方案。然而，現有的解決方案不是提供不充分的保護，就是會帶來巨大的效能開銷。本文考量安全性與效能，提出 TBNet，一個基於 TEE 的防禦架構，從神經架構角度保護 DNN 模型。具體來說，TBNet 產生一個新穎的雙分支替換模型，分別利用 (1) 不受信任的豐富執行環境 (REE) 中的運算資源來降低延遲，以及 (2) 物理隔離的 TEE 來保護模型。在覆盆子 Pi 上針對各種 DNN 模型架構和資料集進行的實驗結果證明，TBNet 以低成本實現高效的模型保護。

##### **ERATTA: Extreme RAG for Table To Answers with Large Language Models**
2405.03963v1 by Sohini Roychowdhury, Marko Krema, Anvar Mahammad, Brian Moore, Arijit Mukherjee, Punit Prakashchandra

Large language models (LLMs) with residual augmented-generation (RAG) have
been the optimal choice for scalable generative AI solutions in the recent
past. However, the choice of use-cases that incorporate RAG with LLMs have been
either generic or extremely domain specific, thereby questioning the
scalability and generalizability of RAG-LLM approaches. In this work, we
propose a unique LLM-based system where multiple LLMs can be invoked to enable
data authentication, user query routing, data retrieval and custom prompting
for question answering capabilities from data tables that are highly varying
and large in size. Our system is tuned to extract information from
Enterprise-level data products and furnish real time responses under 10
seconds. One prompt manages user-to-data authentication followed by three
prompts to route, fetch data and generate a customizable prompt natural
language responses. Additionally, we propose a five metric scoring module that
detects and reports hallucinations in the LLM responses. Our proposed system
and scoring metrics achieve >90% confidence scores across hundreds of user
queries in the sustainability, financial health and social media domains.
Extensions to the proposed extreme RAG architectures can enable heterogeneous
source querying using LLMs.

摘要：

##### **ESIHGNN: Event-State Interactions Infused Heterogeneous Graph Neural Network for Conversational Emotion Recognition**
2405.03960v1 by Xupeng Zha, Huan Zhao, Zixing Zhang

Conversational Emotion Recognition (CER) aims to predict the emotion
expressed by an utterance (referred to as an ``event'') during a conversation.
Existing graph-based methods mainly focus on event interactions to comprehend
the conversational context, while overlooking the direct influence of the
speaker's emotional state on the events. In addition, real-time modeling of the
conversation is crucial for real-world applications but is rarely considered.
Toward this end, we propose a novel graph-based approach, namely Event-State
Interactions infused Heterogeneous Graph Neural Network (ESIHGNN), which
incorporates the speaker's emotional state and constructs a heterogeneous
event-state interaction graph to model the conversation. Specifically, a
heterogeneous directed acyclic graph neural network is employed to dynamically
update and enhance the representations of events and emotional states at each
turn, thereby improving conversational coherence and consistency. Furthermore,
to further improve the performance of CER, we enrich the graph's edges with
external knowledge. Experimental results on four publicly available CER
datasets show the superiority of our approach and the effectiveness of the
introduced heterogeneous event-state interaction graph.

摘要：對話情緒辨識 (CER) 旨在預測對話中話語 (稱為「事件」) 所表達的情緒。現有的基於圖形的方法主要關注事件互動，以理解對話脈絡，同時忽略說話者情緒狀態對事件的直接影響。此外，對話的即時建模對於真實世界的應用至關重要，但很少被考慮。為此，我們提出了一種新穎的基於圖形的方法，即事件狀態互動注入異質圖形神經網路 (ESIHGNN)，它結合了說話者的情緒狀態，並構建了一個異質事件狀態互動圖形來建模對話。具體來說，採用異質有向無環圖形神經網路，在每個回合動態更新和增強事件和情緒狀態的表示，從而改善對話的連貫性和一致性。此外，為了進一步提高 CER 的性能，我們使用外部知識豐富圖形的邊緣。在四個公開可用的 CER 資料集上的實驗結果顯示了我們方法的優越性，以及引入的異質事件狀態互動圖形的有效性。

##### **Simple Drop-in LoRA Conditioning on Attention Layers Will Improve Your Diffusion Model**
2405.03958v1 by Joo Young Choi, Jaesung R. Park, Inkyu Park, Jaewoong Cho, Albert No, Ernest K. Ryu

Current state-of-the-art diffusion models employ U-Net architectures
containing convolutional and (qkv) self-attention layers. The U-Net processes
images while being conditioned on the time embedding input for each sampling
step and the class or caption embedding input corresponding to the desired
conditional generation. Such conditioning involves scale-and-shift operations
to the convolutional layers but does not directly affect the attention layers.
While these standard architectural choices are certainly effective, not
conditioning the attention layers feels arbitrary and potentially suboptimal.
In this work, we show that simply adding LoRA conditioning to the attention
layers without changing or tuning the other parts of the U-Net architecture
improves the image generation quality. For example, a drop-in addition of LoRA
conditioning to EDM diffusion model yields FID scores of 1.91/1.75 for
unconditional and class-conditional CIFAR-10 generation, improving upon the
baseline of 1.97/1.79.

摘要：目前最先進的擴散模型採用 U-Net 架構，包含卷積和 (qkv) 自注意力層。U-Net 處理影像時，會根據每個採樣步驟的時間內嵌輸入和對應於所需條件式生成的類別或標題內嵌輸入進行調整。這種調整涉及對卷積層進行縮放和平移操作，但不會直接影響注意力層。雖然這些標準架構選擇肯定有效，但對注意力層不進行調整感覺很隨意，而且潛在次優。在這項工作中，我們展示了僅將 LoRA 調整新增到注意力層，而不會改變或調整 U-Net 架構的其他部分，就能提升影像生成品質。例如，將 LoRA 調整新增到 EDM 擴散模型中，就會產生無條件和類別條件 CIFAR-10 生成的 FID 分數為 1.91/1.75，優於 1.97/1.79 的基準。

##### **HAFFormer: A Hierarchical Attention-Free Framework for Alzheimer's Disease Detection From Spontaneous Speech**
2405.03952v1 by Zhongren Dong, Zixing Zhang, Weixiang Xu, Jing Han, Jianjun Ou, Björn W. Schuller

Automatically detecting Alzheimer's Disease (AD) from spontaneous speech
plays an important role in its early diagnosis. Recent approaches highly rely
on the Transformer architectures due to its efficiency in modelling long-range
context dependencies. However, the quadratic increase in computational
complexity associated with self-attention and the length of audio poses a
challenge when deploying such models on edge devices. In this context, we
construct a novel framework, namely Hierarchical Attention-Free Transformer
(HAFFormer), to better deal with long speech for AD detection. Specifically, we
employ an attention-free module of Multi-Scale Depthwise Convolution to replace
the self-attention and thus avoid the expensive computation, and a GELU-based
Gated Linear Unit to replace the feedforward layer, aiming to automatically
filter out the redundant information. Moreover, we design a hierarchical
structure to force it to learn a variety of information grains, from the frame
level to the dialogue level. By conducting extensive experiments on the
ADReSS-M dataset, the introduced HAFFormer can achieve competitive results
(82.6% accuracy) with other recent work, but with significant computational
complexity and model size reduction compared to the standard Transformer. This
shows the efficiency of HAFFormer in dealing with long audio for AD detection.

摘要：自動從自發性語言中偵測阿茲海默症 (AD) 在其早期診斷中扮演重要角色。由於 Transformer 架構在建模長程背景依賴關係方面的效率，最近的方法高度依賴於 Transformer 架構。然而，與自我注意和音訊長度相關的計算複雜度二次增加，在邊緣裝置上部署此類模型時構成了一項挑戰。在此背景下，我們建構了一個新穎的架構，即分層無注意力 Transformer (HAFFormer)，以更好地處理 AD 偵測的長語音。具體來說，我們採用多尺度深度卷積的無注意力模組來取代自我注意，從而避免昂貴的計算，以及基於 GELU 的閘控線性單元來取代前饋層，旨在自動過濾掉冗餘資訊。此外，我們設計了一個分層結構來強制它學習各種資訊顆粒，從幀級到對話級。通過在 ADReSS-M 資料集上進行廣泛的實驗，引入的 HAFFormer 可以實現與其他近期工作具有競爭力的結果（82.6%  accuracy），但與標準 Transformer 相比，計算複雜度和模型大小顯著降低。這顯示了 HAFFormer 在處理 AD 偵測的長音訊方面的效率。

##### **Predictive Modeling with Temporal Graphical Representation on Electronic Health Records**
2405.03943v1 by Jiayuan Chen, Changchang Yin, Yuanlong Wang, Ping Zhang

Deep learning-based predictive models, leveraging Electronic Health Records
(EHR), are receiving increasing attention in healthcare. An effective
representation of a patient's EHR should hierarchically encompass both the
temporal relationships between historical visits and medical events, and the
inherent structural information within these elements. Existing patient
representation methods can be roughly categorized into sequential
representation and graphical representation. The sequential representation
methods focus only on the temporal relationships among longitudinal visits. On
the other hand, the graphical representation approaches, while adept at
extracting the graph-structured relationships between various medical events,
fall short in effectively integrate temporal information. To capture both types
of information, we model a patient's EHR as a novel temporal heterogeneous
graph. This graph includes historical visits nodes and medical events nodes. It
propagates structured information from medical event nodes to visit nodes and
utilizes time-aware visit nodes to capture changes in the patient's health
status. Furthermore, we introduce a novel temporal graph transformer (TRANS)
that integrates temporal edge features, global positional encoding, and local
structural encoding into heterogeneous graph convolution, capturing both
temporal and structural information. We validate the effectiveness of TRANS
through extensive experiments on three real-world datasets. The results show
that our proposed approach achieves state-of-the-art performance.

摘要：

##### **Long Context Alignment with Short Instructions and Synthesized Positions**
2405.03939v1 by Wenhao Wu, Yizhong Wang, Yao Fu, Xiang Yue, Dawei Zhu, Sujian Li

Effectively handling instructions with extremely long context remains a
challenge for Large Language Models (LLMs), typically necessitating
high-quality long data and substantial computational resources. This paper
introduces Step-Skipping Alignment (SkipAlign), a new technique designed to
enhance the long-context capabilities of LLMs in the phase of alignment without
the need for additional efforts beyond training with original data length.
SkipAlign is developed on the premise that long-range dependencies are
fundamental to enhancing an LLM's capacity of long context. Departing from
merely expanding the length of input samples, SkipAlign synthesizes long-range
dependencies from the aspect of positions indices. This is achieved by the
strategic insertion of skipped positions within instruction-following samples,
which utilizes the semantic structure of the data to effectively expand the
context. Through extensive experiments on base models with a variety of context
window sizes, SkipAlign demonstrates its effectiveness across a spectrum of
long-context tasks. Particularly noteworthy is that with a careful selection of
the base model and alignment datasets, SkipAlign with only 6B parameters
achieves it's best performance and comparable with strong baselines like
GPT-3.5-Turbo-16K on LongBench.

摘要：有效地處理極長語境的指令仍然是大型語言模型 (LLM) 的一項挑戰，通常需要高品質的長數據和大量的計算資源。本文介紹了跳步對齊 (SkipAlign)，這是一種新技術，旨在增強 LLM 在對齊階段的長語境能力，而無需除了使用原始數據長度進行訓練之外的額外工作。
SkipAlign 是基於長距離依賴關係對於增強 LLM 的長語境能力至關重要的前提而開發的。與僅僅擴展輸入樣本的長度不同，SkipAlign 從位置索引的角度綜合了長距離依賴關係。這是通過在遵循指令的樣本中策略性地插入跳過的索引位置來實現的，它利用數據的語義結構來有效地擴展語境。通過對具有各種語境窗口大小的基本模型進行廣泛的實驗，SkipAlign 展示了其在各種長語境任務中的有效性。特別值得注意的是，通過仔細選擇基本模型和對齊數據集，只有 6B 參數的 SkipAlign 就能達到其最佳性能，並且在 LongBench 上與 GPT-3.5-Turbo-16K 等強大的基準相當。

##### **CleanGraph: Human-in-the-loop Knowledge Graph Refinement and Completion**
2405.03932v1 by Tyler Bikaun, Michael Stewart, Wei Liu

This paper presents CleanGraph, an interactive web-based tool designed to
facilitate the refinement and completion of knowledge graphs. Maintaining the
reliability of knowledge graphs, which are grounded in high-quality and
error-free facts, is crucial for real-world applications such as
question-answering and information retrieval systems. These graphs are often
automatically assembled from textual sources by extracting semantic triples via
information extraction. However, assuring the quality of these extracted
triples, especially when dealing with large or low-quality datasets, can pose a
significant challenge and adversely affect the performance of downstream
applications. CleanGraph allows users to perform Create, Read, Update, and
Delete (CRUD) operations on their graphs, as well as apply models in the form
of plugins for graph refinement and completion tasks. These functionalities
enable users to enhance the integrity and reliability of their graph data. A
demonstration of CleanGraph and its source code can be accessed at
https://github.com/nlp-tlp/CleanGraph under the MIT License.

摘要：本文介紹 CleanGraph，這是一個互動式網頁工具，旨在促進知識圖譜的完善和完成。維護知識圖譜的可靠性，建立於高品質且無錯誤的事實上，對於實際應用至關重要，例如問答和資訊檢索系統。這些圖譜通常透過資訊萃取，從文字來源自動組成語意三元組。然而，確保這些萃取三元組的品質，特別是在處理大型或低品質資料集時，可能會構成重大挑戰，並對下游應用的效能產生負面影響。CleanGraph 使用者可以對其圖譜執行建立、讀取、更新和刪除 (CRUD) 作業，並以外掛程式的形式套用模型，以進行圖譜完善和完成任務。這些功能讓使用者能夠提升其圖譜資料的完整性和可靠性。CleanGraph 的示範和原始碼可以在 https://github.com/nlp-tlp/CleanGraph 取得，並採用 MIT 授權。

##### **Unicorn: U-Net for Sea Ice Forecasting with Convolutional Neural Ordinary Differential Equations**
2405.03929v1 by Jaesung Park, Sungchul Hong, Yoonseo Cho, Jong-June Jeon

Sea ice at the North Pole is vital to global climate dynamics. However,
accurately forecasting sea ice poses a significant challenge due to the
intricate interaction among multiple variables. Leveraging the capability to
integrate multiple inputs and powerful performances seamlessly, many studies
have turned to neural networks for sea ice forecasting. This paper introduces a
novel deep architecture named Unicorn, designed to forecast weekly sea ice. Our
model integrates multiple time series images within its architecture to enhance
its forecasting performance. Moreover, we incorporate a bottleneck layer within
the U-Net architecture, serving as neural ordinary differential equations with
convolution operations, to capture the spatiotemporal dynamics of latent
variables. Through real data analysis with datasets spanning from 1998 to 2021,
our proposed model demonstrates significant improvements over state-of-the-art
models in the sea ice concentration forecasting task. It achieves an average
MAE improvement of 12% compared to benchmark models. Additionally, our method
outperforms existing approaches in sea ice extent forecasting, achieving a
classification performance improvement of approximately 18%. These experimental
results show the superiority of our proposed model.

摘要：北極海冰對於全球氣候動態至關重要。然而，由於多個變數之間的複雜交互作用，準確預測海冰是一個重大的挑戰。利用將多重輸入和強大效能無縫整合的能力，許多研究已轉向神經網路來預測海冰。本文介紹了一種名為 Unicorn 的新穎深度架構，旨在預測每週海冰。我們的模型在其架構中整合了多個時間序列影像，以增強其預測效能。此外，我們在 U-Net 架構中加入了一個瓶頸層，作為具有卷積運算的神經常微分方程式，以捕捉潛在變數的時空動態。透過使用涵蓋 1998 年至 2021 年資料集的真實資料分析，我們提出的模型證明了在海冰濃度預測任務中，相較於最先進的模型有顯著的改進。與基準模型相比，它達到了平均 MAE 改善 12%。此外，我們的模型在海冰範圍預測方面優於現有方法，分類效能改善了約 18%。這些實驗結果顯示了我們提出的模型的優越性。

##### **A Roadmap for Multilingual, Multimodal Domain Independent Deception Detection**
2405.03920v1 by Dainis Boumber, Rakesh M. Verma, Fatima Zahra Qachfar

Deception, a prevalent aspect of human communication, has undergone a
significant transformation in the digital age. With the globalization of online
interactions, individuals are communicating in multiple languages and mixing
languages on social media, with varied data becoming available in each language
and dialect. At the same time, the techniques for detecting deception are
similar across the board. Recent studies have shown the possibility of the
existence of universal linguistic cues to deception across domains within the
English language; however, the existence of such cues in other languages
remains unknown. Furthermore, the practical task of deception detection in
low-resource languages is not a well-studied problem due to the lack of labeled
data. Another dimension of deception is multimodality. For example, a picture
with an altered caption in fake news or disinformation may exist. This paper
calls for a comprehensive investigation into the complexities of deceptive
language across linguistic boundaries and modalities within the realm of
computer security and natural language processing and the possibility of using
multilingual transformer models and labeled data in various languages to
universally address the task of deception detection.

摘要：欺騙，是人類溝通中普遍存在的一面，在數位時代經歷了顯著的轉變。隨著線上互動的全球化，人們在社群媒體上使用多種語言溝通並混合語言，且在每種語言和方言中都有不同的資料可供取得。同時，偵測欺騙的技術在各方面都很相似。最近的研究顯示，在英語領域內的不同範疇中，存在普遍的語言線索可以偵測欺騙；然而，在其他語言中是否存在此類線索仍不得而知。此外，由於缺乏標記資料，低資源語言中的欺騙偵測實務工作並非一個研究完善的問題。欺騙的另一個面向是多模態。例如，假新聞或錯誤資訊中可能存在一張圖片，其標題經過竄改。本文呼籲對跨語言界線和模態的欺騙語言複雜性進行全面調查，並探討在電腦安全和自然語言處理領域中使用多語言轉換器模型和各種語言中的標記資料，以普遍解決欺騙偵測任務的可能性。

##### **OmniActions: Predicting Digital Actions in Response to Real-World Multimodal Sensory Inputs with LLMs**
2405.03901v1 by Jiahao Nick Li, Yan Xu, Tovi Grossman, Stephanie Santosa, Michelle Li

The progression to "Pervasive Augmented Reality" envisions easy access to
multimodal information continuously. However, in many everyday scenarios, users
are occupied physically, cognitively or socially. This may increase the
friction to act upon the multimodal information that users encounter in the
world. To reduce such friction, future interactive interfaces should
intelligently provide quick access to digital actions based on users' context.
To explore the range of possible digital actions, we conducted a diary study
that required participants to capture and share the media that they intended to
perform actions on (e.g., images or audio), along with their desired actions
and other contextual information. Using this data, we generated a holistic
design space of digital follow-up actions that could be performed in response
to different types of multimodal sensory inputs. We then designed OmniActions,
a pipeline powered by large language models (LLMs) that processes multimodal
sensory inputs and predicts follow-up actions on the target information
grounded in the derived design space. Using the empirical data collected in the
diary study, we performed quantitative evaluations on three variations of LLM
techniques (intent classification, in-context learning and finetuning) and
identified the most effective technique for our task. Additionally, as an
instantiation of the pipeline, we developed an interactive prototype and
reported preliminary user feedback about how people perceive and react to the
action predictions and its errors.

摘要：「普遍擴增實境」的進展設想持續輕鬆存取多模態資訊。然而，在許多日常情境中，使用者在身體、認知或社交上都很忙碌。這可能會增加使用者在世界上遭遇多模態資訊時採取行動的摩擦力。為了減少這種摩擦力，未來的互動式介面應該根據使用者的脈絡，智慧地提供快速存取數位動作。為了探索可能的數位動作範圍，我們進行了一項日記研究，要求參與者擷取並分享他們打算對其執行動作的媒體（例如，影像或音訊），以及他們想要的動作和其他脈絡資訊。使用這些資料，我們生成了全面的數位後續動作設計空間，可以根據不同類型的多模態感官輸入來執行。然後，我們設計了 OmniActions，一個由大型語言模型 (LLM) 提供動力的管道，它處理多模態感官輸入，並根據衍生的設計空間預測目標資訊的後續動作。使用在日記研究中收集的實證資料，我們對 LLM 技術的三種變異（意圖分類、情境中學習和微調）進行了量化評估，並找出對我們的任務最有效的技術。此外，作為管道實例化，我們開發了一個互動式原型，並回報了使用者對動作預測及其錯誤的初步看法和反應。

##### **Out-of-Distribution Adaptation in Offline RL: Counterfactual Reasoning via Causal Normalizing Flows**
2405.03892v1 by Minjae Cho, Jonathan P. How, Chuangchuang Sun

Despite notable successes of Reinforcement Learning (RL), the prevalent use
of an online learning paradigm prevents its widespread adoption, especially in
hazardous or costly scenarios. Offline RL has emerged as an alternative
solution, learning from pre-collected static datasets. However, this offline
learning introduces a new challenge known as distributional shift, degrading
the performance when the policy is evaluated on scenarios that are
Out-Of-Distribution (OOD) from the training dataset. Most existing offline RL
resolves this issue by regularizing policy learning within the information
supported by the given dataset. However, such regularization overlooks the
potential for high-reward regions that may exist beyond the dataset. This
motivates exploring novel offline learning techniques that can make
improvements beyond the data support without compromising policy performance,
potentially by learning causation (cause-and-effect) instead of correlation
from the dataset. In this paper, we propose the MOOD-CRL (Model-based Offline
OOD-Adapting Causal RL) algorithm, which aims to address the challenge of
extrapolation for offline policy training through causal inference instead of
policy-regularizing methods. Specifically, Causal Normalizing Flow (CNF) is
developed to learn the transition and reward functions for data generation and
augmentation in offline policy evaluation and training. Based on the
data-invariant, physics-based qualitative causal graph and the observational
data, we develop a novel learning scheme for CNF to learn the quantitative
structural causal model. As a result, CNF gains predictive and counterfactual
reasoning capabilities for sequential decision-making tasks, revealing a high
potential for OOD adaptation. Our CNF-based offline RL approach is validated
through empirical evaluations, outperforming model-free and model-based methods
by a significant margin.

摘要：儘管強化學習 (RL) 取得顯著成功，但普遍使用線上學習範例會阻礙其廣泛採用，尤其是在危險或成本高昂的場景中。離線 RL 已成為一種替代方案，從預先收集的靜態資料集學習。然而，這種離線學習會產生一個稱為分佈轉移的新挑戰，當策略在訓練資料集的 Out-Of-Distribution (OOD) 場景中進行評估時，會降低效能。現有的離線 RL 大多透過在給定資料集支援的資訊中規範策略學習來解決此問題。然而，這種規範忽略了資料集之外可能存在的高回報區域。這促使我們探索新的離線學習技術，這些技術可以在不損害策略效能的情況下，超越資料支援進行改進，潛在的做法是從資料集中學習因果關係（因果關係）而不是相關性。在本文中，我們提出 MOOD-CRL（基於模型的離線 OOD 適應因果 RL）演算法，其目標是透過因果推論而不是策略規範化方法來解決離線策略訓練的外推挑戰。具體來說，因果常態化流 (CNF) 被開發出來，用於學習離線策略評估和訓練中的資料生成和擴充的轉換和回報函數。基於資料不變、基於物理的定性因果圖和觀測資料，我們開發了一種新的學習架構，讓 CNF 學習定量結構因果模型。因此，CNF 獲得了用於序貫決策任務的預測和反事實推理能力，顯示出 OOD 適應的高潛力。我們的基於 CNF 的離線 RL 方法已通過經驗評估得到驗證，其效能顯著優於無模型和基於模型的方法。

##### **Enhancing O-RAN Security: Evasion Attacks and Robust Defenses for Graph Reinforcement Learning-based Connection Management**
2405.03891v1 by Ravikumar Balakrishnan, Marius Arvinte, Nageen Himayat, Hosein Nikopour, Hassnaa Moustafa

Adversarial machine learning, focused on studying various attacks and
defenses on machine learning (ML) models, is rapidly gaining importance as ML
is increasingly being adopted for optimizing wireless systems such as Open
Radio Access Networks (O-RAN). A comprehensive modeling of the security threats
and the demonstration of adversarial attacks and defenses on practical AI based
O-RAN systems is still in its nascent stages. We begin by conducting threat
modeling to pinpoint attack surfaces in O-RAN using an ML-based Connection
management application (xApp) as an example. The xApp uses a Graph Neural
Network trained using Deep Reinforcement Learning and achieves on average 54%
improvement in the coverage rate measured as the 5th percentile user data
rates. We then formulate and demonstrate evasion attacks that degrade the
coverage rates by as much as 50% through injecting bounded noise at different
threat surfaces including the open wireless medium itself. Crucially, we also
compare and contrast the effectiveness of such attacks on the ML-based xApp and
a non-ML based heuristic. We finally develop and demonstrate robust
training-based defenses against the challenging physical/jamming-based attacks
and show a 15% improvement in the coverage rates when compared to employing no
defense over a range of noise budgets

摘要：對抗式機器學習專注於研究各種攻擊和防禦機器學習 (ML) 模型，隨著 ML 愈來愈常被用於最佳化無線系統（例如開放式無線接取網路 (O-RAN)），其重要性也迅速提升。安全威脅的全面建模以及在基於 AI 的實際 O-RAN 系統上展示對抗式攻擊和防禦，目前仍處於萌芽階段。我們先進行威脅建模，找出 O-RAN 中的攻擊面，並以基於 ML 的連線管理應用程式 (xApp) 為例。xApp 使用深度強化學習訓練的圖形神經網路，並平均將以使用者資料速率第 5 個百分位數測量的覆蓋率提升了 54%。接著我們制定並展示規避攻擊，透過在包括開放式無線媒體本身在內的不同威脅面上注入有界雜訊，將覆蓋率降低多達 50%。最重要的是，我們還比較並對比此類攻擊在基於 ML 的 xApp 和非基於 ML 的啟發式方法上的效能。最後，我們針對具有挑戰性的物理/干擾式攻擊開發並展示強健的基於訓練的防禦，並在各種雜訊預算下與不採用任何防禦措施相比，顯示覆蓋率提升了 15%。

##### **Trio-ViT: Post-Training Quantization and Acceleration for Softmax-Free Efficient Vision Transformer**
2405.03882v1 by Huihong Shi, Haikuo Shao, Wendong Mao, Zhongfeng Wang

Motivated by the huge success of Transformers in the field of natural
language processing (NLP), Vision Transformers (ViTs) have been rapidly
developed and achieved remarkable performance in various computer vision tasks.
However, their huge model sizes and intensive computations hinder ViTs'
deployment on embedded devices, calling for effective model compression
methods, such as quantization. Unfortunately, due to the existence of
hardware-unfriendly and quantization-sensitive non-linear operations,
particularly {Softmax}, it is non-trivial to completely quantize all operations
in ViTs, yielding either significant accuracy drops or non-negligible hardware
costs. In response to challenges associated with \textit{standard ViTs}, we
focus our attention towards the quantization and acceleration for
\textit{efficient ViTs}, which not only eliminate the troublesome Softmax but
also integrate linear attention with low computational complexity, and propose
\emph{Trio-ViT} accordingly. Specifically, at the algorithm level, we develop a
{tailored post-training quantization engine} taking the unique activation
distributions of Softmax-free efficient ViTs into full consideration, aiming to
boost quantization accuracy. Furthermore, at the hardware level, we build an
accelerator dedicated to the specific Convolution-Transformer hybrid
architecture of efficient ViTs, thereby enhancing hardware efficiency.
Extensive experimental results consistently prove the effectiveness of our
Trio-ViT framework. {Particularly, we can gain up to
$\uparrow$$\mathbf{7.2}\times$ and $\uparrow$$\mathbf{14.6}\times$ FPS under
comparable accuracy over state-of-the-art ViT accelerators, as well as
$\uparrow$$\mathbf{5.9}\times$ and $\uparrow$$\mathbf{2.0}\times$ DSP
efficiency.} Codes will be released publicly upon acceptance.

摘要：<paragraph>受 Transformer 在自然語言處理 (NLP) 領域取得巨大成功的啟發，視覺 Transformer (ViT) 已被迅速開發，並在各種電腦視覺任務中取得顯著成效。然而，它們龐大的模型規模和密集運算阻礙了 ViT 在嵌入式裝置上的部署，這需要有效的模型壓縮方法，例如量化。不幸的是，由於存在硬體不友善且對量化敏感的非線性運算，特別是 {Softmax}，因此要完全量化 ViT 中的所有運算並非易事，這會導致顯著的準確度下降或不可忽視的硬體成本。為了應對與\textit{標準 ViT}相關的挑戰，我們將注意力集中在\textit{高效 ViT}的量化和加速上，這不僅消除了麻煩的 Softmax，還整合了低運算複雜度的線性注意力，並據此提出了\emph{Trio-ViT}。具體來說，在演算法層級，我們開發了一個{量身打造的訓練後量化引擎}，充分考慮了無 Softmax 高效 ViT 的獨特激活分佈，旨在提升量化準確度。此外，在硬體層級，我們建立了一個專門用於高效 ViT 的特定卷積Transformer混合架構的加速器，從而提升硬體效率。廣泛的實驗結果一致證明了我們 Trio-ViT 框架的有效性。{特別是，在與最先進的 ViT 加速器相當的準確度下，我們可以獲得高達 $\uparrow$$\mathbf{7.2}\times$ 和 $\uparrow$$\mathbf{14.6}\times$ FPS，以及 $\uparrow$$\mathbf{5.9}\times$ 和 $\uparrow$$\mathbf{2.0}\times$ DSP 效率。}代碼將在接受後公開發布。</paragraph>

##### **Investigating Personalized Driving Behaviors in Dilemma Zones: Analysis and Prediction of Stop-or-Go Decisions**
2405.03873v1 by Ziye Qin, Siyan Li, Guoyuan Wu, Matthew J. Barth, Amr Abdelraouf, Rohit Gupta, Kyungtae Han

Dilemma zones at signalized intersections present a commonly occurring but
unsolved challenge for both drivers and traffic operators. Onsets of the yellow
lights prompt varied responses from different drivers: some may brake abruptly,
compromising the ride comfort, while others may accelerate, increasing the risk
of red-light violations and potential safety hazards. Such diversity in
drivers' stop-or-go decisions may result from not only surrounding traffic
conditions, but also personalized driving behaviors. To this end, identifying
personalized driving behaviors and integrating them into advanced driver
assistance systems (ADAS) to mitigate the dilemma zone problem presents an
intriguing scientific question. In this study, we employ a game engine-based
(i.e., CARLA-enabled) driving simulator to collect high-resolution vehicle
trajectories, incoming traffic signal phase and timing information, and
stop-or-go decisions from four subject drivers in various scenarios. This
approach allows us to analyze personalized driving behaviors in dilemma zones
and develop a Personalized Transformer Encoder to predict individual drivers'
stop-or-go decisions. The results show that the Personalized Transformer
Encoder improves the accuracy of predicting driver decision-making in the
dilemma zone by 3.7% to 12.6% compared to the Generic Transformer Encoder, and
by 16.8% to 21.6% over the binary logistic regression model.

摘要：<paragraph>信號交叉路口的兩難地帶對駕駛和交通管理員來說是一個普遍存在但尚未解決的挑戰。黃燈的出現會引發不同駕駛人的不同反應：有些人可能會突然煞車，犧牲行車舒適性，而另一些人可能會加速，增加闖紅燈和潛在安全危害的風險。駕駛人的停車或行駛決策出現這種差異，可能不僅是因為周圍的交通狀況，也可能是因為個人的駕駛行為。因此，找出個人的駕駛行為並將其整合到先進駕駛輔助系統 (ADAS) 中以減輕兩難地帶問題，是一個引人入勝的科學問題。在這項研究中，我們採用基於遊戲引擎（即 CARLA 啟用）的駕駛模擬器來收集高解析度車輛軌跡、來車信號相位和時序資訊，以及四位受試駕駛在各種情境下的停車或行駛決策。這種方法讓我們能夠分析兩難地帶的個人駕駛行為，並開發一個個人化 Transformer 編碼器來預測個別駕駛的停車或行駛決策。結果顯示，與通用 Transformer 編碼器相比，個人化 Transformer 編碼器將兩難地帶駕駛決策預測的準確度提高了 3.7% 至 12.6%，與二元邏輯迴歸模型相比，提高了 16.8% 至 21.6%。</paragraph>

##### **AI-Driven Frameworks for Enhancing Data Quality in Big Data Ecosystems: Error_Detection, Correction, and Metadata Integration**
2405.03870v1 by Widad Elouataoui

The widespread adoption of big data has ushered in a new era of data-driven
decision-making, transforming numerous industries and sectors. However, the
efficacy of these decisions hinges on the quality of the underlying data. Poor
data quality can result in inaccurate analyses and deceptive conclusions.
Managing the vast volume, velocity, and variety of data sources presents
significant challenges, heightening the importance of addressing big data
quality issues. While there has been increased attention from both academia and
industry, current approaches often lack comprehensiveness and universality.
They tend to focus on limited metrics, neglecting other dimensions of data
quality. Moreover, existing methods are often context-specific, limiting their
applicability across different domains. There is a clear need for intelligent,
automated approaches leveraging artificial intelligence (AI) for advanced data
quality corrections.
  To bridge these gaps, this Ph.D. thesis proposes a novel set of
interconnected frameworks aimed at enhancing big data quality comprehensively.
Firstly, we introduce new quality metrics and a weighted scoring system for
precise data quality assessment. Secondly, we present a generic framework for
detecting various quality anomalies using AI models. Thirdly, we propose an
innovative framework for correcting detected anomalies through predictive
modeling. Additionally, we address metadata quality enhancement within big data
ecosystems. These frameworks are rigorously tested on diverse datasets,
demonstrating their efficacy in improving big data quality. Finally, the thesis
concludes with insights and suggestions for future research directions.

摘要：大數據的廣泛採用開啟了由數據驅動的決策制定的新時代，轉變了許多產業和部門。然而，這些決策的效力取決於基礎數據的品質。品質不佳的數據可能導致分析不準確和結論具有誤導性。管理大量、高速率和多樣化的數據來源會帶來重大挑戰，這提高了解決大數據品質問題的重要性。儘管學術界和產業都越來越關注，但目前的方法通常缺乏全面性和普遍性。它們傾向於關注有限的指標，忽略數據品質的其他面向。此外，現有方法通常具有特定情境，這限制了它們在不同領域的適用性。顯然需要利用人工智慧 (AI) 進行智慧且自動化的處理，以進行進階的數據品質修正。
為了彌補這些差距，本博士論文提出了一組新的互連架構，旨在全面提升大數據品質。首先，我們引進新的品質指標和加權評分系統，以進行精確的數據品質評估。其次，我們提出一個通用架構，以使用 AI 模型偵測各種品質異常。第三，我們提出一個創新的架構，以透過預測模型修正已偵測到的異常。此外，我們處理大數據生態系統中的元數據品質提升。這些架構在不同的資料集上經過嚴格測試，證明了它們在改善大數據品質方面的效力。最後，本論文以對未來研究方向的見解和建議作為結論。

##### **Outlier Gradient Analysis: Efficiently Improving Deep Learning Model Performance via Hessian-Free Influence Functions**
2405.03869v1 by Anshuman Chhabra, Bo Li, Jian Chen, Prasant Mohapatra, Hongfu Liu

Influence functions offer a robust framework for assessing the impact of each
training data sample on model predictions, serving as a prominent tool in
data-centric learning. Despite their widespread use in various tasks, the
strong convexity assumption on the model and the computational cost associated
with calculating the inverse of the Hessian matrix pose constraints,
particularly when analyzing large deep models. This paper focuses on a
classical data-centric scenario--trimming detrimental samples--and addresses
both challenges within a unified framework. Specifically, we establish an
equivalence transformation between identifying detrimental training samples via
influence functions and outlier gradient detection. This transformation not
only presents a straightforward and Hessian-free formulation but also provides
profound insights into the role of the gradient in sample impact. Moreover, it
relaxes the convexity assumption of influence functions, extending their
applicability to non-convex deep models. Through systematic empirical
evaluations, we first validate the correctness of our proposed outlier gradient
analysis on synthetic datasets and then demonstrate its effectiveness in
detecting mislabeled samples in vision models, selecting data samples for
improving performance of transformer models for natural language processing,
and identifying influential samples for fine-tuned Large Language Models.

摘要：影響函數提供了一個強大的架構，用於評估每個訓練資料範例對模型預測的影響，並作為資料中心學習中的重要工具。儘管它們廣泛用於各種任務，但模型的強凸性假設和與計算 Hessian 矩陣的逆相關的計算成本會造成限制，特別是在分析大型深度模型時。本文重點關注一個經典的資料中心場景——修剪有害範例——並在一個統一的架構中解決這兩個挑戰。具體來說，我們建立了透過影響函數和異常值梯度偵測來識別有害訓練範例之間的等價轉換。此轉換不僅呈現了一個直接且無 Hessian 的公式，還深入了解了梯度在範例影響中的角色。此外，它放寬了影響函數的凸性假設，將其適用性擴展到非凸深度模型。透過系統性的經驗評估，我們首先驗證了我們提出的異常值梯度分析在合成資料集上的正確性，然後證明了其在偵測視覺模型中的標籤錯誤範例、選擇資料範例以改善自然語言處理的 Transformer 模型效能，以及識別微調的大型語言模型中的影響力範例方面的有效性。

##### **Learning Planning Abstractions from Language**
2405.03864v1 by Weiyu Liu, Geng Chen, Joy Hsu, Jiayuan Mao, Jiajun Wu

This paper presents a framework for learning state and action abstractions in
sequential decision-making domains. Our framework, planning abstraction from
language (PARL), utilizes language-annotated demonstrations to automatically
discover a symbolic and abstract action space and induce a latent state
abstraction based on it. PARL consists of three stages: 1) recovering
object-level and action concepts, 2) learning state abstractions, abstract
action feasibility, and transition models, and 3) applying low-level policies
for abstract actions. During inference, given the task description, PARL first
makes abstract action plans using the latent transition and feasibility
functions, then refines the high-level plan using low-level policies. PARL
generalizes across scenarios involving novel object instances and environments,
unseen concept compositions, and tasks that require longer planning horizons
than settings it is trained on.

摘要：本論文提出了一個用於在順序決策領域中學習狀態和動作抽象的框架。我們的框架，從語言規劃抽象（PARL），利用語言註解演示自動發現一個符號和抽象動作空間，並根據它誘導一個潛在狀態抽象。PARL 包含三個階段：1）恢復物件層級和動作概念，2）學習狀態抽象、抽象動作可行性和轉換模型，以及 3）應用低層級策略以進行抽象動作。在推論期間，給定任務描述，PARL 首先使用潛在轉換和可行性函數制定抽象動作計畫，然後使用低層級策略改善高層級計畫。PARL 概括了涉及新物件實例和環境、未見概念組合以及需要比其訓練設定更長計畫範圍的任務的不同場景。

##### **Conformity, Confabulation, and Impersonation: Persona Inconstancy in Multi-Agent LLM Collaboration**
2405.03862v1 by Razan Baltaji, Babak Hemmatian, Lav R. Varshney

This study explores the sources of instability in maintaining cultural
personas and opinions within multi-agent LLM systems. Drawing on simulations of
inter-cultural collaboration and debate, we analyze agents' pre- and
post-discussion private responses alongside chat transcripts to assess the
stability of cultural personas and the impact of opinion diversity on group
outcomes. Our findings suggest that multi-agent discussions can encourage
collective decisions that reflect diverse perspectives, yet this benefit is
tempered by the agents' susceptibility to conformity due to perceived peer
pressure and challenges in maintaining consistent personas and opinions.
Counterintuitively, instructions that encourage debate in support of one's
opinions increase the rate of inconstancy. Without addressing the factors we
identify, the full potential of multi-agent frameworks for producing more
culturally diverse AI outputs will remain untapped.

摘要：本研究探討在多主體 LLM 系統中維持文化人格和意見的不穩定性來源。透過跨文化合作和辯論的模擬，我們分析主體在討論前和討論後的私人回應以及聊天記錄，以評估文化人格的穩定性和意見多樣性對群體結果的影響。我們的研究結果表明，多主體討論可以鼓勵反映不同觀點的集體決策，但由於主體容易因感知到的同儕壓力和維持一致的人格和意見的挑戰而順應，因此這項優點受到影響。反直覺的是，鼓勵為自己的意見辯論的指示會增加不一致的比率。如果不解決我們確定的因素，多主體框架發揮更多元文化 AI 輸出的全部潛力將無法實現。

##### **VSA4VQA: Scaling a Vector Symbolic Architecture to Visual Question Answering on Natural Images**
2405.03852v1 by Anna Penzkofer, Lei Shi, Andreas Bulling

While Vector Symbolic Architectures (VSAs) are promising for modelling
spatial cognition, their application is currently limited to artificially
generated images and simple spatial queries. We propose VSA4VQA - a novel 4D
implementation of VSAs that implements a mental representation of natural
images for the challenging task of Visual Question Answering (VQA). VSA4VQA is
the first model to scale a VSA to complex spatial queries. Our method is based
on the Semantic Pointer Architecture (SPA) to encode objects in a
hyperdimensional vector space. To encode natural images, we extend the SPA to
include dimensions for object's width and height in addition to their spatial
location. To perform spatial queries we further introduce learned spatial query
masks and integrate a pre-trained vision-language model for answering
attribute-related questions. We evaluate our method on the GQA benchmark
dataset and show that it can effectively encode natural images, achieving
competitive performance to state-of-the-art deep learning methods for zero-shot
VQA.

摘要：雖然向量符號架構 (VSA) 對於建模空間認知很有前景，但其應用目前僅限於人工產生的圖像和簡單的空間查詢。我們提出 VSA4VQA - 一種 VSA 的新型 4D 實作，用於實作自然影像的心智表徵，以執行具挑戰性的視覺問答 (VQA) 任務。VSA4VQA 是第一個將 VSA 擴展到複雜空間查詢的模型。我們的做法建構於語意指標架構 (SPA)，用於在超維向量空間中編碼物件。為了編碼自然影像，我們將 SPA 延伸，除了空間位置外，還包括物件的寬度和高度維度。為了執行空間查詢，我們進一步引入已學習的空間查詢遮罩，並整合預先訓練好的視覺語言模型，以回答與屬性相關的問題。我們在 GQA 基準資料集上評估我們的做法，並顯示它可以有效地編碼自然影像，在零次學習 VQA 中達成與最先進的深度學習方法相近的效能。

##### **Self-Improving Customer Review Response Generation Based on LLMs**
2405.03845v1 by Guy Azov, Tatiana Pelc, Adi Fledel Alon, Gila Kamhi

Previous studies have demonstrated that proactive interaction with user
reviews has a positive impact on the perception of app users and encourages
them to submit revised ratings. Nevertheless, developers encounter challenges
in managing a high volume of reviews, particularly in the case of popular apps
with a substantial influx of daily reviews. Consequently, there is a demand for
automated solutions aimed at streamlining the process of responding to user
reviews. To address this, we have developed a new system for generating
automatic responses by leveraging user-contributed documents with the help of
retrieval-augmented generation (RAG) and advanced Large Language Models (LLMs).
Our solution, named SCRABLE, represents an adaptive customer review response
automation that enhances itself with self-optimizing prompts and a judging
mechanism based on LLMs. Additionally, we introduce an automatic scoring
mechanism that mimics the role of a human evaluator to assess the quality of
responses generated in customer review domains. Extensive experiments and
analyses conducted on real-world datasets reveal that our method is effective
in producing high-quality responses, yielding improvement of more than 8.5%
compared to the baseline. Further validation through manual examination of the
generated responses underscores the efficacy our proposed system.

摘要：先前的研究已證明，主動與使用者評論互動對應用程式使用者的認知有正面的影響，且鼓勵他們提交已修改的評分。儘管如此，開發人員在管理大量的評論時會遇到挑戰，特別是在每天湧入大量評論的熱門應用程式中。因此，需要自動化的解決方案來簡化回應使用者評論的流程。為了解決這個問題，我們開發了一個新的系統，利用使用者貢獻的文件，在檢索擴充生成 (RAG) 和進階大型語言模型 (LLM) 的幫助下，產生自動化的回應。我們的解決方案，名為 SCRABLE，代表一種適應式客戶評論回應自動化，它會透過自我最佳化提示和基於 LLM 的判斷機制來提升自己。此外，我們引入了一種自動評分機制，模擬人類評估者的角色，以評估在客戶評論領域中產生的回應品質。在真實世界資料集上進行的廣泛實驗和分析顯示，我們的做法在產生高品質的回應上是有效的，與基準相比，改進幅度超過 8.5%。進一步透過手動檢查產生的回應來驗證，突顯了我們提出的系統的功效。

##### **A Novel Cross-band CSI Prediction Scheme for Multi-band Fingerprint based Localization**
2405.03842v1 by Yuan Ruihao, Huang Kaixuan, Zhang Shunqing

Because of the advantages of computation complexity compared with traditional
localization algorithms, fingerprint based localization is getting increasing
demand. Expanding the fingerprint database from the frequency domain by channel
reconstruction can improve localization accuracy. However, in a mobility
environment, the channel reconstruction accuracy is limited by the time-varying
parameters. In this paper, we proposed a system to extract the time-varying
parameters based on space-alternating generalized expectation maximization
(SAGE) algorithm, then used variational auto-encoder (VAE) to reconstruct the
channel state information on another channel. The proposed scheme is tested on
the data generated by the deep-MIMO channel model. Mathematical analysis for
the viability of our system is also shown in this paper.

摘要：由於運算複雜度優於傳統定位演算法，因此基於指紋的定位越來越受到重視。透過通道重建從頻域擴充指紋資料庫可以提升定位的準確度。然而，在一個移動環境中，通道重建的準確度會受到時變參數的限制。在本文中，我們提出了一個系統，以空間交替廣義期望最大化 (SAGE) 演算法萃取出時變參數，然後使用變異自動編碼器 (VAE) 在另一個通道上重建通道狀態資訊。我們在深層 MIMO 通道模型所產生的資料上測試了所提出的方案。本文也顯示了對我們系統可行性的數學分析。

##### **Guylingo: The Republic of Guyana Creole Corpora**
2405.03832v1 by Christopher Clarke, Roland Daynauth, Charlene Wilkinson, Hubert Devonish, Jason Mars

While major languages often enjoy substantial attention and resources, the
linguistic diversity across the globe encompasses a multitude of smaller,
indigenous, and regional languages that lack the same level of computational
support. One such region is the Caribbean. While commonly labeled as "English
speaking", the ex-British Caribbean region consists of a myriad of Creole
languages thriving alongside English. In this paper, we present Guylingo: a
comprehensive corpus designed for advancing NLP research in the domain of
Creolese (Guyanese English-lexicon Creole), the most widely spoken language in
the culturally rich nation of Guyana. We first outline our framework for
gathering and digitizing this diverse corpus, inclusive of colloquial
expressions, idioms, and regional variations in a low-resource language. We
then demonstrate the challenges of training and evaluating NLP models for
machine translation in Creole. Lastly, we discuss the unique opportunities
presented by recent NLP advancements for accelerating the formal adoption of
Creole languages as official languages in the Caribbean.

摘要：雖然主流語言通常備受關注且資源豐富，但全球的語言多元性涵蓋了許多規模較小、本土且區域性的語言，這些語言缺乏相同的計算支援。加勒比海地區就是這樣的一個區域。儘管通常被標記為「英語系」，但前英國加勒比海地區包含了許多與英語並存且蓬勃發展的克里奧爾語。在本文中，我們展示了 Guylingo：一個全面的語料庫，旨在推進克里奧爾語（蓋亞那英語詞彙克里奧爾語）領域的自然語言處理研究，這是文化豐富的蓋亞那國家中最廣泛使用的語言。我們首先概述了我們收集和數位化這個多元語料庫的架構，包括口語表達、慣用語和低資源語言中的區域變異。然後，我們展示了在克里奧爾語中訓練和評估機器翻譯的自然語言處理模型的挑戰。最後，我們討論了最近自然語言處理進展帶來的獨特機會，以加速在加勒比海地區正式採用克里奧爾語作為官方語言。

##### **Organizing a Society of Language Models: Structures and Mechanisms for Enhanced Collective Intelligence**
2405.03825v1 by Silvan Ferreira, Ivanovitch Silva, Allan Martins

Recent developments in Large Language Models (LLMs) have significantly
expanded their applications across various domains. However, the effectiveness
of LLMs is often constrained when operating individually in complex
environments. This paper introduces a transformative approach by organizing
LLMs into community-based structures, aimed at enhancing their collective
intelligence and problem-solving capabilities. We investigate different
organizational models-hierarchical, flat, dynamic, and federated-each
presenting unique benefits and challenges for collaborative AI systems. Within
these structured communities, LLMs are designed to specialize in distinct
cognitive tasks, employ advanced interaction mechanisms such as direct
communication, voting systems, and market-based approaches, and dynamically
adjust their governance structures to meet changing demands. The implementation
of such communities holds substantial promise for improve problem-solving
capabilities in AI, prompting an in-depth examination of their ethical
considerations, management strategies, and scalability potential. This position
paper seeks to lay the groundwork for future research, advocating a paradigm
shift from isolated to synergistic operational frameworks in AI research and
application.

摘要：大型語言模型 (LLM) 近期發展已大幅擴展其在各個領域的應用。然而，LLM 在複雜環境中單獨運作時，其效能常常受到限制。本文介紹了一種變革性方法，將 LLM 組織成基於社群的結構，旨在提升其集體智慧和問題解決能力。我們探討了不同的組織模型，包括階層式、扁平式、動態式和聯盟式，每個模型在協作式 AI 系統中都呈現獨特的優點和挑戰。在這些結構化的社群中，LLM 被設計成專精於不同的認知任務，採用進階互動機制，例如直接溝通、投票系統和基於市場的方法，並動態調整其治理結構以滿足不斷變化的需求。實作此類社群對於提升 AI 的問題解決能力極具潛力，並促使深入探討其道德考量、管理策略和可擴充性潛力。本立場文件旨在為未來的研究奠定基礎，提倡從孤立的運作架構轉變到 AI 研究和應用中的協同運作架構。

##### **Thoughtful Things: Building Human-Centric Smart Devices with Small Language Models**
2405.03821v1 by Evan King, Haoxiang Yu, Sahil Vartak, Jenna Jacob, Sangsu Lee, Christine Julien

Everyday devices like light bulbs and kitchen appliances are now embedded
with so many features and automated behaviors that they have become complicated
to actually use. While such "smart" capabilities can better support users'
goals, the task of learning the "ins and outs" of different devices is
daunting. Voice assistants aim to solve this problem by providing a natural
language interface to devices, yet such assistants cannot understand
loosely-constrained commands, they lack the ability to reason about and explain
devices' behaviors to users, and they rely on connectivity to intrusive cloud
infrastructure. Toward addressing these issues, we propose thoughtful things:
devices that leverage lightweight, on-device language models to take actions
and explain their behaviors in response to unconstrained user commands. We
propose an end-to-end framework that leverages formal modeling, automated
training data synthesis, and generative language models to create devices that
are both capable and thoughtful in the presence of unconstrained user goals and
inquiries. Our framework requires no labeled data and can be deployed
on-device, with no cloud dependency. We implement two thoughtful things (a lamp
and a thermostat) and deploy them on real hardware, evaluating their practical
performance.

摘要：日常用品，例如燈泡和廚房電器，現在都內嵌了許多功能和自動化行為，導致它們變得複雜難用。雖然這些「智慧」功能可以更好地支援使用者的目標，但學習不同裝置的「內外」是一項艱鉅的任務。語音助理旨在透過提供自然語言裝置介面來解決這個問題，但這些助理無法理解約束較少的指令，它們缺乏推論和向使用者解釋裝置行為的能力，而且它們依賴於侵入式雲端基礎架構的連線。為了解決這些問題，我們提出 thoughtful things：裝置利用輕量級的裝置語言模型，根據使用者不受約束的指令採取行動並說明其行為。我們提出一個端對端框架，利用正式建模、自動化訓練資料合成和生成式語言模型，建立在不受約束使用者目標和查詢的情況下既有能力又貼心的裝置。我們的框架不需要標籤資料，而且可以部署在裝置上，無需依賴雲端。我們實作了兩個 thoughtful things（一盞燈和一個恆溫器），並將它們部署在真實硬體上，評估它們的實際效能。

##### **SocialFormer: Social Interaction Modeling with Edge-enhanced Heterogeneous Graph Transformers for Trajectory Prediction**
2405.03809v1 by Zixu Wang, Zhigang Sun, Juergen Luettin, Lavdim Halilaj

Accurate trajectory prediction is crucial for ensuring safe and efficient
autonomous driving. However, most existing methods overlook complex
interactions between traffic participants that often govern their future
trajectories. In this paper, we propose SocialFormer, an agent
interaction-aware trajectory prediction method that leverages the semantic
relationship between the target vehicle and surrounding vehicles by making use
of the road topology. We also introduce an edge-enhanced heterogeneous graph
transformer (EHGT) as the aggregator in a graph neural network (GNN) to encode
the semantic and spatial agent interaction information. Additionally, we
introduce a temporal encoder based on gated recurrent units (GRU) to model the
temporal social behavior of agent movements. Finally, we present an information
fusion framework that integrates agent encoding, lane encoding, and agent
interaction encoding for a holistic representation of the traffic scene. We
evaluate SocialFormer for the trajectory prediction task on the popular
nuScenes benchmark and achieve state-of-the-art performance.

摘要：準確的軌跡預測對於確保安全且有效率的自動駕駛至關重要。然而，現有的大多數方法都忽略了交通參與者之間的複雜互動，而這些互動通常會影響其未來的軌跡。在本文中，我們提出了 SocialFormer，這是一種基於代理互動的軌跡預測方法，它通過利用道路拓撲結構來提升目標車輛與周圍車輛之間的語義關聯。我們還引入了一個邊緣增強異質圖形轉換器 (EHGT) 作為圖形神經網路 (GNN) 中的聚合器，以編碼語義和空間代理互動資訊。此外，我們還引入了一個基於門控遞歸單元 (GRU) 的時間編碼器，以模擬代理運動的時間社會行為。最後，我們提出了資訊融合架構，它整合了代理編碼、車道編碼和代理互動編碼，以全面呈現交通場景。我們針對流行的 nuScenes 基準對 SocialFormer 進行了軌跡預測任務評估，並取得了最先進的效能。

##### **Synthetic Data from Diffusion Models Improve Drug Discovery Prediction**
2405.03799v1 by Bing Hu, Ashish Saragadam, Anita Layton, Helen Chen

Artificial intelligence (AI) is increasingly used in every stage of drug
development. Continuing breakthroughs in AI-based methods for drug discovery
require the creation, improvement, and refinement of drug discovery data. We
posit a new data challenge that slows the advancement of drug discovery AI:
datasets are often collected independently from each other, often with little
overlap, creating data sparsity. Data sparsity makes data curation difficult
for researchers looking to answer key research questions requiring values posed
across multiple datasets. We propose a novel diffusion GNN model Syngand
capable of generating ligand and pharmacokinetic data end-to-end. We show and
provide a methodology for sampling pharmacokinetic data for existing ligands
using our Syngand model. We show the initial promising results on the efficacy
of the Syngand-generated synthetic target property data on downstream
regression tasks with AqSolDB, LD50, and hERG central. Using our proposed model
and methodology, researchers can easily generate synthetic ligand data to help
them explore research questions that require data spanning multiple datasets.

摘要：人工智慧（AI）在藥物開發的每個階段都越來越廣泛地使用。基於 AI 的藥物發現方法的持續突破需要建立、改進和優化藥物發現數據。我們提出了一個新的數據挑戰，它會減緩藥物發現 AI 的進展：數據集通常是彼此獨立收集的，通常重疊很少，造成數據稀疏。數據稀疏使得研究人員難以進行數據管理，因為他們希望回答需要跨多個數據集提供值的關鍵研究問題。我們提出了一種新穎的擴散 GNN 模型 Syngand，它能夠端到端生成配體和藥代動力學數據。我們展示並提供了一種使用我們的 Syngand 模型對現有配體進行藥代動力學數據採樣的辦法。我們展示了 Syngand 生成的合成目標屬性數據在使用 AqSolDB、LD50 和 hERG central 進行下游回歸任務時的初步有希望的結果。使用我們提出的模型和方法，研究人員可以輕鬆生成合成配體數據，以幫助他們探索需要跨多個數據集的數據的研究問題。

##### **Detecting Anti-Semitic Hate Speech using Transformer-based Large Language Models**
2405.03794v1 by Dengyi Liu, Minghao Wang, Andrew G. Catlin

Academic researchers and social media entities grappling with the
identification of hate speech face significant challenges, primarily due to the
vast scale of data and the dynamic nature of hate speech. Given the ethical and
practical limitations of large predictive models like ChatGPT in directly
addressing such sensitive issues, our research has explored alternative
advanced transformer-based and generative AI technologies since 2019.
Specifically, we developed a new data labeling technique and established a
proof of concept targeting anti-Semitic hate speech, utilizing a variety of
transformer models such as BERT (arXiv:1810.04805), DistillBERT
(arXiv:1910.01108), RoBERTa (arXiv:1907.11692), and LLaMA-2 (arXiv:2307.09288),
complemented by the LoRA fine-tuning approach (arXiv:2106.09685). This paper
delineates and evaluates the comparative efficacy of these cutting-edge methods
in tackling the intricacies of hate speech detection, highlighting the need for
responsible and carefully managed AI applications within sensitive contexts.

摘要：學術研究人員和社群媒體實體在面對仇恨言論的辨識上，面臨著重大的挑戰，這主要是由於資料的規模龐大，以及仇恨言論的動態本質。鑑於像 ChatGPT 這樣的大型預測模型在直接處理此類敏感議題上存在倫理和實際限制，我們的研究自 2019 年以來探索了替代性的先進Transformer式和生成式 AI 技術。具體來說，我們開發了一種新的資料標記技術，並建立了一個針對反猶太仇恨言論的概念驗證，利用了各種Transformer模型，例如 BERT (arXiv:1810.04805)、DistillBERT (arXiv:1910.01108)、RoBERTa (arXiv:1907.11692) 和 LLaMA-2 (arXiv:2307.09288)，並輔以 LoRA 微調方法 (arXiv:2106.09685)。本文描述並評估了這些尖端方法在處理仇恨言論偵測的複雜性方面的比較效能，強調在敏感情境中負責任且小心管理 AI 應用程式的必要性。

