{"2412.09049": {"publish_time": "2024-12-12", "title": "Dial-In LLM: Human-Aligned Dialogue Intent Clustering with LLM-in-the-loop", "paper_summary": "The discovery of customer intention from dialogue plays an important role in\nautomated support system. However, traditional text clustering methods are\npoorly aligned with human perceptions due to the shift from embedding distance\nto semantic distance, and existing quantitative metrics for text clustering may\nnot accurately reflect the true quality of intent clusters. In this paper, we\nleverage the superior language understanding capabilities of Large Language\nModels (LLMs) for designing better-calibrated intent clustering algorithms. We\nfirst establish the foundation by verifying the robustness of fine-tuned LLM\nutility in semantic coherence evaluation and cluster naming, resulting in an\naccuracy of 97.50% and 94.40%, respectively, when compared to the human-labeled\nground truth. Then, we propose an iterative clustering algorithm that\nfacilitates cluster-level refinement and the continuous discovery of\nhigh-quality intent clusters. Furthermore, we present several LLM-in-the-loop\nsemi-supervised clustering techniques tailored for intent discovery from\ncustomer service dialogue. Experiments on a large-scale industrial dataset\ncomprising 1,507 intent clusters demonstrate the effectiveness of the proposed\ntechniques. The methods outperformed existing counterparts, achieving 6.25%\nimprovement in quantitative metrics and 12% enhancement in application-level\nperformance when constructing an intent classifier.", "paper_summary_zh": "\u5f9e\u5c0d\u8a71\u4e2d\u767c\u73fe\u5ba2\u6236\u610f\u5716\u5728\u81ea\u52d5\u5316\u652f\u63f4\u7cfb\u7d71\u4e2d\u626e\u6f14\u91cd\u8981\u89d2\u8272\u3002\u7136\u800c\uff0c\u50b3\u7d71\u7684\u6587\u5b57\u5206\u7fa4\u65b9\u6cd5\u7531\u65bc\u5f9e\u5d4c\u5165\u8ddd\u96e2\u8f49\u63db\u70ba\u8a9e\u7fa9\u8ddd\u96e2\uff0c\u8207\u4eba\u985e\u7684\u8a8d\u77e5\u4e0d\u7b26\uff0c\u800c\u73fe\u6709\u7684\u6587\u5b57\u5206\u7fa4\u91cf\u5316\u6307\u6a19\u53ef\u80fd\u7121\u6cd5\u6e96\u78ba\u53cd\u6620\u610f\u5716\u5206\u7fa4\u7684\u771f\u5be6\u54c1\u8cea\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5229\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u512a\u7570\u7684\u8a9e\u8a00\u7406\u89e3\u80fd\u529b\uff0c\u4f86\u8a2d\u8a08\u6821\u6e96\u66f4\u597d\u7684\u610f\u5716\u5206\u7fa4\u6f14\u7b97\u6cd5\u3002\u6211\u5011\u9996\u5148\u900f\u904e\u9a57\u8b49\u5fae\u8abf\u5f8c\u7684 LLM \u5be6\u7528\u7a0b\u5f0f\u5728\u8a9e\u7fa9\u4e00\u81f4\u6027\u8a55\u4f30\u548c\u5206\u7fa4\u547d\u540d\u4e2d\u7684\u7a69\u5065\u6027\uff0c\u5efa\u7acb\u57fa\u790e\uff0c\u8207\u4eba\u70ba\u6a19\u8a18\u7684\u5730\u9762\u5be6\u6cc1\u76f8\u6bd4\uff0c\u5206\u5225\u5f97\u5230 97.50% \u548c 94.40% \u7684\u6e96\u78ba\u7387\u3002\u63a5\u8457\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u53cd\u8986\u904b\u7b97\u7684\u5206\u7fa4\u6f14\u7b97\u6cd5\uff0c\u4fc3\u9032\u5206\u7fa4\u5c64\u7d1a\u7684\u7cbe\u9032\u548c\u6301\u7e8c\u767c\u73fe\u9ad8\u54c1\u8cea\u7684\u610f\u5716\u5206\u7fa4\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u6578\u7a2e LLM in the loop \u534a\u76e3\u7763\u5f0f\u5206\u7fa4\u6280\u8853\uff0c\u5c08\u9580\u7528\u65bc\u5f9e\u5ba2\u6236\u670d\u52d9\u5c0d\u8a71\u4e2d\u767c\u73fe\u610f\u5716\u3002\u5728\u5305\u542b 1,507 \u500b\u610f\u5716\u5206\u7fa4\u7684\u5927\u898f\u6a21\u7522\u696d\u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u7684\u5be6\u9a57\uff0c\u8b49\u660e\u4e86\u6240\u63d0\u51fa\u6280\u8853\u7684\u6709\u6548\u6027\u3002\u9019\u4e9b\u65b9\u6cd5\u512a\u65bc\u73fe\u6709\u7684\u5c0d\u61c9\u65b9\u6cd5\uff0c\u5728\u5efa\u69cb\u610f\u5716\u5206\u985e\u5668\u6642\uff0c\u91cf\u5316\u6307\u6a19\u63d0\u5347\u4e86 6.25%\uff0c\u61c9\u7528\u5c64\u7d1a\u6548\u80fd\u63d0\u5347\u4e86 12%\u3002", "author": "Mengze Hong et.al.", "authors": "Mengze Hong, Yuanfeng Song, Di Jiang, Wailing Ng, Yanjie Sun, Chen Jason Zhang", "id": "2412.09049v1", "paper_url": "http://arxiv.org/abs/2412.09049v1", "repo": "null"}}