{"2405.14608": {"publish_time": "2024-05-23", "title": "ShapeFormer: Shapelet Transformer for Multivariate Time Series Classification", "paper_summary": "Multivariate time series classification (MTSC) has attracted significant\nresearch attention due to its diverse real-world applications. Recently,\nexploiting transformers for MTSC has achieved state-of-the-art performance.\nHowever, existing methods focus on generic features, providing a comprehensive\nunderstanding of data, but they ignore class-specific features crucial for\nlearning the representative characteristics of each class. This leads to poor\nperformance in the case of imbalanced datasets or datasets with similar overall\npatterns but differing in minor class-specific details. In this paper, we\npropose a novel Shapelet Transformer (ShapeFormer), which comprises\nclass-specific and generic transformer modules to capture both of these\nfeatures. In the class-specific module, we introduce the discovery method to\nextract the discriminative subsequences of each class (i.e. shapelets) from the\ntraining set. We then propose a Shapelet Filter to learn the difference\nfeatures between these shapelets and the input time series. We found that the\ndifference feature for each shapelet contains important class-specific\nfeatures, as it shows a significant distinction between its class and others.\nIn the generic module, convolution filters are used to extract generic features\nthat contain information to distinguish among all classes. For each module, we\nemploy the transformer encoder to capture the correlation between their\nfeatures. As a result, the combination of two transformer modules allows our\nmodel to exploit the power of both types of features, thereby enhancing the\nclassification performance. Our experiments on 30 UEA MTSC datasets demonstrate\nthat ShapeFormer has achieved the highest accuracy ranking compared to\nstate-of-the-art methods. The code is available at\nhttps://github.com/xuanmay2701/shapeformer.", "paper_summary_zh": "\u591a\u8b8a\u91cf\u6642\u9593\u5e8f\u5217\u5206\u985e (MTSC) \u7531\u65bc\u5176\u591a\u6a23\u5316\u7684\u771f\u5be6\u4e16\u754c\u61c9\u7528\u800c\u5f15\u8d77\u4e86\u91cd\u5927\u7684\u7814\u7a76\u95dc\u6ce8\u3002\u6700\u8fd1\uff0c\u5229\u7528Transformer\u9032\u884c MTSC \u5df2\u5be6\u73fe\u4e86\u6700\u5148\u9032\u7684\u6027\u80fd\u3002\u7136\u800c\uff0c\u73fe\u6709\u65b9\u6cd5\u5c08\u6ce8\u65bc\u901a\u7528\u7279\u5fb5\uff0c\u63d0\u4f9b\u5c0d\u6578\u64da\u7684\u5168\u9762\u7406\u89e3\uff0c\u4f46\u5b83\u5011\u5ffd\u7565\u4e86\u5c0d\u5b78\u7fd2\u6bcf\u500b\u985e\u5225\u7684\u4ee3\u8868\u6027\u7279\u5fb5\u81f3\u95dc\u91cd\u8981\u7684\u985e\u5225\u7279\u5b9a\u7279\u5fb5\u3002\u9019\u5c0e\u81f4\u5728\u4e0d\u5e73\u8861\u7684\u6578\u64da\u96c6\u6216\u5177\u6709\u76f8\u4f3c\u6574\u9ad4\u6a21\u5f0f\u4f46\u985e\u5225\u7279\u5b9a\u7d30\u7bc0\u4e0d\u540c\u7684\u6578\u64da\u96c6\u7684\u60c5\u6cc1\u4e0b\u6027\u80fd\u4e0d\u4f73\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7a4e\u7684 Shapelet Transformer\uff08ShapeFormer\uff09\uff0c\u5b83\u5305\u542b\u985e\u5225\u7279\u5b9a\u548c\u901a\u7528Transformer\u6a21\u7d44\uff0c\u4ee5\u64f7\u53d6\u9019\u5169\u500b\u7279\u5fb5\u3002\u5728\u985e\u5225\u7279\u5b9a\u6a21\u7d44\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86\u767c\u73fe\u65b9\u6cd5\uff0c\u5f9e\u8a13\u7df4\u96c6\u4e2d\u63d0\u53d6\u6bcf\u500b\u985e\u5225\u7684\u5340\u5206\u5b50\u5e8f\u5217\uff08\u5373 shapelets\uff09\u3002\u7136\u5f8c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b Shapelet Filter \u4f86\u5b78\u7fd2\u9019\u4e9b shapelets \u8207\u8f38\u5165\u6642\u9593\u5e8f\u5217\u4e4b\u9593\u7684\u5dee\u7570\u7279\u5fb5\u3002\u6211\u5011\u767c\u73fe\u6bcf\u500b shapelet \u7684\u5dee\u7570\u7279\u5fb5\u5305\u542b\u91cd\u8981\u7684\u985e\u5225\u7279\u5b9a\u7279\u5fb5\uff0c\u56e0\u70ba\u5b83\u986f\u793a\u4e86\u5176\u985e\u5225\u8207\u5176\u4ed6\u985e\u5225\u4e4b\u9593\u7684\u986f\u8457\u5340\u5225\u3002\u5728\u901a\u7528\u6a21\u7d44\u4e2d\uff0c\u5377\u7a4d\u6ffe\u6ce2\u5668\u7528\u65bc\u63d0\u53d6\u5305\u542b\u5340\u5206\u6240\u6709\u985e\u5225\u7684\u8cc7\u8a0a\u7684\u901a\u7528\u7279\u5fb5\u3002\u5c0d\u65bc\u6bcf\u500b\u6a21\u7d44\uff0c\u6211\u5011\u63a1\u7528Transformer\u7de8\u78bc\u5668\u4f86\u64f7\u53d6\u5176\u7279\u5fb5\u4e4b\u9593\u7684\u95dc\u806f\u3002\u56e0\u6b64\uff0c\u5169\u500bTransformer\u6a21\u7d44\u7684\u7d44\u5408\u4f7f\u6211\u5011\u7684\u6a21\u578b\u80fd\u5920\u5229\u7528\u5169\u7a2e\u7279\u5fb5\u7684\u529b\u91cf\uff0c\u5f9e\u800c\u589e\u5f37\u5206\u985e\u6027\u80fd\u3002\u6211\u5011\u5728 30 \u500b UEA MTSC \u6578\u64da\u96c6\u4e0a\u7684\u5be6\u9a57\u8868\u660e\uff0c\u8207\u6700\u5148\u9032\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0cShapeFormer \u5df2\u7d93\u53d6\u5f97\u4e86\u6700\u9ad8\u7684\u6e96\u78ba\u7387\u6392\u540d\u3002\u7a0b\u5f0f\u78bc\u53ef\u4ee5\u5728 https://github.com/xuanmay2701/shapeformer \u7372\u5f97\u3002", "author": "Xuan-May Le et.al.", "authors": "Xuan-May Le, Ling Luo, Uwe Aickelin, Minh-Tuan Tran", "id": "2405.14608v1", "paper_url": "http://arxiv.org/abs/2405.14608v1", "repo": "null"}}