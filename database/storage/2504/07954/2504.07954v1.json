{"2504.07954": {"publish_time": "2025-04-10", "title": "Perception-R1: Pioneering Perception Policy with Reinforcement Learning", "paper_summary": "Inspired by the success of DeepSeek-R1, we explore the potential of\nrule-based reinforcement learning (RL) in MLLM post-training for perception\npolicy learning. While promising, our initial experiments reveal that\nincorporating a thinking process through RL does not consistently lead to\nperformance gains across all visual perception tasks. This leads us to delve\ninto the essential role of RL in the context of visual perception. In this\nwork, we return to the fundamentals and explore the effects of RL on different\nperception tasks. We observe that the perceptual complexity is a major factor\nin determining the effectiveness of RL. We also observe that reward design\nplays a crucial role in further approching the upper limit of model perception.\nTo leverage these findings, we propose Perception-R1, a scalable RL framework\nusing GRPO during MLLM post-training. With a standard Qwen2.5-VL-3B-Instruct,\nPerception-R1 achieves +4.2% on RefCOCO+, +17.9% on PixMo-Count, +4.2% on\nPageOCR, and notably, 31.9% AP on COCO2017 val for the first time, establishing\na strong baseline for perception policy learning.", "paper_summary_zh": "\u53d7\u5230 DeepSeek-R1 \u7684\u6210\u529f\u555f\u767c\uff0c\u6211\u5011\u63a2\u7d22\u57fa\u65bc\u898f\u5247\u7684\u5f37\u5316\u5b78\u7fd2 (RL) \u5728\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM) \u5f8c\u8a13\u7df4\u4e2d\uff0c\u7528\u65bc\u611f\u77e5\u7b56\u7565\u5b78\u7fd2\u7684\u6f5b\u529b\u3002\u96d6\u7136\u524d\u666f\u770b\u597d\uff0c\u4f46\u6211\u5011\u6700\u521d\u7684\u5be6\u9a57\u8868\u660e\uff0c\u900f\u904e\u5f37\u5316\u5b78\u7fd2\u7d0d\u5165\u601d\u7dad\u904e\u7a0b\u4e26\u4e0d\u80fd\u5728\u6240\u6709\u8996\u89ba\u611f\u77e5\u4efb\u52d9\u4e2d\u90fd\u5e36\u4f86\u4e00\u81f4\u7684\u6548\u80fd\u63d0\u5347\u3002\u9019\u4fc3\u4f7f\u6211\u5011\u6df1\u5165\u7814\u7a76\u5f37\u5316\u5b78\u7fd2\u5728\u8996\u89ba\u611f\u77e5\u9818\u57df\u4e2d\u7684\u91cd\u8981\u4f5c\u7528\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u56de\u6b78\u57fa\u790e\uff0c\u63a2\u7d22\u5f37\u5316\u5b78\u7fd2\u5c0d\u4e0d\u540c\u611f\u77e5\u4efb\u52d9\u7684\u5f71\u97ff\u3002\u6211\u5011\u89c0\u5bdf\u5230\uff0c\u611f\u77e5\u7684\u8907\u96dc\u6027\u662f\u6c7a\u5b9a\u5f37\u5316\u5b78\u7fd2\u6709\u6548\u6027\u7684\u4e00\u500b\u4e3b\u8981\u56e0\u7d20\u3002\u6211\u5011\u9084\u89c0\u5bdf\u5230\uff0c\u734e\u52f5\u8a2d\u8a08\u5728\u9032\u4e00\u6b65\u903c\u8fd1\u6a21\u578b\u611f\u77e5\u4e0a\u9650\u65b9\u9762\u8d77\u8457\u81f3\u95dc\u91cd\u8981\u7684\u4f5c\u7528\u3002\u70ba\u4e86\u5229\u7528\u9019\u4e9b\u767c\u73fe\uff0c\u6211\u5011\u63d0\u51fa\u4e86 Perception-R1\uff0c\u9019\u662f\u4e00\u500b\u5728 MLLM \u5f8c\u8a13\u7df4\u671f\u9593\u4f7f\u7528 GRPO \u7684\u53ef\u64f4\u5c55\u5f37\u5316\u5b78\u7fd2\u6846\u67b6\u3002\u900f\u904e\u6a19\u6e96\u7684 Qwen2.5-VL-3B-Instruct \u6a21\u578b\uff0cPerception-R1 \u5728 RefCOCO+ \u4e0a\u63d0\u5347\u4e86 4.2%\uff0c\u5728 PixMo-Count \u4e0a\u63d0\u5347\u4e86 17.9%\uff0c\u5728 PageOCR \u4e0a\u63d0\u5347\u4e86 4.2%\uff0c\u5c24\u5176\u662f\u5728 COCO2017 val \u4e0a\u9996\u6b21\u9054\u5230\u4e86 31.9% \u7684 AP\uff0c\u70ba\u611f\u77e5\u7b56\u7565\u5b78\u7fd2\u5efa\u7acb\u4e86\u5f37\u5927\u7684\u57fa\u6e96\u3002\n", "author": "En Yu et.al.", "authors": "En Yu, Kangheng Lin, Liang Zhao, Jisheng Yin, Yana Wei, Yuang Peng, Haoran Wei, Jianjian Sun, Chunrui Han, Zheng Ge, Xiangyu Zhang, Daxin Jiang, Jingyu Wang, Wenbing Tao", "id": "2504.07954v1", "paper_url": "http://arxiv.org/abs/2504.07954v1", "repo": "null"}}