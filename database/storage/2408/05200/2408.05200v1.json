{"2408.05200": {"publish_time": "2024-08-09", "title": "TaSL: Task Skill Localization and Consolidation for Language Model Continual Learning", "paper_summary": "Language model continual learning (CL) has recently garnered significant\ninterest due to its potential to adapt large language models (LLMs) to dynamic\nreal-world environments without re-training. A key challenge in this field is\ncatastrophic forgetting, where models lose previously acquired knowledge when\nlearning new tasks. Existing methods commonly employ multiple\nparameter-efficient fine-tuning (PEFT) blocks to acquire task-specific\nknowledge for each task, but these approaches lack efficiency and overlook the\npotential for knowledge transfer through task interaction. In this paper, we\npresent a novel CL framework for language models called Task Skill Localization\nand Consolidation (TaSL), which enhances knowledge transfer without relying on\nmemory replay. TaSL first divides the model into `skill units' based on\nparameter dependencies, enabling more granular control. It then employs a novel\ngroup-wise skill localization technique to identify the importance distribution\nof skill units for a new task. By comparing this importance distribution with\nthose from previous tasks, we implement a fine-grained skill consolidation\nstrategy that retains task-specific knowledge, thereby preventing forgetting,\nand updates task-shared knowledge, which facilitates bi-directional knowledge\ntransfer. As a result, TaSL achieves a superior balance between retaining\nprevious knowledge and excelling in new tasks. TaSL also shows strong\ngeneralizability, suitable for general models and customizable for PEFT methods\nlike LoRA. Additionally, it demonstrates notable extensibility, allowing\nintegration with memory replay to further enhance performance. Extensive\nexperiments on two CL benchmarks, with varying model sizes (from 220M to 7B),\ndemonstrate the effectiveness of TaSL and its variants across different\nsettings.", "paper_summary_zh": "<paragraph>\u8a9e\u8a00\u6a21\u578b\u6301\u7e8c\u5b78\u7fd2 (CL) \u8fd1\u4f86\u5099\u53d7\u95dc\u6ce8\uff0c\u56e0\u70ba\u5b83\u6709\u6f5b\u529b\u8b93\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u9069\u61c9\u52d5\u614b\u7684\u771f\u5be6\u4e16\u754c\u74b0\u5883\uff0c\u800c\u7121\u9700\u91cd\u65b0\u8a13\u7df4\u3002\u6b64\u9818\u57df\u7684\u4e00\u9805\u95dc\u9375\u6311\u6230\u662f\u707d\u96e3\u6027\u907a\u5fd8\uff0c\u4e5f\u5c31\u662f\u6a21\u578b\u5728\u5b78\u7fd2\u65b0\u4efb\u52d9\u6642\u6703\u907a\u5931\u5148\u524d\u7fd2\u5f97\u7684\u77e5\u8b58\u3002\u73fe\u6709\u65b9\u6cd5\u901a\u5e38\u63a1\u7528\u591a\u500b\u53c3\u6578\u9ad8\u6548\u5fae\u8abf (PEFT) \u5340\u584a\u4f86\u70ba\u6bcf\u500b\u4efb\u52d9\u53d6\u5f97\u7279\u5b9a\u65bc\u4efb\u52d9\u7684\u77e5\u8b58\uff0c\u4f46\u9019\u4e9b\u65b9\u6cd5\u7f3a\u4e4f\u6548\u7387\uff0c\u800c\u4e14\u5ffd\u7565\u4e86\u900f\u904e\u4efb\u52d9\u4e92\u52d5\u9032\u884c\u77e5\u8b58\u50b3\u8f38\u7684\u6f5b\u529b\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u7a31\u70ba\u4efb\u52d9\u6280\u80fd\u5b9a\u4f4d\u548c\u6574\u5408 (TaSL) \u7684\u8a9e\u8a00\u6a21\u578b\u65b0 CL \u67b6\u69cb\uff0c\u5b83\u589e\u5f37\u4e86\u77e5\u8b58\u50b3\u8f38\uff0c\u800c\u7121\u9700\u4f9d\u8cf4\u8a18\u61b6\u9ad4\u91cd\u64ad\u3002TaSL \u9996\u5148\u6839\u64da\u53c3\u6578\u4f9d\u8cf4\u6027\u5c07\u6a21\u578b\u5206\u6210\u300c\u6280\u80fd\u55ae\u5143\u300d\uff0c\u9032\u800c\u80fd\u66f4\u7cbe\u7d30\u5730\u63a7\u5236\u3002\u63a5\u8457\uff0c\u5b83\u63a1\u7528\u4e00\u7a2e\u65b0\u7684\u7fa4\u7d44\u5f0f\u6280\u80fd\u5b9a\u4f4d\u6280\u8853\uff0c\u627e\u51fa\u6280\u80fd\u55ae\u5143\u5728\u65b0\u4efb\u52d9\u4e2d\u7684\u91cd\u8981\u6027\u5206\u4f48\u3002\u900f\u904e\u5c07\u6b64\u91cd\u8981\u6027\u5206\u4f48\u8207\u5148\u524d\u4efb\u52d9\u4e2d\u7684\u91cd\u8981\u6027\u5206\u4f48\u9032\u884c\u6bd4\u8f03\uff0c\u6211\u5011\u5be6\u4f5c\u4e86\u4e00\u7a2e\u7cbe\u7d30\u7684\u6280\u80fd\u6574\u5408\u7b56\u7565\uff0c\u4fdd\u7559\u7279\u5b9a\u65bc\u4efb\u52d9\u7684\u77e5\u8b58\uff0c\u9032\u800c\u9632\u6b62\u907a\u5fd8\uff0c\u4e26\u66f4\u65b0\u5171\u7528\u65bc\u4efb\u52d9\u7684\u77e5\u8b58\uff0c\u4fc3\u9032\u96d9\u5411\u77e5\u8b58\u50b3\u8f38\u3002\u56e0\u6b64\uff0cTaSL \u5728\u4fdd\u7559\u5148\u524d\u77e5\u8b58\u548c\u5728\u65b0\u7684\u4efb\u52d9\u4e2d\u8868\u73fe\u51fa\u8272\u4e4b\u9593\u53d6\u5f97\u4e86\u66f4\u4f73\u7684\u5e73\u8861\u3002TaSL \u4e5f\u5c55\u73fe\u51fa\u5f37\u5927\u7684\u6982\u62ec\u6027\uff0c\u9069\u7528\u65bc\u4e00\u822c\u6a21\u578b\uff0c\u4e14\u53ef\u81ea\u8a02\u70ba PEFT \u65b9\u6cd5\uff0c\u4f8b\u5982 LoRA\u3002\u6b64\u5916\uff0c\u5b83\u5c55\u73fe\u51fa\u986f\u8457\u7684\u53ef\u64f4\u5145\u6027\uff0c\u5141\u8a31\u8207\u8a18\u61b6\u9ad4\u91cd\u64ad\u6574\u5408\uff0c\u4ee5\u9032\u4e00\u6b65\u589e\u5f37\u6548\u80fd\u3002\u5728\u5169\u500b CL \u57fa\u6e96\u4e0a\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\uff0c\u4f7f\u7528\u4e0d\u540c\u5927\u5c0f\u7684\u6a21\u578b\uff08\u5f9e 220M \u5230 7B\uff09\uff0c\u8b49\u660e\u4e86 TaSL \u53ca\u5176\u8b8a\u9ad4\u5728\u4e0d\u540c\u8a2d\u5b9a\u4e2d\u7684\u6709\u6548\u6027\u3002</paragraph>", "author": "Yujie Feng et.al.", "authors": "Yujie Feng, Xu Chu, Yongxin Xu, Zexin Lu, Bo Liu, Philip S. Yu, Xiao-Ming Wu", "id": "2408.05200v1", "paper_url": "http://arxiv.org/abs/2408.05200v1", "repo": "null"}}