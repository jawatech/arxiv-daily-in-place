{"2407.06189": {"publish_time": "2024-07-08", "title": "Video-STaR: Self-Training Enables Video Instruction Tuning with Any Supervision", "paper_summary": "The performance of Large Vision Language Models (LVLMs) is dependent on the\nsize and quality of their training datasets. Existing video instruction tuning\ndatasets lack diversity as they are derived by prompting large language models\nwith video captions to generate question-answer pairs, and are therefore mostly\ndescriptive. Meanwhile, many labeled video datasets with diverse labels and\nsupervision exist - however, we find that their integration into LVLMs is\nnon-trivial. Herein, we present Video Self-Training with augmented Reasoning\n(Video-STaR), the first video self-training approach. Video-STaR allows the\nutilization of any labeled video dataset for video instruction tuning. In\nVideo-STaR, an LVLM cycles between instruction generation and finetuning, which\nwe show (I) improves general video understanding and (II) adapts LVLMs to novel\ndownstream tasks with existing supervision. During generation, an LVLM is\nprompted to propose an answer. The answers are then filtered only to those that\ncontain the original video labels, and the LVLM is then re-trained on the\ngenerated dataset. By only training on generated answers that contain the\ncorrect video labels, Video-STaR utilizes these existing video labels as weak\nsupervision for video instruction tuning. Our results demonstrate that\nVideo-STaR-enhanced LVLMs exhibit improved performance in (I) general video QA,\nwhere TempCompass performance improved by 10%, and (II) on downstream tasks,\nwhere Video-STaR improved Kinetics700-QA accuracy by 20% and action quality\nassessment on FineDiving by 15%.", "paper_summary_zh": "\u5927\u578b\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (LVLMs) \u7684\u6548\u80fd\u53d6\u6c7a\u65bc\u5176\u8a13\u7df4\u8cc7\u6599\u96c6\u7684\u5927\u5c0f\u548c\u54c1\u8cea\u3002\u73fe\u6709\u7684\u5f71\u7247\u8aaa\u660e\u8abf\u6574\u8cc7\u6599\u96c6\u7f3a\u4e4f\u591a\u6a23\u6027\uff0c\u56e0\u70ba\u5b83\u5011\u662f\u900f\u904e\u63d0\u793a\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u4f7f\u7528\u5f71\u7247\u5b57\u5e55\u4f86\u7522\u751f\u554f\u7b54\u914d\u5c0d\u800c\u884d\u751f\u51fa\u4f86\u7684\uff0c\u56e0\u6b64\u5927\u591a\u662f\u63cf\u8ff0\u6027\u7684\u3002\u540c\u6642\uff0c\u5b58\u5728\u8a31\u591a\u5177\u6709\u591a\u6a23\u5316\u6a19\u7c64\u548c\u76e3\u7763\u7684\u6a19\u7c64\u5f71\u7247\u8cc7\u6599\u96c6\uff0c\u4f46\u6211\u5011\u767c\u73fe\u5c07\u5b83\u5011\u6574\u5408\u5230 LVLMs \u4e2d\u4e26\u975e\u6613\u4e8b\u3002\u5728\u6b64\uff0c\u6211\u5011\u63d0\u51fa\u5e36\u6709\u64f4\u5145\u63a8\u7406\u7684\u5f71\u7247\u81ea\u8a13\u7df4\uff08Video-STaR\uff09\uff0c\u9019\u662f\u4e00\u7a2e\u9996\u5275\u7684\u5f71\u7247\u81ea\u8a13\u7df4\u65b9\u6cd5\u3002Video-STaR \u5141\u8a31\u5229\u7528\u4efb\u4f55\u6a19\u7c64\u5f71\u7247\u8cc7\u6599\u96c6\u9032\u884c\u5f71\u7247\u8aaa\u660e\u8abf\u6574\u3002\u5728 Video-STaR \u4e2d\uff0cLVLM \u5728\u8aaa\u660e\u7522\u751f\u548c\u5fae\u8abf\u4e4b\u9593\u5faa\u74b0\uff0c\u6211\u5011\u8b49\u660e\u9019\uff08\u4e00\uff09\u6539\u5584\u4e86\u5c0d\u5f71\u7247\u7684\u6574\u9ad4\u7406\u89e3\uff0c\u4e14\uff08\u4e8c\uff09\u8b93 LVLMs \u9069\u61c9\u73fe\u6709\u76e3\u7763\u7684\u65b0\u4e0b\u6e38\u4efb\u52d9\u3002\u5728\u7522\u751f\u904e\u7a0b\u4e2d\uff0c\u6703\u63d0\u793a LVLM \u63d0\u51fa\u7b54\u6848\u3002\u7136\u5f8c\uff0c\u7b54\u6848\u6703\u904e\u6ffe\uff0c\u50c5\u4fdd\u7559\u5305\u542b\u539f\u59cb\u5f71\u7247\u6a19\u7c64\u7684\u7b54\u6848\uff0c\u63a5\u8457\u5728\u7522\u751f\u7684\u8cc7\u6599\u96c6\u4e0a\u91cd\u65b0\u8a13\u7df4 LVLM\u3002Video-STaR \u50c5\u8a13\u7df4\u5305\u542b\u6b63\u78ba\u5f71\u7247\u6a19\u7c64\u7684\u7522\u751f\u7b54\u6848\uff0c\u5229\u7528\u9019\u4e9b\u73fe\u6709\u7684\u5f71\u7247\u6a19\u7c64\u4f5c\u70ba\u5f71\u7247\u8aaa\u660e\u8abf\u6574\u7684\u5f31\u76e3\u7763\u3002\u6211\u5011\u7684\u7d50\u679c\u8b49\u660e\uff0cVideo-STaR \u589e\u5f37\u7684 LVLMs \u5728\uff08\u4e00\uff09\u4e00\u822c\u5f71\u7247\u554f\u7b54\u4e2d\u8868\u73fe\u51fa\u66f4\u597d\u7684\u6548\u80fd\uff0c\u5176\u4e2d TempCompass \u7684\u6548\u80fd\u63d0\u5347\u4e86 10%\uff0c\u4ee5\u53ca\uff08\u4e8c\uff09\u4e0b\u6e38\u4efb\u52d9\u4e2d\uff0c\u5176\u4e2d Video-STaR \u5c07 Kinetics700-QA \u7684\u6e96\u78ba\u5ea6\u63d0\u5347\u4e86 20%\uff0c\u4e26\u5c07 FineDiving \u7684\u52d5\u4f5c\u54c1\u8cea\u8a55\u4f30\u63d0\u5347\u4e86 15%\u3002", "author": "Orr Zohar et.al.", "authors": "Orr Zohar, Xiaohan Wang, Yonatan Bitton, Idan Szpektor, Serena Yeung-Levy", "id": "2407.06189v1", "paper_url": "http://arxiv.org/abs/2407.06189v1", "repo": "null"}}