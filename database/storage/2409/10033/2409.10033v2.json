{"2409.10033": {"publish_time": "2024-09-16", "title": "Can GPT-O1 Kill All Bugs? An Evaluation of GPT-Family LLMs on QuixBugs", "paper_summary": "LLMs have long demonstrated remarkable effectiveness in automatic program\nrepair (APR), with OpenAI's ChatGPT being one of the most widely used models in\nthis domain. Through continuous iterations and upgrades of GPT-family models,\ntheir performance in fixing bugs has already reached state-of-the-art levels.\nHowever, there are few works comparing the effectiveness and variations of\ndifferent versions of GPT-family models on APR. In this work, inspired by the\nrecent public release of the GPT-o1 models, we conduct the first study to\ncompare the effectiveness of different versions of the GPT-family models in\nAPR. We evaluate the performance of the latest version of the GPT-family models\n(i.e., O1-preview and O1-mini), GPT-4o, and the historical version of ChatGPT\non APR. We conduct an empirical study of the four GPT-family models against\nother LLMs and APR techniques on the QuixBugs benchmark from multiple\nevaluation perspectives, including repair success rate, repair cost, response\nlength, and behavior patterns. The results demonstrate that O1's repair\ncapability exceeds that of prior GPT-family models, successfully fixing all 40\nbugs in the benchmark. Our work can serve as a foundation for further in-depth\nexploration of the applications of GPT-family models in APR.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u5728\u81ea\u52d5\u7a0b\u5f0f\u4fee\u5fa9 (APR) \u4e2d\u9577\u671f\u4ee5\u4f86\u5c55\u73fe\u51fa\u9a5a\u4eba\u7684\u6548\u679c\uff0c\u800c OpenAI \u7684 ChatGPT \u662f\u6b64\u9818\u57df\u4f7f\u7528\u6700\u5ee3\u6cdb\u7684\u6a21\u578b\u4e4b\u4e00\u3002\u900f\u904e GPT \u5bb6\u65cf\u6a21\u578b\u7684\u6301\u7e8c\u8fed\u4ee3\u548c\u5347\u7d1a\uff0c\u5b83\u5011\u5728\u4fee\u5fa9\u932f\u8aa4\u65b9\u9762\u7684\u6548\u80fd\u5df2\u9054\u5230\u6700\u5148\u9032\u7684\u6c34\u5e73\u3002\u7136\u800c\uff0c\u6bd4\u8f03\u4e0d\u540c\u7248\u672c\u7684 GPT \u5bb6\u65cf\u6a21\u578b\u5728 APR \u4e0a\u7684\u6548\u80fd\u548c\u5dee\u7570\u6027\u7684\u7814\u7a76\u5f88\u5c11\u3002\u5728\u9019\u9805\u7814\u7a76\u4e2d\uff0c\u53d7\u5230 GPT-o1 \u6a21\u578b\u6700\u8fd1\u516c\u958b\u767c\u5e03\u7684\u555f\u767c\uff0c\u6211\u5011\u9032\u884c\u4e86\u7b2c\u4e00\u500b\u7814\u7a76\uff0c\u4ee5\u6bd4\u8f03\u4e0d\u540c\u7248\u672c\u7684 GPT \u5bb6\u65cf\u6a21\u578b\u5728 APR \u4e2d\u7684\u6548\u80fd\u3002\u6211\u5011\u8a55\u4f30\u4e86\u6700\u65b0\u7248\u672c\u7684 GPT \u5bb6\u65cf\u6a21\u578b\uff08\u5373 O1-preview \u548c O1-mini\uff09\u3001GPT-4o \u548c\u6b77\u53f2\u7248\u672c\u7684 ChatGPT \u5728 APR \u4e0a\u7684\u6548\u80fd\u3002\u6211\u5011\u91dd\u5c0d QuixBugs \u57fa\u6e96\uff0c\u6839\u64da\u4fee\u5fa9\u6210\u529f\u7387\u3001\u4fee\u5fa9\u6210\u672c\u3001\u56de\u61c9\u9577\u5ea6\u548c\u884c\u70ba\u6a21\u5f0f\u7b49\u591a\u500b\u8a55\u4f30\u89d2\u5ea6\uff0c\u5c0d\u9019\u56db\u500b GPT \u5bb6\u65cf\u6a21\u578b\u8207\u5176\u4ed6\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u548c APR \u6280\u8853\u9032\u884c\u5be6\u8b49\u7814\u7a76\u3002\u7d50\u679c\u8868\u660e\uff0cO1 \u7684\u4fee\u5fa9\u80fd\u529b\u8d85\u904e\u4e86\u5148\u524d\u7684 GPT \u5bb6\u65cf\u6a21\u578b\uff0c\u6210\u529f\u4fee\u5fa9\u4e86\u57fa\u6e96\u4e2d\u7684\u6240\u6709 40 \u500b\u932f\u8aa4\u3002\u6211\u5011\u7684\u7814\u7a76\u53ef\u4ee5\u4f5c\u70ba\u9032\u4e00\u6b65\u6df1\u5165\u63a2\u8a0e GPT \u5bb6\u65cf\u6a21\u578b\u5728 APR \u4e2d\u61c9\u7528\u57fa\u790e\u3002", "author": "Haichuan Hu et.al.", "authors": "Haichuan Hu, Ye Shang, Guolin Xu, Congqing He, Quanjun Zhang", "id": "2409.10033v2", "paper_url": "http://arxiv.org/abs/2409.10033v2", "repo": "https://github.com/tomsawyerhu/gpt-o1-on-quixbugs"}}