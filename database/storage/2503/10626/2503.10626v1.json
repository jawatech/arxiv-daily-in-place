{"2503.10626": {"publish_time": "2025-03-13", "title": "NIL: No-data Imitation Learning by Leveraging Pre-trained Video Diffusion Models", "paper_summary": "Acquiring physically plausible motor skills across diverse and unconventional\nmorphologies-including humanoid robots, quadrupeds, and animals-is essential\nfor advancing character simulation and robotics. Traditional methods, such as\nreinforcement learning (RL) are task- and body-specific, require extensive\nreward function engineering, and do not generalize well. Imitation learning\noffers an alternative but relies heavily on high-quality expert demonstrations,\nwhich are difficult to obtain for non-human morphologies. Video diffusion\nmodels, on the other hand, are capable of generating realistic videos of\nvarious morphologies, from humans to ants. Leveraging this capability, we\npropose a data-independent approach for skill acquisition that learns 3D motor\nskills from 2D-generated videos, with generalization capability to\nunconventional and non-human forms. Specifically, we guide the imitation\nlearning process by leveraging vision transformers for video-based comparisons\nby calculating pair-wise distance between video embeddings. Along with\nvideo-encoding distance, we also use a computed similarity between segmented\nvideo frames as a guidance reward. We validate our method on locomotion tasks\ninvolving unique body configurations. In humanoid robot locomotion tasks, we\ndemonstrate that 'No-data Imitation Learning' (NIL) outperforms baselines\ntrained on 3D motion-capture data. Our results highlight the potential of\nleveraging generative video models for physically plausible skill learning with\ndiverse morphologies, effectively replacing data collection with data\ngeneration for imitation learning.", "paper_summary_zh": "<paragraph>\u5728\u5305\u62ec\u4eba\u5f62\u6a5f\u5668\u4eba\u3001\u56db\u8db3\u52d5\u7269\u548c\u4e00\u822c\u52d5\u7269\u5728\u5167\u7684\u5404\u7a2e\u975e\u5e38\u898f\u5f62\u614b\u4e2d\u7fd2\u5f97\u7269\u7406\u4e0a\u5408\u7406\u7684\u904b\u52d5\u6280\u80fd\uff0c\u5c0d\u65bc\u63a8\u9032\u89d2\u8272\u6a21\u64ec\u548c\u6a5f\u5668\u4eba\u6280\u8853\u81f3\u95dc\u91cd\u8981\u3002\u50b3\u7d71\u65b9\u6cd5\uff0c\u4f8b\u5982\u5f37\u5316\u5b78\u7fd2 (RL)\uff0c\u662f\u91dd\u5c0d\u7279\u5b9a\u4efb\u52d9\u548c\u8eab\u9ad4\u7684\uff0c\u9700\u8981\u5927\u91cf\u7684\u734e\u52f5\u51fd\u6578\u5de5\u7a0b\uff0c\u800c\u4e14\u6cdb\u5316\u80fd\u529b\u4e0d\u4f73\u3002\u6a21\u4eff\u5b78\u7fd2\u63d0\u4f9b\u4e86\u4e00\u7a2e\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u56b4\u91cd\u4f9d\u8cf4\u65bc\u96e3\u4ee5\u7372\u5f97\u7684\u975e\u4eba\u985e\u5f62\u614b\u7684\u9ad8\u8cea\u91cf\u5c08\u5bb6\u793a\u7bc4\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u8996\u983b\u64f4\u6563\u6a21\u578b\u80fd\u5920\u751f\u6210\u5f9e\u4eba\u985e\u5230\u879e\u87fb\u7b49\u5404\u7a2e\u5f62\u614b\u7684\u903c\u771f\u8996\u983b\u3002\u5229\u7528\u6b64\u529f\u80fd\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u8207\u6578\u64da\u7121\u95dc\u7684\u6280\u80fd\u7fd2\u5f97\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5f9e 2D \u751f\u6210\u7684\u8996\u983b\u4e2d\u5b78\u7fd2 3D \u904b\u52d5\u6280\u80fd\uff0c\u4e26\u5177\u6709\u6cdb\u5316\u5230\u975e\u5e38\u898f\u548c\u975e\u4eba\u985e\u5f62\u614b\u7684\u80fd\u529b\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u5229\u7528\u8996\u89ba\u8b8a\u63db\u5668\u9032\u884c\u57fa\u65bc\u8996\u983b\u7684\u6bd4\u8f03\uff0c\u901a\u904e\u8a08\u7b97\u8996\u983b\u5d4c\u5165\u4e4b\u9593\u7684\u6210\u5c0d\u8ddd\u96e2\u4f86\u5f15\u5c0e\u6a21\u4eff\u5b78\u7fd2\u904e\u7a0b\u3002\u9664\u4e86\u8996\u983b\u7de8\u78bc\u8ddd\u96e2\u4e4b\u5916\uff0c\u6211\u5011\u9084\u4f7f\u7528\u8a08\u7b97\u51fa\u7684\u5206\u6bb5\u8996\u983b\u5e40\u4e4b\u9593\u7684\u76f8\u4f3c\u5ea6\u4f5c\u70ba\u6307\u5c0e\u734e\u52f5\u3002\u6211\u5011\u5728\u6d89\u53ca\u7368\u7279\u8eab\u9ad4\u7d50\u69cb\u7684\u904b\u52d5\u4efb\u52d9\u4e0a\u9a57\u8b49\u4e86\u6211\u5011\u7684\u65b9\u6cd5\u3002\u5728\u4eba\u5f62\u6a5f\u5668\u4eba\u904b\u52d5\u4efb\u52d9\u4e2d\uff0c\u6211\u5011\u8b49\u660e\u4e86\u300c\u7121\u6578\u64da\u6a21\u4eff\u5b78\u7fd2\u300d(NIL) \u7684\u8868\u73fe\u512a\u65bc\u4f7f\u7528 3D \u904b\u52d5\u6355\u6349\u6578\u64da\u8a13\u7df4\u7684\u57fa\u6e96\u6a21\u578b\u3002\u6211\u5011\u7684\u7d50\u679c\u7a81\u51fa\u4e86\u5229\u7528\u751f\u6210\u8996\u983b\u6a21\u578b\u9032\u884c\u5404\u7a2e\u5f62\u614b\u7684\u7269\u7406\u4e0a\u5408\u7406\u7684\u6280\u80fd\u5b78\u7fd2\u7684\u6f5b\u529b\uff0c\u6709\u6548\u5730\u7528\u6578\u64da\u751f\u6210\u53d6\u4ee3\u4e86\u6a21\u4eff\u5b78\u7fd2\u7684\u6578\u64da\u6536\u96c6\u3002</paragraph>\n", "author": "Mert Albaba et.al.", "authors": "Mert Albaba, Chenhao Li, Markos Diomataris, Omid Taheri, Andreas Krause, Michael Black", "id": "2503.10626v1", "paper_url": "http://arxiv.org/abs/2503.10626v1", "repo": "null"}}