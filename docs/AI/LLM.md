
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-15**|**How Do Generative Models Draw a Software Engineer? A Case Study on Stable Diffusion Bias**|Tosin Fadahunsi et.al.|[2501.09014v1](http://arxiv.org/abs/2501.09014v1)|[link](https://github.com/giordanodaloisio/sd-bias)|
|**2025-01-15**|**Multimodal LLMs Can Reason about Aesthetics in Zero-Shot**|Ruixiang Jiang et.al.|[2501.09012v1](http://arxiv.org/abs/2501.09012v1)|[link](https://github.com/songrise/mllm4art)|
|**2025-01-15**|**Aegis2.0: A Diverse AI Safety Dataset and Risks Taxonomy for Alignment of LLM Guardrails**|Shaona Ghosh et.al.|[2501.09004v1](http://arxiv.org/abs/2501.09004v1)|null|
|**2025-01-15**|**Personality Modeling for Persuasion of Misinformation using AI Agent**|Qianmin Lou et.al.|[2501.08985v1](http://arxiv.org/abs/2501.08985v1)|null|
|**2025-01-15**|**Development and Validation of the Provider Documentation Summarization Quality Instrument for Large Language Models**|Emma Croxford et.al.|[2501.08977v1](http://arxiv.org/abs/2501.08977v1)|null|
|**2025-01-15**|**Learning to Extract Cross-Domain Aspects and Understanding Sentiments Using Large Language Models**|Karukriti Kaushik Ghosh et.al.|[2501.08974v1](http://arxiv.org/abs/2501.08974v1)|null|
|**2025-01-15**|**Trusted Machine Learning Models Unlock Private Inference for Problems Currently Infeasible with Cryptography**|Ilia Shumailov et.al.|[2501.08970v1](http://arxiv.org/abs/2501.08970v1)|null|
|**2025-01-15**|**An analysis of data variation and bias in image-based dermatological datasets for machine learning classification**|Francisco Mauro et.al.|[2501.08962v1](http://arxiv.org/abs/2501.08962v1)|null|
|**2025-01-15**|**Kolmogorov-Arnold Networks for Time Series Granger Causality Inference**|Meiliang Liu et.al.|[2501.08958v1](http://arxiv.org/abs/2501.08958v1)|null|
|**2025-01-15**|**Analyzing the Ethical Logic of Six Large Language Models**|W. Russell Neuman et.al.|[2501.08951v1](http://arxiv.org/abs/2501.08951v1)|null|
|**2025-01-15**|**Applying General Turn-taking Models to Conversational Human-Robot Interaction**|Gabriel Skantze et.al.|[2501.08946v1](http://arxiv.org/abs/2501.08946v1)|null|
|**2025-01-15**|**Visual WetlandBirds Dataset: Bird Species Identification and Behavior Recognition in Videos**|Javier Rodriguez-Juan et.al.|[2501.08931v1](http://arxiv.org/abs/2501.08931v1)|[link](https://github.com/3dperceptionlab/visual-wetlandbirds)|
|**2025-01-15**|**Disentangling Exploration of Large Language Models by Optimal Exploitation**|Tim Grams et.al.|[2501.08925v1](http://arxiv.org/abs/2501.08925v1)|null|
|**2025-01-15**|**Modeling Melt Pool Features and Spatter Using Symbolic Regression and Machine Learning**|Olabode T. Ajenifujah et.al.|[2501.08922v1](http://arxiv.org/abs/2501.08922v1)|null|
|**2025-01-15**|**GenAI Content Detection Task 3: Cross-Domain Machine-Generated Text Detection Challenge**|Liam Dugan et.al.|[2501.08913v1](http://arxiv.org/abs/2501.08913v1)|null|
|**2025-01-15**|**Leveraging Large Language Models as Knowledge-Driven Agents for Reliable Retrosynthesis Planning**|Qinyu Ma et.al.|[2501.08897v1](http://arxiv.org/abs/2501.08897v1)|null|
|**2025-01-15**|**Incrementally Learning Multiple Diverse Data Domains via Multi-Source Dynamic Expansion Model**|Runqing Wu et.al.|[2501.08878v1](http://arxiv.org/abs/2501.08878v1)|null|
|**2025-01-15**|**Silent Abandonment in Text-Based Contact Centers: Identifying, Quantifying, and Mitigating its Operational Impacts**|Antonio Castellanos et.al.|[2501.08869v1](http://arxiv.org/abs/2501.08869v1)|null|
|**2025-01-15**|**ARMOR: Shielding Unlearnable Examples against Data Augmentation**|Xueluan Gong et.al.|[2501.08862v1](http://arxiv.org/abs/2501.08862v1)|null|
|**2025-01-15**|**Digital Phenotyping for Adolescent Mental Health: A Feasibility Study Employing Machine Learning to Predict Mental Health Risk From Active and Passive Smartphone Data**|Balasundaram Kadirvelu et.al.|[2501.08851v1](http://arxiv.org/abs/2501.08851v1)|null|
|**2025-01-15**|**Graph Counterfactual Explainable AI via Latent Space Traversal**|Andreas Abildtrup Hansen et.al.|[2501.08850v1](http://arxiv.org/abs/2501.08850v1)|null|
|**2025-01-15**|**RouteNet-Gauss: Hardware-Enhanced Network Modeling with Machine Learning**|Carlos Güemes-Palau et.al.|[2501.08848v1](http://arxiv.org/abs/2501.08848v1)|null|
|**2025-01-15**|**Exploring Task-Level Optimal Prompts for Visual In-Context Learning**|Yan Zhu et.al.|[2501.08841v1](http://arxiv.org/abs/2501.08841v1)|null|
|**2025-01-15**|**ToMATO: Verbalizing the Mental States of Role-Playing LLMs for Benchmarking Theory of Mind**|Kazutoshi Shinoda et.al.|[2501.08838v1](http://arxiv.org/abs/2501.08838v1)|[link](https://github.com/nttmdlab-nlp/ToMATO)|
|**2025-01-15**|**IDEA: Image Description Enhanced CLIP-Adapter**|Zhipeng Ye et.al.|[2501.08816v1](http://arxiv.org/abs/2501.08816v1)|null|
|**2025-01-15**|**How Developers Interact with AI: A Taxonomy of Human-AI Collaboration in Software Engineering**|Christoph Treude et.al.|[2501.08774v1](http://arxiv.org/abs/2501.08774v1)|null|
|**2025-01-15**|**Enhanced Large Language Models for Effective Screening of Depression and Anxiety**|June M. Liu et.al.|[2501.08769v1](http://arxiv.org/abs/2501.08769v1)|null|
|**2025-01-15**|**Leveraging LLM Agents for Translating Network Configurations**|Yunze Wei et.al.|[2501.08760v1](http://arxiv.org/abs/2501.08760v1)|null|
|**2025-01-15**|**Expanding Vietnamese SentiWordNet to Improve Performance of Vietnamese Sentiment Analysis Models**|Hong-Viet Tran et.al.|[2501.08758v1](http://arxiv.org/abs/2501.08758v1)|null|
|**2025-01-15**|**The Inherent Limits of Pretrained LLMs: The Unexpected Convergence of Instruction Tuning and In-Context Learning Capabilities**|Irina Bigoulaeva et.al.|[2501.08716v1](http://arxiv.org/abs/2501.08716v1)|[link](https://github.com/ukplab/arxiv2025-inherent-limits-plms)|
|**2025-01-15**|**Self-supervised Transformation Learning for Equivariant Representations**|Jaemyung Yu et.al.|[2501.08712v1](http://arxiv.org/abs/2501.08712v1)|[link](https://github.com/jaemyung-u/stl)|
|**2025-01-15**|**Deep Learning-Based Feature Fusion for Emotion Analysis and Suicide Risk Differentiation in Chinese Psychological Support Hotlines**|Han Wang et.al.|[2501.08696v1](http://arxiv.org/abs/2501.08696v1)|[link](https://github.com/sco-field/speechemotionrecognition)|
|**2025-01-15**|**Knowledge Graph-based Retrieval-Augmented Generation for Schema Matching**|Chuangtao Ma et.al.|[2501.08686v1](http://arxiv.org/abs/2501.08686v1)|null|
|**2025-01-15**|**Application of Deep Reinforcement Learning to UAV Swarming for Ground Surveillance**|Raúl Arranz et.al.|[2501.08655v1](http://arxiv.org/abs/2501.08655v1)|null|
|**2025-01-15**|**Fine-grained Spatio-temporal Event Prediction with Self-adaptive Anchor Graph**|Wang-Tao Zhou et.al.|[2501.08653v1](http://arxiv.org/abs/2501.08653v1)|null|
|**2025-01-15**|**MAGNET: Augmenting Generative Decoders with Representation Learning and Infilling Capabilities**|Savya Khosla et.al.|[2501.08648v1](http://arxiv.org/abs/2501.08648v1)|null|
|**2025-01-15**|**Reassessing the Role of Chain-of-Thought in Sentiment Analysis: Insights and Limitations**|Kaiyuan Zheng et.al.|[2501.08641v1](http://arxiv.org/abs/2501.08641v1)|null|
|**2025-01-15**|**SWSC: Shared Weight for Similar Channel in LLM**|Binrui Zeng et.al.|[2501.08631v1](http://arxiv.org/abs/2501.08631v1)|null|
|**2025-01-15**|**ViBidirectionMT-Eval: Machine Translation for Vietnamese-Chinese and Vietnamese-Lao language pair**|Hong-Viet Tran et.al.|[2501.08621v1](http://arxiv.org/abs/2501.08621v1)|null|
|**2025-01-15**|**Disjoint Processing Mechanisms of Hierarchical and Linear Grammars in Large Language Models**|Aruna Sankaranarayanan et.al.|[2501.08618v1](http://arxiv.org/abs/2501.08618v1)|[link](https://github.com/arunasank/disjoint-processing-llms)|
|**2025-01-15**|**RLHS: Mitigating Misalignment in RLHF with Hindsight Simulation**|Kaiqu Liang et.al.|[2501.08617v1](http://arxiv.org/abs/2501.08617v1)|null|
|**2025-01-15**|**Assessing the Alignment of FOL Closeness Metrics with Human Judgement**|Ramya Keerthy Thatikonda et.al.|[2501.08613v1](http://arxiv.org/abs/2501.08613v1)|[link](https://github.com/ramyakeerthy/alignmentfol)|
|**2025-01-15**|**Monte Carlo Tree Search for Comprehensive Exploration in LLM-Based Automatic Heuristic Design**|Zhi Zheng et.al.|[2501.08603v1](http://arxiv.org/abs/2501.08603v1)|[link](https://github.com/zz1358m/mcts-ahd-master)|
|**2025-01-15**|**AutoRestTest: A Tool for Automated REST API Testing Using LLMs and MARL**|Tyler Stennett et.al.|[2501.08600v1](http://arxiv.org/abs/2501.08600v1)|null|
|**2025-01-15**|**LlamaRestTest: Effective REST API Testing with Small Language Models**|Myeongsoo Kim et.al.|[2501.08598v1](http://arxiv.org/abs/2501.08598v1)|null|
|**2025-01-15**|**Dynamic Knowledge Integration for Enhanced Vision-Language Reasoning**|Julian Perry et.al.|[2501.08597v1](http://arxiv.org/abs/2501.08597v1)|null|
|**2025-01-15**|**OpenMLDB: A Real-Time Relational Data Feature Computation System for Online ML**|Xuanhe Zhou et.al.|[2501.08591v1](http://arxiv.org/abs/2501.08591v1)|null|
|**2025-01-15**|**Sound Scene Synthesis at the DCASE 2024 Challenge**|Mathieu Lagrange et.al.|[2501.08587v1](http://arxiv.org/abs/2501.08587v1)|null|
|**2025-01-15**|**LoRS: Efficient Low-Rank Adaptation for Sparse Large Language Model**|Yuxuan Hu et.al.|[2501.08582v1](http://arxiv.org/abs/2501.08582v1)|null|
|**2025-01-15**|**What Limits LLM-based Human Simulation: LLMs or Our Design?**|Qian Wang et.al.|[2501.08579v1](http://arxiv.org/abs/2501.08579v1)|null|
|**2025-01-15**|**Information Entropy Invariance: Enhancing Length Extrapolation in Attention Mechanisms**|Kewei Li et.al.|[2501.08570v1](http://arxiv.org/abs/2501.08570v1)|null|
|**2025-01-15**|**Towards Lightweight and Stable Zero-shot TTS with Self-distilled Representation Disentanglement**|Qianniu Chen et.al.|[2501.08566v1](http://arxiv.org/abs/2501.08566v1)|null|
|**2025-01-15**|**ANSR-DT: An Adaptive Neuro-Symbolic Learning and Reasoning Framework for Digital Twins**|Safayat Bin Hakim et.al.|[2501.08561v1](http://arxiv.org/abs/2501.08561v1)|[link](https://github.com/sbhakim/ansr-dt)|
|**2025-01-15**|**LAMS: LLM-Driven Automatic Mode Switching for Assistive Teleoperation**|Yiran Tao et.al.|[2501.08558v1](http://arxiv.org/abs/2501.08558v1)|null|
|**2025-01-15**|**The Devil is in Temporal Token: High Quality Video Reasoning Segmentation**|Sitong Gong et.al.|[2501.08549v1](http://arxiv.org/abs/2501.08549v1)|null|
|**2025-01-15**|**Knowledge prompt chaining for semantic modeling**|Ning Pei Ding et.al.|[2501.08540v1](http://arxiv.org/abs/2501.08540v1)|[link](https://github.com/dingningpei/llm_semantics)|
|**2025-01-15**|**Complexity Control Facilitates Reasoning-Based Compositional Generalization in Transformers**|Zhongwang Zhang et.al.|[2501.08537v1](http://arxiv.org/abs/2501.08537v1)|[link](https://github.com/sjtuzzw/complexity_control)|
|**2025-01-15**|**Dynamic Portfolio Optimization via Augmented DDPG with Quantum Price Levels-Based Trading Strategy**|Runsheng Lin et.al.|[2501.08528v1](http://arxiv.org/abs/2501.08528v1)|null|
|**2025-01-15**|**Doc-Guided Sent2Sent++: A Sent2Sent++ Agent with Doc-Guided memory for Document-level Machine Translation**|Jiaxin Guo et.al.|[2501.08523v1](http://arxiv.org/abs/2501.08523v1)|null|
|**2025-01-15**|**Mitigating Domain Shift in Federated Learning via Intra- and Inter-Domain Prototypes**|Huy Q. Le et.al.|[2501.08521v1](http://arxiv.org/abs/2501.08521v1)|null|
|**2025-01-15**|**Exploring the Efficacy of Meta-Learning: Unveiling Superior Data Diversity Utilization of MAML Over Pre-training**|Kavita Selva et.al.|[2501.08506v1](http://arxiv.org/abs/2501.08506v1)|null|
|**2025-01-15**|**Adapting Whisper for Regional Dialects: Enhancing Public Services for Vulnerable Populations in the United Kingdom**|Melissa Torgbi et.al.|[2501.08502v1](http://arxiv.org/abs/2501.08502v1)|null|
|**2025-01-14**|**Quantifying the Importance of Data Alignment in Downstream Model Performance**|Krrish Chawla et.al.|[2501.08496v1](http://arxiv.org/abs/2501.08496v1)|null|
|**2025-01-14**|**Benchmarking Classical, Deep, and Generative Models for Human Activity Recognition**|Md Meem Hossain et.al.|[2501.08471v1](http://arxiv.org/abs/2501.08471v1)|null|
|**2025-01-14**|**Detecting Contextual Anomalies by Discovering Consistent Spatial Regions**|Zhengye Yang et.al.|[2501.08470v1](http://arxiv.org/abs/2501.08470v1)|null|
|**2025-01-14**|**Selective Attention Merging for low resource tasks: A case study of Child ASR**|Natarajan Balaji Shankar et.al.|[2501.08468v1](http://arxiv.org/abs/2501.08468v1)|[link](https://github.com/balaji1312/sa_merging)|
|**2025-01-14**|**Towards Zero-Shot & Explainable Video Description by Reasoning over Graphs of Events in Space and Time**|Mihai Masala et.al.|[2501.08460v1](http://arxiv.org/abs/2501.08460v1)|null|
|**2025-01-14**|**Large Language Models For Text Classification: Case Study And Comprehensive Review**|Arina Kostina et.al.|[2501.08457v1](http://arxiv.org/abs/2501.08457v1)|null|
|**2025-01-14**|**Tag&Tab: Pretraining Data Detection in Large Language Models Using Keyword-Based Membership Inference Attack**|Sagiv Antebi et.al.|[2501.08454v1](http://arxiv.org/abs/2501.08454v1)|null|
|**2025-01-14**|**Active Sampling for Node Attribute Completion on Graphs**|Benyuan Liu et.al.|[2501.08450v1](http://arxiv.org/abs/2501.08450v1)|null|
|**2025-01-14**|**Jochre 3 and the Yiddish OCR corpus**|Assaf Urieli et.al.|[2501.08442v1](http://arxiv.org/abs/2501.08442v1)|null|
|**2025-01-14**|**Religious Bias Landscape in Language and Text-to-Image Models: Analysis, Detection, and Debiasing Strategies**|Ajwad Abrar et.al.|[2501.08441v1](http://arxiv.org/abs/2501.08441v1)|null|
|**2025-01-14**|**Modeling Discrimination with Causal Abstraction**|Milan Mossé et.al.|[2501.08429v1](http://arxiv.org/abs/2501.08429v1)|null|
|**2025-01-14**|**Causal vs. Anticausal merging of predictors**|Sergio Hernan Garrido Mejia et.al.|[2501.08426v1](http://arxiv.org/abs/2501.08426v1)|null|
|**2025-01-14**|**SEAL: Speaker Error Correction using Acoustic-conditioned Large Language Models**|Anurag Kumar et.al.|[2501.08421v1](http://arxiv.org/abs/2501.08421v1)|null|
|**2025-01-14**|**CVaR-Based Variational Quantum Optimization for User Association in Handoff-Aware Vehicular Networks**|Zijiang Yan et.al.|[2501.08418v1](http://arxiv.org/abs/2501.08418v1)|null|
|**2025-01-14**|**Cross-Modal Transferable Image-to-Video Attack on Video Quality Metrics**|Georgii Gotin et.al.|[2501.08415v1](http://arxiv.org/abs/2501.08415v1)|null|
|**2025-01-14**|**Ensemble of Large Language Models for Curated Labeling and Rating of Free-text Data**|Jiaxing Qiu et.al.|[2501.08413v1](http://arxiv.org/abs/2501.08413v1)|null|
|**2025-01-14**|**OptiChat: Bridging Optimization Models and Practitioners with Large Language Models**|Hao Chen et.al.|[2501.08406v1](http://arxiv.org/abs/2501.08406v1)|[link](https://github.com/li-group/optichat)|
|**2025-01-14**|**Addressing Quality Challenges in Deep Learning: The Role of MLOps and Domain Knowledge**|Santiago del Rey et.al.|[2501.08402v1](http://arxiv.org/abs/2501.08402v1)|null|
|**2025-01-14**|**PokerBench: Training Large Language Models to become Professional Poker Players**|Richard Zhuang et.al.|[2501.08328v1](http://arxiv.org/abs/2501.08328v1)|[link](https://github.com/pokerllm/pokerbench)|
|**2025-01-14**|**ADAM-1: AI and Bioinformatics for Alzheimer's Detection and Microbiome-Clinical Data Integrations**|Ziyuan Huang et.al.|[2501.08324v1](http://arxiv.org/abs/2501.08324v1)|null|
|**2025-01-14**|**Exploring Robustness of Multilingual LLMs on Real-World Noisy Data**|Amirhossein Aliakbarzadeh et.al.|[2501.08322v1](http://arxiv.org/abs/2501.08322v1)|[link](https://github.com/caisa-lab/llms-real-world-noise-robustness)|
|**2025-01-14**|**Enhancing Automated Interpretability with Output-Centric Feature Descriptions**|Yoav Gur-Arieh et.al.|[2501.08319v1](http://arxiv.org/abs/2501.08319v1)|[link](https://github.com/yoavgur/feature-descriptions)|
|**2025-01-14**|**Diffusion Adversarial Post-Training for One-Step Video Generation**|Shanchuan Lin et.al.|[2501.08316v1](http://arxiv.org/abs/2501.08316v1)|null|
|**2025-01-14**|**MiniMax-01: Scaling Foundation Models with Lightning Attention**|MiniMax et.al.|[2501.08313v1](http://arxiv.org/abs/2501.08313v1)|null|
|**2025-01-14**|**Everybody Likes to Sleep: A Computer-Assisted Comparison of Object Naming Data from 30 Languages**|Alžběta Kučerová et.al.|[2501.08312v1](http://arxiv.org/abs/2501.08312v1)|[link](https://github.com/calc-project/object-naming-data)|
|**2025-01-14**|**Polynomial Threshold Functions of Bounded Tree-Width: Some Explainability and Complexity Aspects**|Karine Chubarian et.al.|[2501.08297v1](http://arxiv.org/abs/2501.08297v1)|null|
|**2025-01-14**|**HALoGEN: Fantastic LLM Hallucinations and Where to Find Them**|Abhilasha Ravichander et.al.|[2501.08292v1](http://arxiv.org/abs/2501.08292v1)|null|
|**2025-01-14**|**AfriHate: A Multilingual Collection of Hate Speech and Abusive Language Datasets for African Languages**|Shamsuddeen Hassan Muhammad et.al.|[2501.08284v2](http://arxiv.org/abs/2501.08284v2)|[link](https://github.com/afrihate/afrihate)|
|**2025-01-14**|**Exploring Robustness of LLMs to Sociodemographically-Conditioned Paraphrasing**|Pulkit Arora et.al.|[2501.08276v1](http://arxiv.org/abs/2501.08276v1)|null|
|**2025-01-14**|**Comparative Analysis of Efficient Adapter-Based Fine-Tuning of State-of-the-Art Transformer Models**|Saad Mashkoor Siddiqui et.al.|[2501.08271v1](http://arxiv.org/abs/2501.08271v1)|null|
|**2025-01-14**|**AI Driven Water Segmentation with deep learning models for Enhanced Flood Monitoring**|Sanjida Afrin Mou et.al.|[2501.08266v1](http://arxiv.org/abs/2501.08266v1)|[link](https://github.com/SanjidaAfrin25/flood-detection-using-deepLab-unet-resnet)|
|**2025-01-14**|**Towards Best Practices for Open Datasets for LLM Training**|Stefan Baack et.al.|[2501.08365v1](http://arxiv.org/abs/2501.08365v1)|null|
|**2025-01-14**|**Eliciting In-context Retrieval and Reasoning for Long-context Large Language Models**|Yifu Qiu et.al.|[2501.08248v1](http://arxiv.org/abs/2501.08248v1)|null|
|**2025-01-14**|**A Feature-Level Ensemble Model for COVID-19 Identification in CXR Images using Choquet Integral and Differential Evolution Optimization**|Amir Reza Takhsha et.al.|[2501.08241v1](http://arxiv.org/abs/2501.08241v1)|null|
|**2025-01-14**|**Dynamic Pricing in High-Speed Railways Using Multi-Agent Reinforcement Learning**|Enrique Adrian Villarrubia-Martin et.al.|[2501.08234v1](http://arxiv.org/abs/2501.08234v1)|null|
|**2025-01-14**|**ASTRID -- An Automated and Scalable TRIaD for the Evaluation of RAG-based Clinical Question Answering Systems**|Mohita Chowdhury et.al.|[2501.08208v1](http://arxiv.org/abs/2501.08208v1)|null|
|**2025-01-14**|**Modeling Feature Maps for Quantum Machine Learning**|Navneet Singh et.al.|[2501.08205v1](http://arxiv.org/abs/2501.08205v1)|null|
|**2025-01-14**|**ArithmAttack: Evaluating Robustness of LLMs to Noisy Context in Math Problem Solving**|Zain Ul Abedin et.al.|[2501.08203v1](http://arxiv.org/abs/2501.08203v1)|null|

#### Abstracts
##### **How Do Generative Models Draw a Software Engineer? A Case Study on Stable Diffusion Bias**
2501.09014v1 by Tosin Fadahunsi, Giordano d'Aloisio, Antinisca Di Marco, Federica Sarro

Generative models are nowadays widely used to generate graphical content used
for multiple purposes, e.g. web, art, advertisement. However, it has been shown
that the images generated by these models could reinforce societal biases
already existing in specific contexts. In this paper, we focus on understanding
if this is the case when one generates images related to various software
engineering tasks. In fact, the Software Engineering (SE) community is not
immune from gender and ethnicity disparities, which could be amplified by the
use of these models. Hence, if used without consciousness, artificially
generated images could reinforce these biases in the SE domain. Specifically,
we perform an extensive empirical evaluation of the gender and ethnicity bias
exposed by three versions of the Stable Diffusion (SD) model (a very popular
open-source text-to-image model) - SD 2, SD XL, and SD 3 - towards SE tasks. We
obtain 6,720 images by feeding each model with two sets of prompts describing
different software-related tasks: one set includes the Software Engineer
keyword, and one set does not include any specification of the person
performing the task. Next, we evaluate the gender and ethnicity disparities in
the generated images. Results show how all models are significantly biased
towards male figures when representing software engineers. On the contrary,
while SD 2 and SD XL are strongly biased towards White figures, SD 3 is
slightly more biased towards Asian figures. Nevertheless, all models
significantly under-represent Black and Arab figures, regardless of the prompt
style used. The results of our analysis highlight severe concerns about
adopting those models to generate content for SE tasks and open the field for
future research on bias mitigation in this context.

摘要：生成模型現今廣泛用於產生圖形內容，用於多種目的，例如網路、藝術、廣告。然而，已顯示由這些模型產生的影像可能強化特定情境中已存在的社會偏見。在本文中，我們專注於了解在產生與各種軟體工程任務相關的影像時是否如此。事實上，軟體工程 (SE) 社群並非不受性別和種族差異影響，而這些差異可能會因使用這些模型而擴大。因此，如果在沒有意識的情況下使用，人工產生的影像可能會強化 SE 領域中的這些偏見。具體來說，我們對 Stable Diffusion (SD) 模型（一個非常流行的開源文字轉影像模型）的三個版本（SD 2、SD XL 和 SD 3）對 SE 任務所揭露的性別和種族偏見進行廣泛的實證評估。我們透過提供兩組描述不同軟體相關任務的提示給各個模型，取得 6,720 張影像：一組包含軟體工程師關鍵字，另一組則不包含執行任務的人員的任何說明。接下來，我們評估產生影像中的性別和種族差異。結果顯示，所有模型在代表軟體工程師時都顯著偏向男性角色。相反地，SD 2 和 SD XL 雖然強烈偏向白人角色，但 SD 3 稍微更偏向亞洲角色。然而，所有模型都顯著低估了黑人和阿拉伯人的角色，無論使用哪種提示樣式。我們的分析結果突顯了採用這些模型來產生 SE 任務內容的嚴重疑慮，並為未來在這個情境中減輕偏見的研究開啟了領域。

##### **Multimodal LLMs Can Reason about Aesthetics in Zero-Shot**
2501.09012v1 by Ruixiang Jiang, Changwen Chen

We present the first study on how Multimodal LLMs' (MLLMs) reasoning ability
shall be elicited to evaluate the aesthetics of artworks. To facilitate this
investigation, we construct MM-StyleBench, a novel high-quality dataset for
benchmarking artistic stylization. We then develop a principled method for
human preference modeling and perform a systematic correlation analysis between
MLLMs' responses and human preference. Our experiments reveal an inherent
hallucination issue of MLLMs in art evaluation, associated with response
subjectivity. ArtCoT is proposed, demonstrating that art-specific task
decomposition and the use of concrete language boost MLLMs' reasoning ability
for aesthetics. Our findings offer valuable insights into MLLMs for art and can
benefit a wide range of downstream applications, such as style transfer and
artistic image generation. Code available at
https://github.com/songrise/MLLM4Art.

摘要：我們提出第一個關於如何引發多模態 LLM (MLLM) 推理能力的研究，以評估藝術品的美感。為了促進這項調查，我們構建了 MM-StyleBench，這是一個用於基準化藝術風格化的全新高品質資料集。然後，我們開發了一種基於原則的方法進行人類偏好建模，並在 MLLM 的回應和人類偏好之間執行系統性的相關性分析。我們的實驗揭示了 MLLM 在藝術評估中固有的幻覺問題，與回應的主觀性有關。ArtCoT 被提出，證明特定於藝術的任務分解和具體語言的使用提升了 MLLM 對美學的推理能力。我們的研究結果為 MLLM 在藝術領域提供了寶貴的見解，並可以使廣泛的下游應用受益，例如風格轉移和藝術圖像生成。程式碼可在 https://github.com/songrise/MLLM4Art 取得。

##### **Aegis2.0: A Diverse AI Safety Dataset and Risks Taxonomy for Alignment of LLM Guardrails**
2501.09004v1 by Shaona Ghosh, Prasoon Varshney, Makesh Narsimhan Sreedhar, Aishwarya Padmakumar, Traian Rebedea, Jibin Rajan Varghese, Christopher Parisien

As Large Language Models (LLMs) and generative AI become increasingly
widespread, concerns about content safety have grown in parallel. Currently,
there is a clear lack of high-quality, human-annotated datasets that address
the full spectrum of LLM-related safety risks and are usable for commercial
applications. To bridge this gap, we propose a comprehensive and adaptable
taxonomy for categorizing safety risks, structured into 12 top-level hazard
categories with an extension to 9 fine-grained subcategories. This taxonomy is
designed to meet the diverse requirements of downstream users, offering more
granular and flexible tools for managing various risk types. Using a hybrid
data generation pipeline that combines human annotations with a multi-LLM
"jury" system to assess the safety of responses, we obtain Aegis 2.0, a
carefully curated collection of 34,248 samples of human-LLM interactions,
annotated according to our proposed taxonomy. To validate its effectiveness, we
demonstrate that several lightweight models, trained using parameter-efficient
techniques on Aegis 2.0, achieve performance competitive with leading safety
models fully fine-tuned on much larger, non-commercial datasets. In addition,
we introduce a novel training blend that combines safety with topic following
data.This approach enhances the adaptability of guard models, enabling them to
generalize to new risk categories defined during inference. We plan to
open-source Aegis 2.0 data and models to the research community to aid in the
safety guardrailing of LLMs.

摘要：隨著大型語言模型 (LLM) 和生成式 AI 日益普及，內容安全方面的擔憂也同步增加。目前，顯著缺乏高品質、人工標註的資料集來解決與 LLM 相關的安全風險全貌，且可供商業應用使用。為了彌補這個差距，我們提出了一個全面且適應性強的分類法，用於分類安全風險，架構成 12 個頂層危害類別，並延伸到 9 個細緻的子類別。此分類法旨在滿足下游使用者的多元需求，提供更細緻且彈性的工具來管理各種風險類型。我們使用結合人工標註和多 LLM「評審團」系統的混合資料產生流程來評估回應的安全性，取得 Aegis 2.0，一個經過仔細整理、包含 34,248 個範例的人類 LLM 互動集合，並根據我們提出的分類法進行標註。為了驗證其有效性，我們示範了數個輕量級模型，使用參數有效技術在 Aegis 2.0 上訓練，其效能與在更大、非商業資料集上進行微調的領先安全模型不相上下。此外，我們引進一種新穎的訓練混合，結合安全性與主題追蹤資料。此方法增強了防護模型的適應性，讓它們能夠在推論期間概化到新的風險類別。我們計畫將 Aegis 2.0 資料和模型開源給研究社群，以協助 LLM 的安全防護。

##### **Personality Modeling for Persuasion of Misinformation using AI Agent**
2501.08985v1 by Qianmin Lou, Wentao Xu

The proliferation of misinformation on social media platforms has highlighted
the need to understand how individual personality traits influence
susceptibility to and propagation of misinformation. This study employs an
innovative agent-based modeling approach to investigate the relationship
between personality traits and misinformation dynamics. Using six AI agents
embodying different dimensions of the Big Five personality traits
(Extraversion, Agreeableness, and Neuroticism), we simulated interactions
across six diverse misinformation topics. The experiment, implemented through
the AgentScope framework using the GLM-4-Flash model, generated 90 unique
interactions, revealing complex patterns in how personality combinations affect
persuasion and resistance to misinformation. Our findings demonstrate that
analytical and critical personality traits enhance effectiveness in
evidence-based discussions, while non-aggressive persuasion strategies show
unexpected success in misinformation correction. Notably, agents with critical
traits achieved a 59.4% success rate in HIV-related misinformation discussions,
while those employing non-aggressive approaches maintained consistent
persuasion rates above 40% across different personality combinations. The study
also revealed a non-transitive pattern in persuasion effectiveness, challenging
conventional assumptions about personality-based influence. These results
provide crucial insights for developing personality-aware interventions in
digital environments and suggest that effective misinformation countermeasures
should prioritize emotional connection and trust-building over confrontational
approaches. The findings contribute to both theoretical understanding of
personality-misinformation dynamics and practical strategies for combating
misinformation in social media contexts.

摘要：社交媒體平台上錯誤訊息的激增，凸顯了了解個人人格特質如何影響對錯誤訊息的敏感度和傳播的重要性。本研究採用創新的基於代理的建模方法來探討人格特質與錯誤訊息動態之間的關係。我們使用六個體現大五人格特質不同面向（外向性、親和性和神經質）的人工智慧代理，模擬了六個不同錯誤訊息主題之間的互動。透過使用 GLM-4-Flash 模型，透過 AgentScope 框架執行的實驗產生了 90 個獨特互動，揭示了人格組合如何影響說服力和對錯誤訊息的抵抗力。我們的研究結果表明，分析和批判的人格特質可以提高基於證據的討論的有效性，而非侵略性的說服策略在錯誤訊息更正方面顯示出意想不到的成功。值得注意的是，具有批判特質的代理人在與 HIV 相關的錯誤訊息討論中取得了 59.4% 的成功率，而採用非侵略性方法的代理人在不同人格組合中維持了一致的說服率，高於 40%。該研究還揭示了說服有效性的非遞移模式，挑戰了基於人格的影響的傳統假設。這些結果為在數位環境中開發具有個性化的干預措施提供了重要的見解，並表明有效的錯誤訊息對策應優先考慮情感聯繫和建立信任，而不是對抗性方法。這些發現有助於對人格錯誤訊息動態的理論理解和在社交媒體背景下打擊錯誤訊息的實用策略。

##### **Development and Validation of the Provider Documentation Summarization Quality Instrument for Large Language Models**
2501.08977v1 by Emma Croxford, Yanjun Gao, Nicholas Pellegrino, Karen K. Wong, Graham Wills, Elliot First, Miranda Schnier, Kyle Burton, Cris G. Ebby, Jillian Gorskic, Matthew Kalscheur, Samy Khalil, Marie Pisani, Tyler Rubeor, Peter Stetson, Frank Liao, Cherodeep Goswami, Brian Patterson, Majid Afshar

As Large Language Models (LLMs) are integrated into electronic health record
(EHR) workflows, validated instruments are essential to evaluate their
performance before implementation. Existing instruments for provider
documentation quality are often unsuitable for the complexities of
LLM-generated text and lack validation on real-world data. The Provider
Documentation Summarization Quality Instrument (PDSQI-9) was developed to
evaluate LLM-generated clinical summaries. Multi-document summaries were
generated from real-world EHR data across multiple specialties using several
LLMs (GPT-4o, Mixtral 8x7b, and Llama 3-8b). Validation included Pearson
correlation for substantive validity, factor analysis and Cronbach's alpha for
structural validity, inter-rater reliability (ICC and Krippendorff's alpha) for
generalizability, a semi-Delphi process for content validity, and comparisons
of high- versus low-quality summaries for discriminant validity. Seven
physician raters evaluated 779 summaries and answered 8,329 questions,
achieving over 80% power for inter-rater reliability. The PDSQI-9 demonstrated
strong internal consistency (Cronbach's alpha = 0.879; 95% CI: 0.867-0.891) and
high inter-rater reliability (ICC = 0.867; 95% CI: 0.867-0.868), supporting
structural validity and generalizability. Factor analysis identified a 4-factor
model explaining 58% of the variance, representing organization, clarity,
accuracy, and utility. Substantive validity was supported by correlations
between note length and scores for Succinct (rho = -0.200, p = 0.029) and
Organized (rho = -0.190, p = 0.037). Discriminant validity distinguished high-
from low-quality summaries (p < 0.001). The PDSQI-9 demonstrates robust
construct validity, supporting its use in clinical practice to evaluate
LLM-generated summaries and facilitate safer integration of LLMs into
healthcare workflows.

摘要：隨著大型語言模型 (LLM) 整合到電子健康紀錄 (EHR) 工作流程中，驗證工具對於在實施前評估其效能至關重要。現有的提供者文件品質工具通常不適合 LLM 生成的文字複雜性，且缺乏對真實世界資料的驗證。提供者文件摘要品質工具 (PDSQI-9) 的開發目的是評估 LLM 生成的臨床摘要。使用多個 LLM（GPT-4o、Mixtral 8x7b 和 Llama 3-8b）從跨多個專科的真實世界 EHR 資料中產生多文件摘要。驗證包括實質效度的皮爾森相關係數、結構效度的因子分析和克朗巴赫 α 係數、概括性的評分者間信度（ICC 和克里彭多夫 α 係數）、內容效度的半德爾菲程序，以及用於判別效度的優質與劣質摘要比較。七位醫師評分者評估了 779 份摘要並回答了 8,329 個問題，評分者間信度達到 80% 以上。PDSQI-9 表現出強大的內部一致性（克朗巴赫 α 係數 = 0.879；95% CI：0.867-0.891）和高評分者間信度（ICC = 0.867；95% CI：0.867-0.868），支持結構效度和概括性。因子分析辨識出一個 4 因子模型，解釋了 58% 的變異，代表組織、清晰度、準確性和實用性。實質效度受到摘要長度與簡潔（rho = -0.200，p = 0.029）和組織（rho = -0.190，p = 0.037）分數之間相關性的支持。判別效度區分了優質和劣質摘要（p < 0.001）。PDSQI-9 表現出穩健的建構效度，支持在臨床實務中使用它來評估 LLM 生成的摘要，並促進 LLM 更安全的整合到醫療保健工作流程中。

##### **Learning to Extract Cross-Domain Aspects and Understanding Sentiments Using Large Language Models**
2501.08974v1 by Karukriti Kaushik Ghosh, Chiranjib Sur

Aspect-based sentiment analysis (ASBA) is a refined approach to sentiment
analysis that aims to extract and classify sentiments based on specific aspects
or features of a product, service, or entity. Unlike traditional sentiment
analysis, which assigns a general sentiment score to entire reviews or texts,
ABSA focuses on breaking down the text into individual components or aspects
(e.g., quality, price, service) and evaluating the sentiment towards each. This
allows for a more granular level of understanding of customer opinions,
enabling businesses to pinpoint specific areas of strength and improvement. The
process involves several key steps, including aspect extraction, sentiment
classification, and aspect-level sentiment aggregation for a review paragraph
or any other form that the users have provided. ABSA has significant
applications in areas such as product reviews, social media monitoring,
customer feedback analysis, and market research. By leveraging techniques from
natural language processing (NLP) and machine learning, ABSA facilitates the
extraction of valuable insights, enabling companies to make data-driven
decisions that enhance customer satisfaction and optimize offerings. As ABSA
evolves, it holds the potential to greatly improve personalized customer
experiences by providing a deeper understanding of sentiment across various
product aspects. In this work, we have analyzed the strength of LLMs for a
complete cross-domain aspect-based sentiment analysis with the aim of defining
the framework for certain products and using it for other similar situations.
We argue that it is possible to that at an effectiveness of 92\% accuracy for
the Aspect Based Sentiment Analysis dataset of SemEval-2015 Task 12.

摘要：基於面向方面的觀點分析 (ASBA) 是一種精緻的情感分析方法，旨在根據產品、服務或實體的特定面向或特徵來提取和分類觀點。與將一般觀點評分分配給整個評論或文字的傳統觀點分析不同，ABSA 專注於將文字分解為個別組成部分或面向（例如，品質、價格、服務），並評估對每個面向的觀點。這允許更細緻地了解客戶意見，使企業能夠精確找出優勢和改進領域。這個過程涉及幾個關鍵步驟，包括面向提取、觀點分類，以及評論段落或使用者提供的任何其他形式的觀點層級觀點彙總。ABSA 在產品評論、社群媒體監控、客戶回饋分析和市場研究等領域有重要的應用。透過利用自然語言處理 (NLP) 和機器學習的技術，ABSA 促進有價值見解的提取，讓公司能夠做出以數據為基礎的決策，以增強客戶滿意度並最佳化產品。隨著 ABSA 的演進，它有潛力透過提供對各種產品面向觀點的更深入了解，來大幅改善個人化的客戶體驗。在這項工作中，我們分析了 LLM 在完整的跨領域基於面向的觀點分析中的優勢，目的是定義特定產品的架構，並將其用於其他類似情況。我們論證，在 SemEval-2015 任務 12 的基於面向的觀點分析資料集上達到 92% 精確度的有效性是可能的。

##### **Trusted Machine Learning Models Unlock Private Inference for Problems Currently Infeasible with Cryptography**
2501.08970v1 by Ilia Shumailov, Daniel Ramage, Sarah Meiklejohn, Peter Kairouz, Florian Hartmann, Borja Balle, Eugene Bagdasarian

We often interact with untrusted parties. Prioritization of privacy can limit
the effectiveness of these interactions, as achieving certain goals
necessitates sharing private data. Traditionally, addressing this challenge has
involved either seeking trusted intermediaries or constructing cryptographic
protocols that restrict how much data is revealed, such as multi-party
computations or zero-knowledge proofs. While significant advances have been
made in scaling cryptographic approaches, they remain limited in terms of the
size and complexity of applications they can be used for. In this paper, we
argue that capable machine learning models can fulfill the role of a trusted
third party, thus enabling secure computations for applications that were
previously infeasible. In particular, we describe Trusted Capable Model
Environments (TCMEs) as an alternative approach for scaling secure computation,
where capable machine learning model(s) interact under input/output
constraints, with explicit information flow control and explicit statelessness.
This approach aims to achieve a balance between privacy and computational
efficiency, enabling private inference where classical cryptographic solutions
are currently infeasible. We describe a number of use cases that are enabled by
TCME, and show that even some simple classic cryptographic problems can already
be solved with TCME. Finally, we outline current limitations and discuss the
path forward in implementing them.

摘要：<paragraph>我們經常與不可信賴的對象互動。隱私優先考量可能會限制這些互動的成效，因為達成特定目標需要分享私人資料。傳統上，解決此挑戰的方法是尋求受信任的中介者或建構加密協定來限制揭露的資料量，例如多方運算或零知識證明。雖然加密方法的規模化已取得顯著進展，但在可使用的應用程式大小和複雜度方面仍然有限。在本文中，我們主張有能力的機器學習模型可以扮演受信任第三方角色，進而為以前不可行的應用程式啟用安全運算。特別是，我們將受信任有能力模型環境 (TCME) 描述為安全運算規模化的另一種方法，其中有能力的機器學習模型在輸入/輸出限制下互動，並具有明確的資訊流控制和明確的無狀態性。此方法旨在達成隱私和運算效率之間的平衡，在傳統加密解決方案目前不可行的情況下啟用私人推論。我們描述了 TCME 啟用的許多使用案例，並展示了即使是一些簡單的經典加密問題也可以藉由 TCME 解決。最後，我們概述了目前的限制，並討論了實作它們的未來道路。</paragraph>

##### **An analysis of data variation and bias in image-based dermatological datasets for machine learning classification**
2501.08962v1 by Francisco Mauro, Emanoel Thyago, Othon Vinicius, Rodrigo Abreu, Kelvin Cunha, José Gabriel, Rafael Barros, Thales Bezerra, Manoel Henriques, Natalia Lopes, Érico Moutinho, Jéssica Guido, Tsang Ing Ren, Paulo Borba

AI algorithms have become valuable in aiding professionals in healthcare. The
increasing confidence obtained by these models is helpful in critical decision
demands. In clinical dermatology, classification models can detect malignant
lesions on patients' skin using only RGB images as input. However, most
learning-based methods employ data acquired from dermoscopic datasets on
training, which are large and validated by a gold standard. Clinical models aim
to deal with classification on users' smartphone cameras that do not contain
the corresponding resolution provided by dermoscopy. Also, clinical
applications bring new challenges. It can contain captures from uncontrolled
environments, skin tone variations, viewpoint changes, noises in data and
labels, and unbalanced classes. A possible alternative would be to use transfer
learning to deal with the clinical images. However, as the number of samples is
low, it can cause degradations on the model's performance; the source
distribution used in training differs from the test set. This work aims to
evaluate the gap between dermoscopic and clinical samples and understand how
the dataset variations impact training. It assesses the main differences
between distributions that disturb the model's prediction. Finally, from
experiments on different architectures, we argue how to combine the data from
divergent distributions, decreasing the impact on the model's final accuracy.

摘要：AI 演算法已成為協助醫療保健專業人員的寶貴工具。這些模型獲得的信心日益提升，有助於關鍵決策需求。在臨床皮膚科，分類模型僅使用 RGB 影像作為輸入，即可偵測患者皮膚上的惡性病灶。然而，大多數基於學習的方法採用從皮膚鏡資料集取得的資料進行訓練，這些資料集龐大且已通過金標準驗證。臨床模型旨在處理使用者智慧型手機相機上的分類，這些相機不包含皮膚鏡提供的對應解析度。此外，臨床應用程式帶來新的挑戰。它可能包含來自不受控環境的擷取、膚色變化、視點變更、資料和標籤中的雜訊，以及不平衡的類別。一種可能的替代方案是使用遷移學習來處理臨床影像。然而，由於樣本數量少，可能會導致模型效能下降；訓練中使用的來源分佈與測試集不同。這項工作旨在評估皮膚鏡和臨床樣本之間的差距，並了解資料集變化如何影響訓練。它評估會干擾模型預測的主要分佈差異。最後，從不同架構的實驗中，我們論證如何結合來自不同分佈的資料，降低對模型最終準確度的影響。

##### **Kolmogorov-Arnold Networks for Time Series Granger Causality Inference**
2501.08958v1 by Meiliang Liu, Yunfang Xu, Zijin Li, Zhengye Si, Xiaoxiao Yang, Xinyue Yang, Zhiwen Zhao

We introduce Granger Causality Kolmogorov-Arnold Networks (GCKAN), an
innovative architecture that extends the recently proposed Kolmogorov-Arnold
Networks (KAN) to the domain of causal inference. By extracting base weights
from KAN layers and incorporating the sparsity-inducing penalty along with
ridge regularization, GCKAN infers the Granger causality from time series while
enabling automatic time lag selection. Additionally, we propose an algorithm
leveraging time-reversed Granger causality to enhance inference accuracy. The
algorithm compares prediction and sparse-inducing losses derived from the
original and time-reversed series, automatically selecting the casual
relationship with the higher score or integrating the results to mitigate
spurious connectivities. Comprehensive experiments conducted on Lorenz-96, gene
regulatory networks, fMRI BOLD signals, and VAR datasets demonstrate that the
proposed model achieves competitive performance to state-of-the-art methods in
inferring Granger causality from nonlinear, high-dimensional, and
limited-sample time series.

摘要：我們介紹 Granger 因果關係 Kolmogorov-Arnold 網路 (GCKAN)，這是一種創新的架構，將最近提出的 Kolmogorov-Arnold 網路 (KAN) 延伸到因果推論的領域。透過從 KAN 層中提取基礎權重並結合稀疏性誘導懲罰以及嶺回歸，GCKAN 從時間序列中推斷 Granger 因果關係，同時啟用自動時間滯後選擇。此外，我們提出一個演算法，利用時間反轉 Granger 因果關係來增強推論準確性。該演算法比較從原始時間序列和時間反轉時間序列中衍生的預測和稀疏性誘導損失，自動選擇具有較高分數的因果關係或整合結果以減輕虛假連通性。在 Lorenz-96、基因調控網路、fMRI BOLD 訊號和 VAR 資料集上進行的全面實驗證明，所提出的模型在從非線性、高維和有限樣本時間序列中推斷 Granger 因果關係方面，可達到與最先進方法相媲美的效能。

##### **Analyzing the Ethical Logic of Six Large Language Models**
2501.08951v1 by W. Russell Neuman, Chad Coleman, Manan Shah

This study examines the ethical reasoning of six prominent generative large
language models: OpenAI GPT-4o, Meta LLaMA 3.1, Perplexity, Anthropic Claude
3.5 Sonnet, Google Gemini, and Mistral 7B. The research explores how these
models articulate and apply ethical logic, particularly in response to moral
dilemmas such as the Trolley Problem, and Heinz Dilemma. Departing from
traditional alignment studies, the study adopts an explainability-transparency
framework, prompting models to explain their ethical reasoning. This approach
is analyzed through three established ethical typologies: the
consequentialist-deontological analytic, Moral Foundations Theory, and the
Kohlberg Stages of Moral Development Model. Findings reveal that LLMs exhibit
largely convergent ethical logic, marked by a rationalist, consequentialist
emphasis, with decisions often prioritizing harm minimization and fairness.
Despite similarities in pre-training and model architecture, a mixture of
nuanced and significant differences in ethical reasoning emerge across models,
reflecting variations in fine-tuning and post-training processes. The models
consistently display erudition, caution, and self-awareness, presenting ethical
reasoning akin to a graduate-level discourse in moral philosophy. In striking
uniformity these systems all describe their ethical reasoning as more
sophisticated than what is characteristic of typical human moral logic.

摘要：這項研究探討了六種著名的生成式大型語言模型的倫理推理：OpenAI GPT-4o、Meta LLaMA 3.1、Perplexity、Anthropic Claude 3.5 Sonnet、Google Gemini 和 Mistral 7B。該研究探討了這些模型如何闡述和應用倫理邏輯，特別是在回應道德兩難問題，例如電車難題和海因茨兩難問題時。該研究跳脫傳統的對齊研究，採用可解釋性透明度架構，促使模型解釋其倫理推理。此方法透過三種既定的倫理類型學進行分析：後果論 - 義務論分析、道德基礎理論和科爾伯格道德發展階段模型。研究結果顯示，LLM 表現出高度一致的倫理邏輯，特徵在於理性主義、後果論的強調，決策通常優先考慮最小化傷害和公平性。儘管預訓練和模型架構相似，但不同模型之間出現了細微且顯著的倫理推理差異，反映了微調和後訓練過程的差異。這些模型始終表現出博學、謹慎和自我意識，呈現出類似於道德哲學研究生層級論述的倫理推理。這些系統驚人地一致地描述它們的倫理推理比典型人類道德邏輯的特性更為複雜。

##### **Applying General Turn-taking Models to Conversational Human-Robot Interaction**
2501.08946v1 by Gabriel Skantze, Bahar Irfan

Turn-taking is a fundamental aspect of conversation, but current Human-Robot
Interaction (HRI) systems often rely on simplistic, silence-based models,
leading to unnatural pauses and interruptions. This paper investigates, for the
first time, the application of general turn-taking models, specifically TurnGPT
and Voice Activity Projection (VAP), to improve conversational dynamics in HRI.
These models are trained on human-human dialogue data using self-supervised
learning objectives, without requiring domain-specific fine-tuning. We propose
methods for using these models in tandem to predict when a robot should begin
preparing responses, take turns, and handle potential interruptions. We
evaluated the proposed system in a within-subject study against a traditional
baseline system, using the Furhat robot with 39 adults in a conversational
setting, in combination with a large language model for autonomous response
generation. The results show that participants significantly prefer the
proposed system, and it significantly reduces response delays and
interruptions.

摘要：輪流發言是對話的基本面向，但當前的機器人人類互動 (HRI) 系統經常依賴於簡化的、基於沉默的模型，導致不自然的停頓和中斷。本文首次探討將一般的輪流發言模型，特別是 TurnGPT 和語音活動預測 (VAP)，應用於改善 HRI 中的對話動態。這些模型使用自我監督的學習目標在人與人的對話資料上進行訓練，而不需要特定於領域的微調。我們提出使用這些模型串聯的方法，以預測機器人應該何時開始準備回應、輪流發言以及處理潛在的中斷。我們在一個主題內研究中評估了所提出的系統，並針對傳統的基準系統，使用 Furhat 機器人和 39 位成人進行對話設定，並結合大型語言模型進行自主回應產生。結果顯示，參與者顯著偏好所提出的系統，並且它顯著減少了回應延遲和中斷。

##### **Visual WetlandBirds Dataset: Bird Species Identification and Behavior Recognition in Videos**
2501.08931v1 by Javier Rodriguez-Juan, David Ortiz-Perez, Manuel Benavent-Lledo, David Mulero-Pérez, Pablo Ruiz-Ponce, Adrian Orihuela-Torres, Jose Garcia-Rodriguez, Esther Sebastián-González

The current biodiversity loss crisis makes animal monitoring a relevant field
of study. In light of this, data collected through monitoring can provide
essential insights, and information for decision-making aimed at preserving
global biodiversity. Despite the importance of such data, there is a notable
scarcity of datasets featuring videos of birds, and none of the existing
datasets offer detailed annotations of bird behaviors in video format. In
response to this gap, our study introduces the first fine-grained video dataset
specifically designed for bird behavior detection and species classification.
This dataset addresses the need for comprehensive bird video datasets and
provides detailed data on bird actions, facilitating the development of deep
learning models to recognize these, similar to the advancements made in human
action recognition. The proposed dataset comprises 178 videos recorded in
Spanish wetlands, capturing 13 different bird species performing 7 distinct
behavior classes. In addition, we also present baseline results using state of
the art models on two tasks: bird behavior recognition and species
classification.

摘要：當前生物多樣性喪失危機使得動物監控成為一個相關的研究領域。有鑑於此，透過監控收集的資料可以提供必要的見解，以及用於決策制定以保護全球生物多樣性的資訊。儘管此類資料很重要，但其中缺少鳥類影片的資料集，而且現有的資料集都沒有提供影片格式的鳥類行為詳細註解。為了回應這個差距，我們的研究引入了第一個細緻的影片資料集，專門設計用於鳥類行為偵測和物種分類。此資料集解決了對全面鳥類影片資料集的需求，並提供關於鳥類動作的詳細資料，促進開發深度學習模型來識別這些動作，類似於人類動作識別方面取得的進展。建議的資料集包含 178 部在西班牙濕地錄製的影片，捕捉到 13 種不同的鳥類執行 7 種不同的行為類別。此外，我們還使用最先進的模型在兩個任務上呈現基準結果：鳥類行為識別和物種分類。

##### **Disentangling Exploration of Large Language Models by Optimal Exploitation**
2501.08925v1 by Tim Grams, Patrick Betz, Christian Bartelt

Exploration is a crucial skill for self-improvement and open-ended
problem-solving. However, it remains uncertain whether large language models
can effectively explore the state-space. Existing evaluations predominantly
focus on the trade-off between exploration and exploitation, often assessed in
multi-armed bandit problems. In contrast, this work isolates exploration as the
sole objective, tasking the agent with delivering information that enhances
future returns. For the evaluation, we propose to decompose missing rewards
into exploration and exploitation components by measuring the optimal
achievable return for the states already explored. Our experiments with various
LLMs reveal that most models struggle to sufficiently explore the state-space
and that weak exploration is insufficient. We observe a positive correlation
between model size and exploration performance, with larger models
demonstrating superior capabilities. Furthermore, we show that our
decomposition provides insights into differences in behaviors driven by agent
instructions during prompt engineering, offering a valuable tool for refining
LLM performance in exploratory tasks.

摘要：探索是自我提升和開放式問題解決的關鍵技能。然而，大型語言模型是否能有效探索狀態空間仍不確定。現有的評估主要關注探索和利用之間的權衡，通常在多臂賭徒問題中進行評估。相反，這項工作將探索孤立為唯一目標，賦予代理人提供增強未來回報的資訊的任務。對於評估，我們建議將遺失的獎勵分解為探索和利用組成，方法是測量已探索狀態的可實現最佳回報。我們對各種 LLM 的實驗表明，大多數模型難以充分探索狀態空間，並且探索不足。我們觀察到模型大小和探索性能之間存在正相關，較大的模型表現出更強的能力。此外，我們表明我們的分解提供了對提示工程過程中代理指令驅動的行為差異的見解，為改進探索性任務中的 LLM 性能提供了一個有價值的工具。

##### **Modeling Melt Pool Features and Spatter Using Symbolic Regression and Machine Learning**
2501.08922v1 by Olabode T. Ajenifujah, Amir Barati Farimani

Additive manufacturing (AM) is a rapidly evolving technology that has
attracted applications across a wide range of fields due to its ability to
fabricate complex geometries. However, one of the key challenges in AM is
achieving consistent print quality. This inconsistency is often attributed to
uncontrolled melt pool dynamics, partly caused by spatter which can lead to
defects. Therefore, capturing and controlling the evolution of the melt pool is
crucial for enhancing process stability and part quality. In this study, we
developed a framework to support decision-making in AM operations, facilitating
quality control and minimizing defects via machine learning (ML) and polynomial
symbolic regression models. We implemented experimentally validated
computational tools as a cost-effective approach to collect large datasets from
laser powder bed fusion (LPBF) processes. For a dataset consisting of 281
process conditions, parameters such as melt pool dimensions (length, width,
depth), melt pool geometry (area, volume), and volume indicated as spatter were
extracted. Using machine learning (ML) and polynomial symbolic regression
models, a high R2 of over 95 % was achieved in predicting the melt pool
dimensions and geometry features for both the training and testing datasets,
with either process conditions (power and velocity) or melt pool dimensions as
the model inputs. In the case of volume indicated as spatter, R2 improved after
logarithmic transforming the model inputs, which was either the process
conditions or the melt pool dimensions. Among the investigated ML models, the
ExtraTree model achieved the highest R2 values of 96.7 % and 87.5 %.

摘要：增材製造 (AM) 是一項快速發展的技術，由於其製造複雜幾何形狀的能力，在廣泛的領域中備受關注。然而，AM 的主要挑戰之一是實現一致的列印品質。這種不一致性通常歸因於熔池動力學不受控，部分原因是飛濺可能導致缺陷。因此，捕捉和控制熔池的演變對於提高製程穩定性和零件品質至關重要。在本研究中，我們開發了一個架構來支援 AM 作業中的決策制定，透過機器學習 (ML) 和多項式符號回歸模型，促進品質控管並將缺陷降至最低。我們實作了經過實驗驗證的計算工具，作為一種具成本效益的方法，從雷射粉末床熔合 (LPBF) 製程中收集大型資料集。對於由 281 個製程條件組成的資料集，萃取了熔池尺寸（長度、寬度、深度）、熔池幾何形狀（面積、體積）和標示為飛濺的體積等參數。使用機器學習 (ML) 和多項式符號回歸模型，在訓練和測試資料集中預測熔池尺寸和幾何特徵時，達到了超過 95% 的高 R2，模型輸入為製程條件（功率和速度）或熔池尺寸。在標示為飛濺的體積情況下，在對模型輸入（製程條件或熔池尺寸）進行對數轉換後，R2 有所提升。在所調查的 ML 模型中，ExtraTree 模型達到了最高的 R2 值，分別為 96.7% 和 87.5%。

##### **GenAI Content Detection Task 3: Cross-Domain Machine-Generated Text Detection Challenge**
2501.08913v1 by Liam Dugan, Andrew Zhu, Firoj Alam, Preslav Nakov, Marianna Apidianaki, Chris Callison-Burch

Recently there have been many shared tasks targeting the detection of
generated text from Large Language Models (LLMs). However, these shared tasks
tend to focus either on cases where text is limited to one particular domain or
cases where text can be from many domains, some of which may not be seen during
test time. In this shared task, using the newly released RAID benchmark, we aim
to answer whether or not models can detect generated text from a large, yet
fixed, number of domains and LLMs, all of which are seen during training. Over
the course of three months, our task was attempted by 9 teams with 23 detector
submissions. We find that multiple participants were able to obtain accuracies
of over 99% on machine-generated text from RAID while maintaining a 5% False
Positive Rate -- suggesting that detectors are able to robustly detect text
from many domains and models simultaneously. We discuss potential
interpretations of this result and provide directions for future research.

摘要：<paragraph>最近有許多共用任務針對大型語言模型 (LLM) 生成的文字偵測。然而，這些共用任務傾向於專注於文字僅限於特定領域的案例，或文字可能來自許多領域的案例，其中一些領域在測試期間可能看不到。在這個共用任務中，使用新發布的 RAID 基準，我們的目標是回答模型是否可以從大量但固定的領域和 LLM 中偵測生成的文字，所有這些在訓練期間都可以看到。在三個月內，我們的任務由 9 個團隊嘗試，提交了 23 個偵測器。我們發現，多位參與者能夠在 RAID 的機器生成的文字中獲得超過 99% 的準確度，同時保持 5% 的誤報率——這表明偵測器能夠穩健地同時偵測來自許多領域和模型的文字。我們討論了這個結果的潛在解釋，並為未來的研究提供方向。</paragraph>

##### **Leveraging Large Language Models as Knowledge-Driven Agents for Reliable Retrosynthesis Planning**
2501.08897v1 by Qinyu Ma, Yuhao Zhou, Jianfeng Li

Identifying reliable synthesis pathways in materials chemistry is a complex
task, particularly in polymer science, due to the intricate and often
non-unique nomenclature of macromolecules. To address this challenge, we
propose an agent system that integrates large language models (LLMs) and
knowledge graphs (KGs). By leveraging LLMs' powerful capabilities for
extracting and recognizing chemical substance names, and storing the extracted
data in a structured knowledge graph, our system fully automates the retrieval
of relevant literatures, extraction of reaction data, database querying,
construction of retrosynthetic pathway trees, further expansion through the
retrieval of additional literature and recommendation of optimal reaction
pathways. A novel Multi-branched Reaction Pathway Search (MBRPS) algorithm
enables the exploration of all pathways, with a particular focus on
multi-branched ones, helping LLMs overcome weak reasoning in multi-branched
paths. This work represents the first attempt to develop a fully automated
retrosynthesis planning agent tailored specially for macromolecules powered by
LLMs. Applied to polyimide synthesis, our new approach constructs a
retrosynthetic pathway tree with hundreds of pathways and recommends optimized
routes, including both known and novel pathways, demonstrating its
effectiveness and potential for broader applications.

摘要：辨識材料化學中可靠的合成路徑是一項複雜的任務，特別是在聚合物科學中，因為巨分子的命名法錯綜複雜且經常不唯一。為了應對這個挑戰，我們提出一個整合大型語言模型 (LLM) 與知識圖譜 (KG) 的代理系統。透過利用 LLM 強大的化學物質名稱萃取和辨識能力，並將萃取的資料儲存在結構化的知識圖譜中，我們的系統可完全自動化相關文獻的檢索、反應資料的萃取、資料庫查詢、逆合成路徑樹的建構、透過檢索額外文獻進一步擴充，以及最佳反應路徑的建議。一種新穎的多分支反應路徑搜尋 (MBRPS) 演算法能探索所有路徑，特別專注於多分支路徑，協助 LLM 克服多分支路徑中的弱推理。這項工作代表首次嘗試開發一種完全自動化的逆合成規劃代理，專門針對由 LLM 驅動的巨分子量身打造。應用於聚醯亞胺合成，我們的新方法建構了一個包含數百條路徑的逆合成路徑樹，並建議最佳化路徑，包括已知和新穎的路徑，證明其在更廣泛應用中的效能和潛力。

##### **Incrementally Learning Multiple Diverse Data Domains via Multi-Source Dynamic Expansion Model**
2501.08878v1 by Runqing Wu, Fei Ye, Qihe Liu, Guoxi Huang, Jinyu Guo, Rongyao Hu

Continual Learning seeks to develop a model capable of incrementally
assimilating new information while retaining prior knowledge. However, current
research predominantly addresses a straightforward learning context, wherein
all data samples originate from a singular data domain. This paper shifts focus
to a more complex and realistic learning environment, characterized by data
samples sourced from multiple distinct domains. We tackle this intricate
learning challenge by introducing a novel methodology, termed the Multi-Source
Dynamic Expansion Model (MSDEM), which leverages various pre-trained models as
backbones and progressively establishes new experts based on them to adapt to
emerging tasks. Additionally, we propose an innovative dynamic expandable
attention mechanism designed to selectively harness knowledge from multiple
backbones, thereby accelerating the new task learning. Moreover, we introduce a
dynamic graph weight router that strategically reuses all previously acquired
parameters and representations for new task learning, maximizing the positive
knowledge transfer effect, which further improves generalization performance.
We conduct a comprehensive series of experiments, and the empirical findings
indicate that our proposed approach achieves state-of-the-art performance.

摘要：持續學習旨在開發一種模型，能夠逐步吸收新資訊，同時保留先前的知識。然而，目前的研究主要針對直接的學習環境，其中所有資料範例都來自單一資料網域。本文將重點轉移到更複雜且更真實的學習環境，其特點是資料範例來自多個不同網域。我們透過引入一種新方法來應對這個複雜的學習挑戰，稱為多來源動態擴充模型 (MSDEM)，它利用各種預先訓練的模型作為主幹，並根據這些模型逐步建立新的專家以適應新興任務。此外，我們提出了一種創新的動態可擴充注意力機制，旨在有選擇地利用來自多個主幹的知識，從而加速新任務的學習。此外，我們引入了一個動態圖形權重路由器，可策略性地重複使用所有先前獲得的參數和表示，以進行新的任務學習，最大化正向知識傳遞效果，進一步提升泛化效能。我們進行了一系列全面的實驗，而經驗發現表明我們提出的方法達到了最先進的效能。

##### **Silent Abandonment in Text-Based Contact Centers: Identifying, Quantifying, and Mitigating its Operational Impacts**
2501.08869v1 by Antonio Castellanos, Galit B. Yom-Tov, Yair Goldberg, Jaeyoung Park

In the quest to improve services, companies offer customers the option to
interact with agents via texting. Such contact centers face unique challenges
compared to traditional call centers, as measuring customer experience proxies
like abandonment and patience involves uncertainty. A key source of this
uncertainty is silent abandonment, where customers leave without notifying the
system, wasting agent time and leaving their status unclear. Silent abandonment
also obscures whether a customer was served or left. Our goals are to measure
the magnitude of silent abandonment and mitigate its effects. Classification
models show that 3%-70% of customers across 17 companies abandon silently. In
one study, 71.3% of abandoning customers did so silently, reducing agent
efficiency by 3.2% and system capacity by 15.3%, incurring $5,457 in annual
costs per agent. We develop an expectation-maximization (EM) algorithm to
estimate customer patience under uncertainty and identify influencing
covariates. We find that companies should use classification models to estimate
abandonment scope and our EM algorithm to assess patience. We suggest
strategies to operationally mitigate the impact of silent abandonment by
predicting suspected silent-abandonment behavior or changing service design.
Specifically, we show that while allowing customers to write while waiting in
the queue creates a missing data challenge, it also significantly increases
patience and reduces service time, leading to reduced abandonment and lower
staffing requirements.

摘要：<paragraph>為了改善服務，公司提供客戶透過簡訊與客服人員互動的選項。此類聯繫中心面臨的挑戰與傳統呼叫中心不同，因為衡量客戶體驗代理，例如放棄和耐心，涉及不確定性。造成這種不確定性的關鍵來源是靜默放棄，客戶在未通知系統的情況下離開，浪費客服人員時間並讓他們的狀態不明確。靜默放棄也模糊了客戶是獲得服務還是離開。我們的目標是衡量靜默放棄的規模並減輕其影響。分類模型顯示，17 家公司的 3%-70% 的客戶會靜默放棄。在一項研究中，71.3% 放棄的客戶是靜默放棄，導致客服人員效率降低 3.2%，系統容量降低 15.3%，每年每位客服人員產生 5,457 美元的成本。我們開發了一個期望最大化 (EM) 演算法，在不確定性下估計客戶耐心並找出影響協變數。我們發現，公司應使用分類模型估計放棄範圍，並使用我們的 EM 演算法評估耐心。我們建議透過預測疑似靜默放棄行為或變更服務設計，在營運上減輕靜默放棄的影響。具體來說，我們表明，雖然允許客戶在排隊時寫訊息會造成遺失資料的挑戰，但它也會顯著提高耐心並減少服務時間，從而減少放棄並降低人員需求。</paragraph>

##### **ARMOR: Shielding Unlearnable Examples against Data Augmentation**
2501.08862v1 by Xueluan Gong, Yuji Wang, Yanjiao Chen, Haocheng Dong, Yiming Li, Mengyuan Sun, Shuaike Li, Qian Wang, Chen Chen

Private data, when published online, may be collected by unauthorized parties
to train deep neural networks (DNNs). To protect privacy, defensive noises can
be added to original samples to degrade their learnability by DNNs. Recently,
unlearnable examples are proposed to minimize the training loss such that the
model learns almost nothing. However, raw data are often pre-processed before
being used for training, which may restore the private information of protected
data. In this paper, we reveal the data privacy violation induced by data
augmentation, a commonly used data pre-processing technique to improve model
generalization capability, which is the first of its kind as far as we are
concerned. We demonstrate that data augmentation can significantly raise the
accuracy of the model trained on unlearnable examples from 21.3% to 66.1%. To
address this issue, we propose a defense framework, dubbed ARMOR, to protect
data privacy from potential breaches of data augmentation. To overcome the
difficulty of having no access to the model training process, we design a
non-local module-assisted surrogate model that better captures the effect of
data augmentation. In addition, we design a surrogate augmentation selection
strategy that maximizes distribution alignment between augmented and
non-augmented samples, to choose the optimal augmentation strategy for each
class. We also use a dynamic step size adjustment algorithm to enhance the
defensive noise generation process. Extensive experiments are conducted on 4
datasets and 5 data augmentation methods to verify the performance of ARMOR.
Comparisons with 6 state-of-the-art defense methods have demonstrated that
ARMOR can preserve the unlearnability of protected private data under data
augmentation. ARMOR reduces the test accuracy of the model trained on augmented
protected samples by as much as 60% more than baselines.

摘要：<paragraph>當私人資料在網路上公開時，可能會被未經授權的第三方收集，用於訓練深度神經網路 (DNN)。為了保護隱私，可以將防禦性雜訊加入原始樣本中，以降低 DNN 的可學習性。最近，不可學習的範例被提出，用於最小化訓練損失，使模型幾乎學不到任何東西。然而，原始資料在用於訓練之前通常會經過預處理，這可能會還原受保護資料的私人資訊。在本文中，我們揭露了資料擴充所引發的資料隱私侵害，資料擴充是一種常用的資料預處理技術，用於提升模型概化能力，就我們所知，這是同類技術中的第一個。我們證明了資料擴充可以顯著提高在不可學習的範例上訓練的模型的準確度，從 21.3% 提升到 66.1%。為了解決這個問題，我們提出了一個名為 ARMOR 的防禦架構，以保護資料隱私免於資料擴充的潛在侵害。為了克服無法存取模型訓練過程的困難，我們設計了一個非局部模組輔助代理模型，以更好地捕捉資料擴充的效果。此外，我們設計了一個代理擴充選擇策略，以最大化擴充和未擴充樣本之間的分布對齊，為每個類別選擇最佳的擴充策略。我們還使用動態步長調整演算法來增強防禦性雜訊生成過程。在 4 個資料集和 5 個資料擴充方法上進行了廣泛的實驗，以驗證 ARMOR 的效能。與 6 種最先進的防禦方法的比較結果表明，ARMOR 可以保留受保護私人資料在資料擴充下的不可學習性。與基線相比，ARMOR 將在擴充的受保護樣本上訓練的模型的測試準確度降低了多達 60%。</paragraph>

##### **Digital Phenotyping for Adolescent Mental Health: A Feasibility Study Employing Machine Learning to Predict Mental Health Risk From Active and Passive Smartphone Data**
2501.08851v1 by Balasundaram Kadirvelu, Teresa Bellido Bel, Aglaia Freccero, Martina Di Simplicio, Dasha Nicholls, A Aldo Faisal

Background: Adolescents are particularly vulnerable to mental disorders, with
over 75% of cases manifesting before the age of 25. Research indicates that
only 18 to 34% of young people experiencing high levels of depression or
anxiety symptoms seek support. Digital tools leveraging smartphones offer
scalable and early intervention opportunities. Objective: Using a novel machine
learning framework, this study evaluated the feasibility of integrating active
and passive smartphone data to predict mental disorders in non-clinical
adolescents. Specifically, we investigated the utility of the Mindcraft app in
predicting risks for internalising and externalising disorders, eating
disorders, insomnia and suicidal ideation. Methods: Participants (N=103; mean
age 16.1 years) were recruited from three London schools. Participants
completed the Strengths and Difficulties Questionnaire, the Eating Disorders-15
Questionnaire, Sleep Condition Indicator Questionnaire and indicated the
presence/absence of suicidal ideation. They used the Mindcraft app for 14 days,
contributing active data via self-reports and passive data from smartphone
sensors. A contrastive pretraining phase was applied to enhance user-specific
feature stability, followed by supervised fine-tuning. The model evaluation
employed leave-one-subject-out cross-validation using balanced accuracy as the
primary metric. Results: The integration of active and passive data achieved
superior performance compared to individual data sources, with mean balanced
accuracies of 0.71 for SDQ-High risk, 0.67 for insomnia, 0.77 for suicidal
ideation and 0.70 for eating disorders. The contrastive learning framework
stabilised daily behavioural representations, enhancing predictive robustness.
This study demonstrates the potential of integrating active and passive
smartphone data with advanced machine-learning techniques for predicting mental
health risks.

摘要：<paragraph>背景：青少年特别容易罹患精神疾病，75% 以上的病例在 25 岁之前显现。研究表明，只有 18% 到 34% 经历高度抑郁或焦虑症状的年轻人寻求支持。利用智能手机的数位工具提供可扩展的早期介入机会。目标：本研究使用新颖的机器学习框架，评估将主动和被动智能手机数据整合来预测非临床青少年精神疾病的可行性。具体来说，我们调查了 Mindcraft 应用程序在预测内化和外化障碍、饮食失调、失眠和自杀意念方面的效用。方法：参与者（N=103；平均年龄 16.1 岁）来自伦敦的三所学校。参与者完成了优势和困难问卷、进食障碍-15 问卷、睡眠状况指标问卷，并指出了是否存在自杀意念。他们使用 Mindcraft 应用程序 14 天，通过自我报告提供主动数据，并从智能手机传感器提供被动数据。应用对比预训练阶段来增强特定用户的特征稳定性，然后进行监督微调。模型评估采用留一法交叉验证，使用平衡准确度作为主要指标。结果：与个别数据源相比，主动和被动数据的整合实现了更好的性能，SDQ 高风险的平均平衡准确度为 0.71，失眠为 0.67，自杀意念为 0.77，饮食失调为 0.70。对比学习框架稳定了每日行为表征，增强了预测鲁棒性。本研究展示了将主动和被动智能手机数据与先进机器学习技术相结合以预测心理健康风险的潜力。</paragraph>

##### **Graph Counterfactual Explainable AI via Latent Space Traversal**
2501.08850v1 by Andreas Abildtrup Hansen, Paraskevas Pegios, Anna Calissano, Aasa Feragen

Explaining the predictions of a deep neural network is a nontrivial task, yet
high-quality explanations for predictions are often a prerequisite for
practitioners to trust these models. Counterfactual explanations aim to explain
predictions by finding the ''nearest'' in-distribution alternative input whose
prediction changes in a pre-specified way. However, it remains an open question
how to define this nearest alternative input, whose solution depends on both
the domain (e.g. images, graphs, tabular data, etc.) and the specific
application considered. For graphs, this problem is complicated i) by their
discrete nature, as opposed to the continuous nature of state-of-the-art graph
classifiers; and ii) by the node permutation group acting on the graphs. We
propose a method to generate counterfactual explanations for any differentiable
black-box graph classifier, utilizing a case-specific permutation equivariant
graph variational autoencoder. We generate counterfactual explanations in a
continuous fashion by traversing the latent space of the autoencoder across the
classification boundary of the classifier, allowing for seamless integration of
discrete graph structure and continuous graph attributes. We empirically
validate the approach on three graph datasets, showing that our model is
consistently high-performing and more robust than the baselines.

摘要：解釋深度神經網路的預測並非易事，但高品質的預測解釋通常是實務人員信賴這些模型的先決條件。反事實解釋旨在透過尋找預測以預先指定方式改變的「最近」同分佈替代輸入，來解釋預測。然而，如何定義這個最近的替代輸入仍然是一個開放問題，其解決方案取決於領域（例如影像、圖表、表格資料等）和所考慮的特定應用程式。對於圖表而言，這個問題的複雜性在於：i）與最先進圖表分類器的連續性質相反，圖表的離散性質；以及 ii）作用於圖表的節點置換群。我們提出一個方法，利用特定案例置換等變圖表變異自動編碼器，為任何可微分的黑盒圖表分類器產生反事實解釋。我們透過在分類器分類邊界上穿越自動編碼器的潛在空間，以連續的方式產生反事實解釋，允許離散圖表結構和連續圖表屬性的無縫整合。我們在三個圖表資料集上實證驗證了此方法，顯示我們的模型效能始終很高，且比基線更強健。

##### **RouteNet-Gauss: Hardware-Enhanced Network Modeling with Machine Learning**
2501.08848v1 by Carlos Güemes-Palau, Miquel Ferriol-Galmés, Jordi Paillisse-Vilanova, Albert López-Brescó, Pere Barlet-Ros, Albert Cabellos-Aparicio

Network simulation is pivotal in network modeling, assisting with tasks
ranging from capacity planning to performance estimation. Traditional
approaches such as Discrete Event Simulation (DES) face limitations in terms of
computational cost and accuracy. This paper introduces RouteNet-Gauss, a novel
integration of a testbed network with a Machine Learning (ML) model to address
these challenges. By using the testbed as a hardware accelerator,
RouteNet-Gauss generates training datasets rapidly and simulates network
scenarios with high fidelity to real-world conditions. Experimental results
show that RouteNet-Gauss significantly reduces prediction errors by up to 95%
and achieves a 488x speedup in inference time compared to state-of-the-art
DES-based methods. RouteNet-Gauss's modular architecture is dynamically
constructed based on the specific characteristics of the network scenario, such
as topology and routing. This enables it to understand and generalize to
different network configurations beyond those seen during training, including
networks up to 10x larger. Additionally, it supports Temporal Aggregated
Performance Estimation (TAPE), providing configurable temporal granularity and
maintaining high accuracy in flow performance metrics. This approach shows
promise in improving both simulation efficiency and accuracy, offering a
valuable tool for network operators.

摘要：網路模擬在網路建模中至關重要，協助執行從容量規劃到效能估計的任務。傳統方法（例如離散事件模擬 (DES)）在運算成本和準確性方面面臨限制。本文介紹 RouteNet-Gauss，一種測試網路與機器學習 (ML) 模型的創新整合，以解決這些挑戰。透過使用測試網路作為硬體加速器，RouteNet-Gauss 能快速產生訓練資料集，並模擬與真實世界條件高度吻合的網路場景。實驗結果顯示，RouteNet-Gauss 將預測誤差顯著降低達 95%，並且與最先進的基於 DES 的方法相比，推理時間加快了 488 倍。RouteNet-Gauss 的模組化架構是根據網路場景的特定特性動態建構的，例如拓撲和路由。這使其能夠理解並概括到訓練期間未見的不同網路組態，包括大至 10 倍的網路。此外，它支援時間聚合效能估計 (TAPE)，提供可設定的時間粒度，並在流量效能指標中維持高準確度。這種方法顯示出在改善模擬效率和準確度方面很有前景，為網路營運商提供了一個有價值的工具。

##### **Exploring Task-Level Optimal Prompts for Visual In-Context Learning**
2501.08841v1 by Yan Zhu, Huan Ma, Changqing Zhang

With the development of Vision Foundation Models (VFMs) in recent years,
Visual In-Context Learning (VICL) has become a better choice compared to
modifying models in most scenarios. Different from retraining or fine-tuning
model, VICL does not require modifications to the model's weights or
architecture, and only needs a prompt with demonstrations to teach VFM how to
solve tasks. Currently, significant computational cost for finding optimal
prompts for every test sample hinders the deployment of VICL, as determining
which demonstrations to use for constructing prompts is very costly. In this
paper, however, we find a counterintuitive phenomenon that most test samples
actually achieve optimal performance under the same prompts, and searching for
sample-level prompts only costs more time but results in completely identical
prompts. Therefore, we propose task-level prompting to reduce the cost of
searching for prompts during the inference stage and introduce two time-saving
yet effective task-level prompt search strategies. Extensive experimental
results show that our proposed method can identify near-optimal prompts and
reach the best VICL performance with a minimal cost that prior work has never
achieved.

摘要：隨著近年來 Vision Foundation Models (VFMs) 的發展，與其在多數情況下修改模型，視覺情境學習 (VICL) 已成為更好的選擇。VICL 與重新訓練或微調模型不同，它不需要修改模型的權重或架構，只需要一個帶有示範的提示來教導 VFM 如何解決任務。目前，為每個測試樣本尋找最佳提示的顯著運算成本阻礙了 VICL 的部署，因為決定用於建構提示的示範代價很高。然而，在本文中，我們發現了一個反直覺的現象，即大多數測試樣本實際上在相同的提示下都能達到最佳效能，而且只搜尋樣本層級的提示只會花費更多時間，但會產生完全相同的提示。因此，我們提出任務層級提示，以降低在推論階段搜尋提示的成本，並引入兩種省時且有效的任務層級提示搜尋策略。廣泛的實驗結果顯示，我們提出的方法可以識別接近最佳的提示，並以先前工作從未達成的最小成本達到最佳 VICL 效能。

##### **ToMATO: Verbalizing the Mental States of Role-Playing LLMs for Benchmarking Theory of Mind**
2501.08838v1 by Kazutoshi Shinoda, Nobukatsu Hojo, Kyosuke Nishida, Saki Mizuno, Keita Suzuki, Ryo Masumura, Hiroaki Sugiyama, Kuniko Saito

Existing Theory of Mind (ToM) benchmarks diverge from real-world scenarios in
three aspects: 1) they assess a limited range of mental states such as beliefs,
2) false beliefs are not comprehensively explored, and 3) the diverse
personality traits of characters are overlooked. To address these challenges,
we introduce ToMATO, a new ToM benchmark formulated as multiple-choice QA over
conversations. ToMATO is generated via LLM-LLM conversations featuring
information asymmetry. By employing a prompting method that requires
role-playing LLMs to verbalize their thoughts before each utterance, we capture
both first- and second-order mental states across five categories: belief,
intention, desire, emotion, and knowledge. These verbalized thoughts serve as
answers to questions designed to assess the mental states of characters within
conversations. Furthermore, the information asymmetry introduced by hiding
thoughts from others induces the generation of false beliefs about various
mental states. Assigning distinct personality traits to LLMs further
diversifies both utterances and thoughts. ToMATO consists of 5.4k questions,
753 conversations, and 15 personality trait patterns. Our analysis shows that
this dataset construction approach frequently generates false beliefs due to
the information asymmetry between role-playing LLMs, and effectively reflects
diverse personalities. We evaluate nine LLMs on ToMATO and find that even
GPT-4o mini lags behind human performance, especially in understanding false
beliefs, and lacks robustness to various personality traits.

摘要：現有的心智理論 (ToM) 基準在三個方面與真實世界的場景有所不同：1) 它們評估的範圍僅限於信念等心智狀態，2) 沒有全面探討錯誤信念，以及 3) 忽略了角色的多樣化人格特質。為了應對這些挑戰，我們引入了 ToMATO，這是一個新的 ToM 基準，以多選題問答的形式制定，內容是對話。ToMATO 是透過具有資訊不對稱的 LLM-LLM 對話所產生。透過採用一種提示方法，要求角色扮演 LLM 在每次發言前將其想法口頭化，我們捕捉到了五種類別的一階和二階心智狀態：信念、意圖、慾望、情緒和知識。這些口頭化的想法可用於回答問題，這些問題旨在評估對話中角色的心智狀態。此外，透過隱藏他人想法所產生的資訊不對稱，會導致對各種心智狀態產生錯誤信念。為 LLM 分配不同的個性特質，進一步使發言和想法多樣化。ToMATO 由 5.4k 個問題、753 個對話和 15 種個性特質模式組成。我們的分析顯示，這種資料集建構方法由於角色扮演 LLM 之間的資訊不對稱，經常會產生錯誤信念，並有效地反映出不同的個性。我們在 ToMATO 上評估了九個 LLM，發現即使是 GPT-4o mini 也落後於人類表現，特別是在理解錯誤信念方面，並且缺乏對各種個性特質的穩健性。

##### **IDEA: Image Description Enhanced CLIP-Adapter**
2501.08816v1 by Zhipeng Ye, Feng Jiang, Qiufeng Wang, Kaizhu Huang, Jiaqi Huang

CLIP (Contrastive Language-Image Pre-training) has attained great success in
pattern recognition and computer vision. Transferring CLIP to downstream tasks
(e.g. zero- or few-shot classification) is a hot topic in multimodal learning.
However, current studies primarily focus on either prompt learning for text or
adapter tuning for vision, without fully exploiting the complementary
information and correlations among image-text pairs. In this paper, we propose
an Image Description Enhanced CLIP-Adapter (IDEA) method to adapt CLIP to
few-shot image classification tasks. This method captures fine-grained features
by leveraging both visual features and textual descriptions of images. IDEA is
a training-free method for CLIP, and it can be comparable to or even exceeds
state-of-the-art models on multiple tasks. Furthermore, we introduce
Trainable-IDEA (T-IDEA), which extends IDEA by adding two lightweight learnable
components (i.e., a projector and a learnable latent space), further enhancing
the model's performance and achieving SOTA results on 11 datasets. As one
important contribution, we employ the Llama model and design a comprehensive
pipeline to generate textual descriptions for images of 11 datasets, resulting
in a total of 1,637,795 image-text pairs, named "IMD-11". Our code and data are
released at https://github.com/FourierAI/IDEA.

摘要：CLIP（对比语言图像预训练）在模式识别和计算机视觉中取得了巨大成功。将 CLIP 转移到下游任务（例如零样本或少样本分类）是多模态学习中的热门话题。然而，目前的研究主要集中在文本的提示学习或视觉的适配器调整上，并未充分利用图像文本对之间的互补信息和相关性。在本文中，我们提出了一种图像描述增强 CLIP 适配器 (IDEA) 方法，以将 CLIP 适应于少样本图像分类任务。此方法通过利用图像的视觉特征和文本描述来捕捉细粒度特征。IDEA 是 CLIP 的一种无训练方法，并且在多项任务上可以与最先进的模型媲美甚至超越它们。此外，我们引入了可训练 IDEA (T-IDEA)，它通过添加两个轻量级可学习组件（即投影仪和可学习潜在空间）来扩展 IDEA，进一步增强了模型的性能，并在 11 个数据集上取得了 SOTA 结果。作为一项重要贡献，我们采用了 Llama 模型并设计了一个综合管道来为 11 个数据集的图像生成文本描述，共产生了 1,637,795 对图像文本，名为“IMD-11”。我们的代码和数据已在 https://github.com/FourierAI/IDEA 上发布。

##### **How Developers Interact with AI: A Taxonomy of Human-AI Collaboration in Software Engineering**
2501.08774v1 by Christoph Treude, Marco A. Gerosa

Artificial intelligence (AI), including large language models and generative
AI, is emerging as a significant force in software development, offering
developers powerful tools that span the entire development lifecycle. Although
software engineering research has extensively studied AI tools in software
development, the specific types of interactions between developers and these
AI-powered tools have only recently begun to receive attention. Understanding
and improving these interactions has the potential to improve productivity,
trust, and efficiency in AI-driven workflows. In this paper, we propose a
taxonomy of interaction types between developers and AI tools, identifying
eleven distinct interaction types, such as auto-complete code suggestions,
command-driven actions, and conversational assistance. Building on this
taxonomy, we outline a research agenda focused on optimizing AI interactions,
improving developer control, and addressing trust and usability challenges in
AI-assisted development. By establishing a structured foundation for studying
developer-AI interactions, this paper aims to stimulate research on creating
more effective, adaptive AI tools for software development.

摘要：人工智慧（AI），包含大型語言模型和生成式 AI，正成為軟體開發中一股重要的力量，為開發人員提供橫跨整個開發生命週期的強大工具。儘管軟體工程研究已廣泛探討軟體開發中的人工智慧工具，但開發人員與這些 AI 驅動工具之間的特定互動類型直到最近才開始受到關注。了解和改進這些互動有潛力提高 AI 驅動工作流程的生產力、信任和效率。在本文中，我們提出開發人員與 AI 工具之間互動類型的分類法，找出 11 種不同的互動類型，例如自動完成程式碼建議、命令驅動動作和對話協助。根據此分類法，我們概述了專注於最佳化 AI 互動、改善開發人員控制，以及解決 AI 輔助開發中的信任和可用性挑戰的研究議程。透過為研究開發人員與 AI 的互動建立一個結構化的基礎，本文旨在激勵研究，以創造更有效、更具適應性的軟體開發 AI 工具。

##### **Enhanced Large Language Models for Effective Screening of Depression and Anxiety**
2501.08769v1 by June M. Liu, Mengxia Gao, Sahand Sabour, Zhuang Chen, Minlie Huang, Tatia M. C. Lee

Depressive and anxiety disorders are widespread, necessitating timely
identification and management. Recent advances in Large Language Models (LLMs)
offer potential solutions, yet high costs and ethical concerns about training
data remain challenges. This paper introduces a pipeline for synthesizing
clinical interviews, resulting in 1,157 interactive dialogues (PsyInterview),
and presents EmoScan, an LLM-based emotional disorder screening system. EmoScan
distinguishes between coarse (e.g., anxiety or depressive disorders) and fine
disorders (e.g., major depressive disorders) and conducts high-quality
interviews. Evaluations showed that EmoScan exceeded the performance of base
models and other LLMs like GPT-4 in screening emotional disorders
(F1-score=0.7467). It also delivers superior explanations (BERTScore=0.9408)
and demonstrates robust generalizability (F1-score of 0.67 on an external
dataset). Furthermore, EmoScan outperforms baselines in interviewing skills, as
validated by automated ratings and human evaluations. This work highlights the
importance of scalable data-generative pipelines for developing effective
mental health LLM tools.

摘要：憂鬱症和焦慮症十分普遍，需要及時識別和管理。大型語言模型 (LLM) 的最新進展提供了潛在的解決方案，但訓練資料的高成本和倫理問題仍然是挑戰。本文介紹了一個用於合成臨床訪談的管道，產生了 1,157 個互動對話 (PsyInterview)，並展示了 EmoScan，一個基於 LLM 的情緒障礙篩檢系統。EmoScan 區分了粗略的（例如，焦慮症或憂鬱症）和精細的障礙（例如，重度憂鬱症），並進行高品質的訪談。評估顯示，EmoScan 在篩檢情緒障礙方面優於基礎模型和其他 LLM，例如 GPT-4（F1 分數 = 0.7467）。它還提供了優異的解釋（BERTScore = 0.9408），並展示了強健的概括性（在外部資料集上的 F1 分數為 0.67）。此外，EmoScan 在訪談技巧方面優於基準，經由自動評分和人類評估驗證。這項工作突顯了可擴充資料生成管道對於開發有效的 LLM 心理健康工具的重要性。

##### **Leveraging LLM Agents for Translating Network Configurations**
2501.08760v1 by Yunze Wei, Xiaohui Xie, Yiwei Zuo, Tianshuo Hu, Xinyi Chen, Kaiwen Chi, Yong Cui

Configuration translation is a critical and frequent task in network
operations. When a network device is damaged or outdated, administrators need
to replace it to maintain service continuity. The replacement devices may
originate from different vendors, necessitating configuration translation to
ensure seamless network operation. However, translating configurations manually
is a labor-intensive and error-prone process. In this paper, we propose an
intent-based framework for translating network configuration with Large
Language Model (LLM) Agents. The core of our approach is an Intent-based
Retrieval Augmented Generation (IRAG) module that systematically splits a
configuration file into fragments, extracts intents, and generates accurate
translations. We also design a two-stage verification method to validate the
syntax and semantics correctness of the translated configurations. We implement
and evaluate the proposed method on real-world network configurations.
Experimental results show that our method achieves 97.74% syntax correctness,
outperforming state-of-the-art methods in translation accuracy.

摘要：網路操作中，組態轉換是一項重要且頻繁的任務。當網路裝置損壞或過時，管理員需要更換它以維持服務的連續性。更換的裝置可能來自不同的供應商，需要進行組態轉換，以確保網路操作的順暢。然而，手動轉換組態是一個勞力密集且容易出錯的過程。在本文中，我們提出了一個基於意圖的架構，使用大型語言模型 (LLM) 代理來轉換網路組態。我們的方法的核心是一個基於意圖的檢索增強生成 (IRAG) 模組，它會系統性地將組態檔案拆分為片段、萃取意圖，並產生準確的轉換。我們還設計了一個兩階段驗證方法，用於驗證已轉換組態的語法和語意正確性。我們在真實世界的網路組態上實作並評估所提出的方法。實驗結果顯示，我們的方法達到了 97.74% 的語法正確性，在轉換準確度方面優於最先進的方法。

##### **Expanding Vietnamese SentiWordNet to Improve Performance of Vietnamese Sentiment Analysis Models**
2501.08758v1 by Hong-Viet Tran, Van-Tan Bui, Lam-Quan Tran

Sentiment analysis is one of the most crucial tasks in Natural Language
Processing (NLP), involving the training of machine learning models to classify
text based on the polarity of opinions. Pre-trained Language Models (PLMs) can
be applied to downstream tasks through fine-tuning, eliminating the need to
train the model from scratch. Specifically, PLMs have been employed for
Sentiment Analysis, a process that involves detecting, analyzing, and
extracting the polarity of text sentiments. Numerous models have been proposed
to address this task, with pre-trained PhoBERT-V2 models standing out as the
state-of-the-art language models for Vietnamese. The PhoBERT-V2 pre-training
approach is based on RoBERTa, optimizing the BERT pre-training method for more
robust performance. In this paper, we introduce a novel approach that combines
PhoBERT-V2 and SentiWordnet for Sentiment Analysis of Vietnamese reviews. Our
proposed model utilizes PhoBERT-V2 for Vietnamese, offering a robust
optimization for the prominent BERT model in the context of Vietnamese
language, and leverages SentiWordNet, a lexical resource explicitly designed to
support sentiment classification applications. Experimental results on the VLSP
2016 and AIVIVN 2019 datasets demonstrate that our sentiment analysis system
has achieved excellent performance in comparison to other models.

摘要：情感分析是自然語言處理 (NLP) 中最重要的任務之一，涉及訓練機器學習模型以根據意見的極性對文本進行分類。預訓練語言模型 (PLM) 可透過微調應用於下游任務，無需從頭開始訓練模型。具體來說，PLM 已被用於情感分析，這是一個涉及檢測、分析和提取文本情感極性的過程。已經提出了許多模型來解決這個任務，其中預訓練的 PhoBERT-V2 模型作為越南語的最新語言模型而脫穎而出。PhoBERT-V2 預訓練方法基於 RoBERTa，針對更強大的效能最佳化 BERT 預訓練方法。在本文中，我們介紹了一種結合 PhoBERT-V2 和 SentiWordnet 的新方法，用於越南評論的情感分析。我們提出的模型利用 PhoBERT-V2 處理越南語，針對越南語境中的知名 BERT 模型提供強大的最佳化，並利用 SentiWordNet，這是一個明確設計用於支援情感分類應用程式的詞彙資源。在 VLSP 2016 和 AIVIVN 2019 資料集上的實驗結果表明，與其他模型相比，我們的語意分析系統已經取得了極佳的效能。

##### **The Inherent Limits of Pretrained LLMs: The Unexpected Convergence of Instruction Tuning and In-Context Learning Capabilities**
2501.08716v1 by Irina Bigoulaeva, Harish Tayyar Madabushi, Iryna Gurevych

Large Language Models (LLMs), trained on extensive web-scale corpora, have
demonstrated remarkable abilities across diverse tasks, especially as they are
scaled up. Nevertheless, even state-of-the-art models struggle in certain
cases, sometimes failing at problems solvable by young children, indicating
that traditional notions of task complexity are insufficient for explaining LLM
capabilities. However, exploring LLM capabilities is complicated by the fact
that most widely-used models are also "instruction-tuned" to respond
appropriately to prompts. With the goal of disentangling the factors
influencing LLM performance, we investigate whether instruction-tuned models
possess fundamentally different capabilities from base models that are prompted
using in-context examples. Through extensive experiments across various model
families, scales and task types, which included instruction tuning 90 different
LLMs, we demonstrate that the performance of instruction-tuned models is
significantly correlated with the in-context performance of their base
counterparts. By clarifying what instruction-tuning contributes, we extend
prior research into in-context learning, which suggests that base models use
priors from pretraining data to solve tasks. Specifically, we extend this
understanding to instruction-tuned models, suggesting that their pretraining
data similarly sets a limiting boundary on the tasks they can solve, with the
added influence of the instruction-tuning dataset.

摘要：大型語言模型 (LLM) 在廣泛的網路規模語料庫上訓練，在不同的任務中展現出非凡的能力，特別是在它們擴大規模時。然而，即使是最先進的模型在某些情況下也會遇到困難，有時甚至無法解決幼兒可以解決的問題，這表示傳統任務複雜性的概念不足以解釋 LLM 的能力。然而，探索 LLM 能力會因為一個事實而變得複雜，那就是大多數廣泛使用的模型也經過「指令調整」，以適當地回應提示。為了解開影響 LLM 效能的因素，我們調查經過指令調整的模型是否具備與使用情境範例提示的基本模型截然不同的能力。透過針對各種模型家族、規模和任務類型進行廣泛的實驗，其中包括對 90 個不同的 LLM 進行指令調整，我們證明了經過指令調整的模型的效能與其基本對應模型的情境效能顯著相關。透過釐清指令調整的貢獻，我們擴展了先前對情境學習的研究，這表明基本模型使用預訓練資料中的先驗知識來解決任務。具體來說，我們將此理解擴展到經過指令調整的模型，這表明他們的預訓練資料同樣設定了一個限制邊界，限制了他們可以解決的任務，並增加了指令調整資料集的影響。

##### **Self-supervised Transformation Learning for Equivariant Representations**
2501.08712v1 by Jaemyung Yu, Jaehyun Choi, Dong-Jae Lee, HyeongGwon Hong, Junmo Kim

Unsupervised representation learning has significantly advanced various
machine learning tasks. In the computer vision domain, state-of-the-art
approaches utilize transformations like random crop and color jitter to achieve
invariant representations, embedding semantically the same inputs despite
transformations. However, this can degrade performance in tasks requiring
precise features, such as localization or flower classification. To address
this, recent research incorporates equivariant representation learning, which
captures transformation-sensitive information. However, current methods depend
on transformation labels and thus struggle with interdependency and complex
transformations. We propose Self-supervised Transformation Learning (STL),
replacing transformation labels with transformation representations derived
from image pairs. The proposed method ensures transformation representation is
image-invariant and learns corresponding equivariant transformations, enhancing
performance without increased batch complexity. We demonstrate the approach's
effectiveness across diverse classification and detection tasks, outperforming
existing methods in 7 out of 11 benchmarks and excelling in detection. By
integrating complex transformations like AugMix, unusable by prior equivariant
methods, this approach enhances performance across tasks, underscoring its
adaptability and resilience. Additionally, its compatibility with various base
models highlights its flexibility and broad applicability. The code is
available at https://github.com/jaemyung-u/stl.

摘要：無監督表示學習已大幅提升各種機器學習任務。在電腦視覺領域中，最先進的方法利用隨機裁剪和色彩抖動等轉換，以達成不變表示，即使經過轉換，語意上相同的輸入仍會嵌入。然而，這可能會降低需要精確特徵的任務效能，例如定位或花卉分類。為了解決此問題，最近的研究納入了等變表示學習，這擷取了對轉換敏感的資訊。然而，目前的方法依賴於轉換標籤，因此難以處理相互依賴性和複雜的轉換。我們提出自監督轉換學習 (STL)，以從影像對中衍生的轉換表示取代轉換標籤。所提出的方法確保轉換表示是影像不變的，並學習對應的等變轉換，在不增加批次複雜度的情況下提升效能。我們展示了此方法在各種分類和偵測任務中的有效性，在 11 個基準中的 7 個表現優於現有方法，且在偵測方面表現出色。透過整合先前的等變方法無法使用的複雜轉換，例如 AugMix，此方法提升了各種任務的效能，突顯其適應性和韌性。此外，它與各種基礎模型的相容性突顯了其靈活性與廣泛的適用性。程式碼可在 https://github.com/jaemyung-u/stl 取得。

##### **Deep Learning-Based Feature Fusion for Emotion Analysis and Suicide Risk Differentiation in Chinese Psychological Support Hotlines**
2501.08696v1 by Han Wang, Jianqiang Li, Qing Zhao, Zhonglong Chen, Changwei Song, Jing Tang, Yuning Huang, Wei Zhai, Yongsheng Tong, Guanghui Fu

Mental health is a critical global public health issue, and psychological
support hotlines play a pivotal role in providing mental health assistance and
identifying suicide risks at an early stage. However, the emotional expressions
conveyed during these calls remain underexplored in current research. This
study introduces a method that combines pitch acoustic features with deep
learning-based features to analyze and understand emotions expressed during
hotline interactions. Using data from China's largest psychological support
hotline, our method achieved an F1-score of 79.13% for negative binary emotion
classification.Additionally, the proposed approach was validated on an open
dataset for multi-class emotion classification,where it demonstrated better
performance compared to the state-of-the-art methods. To explore its clinical
relevance, we applied the model to analysis the frequency of negative emotions
and the rate of emotional change in the conversation, comparing 46 subjects
with suicidal behavior to those without. While the suicidal group exhibited
more frequent emotional changes than the non-suicidal group, the difference was
not statistically significant.Importantly, our findings suggest that emotional
fluctuation intensity and frequency could serve as novel features for
psychological assessment scales and suicide risk prediction.The proposed method
provides valuable insights into emotional dynamics and has the potential to
advance early intervention and improve suicide prevention strategies through
integration with clinical tools and assessments The source code is publicly
available at https://github.com/Sco-field/Speechemotionrecognition/tree/main.

摘要：心理健康是全球公共衛生的一項重要議題，而心理諮詢熱線在提供心理健康協助和早期辨識自殺風險上扮演著關鍵的角色。然而，在這些通話中所傳達的情緒表達在目前的研究中仍未受到充分的探討。本研究提出了一種結合音高聲學特徵與深度學習特徵的方法，用於分析和理解熱線互動中所表達的情緒。使用來自中國最大的心理諮詢熱線的數據，我們的模型在負面二元情緒分類中達到了 79.13% 的 F1 分數。此外，所提出的方法在一個開放的多類情緒分類數據集上得到了驗證，與最先進的方法相比，它表現出更好的性能。為了探討其臨床相關性，我們將模型應用於分析負面情緒的頻率和對話中的情緒變化率，並將 46 名有自殺行為的受試者與沒有自殺行為的受試者進行比較。雖然有自殺行為的組別表現出比沒有自殺行為的組別更頻繁的情緒變化，但差異並未達到統計顯著性。重要的是，我們的研究結果表明，情緒波動的強度和頻率可用作心理評估量表和自殺風險預測的新特徵。所提出的方法提供了對情緒動態的寶貴見解，並有潛力透過與臨床工具和評估整合，推進早期干預並改善自殺預防策略。原始碼已公開發布在 https://github.com/Sco-field/Speechemotionrecognition/tree/main。

##### **Knowledge Graph-based Retrieval-Augmented Generation for Schema Matching**
2501.08686v1 by Chuangtao Ma, Sriom Chakrabarti, Arijit Khan, Bálint Molnár

Traditional similarity-based schema matching methods are incapable of
resolving semantic ambiguities and conflicts in domain-specific complex mapping
scenarios due to missing commonsense and domain-specific knowledge. The
hallucination problem of large language models (LLMs) also makes it challenging
for LLM-based schema matching to address the above issues. Therefore, we
propose a Knowledge Graph-based Retrieval-Augmented Generation model for Schema
Matching, referred to as the KG-RAG4SM. In particular, KG-RAG4SM introduces
novel vector-based, graph traversal-based, and query-based graph retrievals, as
well as a hybrid approach and ranking schemes that identify the most relevant
subgraphs from external large knowledge graphs (KGs). We showcase that KG-based
retrieval-augmented LLMs are capable of generating more accurate results for
complex matching cases without any re-training. Our experimental results show
that KG-RAG4SM outperforms the LLM-based state-of-the-art (SOTA) methods (e.g.,
Jellyfish-8B) by 35.89% and 30.50% in terms of precision and F1 score on the
MIMIC dataset, respectively; KG-RAG4SM with GPT-4o-mini outperforms the
pre-trained language model (PLM)-based SOTA methods (e.g., SMAT) by 69.20% and
21.97% in terms of precision and F1 score on the Synthea dataset, respectively.
The results also demonstrate that our approach is more efficient in end-to-end
schema matching, and scales to retrieve from large KGs. Our case studies on the
dataset from the real-world schema matching scenario exhibit that the
hallucination problem of LLMs for schema matching is well mitigated by our
solution.

摘要：傳統基於相似度的模式比對方法無法解決特定領域複雜比對場景中的語意模糊性和衝突，這是因為缺乏常識和特定領域知識。大型語言模型 (LLM) 的幻覺問題也使得基於 LLM 的模式比對難以解決上述問題。因此，我們提出一個基於知識圖譜的檢索增強生成模型，用於模式比對，稱為 KG-RAG4SM。具體而言，KG-RAG4SM 引入了基於向量的、基於圖形遍歷的和基於查詢的圖形檢索，以及一種混合方法和排名方案，這些方案從外部大型知識圖譜 (KG) 中識別最相關的子圖。我們展示了基於 KG 的檢索增強 LLM 能夠在不進行任何重新訓練的情況下為複雜的比對案例生成更準確的結果。我們的實驗結果表明，在 MIMIC 資料集上，KG-RAG4SM 在準確度和 F1 分數方面分別比基於 LLM 的最新 (SOTA) 方法 (例如 Jellyfish-8B) 高出 35.89% 和 30.50%；具有 GPT-4o-mini 的 KG-RAG4SM 在準確度和 F1 分數方面分別比基於預先訓練語言模型 (PLM) 的 SOTA 方法 (例如 SMAT) 高出 69.20% 和 21.97% 在 Synthea 資料集上。結果還表明，我們的做法在端到端模式比對中更有效率，並且可以擴展到從大型 KG 中檢索。我們對來自現實世界模式比對場景的資料集進行的案例研究表明，我們的解決方案很好地緩解了 LLM 在模式比對中的幻覺問題。

##### **Application of Deep Reinforcement Learning to UAV Swarming for Ground Surveillance**
2501.08655v1 by Raúl Arranz, David Carramiñana, Gonzalo de Miguel, Juan A. Besada, Ana M. Bernardos

This paper summarizes in depth the state of the art of aerial swarms,
covering both classical and new reinforcement-learning-based approaches for
their management. Then, it proposes a hybrid AI system, integrating deep
reinforcement learning in a multi-agent centralized swarm architecture. The
proposed system is tailored to perform surveillance of a specific area,
searching and tracking ground targets, for security and law enforcement
applications. The swarm is governed by a central swarm controller responsible
for distributing different search and tracking tasks among the cooperating
UAVs. Each UAV agent is then controlled by a collection of cooperative
sub-agents, whose behaviors have been trained using different deep
reinforcement learning models, tailored for the different task types proposed
by the swarm controller. More specifically, proximal policy optimization (PPO)
algorithms were used to train the agents' behavior. In addition, several
metrics to assess the performance of the swarm in this application were
defined. The results obtained through simulation show that our system searches
the operation area effectively, acquires the targets in a reasonable time, and
is capable of tracking them continuously and consistently.

摘要：本文深入总结了空中蜂群的最新技术，涵盖了用于管理空中蜂群的经典方法和新的基于强化学习的方法。然后，本文提出了一种混合人工智能系统，将深度强化学习整合到多智能体集中蜂群架构中。所提出的系统专门用于执行特定区域的监视、搜索和跟踪地面目标，以用于安全和执法应用。蜂群由一个中央蜂群控制器管理，负责在合作无人机之间分配不同的搜索和跟踪任务。然后，每个无人机代理由一组协作子代理控制，这些子代理的行为已使用不同的深度强化学习模型进行训练，这些模型针对蜂群控制器提出的不同任务类型量身定制。更具体地说，近端策略优化 (PPO) 算法用于训练代理行为。此外，还定义了几个指标来评估蜂群在此应用中的性能。通过仿真获得的结果表明，我们的系统有效地搜索了操作区域，在合理的时间内获取了目标，并且能够持续不断地跟踪目标。

##### **Fine-grained Spatio-temporal Event Prediction with Self-adaptive Anchor Graph**
2501.08653v1 by Wang-Tao Zhou, Zhao Kang, Sicong Liu, Lizong Zhang, Ling Tian

Event prediction tasks often handle spatio-temporal data distributed in a
large spatial area. Different regions in the area exhibit different
characteristics while having latent correlations. This spatial heterogeneity
and correlations greatly affect the spatio-temporal distributions of event
occurrences, which has not been addressed by state-of-the-art models. Learning
spatial dependencies of events in a continuous space is challenging due to its
fine granularity and a lack of prior knowledge. In this work, we propose a
novel Graph Spatio-Temporal Point Process (GSTPP) model for fine-grained event
prediction. It adopts an encoder-decoder architecture that jointly models the
state dynamics of spatially localized regions using neural Ordinary
Differential Equations (ODEs). The state evolution is built on the foundation
of a novel Self-Adaptive Anchor Graph (SAAG) that captures spatial
dependencies. By adaptively localizing the anchor nodes in the space and
jointly constructing the correlation edges between them, the SAAG enhances the
model's ability of learning complex spatial event patterns. The proposed GSTPP
model greatly improves the accuracy of fine-grained event prediction. Extensive
experimental results show that our method greatly improves the prediction
accuracy over existing spatio-temporal event prediction approaches.

摘要：事件预测任務通常會處理分布在廣闊空間區域中的時空資料。該區域中的不同區域表現出不同的特徵，同時具有潛在相關性。這種空間異質性和相關性極大地影響了事件發生的時空分佈，而最先進的模型尚未解決這個問題。由於事件在連續空間中的精細粒度和缺乏先驗知識，學習事件的空間依賴性具有挑戰性。在這項工作中，我們提出了一個新的圖形時空點過程 (GSTPP) 模型，用於精細的事件預測。它採用編碼器-解碼器架構，使用神經常微分方程 (ODE) 聯合建模空間定位區域的狀態動態。狀態演化建立在新的自適應錨定圖 (SAAG) 的基礎上，該圖捕捉了空間依賴性。通過自適應地定位空間中的錨定節點並聯合構造它們之間的相關邊緣，SAAG 增強了模型學習複雜空間事件模式的能力。提出的 GSTPP 模型大大提高了精細事件預測的準確性。廣泛的實驗結果表明，我們的模型比現有的時空事件預測方法大大提高了預測準確性。

##### **MAGNET: Augmenting Generative Decoders with Representation Learning and Infilling Capabilities**
2501.08648v1 by Savya Khosla, Kushal Kafle, Simon Jenni, Handong Zhao, John Collomosse, Jing Shi

While originally designed for unidirectional generative modeling,
decoder-only large language models (LLMs) are increasingly being adapted for
bidirectional modeling. However, unidirectional and bidirectional models are
typically trained separately with distinct objectives (generation and
representation learning, respectively). This separation overlooks the
opportunity for developing a more versatile language model and for these
objectives to complement each other. In this work, we introduce MAGNET, an
adaptation of decoder-only LLMs that enhances their ability to generate robust
representations and infill missing text spans, while preserving their knowledge
and text generation capabilities. MAGNET employs three self-supervised training
objectives and introduces an attention mechanism that combines bidirectional
and causal attention, enabling unified training across all objectives. Our
results demonstrate that LLMs adapted with MAGNET (1) surpass strong text
encoders on token-level and sentence-level representation learning tasks, (2)
generate contextually appropriate text infills by leveraging future context,
(3) retain the ability for open-ended text generation without exhibiting
repetition problem, and (4) preserve the knowledge gained by the LLM during
pretraining.

摘要：儘管最初是為單向生成式建模而設計，
僅解碼器的大語言模型 (LLM) 卻日益被改編為
雙向建模。然而，單向和雙向模型
通常會以不同的目標（分別為產生和
表示學習）分開訓練。這種分離忽視了
開發更通用語言模型的機會，以及這些
目標相互補充的機會。在這項工作中，我們引入了 MAGNET，一種僅解碼器 LLM 的改編，它增強了它們生成穩健
表示和填補缺失文字區段的能力，同時保留它們的知識
和文字生成能力。MAGNET 採用三個自我監督訓練
目標，並引入一種結合雙向
和因果注意力的注意力機制，讓所有目標都能進行統一訓練。我們的
結果證明使用 MAGNET 改編的 LLM (1) 在標記層級和句子層級表示學習任務中超越強大的文字
編碼器，(2)
利用未來內容產生適當的文字填補，
(3) 保留進行開放式文字生成的能力，而不會出現
重複的問題，以及 (4) 保留 LLM 在
預訓練期間獲得的知識。

##### **Reassessing the Role of Chain-of-Thought in Sentiment Analysis: Insights and Limitations**
2501.08641v1 by Kaiyuan Zheng, Qinghua Zhao, Lei Li

The relationship between language and thought remains an unresolved
philosophical issue. Existing viewpoints can be broadly categorized into two
schools: one asserting their independence, and another arguing that language
constrains thought. In the context of large language models, this debate raises
a crucial question: Does a language model's grasp of semantic meaning depend on
thought processes? To explore this issue, we investigate whether reasoning
techniques can facilitate semantic understanding. Specifically, we
conceptualize thought as reasoning, employ chain-of-thought prompting as a
reasoning technique, and examine its impact on sentiment analysis tasks. The
experiments show that chain-of-thought has a minimal impact on sentiment
analysis tasks. Both the standard and chain-of-thought prompts focus on aspect
terms rather than sentiment in the generated content. Furthermore,
counterfactual experiments reveal that the model's handling of sentiment tasks
primarily depends on information from demonstrations. The experimental results
support the first viewpoint.

摘要：語言與思考之間的關係仍然是一個未解決的哲學問題。現有的觀點大致可分為兩派：一派主張它們的獨立性，另一派則認為語言約束了思考。在大語言模型的背景下，這種爭論引發了一個關鍵問題：語言模型對語義意義的掌握是否依賴於思考過程？為了探討這個問題，我們研究了推理技術是否可以促進語義理解。具體來說，我們將思考概念化為推理，採用思想鏈提示作為推理技術，並檢驗其對情緒分析任務的影響。實驗表明，思想鏈對情緒分析任務的影響很小。標準提示和思想鏈提示都側重於生成的內容中的方面術語，而不是情緒。此外，反事實實驗表明，模型對情緒任務的處理主要依賴於演示中的信息。實驗結果支持第一個觀點。

##### **SWSC: Shared Weight for Similar Channel in LLM**
2501.08631v1 by Binrui Zeng, Yongtao Tang, Xiaodong Liu, Xiaopeng Li

Large language models (LLMs) have spurred development in multiple industries.
However, the growing number of their parameters brings substantial storage and
computing burdens, making it essential to explore model compression techniques
for parameter reduction and easier deployment. We propose SWSC, an LLM
compression method based on the concept of Shared Weight for Similar Channel.
It uses the K-Means clustering algorithm to cluster model weights
channel-by-channel, generating clusters with highly similar vectors within
each. A representative vector from each cluster is selected to approximately
replace all vectors in the cluster, significantly reducing the number of model
weight parameters. However, approximate restoration will inevitably cause
damage to the performance of the model. To tackle this issue, we perform
singular value decomposition on the weight error values before and after
compression and retain the larger singular values and their corresponding
singular vectors to compensate for the accuracy. The experimental results show
that our method can effectively ensure the performance of the compressed LLM
even under low-precision conditions.

摘要：大型語言模型 (LLM) 已促使多個產業發展。
然而，其參數數量不斷增加，帶來龐大的儲存和運算負擔，因此探索模型壓縮技術以減少參數並簡化部署至關重要。我們提出 SWSC，一種基於相似通道共享權重的 LLM 壓縮方法。
它使用 K-Means 聚類演算法對模型權重逐通道聚類，在每個通道內產生具有高度相似向量的聚類。從每個聚類中選取一個代表向量來近似替換聚類中的所有向量，大幅減少模型權重參數的數量。然而，近似還原不可避免地會損害模型的效能。為了解決這個問題，我們在壓縮前後對權重誤差值執行奇異值分解，並保留較大的奇異值及其對應的奇異向量以補償準確度。實驗結果表明，即使在低精度條件下，我們的方法也能有效確保壓縮 LLM 的效能。

##### **ViBidirectionMT-Eval: Machine Translation for Vietnamese-Chinese and Vietnamese-Lao language pair**
2501.08621v1 by Hong-Viet Tran, Minh-Quy Nguyen, Van-Vinh Nguyen

This paper presents an results of the VLSP 2022-2023 Machine Translation
Shared Tasks, focusing on Vietnamese-Chinese and Vietnamese-Lao machine
translation. The tasks were organized as part of the 9th, 10th annual workshop
on Vietnamese Language and Speech Processing (VLSP 2022, VLSP 2023). The
objective of the shared task was to build machine translation systems,
specifically targeting Vietnamese-Chinese and Vietnamese-Lao translation
(corresponding to 4 translation directions). The submission were evaluated on
1,000 pairs for testing (news and general domains) using established metrics
like BLEU [11] and SacreBLEU [12]. Additionally, system outputs also were
evaluated with human judgment provided by experts in Chinese and Lao languages.
These human assessments played a crucial role in ranking the performance of the
machine translation models, ensuring a more comprehensive evaluation.

摘要：本文介紹了 VLSP 2022-2023 機器翻譯共享任務的結果，重點關注越南語-中文和越南語-寮語機器翻譯。這些任務是作為第 9 屆、第 10 屆越南語言和語音處理年度研討會 (VLSP 2022、VLSP 2023) 的一部分來組織的。共享任務的目標是建構機器翻譯系統，特別針對越南語-中文和越南語-寮語翻譯（對應 4 個翻譯方向）。提交內容使用既定的指標（例如 BLEU [11] 和 SacreBLEU [12]）針對 1,000 對測試對（新聞和一般領域）進行評估。此外，系統輸出也由中文和寮語專家提供的人類判斷進行評估。這些人類評估在對機器翻譯模型的效能進行排名時發揮了至關重要的作用，確保了更全面的評估。

##### **Disjoint Processing Mechanisms of Hierarchical and Linear Grammars in Large Language Models**
2501.08618v1 by Aruna Sankaranarayanan, Dylan Hadfield-Menell, Aaron Mueller

All natural languages are structured hierarchically. In humans, this
structural restriction is neurologically coded: when two grammars are presented
with identical vocabularies, brain areas responsible for language processing
are only sensitive to hierarchical grammars. Using large language models
(LLMs), we investigate whether such functionally distinct hierarchical
processing regions can arise solely from exposure to large-scale language
distributions. We generate inputs using English, Italian, Japanese, or nonce
words, varying the underlying grammars to conform to either hierarchical or
linear/positional rules. Using these grammars, we first observe that language
models show distinct behaviors on hierarchical versus linearly structured
inputs. Then, we find that the components responsible for processing
hierarchical grammars are distinct from those that process linear grammars; we
causally verify this in ablation experiments. Finally, we observe that
hierarchy-selective components are also active on nonce grammars; this suggests
that hierarchy sensitivity is not tied to meaning, nor in-distribution inputs.

摘要：所有自然語言都是層級結構的。在人類身上，這種結構限制是由神經編碼的：當兩個文法被賦予相同的詞彙時，負責語言處理的大腦區域只對層級文法敏感。使用大型語言模型 (LLM)，我們研究這種功能上不同的層級處理區域是否僅能從接觸大規模語言分佈中產生。我們使用英語、義大利語、日語或虛構詞彙產生輸入，改變基礎文法以符合層級或線性/位置規則。使用這些文法，我們首先觀察到語言模型在層級結構的輸入與線性結構的輸入上表現出不同的行為。接著，我們發現處理層級文法的組成部分與處理線性文法的組成部分不同；我們在消融實驗中因果驗證了這一點。最後，我們觀察到層級選擇性組成部分在虛構文法中也活躍；這表示層級敏感性與意義或分佈中的輸入無關。

##### **RLHS: Mitigating Misalignment in RLHF with Hindsight Simulation**
2501.08617v1 by Kaiqu Liang, Haimin Hu, Ryan Liu, Thomas L. Griffiths, Jaime Fernández Fisac

Generative AI systems like foundation models (FMs) must align well with human
values to ensure their behavior is helpful and trustworthy. While Reinforcement
Learning from Human Feedback (RLHF) has shown promise for optimizing model
performance using human judgments, existing RLHF pipelines predominantly rely
on immediate feedback, which can fail to accurately reflect the downstream
impact of an interaction on users' utility. We demonstrate that feedback based
on evaluators' foresight estimates of downstream consequences systematically
induces Goodhart's Law dynamics, incentivizing misaligned behaviors like
sycophancy and deception and ultimately degrading user outcomes. To alleviate
this, we propose decoupling evaluation from prediction by refocusing RLHF on
hindsight feedback. Our theoretical analysis reveals that conditioning
evaluator feedback on downstream observations mitigates misalignment and
improves expected human utility, even when these observations are simulated by
the AI system itself. To leverage this insight in a practical alignment
algorithm, we introduce Reinforcement Learning from Hindsight Simulation
(RLHS), which first simulates plausible consequences and then elicits feedback
to assess what behaviors were genuinely beneficial in hindsight. We apply RLHS
to two widely-employed online and offline preference optimization methods --
Proximal Policy Optimization (PPO) and Direct Preference Optimization (DPO) --
and show empirically that misalignment is significantly reduced with both
methods. Through an online human user study, we show that RLHS consistently
outperforms RLHF in helping users achieve their goals and earns higher
satisfaction ratings, despite being trained solely with simulated hindsight
feedback. These results underscore the importance of focusing on long-term
consequences, even simulated ones, to mitigate misalignment in RLHF.

摘要：生成式人工智能系統，如基礎模型 (FM)，必須與人類價值觀保持一致，以確保其行為是有幫助且值得信賴的。雖然透過人類回饋進行強化學習 (RLHF) 已顯示出利用人類判斷來最佳化模型效能的可能性，但現有的 RLHF 管線主要依賴即時回饋，這可能無法準確反映互動對使用者效用的下游影響。我們證明，基於評估者對下游後果的前瞻性估計的回饋系統性地誘發古德哈特定律動態，鼓勵拍馬屁和欺騙等不一致的行為，並最終降低使用者成果。為了解決這個問題，我們建議透過重新關注 RLHF 在事後回饋上來解除評估與預測的關聯。我們的理論分析表明，在評估者回饋中加入下游觀察結果可以減輕不一致性，並提高預期的使用者效用，即使這些觀察結果是由 AI 系統本身模擬的。為了在實際對齊演算法中運用這個見解，我們引入了事後模擬強化學習 (RLHS)，它會先模擬合理的後果，然後引發回饋，以評估哪些行為在事後真的有益。我們將 RLHS 應用於兩種廣泛使用的線上和離線偏好最佳化方法——近端策略最佳化 (PPO) 和直接偏好最佳化 (DPO)——並透過實證顯示，這兩種方法的不一致性都顯著降低。透過一項線上人類使用者研究，我們證明了 RLHS 在幫助使用者達成目標方面始終優於 RLHF，並獲得更高的滿意度評分，儘管僅使用模擬事後回饋進行訓練。這些結果強調了關注長期後果（即使是模擬的後果）以減輕 RLHF 中不一致性的重要性。

##### **Assessing the Alignment of FOL Closeness Metrics with Human Judgement**
2501.08613v1 by Ramya Keerthy Thatikonda, Wray Buntine, Ehsan Shareghi

The recent successful paradigm of solving logical reasoning problems with
tool-augmented large language models (LLMs) leverages translation of natural
language statements into First-Order Logic~(FOL) and external theorem provers.
However, the correctness of FOL statements, comprising operators and text
predicates, often goes unverified due to the lack of a reliable evaluation
metric for comparing generated and ground-truth FOLs. In this paper, we present
a comprehensive study of sensitivity of existing metrics and their alignment
with human judgement on FOL evaluation. Using ground-truth FOLs, we carefully
designed various perturbations on the ground-truth to assess metric
sensitivity. We sample FOL translation candidates for natural language
statements and measure the ranking alignment between automatic metrics and
human annotators. Our empirical findings highlight oversensitivity in the
n-gram metric BLEU for text perturbations, the semantic graph metric Smatch++
for structural perturbations, and FOL metric for operator perturbation. We also
observe a closer alignment between BertScore and human judgement. Additionally,
we show that combining metrics enhances both alignment and sensitivity compared
to using individual metrics.

摘要：最近以工具增强型大型语言模型 (LLM) 解决逻辑推理问题的新兴范例利用了自然语言陈述到一阶逻辑 (FOL) 和外部定理证明器的转化。然而，FOL 陈述的正确性（包括算子和文本谓词）通常因缺乏用于比较生成的 FOL 和真实 FOL 的可靠评估指标而无法得到验证。在本文中，我们对现有指标的敏感性及其与人类对 FOL 评估判断的一致性进行了全面研究。使用真实 FOL，我们精心设计了对真实 FOL 的各种扰动来评估指标敏感性。我们对自然语言陈述抽样 FOL 翻译候选，并测量自动指标和人类注释者之间的排名一致性。我们的经验结果突出了 n-gram 指标 BLEU 对文本扰动的过度敏感性、语义图指标 Smatch++ 对结构扰动的过度敏感性以及 FOL 指标对算子扰动的过度敏感性。我们还观察到 BertScore 与人类判断之间更紧密的一致性。此外，我们表明，与使用单个指标相比，组合指标可以提高一致性和敏感性。

##### **Monte Carlo Tree Search for Comprehensive Exploration in LLM-Based Automatic Heuristic Design**
2501.08603v1 by Zhi Zheng, Zhuoliang Xie, Zhenkun Wang, Bryan Hooi

Handcrafting heuristics for solving complex planning tasks (e.g., NP-hard
combinatorial optimization (CO) problems) is a common practice but requires
extensive domain knowledge. Recently, Large Language Model (LLM)-based
automatic heuristics design (AHD) methods have shown promise in generating
high-quality heuristics without manual intervention. Existing LLM-based AHD
methods employ a population to maintain a fixed number of top-performing
LLM-generated heuristics and introduce evolutionary computation (EC) to enhance
the population iteratively. However, the population-based procedure brings
greedy properties, often resulting in convergence to local optima. Instead, to
more comprehensively explore the space of heuristics, we propose using Monte
Carlo Tree Search (MCTS) for LLM-based heuristic evolution while preserving all
LLM-generated heuristics in a tree structure. With a novel thought-alignment
process and an exploration-decay technique, the proposed MCTS-AHD method
delivers significantly higher-quality heuristics on various complex tasks. Our
code is available at https://github.com/zz1358m/MCTS-AHD-master.

摘要：手工制定启发式方法来解决复杂的规划任务（例如，NP 困难的组合优化 (CO) 问题）是一种常见的做法，但需要广泛的领域知识。最近，基于大语言模型 (LLM) 的自动启发式设计 (AHD) 方法在无需人工干预的情况下生成高质量启发式方面显示出前景。现有的基于 LLM 的 AHD 方法采用种群来维持一定数量的性能最佳的 LLM 生成的启发式方法，并引入进化计算 (EC) 来迭代增强种群。然而，基于种群的过程带来了贪婪属性，通常会导致收敛到局部最优。相反，为了更全面地探索启发式空间，我们建议在基于 LLM 的启发式进化中使用蒙特卡罗树搜索 (MCTS)，同时将所有 LLM 生成的启发式保存在树结构中。通过新颖的思想对齐过程和探索衰减技术，所提出的 MCTS-AHD 方法在各种复杂任务上提供了明显更高质量的启发式方法。我们的代码可在 https://github.com/zz1358m/MCTS-AHD-master 获得。

##### **AutoRestTest: A Tool for Automated REST API Testing Using LLMs and MARL**
2501.08600v1 by Tyler Stennett, Myeongsoo Kim, Saurabh Sinha, Alessandro Orso

As REST APIs have become widespread in modern web services, comprehensive
testing of these APIs has become increasingly crucial. Due to the vast search
space consisting of operations, parameters, and parameter values along with
their complex dependencies and constraints, current testing tools suffer from
low code coverage, leading to suboptimal fault detection. To address this
limitation, we present a novel tool, AutoRestTest, which integrates the
Semantic Operation Dependency Graph (SODG) with Multi-Agent Reinforcement
Learning (MARL) and large language models (LLMs) for effective REST API
testing. AutoRestTest determines operation-dependent parameters using the SODG
and employs five specialized agents (operation, parameter, value, dependency,
and header) to identify dependencies of operations and generate operation
sequences, parameter combinations, and values. AutoRestTest provides a
command-line interface and continuous telemetry on successful operation count,
unique server errors detected, and time elapsed. Upon completion, AutoRestTest
generates a detailed report highlighting errors detected and operations
exercised. In this paper, we introduce our tool and present preliminary
results.

摘要：隨著 REST API 在現代網路服務中廣泛使用，對這些 API 進行全面的測試變得越來越重要。由於廣大的搜尋空間包含操作、參數和參數值以及它們複雜的依賴關係和約束，目前的測試工具存在程式碼覆蓋率低的問題，導致故障偵測不佳。為了解決這個限制，我們提出一個新工具 AutoRestTest，它整合了語義操作依賴圖 (SODG) 與多智能體強化學習 (MARL) 和大型語言模型 (LLM)，以進行有效的 REST API 測試。AutoRestTest 使用 SODG 確定依賴於操作的參數，並使用五個專門的代理 (操作、參數、值、依賴關係和標頭) 來識別操作的依賴關係並產生操作序列、參數組合和值。AutoRestTest 提供命令列介面和持續遙測，包括成功操作次數、偵測到的唯一伺服器錯誤和經過時間。完成後，AutoRestTest 會產生一份詳細報告，重點說明偵測到的錯誤和執行的操作。在本文中，我們介紹我們的工具並提出初步結果。

##### **LlamaRestTest: Effective REST API Testing with Small Language Models**
2501.08598v1 by Myeongsoo Kim, Saurabh Sinha, Alessandro Orso

Modern web services rely heavily on REST APIs, typically documented using the
OpenAPI specification. The widespread adoption of this standard has resulted in
the development of many black-box testing tools that generate tests based on
these specifications. Recent advancements in Natural Language Processing (NLP),
particularly with Large Language Models (LLMs), have enhanced REST API testing
by extracting actionable rules and generating input values from the
human-readable portions of the specification. However, these advancements
overlook the potential of continuously refining the identified rules and test
inputs based on server responses. To address this limitation, we present
LlamaRestTest, a novel approach that employs two custom LLMs to generate
realistic test inputs and uncover parameter dependencies during the testing
process by incorporating server responses. These LLMs are created by
fine-tuning the Llama3-8b model, using mined datasets of REST API example
values and inter-parameter dependencies. We evaluated LlamaRestTest on 12
real-world services (including popular services such as Spotify), comparing it
against RESTGPT, a GPT-powered specification-enhancement tool, as well as
several state-of-the-art REST API testing tools, including RESTler, MoRest,
EvoMaster, and ARAT-RL. Our results show that fine-tuning enables smaller LLMs
to outperform larger models in detecting actionable rules and generating inputs
for REST API testing. We evaluated configurations from the base Llama3-8B to
fine-tuned versions and explored 2-bit, 4-bit, and 8-bit quantization for
efficiency. LlamaRestTest surpasses state-of-the-art tools in code coverage and
error detection, even with RESTGPT-enhanced specifications, and an ablation
study highlights the impact of its novel components.

摘要：<paragraph>現代網路服務高度依賴 REST API，通常使用 OpenAPI 規範文件。這個標準的廣泛採用，導致許多黑盒測試工具的開發，這些工具會根據這些規範文件產生測試。自然語言處理 (NLP) 的最新進展，特別是大語言模型 (LLM)，透過從規範文件的人類可讀部分中萃取可行的規則和產生輸入值，增強了 REST API 測試。然而，這些進展忽略了根據伺服器回應持續精進已識別規則和測試輸入的潛力。為了解決這個限制，我們提出 LlamaRestTest，這是一種新穎的方法，它使用兩個自訂的 LLM 產生逼真的測試輸入，並在測試過程中透過納入伺服器回應來揭露參數依賴性。這些 LLM 是透過微調 Llama3-8b 模型，使用 REST API 範例值的挖掘資料集和參數間的依賴性所建立的。我們在 12 項真實世界的服務（包括 Spotify 等熱門服務）上評估 LlamaRestTest，並將它與 RESTGPT（一種由 GPT 驅動的規範文件增強工具）以及幾個最先進的 REST API 測試工具（包括 RESTler、MoRest、EvoMaster 和 ARAT-RL）進行比較。我們的結果顯示，微調讓較小的 LLM 能在偵測可行的規則和產生 REST API 測試的輸入方面，表現優於較大的模型。我們評估了從基礎 Llama3-8B 到微調版本的組態，並探索了 2 位元、4 位元和 8 位元量化以提升效率。即使在 RESTGPT 增強的規範文件中，LlamaRestTest 也在程式碼涵蓋率和錯誤偵測方面超越了最先進的工具，而且消融研究突顯了其新穎元件的影響。</paragraph>

##### **Dynamic Knowledge Integration for Enhanced Vision-Language Reasoning**
2501.08597v1 by Julian Perry, Surasakdi Siripong, Thanakorn Phonchai

Large Vision-Language Models (LVLMs) have demonstrated impressive
capabilities in multimodal tasks, but their performance is often constrained by
the lack of external knowledge integration, limiting their ability to handle
knowledge-intensive tasks such as visual question answering and reasoning. To
address this challenge, we propose a novel method, Adaptive Knowledge-Guided
Pretraining for Large Vision-Language Models (AKGP-LVLM), which dynamically
incorporates structured and unstructured knowledge into LVLMs during
pretraining and fine-tuning. Our approach employs a knowledge encoder to
represent external knowledge, a retrieval mechanism to select task-relevant
information, and a dynamic adaptor to align multimodal and knowledge
representations effectively. We evaluate our method on four benchmark datasets,
demonstrating significant performance improvements over state-of-the-art
models. Furthermore, human evaluations highlight the superior correctness and
relevance of our model's outputs. Extensive analyses confirm the robustness,
efficiency, and scalability of AKGP-LVLM, making it a compelling solution for
real-world knowledge-intensive tasks.

摘要：大型視覺語言模型 (LVLMs) 已在多模態任務中展現出令人印象深刻的能力，但其效能經常受到外部知識整合不足的限制，這會限制它們處理知識密集型任務（例如視覺問答和推理）的能力。為了解決這個挑戰，我們提出了一種創新的方法，即大型視覺語言模型的自適應知識引導預訓練 (AKGP-LVLM)，它會在預訓練和微調期間動態地將結構化和非結構化知識納入 LVLMs。我們的做法採用知識編碼器來表示外部知識，採用檢索機制來選擇與任務相關的資訊，並採用動態適配器來有效地對齊多模態和知識表示。我們在四大基準資料集上評估了我們的模型，證明其效能顯著優於現有最先進的模型。此外，人工評估突顯了我們模型輸出的正確性和相關性的優越性。廣泛的分析證實了 AKGP-LVLM 的穩健性、效率和可擴充性，使其成為現實世界知識密集型任務的強大解決方案。

##### **OpenMLDB: A Real-Time Relational Data Feature Computation System for Online ML**
2501.08591v1 by Xuanhe Zhou, Wei Zhou, Liguo Qi, Hao Zhang, Dihao Chen, Bingsheng He, Mian Lu, Guoliang Li, Fan Wu, Yuqiang Chen

Efficient and consistent feature computation is crucial for a wide range of
online ML applications. Typically, feature computation is divided into two
distinct phases, i.e., offline stage for model training and online stage for
model serving. These phases often rely on execution engines with different
interface languages and function implementations, causing significant
inconsistencies. Moreover, many online ML features involve complex time-series
computations (e.g., functions over varied-length table windows) that differ
from standard streaming and analytical queries. Existing data processing
systems (e.g., Spark, Flink, DuckDB) often incur multi-second latencies for
these computations, making them unsuitable for real-time online ML applications
that demand timely feature updates.
  This paper presents OpenMLDB, a feature computation system deployed in
4Paradigm's SageOne platform and over 100 real scenarios. Technically, OpenMLDB
first employs a unified query plan generator for consistent computation results
across the offline and online stages, significantly reducing feature deployment
overhead. Second, OpenMLDB provides an online execution engine that resolves
performance bottlenecks caused by long window computations (via
pre-aggregation) and multi-table window unions (via data self-adjusting). It
also provides a high-performance offline execution engine with window parallel
optimization and time-aware data skew resolving. Third, OpenMLDB features a
compact data format and stream-focused indexing to maximize memory usage and
accelerate data access. Evaluations in testing and real workloads reveal
significant performance improvements and resource savings compared to the
baseline systems. The open community of OpenMLDB now has over 150 contributors
and gained 1.6k stars on GitHub.

摘要：<paragraph>高效且一致的特征计算对于广泛的在线机器学习应用至关重要。通常，特征计算分为两个不同的阶段，即用于模型训练的离线阶段和用于模型服务的在线阶段。这些阶段通常依赖于具有不同界面语言和函数实现的执行引擎，从而导致重大不一致。此外，许多在线机器学习特征涉及复杂的时间序列计算（例如，对不同长度表窗口的函数），这不同于标准流和分析查询。现有的数据处理系统（例如，Spark、Flink、DuckDB）通常会为这些计算造成多秒的延迟，这使得它们不适用于需要及时特征更新的实时在线机器学习应用。
本文介绍了 OpenMLDB，这是一个部署在 4Paradigm 的 SageOne 平台和 100 多个真实场景中的特征计算系统。从技术上讲，OpenMLDB 首先采用统一的查询计划生成器，以在离线和在线阶段获得一致的计算结果，从而显著减少特征部署开销。其次，OpenMLDB 提供了一个在线执行引擎，通过预聚合（针对长窗口计算）和多表窗口联合（通过数据自调整）解决了性能瓶颈。它还提供了一个高性能的离线执行引擎，具有窗口并行优化和时间感知数据倾斜解决。第三，OpenMLDB 采用紧凑的数据格式和以流为中心的索引，以最大化内存使用并加速数据访问。在测试和实际工作负载中的评估显示，与基线系统相比，性能有了显著提升，资源也得到了节省。OpenMLDB 的开放社区现在拥有 150 多位贡献者，并在 GitHub 上获得了 1.6k 颗星。</paragraph>

##### **Sound Scene Synthesis at the DCASE 2024 Challenge**
2501.08587v1 by Mathieu Lagrange, Junwon Lee, Modan Tailleur, Laurie M. Heller, Keunwoo Choi, Brian McFee, Keisuke Imoto, Yuki Okamoto

This paper presents Task 7 at the DCASE 2024 Challenge: sound scene
synthesis. Recent advances in sound synthesis and generative models have
enabled the creation of realistic and diverse audio content. We introduce a
standardized evaluation framework for comparing different sound scene synthesis
systems, incorporating both objective and subjective metrics. The challenge
attracted four submissions, which are evaluated using the Fr\'echet Audio
Distance (FAD) and human perceptual ratings. Our analysis reveals significant
insights into the current capabilities and limitations of sound scene synthesis
systems, while also highlighting areas for future improvement in this rapidly
evolving field.

摘要：這篇論文介紹了 DCASE 2024 挑戰中的任務 7：聲音場景合成。聲音合成和生成模型的最新進展使得能夠創造出逼真且多樣化的音訊內容。我們引入了一個標準化的評估架構，用於比較不同的聲音場景合成系統，結合了客觀和主觀的指標。此挑戰吸引了四份提交，這些提交使用 Fr\'echet 音訊距離 (FAD) 和人類感知評分進行評估。我們的分析揭示了對聲音場景合成系統當前能力和限制的重大見解，同時也強調了這個快速發展領域中未來改進的領域。

##### **LoRS: Efficient Low-Rank Adaptation for Sparse Large Language Model**
2501.08582v1 by Yuxuan Hu, Jing Zhang, Xiaodong Chen, Zhe Zhao, Cuiping Li, Hong Chen

Existing low-rank adaptation (LoRA) methods face challenges on sparse large
language models (LLMs) due to the inability to maintain sparsity. Recent works
introduced methods that maintain sparsity by augmenting LoRA techniques with
additional masking mechanisms. Despite these successes, such approaches suffer
from an increased memory and computation overhead, which affects efficiency of
LoRA methods. In response to this limitation, we introduce LoRS, an innovative
method designed to achieve both memory and computation efficiency when
fine-tuning sparse LLMs. To mitigate the substantial memory and computation
demands associated with preserving sparsity, our approach incorporates
strategies of weight recompute and computational graph rearrangement. In
addition, we also improve the effectiveness of LoRS through better adapter
initialization. These innovations lead to a notable reduction in memory and
computation consumption during the fine-tuning phase, all while achieving
performance levels that outperform existing LoRA approaches.

摘要：現有的低秩適應 (LoRA) 方法由於無法維持稀疏性，在稀疏大型語言模型 (LLM) 上面臨挑戰。最近的作品引入了透過使用額外的遮罩機制來擴充 LoRA 技術的方法來維持稀疏性。儘管有這些成功，但這些方法會增加記憶體和運算的開銷，這會影響 LoRA 方法的效率。為了回應這個限制，我們引入了 LoRS，這是一種創新的方法，旨在在微調稀疏 LLM 時同時實現記憶體和運算效率。為了減輕與維持稀疏性相關的龐大記憶體和運算需求，我們的做法結合了權重重新計算和計算圖形重新排列的策略。此外，我們還透過更好的適配器初始化來提高 LoRS 的有效性。這些創新在微調階段顯著減少了記憶體和運算消耗，同時實現了優於現有 LoRA 方法的效能等級。

##### **What Limits LLM-based Human Simulation: LLMs or Our Design?**
2501.08579v1 by Qian Wang, Jiaying Wu, Zhenheng Tang, Bingqiao Luo, Nuo Chen, Wei Chen, Bingsheng He

We argue that advancing LLM-based human simulation requires addressing both
LLM's inherent limitations and simulation framework design challenges. Recent
studies have revealed significant gaps between LLM-based human simulations and
real-world observations, highlighting these dual challenges. To address these
gaps, we present a comprehensive analysis of LLM limitations and our design
issues, proposing targeted solutions for both aspects. Furthermore, we explore
future directions that address both challenges simultaneously, particularly in
data collection, LLM generation, and evaluation. To support further research in
this field, we provide a curated collection of LLM-based human simulation
resources.\footnote{https://github.com/Persdre/llm-human-simulation}

摘要：我們認為，要推進基於 LLM 的人類模擬，需要解決 LLM 本身的限制和模擬框架設計挑戰。最近的研究表明，基於 LLM 的人類模擬與真實世界的觀察之間存在顯著差距，凸顯了這兩個挑戰。為了應對這些差距，我們對 LLM 的限制和我們的設計問題進行了全面的分析，並針對這兩個方面提出了有針對性的解決方案。此外，我們還探討了同時應對這兩個挑戰的未來方向，特別是在數據收集、LLM 生成和評估方面。為了支持該領域的進一步研究，我們提供了一系列經過整理的基於 LLM 的人類模擬資源。\footnote{https://github.com/Persdre/llm-human-simulation}

##### **Information Entropy Invariance: Enhancing Length Extrapolation in Attention Mechanisms**
2501.08570v1 by Kewei Li, Yanwen Kong, Yiping Xu, Lan Huang, Ruochi Zhang, Fengfeng Zhou

Improving the length extrapolation capabilities of Large Language Models
(LLMs) remains a critical challenge in natural language processing. Many recent
efforts have focused on modifying the scaled dot-product attention mechanism,
and often introduce scaled temperatures without rigorous theoretical
justification. To fill this gap, we introduce a novel approach based on
information entropy invariance. We propose two new scaled temperatures to
enhance length extrapolation. First, a training-free method InfoScale is
designed for dot-product attention, and preserves focus on original tokens
during length extrapolation by ensuring information entropy remains consistent.
Second, we theoretically analyze the impact of scaling (CosScale) on cosine
attention. Experimental data demonstrates that combining InfoScale and CosScale
achieves state-of-the-art performance on the GAU-{\alpha} model with a context
window extended to 64 times the training length, and outperforms seven existing
methods. Our analysis reveals that significantly increasing CosScale
approximates windowed attention, and highlights the significance of attention
score dilution as a key challenge in long-range context handling. The code and
data are available at https://github.com/HT-NEKO/InfoScale.

摘要：改善大型語言模型 (LLM) 的長度外推能力仍然是自然語言處理中的一項關鍵挑戰。許多近期的努力都專注於修改縮放點積注意力機制，並且經常在沒有嚴謹理論依據的情況下引入縮放溫度。為了填補這個缺口，我們引入了一種基於資訊熵不變性的新方法。我們提出了兩種新的縮放溫度來增強長度外推。首先，一種免訓練的方法 InfoScale 是為點積注意力設計的，並且在長度外推期間保持對原始標記的關注，方法是確保資訊熵保持一致。其次，我們從理論上分析了縮放 (CosScale) 對餘弦注意力的影響。實驗數據表明，將 InfoScale 和 CosScale 結合使用，在 GAU-{\alpha} 模型上實現了最先進的性能，上下文窗口擴展到訓練長度的 64 倍，並且優於七種現有方法。我們的分析表明，顯著增加 CosScale 近似於視窗注意力，並強調了注意力分數稀釋作為長程上下文處理中的關鍵挑戰。程式碼和資料可在 https://github.com/HT-NEKO/InfoScale 取得。

##### **Towards Lightweight and Stable Zero-shot TTS with Self-distilled Representation Disentanglement**
2501.08566v1 by Qianniu Chen, Xiaoyang Hao, Bowen Li, Yue Liu, Li Lu

Zero-shot Text-To-Speech (TTS) synthesis shows great promise for personalized
voice customization through voice cloning. However, current methods for
achieving zero-shot TTS heavily rely on large model scales and extensive
training datasets to ensure satisfactory performance and generalizability
across various speakers. This raises concerns regarding both deployment costs
and data security. In this paper, we present a lightweight and stable zero-shot
TTS system. We introduce a novel TTS architecture designed to effectively model
linguistic content and various speaker attributes from source speech and prompt
speech, respectively. Furthermore, we present a two-stage self-distillation
framework that constructs parallel data pairs for effectively disentangling
linguistic content and speakers from the perspective of training data.
Extensive experiments show that our system exhibits excellent performance and
superior stability on the zero-shot TTS tasks. Moreover, it shows markedly
superior computational efficiency, with RTFs of 0.13 and 0.012 on the CPU and
GPU, respectively.

摘要：零樣本文字轉語音 (TTS) 合成在透過語音複製技術進行個性化語音自訂方面展現出極佳的潛力。然而，目前達成零樣本 TTS 的方法極度依賴大型模型規模和廣泛的訓練資料集，以確保在各種說話者之間有令人滿意的效能和概括性。這引發了對部署成本和資料安全的疑慮。在本文中，我們提出一個輕量且穩定的零樣本 TTS 系統。我們推出一種創新的 TTS 架構，旨在有效地建構語言內容和各種說話者屬性，分別來自原始語音和提示語音。此外，我們提出一個兩階段的自蒸餾架構，用於建構平行資料對，以有效地從訓練資料的角度解開語言內容和說話者。廣泛的實驗顯示，我們的系統在零樣本 TTS 任務中展現出極佳的效能和優異的穩定性。此外，它展現出顯著優異的運算效率，在 CPU 和 GPU 上的 RTF 分別為 0.13 和 0.012。

##### **ANSR-DT: An Adaptive Neuro-Symbolic Learning and Reasoning Framework for Digital Twins**
2501.08561v1 by Safayat Bin Hakim, Muhammad Adil, Alvaro Velasquez, Houbing Herbert Song

In this paper, we propose an Adaptive Neuro-Symbolic Learning Framework for
digital twin technology called ``ANSR-DT." Our approach combines pattern
recognition algorithms with reinforcement learning and symbolic reasoning to
enable real-time learning and adaptive intelligence. This integration enhances
the understanding of the environment and promotes continuous learning, leading
to better and more effective decision-making in real-time for applications that
require human-machine collaboration. We evaluated the \textit{ANSR-DT}
framework for its ability to learn and adapt to dynamic patterns, observing
significant improvements in decision accuracy, reliability, and
interpretability when compared to existing state-of-the-art methods. However,
challenges still exist in extracting and integrating symbolic rules in complex
environments, which limits the full potential of our framework in heterogeneous
settings. Moreover, our ongoing research aims to address this issue in the
future by ensuring seamless integration of neural models at large. In addition,
our open-source implementation promotes reproducibility and encourages future
research to build on our foundational work.

摘要：在本文中，我们提出一个自适应神经符号学习框架，用于称为 ``ANSR-DT'' 的数字孪生技术。我们的方法将模式识别算法与强化学习和符号推理相结合，以实现实时学习和自适应智能。这种集成增强了对环境的理解并促进了持续学习，从而在需要人机协作的应用中实时做出更好、更有效的决策。我们评估了 \textit{ANSR-DT} 框架学习和适应动态模式的能力，与现有的最先进方法相比，观察到决策准确性、可靠性和可解释性的显着提高。然而，在复杂环境中提取和集成符号规则仍然存在挑战，这限制了我们在异构环境中框架的全部潜力。此外，我们正在进行的研究旨在通过确保神经模型的大规模无缝集成，在未来解决此问题。此外，我们的开源实现促进了可重复性，并鼓励未来的研究建立在我们的基础工作之上。

##### **LAMS: LLM-Driven Automatic Mode Switching for Assistive Teleoperation**
2501.08558v1 by Yiran Tao, Jehan Yang, Dan Ding, Zackory Erickson

Teleoperating high degrees-of-freedom (DoF) robotic manipulators via low-DoF
controllers like joysticks often requires frequent switching between control
modes, where each mode maps controller movements to specific robot actions.
Manually performing this frequent switching can make teleoperation cumbersome
and inefficient. On the other hand, existing automatic mode-switching
solutions, such as heuristic-based or learning-based methods, are often
task-specific and lack generalizability. In this paper, we introduce LLM-Driven
Automatic Mode Switching (LAMS), a novel approach that leverages Large Language
Models (LLMs) to automatically switch control modes based on task context.
Unlike existing methods, LAMS requires no prior task demonstrations and
incrementally improves by integrating user-generated mode-switching examples.
We validate LAMS through an ablation study and a user study with 10
participants on complex, long-horizon tasks, demonstrating that LAMS
effectively reduces manual mode switches, is preferred over alternative
methods, and improves performance over time. The project website with
supplementary materials is at https://lams-assistance.github.io/.

摘要：透過低自由度 (DoF) 控制器（如操縱桿）遠端操作高自由度機器人機械手，通常需要在控制模式之間頻繁切換，其中每個模式將控制器移動對應到特定的機器人動作。手動執行這種頻繁切換會使遠端操作變得繁瑣且低效率。另一方面，現有的自動模式切換解決方案（例如基於啟發式或基於學習的方法）通常是特定於任務的，並且缺乏普遍性。在本文中，我們介紹了 LLM 驅動的自動模式切換 (LAMS)，這是一種新穎的方法，利用大型語言模型 (LLM) 根據任務上下文自動切換控制模式。與現有方法不同，LAMS 不需要先前的任務演示，並且通過整合使用者產生的模式切換範例來逐步改進。我們透過消融研究和與 10 位參與者進行的使用者研究驗證了 LAMS 在複雜、長時程任務上的表現，證明 LAMS 有效減少了手動模式切換，優於其他方法，並且隨著時間推移而提升效能。包含補充資料的專案網站位於 https://lams-assistance.github.io/。

##### **The Devil is in Temporal Token: High Quality Video Reasoning Segmentation**
2501.08549v1 by Sitong Gong, Yunzhi Zhuge, Lu Zhang, Zongxin Yang, Pingping Zhang, Huchuan Lu

Existing methods for Video Reasoning Segmentation rely heavily on a single
special token to represent the object in the keyframe or the entire video,
inadequately capturing spatial complexity and inter-frame motion. To overcome
these challenges, we propose VRS-HQ, an end-to-end video reasoning segmentation
approach that leverages Multimodal Large Language Models (MLLMs) to inject rich
spatiotemporal features into hierarchical tokens.Our key innovations include a
Temporal Dynamic Aggregation (TDA) and a Token-driven Keyframe Selection (TKS).
Specifically, we design frame-level <SEG> and temporal-level <TAK> tokens that
utilize MLLM's autoregressive learning to effectively capture both local and
global information. Subsequently, we apply a similarity-based weighted fusion
and frame selection strategy, then utilize SAM2 to perform keyframe
segmentation and propagation. To enhance keyframe localization accuracy, the
TKS filters keyframes based on SAM2's occlusion scores during inference. VRS-HQ
achieves state-of-the-art performance on ReVOS, surpassing VISA by
5.9%/12.5%/9.1% in J&F scores across the three subsets. These results highlight
the strong temporal reasoning and segmentation capabilities of our method. Code
and model weights will be released at VRS-HQ.

摘要：現有的影片推理分割方法過度依賴單一特殊符號來表示關鍵影格或整個影片中的物件，無法充分捕捉空間複雜度和影格間的動作。為了克服這些挑戰，我們提出 VRS-HQ，一種端對端的影片推理分割方法，利用多模態大型語言模型 (MLLM) 將豐富的時空特徵注入分層符號。我們的關鍵創新包括時序動態聚合 (TDA) 和符號驅動關鍵影格選擇 (TKS)。具體來說，我們設計了影格層級的 <SEG> 和時序層級的 <TAK> 符號，利用 MLLM 的自迴歸學習來有效捕捉局部和全域資訊。隨後，我們應用基於相似性的加權融合和影格選擇策略，然後利用 SAM2 來執行關鍵影格分割和傳播。為了增強關鍵影格定位的準確度，TKS 在推論期間根據 SAM2 的遮擋分數過濾關鍵影格。VRS-HQ 在 ReVOS 上取得最先進的效能，在三個子集中以 J&F 分數超越 VISA 5.9%/12.5%/9.1%。這些結果突顯了我們方法強大的時序推理和分割能力。程式碼和模型權重將在 VRS-HQ 發布。

##### **Knowledge prompt chaining for semantic modeling**
2501.08540v1 by Ning Pei Ding, Jingge Du, Zaiwen Feng

The task of building semantics for structured data such as CSV, JSON, and XML
files is highly relevant in the knowledge representation field. Even though we
have a vast of structured data on the internet, mapping them to domain
ontologies to build semantics for them is still very challenging as it requires
the construction model to understand and learn graph-structured knowledge.
Otherwise, the task will require human beings' effort and cost. In this paper,
we proposed a novel automatic semantic modeling framework: Knowledge Prompt
Chaining. It can serialize the graph-structured knowledge and inject it into
the LLMs properly in a Prompt Chaining architecture. Through this knowledge
injection and prompting chaining, the model in our framework can learn the
structure information and latent space of the graph and generate the semantic
labels and semantic graphs following the chains' insturction naturally. Based
on experimental results, our method achieves better performance than existing
leading techniques, despite using reduced structured input data.

摘要：在知識表示領域中，為結構化資料（例如 CSV、JSON 和 XML 檔案）建立語意的任務非常重要。儘管網路上有大量的結構化資料，但將它們對應到領域本体以建立語意仍然非常具有挑戰性，因為這需要建構模型來理解和學習圖形結構的知識。否則，此任務將需要人類的努力和成本。在本文中，我們提出了一個新穎的自動語義建模框架：知識提示鏈接。它可以序列化圖形結構的知識，並適當地將其注入到提示鏈接架構中的 LLM 中。透過這種知識注入和提示鏈接，我們框架中的模型可以學習圖形的結構資訊和潛在空間，並自然地遵循鏈接的指示來產生語義標籤和語義圖。根據實驗結果，儘管使用減少的結構化輸入資料，但我們的方法仍比現有的領先技術獲得更好的效能。

##### **Complexity Control Facilitates Reasoning-Based Compositional Generalization in Transformers**
2501.08537v1 by Zhongwang Zhang, Pengxiao Lin, Zhiwei Wang, Yaoyu Zhang, Zhi-Qin John Xu

Transformers have demonstrated impressive capabilities across various tasks,
yet their performance on compositional problems remains a subject of debate. In
this study, we investigate the internal mechanisms underlying Transformers'
behavior in compositional tasks. We find that complexity control strategies
significantly influence whether the model learns primitive-level rules that
generalize out-of-distribution (reasoning-based solutions) or relies solely on
memorized mappings (memory-based solutions). By applying masking strategies to
the model's information circuits and employing multiple complexity metrics, we
reveal distinct internal working mechanisms associated with different solution
types. Further analysis reveals that reasoning-based solutions exhibit a lower
complexity bias, which aligns with the well-studied neuron condensation
phenomenon. This lower complexity bias is hypothesized to be the key factor
enabling these solutions to learn reasoning rules. We validate these
conclusions across multiple real-world datasets, including image generation and
natural language processing tasks, confirming the broad applicability of our
findings.

摘要：變形金剛在各種任務中展現出令人印象深刻的能力，
但它們在組合問題上的表現仍有爭議。在
本研究中，我們探討了變形金剛在組合任務中的行為背後的基本機制。我們發現複雜性控制策略
顯著影響模型是否學習原始級別的規則，這些規則概括了分布外（基於推理的解決方案）或僅依賴
記憶映射（基於記憶的解決方案）。通過對
模型的信息電路應用屏蔽策略並採用多個複雜性指標，我們
揭示了與不同解決方案類型相關的不同內部工作機制。進一步的分析表明，基於推理的解決方案表現出較低的
複雜性偏差，這與研究充分的神經元凝聚現象一致。假設這種較低的複雜性偏差是
使這些解決方案能夠學習推理規則的關鍵因素。我們驗證了這些
結論跨多個真實世界數據集，包括圖像生成和自然語言處理任務，確認了我們
發現的廣泛適用性。

##### **Dynamic Portfolio Optimization via Augmented DDPG with Quantum Price Levels-Based Trading Strategy**
2501.08528v1 by Runsheng Lin, Zihan Xing, Mingze Ma, Raymond S. T. Lee

With the development of deep learning, Dynamic Portfolio Optimization (DPO)
problem has received a lot of attention in recent years, not only in the field
of finance but also in the field of deep learning. Some advanced research in
recent years has proposed the application of Deep Reinforcement Learning (DRL)
to the DPO problem, which demonstrated to be more advantageous than supervised
learning in solving the DPO problem. However, there are still certain unsolved
issues: 1) DRL algorithms usually have the problems of slow learning speed and
high sample complexity, which is especially problematic when dealing with
complex financial data. 2) researchers use DRL simply for the purpose of
obtaining high returns, but pay little attention to the problem of risk control
and trading strategy, which will affect the stability of model returns. In
order to address these issues, in this study we revamped the intrinsic
structure of the model based on the Deep Deterministic Policy Gradient (DDPG)
and proposed the Augmented DDPG model. Besides, we also proposed an innovative
risk control strategy based on Quantum Price Levels (QPLs) derived from Quantum
Finance Theory (QFT). Our experimental results revealed that our model has
better profitability as well as risk control ability with less sample
complexity in the DPO problem compared to the baseline models.

摘要：<paragraph>隨著深度學習的發展，動態投資組合最佳化（DPO）問題近年來受到廣泛關注，不僅在金融領域，也在深度學習領域。近年來一些進階的研究提出將深度強化學習（DRL）應用於 DPO 問題，證明比監督式學習在解決 DPO 問題上更有優勢。然而，仍存在一些未解決的問題：1）DRL 演算法通常有學習速度慢、樣本複雜度高的問題，特別是在處理複雜的金融資料時會出現問題。2）研究人員使用 DRL 僅僅是為了獲得高報酬，但較少關注風險控管和交易策略的問題，這將影響模型報酬的穩定性。為了解決這些問題，本研究以深度確定性策略梯度（DDPG）為基礎，改造了模型的內在結構，並提出了擴增 DDPG 模型。此外，我們還提出了一種創新的風險控管策略，該策略基於量子金融理論（QFT）衍生的量子價格水準（QPL）。我們的實驗結果顯示，與基線模型相比，我們的模型在 DPO 問題上具有更好的獲利能力和風險控管能力，且樣本複雜度較低。</paragraph>

##### **Doc-Guided Sent2Sent++: A Sent2Sent++ Agent with Doc-Guided memory for Document-level Machine Translation**
2501.08523v1 by Jiaxin Guo, Yuanchang Luo, Daimeng Wei, Ling Zhang, Zongyao Li, Hengchao Shang, Zhiqiang Rao, Shaojun Li, Jinlong Yang, Zhanglin Wu, Hao Yang

The field of artificial intelligence has witnessed significant advancements
in natural language processing, largely attributed to the capabilities of Large
Language Models (LLMs). These models form the backbone of Agents designed to
address long-context dependencies, particularly in Document-level Machine
Translation (DocMT). DocMT presents unique challenges, with quality,
consistency, and fluency being the key metrics for evaluation. Existing
approaches, such as Doc2Doc and Doc2Sent, either omit sentences or compromise
fluency. This paper introduces Doc-Guided Sent2Sent++, an Agent that employs an
incremental sentence-level forced decoding strategy \textbf{to ensure every
sentence is translated while enhancing the fluency of adjacent sentences.} Our
Agent leverages a Doc-Guided Memory, focusing solely on the summary and its
translation, which we find to be an efficient approach to maintaining
consistency. Through extensive testing across multiple languages and domains,
we demonstrate that Sent2Sent++ outperforms other methods in terms of quality,
consistency, and fluency. The results indicate that, our approach has achieved
significant improvements in metrics such as s-COMET, d-COMET, LTCR-$1_f$, and
document-level perplexity (d-ppl). The contributions of this paper include a
detailed analysis of current DocMT research, the introduction of the
Sent2Sent++ decoding method, the Doc-Guided Memory mechanism, and validation of
its effectiveness across languages and domains.

摘要：人工智能领域见证了自然语言处理的重大进展，这在很大程度上归功于大型语言模型 (LLM) 的能力。这些模型构成了代理的基础，旨在解决长上下文依赖性，尤其是在文档级机器翻译 (DocMT) 中。DocMT 呈现出独特的挑战，其中质量、一致性和流畅性是评估的关键指标。现有的方法，例如 Doc2Doc 和 Doc2Sent，要么省略句子，要么影响流畅性。本文介绍了 Doc-Guided Sent2Sent++，这是一个采用增量句子级强制解码策略的代理，以确保翻译每个句子，同时增强相邻句子的流畅性。我们的代理利用 Doc-Guided Memory，仅关注摘要及其翻译，我们发现这是一种保持一致性的有效方法。通过跨多个语言和领域的广泛测试，我们证明 Sent2Sent++ 在质量、一致性和流畅性方面优于其他方法。结果表明，我们的方法在 s-COMET、d-COMET、LTCR-$1_f$ 和文档级困惑度 (d-ppl) 等指标方面取得了显着改进。本文的贡献包括对当前 DocMT 研究的详细分析、Sent2Sent++ 解码方法的介绍、Doc-Guided Memory 机制，以及跨语言和领域的有效性验证。

##### **Mitigating Domain Shift in Federated Learning via Intra- and Inter-Domain Prototypes**
2501.08521v1 by Huy Q. Le, Ye Lin Tun, Yu Qiao, Minh N. H. Nguyen, Keon Oh Kim, Choong Seon Hong

Federated Learning (FL) has emerged as a decentralized machine learning
technique, allowing clients to train a global model collaboratively without
sharing private data. However, most FL studies ignore the crucial challenge of
heterogeneous domains where each client has a distinct feature distribution,
which is common in real-world scenarios. Prototype learning, which leverages
the mean feature vectors within the same classes, has become a prominent
solution for federated learning under domain skew. However, existing federated
prototype learning methods only consider inter-domain prototypes on the server
and overlook intra-domain characteristics. In this work, we introduce a novel
federated prototype learning method, namely I$^2$PFL, which incorporates
$\textbf{I}$ntra-domain and $\textbf{I}$nter-domain $\textbf{P}$rototypes, to
mitigate domain shifts and learn a generalized global model across multiple
domains in federated learning. To construct intra-domain prototypes, we propose
feature alignment with MixUp-based augmented prototypes to capture the
diversity of local domains and enhance the generalization of local features.
Additionally, we introduce a reweighting mechanism for inter-domain prototypes
to generate generalized prototypes to provide inter-domain knowledge and reduce
domain skew across multiple clients. Extensive experiments on the Digits,
Office-10, and PACS datasets illustrate the superior performance of our method
compared to other baselines.

摘要：聯邦學習 (FL) 已成為一種分散式機器學習技術，允許客戶在不共用私人資料的情況下，協同訓練全球模型。然而，大多數 FL 研究忽略了異質網域的關鍵挑戰，其中每個客戶端都有不同的特徵分布，這在現實世界場景中很常見。原型學習利用相同類別中的平均特徵向量，已成為在網域偏差下進行聯邦學習的傑出解決方案。然而，現有的聯邦原型學習方法僅考慮伺服器上的網域間原型，而忽略了網域內特徵。在這項工作中，我們引入了一種新的聯邦原型學習方法，即 I$^2$PFL，它結合了網域內和網域間原型，以減輕網域轉移，並在聯邦學習中跨多個網域學習廣義的全球模型。為了建構網域內原型，我們提出使用基於 MixUp 的擴充原型的特徵比對，以擷取本地網域的多樣性，並增強本地特徵的概括性。此外，我們為網域間原型引入了一個重新加權機制，以產生廣義原型，以提供網域間知識並減少多個客戶端之間的網域偏差。在 Digits、Office-10 和 PACS 資料集上的廣泛實驗說明了我們的方法與其他基線相比具有優異的效能。

##### **Exploring the Efficacy of Meta-Learning: Unveiling Superior Data Diversity Utilization of MAML Over Pre-training**
2501.08506v1 by Kavita Selva, Satita Vittayaareekul, Brando Miranda

Currently, data and model size dominate the narrative in the training of
super-large, powerful models. However, there has been a lack of exploration on
the effect of other attributes of the training dataset on model performance. We
hypothesize that dataset diversity can impact the performance of vision models.
Our study shows positive correlations between test set accuracy and data
diversity, providing an argument for furthering the research of dataset
attributes beyond size. We analyzed pre-training and model-agnostic
meta-learning methods on twelve popular visual datasets (e.g., Omniglot,
CIFAR-FS, Aircraft) and five model configurations, including MAML variants with
different numbers of inner gradient steps and supervised learning. We show
moderate to strong positive correlations (R-squared: 0.15-0.42) between
accuracy and data diversity and weaker but significant correlations (R-squared:
~0.2) between loss and diversity. These findings support our hypothesis and
demonstrate a promising way for a deeper exploration of how formal data
diversity influences model performance. This initial study highlights the
potential of (Task2Vec) data diversity as a valuable measure in the rapidly
evolving field of large-scale learning and emphasizes that understanding the
dataset is key to building more powerful and generalizable models.

摘要：目前，資料和模型大小主導了超級大型、強大模型的訓練敘述。然而，對於訓練資料集的其他屬性對模型效能的影響，一直缺乏探討。我們假設資料集的多樣性會影響視覺模型的效能。我們的研究顯示測試集準確度和資料多樣性之間存在正相關，這為進一步研究資料集屬性（不只大小）提供了論據。我們分析了十二個流行的視覺資料集（例如 Omniglot、CIFAR-FS、Aircraft）和五種模型組態（包括具有不同內部梯度步驟數的 MAML 變體和監督式學習）上的預訓練和與模型無關的元學習方法。我們顯示準確度和資料多樣性之間存在中等至強烈的正相關（R 平方：0.15-0.42），損失和多樣性之間存在較弱但顯著的相關性（R 平方：~0.2）。這些發現支持我們的假設，並展示了一種有前途的方法，可以更深入地探討正式資料多樣性如何影響模型效能。這項初步研究突顯了（Task2Vec）資料多樣性作為快速發展的大規模學習領域中一項有價值的衡量標準的潛力，並強調了解資料集是建構更強大且更具泛化性的模型的關鍵。

##### **Adapting Whisper for Regional Dialects: Enhancing Public Services for Vulnerable Populations in the United Kingdom**
2501.08502v1 by Melissa Torgbi, Andrew Clayman, Jordan J. Speight, Harish Tayyar Madabushi

We collect novel data in the public service domain to evaluate the capability
of the state-of-the-art automatic speech recognition (ASR) models in capturing
regional differences in accents in the United Kingdom (UK), specifically
focusing on two accents from Scotland with distinct dialects. This study
addresses real-world problems where biased ASR models can lead to
miscommunication in public services, disadvantaging individuals with regional
accents particularly those in vulnerable populations. We first examine the
out-of-the-box performance of the Whisper large-v3 model on a baseline dataset
and our data. We then explore the impact of fine-tuning Whisper on the
performance in the two UK regions and investigate the effectiveness of existing
model evaluation techniques for our real-world application through manual
inspection of model errors. We observe that the Whisper model has a higher word
error rate (WER) on our test datasets compared to the baseline data and
fine-tuning on a given data improves performance on the test dataset with the
same domain and accent. The fine-tuned models also appear to show improved
performance when applied to the test data outside of the region it was trained
on suggesting that fine-tuned models may be transferable within parts of the
UK. Our manual analysis of model outputs reveals the benefits and drawbacks of
using WER as an evaluation metric and fine-tuning to adapt to regional
dialects.

摘要：我們在公共服務領域收集新穎數據，以評估最先進的自動語音辨識 (ASR) 模型在捕捉英國區域口音差異的能力，特別專注於蘇格蘭兩個具有不同方言的口音。這項研究探討了現實世界中的問題，其中有偏差的 ASR 模型可能導致公共服務中的溝通不良，特別是對弱勢群體中具有區域口音的個人造成不利影響。我們首先檢查 Whisper large-v3 模型在基線數據集和我們數據上的開箱即用效能。然後，我們探討微調 Whisper 對英國兩個地區效能的影響，並透過手動檢查模型錯誤來探討現有模型評估技術對我們現實世界應用程式的有效性。我們觀察到，與基線數據相比，Whisper 模型在我們的測試數據集上具有較高的字元錯誤率 (WER)，並且在特定數據上進行微調會改善具有相同領域和口音的測試數據集上的效能。微調後的模型在應用於訓練區域以外的測試數據時，似乎也顯示出改善的效能，這表明微調後的模型可能可以在英國部分地區轉移。我們對模型輸出的手動分析揭示了使用 WER 作為評估指標和微調以適應區域方言的優缺點。

##### **Quantifying the Importance of Data Alignment in Downstream Model Performance**
2501.08496v1 by Krrish Chawla, Aryan Sahai, Mario DePavia, Sudharsan Sundar, Brando Miranda

Contrary to the conventional emphasis on dataset size, we explore the role of
data alignment -- an often overlooked aspect of data quality -- in training
capable Large Language Models (LLMs). To do so, we use the Task2Vec-based
alignment coefficient, a quantitative measure of the similarity between two
datasets, to quantify the impact of alignment between training data and
evaluation data on downstream performance. In particular, we conduct controlled
\textit{interventional} experiments for two settings: 1. the impact of
increased alignment coefficients between various pre-training (pt) against
evaluation datasets, and 2. the impact of increased alignment coefficients
between domain specific fine-tuning (ft) against domain specific evaluation.
The domain specific task we explore is Autoformalization -- the machine
translation task between natural language and code for formal verification. In
both settings, we find a strong, predictable negative correlation between the
alignment coefficient of a model's training and evaluation data and the model's
loss/perplexity on the respective downstream task. These findings suggest a
re-evaluation of LLM training approaches, demonstrating the relevance of data
alignment compared to data quantity, especially in specialized downstream tasks
such as Autoformalization.

摘要：與傳統強調資料集大小相反，我們探討資料對齊的角色 - 資料品質中經常被忽略的層面 - 在訓練大型語言模型 (LLM) 中。為此，我們使用基於 Task2Vec 的對齊係數，這是衡量兩個資料集相似性的量化指標，用於量化訓練資料和評估資料之間的對齊對下游效能的影響。特別是，我們針對兩種設定進行受控的「介入」實驗：1. 各種預訓練 (pt) 與評估資料集之間增加對齊係數的影響，以及 2. 領域特定微調 (ft) 與領域特定評估之間增加對齊係數的影響。我們探討的領域特定任務是自動形式化 - 自然語言與程式碼之間的機器翻譯，用於形式驗證。在這兩種設定中，我們發現模型訓練和評估資料的對齊係數與模型在各自下游任務上的損失/困惑度之間存在強烈的、可預測的負相關。這些發現表明重新評估 LLM 訓練方法，證明資料對齊與資料量相比具有相關性，特別是在自動形式化等專業的下游任務中。

##### **Benchmarking Classical, Deep, and Generative Models for Human Activity Recognition**
2501.08471v1 by Md Meem Hossain, The Anh Han, Safina Showkat Ara, Zia Ush Shamszaman

Human Activity Recognition (HAR) has gained significant importance with the
growing use of sensor-equipped devices and large datasets. This paper evaluates
the performance of three categories of models : classical machine learning,
deep learning architectures, and Restricted Boltzmann Machines (RBMs) using
five key benchmark datasets of HAR (UCI-HAR, OPPORTUNITY, PAMAP2, WISDM, and
Berkeley MHAD). We assess various models, including Decision Trees, Random
Forests, Convolutional Neural Networks (CNN), and Deep Belief Networks (DBNs),
using metrics such as accuracy, precision, recall, and F1-score for a
comprehensive comparison. The results show that CNN models offer superior
performance across all datasets, especially on the Berkeley MHAD. Classical
models like Random Forest do well on smaller datasets but face challenges with
larger, more complex data. RBM-based models also show notable potential,
particularly for feature learning. This paper offers a detailed comparison to
help researchers choose the most suitable model for HAR tasks.

摘要：人類活動辨識 (HAR) 隨著配備感測器裝置和大型資料集的使用日益普及，變得越來越重要。本文評估了三種類別模型的效能：傳統機器學習、深度學習架構和受限玻爾茲曼機 (RBM)，使用五個 HAR 主要基準資料集 (UCI-HAR、OPPORTUNITY、PAMAP2、WISDM 和 Berkeley MHAD)。我們評估了各種模型，包括決策樹、隨機森林、卷積神經網路 (CNN) 和深度信念網路 (DBN)，使用準確度、精確度、召回率和 F1 分數等指標進行全面比較。結果顯示 CNN 模型在所有資料集上都提供優異的效能，特別是在 Berkeley MHAD 上。隨機森林等傳統模型在較小的資料集上表現良好，但面對較大、較複雜的資料時會面臨挑戰。基於 RBM 的模型也展現了顯著的潛力，特別是在特徵學習方面。本文提供了詳細的比較，以協助研究人員選擇最適合 HAR 任務的模型。

##### **Detecting Contextual Anomalies by Discovering Consistent Spatial Regions**
2501.08470v1 by Zhengye Yang, Richard J. Radke

We describe a method for modeling spatial context to enable video anomaly
detection. The main idea is to discover regions that share similar object-level
activities by clustering joint object attributes using Gaussian mixture models.
We demonstrate that this straightforward approach, using orders of magnitude
fewer parameters than competing models, achieves state-of-the-art performance
in the challenging spatial-context-dependent Street Scene dataset. As a side
benefit, the high-resolution discovered regions learned by the model also
provide explainable normalcy maps for human operators without the need for any
pre-trained segmentation model.

摘要：我們描述了一種對空間背景建模的方法，以實現影片異常偵測。主要概念是透過使用高斯混合模型對關節物件屬性進行分群，找出共享類似物件級別活動的區域。我們證明了這種直接的方法，使用比競爭模型少幾個數量級的參數，在具有挑戰性的空間背景依賴性街景資料集上，達到了最先進的效能。作為額外的優點，模型所學到的高解析度發現區域，也為人類操作員提供了可解釋的常態地圖，而無需任何預先訓練的分段模型。

##### **Selective Attention Merging for low resource tasks: A case study of Child ASR**
2501.08468v1 by Natarajan Balaji Shankar, Zilai Wang, Eray Eren, Abeer Alwan

While Speech Foundation Models (SFMs) excel in various speech tasks, their
performance for low-resource tasks such as child Automatic Speech Recognition
(ASR) is hampered by limited pretraining data. To address this, we explore
different model merging techniques to leverage knowledge from models trained on
larger, more diverse speech corpora. This paper also introduces Selective
Attention (SA) Merge, a novel method that selectively merges task vectors from
attention matrices to enhance SFM performance on low-resource tasks.
Experiments on the MyST database show significant reductions in relative word
error rate of up to 14%, outperforming existing model merging and data
augmentation techniques. By combining data augmentation techniques with SA
Merge, we achieve a new state-of-the-art WER of 8.69 on the MyST database for
the Whisper-small model, highlighting the potential of SA Merge for improving
low-resource ASR.

摘要：雖然語音基礎模型 (SFM) 在各種語音任務中表現出色，但它們在低資源任務（例如兒童自動語音辨識 (ASR)）中的表現受到預訓練數據有限的阻礙。為了解決這個問題，我們探索了不同的模型合併技術，以利用在更大、更多樣化的語音語料庫上訓練模型的知識。本文還介紹了選擇性注意 (SA) 合併，這是一種創新的方法，可以選擇性地合併來自注意矩陣的任務向量，以增強 SFM 在低資源任務上的效能。在 MyST 資料庫上的實驗顯示，相對字錯誤率顯著降低，最高達 14%，優於現有的模型合併和資料擴充技術。透過將資料擴充技術與 SA 合併結合，我們在 MyST 資料庫上為 Whisper-small 模型達到了 8.69 的新最先進 WER，突顯了 SA 合併在改善低資源 ASR 方面的潛力。

##### **Towards Zero-Shot & Explainable Video Description by Reasoning over Graphs of Events in Space and Time**
2501.08460v1 by Mihai Masala, Marius Leordeanu

In the current era of Machine Learning, Transformers have become the de facto
approach across a variety of domains, such as computer vision and natural
language processing. Transformer-based solutions are the backbone of current
state-of-the-art methods for language generation, image and video
classification, segmentation, action and object recognition, among many others.
Interestingly enough, while these state-of-the-art methods produce impressive
results in their respective domains, the problem of understanding the
relationship between vision and language is still beyond our reach. In this
work, we propose a common ground between vision and language based on events in
space and time in an explainable and programmatic way, to connect
learning-based vision and language state of the art models and provide a
solution to the long standing problem of describing videos in natural language.
We validate that our algorithmic approach is able to generate coherent, rich
and relevant textual descriptions on videos collected from a variety of
datasets, using both standard metrics (e.g. Bleu, ROUGE) and the modern
LLM-as-a-Jury approach.

摘要：在機器學習的當代，Transformer 已成為各種領域的事實標準方法，例如電腦視覺和自然語言處理。基於 Transformer 的解決方案是當前語言生成、影像和影片分類、分割、動作和物件辨識等最新方法的骨幹。有趣的是，雖然這些最新方法在其各自的領域中產生令人印象深刻的結果，但理解視覺和語言之間關係的問題仍然超出了我們的理解範圍。在這項工作中，我們以可解釋且以程式為基礎的方式，在時空中的事件之間提出了視覺和語言的共同基礎，以連接基於學習的視覺和語言最新模型，並提供描述影片的自然語言長期問題的解決方案。我們驗證了我們的演算法方法能夠在從各種資料集收集的影片中產生連貫、豐富且相關的文字描述，同時使用標準指標（例如 Bleu、ROUGE）和現代 LLM 作為評審方法。

##### **Large Language Models For Text Classification: Case Study And Comprehensive Review**
2501.08457v1 by Arina Kostina, Marios D. Dikaiakos, Dimosthenis Stefanidis, George Pallis

Unlocking the potential of Large Language Models (LLMs) in data
classification represents a promising frontier in natural language processing.
In this work, we evaluate the performance of different LLMs in comparison with
state-of-the-art deep-learning and machine-learning models, in two different
classification scenarios: i) the classification of employees' working locations
based on job reviews posted online (multiclass classification), and 2) the
classification of news articles as fake or not (binary classification). Our
analysis encompasses a diverse range of language models differentiating in
size, quantization, and architecture. We explore the impact of alternative
prompting techniques and evaluate the models based on the weighted F1-score.
Also, we examine the trade-off between performance (F1-score) and time
(inference response time) for each language model to provide a more nuanced
understanding of each model's practical applicability. Our work reveals
significant variations in model responses based on the prompting strategies. We
find that LLMs, particularly Llama3 and GPT-4, can outperform traditional
methods in complex classification tasks, such as multiclass classification,
though at the cost of longer inference times. In contrast, simpler ML models
offer better performance-to-time trade-offs in simpler binary classification
tasks.

摘要：利用大型語言模型 (LLM) 在資料分類中的潛力，代表了自然語言處理中一個有前途的新領域。在這項工作中，我們評估了不同 LLM 的效能，並與最先進的深度學習和機器學習模型進行比較，在兩種不同的分類情境中：一）根據在網路上發布的工作評論，對員工的工作地點進行分類（多類分類），以及二）將新聞文章分類為真或假（二元分類）。我們的分析涵蓋了各種語言模型，它們在大小、量化和架構上有所不同。我們探討了替代提示技術的影響，並根據加權 F1 分數評估模型。此外，我們針對每個語言模型探討效能（F1 分數）和時間（推論回應時間）之間的權衡，以提供對每個模型實用性的更細緻理解。我們的研究揭示了基於提示策略的模型回應的顯著差異。我們發現，LLM，特別是 Llama3 和 GPT-4，可以在複雜的分類任務中優於傳統方法，例如多類分類，儘管代價是推論時間較長。相比之下，較簡單的 ML 模型在較簡單的二元分類任務中提供了更好的效能時間權衡。

##### **Tag&Tab: Pretraining Data Detection in Large Language Models Using Keyword-Based Membership Inference Attack**
2501.08454v1 by Sagiv Antebi, Edan Habler, Asaf Shabtai, Yuval Elovici

Large language models (LLMs) have become essential digital task assistance
tools. Their training relies heavily on the collection of vast amounts of data,
which may include copyright-protected or sensitive information. Recent studies
on the detection of pretraining data in LLMs have primarily focused on
sentence-level or paragraph-level membership inference attacks (MIAs), usually
involving probability analysis of the target model prediction tokens. However,
the proposed methods often demonstrate poor performance, specifically in terms
of accuracy, failing to account for the semantic importance of textual content
and word significance. To address these shortcomings, we propose Tag&Tab, a
novel approach for detecting data that has been used as part of the LLM
pretraining. Our method leverages advanced natural language processing (NLP)
techniques to tag keywords in the input text - a process we term Tagging. Then,
the LLM is used to obtain the probabilities of these keywords and calculate
their average log-likelihood to determine input text membership, a process we
refer to as Tabbing. Our experiments on three benchmark datasets (BookMIA,
MIMIR, and the Pile) and several open-source LLMs of varying sizes demonstrate
an average increase in the AUC scores ranging from 4.1% to 12.1% over
state-of-the-art methods. Tag&Tab not only sets a new standard for data leakage
detection in LLMs, but its outstanding performance is a testament to the
importance of words in MIAs on LLMs.

摘要：大型語言模型 (LLM) 已成為重要的數位工作輔助工具。其訓練仰賴大量資料的蒐集，其中可能包含受著作權保護或敏感的資訊。近期關於 LLM 中預訓練資料偵測的研究，主要集中在句子層級或段落層級的成員身分推論攻擊 (MIA)，通常涉及目標模型預測權杖的機率分析。然而，提出的方法經常展現不佳的效能，特別是在準確度方面，無法考量文字內容的語意重要性與字詞意義。為了解決這些缺點，我們提出 Tag&Tab，一種用於偵測資料是否曾用於 LLM 預訓練的新方法。我們的做法利用進階自然語言處理 (NLP) 技術，標記輸入文字中的關鍵字，這個程序稱之為標記。接著，使用 LLM 取得這些關鍵字的機率，並計算其平均對數似然值，以判定輸入文字的成員身分，這個程序我們稱之為標籤化。我們針對三個基準資料集 (BookMIA、MIMIR 和 Pile) 進行實驗，以及數個不同大小的開源 LLM，結果顯示與現有技術相比，AUC 分數平均提升 4.1% 至 12.1%。Tag&Tab 不僅為 LLM 中的資料外洩偵測樹立新標準，其傑出的效能也證明了字詞在針對 LLM 進行 MIA 的重要性。

##### **Active Sampling for Node Attribute Completion on Graphs**
2501.08450v1 by Benyuan Liu, Xu Chen, Yanfeng Wang, Ya Zhang, Zhi Cao, Ivor Tsang

Node attribute, a type of crucial information for graph analysis, may be
partially or completely missing for certain nodes in real world applications.
Restoring the missing attributes is expected to benefit downstream graph
learning. Few attempts have been made on node attribute completion, but a novel
framework called Structure-attribute Transformer (SAT) was recently proposed by
using a decoupled scheme to leverage structures and attributes. SAT ignores the
differences in contributing to the learning schedule and finding a practical
way to model the different importance of nodes with observed attributes is
challenging. This paper proposes a novel AcTive Sampling algorithm (ATS) to
restore missing node attributes. The representativeness and uncertainty of each
node's information are first measured based on graph structure, representation
similarity and learning bias. To select nodes as train samples in the next
optimization step, a weighting scheme controlled by Beta distribution is then
introduced to linearly combine the two properties. Extensive experiments on
four public benchmark datasets and two downstream tasks have shown the
superiority of ATS in node attribute completion.

摘要：節點屬性是圖形分析中的一種關鍵資訊類型，在現實世界的應用中，某些節點的部分或全部屬性可能遺失。修復遺失的屬性預期將有利於下游圖形學習。很少有人嘗試完成節點屬性，但最近提出了一個稱為結構屬性轉換器 (SAT) 的新穎架構，它使用解耦方案來利用結構和屬性。SAT 忽略了對學習時間表的貢獻差異，並且尋找一種實際的方法來建模具有觀察屬性的節點的不同重要性具有挑戰性。本文提出了一種新穎的積極取樣演算法 (ATS) 來修復遺失的節點屬性。首先根據圖形結構、表示相似性和學習偏差來衡量每個節點資訊的代表性和不確定性。為了在下一優化步驟中選擇節點作為訓練樣本，然後引入由 Beta 分布控制的加權方案來線性組合這兩個屬性。在四個公共基準資料集和兩個下游任務上的大量實驗顯示了 ATS 在節點屬性完成方面的優越性。

##### **Jochre 3 and the Yiddish OCR corpus**
2501.08442v1 by Assaf Urieli, Amber Clooney, Michelle Sigiel, Grisha Leyfer

We describe the construction of a publicly available Yiddish OCR Corpus, and
describe and evaluate the open source OCR tool suite Jochre 3, including an
Alto editor for corpus annotation, OCR software for Alto OCR layer generation,
and a customizable OCR search engine. The current version of the Yiddish OCR
corpus contains 658 pages, 186K tokens and 840K glyphs. The Jochre 3 OCR tool
uses various fine-tuned YOLOv8 models for top-down page layout analysis, and a
custom CNN network for glyph recognition. It attains a CER of 1.5% on our test
corpus, far out-performing all other existing public models for Yiddish. We
analyzed the full 660M word Yiddish Book Center with Jochre 3 OCR, and the new
OCR is searchable through the Yiddish Book Center OCR search engine.

摘要：我們描述了一個公開可用的意第緒語 OCR 語料庫的建構，並描述和評估開源 OCR 工具組 Jochre 3，其中包括用於語料庫註解的 Alto 編輯器、用於 Alto OCR 層生成的高階 OCR 軟體，以及一個可自訂的 OCR 搜尋引擎。意第緒語 OCR 語料庫的現行版本包含 658 頁、186K 個詞彙和 840K 個字形。Jochre 3 OCR 工具使用各種微調的 YOLOv8 模型進行由上而下的頁面版面分析，以及一個自訂的 CNN 網路進行字形辨識。在我們的測試語料庫上，它達到了 1.5% 的字元錯誤率 (CER)，遠遠優於所有其他現有的公開意第緒語模型。我們使用 Jochre 3 OCR 分析了完整的 6.6 億字意第緒語書籍中心，而新的 OCR 可透過意第緒語書籍中心 OCR 搜尋引擎進行搜尋。

##### **Religious Bias Landscape in Language and Text-to-Image Models: Analysis, Detection, and Debiasing Strategies**
2501.08441v1 by Ajwad Abrar, Nafisa Tabassum Oeshy, Mohsinul Kabir, Sophia Ananiadou

Note: This paper includes examples of potentially offensive content related
to religious bias, presented solely for academic purposes. The widespread
adoption of language models highlights the need for critical examinations of
their inherent biases, particularly concerning religion. This study
systematically investigates religious bias in both language models and
text-to-image generation models, analyzing both open-source and closed-source
systems. We construct approximately 400 unique, naturally occurring prompts to
probe language models for religious bias across diverse tasks, including mask
filling, prompt completion, and image generation. Our experiments reveal
concerning instances of underlying stereotypes and biases associated
disproportionately with certain religions. Additionally, we explore
cross-domain biases, examining how religious bias intersects with demographic
factors such as gender, age, and nationality. This study further evaluates the
effectiveness of targeted debiasing techniques by employing corrective prompts
designed to mitigate the identified biases. Our findings demonstrate that
language models continue to exhibit significant biases in both text and image
generation tasks, emphasizing the urgent need to develop fairer language models
to achieve global acceptability.

摘要：注意：本文包含與宗教偏見相關的潛在冒犯性內容範例，僅出於學術目的而呈現。語言模型的廣泛採用凸顯了批判性檢視其內在偏見的必要性，特別是關於宗教。本研究系統性地調查了語言模型和文字轉圖像生成模型中的宗教偏見，分析了開源和閉源系統。我們構建了大約 400 個獨特的、自然發生的提示，以探討語言模型在不同任務中的宗教偏見，包括填空、提示完成和圖像生成。我們的實驗揭示了與某些宗教不成比例地相關的潛在刻板印象和偏見。此外，我們探討了跨領域偏見，檢視宗教偏見如何與性別、年齡和國籍等人口因素相交。本研究進一步評估了目標去偏技術的有效性，採用旨在減輕已識別偏見的修正提示。我們的研究結果表明，語言模型在文字和圖像生成任務中持續展現顯著的偏見，強調了開發更公平的語言模型以實現全球可接受性的迫切需要。

##### **Modeling Discrimination with Causal Abstraction**
2501.08429v1 by Milan Mossé, Kara Schechtman, Frederick Eberhardt, Thomas Icard

A person is directly racially discriminated against only if her race caused
her worse treatment. This implies that race is an attribute sufficiently
separable from other attributes to isolate its causal role. But race is
embedded in a nexus of social factors that resist isolated treatment. If race
is socially constructed, in what sense can it cause worse treatment? Some
propose that the perception of race, rather than race itself, causes worse
treatment. Others suggest that since causal models require modularity, i.e. the
ability to isolate causal effects, attempts to causally model discrimination
are misguided.
  This paper addresses the problem differently. We introduce a framework for
reasoning about discrimination, in which race is a high-level abstraction of
lower-level features. In this framework, race can be modeled as itself causing
worse treatment. Modularity is ensured by allowing assumptions about social
construction to be precisely and explicitly stated, via an alignment between
race and its constituents. Such assumptions can then be subjected to normative
and empirical challenges, which lead to different views of when discrimination
occurs. By distinguishing constitutive and causal relations, the abstraction
framework pinpoints disagreements in the current literature on modeling
discrimination, while preserving a precise causal account of discrimination.

摘要：一個人只有在她的種族導致她受到更差的待遇時，才會直接受到種族歧視。這意味著種族是一個與其他屬性足夠分離的屬性，可以孤立其因果關係。但種族根植於一個抵抗孤立對待的社會因素網絡中。如果種族是社會建構的，那麼它在什麼意義上會導致更差的待遇？有些人提出，種族本身，而不是種族的認知，會導致更差的待遇。另一些人則認為，由於因果模型需要模組化，即隔離因果效應的能力，因此嘗試對歧視進行因果建模是錯誤的。
本文以不同的方式解決這個問題。我們引入了一個推理歧視的框架，其中種族是低層級特徵的高層級抽象。在這個框架中，種族可以被建模為本身導致更差的待遇。通過允許對社會建構的假設通過種族及其組成部分之間的一致性進行精確和明確的陳述，確保了模組化。然後，這些假設可以受到規範性和經驗性挑戰，這會導致對何時發生歧視的不同看法。通過區分構成性和因果關係，抽象框架指出了當前歧視建模文獻中的分歧，同時保留了對歧視的精確因果說明。

##### **Causal vs. Anticausal merging of predictors**
2501.08426v1 by Sergio Hernan Garrido Mejia, Patrick Blöbaum, Bernhard Schölkopf, Dominik Janzing

We study the differences arising from merging predictors in the causal and
anticausal directions using the same data. In particular we study the
asymmetries that arise in a simple model where we merge the predictors using
one binary variable as target and two continuous variables as predictors. We
use Causal Maximum Entropy (CMAXENT) as inductive bias to merge the predictors,
however, we expect similar differences to hold also when we use other merging
methods that take into account asymmetries between cause and effect. We show
that if we observe all bivariate distributions, the CMAXENT solution reduces to
a logistic regression in the causal direction and Linear Discriminant Analysis
(LDA) in the anticausal direction. Furthermore, we study how the decision
boundaries of these two solutions differ whenever we observe only some of the
bivariate distributions implications for Out-Of-Variable (OOV) generalisation.

摘要：我們使用相同的資料研究合併預測器在因果和反因果方向上產生的差異。特別是，我們研究在一個簡單模型中產生的不對稱性，在該模型中，我們使用一個二元變數作為目標和兩個連續變數作為預測器來合併預測器。我們使用因果最大熵 (CMAXENT) 作為歸納偏見來合併預測器，然而，我們預期在我們使用其他考慮到因果之間不對稱性的合併方法時，也會產生類似的差異。我們表明，如果我們觀察到所有二變數分佈，則 CMAXENT 解決方案會簡化為因果方向中的邏輯迴歸和反因果方向中的線性判別分析 (LDA)。此外，我們研究了當我們僅觀察到某些二變數分佈時，這兩個解決方案的決策邊界有何不同，這對變數外 (OOV) 概括的影響。

##### **SEAL: Speaker Error Correction using Acoustic-conditioned Large Language Models**
2501.08421v1 by Anurag Kumar, Rohit Paturi, Amber Afshan, Sundararajan Srinivasan

Speaker Diarization (SD) is a crucial component of modern end-to-end ASR
pipelines. Traditional SD systems, which are typically audio-based and operate
independently of ASR, often introduce speaker errors, particularly during
speaker transitions and overlapping speech. Recently, language models including
fine-tuned large language models (LLMs) have shown to be effective as a
second-pass speaker error corrector by leveraging lexical context in the
transcribed output. In this work, we introduce a novel acoustic conditioning
approach to provide more fine-grained information from the acoustic diarizer to
the LLM. We also show that a simpler constrained decoding strategy reduces LLM
hallucinations, while avoiding complicated post-processing. Our approach
significantly reduces the speaker error rates by 24-43% across Fisher,
Callhome, and RT03-CTS datasets, compared to the first-pass Acoustic SD.

摘要：語者日記化 (SD) 是現代端對端 ASR 管道的關鍵組成部分。傳統的 SD 系統通常基於音訊，並獨立於 ASR 運作，在語者轉換和語音重疊期間，通常會引發語者錯誤。最近，包括微調大型語言模型 (LLM) 在內的語言模型已證明可有效作為第二輪語者錯誤校正器，方法是利用轉錄輸出的詞彙背景。在這項工作中，我們引入了一種新穎的音響條件化方法，以向 LLM 提供來自音響日記器的更細緻資訊。我們也展示了一個更簡單的受限解碼策略可減少 LLM 幻覺，同時避免複雜的後處理。與第一輪音響 SD 相比，我們的做法大幅降低了 Fisher、Callhome 和 RT03-CTS 資料集中的語者錯誤率達 24-43%。

##### **CVaR-Based Variational Quantum Optimization for User Association in Handoff-Aware Vehicular Networks**
2501.08418v1 by Zijiang Yan, Hao Zhou, Jianhua Pei, Aryan Kaushik, Hina Tabassum, Ping Wang

Efficient resource allocation is essential for optimizing various tasks in
wireless networks, which are usually formulated as generalized assignment
problems (GAP). GAP, as a generalized version of the linear sum assignment
problem, involves both equality and inequality constraints that add
computational challenges. In this work, we present a novel Conditional Value at
Risk (CVaR)-based Variational Quantum Eigensolver (VQE) framework to address
GAP in vehicular networks (VNets). Our approach leverages a hybrid
quantum-classical structure, integrating a tailored cost function that balances
both objective and constraint-specific penalties to improve solution quality
and stability. Using the CVaR-VQE model, we handle the GAP efficiently by
focusing optimization on the lower tail of the solution space, enhancing both
convergence and resilience on noisy intermediate-scale quantum (NISQ) devices.
We apply this framework to a user-association problem in VNets, where our
method achieves 23.5% improvement compared to the deep neural network (DNN)
approach.

摘要：有效資源配置對於優化無線網路中的各種任務至關重要，這些任務通常被制定為廣義分配問題 (GAP)。GAP 作為線性總和分配問題的廣義版本，涉及等式和不等式約束，增加了運算挑戰。在這項工作中，我們提出一個新的條件價值風險 (CVaR) 為基礎的變分量子本徵求解器 (VQE) 框架，以解決車輛網路 (VNet) 中的 GAP。我們的做法利用混合量子經典結構，整合一個量身訂做的成本函數，平衡目標和約束特定懲罰，以提高解的品質和穩定性。使用 CVaR-VQE 模型，我們透過將最佳化集中在解空間的下尾，有效地處理 GAP，增強在有雜訊的中間量級量子 (NISQ) 裝置上的收斂性和復原力。我們將此框架應用於 VNet 中的使用者關聯問題，我們的做法與深度神經網路 (DNN) 方法相比，獲得了 23.5% 的改進。

##### **Cross-Modal Transferable Image-to-Video Attack on Video Quality Metrics**
2501.08415v1 by Georgii Gotin, Ekaterina Shumitskaya, Anastasia Antsiferova, Dmitriy Vatolin

Recent studies have revealed that modern image and video quality assessment
(IQA/VQA) metrics are vulnerable to adversarial attacks. An attacker can
manipulate a video through preprocessing to artificially increase its quality
score according to a certain metric, despite no actual improvement in visual
quality. Most of the attacks studied in the literature are white-box attacks,
while black-box attacks in the context of VQA have received less attention.
Moreover, some research indicates a lack of transferability of adversarial
examples generated for one model to another when applied to VQA. In this paper,
we propose a cross-modal attack method, IC2VQA, aimed at exploring the
vulnerabilities of modern VQA models. This approach is motivated by the
observation that the low-level feature spaces of images and videos are similar.
We investigate the transferability of adversarial perturbations across
different modalities; specifically, we analyze how adversarial perturbations
generated on a white-box IQA model with an additional CLIP module can
effectively target a VQA model. The addition of the CLIP module serves as a
valuable aid in increasing transferability, as the CLIP model is known for its
effective capture of low-level semantics. Extensive experiments demonstrate
that IC2VQA achieves a high success rate in attacking three black-box VQA
models. We compare our method with existing black-box attack strategies,
highlighting its superiority in terms of attack success within the same number
of iterations and levels of attack strength. We believe that the proposed
method will contribute to the deeper analysis of robust VQA metrics.

摘要：<paragraph>最近的研究表明，現代影像和影片品質評估 (IQA/VQA) 指標容易受到對抗性攻擊的影響。攻擊者可以透過預處理來操縱影片，以人為提高其品質分數，符合特定指標，儘管視覺品質並沒有實際改善。文獻中研究的大多數攻擊都是白盒攻擊，而 VQA 中的黑盒攻擊則較少受到關注。此外，一些研究指出，當對抗範例應用於 VQA 時，針對一個模型產生的對抗範例缺乏可轉移性。在本文中，我們提出了一種跨模態攻擊方法 IC2VQA，旨在探索現代 VQA 模型的漏洞。這種方法的動機來自於觀察到影像和影片的低階特徵空間是相似的。我們研究了對抗擾動在不同模態之間的可轉移性；具體來說，我們分析了在具有額外 CLIP 模組的白盒 IQA 模型上產生的對抗擾動如何有效地針對 VQA 模型。CLIP 模組的加入有助於提高可轉移性，因為 CLIP 模型以有效擷取低階語意而聞名。廣泛的實驗證明，IC2VQA 在攻擊三個黑盒 VQA 模型時取得了很高的成功率。我們將我們的模型與現有的黑盒攻擊策略進行比較，突顯了它在相同迭代次數和攻擊強度級別下的攻擊成功率優勢。我們相信，所提出的方法將有助於對強健的 VQA 指標進行更深入的分析。</paragraph>

##### **Ensemble of Large Language Models for Curated Labeling and Rating of Free-text Data**
2501.08413v1 by Jiaxing Qiu, Dongliang Guo, Papini Natalie, Peace Noelle, Levinson Cheri, Teague R. Henry

Free-text responses are commonly collected in psychological studies,
providing rich qualitative insights that quantitative measures may not capture.
Labeling curated topics of research interest in free-text data by multiple
trained human coders is typically labor-intensive and time-consuming. Though
large language models (LLMs) excel in language processing, LLM-assisted
labeling techniques relying on closed-source LLMs cannot be directly applied to
free-text data, without explicit consent for external use.
  In this study, we propose a framework of assembling locally-deployable LLMs
to enhance the labeling of predetermined topics in free-text data under privacy
constraints. Analogous to annotation by multiple human raters, this framework
leverages the heterogeneity of diverse open-source LLMs. The ensemble approach
seeks a balance between the agreement and disagreement across LLMs, guided by a
relevancy scoring methodology that utilizes embedding distances between topic
descriptions and LLMs' reasoning. We evaluated the ensemble approach using both
publicly accessible Reddit data from eating disorder related forums, and
free-text responses from eating disorder patients, both complemented by human
annotations.
  We found that: (1) there is heterogeneity in the performance of labeling
among same-sized LLMs, with some showing low sensitivity but high precision,
while others exhibit high sensitivity but low precision. (2) Compared to
individual LLMs, the ensemble of LLMs achieved the highest accuracy and optimal
precision-sensitivity trade-off in predicting human annotations. (3) The
relevancy scores across LLMs showed greater agreement than dichotomous labels,
indicating that the relevancy scoring method effectively mitigates the
heterogeneity in LLMs' labeling.

摘要：<paragraph>在心理研究中，通常会收集自由文本回复，提供定量测量可能无法捕捉到的丰富的定性见解。通过多位训练有素的人类编码员对自由文本数据中感兴趣的研究主题进行标记通常需要大量的人力和时间。尽管大型语言模型 (LLM) 在语言处理方面表现出色，但依赖于闭源 LLM 的 LLM 辅助标记技术不能直接应用于自由文本数据，而无需明确同意外部使用。
在本研究中，我们提出了一个组装可本地部署的 LLM 的框架，以增强在隐私约束下对自由文本数据中预定主题的标记。类似于多个人类评估员的注释，该框架利用了各种开源 LLM 的异质性。集成方法寻求平衡 LLM 之间的一致性和分歧，由相关性评分方法指导，该方法利用主题描述和 LLM 推理之间的嵌入距离。我们使用来自饮食失调相关论坛的公开 Reddit 数据和饮食失调患者的自由文本回复对集成方法进行了评估，这两者都辅以人类注释。
我们发现：(1) 同等规模的 LLM 在标记性能方面存在异质性，一些 LLM 显示出低敏感性但高精度，而另一些 LLM 则显示出高敏感性但低精度。(2) 与单个 LLM 相比，LLM 的集成在预测人类注释时实现了最高的准确性和最佳的精度灵敏度权衡。(3) LLM 之间的相关性得分显示出比二分标签更大的共识，表明相关性评分方法有效地减轻了 LLM 标记中的异质性。</paragraph>

##### **OptiChat: Bridging Optimization Models and Practitioners with Large Language Models**
2501.08406v1 by Hao Chen, Gonzalo Esteban Constante-Flores, Krishna Sri Ipsit Mantri, Sai Madhukiran Kompalli, Akshdeep Singh Ahluwalia, Can Li

Optimization models have been applied to solve a wide variety of
decision-making problems. These models are usually developed by optimization
experts but are used by practitioners without optimization expertise in various
application domains. As a result, practitioners often struggle to interact with
and draw useful conclusions from optimization models independently. To fill
this gap, we introduce OptiChat, a natural language dialogue system designed to
help practitioners interpret model formulation, diagnose infeasibility, analyze
sensitivity, retrieve information, evaluate modifications, and provide
counterfactual explanations. By augmenting large language models (LLMs) with
functional calls and code generation tailored for optimization models, we
enable seamless interaction and minimize the risk of hallucinations in
OptiChat. We develop a new dataset to evaluate OptiChat's performance in
explaining optimization models. Experiments demonstrate that OptiChat
effectively bridges the gap between optimization models and practitioners,
delivering autonomous, accurate, and instant responses.

摘要：最佳化模型已被運用於解決各式各樣的決策問題。這些模型通常是由最佳化專家開發，但會由沒有最佳化專業知識的從業者在各種應用領域中使用。因此，從業者通常難以與最佳化模型互動並獨立得出有用的結論。為了填補這個缺口，我們引入了 OptiChat，這是一個自然語言對話系統，旨在幫助從業者詮釋模型公式、診斷不可行性、分析敏感性、擷取資訊、評估修改，並提供反事實解釋。藉由擴充大型語言模型 (LLM) 的功能呼叫和專為最佳化模型量身打造的程式碼產生，我們讓 OptiChat 能夠順暢互動並將產生幻覺的風險降到最低。我們開發了一個新的資料集，以評估 OptiChat 在解釋最佳化模型方面的效能。實驗證明，OptiChat 有效地彌合了最佳化模型和從業者之間的差距，提供了自主、準確且即時的回應。

##### **Addressing Quality Challenges in Deep Learning: The Role of MLOps and Domain Knowledge**
2501.08402v1 by Santiago del Rey, Adrià Medina, Xavier Franch, Silverio Martínez-Fernández

Deep learning (DL) systems present unique challenges in software engineering,
especially concerning quality attributes like correctness and resource
efficiency. While DL models achieve exceptional performance in specific tasks,
engineering DL-based systems is still essential. The effort, cost, and
potential diminishing returns of continual improvements must be carefully
evaluated, as software engineers often face the critical decision of when to
stop refining a system relative to its quality attributes. This experience
paper explores the role of MLOps practices -- such as monitoring and experiment
tracking -- in creating transparent and reproducible experimentation
environments that enable teams to assess and justify the impact of design
decisions on quality attributes. Furthermore, we report on experiences
addressing the quality challenges by embedding domain knowledge into the design
of a DL model and its integration within a larger system. The findings offer
actionable insights into not only the benefits of domain knowledge and MLOps
but also the strategic consideration of when to limit further optimizations in
DL projects to maximize overall system quality and reliability.

摘要：深度學習 (DL) 系統在軟體工程中呈現出獨特的挑戰，
特別是關於正確性和資源效率等品質屬性。雖然 DL 模型在特定任務中實現了非凡的效能，
但建構基於 DL 的系統仍然至關重要。必須仔細評估持續改進的努力、成本和潛在的遞減報酬，
因為軟體工程師經常面臨何時停止相對於其品質屬性來改善系統的關鍵決策。這份經驗論文探討了 MLOps 實務在建立透明且可重現的實驗環境中的角色，
這些環境使團隊能夠評估和證明設計決策對品質屬性的影響，例如監控和實驗追蹤。此外，我們報告了透過將領域知識嵌入 DL 模型的設計及其在較大型系統中的整合來解決品質挑戰的經驗。這些發現不僅提供了關於領域知識和 MLOps 好處的可行見解，
還提供了關於何時限制進一步最佳化以最大化整體系統品質和可靠性的策略考量。

##### **PokerBench: Training Large Language Models to become Professional Poker Players**
2501.08328v1 by Richard Zhuang, Akshat Gupta, Richard Yang, Aniket Rahane, Zhengyu Li, Gopala Anumanchipalli

We introduce PokerBench - a benchmark for evaluating the poker-playing
abilities of large language models (LLMs). As LLMs excel in traditional NLP
tasks, their application to complex, strategic games like poker poses a new
challenge. Poker, an incomplete information game, demands a multitude of skills
such as mathematics, reasoning, planning, strategy, and a deep understanding of
game theory and human psychology. This makes Poker the ideal next frontier for
large language models. PokerBench consists of a comprehensive compilation of
11,000 most important scenarios, split between pre-flop and post-flop play,
developed in collaboration with trained poker players. We evaluate prominent
models including GPT-4, ChatGPT 3.5, and various Llama and Gemma series models,
finding that all state-of-the-art LLMs underperform in playing optimal poker.
However, after fine-tuning, these models show marked improvements. We validate
PokerBench by having models with different scores compete with each other,
demonstrating that higher scores on PokerBench lead to higher win rates in
actual poker games. Through gameplay between our fine-tuned model and GPT-4, we
also identify limitations of simple supervised fine-tuning for learning optimal
playing strategy, suggesting the need for more advanced methodologies for
effectively training language models to excel in games. PokerBench thus
presents a unique benchmark for a quick and reliable evaluation of the
poker-playing ability of LLMs as well as a comprehensive benchmark to study the
progress of LLMs in complex game-playing scenarios. The dataset and code will
be made available at: \url{https://github.com/pokerllm/pokerbench}.

摘要：<paragraph>我們推出 PokerBench - 一個用於評估大型語言模型 (LLM) 的撲克遊戲能力的基準。由於 LLM 在傳統 NLP 任務中表現出色，因此將其應用於撲克等複雜的策略遊戲構成了一項新的挑戰。撲克是一種不完全資訊遊戲，需要大量的技能，例如數學、推理、規劃、策略，以及對博弈論和人類心理學的深入理解。這使得撲克成為大型語言模型的理想下一個前沿。PokerBench 包含 11,000 個最重要的場景的綜合彙編，分為翻牌前和翻牌後遊戲，並與訓練有素的撲克玩家合作開發。我們評估了包括 GPT-4、ChatGPT 3.5 以及各種 Llama 和 Gemma 系列模型在內的知名模型，發現所有最先進的 LLM 在玩最佳撲克時表現不佳。然而，在微調後，這些模型顯示出顯著的改進。我們通過讓具有不同分數的模型相互競爭來驗證 PokerBench，證明 PokerBench 上較高的分數會導致實際撲克遊戲中較高的獲勝率。通過我們微調的模型和 GPT-4 之間的遊戲，我們還發現了簡單的監督微調在學習最佳遊戲策略方面的局限性，這表明需要更先進的方法來有效地訓練語言模型在遊戲中表現出色。因此，PokerBench 為快速可靠地評估 LLM 的撲克遊戲能力提供了一個獨特的基準，並提供了一個全面的基準來研究 LLM 在複雜遊戲場景中的進展。數據集和代碼將在以下位置提供：\url{https://github.com/pokerllm/pokerbench}。</paragraph>

##### **ADAM-1: AI and Bioinformatics for Alzheimer's Detection and Microbiome-Clinical Data Integrations**
2501.08324v1 by Ziyuan Huang, Vishaldeep Kaur Sekhon, Ouyang Guo, Mark Newman, Roozbeh Sadeghian, Maria L. Vaida, Cynthia Jo, Doyle Ward, Vanni Bucci, John P. Haran

The Alzheimer's Disease Analysis Model Generation 1 (ADAM) is a multi-agent
large language model (LLM) framework designed to integrate and analyze
multi-modal data, including microbiome profiles, clinical datasets, and
external knowledge bases, to enhance the understanding and detection of
Alzheimer's disease (AD). By leveraging retrieval-augmented generation (RAG)
techniques along with its multi-agent architecture, ADAM-1 synthesizes insights
from diverse data sources and contextualizes findings using literature-driven
evidence. Comparative evaluation against XGBoost revealed similar mean F1
scores but significantly reduced variance for ADAM-1, highlighting its
robustness and consistency, particularly in small laboratory datasets. While
currently tailored for binary classification tasks, future iterations aim to
incorporate additional data modalities, such as neuroimaging and biomarkers, to
broaden the scalability and applicability for Alzheimer's research and
diagnostics.

摘要：阿茲海默症分析模型生成 1 (ADAM) 是一個多代理大型語言模型 (LLM) 架構，旨在整合和分析多模式數據，包括微生物組特徵、臨床數據集和外部知識庫，以增進對阿茲海默症 (AD) 的理解和偵測。透過利用擷取增強生成 (RAG) 技術以及其多代理架構，ADAM-1 從不同的數據來源中綜合見解，並使用文獻驅動的證據對發現進行情境化。與 XGBoost 的比較評估顯示類似的平均 F1 分數，但 ADAM-1 的變異顯著降低，突顯其穩健性和一致性，特別是在小型實驗室數據集中。雖然目前針對二元分類任務進行調整，但未來的迭代旨在納入其他數據模式，例如神經影像和生物標記，以擴大阿茲海默症研究和診斷的可擴充性和適用性。

##### **Exploring Robustness of Multilingual LLMs on Real-World Noisy Data**
2501.08322v1 by Amirhossein Aliakbarzadeh, Lucie Flek, Akbar Karimi

Large Language Models (LLMs) are trained on Web data that might contain
spelling errors made by humans. But do they become robust to similar real-world
noise? In this paper, we investigate the effect of real-world spelling mistakes
on the performance of 9 language models, with parameters ranging from 0.2B to
13B, in 3 different NLP tasks, namely Natural Language Inference (NLI), Name
Entity Recognition (NER), and Intent Classification (IC). We perform our
experiments on 6 different languages and build a dictionary of real-world noise
for them using the Wikipedia edit history. We show that the performance gap of
the studied models on the clean and noisy test data averaged across all the
datasets and languages ranges from 2.3 to 4.3 absolute percentage points. In
addition, mT5 models, in general, show more robustness compared to BLOOM,
Falcon, and BERT-like models. In particular, mT5 (13B), was the most robust on
average overall, across the 3 tasks, and in 4 of the 6 languages.

摘要：大型語言模型 (LLM) 是根據網路資料訓練而成的，這些資料可能包含人類拼寫錯誤。但它們是否能對類似的真實世界雜訊產生穩健性？在本文中，我們探討真實世界拼寫錯誤對 9 個語言模型效能的影響，這些模型的參數範圍從 0.2B 到 13B，涵蓋 3 個不同的自然語言處理 (NLP) 任務，即自然語言推論 (NLI)、命名實體辨識 (NER) 和意圖分類 (IC)。我們在 6 種不同的語言上執行實驗，並使用維基百科編輯記錄為這些語言建立真實世界雜訊字典。我們顯示出這些研究模型在乾淨和雜訊測試資料上的效能差距，平均在所有資料集和語言的範圍從 2.3 到 4.3 個絕對百分比點。此外，與 BLOOM、Falcon 和 BERT 類似模型相比，mT5 模型通常表現出更高的穩健性。特別是，mT5 (13B) 在 3 個任務和 6 種語言中的 4 種語言中，整體上最穩健。

##### **Enhancing Automated Interpretability with Output-Centric Feature Descriptions**
2501.08319v1 by Yoav Gur-Arieh, Roy Mayan, Chen Agassy, Atticus Geiger, Mor Geva

Automated interpretability pipelines generate natural language descriptions
for the concepts represented by features in large language models (LLMs), such
as plants or the first word in a sentence. These descriptions are derived using
inputs that activate the feature, which may be a dimension or a direction in
the model's representation space. However, identifying activating inputs is
costly, and the mechanistic role of a feature in model behavior is determined
both by how inputs cause a feature to activate and by how feature activation
affects outputs. Using steering evaluations, we reveal that current pipelines
provide descriptions that fail to capture the causal effect of the feature on
outputs. To fix this, we propose efficient, output-centric methods for
automatically generating feature descriptions. These methods use the tokens
weighted higher after feature stimulation or the highest weight tokens after
applying the vocabulary "unembedding" head directly to the feature. Our
output-centric descriptions better capture the causal effect of a feature on
model outputs than input-centric descriptions, but combining the two leads to
the best performance on both input and output evaluations. Lastly, we show that
output-centric descriptions can be used to find inputs that activate features
previously thought to be "dead".

摘要：自動可解釋性管道會為大型語言模型 (LLM) 中特徵所代表的概念產生自然語言說明，例如植物或句子中的第一個字。這些說明是使用會啟動特徵的輸入所衍生，而這些輸入可能是模型表示空間中的維度或方向。然而，找出啟動輸入的成本很高，且特徵在模型行為中所扮演的機械角色是由輸入如何導致特徵啟動，以及特徵啟動如何影響輸出所決定。使用引導評估，我們揭露目前的管道所提供的說明無法捕捉特徵對輸出的因果關係。為了修正這個問題，我們提出用於自動產生特徵說明的有效且以輸出為中心的各種方法。這些方法會使用在特徵刺激後權重較高的代碼，或在將詞彙「解嵌入」標頭直接套用至特徵後權重最高的代碼。我們以輸出為中心的說明比以輸入為中心的說明更能捕捉特徵對模型輸出的因果關係，但結合這兩種說明可在輸入和輸出評估中獲得最佳效能。最後，我們證明以輸出為中心的說明可用於找出會啟動以前被認為是「無效」的特徵的輸入。

##### **Diffusion Adversarial Post-Training for One-Step Video Generation**
2501.08316v1 by Shanchuan Lin, Xin Xia, Yuxi Ren, Ceyuan Yang, Xuefeng Xiao, Lu Jiang

The diffusion models are widely used for image and video generation, but
their iterative generation process is slow and expansive. While existing
distillation approaches have demonstrated the potential for one-step generation
in the image domain, they still suffer from significant quality degradation. In
this work, we propose Adversarial Post-Training (APT) against real data
following diffusion pre-training for one-step video generation. To improve the
training stability and quality, we introduce several improvements to the model
architecture and training procedures, along with an approximated R1
regularization objective. Empirically, our experiments show that our
adversarial post-trained model, Seaweed-APT, can generate 2-second, 1280x720,
24fps videos in real time using a single forward evaluation step. Additionally,
our model is capable of generating 1024px images in a single step, achieving
quality comparable to state-of-the-art methods.

摘要：擴散模型廣泛用於影像和影片生成，但其反覆生成過程緩慢且耗費資源。雖然現有的蒸餾方法已展示出在影像領域進行單步生成的可能性，但它們仍會造成品質大幅下降。在這項工作中，我們針對真實資料提出對抗式後訓練 (APT)，並在擴散預訓練後進行單步影片生成。為了改善訓練穩定性和品質，我們對模型架構和訓練程序進行多項改良，並採用近似 R1 正則化目標。根據經驗，我們的實驗顯示，我們的對抗式後訓練模型 Seaweed-APT 能夠使用單一前向評估步驟，即時生成 2 秒、1280x720、24fps 的影片。此外，我們的模型能夠在單一步驟中生成 1024px 的影像，並達到與現有方法相當的品質。

##### **MiniMax-01: Scaling Foundation Models with Lightning Attention**
2501.08313v1 by MiniMax, Aonian Li, Bangwei Gong, Bo Yang, Boji Shan, Chang Liu, Cheng Zhu, Chunhao Zhang, Congchao Guo, Da Chen, Dong Li, Enwei Jiao, Gengxin Li, Guojun Zhang, Haohai Sun, Houze Dong, Jiadai Zhu, Jiaqi Zhuang, Jiayuan Song, Jin Zhu, Jingtao Han, Jingyang Li, Junbin Xie, Junhao Xu, Junjie Yan, Kaishun Zhang, Kecheng Xiao, Kexi Kang, Le Han, Leyang Wang, Lianfei Yu, Liheng Feng, Lin Zheng, Linbo Chai, Long Xing, Meizhi Ju, Mingyuan Chi, Mozhi Zhang, Peikai Huang, Pengcheng Niu, Pengfei Li, Pengyu Zhao, Qi Yang, Qidi Xu, Qiexiang Wang, Qin Wang, Qiuhui Li, Ruitao Leng, Shengmin Shi, Shuqi Yu, Sichen Li, Songquan Zhu, Tao Huang, Tianrun Liang, Weigao Sun, Weixuan Sun, Weiyu Cheng, Wenkai Li, Xiangjun Song, Xiao Su, Xiaodong Han, Xinjie Zhang, Xinzhu Hou, Xu Min, Xun Zou, Xuyang Shen, Yan Gong, Yingjie Zhu, Yipeng Zhou, Yiran Zhong, Yongyi Hu, Yuanxiang Fan, Yue Yu, Yufeng Yang, Yuhao Li, Yunan Huang, Yunji Li, Yunpeng Huang, Yunzhi Xu, Yuxin Mao, Zehan Li, Zekang Li, Zewei Tao, Zewen Ying, Zhaoyang Cong, Zhen Qin, Zhenhua Fan, Zhihang Yu, Zhuo Jiang, Zijia Wu

We introduce MiniMax-01 series, including MiniMax-Text-01 and MiniMax-VL-01,
which are comparable to top-tier models while offering superior capabilities in
processing longer contexts. The core lies in lightning attention and its
efficient scaling. To maximize computational capacity, we integrate it with
Mixture of Experts (MoE), creating a model with 32 experts and 456 billion
total parameters, of which 45.9 billion are activated for each token. We
develop an optimized parallel strategy and highly efficient
computation-communication overlap techniques for MoE and lightning attention.
This approach enables us to conduct efficient training and inference on models
with hundreds of billions of parameters across contexts spanning millions of
tokens. The context window of MiniMax-Text-01 can reach up to 1 million tokens
during training and extrapolate to 4 million tokens during inference at an
affordable cost. Our vision-language model, MiniMax-VL-01 is built through
continued training with 512 billion vision-language tokens. Experiments on both
standard and in-house benchmarks show that our models match the performance of
state-of-the-art models like GPT-4o and Claude-3.5-Sonnet while offering 20-32
times longer context window. We publicly release MiniMax-01 at
https://github.com/MiniMax-AI.

摘要：<paragraph>我們推出 MiniMax-01 系列，包括 MiniMax-Text-01 和 MiniMax-VL-01，
它們與頂級模型相當，同時在處理較長語境方面提供卓越的功能。核心在於閃電注意力及其高效縮放。為了最大化計算能力，我們將其與專家混合 (MoE) 整合，建立一個擁有 32 個專家和 4560 億個總參數的模型，其中 459 億個參數被啟用於每個代幣。我們為 MoE 和閃電注意力開發了一個優化的並行策略和高效的計算通訊重疊技術。這種方法使我們能夠對擁有數百億個參數的模型進行高效的訓練和推理，而這些參數跨越數百萬個代幣的語境。MiniMax-Text-01 的語境窗口在訓練期間可以達到 100 萬個代幣，並在推理期間以合理成本推斷到 400 萬個代幣。我們的視覺語言模型 MiniMax-VL-01 是透過持續訓練 5120 億個視覺語言代幣建立的。在標準基準和內部基準上的實驗表明，我們的模型與 GPT-4o 和 Claude-3.5-Sonnet 等最先進模型的性能相匹配，同時提供 20-32 倍更長的語境窗口。我們在 https://github.com/MiniMax-AI 上公開發布 MiniMax-01。</paragraph>

##### **Everybody Likes to Sleep: A Computer-Assisted Comparison of Object Naming Data from 30 Languages**
2501.08312v1 by Alžběta Kučerová, Johann-Mattis List

Object naming - the act of identifying an object with a word or a phrase - is
a fundamental skill in interpersonal communication, relevant to many
disciplines, such as psycholinguistics, cognitive linguistics, or language and
vision research. Object naming datasets, which consist of concept lists with
picture pairings, are used to gain insights into how humans access and select
names for objects in their surroundings and to study the cognitive processes
involved in converting visual stimuli into semantic concepts. Unfortunately,
object naming datasets often lack transparency and have a highly idiosyncratic
structure. Our study tries to make current object naming data transparent and
comparable by using a multilingual, computer-assisted approach that links
individual items of object naming lists to unified concepts. Our current sample
links 17 object naming datasets that cover 30 languages from 10 different
language families. We illustrate how the comparative dataset can be explored by
searching for concepts that recur across the majority of datasets and comparing
the conceptual spaces of covered object naming datasets with classical basic
vocabulary lists from historical linguistics and linguistic typology. Our
findings can serve as a basis for enhancing cross-linguistic object naming
research and as a guideline for future studies dealing with object naming
tasks.

摘要：<paragraph>對象命名——用一個詞或一個短語識別一個對象的行為——是一項人際溝通的基本技能，與許多領域相關，例如心理語言學、認知語言學或語言和視覺研究。對象命名數據集包含帶有圖片配對的概念清單，用於深入了解人類如何訪問和選擇周圍對象的名稱，以及研究將視覺刺激轉換為語義概念所涉及的認知過程。不幸的是，對象命名數據集通常缺乏透明度，並且具有高度的獨特性結構。我們的研究試圖通過使用多語言、計算機輔助的方法將對象命名清單的單個項目鏈接到統一的概念，從而使當前對象命名數據透明且具有可比性。我們目前的樣本鏈接了 17 個對象命名數據集，這些數據集涵蓋了來自 10 個不同語言家族的 30 種語言。我們說明瞭如何通過搜索跨大多數數據集重複出現的概念以及將涵蓋的對象命名數據集的概念空間與歷史語言學和語言類型學中的經典基本詞彙表進行比較來探索比較數據集。我們的研究結果可以作為增強跨語言對象命名研究的基礎，並作為處理對象命名任務的未來研究的指導方針。</paragraph>

##### **Polynomial Threshold Functions of Bounded Tree-Width: Some Explainability and Complexity Aspects**
2501.08297v1 by Karine Chubarian, Johnny Joyce, Gyorgy Turan

The tree-width of a multivariate polynomial is the tree-width of the
hypergraph with hyperedges corresponding to its terms. Multivariate polynomials
of bounded tree-width have been studied by Makowsky and Meer as a new sparsity
condition that allows for polynomial solvability of problems which are
intractable in general. We consider a variation on this theme for Boolean
variables. A representation of a Boolean function as the sign of a polynomial
is called a polynomial threshold representation. We discuss Boolean functions
representable as polynomial threshold functions of bounded tree-width and
present two applications to Bayesian network classifiers, a probabilistic
graphical model. Both applications are in Explainable Artificial Intelligence
(XAI), the research area dealing with the black-box nature of many recent
machine learning models. We also give a separation result between the
representational power of positive and general polynomial threshold functions.

摘要：多變量多項式的樹寬度是與其項對應的超圖的樹寬度。Makowsky 和 Meer 研究了有界樹寬度的多變量多項式，作為一種新的稀疏性條件，允許對一般難以解決的問題進行多項式求解。我們考慮了布林變數的這個主題變體。布林函數的表示形式為多項式的符號，稱為多項式閾值表示。我們討論了可表示為有界樹寬度的多項式閾值函數的布林函數，並介紹了貝氏網路分類器（一種機率圖形模型）的兩個應用。這兩個應用都在可解釋人工智慧（XAI）中，這是一個研究許多近期機器學習模型的黑箱性質的研究領域。我們還給出了正多項式閾值函數和一般多項式閾值函數的表示能力之間的分離結果。

##### **HALoGEN: Fantastic LLM Hallucinations and Where to Find Them**
2501.08292v1 by Abhilasha Ravichander, Shrusti Ghela, David Wadden, Yejin Choi

Despite their impressive ability to generate high-quality and fluent text,
generative large language models (LLMs) also produce hallucinations: statements
that are misaligned with established world knowledge or provided input context.
However, measuring hallucination can be challenging, as having humans verify
model generations on-the-fly is both expensive and time-consuming. In this
work, we release HALoGEN, a comprehensive hallucination benchmark consisting
of: (1) 10,923 prompts for generative models spanning nine domains including
programming, scientific attribution, and summarization, and (2) automatic
high-precision verifiers for each use case that decompose LLM generations into
atomic units, and verify each unit against a high-quality knowledge source. We
use this framework to evaluate ~150,000 generations from 14 language models,
finding that even the best-performing models are riddled with hallucinations
(sometimes up to 86% of generated atomic facts depending on the domain). We
further define a novel error classification for LLM hallucinations based on
whether they likely stem from incorrect recollection of training data (Type A
errors), or incorrect knowledge in training data (Type B errors), or are
fabrication (Type C errors). We hope our framework provides a foundation to
enable the principled study of why generative models hallucinate, and advances
the development of trustworthy large language models.

摘要：儘管生成式大型語言模型 (LLM) 擁有生成高品質且流利文字的驚人能力，
但它們也會產生幻覺：與既定的世界知識或提供的輸入背景不符的陳述。
然而，測量幻覺可能具有挑戰性，因為讓人類即時驗證模型生成既昂貴又耗時。在
這項工作中，我們發布了 HALoGEN，一個全面的幻覺基準，包含：
(1) 10,923 個提示，供生成模型涵蓋九個領域，包括
程式設計、科學歸因和摘要，以及 (2) 針對每個使用案例的自動
高精度驗證器，將 LLM 生成分解為原子單位，並根據高品質知識來源驗證每個單位。我們
使用這個框架從 14 個語言模型評估了約 150,000 個生成，
發現即使是效能最好的模型也充斥著幻覺
（有時高達 86% 的生成原子事實，視領域而定）。我們
進一步定義了 LLM 幻覺的新錯誤分類，基於它們可能源自訓練資料的錯誤回憶（A 型
錯誤）、訓練資料中的錯誤知識（B 型錯誤），或捏造（C 型錯誤）。我們希望我們的框架提供一個基礎，
以讓原則性的研究能夠了解生成模型產生幻覺的原因，並促進可信賴大型語言模型的開發。

##### **AfriHate: A Multilingual Collection of Hate Speech and Abusive Language Datasets for African Languages**
2501.08284v2 by Shamsuddeen Hassan Muhammad, Idris Abdulmumin, Abinew Ali Ayele, David Ifeoluwa Adelani, Ibrahim Said Ahmad, Saminu Mohammad Aliyu, Nelson Odhiambo Onyango, Lilian D. A. Wanzare, Samuel Rutunda, Lukman Jibril Aliyu, Esubalew Alemneh, Oumaima Hourrane, Hagos Tesfahun Gebremichael, Elyas Abdi Ismail, Meriem Beloucif, Ebrahim Chekol Jibril, Andiswa Bukula, Rooweither Mabuya, Salomey Osei, Abigail Oppong, Tadesse Destaw Belay, Tadesse Kebede Guge, Tesfa Tegegne Asfaw, Chiamaka Ijeoma Chukwuneke, Paul Röttger, Seid Muhie Yimam, Nedjma Ousidhoum

Hate speech and abusive language are global phenomena that need
socio-cultural background knowledge to be understood, identified, and
moderated. However, in many regions of the Global South, there have been
several documented occurrences of (1) absence of moderation and (2) censorship
due to the reliance on keyword spotting out of context. Further, high-profile
individuals have frequently been at the center of the moderation process, while
large and targeted hate speech campaigns against minorities have been
overlooked. These limitations are mainly due to the lack of high-quality data
in the local languages and the failure to include local communities in the
collection, annotation, and moderation processes. To address this issue, we
present AfriHate: a multilingual collection of hate speech and abusive language
datasets in 15 African languages. Each instance in AfriHate is annotated by
native speakers familiar with the local culture. We report the challenges
related to the construction of the datasets and present various classification
baseline results with and without using LLMs. The datasets, individual
annotations, and hate speech and offensive language lexicons are available on
https://github.com/AfriHate/AfriHate

摘要：仇恨言論和辱罵性語言是全球現象，需要社會文化背景知識才能理解、識別和管理。然而，在全球南方的許多地區，已經有幾起記錄在案的（1）缺乏管理和（2）由於依賴於語境之外的關鍵字標記而導致的審查制度。此外，備受矚目的個人經常成為管理程序的中心，而針對少數群體的大規模且有針對性的仇恨言論活動卻被忽視了。這些限制主要是由於缺乏當地語言的高品質資料，以及未能讓當地社群參與收集、註解和管理程序。為了解決這個問題，我們提出了 AfriHate：一個多語言的仇恨言論和辱罵性語言資料集，包含 15 種非洲語言。AfriHate 中的每個實例都由熟悉當地文化的母語人士註解。我們報告了與資料集建構相關的挑戰，並展示了使用和不使用 LLM 的各種分類基準結果。資料集、個別註解以及仇恨言論和攻擊性語言詞彙表可在 https://github.com/AfriHate/AfriHate 上取得

##### **Exploring Robustness of LLMs to Sociodemographically-Conditioned Paraphrasing**
2501.08276v1 by Pulkit Arora, Akbar Karimi, Lucie Flek

Large Language Models (LLMs) have shown impressive performance in various NLP
tasks. However, there are concerns about their reliability in different domains
of linguistic variations. Many works have proposed robustness evaluation
measures for local adversarial attacks, but we need globally robust models
unbiased to different language styles. We take a broader approach to explore a
wider range of variations across sociodemographic dimensions to perform
structured reliability tests on the reasoning capacity of language models. We
extend the SocialIQA dataset to create diverse paraphrased sets conditioned on
sociodemographic styles. The assessment aims to provide a deeper understanding
of LLMs in (a) their capability of generating demographic paraphrases with
engineered prompts and (b) their reasoning capabilities in real-world, complex
language scenarios. We also explore measures such as perplexity,
explainability, and ATOMIC performance of paraphrases for fine-grained
reliability analysis of LLMs on these sets. We find that demographic-specific
paraphrasing significantly impacts the performance of language models,
indicating that the subtleties of language variations remain a significant
challenge. The code and dataset will be made available for reproducibility and
future research.

摘要：大型語言模型 (LLM) 在各種自然語言處理 (NLP) 任務中展現了令人印象深刻的效能。然而，對於它們在不同語言變異領域的可靠性仍有疑慮。許多研究已針對局部對抗攻擊提出穩健性評估措施，但我們需要對不同語言風格沒有偏見的全球穩健模型。我們採取更廣泛的方法，探索社會人口特徵維度中更廣泛的變異，對語言模型的推理能力進行結構化的可靠性測試。我們擴充 SocialIQA 資料集，以建立以社會人口特徵風格為條件的不同同義詞組。評估旨在提供對 LLM 的更深入理解，包括：(a) 它們使用設計提示產生人口同義詞的能力，以及 (b) 它們在現實世界中複雜語言情境中的推理能力。我們還探索困惑度、可解釋性和同義詞的 ATOMIC 效能等指標，以對 LLM 在這些集合上的可靠性進行細緻的分析。我們發現，特定人口的同義詞改寫會顯著影響語言模型的效能，這表示語言變異的細微差別仍然是一項重大的挑戰。程式碼和資料集將提供出來，以利於再現性和後續研究。

##### **Comparative Analysis of Efficient Adapter-Based Fine-Tuning of State-of-the-Art Transformer Models**
2501.08271v1 by Saad Mashkoor Siddiqui, Mohammad Ali Sheikh, Muhammad Aleem, Kajol R Singh

In this work, we investigate the efficacy of various adapter architectures on
supervised binary classification tasks from the SuperGLUE benchmark as well as
a supervised multi-class news category classification task from Kaggle.
Specifically, we compare classification performance and time complexity of
three transformer models, namely DistilBERT, ELECTRA, and BART, using
conventional fine-tuning as well as nine state-of-the-art (SoTA) adapter
architectures. Our analysis reveals performance differences across adapter
architectures, highlighting their ability to achieve comparable or better
performance relative to fine-tuning at a fraction of the training time. Similar
results are observed on the new classification task, further supporting our
findings and demonstrating adapters as efficient and flexible alternatives to
fine-tuning. This study provides valuable insights and guidelines for selecting
and implementing adapters in diverse natural language processing (NLP)
applications.

摘要：在本文中，我們探討各種適配器架構在 SuperGLUE 基準中的監督式二元分類任務以及來自 Kaggle 的監督式多類新聞分類任務中的功效。具體來說，我們比較了 DistilBERT、ELECTRA 和 BART 這三種Transformer模型的分類效能和時間複雜度，使用傳統微調以及九種最先進 (SoTA) 適配器架構。我們的分析揭示了適配器架構之間的效能差異，突出了它們以低於訓練時間的一小部分達到與微調相當或更好的效能的能力。在新的分類任務中觀察到了類似的結果，進一步支持我們的發現，並展示適配器作為微調的有效且靈活的替代方案。本研究為在各種自然語言處理 (NLP) 應用中選擇和實作適配器提供了有價值的見解和指南。

##### **AI Driven Water Segmentation with deep learning models for Enhanced Flood Monitoring**
2501.08266v1 by Sanjida Afrin Mou, Tasfia Noor Chowdhury, Adib Ibn Mannan, Sadia Nourin Mim, Lubana Tarannum, Tasrin Noman, Jamal Uddin Ahamed

Flooding is a major natural hazard causing significant fatalities and
economic losses annually, with increasing frequency due to climate change.
Rapid and accurate flood detection and monitoring are crucial for mitigating
these impacts. This study compares the performance of three deep learning
models UNet, ResNet, and DeepLabv3 for pixelwise water segmentation to aid in
flood detection, utilizing images from drones, in field observations, and
social media. This study involves creating a new dataset that augments
wellknown benchmark datasets with flood-specific images, enhancing the
robustness of the models. The UNet, ResNet, and DeepLab v3 architectures are
tested to determine their effectiveness in various environmental conditions and
geographical locations, and the strengths and limitations of each model are
also discussed here, providing insights into their applicability in different
scenarios by predicting image segmentation masks. This fully automated approach
allows these models to isolate flooded areas in images, significantly reducing
processing time compared to traditional semi-automated methods. The outcome of
this study is to predict segmented masks for each image effected by a flood
disaster and the validation accuracy of these models. This methodology
facilitates timely and continuous flood monitoring, providing vital data for
emergency response teams to reduce loss of life and economic damages. It offers
a significant reduction in the time required to generate flood maps, cutting
down the manual processing time. Additionally, we present avenues for future
research, including the integration of multimodal data sources and the
development of robust deep learning architectures tailored specifically for
flood detection tasks. Overall, our work contributes to the advancement of
flood management strategies through innovative use of deep learning
technologies.

摘要：<paragraph>洪水是一種重大的自然災害，每年造成大量人員傷亡和經濟損失，而且由於氣候變遷，洪水發生的頻率越來越高。快速而準確的洪水偵測和監控對於減輕這些影響至關重要。本研究比較了三種深度學習模型 UNet、ResNet 和 DeepLabv3 在像素級水體分割中的表現，以協助洪水偵測，利用無人機、現場觀測和社群媒體中的影像。本研究涉及建立一個新的資料集，將眾所周知的基準資料集與特定洪水的影像擴充，以增強模型的穩健性。測試 UNet、ResNet 和 DeepLab v3 架構，以確定它們在各種環境條件和地理位置中的有效性，並且在此探討每個模型的優點和限制，提供在不同場景中預測影像分割遮罩的應用見解。這種全自動化方法讓這些模型能夠在影像中隔離淹水區域，與傳統的半自動化方法相比，大幅減少處理時間。本研究的成果是預測受洪災影響的每張影像的分割遮罩，以及這些模型的驗證準確度。這種方法促進及時且持續的洪水監控，提供緊急應變小組的重要資料，以減少人員傷亡和經濟損失。它大幅縮短了生成洪水地圖所需的時間，減少了手動處理時間。此外，我們提出了未來研究的途徑，包括整合多模式資料來源，以及開發專門針對洪水偵測任務的穩健深度學習架構。總體而言，我們的研究透過創新使用深度學習技術，為洪水管理策略的進步做出貢獻。</paragraph>

##### **Towards Best Practices for Open Datasets for LLM Training**
2501.08365v1 by Stefan Baack, Stella Biderman, Kasia Odrozek, Aviya Skowron, Ayah Bdeir, Jillian Bommarito, Jennifer Ding, Maximilian Gahntz, Paul Keller, Pierre-Carl Langlais, Greg Lindahl, Sebastian Majstorovic, Nik Marda, Guilherme Penedo, Maarten Van Segbroeck, Jennifer Wang, Leandro von Werra, Mitchell Baker, Julie Belião, Kasia Chmielinski, Marzieh Fadaee, Lisa Gutermuth, Hynek Kydlíček, Greg Leppert, EM Lewis-Jong, Solana Larsen, Shayne Longpre, Angela Oduor Lungati, Cullen Miller, Victor Miller, Max Ryabinin, Kathleen Siminyu, Andrew Strait, Mark Surman, Anna Tumadóttir, Maurice Weber, Rebecca Weiss, Lee White, Thomas Wolf

Many AI companies are training their large language models (LLMs) on data
without the permission of the copyright owners. The permissibility of doing so
varies by jurisdiction: in countries like the EU and Japan, this is allowed
under certain restrictions, while in the United States, the legal landscape is
more ambiguous. Regardless of the legal status, concerns from creative
producers have led to several high-profile copyright lawsuits, and the threat
of litigation is commonly cited as a reason for the recent trend towards
minimizing the information shared about training datasets by both corporate and
public interest actors. This trend in limiting data information causes harm by
hindering transparency, accountability, and innovation in the broader ecosystem
by denying researchers, auditors, and impacted individuals access to the
information needed to understand AI models.
  While this could be mitigated by training language models on open access and
public domain data, at the time of writing, there are no such models (trained
at a meaningful scale) due to the substantial technical and sociological
challenges in assembling the necessary corpus. These challenges include
incomplete and unreliable metadata, the cost and complexity of digitizing
physical records, and the diverse set of legal and technical skills required to
ensure relevance and responsibility in a quickly changing landscape. Building
towards a future where AI systems can be trained on openly licensed data that
is responsibly curated and governed requires collaboration across legal,
technical, and policy domains, along with investments in metadata standards,
digitization, and fostering a culture of openness.

摘要：許多 AI 公司在沒有取得著作權所有者許可的情況下，使用資料來訓練大型語言模型 (LLM)。在不同司法管轄區，這種做法的合法性有所不同：在歐盟和日本等國家，在特定限制下允許此做法，而在美國，法律環境則較為模糊。無論法律地位如何，來自創意製作人的疑慮已導致多起引人注目的著作權訴訟，而訴訟威脅通常被視為近期企業和公共利益參與者趨向於盡量減少分享關於訓練資料集資訊的原因。限制資料資訊的趨勢會透過拒絕研究人員、稽核人員和受影響的個人取得理解 AI 模型所需的資訊，進而阻礙更廣泛生態系統中的透明度、問責制和創新，從而造成傷害。儘管透過在開放取用和公有領域資料上訓練語言模型可以減輕這個問題，但在撰寫本文時，由於在彙編必要的語料庫方面存在重大的技術和社會挑戰，因此並不存在此類模型（以有意義的規模訓練）。這些挑戰包括不完整且不可靠的元資料、數位化實體記錄的成本和複雜性，以及在快速變化的環境中確保相關性和責任所需的多樣化法律和技術技能。朝著 AI 系統能夠在負責任地策展和管理的開放授權資料上進行訓練的未來邁進，需要跨法律、技術和政策領域進行合作，並投資於元資料標準、數位化，以及培養開放文化。

##### **Eliciting In-context Retrieval and Reasoning for Long-context Large Language Models**
2501.08248v1 by Yifu Qiu, Varun Embar, Yizhe Zhang, Navdeep Jaitly, Shay B. Cohen, Benjamin Han

Recent advancements in long-context language models (LCLMs) promise to
transform Retrieval-Augmented Generation (RAG) by simplifying pipelines. With
their expanded context windows, LCLMs can process entire knowledge bases and
perform retrieval and reasoning directly -- a capability we define as
In-Context Retrieval and Reasoning (ICR^2). However, existing benchmarks like
LOFT often overestimate LCLM performance by providing overly simplified
contexts. To address this, we introduce ICR^2, a benchmark that evaluates LCLMs
in more realistic scenarios by including confounding passages retrieved with
strong retrievers. We then propose three methods to enhance LCLM performance:
(1) retrieve-then-generate fine-tuning, (2) retrieval-attention-probing, which
uses attention heads to filter and de-noise long contexts during decoding, and
(3) joint retrieval head training alongside the generation head. Our evaluation
of five well-known LCLMs on LOFT and ICR^2 demonstrates significant gains with
our best approach applied to Mistral-7B: +17 and +15 points by Exact Match on
LOFT, and +13 and +2 points on ICR^2, compared to vanilla RAG and supervised
fine-tuning, respectively. It even outperforms GPT-4-Turbo on most tasks
despite being a much smaller model.

摘要：長文本語言模型 (LCLM) 的最新進展有望透過簡化管線來轉換檢索增強產生 (RAG)。LCLM 透過其擴充的內容視窗，可以處理整個知識庫，並直接執行檢索和推理，我們將此功能定義為情境內檢索和推理 (ICR^2)。不過，現有的基準（例如 LOFT）經常透過提供過度簡化的內容來高估 LCLM 的效能。為了解決這個問題，我們推出 ICR^2，這是一個透過納入使用強大檢索器檢索到的混淆段落，在更實際的場景中評估 LCLM 的基準。接著，我們提出三種方法來提升 LCLM 的效能：(1) 先檢索後產生的微調、(2) 檢索注意力探測，它使用注意力標頭在解碼期間過濾和去除雜訊，以及 (3) 在產生標頭旁進行聯合檢索標頭訓練。我們在 LOFT 和 ICR^2 上對五個知名的 LCLM 進行評估，證明我們的最佳方法應用於 Mistral-7B 時有顯著進步：與原始 RAG 和監督微調相比，在 LOFT 上的完全比對增加了 17 和 15 點，在 ICR^2 上增加了 13 和 2 點。即使它是一個小得多的模型，但在大多數任務上仍優於 GPT-4-Turbo。

##### **A Feature-Level Ensemble Model for COVID-19 Identification in CXR Images using Choquet Integral and Differential Evolution Optimization**
2501.08241v1 by Amir Reza Takhsha, Maryam Rastgarpour, Mozhgan Naderi

The COVID-19 pandemic has profoundly impacted billions globally. It
challenges public health and healthcare systems due to its rapid spread and
severe respiratory effects. An effective strategy to mitigate the COVID-19
pandemic involves integrating testing to identify infected individuals. While
RT-PCR is considered the gold standard for diagnosing COVID-19, it has some
limitations such as the risk of false negatives. To address this problem, this
paper introduces a novel Deep Learning Diagnosis System that integrates
pre-trained Deep Convolutional Neural Networks (DCNNs) within an ensemble
learning framework to achieve precise identification of COVID-19 cases from
Chest X-ray (CXR) images. We combine feature vectors from the final hidden
layers of pre-trained DCNNs using the Choquet integral to capture interactions
between different DCNNs that a linear approach cannot. We employed
Sugeno-$\lambda$ measure theory to derive fuzzy measures for subsets of
networks to enable aggregation. We utilized Differential Evolution to estimate
fuzzy densities. We developed a TensorFlow-based layer for Choquet operation to
facilitate efficient aggregation, due to the intricacies involved in
aggregating feature vectors. Experimental results on the COVIDx dataset show
that our ensemble model achieved 98\% accuracy in three-class classification
and 99.50\% in binary classification, outperforming its components-DenseNet-201
(97\% for three-class, 98.75\% for binary), Inception-v3 (96.25\% for
three-class, 98.50\% for binary), and Xception (94.50\% for three-class, 98\%
for binary)-and surpassing many previous methods.

摘要：新冠肺炎疫情已对全球数十亿人产生深远影响。由于其传播迅速且呼吸道症状严重，它对公共卫生和医疗保健系统构成挑战。减轻新冠肺炎疫情的有效策略包括整合检测以识别受感染者。虽然 RT-PCR 被认为是诊断新冠肺炎的黄金标准，但它也有一些限制，例如假阴性的风险。为了解决这个问题，本文介绍了一种新颖的深度学习诊断系统，该系统将预训练的深度卷积神经网络 (DCNN) 集成到集成学习框架中，以从胸部 X 射线 (CXR) 图像中精确识别新冠肺炎病例。我们使用 Choquet 积分结合来自预训练 DCNN 的最后一个隐藏层的特征向量，以捕获线性方法无法实现的不同 DCNN 之间的交互。我们采用 Sugeno-$\lambda$ 测度理论来导出网络子集的模糊测度以实现聚合。我们利用差分进化来估计模糊密度。由于聚合特征向量的复杂性，我们开发了一个基于 TensorFlow 的 Choquet 操作层以促进高效聚合。COVIDx 数据集上的实验结果表明，我们的集成模型在三类分类中达到 98% 的准确率，在二元分类中达到 99.50%，优于其组件 DenseNet-201（三类为 97%，二元为 98.75%）、Inception-v3（三类为 96.25%，二元为 98.50%）和 Xception（三类为 94.50%，二元为 98%），并超越了许多以前的方法。

##### **Dynamic Pricing in High-Speed Railways Using Multi-Agent Reinforcement Learning**
2501.08234v1 by Enrique Adrian Villarrubia-Martin, Luis Rodriguez-Benitez, David Muñoz-Valero, Giovanni Montana, Luis Jimenez-Linares

This paper addresses a critical challenge in the high-speed passenger railway
industry: designing effective dynamic pricing strategies in the context of
competing and cooperating operators. To address this, a multi-agent
reinforcement learning (MARL) framework based on a non-zero-sum Markov game is
proposed, incorporating random utility models to capture passenger decision
making. Unlike prior studies in areas such as energy, airlines, and mobile
networks, dynamic pricing for railway systems using deep reinforcement learning
has received limited attention. A key contribution of this paper is a
parametrisable and versatile reinforcement learning simulator designed to model
a variety of railway network configurations and demand patterns while enabling
realistic, microscopic modelling of user behaviour, called RailPricing-RL. This
environment supports the proposed MARL framework, which models heterogeneous
agents competing to maximise individual profits while fostering cooperative
behaviour to synchronise connecting services. Experimental results validate the
framework, demonstrating how user preferences affect MARL performance and how
pricing policies influence passenger choices, utility, and overall system
dynamics. This study provides a foundation for advancing dynamic pricing
strategies in railway systems, aligning profitability with system-wide
efficiency, and supporting future research on optimising pricing policies.

摘要：本文探討高速鐵路產業中的關鍵挑戰：在競爭與合作的營運商背景下，設計有效的動態定價策略。為了解決此問題，提出一個基於非零和馬可夫博弈的多重代理強化學習 (MARL) 架構，並納入隨機效用模型來捕捉乘客決策。與能源、航空公司和行動網路等領域先前的研究不同，使用深度強化學習的鐵路系統動態定價受到的關注有限。本文的一項重要貢獻是可參數化且用途廣泛的強化學習模擬器，旨在模擬各種鐵路網路組態和需求模式，同時支援使用者行為的實際微觀建模，稱為 RailPricing-RL。此環境支援所提出的 MARL 架構，該架構模擬異質代理競爭以最大化個別利潤，同時促進合作行為以同步連接服務。實驗結果驗證了此架構，展示使用者偏好如何影響 MARL 性能，以及定價政策如何影響乘客選擇、效用和整體系統動態。本研究提供了推進鐵路系統動態定價策略的基礎，將獲利能力與系統範圍的效率結合起來，並支援未來優化定價政策的研究。

##### **ASTRID -- An Automated and Scalable TRIaD for the Evaluation of RAG-based Clinical Question Answering Systems**
2501.08208v1 by Mohita Chowdhury, Yajie Vera He, Aisling Higham, Ernest Lim

Large Language Models (LLMs) have shown impressive potential in clinical
question answering (QA), with Retrieval Augmented Generation (RAG) emerging as
a leading approach for ensuring the factual accuracy of model responses.
However, current automated RAG metrics perform poorly in clinical and
conversational use cases. Using clinical human evaluations of responses is
expensive, unscalable, and not conducive to the continuous iterative
development of RAG systems. To address these challenges, we introduce ASTRID -
an Automated and Scalable TRIaD for evaluating clinical QA systems leveraging
RAG - consisting of three metrics: Context Relevance (CR), Refusal Accuracy
(RA), and Conversational Faithfulness (CF). Our novel evaluation metric, CF, is
designed to better capture the faithfulness of a model's response to the
knowledge base without penalising conversational elements. To validate our
triad, we curate a dataset of over 200 real-world patient questions posed to an
LLM-based QA agent during surgical follow-up for cataract surgery - the highest
volume operation in the world - augmented with clinician-selected questions for
emergency, clinical, and non-clinical out-of-domain scenarios. We demonstrate
that CF can predict human ratings of faithfulness better than existing
definitions for conversational use cases. Furthermore, we show that evaluation
using our triad consisting of CF, RA, and CR exhibits alignment with clinician
assessment for inappropriate, harmful, or unhelpful responses. Finally, using
nine different LLMs, we demonstrate that the three metrics can closely agree
with human evaluations, highlighting the potential of these metrics for use in
LLM-driven automated evaluation pipelines. We also publish the prompts and
datasets for these experiments, providing valuable resources for further
research and development.

摘要：大型語言模型 (LLM) 在臨床問答 (QA) 中展現了令人印象深刻的潛力，其中檢索增強生成 (RAG) 成為確保模型回應事實準確性的領先方法。然而，目前的自動化 RAG 指標在臨床和對話式用例中表現不佳。使用臨床人類對回應的評估既昂貴又不具可擴充性，也不利於 RAG 系統的持續迭代開發。為了應對這些挑戰，我們引入了 ASTRID - 一種用於評估利用 RAG 的臨床 QA 系統的自動化且可擴充的 TRIaD - 包含三個指標：脈絡相關性 (CR)、拒絕準確性 (RA) 和對話忠實度 (CF)。我們新穎的評估指標 CF 旨在更好地捕捉模型對知識庫的回應的忠實度，同時不懲罰對話元素。為了驗證我們的三元組，我們策劃了一個數據集，其中包含在白內障手術術後隨訪期間向 LLM 基於 QA 的代理提出的 200 多個真實世界的患者問題 - 世界上手術量最大的手術 - 並增加了臨床醫生選擇的問題，用於緊急、臨床和非臨床領域外情境。我們證明，與對話式用例現有定義相比，CF 可以更好地預測人類對忠實度的評分。此外，我們表明使用由 CF、RA 和 CR 組成的三元組進行評估與臨床醫生對不適當、有害或無益的回應的評估保持一致。最後，使用九種不同的 LLM，我們證明這三個指標可以與人類評估緊密一致，突顯了這些指標在 LLM 驅動的自動化評估管道中使用的潛力。我們還公佈了這些實驗的提示和數據集，為進一步的研究和開發提供了寶貴的資源。

##### **Modeling Feature Maps for Quantum Machine Learning**
2501.08205v1 by Navneet Singh, Shiva Raj Pokhrel

Quantum Machine Learning (QML) offers significant potential for complex tasks
like genome sequence classification, but quantum noise on Noisy
Intermediate-Scale Quantum (NISQ) devices poses practical challenges. This
study systematically evaluates how various quantum noise models including
dephasing, amplitude damping, depolarizing, thermal noise, bit-flip, and
phase-flip affect key QML algorithms (QSVC, Peg-QSVC, QNN, VQC) and feature
mapping techniques (ZFeatureMap, ZZFeatureMap, and PauliFeatureMap). Results
indicate that QSVC is notably robust under noise, whereas Peg-QSVC and QNN are
more sensitive, particularly to depolarizing and amplitude-damping noise. The
PauliFeatureMap is especially vulnerable, highlighting difficulties in
maintaining accurate classification under noisy conditions. These findings
underscore the critical importance of feature map selection and noise
mitigation strategies in optimizing QML for genomic classification, with
promising implications for personalized medicine.

摘要：量子機器學習 (QML) 為基因組序列分類等複雜任務提供了巨大的潛力，但有噪聲中階量子 (NISQ) 裝置上的量子噪聲會帶來實際挑戰。本研究系統性地評估了各種量子噪聲模型，包括去相位、振幅阻尼、去極化、熱噪聲、位元翻轉和相位翻轉，如何影響主要的 QML 演算法 (QSVC、Peg-QSVC、QNN、VQC) 和特徵對應技術 (ZFeatureMap、ZZFeatureMap 和 PauliFeatureMap)。結果表明，QSVC 在噪聲下顯著強健，而 Peg-QSVC 和 QNN 則較敏感，特別是對於去極化和振幅阻尼噪聲。PauliFeatureMap 特別容易受到影響，突顯了在有噪聲條件下維持準確分類的難度。這些發現強調了特徵對應選擇和噪聲緩解策略在最佳化 QML 以進行基因組分類中的重要性，對個人化醫療有令人振奮的影響。

##### **ArithmAttack: Evaluating Robustness of LLMs to Noisy Context in Math Problem Solving**
2501.08203v1 by Zain Ul Abedin, Shahzeb Qamar, Lucie Flek, Akbar Karimi

While Large Language Models (LLMs) have shown impressive capabilities in math
problem-solving tasks, their robustness to noisy inputs is not well-studied. In
this work, we propose ArithmAttack to examine how robust the LLMs are when they
encounter noisy prompts that contain extra noise in the form of punctuation
marks. While being easy to implement, ArithmAttack does not cause any
information loss since words are not added or deleted from the context. We
evaluate the robustness of seven LLMs, including LLama3, Mistral, and
Mathstral, on noisy GSM8K and MultiArith datasets. Our experiments suggest that
all the studied models show vulnerability to such noise, with more noise
leading to poorer performances.

摘要：儘管大型語言模型 (LLM) 在數學問題解決任務中展現出令人印象深刻的能力，它們對於有雜訊輸入的健壯性尚未得到充分研究。在這項工作中，我們提出 ArithmAttack 來檢驗 LLM 在遇到包含額外雜訊（以標點符號形式）的雜訊提示時具有多麼健壯。ArithmAttack 容易實作，而且不會造成任何資訊遺失，因為不會從內容中新增或刪除字詞。我們評估了七個 LLM 的健壯性，包括 LLama3、Mistral 和 Mathstral，在有雜訊的 GSM8K 和 MultiArith 資料集上。我們的實驗表明，所有研究的模型都顯示出對這種雜訊的脆弱性，雜訊越多，效能越差。

