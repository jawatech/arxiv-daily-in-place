{"2409.06427": {"publish_time": "2024-09-10", "title": "GeMuCo: Generalized Multisensory Correlational Model for Body Schema Learning", "paper_summary": "Humans can autonomously learn the relationship between sensation and motion\nin their own bodies, estimate and control their own body states, and move while\ncontinuously adapting to the current environment. On the other hand, current\nrobots control their bodies by learning the network structure described by\nhumans from their experiences, making certain assumptions on the relationship\nbetween sensors and actuators. In addition, the network model does not adapt to\nchanges in the robot's body, the tools that are grasped, or the environment,\nand there is no unified theory, not only for control but also for state\nestimation, anomaly detection, simulation, and so on. In this study, we propose\na Generalized Multisensory Correlational Model (GeMuCo), in which the robot\nitself acquires a body schema describing the correlation between sensors and\nactuators from its own experience, including model structures such as network\ninput/output. The robot adapts to the current environment by updating this body\nschema model online, estimates and controls its body state, and even performs\nanomaly detection and simulation. We demonstrate the effectiveness of this\nmethod by applying it to tool-use considering changes in grasping state for an\naxis-driven robot, to joint-muscle mapping learning for a musculoskeletal\nrobot, and to full-body tool manipulation for a low-rigidity plastic-made\nhumanoid.", "paper_summary_zh": "\u4eba\u985e\u53ef\u4ee5\u81ea\u4e3b\u5b78\u7fd2\u8eab\u9ad4\u4e2d\u611f\u89ba\u548c\u52d5\u4f5c\u4e4b\u9593\u7684\u95dc\u4fc2\uff0c\u4f30\u8a08\u548c\u63a7\u5236\u81ea\u5df1\u7684\u8eab\u9ad4\u72c0\u614b\uff0c\u4e26\u5728\u6301\u7e8c\u9069\u61c9\u7576\u524d\u74b0\u5883\u7684\u540c\u6642\u79fb\u52d5\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u7576\u524d\u7684\u6a5f\u5668\u4eba\u901a\u904e\u5f9e\u7d93\u9a57\u4e2d\u5b78\u7fd2\u4eba\u985e\u63cf\u8ff0\u7684\u7db2\u8def\u7d50\u69cb\u4f86\u63a7\u5236\u5176\u8eab\u9ad4\uff0c\u5c0d\u611f\u6e2c\u5668\u548c\u81f4\u52d5\u5668\u4e4b\u9593\u7684\u95dc\u4fc2\u505a\u51fa\u67d0\u4e9b\u5047\u8a2d\u3002\u6b64\u5916\uff0c\u7db2\u8def\u6a21\u578b\u4e0d\u6703\u9069\u61c9\u6a5f\u5668\u4eba\u8eab\u9ad4\u3001\u6240\u6293\u53d6\u7684\u5de5\u5177\u6216\u74b0\u5883\u7684\u8b8a\u5316\uff0c\u800c\u4e14\u4e0d\u50c5\u5c0d\u65bc\u63a7\u5236\uff0c\u800c\u4e14\u5c0d\u65bc\u72c0\u614b\u4f30\u8a08\u3001\u7570\u5e38\u5075\u6e2c\u3001\u6a21\u64ec\u7b49\uff0c\u90fd\u6c92\u6709\u7d71\u4e00\u7684\u7406\u8ad6\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u5ee3\u7fa9\u7684\u591a\u611f\u5b98\u76f8\u95dc\u6a21\u578b (GeMuCo)\uff0c\u5176\u4e2d\u6a5f\u5668\u4eba\u672c\u8eab\u5f9e\u81ea\u5df1\u7684\u7d93\u9a57\u4e2d\u7372\u53d6\u63cf\u8ff0\u611f\u6e2c\u5668\u548c\u81f4\u52d5\u5668\u4e4b\u9593\u76f8\u95dc\u6027\u7684\u8eab\u9ad4\u6a21\u5f0f\uff0c\u5305\u62ec\u7db2\u8def\u8f38\u5165/\u8f38\u51fa\u7b49\u6a21\u578b\u7d50\u69cb\u3002\u6a5f\u5668\u4eba\u901a\u904e\u5728\u7dda\u4e0a\u66f4\u65b0\u9019\u500b\u8eab\u9ad4\u6a21\u5f0f\u6a21\u578b\u4f86\u9069\u61c9\u7576\u524d\u74b0\u5883\uff0c\u4f30\u8a08\u548c\u63a7\u5236\u5176\u8eab\u9ad4\u72c0\u614b\uff0c\u751a\u81f3\u57f7\u884c\u7570\u5e38\u5075\u6e2c\u548c\u6a21\u64ec\u3002\u6211\u5011\u901a\u904e\u5c07\u6b64\u65b9\u6cd5\u61c9\u7528\u65bc\u8003\u616e\u8ef8\u9a45\u52d5\u6a5f\u5668\u4eba\u7684\u6293\u63e1\u72c0\u614b\u8b8a\u5316\u3001\u7528\u65bc\u808c\u8089\u9aa8\u9abc\u6a5f\u5668\u4eba\u7684\u95dc\u7bc0\u808c\u8089\u5c0d\u61c9\u5b78\u7fd2\u4ee5\u53ca\u7528\u65bc\u4f4e\u525b\u6027\u5851\u81a0\u88fd\u6210\u7684\u985e\u4eba\u6a5f\u5668\u4eba\u7684\u5168\u8eab\u5de5\u5177\u64cd\u4f5c\uff0c\u4f86\u8b49\u660e\u6b64\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "author": "Kento Kawaharazuka et.al.", "authors": "Kento Kawaharazuka, Kei Okada, Masayuki Inaba", "id": "2409.06427v1", "paper_url": "http://arxiv.org/abs/2409.06427v1", "repo": "null"}}