{"2412.12661": {"publish_time": "2024-12-17", "title": "MedMax: Mixed-Modal Instruction Tuning for Training Biomedical Assistants", "paper_summary": "Recent advancements in mixed-modal generative models have enabled flexible\nintegration of information across image-text content. These models have opened\nnew avenues for developing unified biomedical assistants capable of analyzing\nbiomedical images, answering complex questions about them, and predicting the\nimpact of medical procedures on a patient's health. However, existing resources\nface challenges such as limited data availability, narrow domain coverage, and\nrestricted sources (e.g., medical papers). To address these gaps, we present\nMedMax, the first large-scale multimodal biomedical instruction-tuning dataset\nfor mixed-modal foundation models. With 1.47 million instances, MedMax\nencompasses a diverse range of tasks, including multimodal content generation\n(interleaved image-text data), biomedical image captioning and generation,\nvisual chatting, and report understanding. These tasks span diverse medical\ndomains such as radiology and histopathology. Subsequently, we fine-tune a\nmixed-modal foundation model on the MedMax dataset, achieving significant\nperformance improvements: a 26% gain over the Chameleon model and an 18.3%\nimprovement over GPT-4o across 12 downstream biomedical visual\nquestion-answering tasks. Additionally, we introduce a unified evaluation suite\nfor biomedical tasks, providing a robust framework to guide the development of\nnext-generation mixed-modal biomedical AI assistants.", "paper_summary_zh": "\u6df7\u5408\u6a21\u5f0f\u751f\u6210\u6a21\u578b\u7684\u6700\u65b0\u8fdb\u5c55\u4f7f\u5f97\u8de8\u56fe\u50cf\u6587\u672c\u5185\u5bb9\u7075\u6d3b\u6574\u5408\u4fe1\u606f\u6210\u4e3a\u53ef\u80fd\u3002\u8fd9\u4e9b\u6a21\u578b\u4e3a\u5f00\u53d1\u7edf\u4e00\u7684\u751f\u7269\u533b\u5b66\u52a9\u624b\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u8fd9\u4e9b\u52a9\u624b\u80fd\u591f\u5206\u6790\u751f\u7269\u533b\u5b66\u56fe\u50cf\u3001\u56de\u7b54\u6709\u5173\u56fe\u50cf\u7684\u590d\u6742\u95ee\u9898\uff0c\u5e76\u9884\u6d4b\u533b\u7597\u7a0b\u5e8f\u5bf9\u60a3\u8005\u5065\u5eb7\u7684\u5f71\u54cd\u3002\u7136\u800c\uff0c\u73b0\u6709\u8d44\u6e90\u9762\u4e34\u7740\u6570\u636e\u53ef\u7528\u6027\u6709\u9650\u3001\u9886\u57df\u8986\u76d6\u8303\u56f4\u72ed\u7a84\u548c\u6765\u6e90\u53d7\u9650\uff08\u4f8b\u5982\u533b\u5b66\u8bba\u6587\uff09\u7b49\u6311\u6218\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u5dee\u8ddd\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 MedMax\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u7528\u4e8e\u6df7\u5408\u6a21\u5f0f\u57fa\u7840\u6a21\u578b\u7684\u5927\u89c4\u6a21\u591a\u6a21\u6001\u751f\u7269\u533b\u5b66\u6307\u4ee4\u5fae\u8c03\u6570\u636e\u96c6\u3002MedMax \u62e5\u6709 147 \u4e07\u4e2a\u5b9e\u4f8b\uff0c\u6db5\u76d6\u4e86\u5404\u79cd\u4efb\u52a1\uff0c\u5305\u62ec\u591a\u6a21\u6001\u5185\u5bb9\u751f\u6210\uff08\u4ea4\u9519\u56fe\u50cf\u6587\u672c\u6570\u636e\uff09\u3001\u751f\u7269\u533b\u5b66\u56fe\u50cf\u6807\u9898\u548c\u751f\u6210\u3001\u53ef\u89c6\u5316\u804a\u5929\u548c\u62a5\u544a\u7406\u89e3\u3002\u8fd9\u4e9b\u4efb\u52a1\u8de8\u8d8a\u4e86\u653e\u5c04\u5b66\u548c\u7ec4\u7ec7\u75c5\u7406\u5b66\u7b49\u4e0d\u540c\u7684\u533b\u5b66\u9886\u57df\u3002\u968f\u540e\uff0c\u6211\u4eec\u5728 MedMax \u6570\u636e\u96c6\u4e0a\u5bf9\u6df7\u5408\u6a21\u5f0f\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff1a\u5728 12 \u4e2a\u4e0b\u6e38\u751f\u7269\u533b\u5b66\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u4e2d\uff0c\u6bd4 Chameleon \u6a21\u578b\u63d0\u5347\u4e86 26%\uff0c\u6bd4 GPT-4o \u63d0\u5347\u4e86 18.3%\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u5f15\u5165\u4e86\u7528\u4e8e\u751f\u7269\u533b\u5b66\u4efb\u52a1\u7684\u7edf\u4e00\u8bc4\u4f30\u5957\u4ef6\uff0c\u4e3a\u6307\u5bfc\u4e0b\u4e00\u4ee3\u6df7\u5408\u6a21\u5f0f\u751f\u7269\u533b\u5b66 AI \u52a9\u624b\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u7a33\u5065\u7684\u6846\u67b6\u3002", "author": "Hritik Bansal et.al.", "authors": "Hritik Bansal, Daniel Israel, Siyan Zhao, Shufan Li, Tung Nguyen, Aditya Grover", "id": "2412.12661v1", "paper_url": "http://arxiv.org/abs/2412.12661v1", "repo": "https://github.com/Hritikbansal/medmax"}}