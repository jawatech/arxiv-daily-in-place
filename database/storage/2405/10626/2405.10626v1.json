{"2405.10626": {"publish_time": "2024-05-17", "title": "Dynamic data sampler for cross-language transfer learning in large language models", "paper_summary": "Large Language Models (LLMs) have gained significant attention in the field\nof natural language processing (NLP) due to their wide range of applications.\nHowever, training LLMs for languages other than English poses significant\nchallenges, due to the difficulty in acquiring large-scale corpus and the\nrequisite computing resources. In this paper, we propose ChatFlow, a\ncross-language transfer-based LLM, to address these challenges and train large\nChinese language models in a cost-effective manner. We employ a mix of Chinese,\nEnglish, and parallel corpus to continuously train the LLaMA2 model, aiming to\nalign cross-language representations and facilitate the knowledge transfer\nspecifically to the Chinese language model. In addition, we use a dynamic data\nsampler to progressively transition the model from unsupervised pre-training to\nsupervised fine-tuning. Experimental results demonstrate that our approach\naccelerates model convergence and achieves superior performance. We evaluate\nChatFlow on popular Chinese and English benchmarks, the results indicate that\nit outperforms other Chinese models post-trained on LLaMA-2-7B.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u56e0\u5176\u5ee3\u6cdb\u7684\u61c9\u7528\u800c\u5728\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u9818\u57df\u5099\u53d7\u95dc\u6ce8\u3002\u7136\u800c\uff0c\u8a13\u7df4\u975e\u82f1\u8a9e\u8a9e\u8a00\u7684 LLM \u5177\u6709\u91cd\u5927\u6311\u6230\uff0c\u56e0\u70ba\u96e3\u4ee5\u7372\u53d6\u5927\u898f\u6a21\u8a9e\u6599\u5eab\u548c\u5fc5\u8981\u7684\u904b\u7b97\u8cc7\u6e90\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa ChatFlow\uff0c\u4e00\u500b\u57fa\u65bc\u8de8\u8a9e\u8a00\u8f49\u79fb\u7684 LLM\uff0c\u4ee5\u89e3\u6c7a\u9019\u4e9b\u6311\u6230\u4e26\u4ee5\u7d93\u6fdf\u6709\u6548\u7684\u65b9\u5f0f\u8a13\u7df4\u5927\u578b\u4e2d\u6587\u8a9e\u8a00\u6a21\u578b\u3002\u6211\u5011\u63a1\u7528\u4e2d\u6587\u3001\u82f1\u6587\u548c\u5e73\u884c\u8a9e\u6599\u5eab\u7684\u7d44\u5408\u4f86\u6301\u7e8c\u8a13\u7df4 LLaMA2 \u6a21\u578b\uff0c\u65e8\u5728\u5c0d\u9f4a\u8de8\u8a9e\u8a00\u8868\u793a\u4e26\u4fc3\u9032\u77e5\u8b58\u8f49\u79fb\uff0c\u7279\u5225\u662f\u8f49\u79fb\u5230\u4e2d\u6587\u8a9e\u8a00\u6a21\u578b\u3002\u6b64\u5916\uff0c\u6211\u5011\u4f7f\u7528\u52d5\u614b\u6578\u64da\u63a1\u6a23\u5668\u9010\u6b65\u5c07\u6a21\u578b\u5f9e\u7121\u76e3\u7763\u9810\u8a13\u7df4\u8f49\u63db\u70ba\u76e3\u7763\u5fae\u8abf\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u6211\u5011\u7684\u505a\u6cd5\u52a0\u901f\u4e86\u6a21\u578b\u6536\u6582\u4e26\u5be6\u73fe\u4e86\u5353\u8d8a\u7684\u6027\u80fd\u3002\u6211\u5011\u5728\u6d41\u884c\u7684\u4e2d\u82f1\u6587\u57fa\u6e96\u4e0a\u8a55\u4f30 ChatFlow\uff0c\u7d50\u679c\u8868\u660e\uff0c\u5b83\u512a\u65bc\u5728 LLaMA-2-7B \u4e0a\u9032\u884c\u5f8c\u8a13\u7df4\u7684\u5176\u4ed6\u4e2d\u6587\u6a21\u578b\u3002", "author": "Yudong Li et.al.", "authors": "Yudong Li, Yuhao Feng, Wen Zhou, Zhe Zhao, Linlin Shen, Cheng Hou, Xianxu Hou", "id": "2405.10626v1", "paper_url": "http://arxiv.org/abs/2405.10626v1", "repo": "https://github.com/cvi-szu/linly"}}