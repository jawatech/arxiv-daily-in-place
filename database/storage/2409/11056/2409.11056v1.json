{"2409.11056": {"publish_time": "2024-09-17", "title": "Large Language Models are Good Multi-lingual Learners : When LLMs Meet Cross-lingual Prompts", "paper_summary": "With the advent of Large Language Models (LLMs), generating rule-based data\nfor real-world applications has become more accessible. Due to the inherent\nambiguity of natural language and the complexity of rule sets, especially in\nlong contexts, LLMs often struggle to follow all specified rules, frequently\nomitting at least one. To enhance the reasoning and understanding of LLMs on\nlong and complex contexts, we propose a novel prompting strategy Multi-Lingual\nPrompt, namely MLPrompt, which automatically translates the error-prone rule\nthat an LLM struggles to follow into another language, thus drawing greater\nattention to it. Experimental results on public datasets across various tasks\nhave shown MLPrompt can outperform state-of-the-art prompting methods such as\nChain of Thought, Tree of Thought, and Self-Consistency. Additionally, we\nintroduce a framework integrating MLPrompt with an auto-checking mechanism for\nstructured data generation, with a specific case study in text-to-MIP\ninstances. Further, we extend the proposed framework for text-to-SQL to\ndemonstrate its generation ability towards structured data synthesis.", "paper_summary_zh": "\u96a8\u8457\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u51fa\u73fe\uff0c\u751f\u6210\u57fa\u65bc\u898f\u5247\u7684\u8cc7\u6599\n\u5c0d\u65bc\u771f\u5be6\u4e16\u754c\u7684\u61c9\u7528\u7a0b\u5f0f\u4f86\u8aaa\u8b8a\u5f97\u66f4\u5bb9\u6613\u53d6\u5f97\u3002\u7531\u65bc\u81ea\u7136\u8a9e\u8a00\u7684\u5167\u5728\n\u6a21\u7cca\u6027\u548c\u898f\u5247\u96c6\u7684\u8907\u96dc\u6027\uff0c\u7279\u5225\u662f\u5728\u9577\u8a9e\u5883\u4e2d\uff0cLLM \u5e38\u5e38\u96e3\u4ee5\u9075\u5faa\u6240\u6709\u6307\u5b9a\u7684\u898f\u5247\uff0c\u7d93\u5e38\n\u81f3\u5c11\u907a\u6f0f\u4e00\u500b\u3002\u70ba\u4e86\u589e\u5f37 LLM \u5728\u9577\u4e14\u8907\u96dc\u7684\u8a9e\u5883\u4e2d\u7684\u63a8\u7406\u548c\u7406\u89e3\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u65b0\u7a4e\u7684\u63d0\u793a\u7b56\u7565\u591a\u8a9e\u8a00\n\u63d0\u793a\uff0c\u5373 MLPrompt\uff0c\u5b83\u81ea\u52d5\u5c07 LLM \u96e3\u4ee5\u9075\u5faa\u7684\u5bb9\u6613\u51fa\u932f\u7684\u898f\u5247\u7ffb\u8b6f\u6210\u53e6\u4e00\u7a2e\u8a9e\u8a00\uff0c\u5f9e\u800c\u5f15\u8d77\u66f4\u5927\u7684\n\u6ce8\u610f\u5b83\u3002\u5728\u5404\u7a2e\u4efb\u52d9\u7684\u516c\u7528\u8cc7\u6599\u96c6\u4e0a\u7684\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0cMLPrompt \u53ef\u4ee5\u512a\u65bc\u6700\u5148\u9032\u7684\u63d0\u793a\u65b9\u6cd5\uff0c\u4f8b\u5982\n\u601d\u8003\u93c8\u3001\u601d\u8003\u6a39\u548c\u81ea\u6211\u4e00\u81f4\u6027\u3002\u6b64\u5916\uff0c\u6211\u5011\n\u5f15\u5165\u4e86\u5c07 MLPrompt \u8207\u81ea\u52d5\u6aa2\u67e5\u6a5f\u5236\u6574\u5408\u7684\u6846\u67b6\uff0c\u7528\u65bc\u7d50\u69cb\u5316\u8cc7\u6599\u751f\u6210\uff0c\u4e26\u4ee5\u6587\u5b57\u8f49\u63db\u70ba MIP\n\u5be6\u4f8b\u70ba\u5177\u9ad4\u6848\u4f8b\u7814\u7a76\u3002\u6b64\u5916\uff0c\u6211\u5011\u64f4\u5145\u4e86\u5efa\u8b70\u7684\u6587\u5b57\u8f49\u63db\u70ba SQL \u6846\u67b6\uff0c\u4ee5\u5c55\u793a\u5176\u5c0d\u7d50\u69cb\u5316\u8cc7\u6599\u5408\u6210\u7684\u751f\u6210\u80fd\u529b\u3002", "author": "Teng Wang et.al.", "authors": "Teng Wang, Zhenqi He, Wing-Yin Yu, Xiaojin Fu, Xiongwei Han", "id": "2409.11056v1", "paper_url": "http://arxiv.org/abs/2409.11056v1", "repo": "null"}}