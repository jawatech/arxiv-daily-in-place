{"2408.05098": {"publish_time": "2024-08-09", "title": "Overcoming the Limitations of Layer Synchronization in Spiking Neural Networks", "paper_summary": "Currently, neural-network processing in machine learning applications relies\non layer synchronization, whereby neurons in a layer aggregate incoming\ncurrents from all neurons in the preceding layer, before evaluating their\nactivation function. This is practiced even in artificial Spiking Neural\nNetworks (SNNs), which are touted as consistent with neurobiology, in spite of\nprocessing in the brain being, in fact asynchronous. A truly asynchronous\nsystem however would allow all neurons to evaluate concurrently their threshold\nand emit spikes upon receiving any presynaptic current. Omitting layer\nsynchronization is potentially beneficial, for latency and energy efficiency,\nbut asynchronous execution of models previously trained with layer\nsynchronization may entail a mismatch in network dynamics and performance. We\npresent a study that documents and quantifies this problem in three datasets on\nour simulation environment that implements network asynchrony, and we show that\nmodels trained with layer synchronization either perform sub-optimally in\nabsence of the synchronization, or they will fail to benefit from any energy\nand latency reduction, when such a mechanism is in place. We then \"make ends\nmeet\" and address the problem with unlayered backprop, a novel\nbackpropagation-based training method, for learning models suitable for\nasynchronous processing. We train with it models that use different neuron\nexecution scheduling strategies, and we show that although their neurons are\nmore reactive, these models consistently exhibit lower overall spike density\n(up to 50%), reach a correct decision faster (up to 2x) without integrating all\nspikes, and achieve superior accuracy (up to 10% higher). Our findings suggest\nthat asynchronous event-based (neuromorphic) AI computing is indeed more\nefficient, but we need to seriously rethink how we train our SNN models, to\nbenefit from it.", "paper_summary_zh": "<paragraph>\u76ee\u524d\uff0c\u6a5f\u5668\u5b78\u7fd2\u61c9\u7528\u7a0b\u5f0f\u4e2d\u7684\u795e\u7d93\u7db2\u8def\u8655\u7406\u4f9d\u8cf4\u65bc\u5c64\u540c\u6b65\uff0c\u85c9\u6b64\uff0c\u4e00\u5c64\u4e2d\u7684\u795e\u7d93\u5143\u6703\u5728\u8a55\u4f30\u5176\u6d3b\u5316\u51fd\u6578\u4e4b\u524d\uff0c\u5f59\u7e3d\u524d\u4e00\u5c64\u4e2d\u6240\u6709\u795e\u7d93\u5143\u7684\u8f38\u5165\u96fb\u6d41\u3002\u9019\u751a\u81f3\u5728\u4eba\u5de5\u5c16\u5cf0\u795e\u7d93\u7db2\u8def (SNN) \u4e2d\u4e5f\u662f\u5982\u6b64\uff0c\u5118\u7ba1\u5927\u8166\u4e2d\u7684\u8655\u7406\u5be6\u969b\u4e0a\u662f\u7570\u6b65\u7684\uff0c\u4f46 SNN \u88ab\u5439\u6367\u70ba\u8207\u795e\u7d93\u751f\u7269\u5b78\u4e00\u81f4\u3002\u7136\u800c\uff0c\u4e00\u500b\u771f\u6b63\u7684\u7570\u6b65\u7cfb\u7d71\u5c07\u5141\u8a31\u6240\u6709\u795e\u7d93\u5143\u540c\u6642\u8a55\u4f30\u5176\u95be\u503c\uff0c\u4e26\u5728\u63a5\u6536\u5230\u4efb\u4f55\u7a81\u89f8\u524d\u96fb\u6d41\u6642\u767c\u51fa\u5c16\u5cf0\u3002\u7701\u7565\u5c64\u540c\u6b65\u5728\u5ef6\u9072\u548c\u80fd\u6e90\u6548\u7387\u65b9\u9762\u53ef\u80fd\u662f\u6709\u76ca\u7684\uff0c\u4f46\u5148\u524d\u4f7f\u7528\u5c64\u540c\u6b65\u8a13\u7df4\u7684\u6a21\u578b\u7684\u7570\u6b65\u57f7\u884c\u53ef\u80fd\u6703\u5c0e\u81f4\u7db2\u8def\u52d5\u614b\u548c\u6548\u80fd\u4e0d\u5339\u914d\u3002\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u9805\u7814\u7a76\uff0c\u8a18\u9304\u4e26\u91cf\u5316\u4e86\u9019\u500b\u554f\u984c\uff0c\u8a72\u7814\u7a76\u5728\u6211\u5011\u7684\u6a21\u64ec\u74b0\u5883\u4e2d\u4f7f\u7528\u4e09\u500b\u8cc7\u6599\u96c6\uff0c\u8a72\u74b0\u5883\u5be6\u73fe\u4e86\u7db2\u8def\u7570\u6b65\u6027\uff0c\u6211\u5011\u8868\u660e\u4f7f\u7528\u5c64\u540c\u6b65\u8a13\u7df4\u7684\u6a21\u578b\u5728\u6c92\u6709\u540c\u6b65\u7684\u60c5\u6cc1\u4e0b\u8868\u73fe\u4e0d\u4f73\uff0c\u6216\u8005\u5728\u9019\u7a2e\u6a5f\u5236\u5230\u4f4d\u6642\uff0c\u5b83\u5011\u5c07\u7121\u6cd5\u5f9e\u4efb\u4f55\u80fd\u91cf\u548c\u5ef6\u9072\u6e1b\u5c11\u4e2d\u53d7\u76ca\u3002\u7136\u5f8c\u6211\u5011\u300c\u5169\u5168\u5176\u7f8e\u300d\uff0c\u4e26\u4f7f\u7528\u975e\u5206\u5c64\u53cd\u5411\u50b3\u64ad\u4f86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684\u53cd\u5411\u50b3\u64ad\u8a13\u7df4\u65b9\u6cd5\uff0c\u7528\u65bc\u5b78\u7fd2\u9069\u5408\u7570\u6b65\u8655\u7406\u7684\u6a21\u578b\u3002\u6211\u5011\u4f7f\u7528\u5b83\u8a13\u7df4\u4f7f\u7528\u4e0d\u540c\u795e\u7d93\u5143\u57f7\u884c\u6392\u7a0b\u7b56\u7565\u7684\u6a21\u578b\uff0c\u6211\u5011\u8868\u660e\uff0c\u5118\u7ba1\u5b83\u5011\u7684\u795e\u7d93\u5143\u53cd\u61c9\u66f4\u9748\u654f\uff0c\u4f46\u9019\u4e9b\u6a21\u578b\u59cb\u7d42\u8868\u73fe\u51fa\u8f03\u4f4e\u7684\u6574\u9ad4\u5c16\u5cf0\u5bc6\u5ea6\uff08\u9ad8\u9054 50%\uff09\uff0c\u5728\u4e0d\u6574\u5408\u6240\u6709\u5c16\u5cf0\u7684\u60c5\u6cc1\u4e0b\u66f4\u5feb\u5730\u505a\u51fa\u6b63\u78ba\u7684\u6c7a\u7b56\uff08\u9ad8\u9054 2 \u500d\uff09\uff0c\u4e26\u5be6\u73fe\u66f4\u9ad8\u7684\u6e96\u78ba\u5ea6\uff08\u9ad8\u9054 10%\uff09\u3002\u6211\u5011\u7684\u767c\u73fe\u8868\u660e\uff0c\u7570\u6b65\u4e8b\u4ef6\u9a45\u52d5\uff08\u795e\u7d93\u5f62\u614b\uff09\u4eba\u5de5\u667a\u6167\u904b\u7b97\u78ba\u5be6\u66f4\u6709\u6548\u7387\uff0c\u4f46\u6211\u5011\u9700\u8981\u8a8d\u771f\u91cd\u65b0\u601d\u8003\u6211\u5011\u5982\u4f55\u8a13\u7df4\u6211\u5011\u7684 SNN \u6a21\u578b\uff0c\u624d\u80fd\u5f9e\u4e2d\u53d7\u76ca\u3002</paragraph>", "author": "Roel Koopman et.al.", "authors": "Roel Koopman, Amirreza Yousefzadeh, Mahyar Shahsavari, Guangzhi Tang, Manolis Sifalakis", "id": "2408.05098v1", "paper_url": "http://arxiv.org/abs/2408.05098v1", "repo": "null"}}