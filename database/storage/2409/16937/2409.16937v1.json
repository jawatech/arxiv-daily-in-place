{"2409.16937": {"publish_time": "2024-09-25", "title": "Semi-Supervised Cognitive State Classification from Speech with Multi-View Pseudo-Labeling", "paper_summary": "The lack of labeled data is a common challenge in speech classification\ntasks, particularly those requiring extensive subjective assessment, such as\ncognitive state classification. In this work, we propose a Semi-Supervised\nLearning (SSL) framework, introducing a novel multi-view pseudo-labeling method\nthat leverages both acoustic and linguistic characteristics to select the most\nconfident data for training the classification model. Acoustically, unlabeled\ndata are compared to labeled data using the Frechet audio distance, calculated\nfrom embeddings generated by multiple audio encoders. Linguistically, large\nlanguage models are prompted to revise automatic speech recognition\ntranscriptions and predict labels based on our proposed task-specific\nknowledge. High-confidence data are identified when pseudo-labels from both\nsources align, while mismatches are treated as low-confidence data. A bimodal\nclassifier is then trained to iteratively label the low-confidence data until a\npredefined criterion is met. We evaluate our SSL framework on emotion\nrecognition and dementia detection tasks. Experimental results demonstrate that\nour method achieves competitive performance compared to fully supervised\nlearning using only 30% of the labeled data and significantly outperforms two\nselected baselines.", "paper_summary_zh": "\u6a19\u7c64\u8cc7\u6599\u7684\u7f3a\u4e4f\u662f\u8a9e\u97f3\u5206\u985e\u4efb\u52d9\u4e2d\u5e38\u898b\u7684\u6311\u6230\uff0c\u7279\u5225\u662f\u9700\u8981\u5ee3\u6cdb\u4e3b\u89c0\u8a55\u4f30\u7684\u4efb\u52d9\uff0c\u4f8b\u5982\u8a8d\u77e5\u72c0\u614b\u5206\u985e\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u534a\u76e3\u7763\u5f0f\u5b78\u7fd2 (SSL) \u67b6\u69cb\uff0c\u5f15\u9032\u4e00\u7a2e\u65b0\u7a4e\u7684\u591a\u8996\u89d2\u507d\u6a19\u7c64\u65b9\u6cd5\uff0c\u8a72\u65b9\u6cd5\u5229\u7528\u8072\u5b78\u548c\u8a9e\u8a00\u7279\u5fb5\u4f86\u9078\u64c7\u6700\u53ef\u9760\u7684\u8cc7\u6599\u4ee5\u8a13\u7df4\u5206\u985e\u6a21\u578b\u3002\u5728\u8072\u5b78\u4e0a\uff0c\u4f7f\u7528\u7531\u591a\u500b\u97f3\u8a0a\u7de8\u78bc\u5668\u7522\u751f\u7684\u5d4c\u5165\u8a08\u7b97\u7684 Frechet \u97f3\u8a0a\u8ddd\u96e2\uff0c\u5c07\u672a\u6a19\u7c64\u8cc7\u6599\u8207\u6a19\u7c64\u8cc7\u6599\u9032\u884c\u6bd4\u8f03\u3002\u5728\u8a9e\u8a00\u5b78\u4e0a\uff0c\u63d0\u793a\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u4fee\u6539\u81ea\u52d5\u8a9e\u97f3\u8fa8\u8b58\u8f49\u9304\uff0c\u4e26\u6839\u64da\u6211\u5011\u63d0\u51fa\u7684\u7279\u5b9a\u4efb\u52d9\u77e5\u8b58\u9810\u6e2c\u6a19\u7c64\u3002\u7576\u4f86\u81ea\u5169\u500b\u4f86\u6e90\u7684\u507d\u6a19\u7c64\u5c0d\u9f4a\u6642\uff0c\u6703\u8b58\u5225\u51fa\u9ad8\u53ef\u9760\u6027\u8cc7\u6599\uff0c\u800c\u932f\u914d\u5247\u8996\u70ba\u4f4e\u53ef\u9760\u6027\u8cc7\u6599\u3002\u7136\u5f8c\u8a13\u7df4\u4e00\u500b\u96d9\u5cf0\u5206\u985e\u5668\uff0c\u4ee5\u53cd\u8986\u6a19\u7c64\u4f4e\u53ef\u9760\u6027\u8cc7\u6599\uff0c\u76f4\u5230\u7b26\u5408\u9810\u5b9a\u7fa9\u7684\u6e96\u5247\u3002\u6211\u5011\u5728\u60c5\u7dd2\u8fa8\u8b58\u548c\u5931\u667a\u75c7\u6aa2\u6e2c\u4efb\u52d9\u4e0a\u8a55\u4f30\u6211\u5011\u7684 SSL \u67b6\u69cb\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u8207\u50c5\u4f7f\u7528 30% \u6a19\u7c64\u8cc7\u6599\u7684\u5168\u76e3\u7763\u5f0f\u5b78\u7fd2\u76f8\u6bd4\uff0c\u6211\u5011\u7684\u65b9\u6cd5\u7372\u5f97\u4e86\u5177\u6709\u7af6\u722d\u529b\u7684\u6548\u80fd\uff0c\u4e26\u4e14\u660e\u986f\u512a\u65bc\u5169\u500b\u9078\u5b9a\u7684\u57fa\u6e96\u3002", "author": "Yuanchao Li et.al.", "authors": "Yuanchao Li, Zixing Zhang, Jing Han, Peter Bell, Catherine Lai", "id": "2409.16937v1", "paper_url": "http://arxiv.org/abs/2409.16937v1", "repo": "https://github.com/yc-li20/semi-supervised-training"}}