{"2411.17679": {"publish_time": "2024-11-26", "title": "Enhancing Character-Level Understanding in LLMs through Token Internal Structure Learning", "paper_summary": "Tokenization techniques such as Byte-Pair Encoding (BPE) and Byte-Level BPE\n(BBPE) have significantly improved the computational efficiency and vocabulary\nrepresentation stability of large language models (LLMs) by segmenting text\ninto tokens. However, this segmentation often obscures the internal character\nstructures and sequences within tokens, preventing models from fully learning\nthese intricate details during training. Consequently, LLMs struggle to\ncomprehend the character compositions and positional relationships within\ntokens, especially when fine-tuned on downstream tasks with limited data. In\nthis paper, we introduce Token Internal Position Awareness (TIPA), a novel\napproach that enhances LLMs' understanding of internal token structures by\ntraining them on reverse character prediction tasks using the tokenizer's own\nvocabulary. This method enables models to effectively learn and generalize\ncharacter positions and internal structures. Experimental results demonstrate\nthat LLMs trained with TIPA outperform baseline models in predicting character\npositions at the token level. Furthermore, when applied to the downstream task\nof Chinese Spelling Correction (CSC), TIPA not only accelerates model\nconvergence but also significantly improves task performance.", "paper_summary_zh": "\u5b57\u8282\u5bf9\u7f16\u7801 (BPE) \u548c\u5b57\u8282\u7ea7 BPE (BBPE) \u7b49\u6807\u8bb0\u5316\u6280\u672f\u901a\u8fc7\u5c06\u6587\u672c\u5206\u5272\u6210\u6807\u8bb0\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5927\u8bed\u8a00\u6a21\u578b (LLM) \u7684\u8ba1\u7b97\u6548\u7387\u548c\u8bcd\u6c47\u8868\u8868\u793a\u7a33\u5b9a\u6027\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u5206\u5272\u5e38\u5e38\u4f1a\u6a21\u7cca\u6807\u8bb0\u5185\u7684\u5185\u90e8\u5b57\u7b26\u7ed3\u6784\u548c\u5e8f\u5217\uff0c\u4ece\u800c\u59a8\u788d\u6a21\u578b\u5728\u8bad\u7ec3\u671f\u95f4\u5145\u5206\u5b66\u4e60\u8fd9\u4e9b\u9519\u7efc\u590d\u6742\u7684\u7ec6\u8282\u3002\u56e0\u6b64\uff0cLLM \u96be\u4ee5\u7406\u89e3\u6807\u8bb0\u5185\u7684\u5b57\u7b26\u6784\u6210\u548c\u4f4d\u7f6e\u5173\u7cfb\uff0c\u5c24\u5176\u662f\u5728\u9488\u5bf9\u6570\u636e\u6709\u9650\u7684\u4e0b\u6e38\u4efb\u52a1\u8fdb\u884c\u5fae\u8c03\u65f6\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u6807\u8bb0\u5185\u90e8\u4f4d\u7f6e\u611f\u77e5 (TIPA)\uff0c\u8fd9\u662f\u4e00\u79cd\u901a\u8fc7\u4f7f\u7528\u6807\u8bb0\u5668\u81ea\u5df1\u7684\u8bcd\u6c47\u8868\u5bf9\u9006\u5411\u5b57\u7b26\u9884\u6d4b\u4efb\u52a1\u8fdb\u884c\u8bad\u7ec3\u6765\u589e\u5f3a LLM \u5bf9\u5185\u90e8\u6807\u8bb0\u7ed3\u6784\u7406\u89e3\u7684\u65b0\u65b9\u6cd5\u3002\u8fd9\u79cd\u65b9\u6cd5\u4f7f\u6a21\u578b\u80fd\u591f\u6709\u6548\u5730\u5b66\u4e60\u548c\u6982\u62ec\u5b57\u7b26\u4f4d\u7f6e\u548c\u5185\u90e8\u7ed3\u6784\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528 TIPA \u8bad\u7ec3\u7684 LLM \u5728\u6807\u8bb0\u7ea7\u522b\u9884\u6d4b\u5b57\u7b26\u4f4d\u7f6e\u65f6\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002\u6b64\u5916\uff0c\u5f53\u5e94\u7528\u4e8e\u4e2d\u6587\u62fc\u5199\u7ea0\u6b63 (CSC) \u7684\u4e0b\u6e38\u4efb\u52a1\u65f6\uff0cTIPA \u4e0d\u4ec5\u53ef\u4ee5\u52a0\u901f\u6a21\u578b\u6536\u655b\uff0c\u8fd8\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u4efb\u52a1\u6027\u80fd\u3002", "author": "Zhu Xu et.al.", "authors": "Zhu Xu, Zhiqiang Zhao, Zihan Zhang, Yuchi Liu, Quanwei Shen, Fei Liu, Yu Kuang", "id": "2411.17679v1", "paper_url": "http://arxiv.org/abs/2411.17679v1", "repo": "null"}}