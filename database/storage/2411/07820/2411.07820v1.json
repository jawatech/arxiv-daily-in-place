{"2411.07820": {"publish_time": "2024-11-12", "title": "Query Optimization for Parametric Knowledge Refinement in Retrieval-Augmented Large Language Models", "paper_summary": "We introduce the \\textit{Extract-Refine-Retrieve-Read} (ERRR) framework, a\nnovel approach designed to bridge the pre-retrieval information gap in\nRetrieval-Augmented Generation (RAG) systems through query optimization\ntailored to meet the specific knowledge requirements of Large Language Models\n(LLMs). Unlike conventional query optimization techniques used in RAG, the ERRR\nframework begins by extracting parametric knowledge from LLMs, followed by\nusing a specialized query optimizer for refining these queries. This process\nensures the retrieval of only the most pertinent information essential for\ngenerating accurate responses. Moreover, to enhance flexibility and reduce\ncomputational costs, we propose a trainable scheme for our pipeline that\nutilizes a smaller, tunable model as the query optimizer, which is refined\nthrough knowledge distillation from a larger teacher model. Our evaluations on\nvarious question-answering (QA) datasets and with different retrieval systems\nshow that ERRR consistently outperforms existing baselines, proving to be a\nversatile and cost-effective module for improving the utility and accuracy of\nRAG systems.", "paper_summary_zh": "\u6211\u5011\u4ecb\u7d39\u4e86\u300c\u8403\u53d6-\u7cbe\u7149-\u64f7\u53d6-\u95b1\u8b80\u300d(ERRR) \u67b6\u69cb\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684\u65b9\u6cd5\uff0c\u65e8\u5728\u900f\u904e\u91dd\u5c0d\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7279\u5b9a\u77e5\u8b58\u9700\u6c42\u91cf\u8eab\u6253\u9020\u7684\u67e5\u8a62\u6700\u4f73\u5316\uff0c\u4f86\u5f4c\u88dc\u64f7\u53d6\u589e\u5f37\u7522\u751f (RAG) \u7cfb\u7d71\u4e2d\u7684\u524d\u64f7\u53d6\u8cc7\u8a0a\u5dee\u8ddd\u3002\u8207 RAG \u4e2d\u4f7f\u7528\u7684\u50b3\u7d71\u67e5\u8a62\u6700\u4f73\u5316\u6280\u8853\u4e0d\u540c\uff0cERRR \u67b6\u69cb\u5f9e LLM \u4e2d\u8403\u53d6\u53c3\u6578\u5316\u77e5\u8b58\u958b\u59cb\uff0c\u63a5\u8457\u4f7f\u7528\u5c08\u9580\u7684\u67e5\u8a62\u6700\u4f73\u5316\u5668\u4f86\u7cbe\u7149\u9019\u4e9b\u67e5\u8a62\u3002\u6b64\u7a0b\u5e8f\u53ef\u78ba\u4fdd\u50c5\u64f7\u53d6\u7522\u751f\u6e96\u78ba\u56de\u61c9\u6240\u5fc5\u8981\u7684\u8cc7\u8a0a\u3002\u6b64\u5916\uff0c\u70ba\u4e86\u589e\u5f37\u5f48\u6027\u4e26\u964d\u4f4e\u904b\u7b97\u6210\u672c\uff0c\u6211\u5011\u70ba\u6211\u5011\u7684\u7ba1\u7dda\u63d0\u51fa\u4e86\u4e00\u500b\u53ef\u8a13\u7df4\u67b6\u69cb\uff0c\u5b83\u5229\u7528\u8f03\u5c0f\u4e14\u53ef\u8abf\u6574\u7684\u6a21\u578b\u4f5c\u70ba\u67e5\u8a62\u6700\u4f73\u5316\u5668\uff0c\u4e26\u900f\u904e\u5f9e\u8f03\u5927\u7684\u6559\u5e2b\u6a21\u578b\u4e2d\u77e5\u8b58\u8403\u53d6\u4f86\u9032\u884c\u7cbe\u7149\u3002\u6211\u5011\u5728\u5404\u7a2e\u554f\u7b54 (QA) \u8cc7\u6599\u96c6\u548c\u4e0d\u540c\u7684\u64f7\u53d6\u7cfb\u7d71\u4e0a\u7684\u8a55\u4f30\u986f\u793a\uff0cERRR \u6301\u7e8c\u512a\u65bc\u73fe\u6709\u7684\u57fa\u6e96\uff0c\u8b49\u660e\u5b83\u662f\u4e00\u500b\u901a\u7528\u4e14\u5177\u6210\u672c\u6548\u76ca\u7684\u6a21\u7d44\uff0c\u53ef\u6539\u5584 RAG \u7cfb\u7d71\u7684\u6548\u7528\u548c\u6e96\u78ba\u6027\u3002", "author": "Youan Cong et.al.", "authors": "Youan Cong, Cheng Wang, Pritom Saha Akash, Kevin Chen-Chuan Chang", "id": "2411.07820v1", "paper_url": "http://arxiv.org/abs/2411.07820v1", "repo": "null"}}