{"2411.11072": {"publish_time": "2024-11-17", "title": "Multilingual Large Language Models: A Systematic Survey", "paper_summary": "This paper provides a comprehensive survey of the latest research on\nmultilingual large language models (MLLMs). MLLMs not only are able to\nunderstand and generate language across linguistic boundaries, but also\nrepresent an important advancement in artificial intelligence. We first discuss\nthe architecture and pre-training objectives of MLLMs, highlighting the key\ncomponents and methodologies that contribute to their multilingual\ncapabilities. We then discuss the construction of multilingual pre-training and\nalignment datasets, underscoring the importance of data quality and diversity\nin enhancing MLLM performance. An important focus of this survey is on the\nevaluation of MLLMs. We present a detailed taxonomy and roadmap covering the\nassessment of MLLMs' cross-lingual knowledge, reasoning, alignment with human\nvalues, safety, interpretability and specialized applications. Specifically, we\nextensively discuss multilingual evaluation benchmarks and datasets, and\nexplore the use of LLMs themselves as multilingual evaluators. To enhance MLLMs\nfrom black to white boxes, we also address the interpretability of multilingual\ncapabilities, cross-lingual transfer and language bias within these models.\nFinally, we provide a comprehensive review of real-world applications of MLLMs\nacross diverse domains, including biology, medicine, computer science,\nmathematics and law. We showcase how these models have driven innovation and\nimprovements in these specialized fields while also highlighting the challenges\nand opportunities in deploying MLLMs within diverse language communities and\napplication scenarios.We listed the paper related in this survey and publicly\navailable at https://github.com/tjunlp-lab/Awesome-Multilingual-LLMs-Papers .", "paper_summary_zh": "<paragraph>\u9019\u7bc7\u8ad6\u6587\u63d0\u4f9b\u4e86\u591a\u8a9e\u8a00\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08MLLM\uff09\u6700\u65b0\u7814\u7a76\u7684\u5168\u9762\u8abf\u67e5\u3002MLLM \u4e0d\u50c5\u80fd\u5920\u8de8\u8d8a\u8a9e\u8a00\u754c\u9650\u7406\u89e3\u548c\u751f\u6210\u8a9e\u8a00\uff0c\u800c\u4e14\u9084\u4ee3\u8868\u4e86\u4eba\u5de5\u667a\u80fd\u7684\u91cd\u8981\u9032\u5c55\u3002\u6211\u5011\u9996\u5148\u8a0e\u8ad6 MLLM \u7684\u67b6\u69cb\u548c\u9810\u8a13\u7df4\u76ee\u6a19\uff0c\u91cd\u9ede\u4ecb\u7d39\u6709\u52a9\u65bc\u5176\u591a\u8a9e\u8a00\u80fd\u529b\u7684\u95dc\u9375\u7d44\u6210\u90e8\u5206\u548c\u65b9\u6cd5\u3002\u7136\u5f8c\uff0c\u6211\u5011\u8a0e\u8ad6\u591a\u8a9e\u8a00\u9810\u8a13\u7df4\u548c\u5c0d\u9f4a\u8cc7\u6599\u96c6\u7684\u5efa\u69cb\uff0c\u5f37\u8abf\u8cc7\u6599\u54c1\u8cea\u548c\u591a\u6a23\u6027\u5728\u63d0\u5347 MLLM \u6548\u80fd\u65b9\u9762\u7684\u91cd\u8981\u6027\u3002\u672c\u8abf\u67e5\u7684\u4e00\u500b\u91cd\u9ede\u662f MLLM \u7684\u8a55\u4f30\u3002\u6211\u5011\u63d0\u51fa\u4e86\u6db5\u84cb MLLM \u8de8\u8a9e\u8a00\u77e5\u8b58\u3001\u63a8\u7406\u3001\u8207\u4eba\u985e\u50f9\u503c\u89c0\u7684\u4e00\u81f4\u6027\u3001\u5b89\u5168\u6027\u3001\u53ef\u89e3\u91cb\u6027\u548c\u5c08\u696d\u61c9\u7528\u8a55\u4f30\u7684\u8a73\u7d30\u5206\u985e\u6cd5\u548c\u8def\u7dda\u5716\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u5ee3\u6cdb\u8a0e\u8ad6\u591a\u8a9e\u8a00\u8a55\u4f30\u57fa\u6e96\u548c\u8cc7\u6599\u96c6\uff0c\u4e26\u63a2\u8a0e\u5c07 LLM \u672c\u8eab\u7528\u4f5c\u591a\u8a9e\u8a00\u8a55\u4f30\u5668\u7684\u7528\u9014\u3002\u70ba\u4e86\u5c07 MLLM \u5f9e\u9ed1\u76d2\u5b50\u63d0\u5347\u5230\u767d\u76d2\u5b50\uff0c\u6211\u5011\u9084\u63a2\u8a0e\u4e86\u9019\u4e9b\u6a21\u578b\u4e2d\u591a\u8a9e\u8a00\u80fd\u529b\u3001\u8de8\u8a9e\u8a00\u8f49\u79fb\u548c\u8a9e\u8a00\u504f\u898b\u7684\u53ef\u89e3\u91cb\u6027\u3002\u6700\u5f8c\uff0c\u6211\u5011\u5c0d MLLM \u5728\u751f\u7269\u5b78\u3001\u91ab\u5b78\u3001\u96fb\u8166\u79d1\u5b78\u3001\u6578\u5b78\u548c\u6cd5\u5f8b\u7b49\u4e0d\u540c\u9818\u57df\u7684\u5be6\u969b\u61c9\u7528\u9032\u884c\u4e86\u5168\u9762\u7684\u56de\u9867\u3002\u6211\u5011\u5c55\u793a\u4e86\u9019\u4e9b\u6a21\u578b\u5982\u4f55\u63a8\u52d5\u9019\u4e9b\u5c08\u696d\u9818\u57df\u7684\u5275\u65b0\u548c\u6539\u9032\uff0c\u540c\u6642\u4e5f\u5f37\u8abf\u4e86\u5728\u4e0d\u540c\u7684\u8a9e\u8a00\u793e\u7fa4\u548c\u61c9\u7528\u5834\u666f\u4e2d\u90e8\u7f72 MLLM \u7684\u6311\u6230\u548c\u6a5f\u9047\u3002\u6211\u5011\u5217\u51fa\u4e86\u672c\u8abf\u67e5\u4e2d\u76f8\u95dc\u7684\u8ad6\u6587\uff0c\u4e26\u5728 https://github.com/tjunlp-lab/Awesome-Multilingual-LLMs-Papers \u516c\u958b\u63d0\u4f9b\u3002</paragraph>", "author": "Shaolin Zhu et.al.", "authors": "Shaolin Zhu, Supryadi, Shaoyang Xu, Haoran Sun, Leiyu Pan, Menglong Cui, Jiangcun Du, Renren Jin, Ant\u00f3nio Branco, Deyi Xiong", "id": "2411.11072v1", "paper_url": "http://arxiv.org/abs/2411.11072v1", "repo": "null"}}