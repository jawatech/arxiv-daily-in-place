{"2406.14491": {"publish_time": "2024-06-20", "title": "Instruction Pre-Training: Language Models are Supervised Multitask Learners", "paper_summary": "Unsupervised multitask pre-training has been the critical method behind the\nrecent success of language models (LMs). However, supervised multitask learning\nstill holds significant promise, as scaling it in the post-training stage\ntrends towards better generalization. In this paper, we explore supervised\nmultitask pre-training by proposing Instruction Pre-Training, a framework that\nscalably augments massive raw corpora with instruction-response pairs to\npre-train LMs. The instruction-response pairs are generated by an efficient\ninstruction synthesizer built on open-source models. In our experiments, we\nsynthesize 200M instruction-response pairs covering 40+ task categories to\nverify the effectiveness of Instruction Pre-Training. In pre-training from\nscratch, Instruction Pre-Training not only consistently enhances pre-trained\nbase models but also benefits more from further instruction tuning. In\ncontinual pre-training, Instruction Pre-Training enables Llama3-8B to be\ncomparable to or even outperform Llama3-70B. Our model, code, and data are\navailable at https://github.com/microsoft/LMOps.", "paper_summary_zh": "\u7121\u76e3\u7763\u591a\u4efb\u52d9\u9810\u8a13\u7df4\u4e00\u76f4\u662f\u8a9e\u8a00\u6a21\u578b (LM) \u8fd1\u671f\u6210\u529f\u7684\u95dc\u9375\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u76e3\u7763\u5f0f\u591a\u4efb\u52d9\u5b78\u7fd2\u4ecd\u5177\u6709\u986f\u8457\u7684\u6f5b\u529b\uff0c\u56e0\u70ba\u5728\u5f8c\u8a13\u7df4\u968e\u6bb5\u64f4\u5c55\u5b83\u8da8\u5411\u65bc\u66f4\u597d\u7684\u6982\u62ec\u80fd\u529b\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u900f\u904e\u63d0\u51fa\u6307\u4ee4\u9810\u8a13\u7df4\u4f86\u63a2\u7d22\u76e3\u7763\u5f0f\u591a\u4efb\u52d9\u9810\u8a13\u7df4\uff0c\u9019\u662f\u4e00\u500b\u900f\u904e\u6307\u4ee4\u56de\u61c9\u914d\u5c0d\u53ef\u64f4\u5145\u5730\u589e\u52a0\u5927\u91cf\u539f\u59cb\u8a9e\u6599\u5eab\u4ee5\u9810\u8a13\u7df4 LM \u7684\u67b6\u69cb\u3002\u6307\u4ee4\u56de\u61c9\u914d\u5c0d\u662f\u7531\u5efa\u7acb\u5728\u958b\u6e90\u6a21\u578b\u4e0a\u7684\u6709\u6548\u6307\u4ee4\u5408\u6210\u5668\u7522\u751f\u7684\u3002\u5728\u6211\u5011\u7684\u5be6\u9a57\u4e2d\uff0c\u6211\u5011\u5408\u6210\u4e86\u6db5\u84cb 40 \u591a\u500b\u4efb\u52d9\u985e\u5225\u7684 2 \u5104\u500b\u6307\u4ee4\u56de\u61c9\u914d\u5c0d\uff0c\u4ee5\u9a57\u8b49\u6307\u4ee4\u9810\u8a13\u7df4\u7684\u6709\u6548\u6027\u3002\u5728\u5f9e\u982d\u958b\u59cb\u9810\u8a13\u7df4\u6642\uff0c\u6307\u4ee4\u9810\u8a13\u7df4\u4e0d\u50c5\u6301\u7e8c\u589e\u5f37\u9810\u8a13\u7df4\u7684\u57fa\u672c\u6a21\u578b\uff0c\u800c\u4e14\u9084\u80fd\u5f9e\u9032\u4e00\u6b65\u7684\u6307\u4ee4\u5fae\u8abf\u4e2d\u53d7\u76ca\u66f4\u591a\u3002\u5728\u6301\u7e8c\u9810\u8a13\u7df4\u4e2d\uff0c\u6307\u4ee4\u9810\u8a13\u7df4\u4f7f Llama3-8B \u80fd\u5920\u8207 Llama3-70B \u76f8\u5ab2\u7f8e\u751a\u81f3\u8868\u73fe\u5f97\u66f4\u597d\u3002\u6211\u5011\u7684\u6a21\u578b\u3001\u7a0b\u5f0f\u78bc\u548c\u8cc7\u6599\u53ef\u5728 https://github.com/microsoft/LMOps \u53d6\u5f97\u3002", "author": "Daixuan Cheng et.al.", "authors": "Daixuan Cheng, Yuxian Gu, Shaohan Huang, Junyu Bi, Minlie Huang, Furu Wei", "id": "2406.14491v1", "paper_url": "http://arxiv.org/abs/2406.14491v1", "repo": "https://github.com/microsoft/lmops"}}