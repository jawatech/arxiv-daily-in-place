{"2410.12380": {"publish_time": "2024-10-16", "title": "Evaluation of Attribution Bias in Retrieval-Augmented Large Language Models", "paper_summary": "Attributing answers to source documents is an approach used to enhance the\nverifiability of a model's output in retrieval augmented generation (RAG).\nPrior work has mainly focused on improving and evaluating the attribution\nquality of large language models (LLMs) in RAG, but this may come at the\nexpense of inducing biases in the attribution of answers. We define and examine\ntwo aspects in the evaluation of LLMs in RAG pipelines, namely attribution\nsensitivity and bias with respect to authorship information. We explicitly\ninform an LLM about the authors of source documents, instruct it to attribute\nits answers, and analyze (i) how sensitive the LLM's output is to the author of\nsource documents, and (ii) whether the LLM exhibits a bias towards\nhuman-written or AI-generated source documents. We design an experimental setup\nin which we use counterfactual evaluation to study three LLMs in terms of their\nattribution sensitivity and bias in RAG pipelines. Our results show that adding\nauthorship information to source documents can significantly change the\nattribution quality of LLMs by 3% to 18%. Moreover, we show that LLMs can have\nan attribution bias towards explicit human authorship, which can serve as a\ncompeting hypothesis for findings of prior work that shows that LLM-generated\ncontent may be preferred over human-written contents. Our findings indicate\nthat metadata of source documents can influence LLMs' trust, and how they\nattribute their answers. Furthermore, our research highlights attribution bias\nand sensitivity as a novel aspect of brittleness in LLMs.", "paper_summary_zh": "<paragraph>\u5728\u6aa2\u7d22\u64f4\u5145\u751f\u6210\uff08RAG\uff09\u4e2d\uff0c\u5c07\u7b54\u6848\u6b78\u56e0\u65bc\u4f86\u6e90\u6587\u4ef6\u662f\u4e00\u7a2e\u7528\u65bc\u589e\u5f37\u6a21\u578b\u8f38\u51fa\u53ef\u9a57\u8b49\u6027\u7684\u65b9\u6cd5\u3002\n\u5148\u524d\u7684\u5de5\u4f5c\u4e3b\u8981\u96c6\u4e2d\u65bc\u6539\u9032\u548c\u8a55\u4f30 RAG \u4e2d\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6b78\u56e0\u54c1\u8cea\uff0c\u4f46\u9019\u53ef\u80fd\u6703\u5c0e\u81f4\u5728\u7b54\u6848\u7684\u6b78\u56e0\u4e2d\u5f15\u767c\u504f\u5dee\u3002\u6211\u5011\u5728 RAG \u7ba1\u7dda\u4e2d\u5b9a\u7fa9\u4e26\u6aa2\u8996\u4e86 LLM \u8a55\u4f30\u7684\u5169\u500b\u9762\u5411\uff0c\u5373\u6b78\u56e0\u654f\u611f\u5ea6\u548c\u95dc\u65bc\u4f5c\u8005\u8cc7\u8a0a\u7684\u504f\u5dee\u3002\u6211\u5011\u660e\u78ba\u5730\u544a\u77e5 LLM \u4f86\u6e90\u6587\u4ef6\u7684\u4f5c\u8005\uff0c\u6307\u793a\u5b83\u6b78\u56e0\u5176\u7b54\u6848\uff0c\u4e26\u5206\u6790 (i) LLM \u7684\u8f38\u51fa\u5c0d\u4f86\u6e90\u6587\u4ef6\u7684\u4f5c\u8005\u6709\u591a\u654f\u611f\uff0c\u4ee5\u53ca (ii) LLM \u662f\u5426\u5c0d\u4eba\u985e\u64b0\u5beb\u6216 AI \u751f\u6210\u7684\u4f86\u6e90\u6587\u4ef6\u8868\u73fe\u51fa\u504f\u5dee\u3002\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u5be6\u9a57\u8a2d\u5b9a\uff0c\u5728\u5176\u4e2d\u6211\u5011\u4f7f\u7528\u53cd\u4e8b\u5be6\u8a55\u4f30\u4f86\u7814\u7a76\u4e09\u500b LLM \u5728 RAG \u7ba1\u7dda\u4e2d\u7684\u6b78\u56e0\u654f\u611f\u5ea6\u548c\u504f\u5dee\u3002\u6211\u5011\u7684\u7d50\u679c\u986f\u793a\uff0c\u5c07\u4f5c\u8005\u8cc7\u8a0a\u65b0\u589e\u5230\u4f86\u6e90\u6587\u4ef6\u53ef\u4ee5\u986f\u8457\u6539\u8b8a LLM \u7684\u6b78\u56e0\u54c1\u8cea\uff0c\u4ecb\u65bc 3% \u5230 18%\u3002\u6b64\u5916\uff0c\u6211\u5011\u986f\u793a LLM \u53ef\u80fd\u5c0d\u660e\u78ba\u7684\u4eba\u985e\u4f5c\u8005\u8eab\u4efd\u6709\u6b78\u56e0\u504f\u5dee\uff0c\u9019\u53ef\u4ee5\u7528\u4f5c\u5148\u524d\u5de5\u4f5c\u767c\u73fe\u7684\u7af6\u722d\u5047\u8a2d\uff0c\u8a72\u767c\u73fe\u986f\u793a LLM \u751f\u6210\u7684\u5167\u5bb9\u53ef\u80fd\u6bd4\u4eba\u985e\u64b0\u5beb\u7684\u5167\u5bb9\u66f4\u53d7\u9752\u775e\u3002\u6211\u5011\u7684\u767c\u73fe\u8868\u660e\uff0c\u4f86\u6e90\u6587\u4ef6\u7684\u5143\u8cc7\u6599\u6703\u5f71\u97ff LLM \u7684\u4fe1\u4efb\uff0c\u4ee5\u53ca\u5b83\u5011\u5982\u4f55\u6b78\u56e0\u5176\u7b54\u6848\u3002\u6b64\u5916\uff0c\u6211\u5011\u7684\u7814\u7a76\u5f37\u8abf\u6b78\u56e0\u504f\u5dee\u548c\u654f\u611f\u5ea6\u662f LLM \u4e2d\u8106\u6027\u7684\u65b0\u9762\u5411\u3002</paragraph>", "author": "Amin Abolghasemi et.al.", "authors": "Amin Abolghasemi, Leif Azzopardi, Seyyed Hadi Hashemi, Maarten de Rijke, Suzan Verberne", "id": "2410.12380v1", "paper_url": "http://arxiv.org/abs/2410.12380v1", "repo": "null"}}