
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-10**|**Preserving Privacy in Large Language Models: A Survey on Current Threats and Solutions**|Michele Miranda et.al.|[2408.05212v1](http://arxiv.org/abs/2408.05212v1)|null|
|**2024-08-09**|**VITA: Towards Open-Source Interactive Omni Multimodal LLM**|Chaoyou Fu et.al.|[2408.05211v1](http://arxiv.org/abs/2408.05211v1)|null|
|**2024-08-09**|**Evaluating the capability of large language models to personalize science texts for diverse middle-school-age learners**|Michael Vaccaro Jr et.al.|[2408.05204v1](http://arxiv.org/abs/2408.05204v1)|null|
|**2024-08-09**|**TaSL: Task Skill Localization and Consolidation for Language Model Continual Learning**|Yujie Feng et.al.|[2408.05200v1](http://arxiv.org/abs/2408.05200v1)|null|
|**2024-08-09**|**HistoKernel: Whole Slide Image Level Maximum Mean Discrepancy Kernels for Pan-Cancer Predictive Modelling**|Piotr Keller et.al.|[2408.05195v1](http://arxiv.org/abs/2408.05195v1)|[link](https://github.com/pkeller00/histokernel)|
|**2024-08-09**|**Separating Style from Substance: Enhancing Cross-Genre Authorship Attribution through Data Selection and Presentation**|Steven Fincke et.al.|[2408.05192v1](http://arxiv.org/abs/2408.05192v1)|null|
|**2024-08-09**|**Deep-change at AXOLOTL-24: Orchestrating WSD and WSI Models for Semantic Change Modeling**|Denis Kokosinskii et.al.|[2408.05184v1](http://arxiv.org/abs/2408.05184v1)|null|
|**2024-08-09**|**AttackER: Towards Enhancing Cyber-Attack Attribution with a Named Entity Recognition Dataset**|Pritam Deka et.al.|[2408.05149v1](http://arxiv.org/abs/2408.05149v1)|null|
|**2024-08-09**|**Gemma Scope: Open Sparse Autoencoders Everywhere All At Once on Gemma 2**|Tom Lieberum et.al.|[2408.05147v1](http://arxiv.org/abs/2408.05147v1)|null|
|**2024-08-09**|**A Hybrid RAG System with Comprehensive Enhancement on Complex Reasoning**|Ye Yuan et.al.|[2408.05141v1](http://arxiv.org/abs/2408.05141v1)|null|
|**2024-08-09**|**Large Language Models and Thematic Analysis: Human-AI Synergy in Researching Hate Speech on Social Media**|Petre Breazu et.al.|[2408.05126v1](http://arxiv.org/abs/2408.05126v1)|null|
|**2024-08-09**|**Beyond the Eye: A Relational Model for Early Dementia Detection Using Retinal OCTA Images**|Shouyue Liu et.al.|[2408.05117v1](http://arxiv.org/abs/2408.05117v1)|null|
|**2024-08-09**|**How Well Do LLMs Identify Cultural Unity in Diversity?**|Jialin Li et.al.|[2408.05102v1](http://arxiv.org/abs/2408.05102v1)|null|
|**2024-08-09**|**MooER: LLM-based Speech Recognition and Translation Models from Moore Threads**|Junhao Xu et.al.|[2408.05101v1](http://arxiv.org/abs/2408.05101v1)|null|
|**2024-08-09**|**AI-driven Java Performance Testing: Balancing Result Quality with Testing Time**|Luca Traini et.al.|[2408.05100v1](http://arxiv.org/abs/2408.05100v1)|null|
|**2024-08-09**|**Overcoming the Limitations of Layer Synchronization in Spiking Neural Networks**|Roel Koopman et.al.|[2408.05098v1](http://arxiv.org/abs/2408.05098v1)|null|
|**2024-08-09**|**Hyperbolic Learning with Multimodal Large Language Models**|Paolo Mandica et.al.|[2408.05097v1](http://arxiv.org/abs/2408.05097v1)|null|
|**2024-08-09**|**Unlocking Decoding-time Controllability: Gradient-Free Multi-Objective Alignment with Contrastive Prompts**|Tingchen Fu et.al.|[2408.05094v1](http://arxiv.org/abs/2408.05094v1)|null|
|**2024-08-09**|**Order Matters in Hallucination: Reasoning Order as Benchmark and Reflexive Prompting for Large-Language-Models**|Zikai Xie et.al.|[2408.05093v1](http://arxiv.org/abs/2408.05093v1)|[link](https://github.com/xiezikai/reflexiveprompting)|
|**2024-08-09**|**Generating novel experimental hypotheses from language models: A case study on cross-dative generalization**|Kanishka Misra et.al.|[2408.05086v1](http://arxiv.org/abs/2408.05086v1)|null|
|**2024-08-09**|**RT-Surv: Improving Mortality Prediction After Radiotherapy with Large Language Model Structuring of Large-Scale Unstructured Electronic Health Records**|Sangjoon Park et.al.|[2408.05074v1](http://arxiv.org/abs/2408.05074v1)|null|
|**2024-08-09**|**A Jailbroken GenAI Model Can Cause Substantial Harm: GenAI-powered Applications are Vulnerable to PromptWares**|Stav Cohen et.al.|[2408.05061v1](http://arxiv.org/abs/2408.05061v1)|[link](https://github.com/stavc/promptwares)|
|**2024-08-09**|**GLEAMS: Bridging the Gap Between Local and Global Explanations**|Giorgio Visani et.al.|[2408.05060v1](http://arxiv.org/abs/2408.05060v1)|null|
|**2024-08-09**|**SELD-Mamba: Selective State-Space Model for Sound Event Localization and Detection with Source Distance Estimation**|Da Mu et.al.|[2408.05057v1](http://arxiv.org/abs/2408.05057v1)|null|
|**2024-08-09**|**A GNN Model with Adaptive Weights for Session-Based Recommendation Systems**|Begüm Özbay et.al.|[2408.05051v1](http://arxiv.org/abs/2408.05051v1)|null|
|**2024-08-09**|**Examining the Behavior of LLM Architectures Within the Framework of Standardized National Exams in Brazil**|Marcelo Sartori Locatelli et.al.|[2408.05035v1](http://arxiv.org/abs/2408.05035v1)|null|
|**2024-08-09**|**Rag and Roll: An End-to-End Evaluation of Indirect Prompt Manipulations in LLM-based Application Frameworks**|Gianluca De Stefano et.al.|[2408.05025v1](http://arxiv.org/abs/2408.05025v1)|null|
|**2024-08-09**|**MIDI-to-Tab: Guitar Tablature Inference via Masked Language Modeling**|Drew Edwards et.al.|[2408.05024v1](http://arxiv.org/abs/2408.05024v1)|null|
|**2024-08-09**|**Investigating a Benchmark for Training-set free Evaluation of Linguistic Capabilities in Machine Reading Comprehension**|Viktor Schlegel et.al.|[2408.05023v1](http://arxiv.org/abs/2408.05023v1)|null|
|**2024-08-09**|**Enhancing the Code Debugging Ability of LLMs via Communicative Agent Based Data Refinement**|Weiqing Yang et.al.|[2408.05006v1](http://arxiv.org/abs/2408.05006v1)|null|
|**2024-08-09**|**ProFuser: Progressive Fusion of Large Language Models**|Tianyuan Shi et.al.|[2408.04998v1](http://arxiv.org/abs/2408.04998v1)|null|
|**2024-08-09**|**Get Confused Cautiously: Textual Sequence Memorization Erasure with Selective Entropy Maximization**|Zhaohan Zhang et.al.|[2408.04983v1](http://arxiv.org/abs/2408.04983v1)|null|
|**2024-08-09**|**reCSE: Portable Reshaping Features for Sentence Embedding in Self-supervised Contrastive Learning**|Fufangchen Zhao et.al.|[2408.04975v2](http://arxiv.org/abs/2408.04975v2)|null|
|**2024-08-09**|**Generalisation First, Memorisation Second? Memorisation Localisation for Natural Language Classification Tasks**|Verna Dankers et.al.|[2408.04965v1](http://arxiv.org/abs/2408.04965v1)|null|
|**2024-08-09**|**LLaVA-VSD: Large Language-and-Vision Assistant for Visual Spatial Description**|Yizhang Jin et.al.|[2408.04957v1](http://arxiv.org/abs/2408.04957v1)|null|
|**2024-08-09**|**CROCODILE: Causality aids RObustness via COntrastive DIsentangled LEarning**|Gianluca Carloni et.al.|[2408.04949v1](http://arxiv.org/abs/2408.04949v1)|[link](https://github.com/gianlucarloni/crocodile)|
|**2024-08-09**|**HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction**|Bhaskarjit Sarmah et.al.|[2408.04948v1](http://arxiv.org/abs/2408.04948v1)|null|
|**2024-08-09**|**Quantitative Information Extraction from Humanitarian Documents**|Daniele Liberatore et.al.|[2408.04941v1](http://arxiv.org/abs/2408.04941v1)|null|
|**2024-08-09**|**UAV-Enhanced Combination to Application: Comprehensive Analysis and Benchmarking of a Human Detection Dataset for Disaster Scenarios**|Ragib Amin Nihal et.al.|[2408.04922v1](http://arxiv.org/abs/2408.04922v1)|null|
|**2024-08-09**|**Avoid Wasted Annotation Costs in Open-set Active Learning with Pre-trained Vision-Language Model**|Jaehyuk Heo et.al.|[2408.04917v1](http://arxiv.org/abs/2408.04917v1)|null|
|**2024-08-09**|**Knowledge Base Embeddings: Semantics and Theoretical Properties**|Camille Bourgaux et.al.|[2408.04913v1](http://arxiv.org/abs/2408.04913v1)|null|
|**2024-08-09**|**Unleashing Artificial Cognition: Integrating Multiple AI Systems**|Muntasir Adnan et.al.|[2408.04910v2](http://arxiv.org/abs/2408.04910v2)|[link](https://github.com/TheOpenSI/cognitive_AI_experiments)|
|**2024-08-09**|**Surveying the Landscape of Image Captioning Evaluation: A Comprehensive Taxonomy and Novel Ensemble Method**|Uri Berger et.al.|[2408.04909v1](http://arxiv.org/abs/2408.04909v1)|null|
|**2024-08-09**|**Towards a Generative Approach for Emotion Detection and Reasoning**|Ankita Bhaumik et.al.|[2408.04906v1](http://arxiv.org/abs/2408.04906v1)|null|
|**2024-08-09**|**GlitchProber: Advancing Effective Detection and Mitigation of Glitch Tokens in Large Language Models**|Zhibo Zhang et.al.|[2408.04905v1](http://arxiv.org/abs/2408.04905v1)|null|
|**2024-08-09**|**Communicate to Play: Pragmatic Reasoning for Efficient Cross-Cultural Communication in Codenames**|Isadora White et.al.|[2408.04900v1](http://arxiv.org/abs/2408.04900v1)|[link](https://github.com/icwhite/codenames)|
|**2024-08-09**|**Unsupervised Episode Detection for Large-Scale News Events**|Priyanka Kargupta et.al.|[2408.04873v1](http://arxiv.org/abs/2408.04873v1)|null|
|**2024-08-09**|**SCOI: Syntax-augmented Coverage-based In-context Example Selection for Machine Translation**|Chenming Tang et.al.|[2408.04872v1](http://arxiv.org/abs/2408.04872v1)|null|
|**2024-08-09**|**ConfusedPilot: Compromising Enterprise Information Integrity and Confidentiality with Copilot for Microsoft 365**|Ayush RoyChowdhury et.al.|[2408.04870v1](http://arxiv.org/abs/2408.04870v1)|null|
|**2024-08-09**|**Ensemble BERT: A student social network text sentiment classification model based on ensemble learning and BERT architecture**|Kai Jiang et.al.|[2408.04849v1](http://arxiv.org/abs/2408.04849v1)|null|
|**2024-08-09**|**Counterfactual Explanations with Probabilistic Guarantees on their Robustness to Model Change**|Ignacy Stępka et.al.|[2408.04842v1](http://arxiv.org/abs/2408.04842v1)|null|
|**2024-08-09**|**Kolmogorov-Arnold Network for Online Reinforcement Learning**|Victor Augusto Kich et.al.|[2408.04841v1](http://arxiv.org/abs/2408.04841v1)|null|
|**2024-08-09**|**mPLUG-Owl3: Towards Long Image-Sequence Understanding in Multi-Modal Large Language Models**|Jiabo Ye et.al.|[2408.04840v1](http://arxiv.org/abs/2408.04840v1)|null|
|**2024-08-09**|**Self-augmented Gaussian Splatting with Structure-aware Masks for Sparse-view 3D Reconstruction**|Lingbei Meng et.al.|[2408.04831v1](http://arxiv.org/abs/2408.04831v1)|null|
|**2024-08-09**|**Performance Prediction of Hub-Based Swarms**|Puneet Jain et.al.|[2408.04822v1](http://arxiv.org/abs/2408.04822v1)|null|
|**2024-08-09**|**Natural Language Outlines for Code: Literate Programming in the LLM Era**|Kensen Shi et.al.|[2408.04820v1](http://arxiv.org/abs/2408.04820v1)|null|
|**2024-08-09**|**Performance Metric for Multiple Anomaly Score Distributions with Discrete Severity Levels**|Wonjun Yi et.al.|[2408.04817v1](http://arxiv.org/abs/2408.04817v1)|[link](https://github.com/jim8220/ws-auroc)|
|**2024-08-09**|**FUSE-ing Language Models: Zero-Shot Adapter Discovery for Prompt Optimization Across Tokenizers**|Joshua Nathaniel Williams et.al.|[2408.04816v1](http://arxiv.org/abs/2408.04816v1)|[link](https://github.com/jnwilliams/fuse_prompt_inversion)|
|**2024-08-09**|**h4rm3l: A Dynamic Benchmark of Composable Jailbreak Attacks for LLM Safety Assessment**|Moussa Koulako Bala Doumbouya et.al.|[2408.04811v1](http://arxiv.org/abs/2408.04811v1)|null|
|**2024-08-09**|**UniBench: Visual Reasoning Requires Rethinking Vision-Language Beyond Scaling**|Haider Al-Tahan et.al.|[2408.04810v1](http://arxiv.org/abs/2408.04810v1)|[link](https://github.com/facebookresearch/unibench)|
|**2024-08-08**|**Hybrid Student-Teacher Large Language Model Refinement for Cancer Toxicity Symptom Extraction**|Reza Khanmohammadi et.al.|[2408.04775v1](http://arxiv.org/abs/2408.04775v1)|null|
|**2024-08-08**|**Data-Driven Pixel Control: Challenges and Prospects**|Saurabh Farkya et.al.|[2408.04767v1](http://arxiv.org/abs/2408.04767v1)|null|
|**2024-08-08**|**Embodied Uncertainty-Aware Object Segmentation**|Xiaolin Fang et.al.|[2408.04760v1](http://arxiv.org/abs/2408.04760v1)|null|
|**2024-08-08**|**More Questions than Answers? Lessons from Integrating Explainable AI into a Cyber-AI Tool**|Ashley Suh et.al.|[2408.04746v1](http://arxiv.org/abs/2408.04746v1)|null|
|**2024-08-08**|**Survey: Transformer-based Models in Data Modality Conversion**|Elyas Rashno et.al.|[2408.04723v1](http://arxiv.org/abs/2408.04723v1)|null|
|**2024-08-08**|**DyGMamba: Efficiently Modeling Long-Term Temporal Dependency on Continuous-Time Dynamic Graphs with State Space Models**|Zifeng Ding et.al.|[2408.04713v1](http://arxiv.org/abs/2408.04713v1)|null|
|**2024-08-08**|**MulliVC: Multi-lingual Voice Conversion With Cycle Consistency**|Jiawei Huang et.al.|[2408.04708v1](http://arxiv.org/abs/2408.04708v1)|null|
|**2024-08-08**|**Arctic-TILT. Business Document Understanding at Sub-Billion Scale**|Łukasz Borchmann et.al.|[2408.04632v1](http://arxiv.org/abs/2408.04632v1)|null|
|**2024-08-08**|**Puppet-Master: Scaling Interactive Video Generation as a Motion Prior for Part-Level Dynamics**|Ruining Li et.al.|[2408.04631v1](http://arxiv.org/abs/2408.04631v1)|null|
|**2024-08-08**|**LogogramNLP: Comparing Visual and Textual Representations of Ancient Logographic Writing Systems for NLP**|Danlu Chen et.al.|[2408.04628v1](http://arxiv.org/abs/2408.04628v1)|null|
|**2024-08-08**|**Transformer Explainer: Interactive Learning of Text-Generative Models**|Aeree Cho et.al.|[2408.04619v1](http://arxiv.org/abs/2408.04619v1)|null|
|**2024-08-08**|**Better Alignment with Instruction Back-and-Forth Translation**|Thao Nguyen et.al.|[2408.04614v1](http://arxiv.org/abs/2408.04614v1)|null|
|**2024-08-08**|**Code-switching in text and speech reveals information-theoretic audience design**|Debasmita Bhattacharya et.al.|[2408.04596v1](http://arxiv.org/abs/2408.04596v1)|null|
|**2024-08-08**|**Img-Diff: Contrastive Data Synthesis for Multimodal Large Language Models**|Qirui Jiao et.al.|[2408.04594v2](http://arxiv.org/abs/2408.04594v2)|[link](https://github.com/modelscope/data-juicer)|
|**2024-08-08**|**HiLo: A Learning Framework for Generalized Category Discovery Robust to Domain Shifts**|Hongjun Wang et.al.|[2408.04591v1](http://arxiv.org/abs/2408.04591v1)|null|
|**2024-08-08**|**Towards Resilient and Efficient LLMs: A Comparative Study of Efficiency, Performance, and Adversarial Robustness**|Xiaojing Fan et.al.|[2408.04585v2](http://arxiv.org/abs/2408.04585v2)|null|
|**2024-08-08**|**SCENE: Evaluating Explainable AI Techniques Using Soft Counterfactuals**|Haoran Zheng et.al.|[2408.04575v1](http://arxiv.org/abs/2408.04575v1)|null|
|**2024-08-08**|**Learning Fine-Grained Grounded Citations for Attributed Large Language Models**|Lei Huang et.al.|[2408.04568v1](http://arxiv.org/abs/2408.04568v1)|[link](https://github.com/luckyyysta/fine-grained-attribution)|
|**2024-08-08**|**Understanding the Performance and Estimating the Cost of LLM Fine-Tuning**|Yuchen Xia et.al.|[2408.04693v1](http://arxiv.org/abs/2408.04693v1)|[link](https://github.com/stsxxx/finetune)|
|**2024-08-08**|**Conversational Prompt Engineering**|Liat Ein-Dor et.al.|[2408.04560v1](http://arxiv.org/abs/2408.04560v1)|null|
|**2024-08-08**|**Bias-Aware Low-Rank Adaptation: Mitigating Catastrophic Inheritance of Large Language Models**|Yupeng Chang et.al.|[2408.04556v1](http://arxiv.org/abs/2408.04556v1)|[link](https://github.com/cyp-jlu-ai/ba-lora)|
|**2024-08-08**|**Molyé: A Corpus-based Approach to Language Contact in Colonial France**|Rasul Dent et.al.|[2408.04554v1](http://arxiv.org/abs/2408.04554v1)|null|
|**2024-08-08**|**MemeMind at ArAIEval Shared Task: Spotting Persuasive Spans in Arabic Text with Persuasion Techniques Identification**|Md Rafiul Biswas et.al.|[2408.04540v1](http://arxiv.org/abs/2408.04540v1)|null|
|**2024-08-08**|**Exploring Scalability in Large-Scale Time Series in DeepVATS framework**|Inmaculada Santamaria-Valenzuela et.al.|[2408.04692v1](http://arxiv.org/abs/2408.04692v1)|[link](https://github.com/vrodriguezf/deepvats)|
|**2024-08-08**|**Compromesso! Italian Many-Shot Jailbreaks Undermine the Safety of Large Language Models**|Fabio Pernisi et.al.|[2408.04522v1](http://arxiv.org/abs/2408.04522v1)|null|
|**2024-08-08**|**Articulatory Configurations across Genders and Periods in French Radio and TV archives**|Benjamin Elie et.al.|[2408.04519v1](http://arxiv.org/abs/2408.04519v1)|null|
|**2024-08-08**|**Towards Synergistic Deep Learning Models for Volumetric Cirrhotic Liver Segmentation in MRIs**|Vandan Gorade et.al.|[2408.04491v1](http://arxiv.org/abs/2408.04491v1)|null|
|**2024-08-08**|**SegXAL: Explainable Active Learning for Semantic Segmentation in Driving Scene Scenarios**|Sriram Mandalika et.al.|[2408.04482v1](http://arxiv.org/abs/2408.04482v1)|null|
|**2024-08-08**|**Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive Debate**|Yiqun Zhang et.al.|[2408.04472v1](http://arxiv.org/abs/2408.04472v1)|[link](https://github.com/zhangyiqun018/agent-for-debate)|
|**2024-08-08**|**Crowd Intelligence for Early Misinformation Prediction on Social Media**|Megha Sundriyal et.al.|[2408.04463v1](http://arxiv.org/abs/2408.04463v1)|null|
|**2024-08-08**|**RiskAwareBench: Towards Evaluating Physical Risk Awareness for High-level Planning of LLM-based Embodied Agents**|Zihao Zhu et.al.|[2408.04449v1](http://arxiv.org/abs/2408.04449v1)|null|
|**2024-08-08**|**FedAD-Bench: A Unified Benchmark for Federated Unsupervised Anomaly Detection in Tabular Data**|Ahmed Anwar et.al.|[2408.04442v1](http://arxiv.org/abs/2408.04442v1)|null|
|**2024-08-08**|**Improving Relational Database Interactions with Large Language Models: Column Descriptions and Their Impact on Text-to-SQL Performance**|Niklas Wretblad et.al.|[2408.04691v1](http://arxiv.org/abs/2408.04691v1)|null|
|**2024-08-08**|**Recognizing Emotion Regulation Strategies from Human Behavior with Large Language Models**|Philipp Müller et.al.|[2408.04420v1](http://arxiv.org/abs/2408.04420v1)|null|
|**2024-08-08**|**Enhancing Robustness of Retrieval-Augmented Language Models with In-Context Learning**|Seong-Il Park et.al.|[2408.04414v1](http://arxiv.org/abs/2408.04414v1)|null|
|**2024-08-08**|**Design of a Quality Management System based on the EU Artificial Intelligence Act**|Henryk Mustroph et.al.|[2408.04689v1](http://arxiv.org/abs/2408.04689v1)|null|
|**2024-08-08**|**Exploring Reasoning Biases in Large Language Models Through Syllogism: Insights from the NeuBAROCO Dataset**|Kentaro Ozeki et.al.|[2408.04403v1](http://arxiv.org/abs/2408.04403v1)|[link](https://github.com/kmineshima/neubaroco)|
|**2024-08-08**|**DIVE: Subgraph Disagreement for Graph Out-of-Distribution Generalization**|Xin Sun et.al.|[2408.04400v1](http://arxiv.org/abs/2408.04400v1)|null|
|**2024-08-08**|**Automated Educational Question Generation at Different Bloom's Skill Levels using Large Language Models: Strategies and Evaluation**|Nicy Scaria et.al.|[2408.04394v1](http://arxiv.org/abs/2408.04394v1)|null|
|**2024-08-08**|**Open-domain Implicit Format Control for Large Language Model Generation**|Yiqun Yao et.al.|[2408.04392v1](http://arxiv.org/abs/2408.04392v1)|null|

#### Abstracts
##### **Preserving Privacy in Large Language Models: A Survey on Current Threats and Solutions**
2408.05212v1 by Michele Miranda, Elena Sofia Ruzzetti, Andrea Santilli, Fabio Massimo Zanzotto, Sébastien Bratières, Emanuele Rodolà

Large Language Models (LLMs) represent a significant advancement in
artificial intelligence, finding applications across various domains. However,
their reliance on massive internet-sourced datasets for training brings notable
privacy issues, which are exacerbated in critical domains (e.g., healthcare).
Moreover, certain application-specific scenarios may require fine-tuning these
models on private data. This survey critically examines the privacy threats
associated with LLMs, emphasizing the potential for these models to memorize
and inadvertently reveal sensitive information. We explore current threats by
reviewing privacy attacks on LLMs and propose comprehensive solutions for
integrating privacy mechanisms throughout the entire learning pipeline. These
solutions range from anonymizing training datasets to implementing differential
privacy during training or inference and machine unlearning after training. Our
comprehensive review of existing literature highlights ongoing challenges,
available tools, and future directions for preserving privacy in LLMs. This
work aims to guide the development of more secure and trustworthy AI systems by
providing a thorough understanding of privacy preservation methods and their
effectiveness in mitigating risks.

摘要：大型語言模型 (LLM) 代表人工智慧的重大進展，在各個領域中找到應用。然而，它們依賴於大量的網際網路來源資料集進行訓練，這帶來了顯著的隱私問題，而在關鍵領域（例如醫療保健）中會更加嚴重。此外，某些特定於應用程式的場景可能需要針對私人資料微調這些模型。這項調查批判性地審查了與 LLM 相關的隱私威脅，強調了這些模型記憶和無意中揭露敏感資訊的可能性。我們透過檢視 LLM 上的隱私攻擊來探討目前的威脅，並提出全面的解決方案，以在整個學習管道中整合隱私機制。這些解決方案的範圍從匿名化訓練資料集到在訓練或推論期間實施差分隱私，以及訓練後的機器遺忘。我們對現有文獻的全面回顧突出了持續的挑戰、可用的工具和在 LLM 中維護隱私的未來方向。這項工作旨在透過提供對隱私保護方法及其在降低風險方面的有效性的透徹理解，來指導更安全和值得信賴的 AI 系統的開發。

##### **VITA: Towards Open-Source Interactive Omni Multimodal LLM**
2408.05211v1 by Chaoyou Fu, Haojia Lin, Zuwei Long, Yunhang Shen, Meng Zhao, Yifan Zhang, Xiong Wang, Di Yin, Long Ma, Xiawu Zheng, Ran He, Rongrong Ji, Yunsheng Wu, Caifeng Shan, Xing Sun

The remarkable multimodal capabilities and interactive experience of GPT-4o
underscore their necessity in practical applications, yet open-source models
rarely excel in both areas. In this paper, we introduce VITA, the first-ever
open-source Multimodal Large Language Model (MLLM) adept at simultaneous
processing and analysis of Video, Image, Text, and Audio modalities, and
meanwhile has an advanced multimodal interactive experience. Starting from
Mixtral 8x7B as a language foundation, we expand its Chinese vocabulary
followed by bilingual instruction tuning. We further endow the language model
with visual and audio capabilities through two-stage multi-task learning of
multimodal alignment and instruction tuning. VITA demonstrates robust
foundational capabilities of multilingual, vision, and audio understanding, as
evidenced by its strong performance across a range of both unimodal and
multimodal benchmarks. Beyond foundational capabilities, we have made
considerable progress in enhancing the natural multimodal human-computer
interaction experience. To the best of our knowledge, we are the first to
exploit non-awakening interaction and audio interrupt in MLLM. VITA is the
first step for the open-source community to explore the seamless integration of
multimodal understanding and interaction. While there is still lots of work to
be done on VITA to get close to close-source counterparts, we hope that its
role as a pioneer can serve as a cornerstone for subsequent research. Project
Page: https://vita-home.github.io.

摘要：GPT-4o 出色的多模態能力和互動體驗突顯了它們在實際應用中的必要性，但開源模型很少在這兩個領域都表現出色。在本文中，我們介紹了 VITA，這是第一個開源的多模態大型語言模型 (MLLM)，擅長同時處理和分析影片、影像、文字和音訊模態，同時具備先進的多模態互動體驗。我們以 Mixtral 8x7B 為語言基礎，擴充其中文詞彙，然後進行雙語指令微調。我們進一步透過多模態對齊和指令微調的兩階段多任務學習，賦予語言模型視覺和音訊功能。VITA 展現了多語言、視覺和音訊理解的穩健基礎能力，這從其在各種單模態和多模態基準中的出色表現中得到證明。除了基礎能力之外，我們在增強自然的多模態人機互動體驗方面取得了顯著進展。據我們所知，我們是第一個在 MLLM 中利用非喚醒互動和音訊中斷的人。VITA 是開源社群探索多模態理解和互動無縫整合的第一步。雖然 VITA 仍有許多工作要做才能接近封閉原始碼的對應程式，但我們希望它作為先驅的角色可以作為後續研究的基石。專案頁面：https://vita-home.github.io。

##### **Evaluating the capability of large language models to personalize science texts for diverse middle-school-age learners**
2408.05204v1 by Michael Vaccaro Jr, Mikayla Friday, Arash Zaghi

Large language models (LLMs), including OpenAI's GPT-series, have made
significant advancements in recent years. Known for their expertise across
diverse subject areas and quick adaptability to user-provided prompts, LLMs
hold unique potential as Personalized Learning (PL) tools. Despite this
potential, their application in K-12 education remains largely unexplored. This
paper presents one of the first randomized controlled trials (n = 23) to
evaluate the effectiveness of GPT-4 in personalizing educational science texts
for middle school students. In this study, GPT-4 was used to profile student
learning preferences based on choices made during a training session. For the
experimental group, GPT-4 was used to rewrite science texts to align with the
student's predicted profile while, for students in the control group, texts
were rewritten to contradict their learning preferences. The results of a
Mann-Whitney U test showed that students significantly preferred (at the .10
level) the rewritten texts when they were aligned with their profile (p =
.059). These findings suggest that GPT-4 can effectively interpret and tailor
educational content to diverse learner preferences, marking a significant
advancement in PL technology. The limitations of this study and ethical
considerations for using artificial intelligence in education are also
discussed.

摘要：大型語言模型（LLM），包括 OpenAI 的 GPT 系列，近年來取得了重大進展。LLM 以其在不同主題領域的專業知識和快速適應使用者提供的提示而聞名，作為個人化學習（PL）工具具有獨特的潛力。儘管有這種潛力，它們在 K-12 教育中的應用仍然很大程度上未被探索。本文提出了第一個隨機對照試驗（n = 23），以評估 GPT-4 在為中學生個性化教育科學文本方面的有效性。在這項研究中，GPT-4 用於根據訓練期間做出的選擇來描繪學生的學習偏好。對於實驗組，GPT-4 用於重寫科學文本以與學生的預測特徵保持一致，而對於對照組中的學生，文本被重寫以與他們的學習偏好相矛盾。Mann-Whitney U 檢定的結果表明，當重寫的文本與學生的特徵一致時，學生顯著偏好（在 .10 水準上）重寫的文本（p = .059）。這些發現表明，GPT-4 可以有效地解釋和調整教育內容以適應不同的學習者偏好，標誌著 PL 技術的重大進步。本研究的局限性以及在教育中使用人工智慧的倫理考量也將予以討論。

##### **TaSL: Task Skill Localization and Consolidation for Language Model Continual Learning**
2408.05200v1 by Yujie Feng, Xu Chu, Yongxin Xu, Zexin Lu, Bo Liu, Philip S. Yu, Xiao-Ming Wu

Language model continual learning (CL) has recently garnered significant
interest due to its potential to adapt large language models (LLMs) to dynamic
real-world environments without re-training. A key challenge in this field is
catastrophic forgetting, where models lose previously acquired knowledge when
learning new tasks. Existing methods commonly employ multiple
parameter-efficient fine-tuning (PEFT) blocks to acquire task-specific
knowledge for each task, but these approaches lack efficiency and overlook the
potential for knowledge transfer through task interaction. In this paper, we
present a novel CL framework for language models called Task Skill Localization
and Consolidation (TaSL), which enhances knowledge transfer without relying on
memory replay. TaSL first divides the model into `skill units' based on
parameter dependencies, enabling more granular control. It then employs a novel
group-wise skill localization technique to identify the importance distribution
of skill units for a new task. By comparing this importance distribution with
those from previous tasks, we implement a fine-grained skill consolidation
strategy that retains task-specific knowledge, thereby preventing forgetting,
and updates task-shared knowledge, which facilitates bi-directional knowledge
transfer. As a result, TaSL achieves a superior balance between retaining
previous knowledge and excelling in new tasks. TaSL also shows strong
generalizability, suitable for general models and customizable for PEFT methods
like LoRA. Additionally, it demonstrates notable extensibility, allowing
integration with memory replay to further enhance performance. Extensive
experiments on two CL benchmarks, with varying model sizes (from 220M to 7B),
demonstrate the effectiveness of TaSL and its variants across different
settings.

摘要：<paragraph>語言模型持續學習 (CL) 近來備受關注，因為它有潛力讓大型語言模型 (LLM) 適應動態的真實世界環境，而無需重新訓練。此領域的一項關鍵挑戰是災難性遺忘，也就是模型在學習新任務時會遺失先前習得的知識。現有方法通常採用多個參數高效微調 (PEFT) 區塊來為每個任務取得特定於任務的知識，但這些方法缺乏效率，而且忽略了透過任務互動進行知識傳輸的潛力。在本文中，我們提出一個稱為任務技能定位和整合 (TaSL) 的語言模型新 CL 架構，它增強了知識傳輸，而無需依賴記憶體重播。TaSL 首先根據參數依賴性將模型分成「技能單元」，進而能更精細地控制。接著，它採用一種新的群組式技能定位技術，找出技能單元在新任務中的重要性分佈。透過將此重要性分佈與先前任務中的重要性分佈進行比較，我們實作了一種精細的技能整合策略，保留特定於任務的知識，進而防止遺忘，並更新共用於任務的知識，促進雙向知識傳輸。因此，TaSL 在保留先前知識和在新的任務中表現出色之間取得了更佳的平衡。TaSL 也展現出強大的概括性，適用於一般模型，且可自訂為 PEFT 方法，例如 LoRA。此外，它展現出顯著的可擴充性，允許與記憶體重播整合，以進一步增強效能。在兩個 CL 基準上進行的廣泛實驗，使用不同大小的模型（從 220M 到 7B），證明了 TaSL 及其變體在不同設定中的有效性。</paragraph>

##### **HistoKernel: Whole Slide Image Level Maximum Mean Discrepancy Kernels for Pan-Cancer Predictive Modelling**
2408.05195v1 by Piotr Keller, Muhammad Dawood, Brinder Singh Chohan, Fayyaz ul Amir Afsar Minhas

Machine learning in computational pathology (CPath) often aggregates
patch-level predictions from multi-gigapixel Whole Slide Images (WSIs) to
generate WSI-level prediction scores for crucial tasks such as survival
prediction and drug effect prediction. However, current methods do not
explicitly characterize distributional differences between patch sets within
WSIs. We introduce HistoKernel, a novel Maximum Mean Discrepancy (MMD) kernel
that measures distributional similarity between WSIs for enhanced prediction
performance on downstream prediction tasks.
  Our comprehensive analysis demonstrates HistoKernel's effectiveness across
various machine learning tasks, including retrieval (n = 9,362), drug
sensitivity regression (n = 551), point mutation classification (n = 3,419),
and survival analysis (n = 2,291), outperforming existing deep learning
methods. Additionally, HistoKernel seamlessly integrates multi-modal data and
offers a novel perturbation-based method for patch-level explainability. This
work pioneers the use of kernel-based methods for WSI-level predictive
modeling, opening new avenues for research. Code is available at
https://github.com/pkeller00/HistoKernel.

摘要：計算病理學 (CPath) 中的機器學習經常彙總來自多吉像素全幻燈片影像 (WSI) 的補丁級別預測，以產生 WSI 級別預測分數，用於存活預測和藥物效果預測等關鍵任務。然而，目前的技術並未明確描述 WSI 中補丁組之間的分配差異。我們引入了 HistoKernel，這是一種新的最大平均差異 (MMD) 核，它測量 WSI 之間的分配相似性，以增強下游預測任務的預測效能。我們的全面分析證明了 HistoKernel 在各種機器學習任務中的有效性，包括檢索 (n = 9,362)、藥物敏感性回歸 (n = 551)、點突變分類 (n = 3,419) 和存活分析 (n = 2,291)，優於現有的深度學習方法。此外，HistoKernel 無縫整合多模式數據，並提供一種新的基於擾動的方法，用於補丁級別的可解釋性。這項工作開創了使用基於核的方法進行 WSI 級別預測建模的先河，為研究開闢了新的途徑。程式碼可在 https://github.com/pkeller00/HistoKernel 取得。

##### **Separating Style from Substance: Enhancing Cross-Genre Authorship Attribution through Data Selection and Presentation**
2408.05192v1 by Steven Fincke, Elizabeth Boschee

The task of deciding whether two documents are written by the same author is
challenging for both machines and humans. This task is even more challenging
when the two documents are written about different topics (e.g. baseball vs.
politics) or in different genres (e.g. a blog post vs. an academic article).
For machines, the problem is complicated by the relative lack of real-world
training examples that cross the topic boundary and the vanishing scarcity of
cross-genre data. We propose targeted methods for training data selection and a
novel learning curriculum that are designed to discourage a model's reliance on
topic information for authorship attribution and correspondingly force it to
incorporate information more robustly indicative of style no matter the topic.
These refinements yield a 62.7% relative improvement in average cross-genre
authorship attribution, as well as 16.6% in the per-genre condition.

摘要：判定兩份文件是否由同一位作者撰寫，對機器和人類來說都是一項艱鉅的任務。如果這兩份文件的主題不同（例如棒球與政治）或體裁不同（例如部落格文章與學術論文），這項任務的難度會更高。對機器而言，問題在於跨越主題邊界的真實世界訓練範例相對不足，以及跨體裁資料的數量極少。我們提出針對性的方法，用於訓練資料選取和新穎的學習課程，這些方法旨在阻止模型依賴主題資訊進行作者歸屬，並相應地迫使模型納入更能穩健地指示風格的資訊，而不管主題為何。這些改進在平均跨體裁作者歸屬方面產生了 62.7% 的相對改善，在單一體裁條件下產生了 16.6% 的改善。

##### **Deep-change at AXOLOTL-24: Orchestrating WSD and WSI Models for Semantic Change Modeling**
2408.05184v1 by Denis Kokosinskii, Mikhail Kuklin, Nikolay Arefyev

This paper describes our solution of the first subtask from the AXOLOTL-24
shared task on Semantic Change Modeling. The goal of this subtask is to
distribute a given set of usages of a polysemous word from a newer time period
between senses of this word from an older time period and clusters representing
gained senses of this word. We propose and experiment with three new methods
solving this task. Our methods achieve SOTA results according to both official
metrics of the first substask. Additionally, we develop a model that can tell
if a given word usage is not described by any of the provided sense
definitions. This model serves as a component in one of our methods, but can
potentially be useful on its own.

摘要：本文描述了我們在 AXOLOTL-24 語意變遷模型共享任務中第一個子任務的解決方案。此子任務的目標是將一組來自較新時間段的多義詞用法分佈到較舊時間段的此字詞義，以及代表此字詞獲得的義的群集。我們提出並實驗了三種新的方法來解決此任務。我們的根據第一個子任務的兩個官方指標都達到了 SOTA 結果。此外，我們開發了一個模型，可以判斷給定的字詞用法是否未由任何提供的義定義所描述。此模型作為我們的方法之一的組成部分，但潛在也可以單獨使用。

##### **AttackER: Towards Enhancing Cyber-Attack Attribution with a Named Entity Recognition Dataset**
2408.05149v1 by Pritam Deka, Sampath Rajapaksha, Ruby Rani, Amirah Almutairi, Erisa Karafili

Cyber-attack attribution is an important process that allows experts to put
in place attacker-oriented countermeasures and legal actions. The analysts
mainly perform attribution manually, given the complex nature of this task. AI
and, more specifically, Natural Language Processing (NLP) techniques can be
leveraged to support cybersecurity analysts during the attribution process.
However powerful these techniques are, they need to deal with the lack of
datasets in the attack attribution domain. In this work, we will fill this gap
and will provide, to the best of our knowledge, the first dataset on
cyber-attack attribution. We designed our dataset with the primary goal of
extracting attack attribution information from cybersecurity texts, utilizing
named entity recognition (NER) methodologies from the field of NLP. Unlike
other cybersecurity NER datasets, ours offers a rich set of annotations with
contextual details, including some that span phrases and sentences. We
conducted extensive experiments and applied NLP techniques to demonstrate the
dataset's effectiveness for attack attribution. These experiments highlight the
potential of Large Language Models (LLMs) capabilities to improve the NER tasks
in cybersecurity datasets for cyber-attack attribution.

摘要：網路攻擊歸因是一個重要的流程，讓專家得以採取以攻擊者為導向的反制措施和法律行動。由於這項任務的複雜性，分析師主要手動執行歸因。人工智慧，更具體地說，自然語言處理 (NLP) 技術可以被利用來在歸因過程中支援網路安全分析師。儘管這些技術非常強大，但它們需要處理攻擊歸因領域中缺乏資料集的問題。在這項工作中，我們將填補這個空白，並根據我們的知識，提供第一個網路攻擊歸因資料集。我們設計資料集的主要目標是從網路安全文字中萃取攻擊歸因資訊，利用自然語言處理領域中的命名實體辨識 (NER) 方法。與其他網路安全 NER 資料集不同，我們的資料集提供了一組豐富的註解，其中包含上下文細節，包括跨越詞組和句子的註解。我們進行了廣泛的實驗，並應用自然語言處理技術來展示資料集在攻擊歸因方面的有效性。這些實驗突顯了大型語言模型 (LLM) 能力在改善網路安全資料集中 NER 任務的潛力，以進行網路攻擊歸因。

##### **Gemma Scope: Open Sparse Autoencoders Everywhere All At Once on Gemma 2**
2408.05147v1 by Tom Lieberum, Senthooran Rajamanoharan, Arthur Conmy, Lewis Smith, Nicolas Sonnerat, Vikrant Varma, János Kramár, Anca Dragan, Rohin Shah, Neel Nanda

Sparse autoencoders (SAEs) are an unsupervised method for learning a sparse
decomposition of a neural network's latent representations into seemingly
interpretable features. Despite recent excitement about their potential,
research applications outside of industry are limited by the high cost of
training a comprehensive suite of SAEs. In this work, we introduce Gemma Scope,
an open suite of JumpReLU SAEs trained on all layers and sub-layers of Gemma 2
2B and 9B and select layers of Gemma 2 27B base models. We primarily train SAEs
on the Gemma 2 pre-trained models, but additionally release SAEs trained on
instruction-tuned Gemma 2 9B for comparison. We evaluate the quality of each
SAE on standard metrics and release these results. We hope that by releasing
these SAE weights, we can help make more ambitious safety and interpretability
research easier for the community. Weights and a tutorial can be found at
https://huggingface.co/google/gemma-scope and an interactive demo can be found
at https://www.neuronpedia.org/gemma-scope

摘要：稀疏自動編碼器 (SAE) 是一種無監督方法，用於學習神經網路潛在表示的稀疏分解，成為看似可解釋的功能。儘管最近對其潛力感到興奮，但產業外的研究應用受到訓練一套全面的 SAE 的高成本所限制。在這項工作中，我們介紹了 Gemma Scope，一個在 Gemma 2 2B 和 9B 的所有層和子層以及 Gemma 2 27B 基礎模型的選定層上訓練的 JumpReLU SAE 的開放套件。我們主要在 Gemma 2 預訓練模型上訓練 SAE，但另外發布了在指令調整的 Gemma 2 9B 上訓練的 SAE 以供比較。我們根據標準指標評估每個 SAE 的品質，並發布這些結果。我們希望通過發布這些 SAE 權重，我們可以幫助社群更容易進行更具野心的安全性和可解釋性研究。權重和教學課程可以在 https://huggingface.co/google/gemma-scope 找到，互動式示範可以在 https://www.neuronpedia.org/gemma-scope 找到

##### **A Hybrid RAG System with Comprehensive Enhancement on Complex Reasoning**
2408.05141v1 by Ye Yuan, Chengwu Liu, Jingyang Yuan, Gongbo Sun, Siqi Li, Ming Zhang

Retrieval-augmented generation (RAG) is a framework enabling large language
models (LLMs) to enhance their accuracy and reduce hallucinations by
integrating external knowledge bases. In this paper, we introduce a hybrid RAG
system enhanced through a comprehensive suite of optimizations that
significantly improve retrieval quality, augment reasoning capabilities, and
refine numerical computation ability. We refined the text chunks and tables in
web pages, added attribute predictors to reduce hallucinations, conducted LLM
Knowledge Extractor and Knowledge Graph Extractor, and finally built a
reasoning strategy with all the references. We evaluated our system on the CRAG
dataset through the Meta CRAG KDD Cup 2024 Competition. Both the local and
online evaluations demonstrate that our system significantly enhances complex
reasoning capabilities. In local evaluations, we have significantly improved
accuracy and reduced error rates compared to the baseline model, achieving a
notable increase in scores. In the meanwhile, we have attained outstanding
results in online assessments, demonstrating the performance and generalization
capabilities of the proposed system. The source code for our system is released
in \url{https://gitlab.aicrowd.com/shizueyy/crag-new}.

摘要：檢索增強生成 (RAG) 是一個架構，使大型語言模型 (LLM) 能夠透過整合外部知識庫來增強其準確性並減少幻覺。在本文中，我們介紹了一個混合 RAG 系統，透過全面的最佳化套件進行增強，可顯著提升檢索品質、增強推理能力，並改善數值計算能力。我們改進了網頁中的文字區塊和表格，加入屬性預測器以減少幻覺，執行 LLM 知識萃取器和知識圖表萃取器，最後建構了一個包含所有參考的推理策略。我們透過 Meta CRAG KDD Cup 2024 競賽在 CRAG 資料集上評估我們的系統。在地端和線上評估都證明我們的系統顯著增強了複雜推理能力。在地端評估中，我們與基準模型相比，顯著提升了準確性並降低了錯誤率，達到了顯著的分數提升。同時，我們在線上評估中取得了傑出的成果，證明了所提出的系統的效能和泛化能力。我們系統的原始碼已發布在 \url{https://gitlab.aicrowd.com/shizueyy/crag-new}。

##### **Large Language Models and Thematic Analysis: Human-AI Synergy in Researching Hate Speech on Social Media**
2408.05126v1 by Petre Breazu, Miriam Schirmer, Songbo Hu, Napoleon Kastos

In the dynamic field of artificial intelligence (AI), the development and
application of Large Language Models (LLMs) for text analysis are of
significant academic interest. Despite the promising capabilities of various
LLMs in conducting qualitative analysis, their use in the humanities and social
sciences has not been thoroughly examined. This article contributes to the
emerging literature on LLMs in qualitative analysis by documenting an
experimental study involving GPT-4. The study focuses on performing thematic
analysis (TA) using a YouTube dataset derived from an EU-funded project, which
was previously analyzed by other researchers. This dataset is about the
representation of Roma migrants in Sweden during 2016, a period marked by the
aftermath of the 2015 refugee crisis and preceding the Swedish national
elections in 2017. Our study seeks to understand the potential of combining
human intelligence with AI's scalability and efficiency, examining the
advantages and limitations of employing LLMs in qualitative research within the
humanities and social sciences. Additionally, we discuss future directions for
applying LLMs in these fields.

摘要：在人工智能 (AI) 的動態領域中，用於文本分析的大語言模型 (LLM) 的開發和應用具有重大的學術興趣。儘管各種 LLM 在進行定性分析方面具有令人滿意的能力，但它們在人文學科和社會科學中的應用尚未得到徹底檢驗。本文透過記錄一項涉及 GPT-4 的實驗研究，為定性分析中關於 LLM 的新興文獻做出貢獻。該研究專注於使用來自歐盟資助專案的 YouTube 資料集執行主題分析 (TA)，該資料集先前已由其他研究人員分析過。此資料集關於 2016 年羅姆人移民在瑞典的代表性，這段期間的特徵是 2015 年難民危機的後果和 2017 年瑞典國家選舉的前夕。我們的研究旨在了解將人類智慧與 AI 的可擴充性和效率相結合的可能性，探討在人文學科和社會科學中採用 LLM 進行定性研究的優點和限制。此外，我們討論了在這些領域應用 LLM 的未來方向。

##### **Beyond the Eye: A Relational Model for Early Dementia Detection Using Retinal OCTA Images**
2408.05117v1 by Shouyue Liu, Jinkui Hao, Yonghuai Liu, Huazhu Fu, Xinyu Guo, Shuting Zhang, Yitian Zhao

Early detection of dementia, such as Alzheimer's disease (AD) or mild
cognitive impairment (MCI), is essential to enable timely intervention and
potential treatment. Accurate detection of AD/MCI is challenging due to the
high complexity, cost, and often invasive nature of current diagnostic
techniques, which limit their suitability for large-scale population screening.
Given the shared embryological origins and physiological characteristics of the
retina and brain, retinal imaging is emerging as a potentially rapid and
cost-effective alternative for the identification of individuals with or at
high risk of AD. In this paper, we present a novel PolarNet+ that uses retinal
optical coherence tomography angiography (OCTA) to discriminate early-onset AD
(EOAD) and MCI subjects from controls. Our method first maps OCTA images from
Cartesian coordinates to polar coordinates, allowing approximate sub-region
calculation to implement the clinician-friendly early treatment of diabetic
retinopathy study (ETDRS) grid analysis. We then introduce a multi-view module
to serialize and analyze the images along three dimensions for comprehensive,
clinically useful information extraction. Finally, we abstract the sequence
embedding into a graph, transforming the detection task into a general graph
classification problem. A regional relationship module is applied after the
multi-view module to excavate the relationship between the sub-regions. Such
regional relationship analyses validate known eye-brain links and reveal new
discriminative patterns.

摘要：早期偵測失智症，例如阿茲海默症 (AD) 或輕度認知障礙 (MCI)，對於及時介入和潛在治療至關重要。由於目前診斷技術的複雜性高、成本高，且常常具有侵入性，因此準確偵測 AD/MCI 極具挑戰性，這也限制了其用於大規模人群篩檢的適用性。考量到視網膜和腦部具有相同的胚胎起源和生理特性，視網膜影像正逐漸成為一種潛在的快速且具成本效益的替代方案，用於找出罹患 AD 或具有高風險的個人。在本文中，我們提出了一種創新的 PolarNet+，它使用視網膜光學相干斷層血管造影 (OCTA) 來區分早發性 AD (EOAD) 和 MCI 受試者與對照組。我們的做法首先將 OCTA 影像從笛卡爾坐標轉換為極坐標，讓近似子區域計算得以實作，進而執行對臨床醫師友善的糖尿病視網膜病變早期治療研究 (ETDRS) 格線分析。接著，我們引入一個多視圖模組，用於串列化並沿著三個向度分析影像，以進行全面的、臨床上有用的資訊萃取。最後，我們將序列嵌入抽象化為一個圖形，將偵測任務轉換為一個通用的圖形分類問題。在多視圖模組後應用區域關係模組，以探討子區域之間的關係。此類區域關係分析驗證了已知的視網膜與腦部關聯，並揭示了新的判別模式。

##### **How Well Do LLMs Identify Cultural Unity in Diversity?**
2408.05102v1 by Jialin Li, Junli Wang, Junjie Hu, Ming Jiang

Much work on the cultural awareness of large language models (LLMs) focuses
on the models' sensitivity to geo-cultural diversity. However, in addition to
cross-cultural differences, there also exists common ground across cultures.
For instance, a bridal veil in the United States plays a similar
cultural-relevant role as a honggaitou in China. In this study, we introduce a
benchmark dataset CUNIT for evaluating decoder-only LLMs in understanding the
cultural unity of concepts. Specifically, CUNIT consists of 1,425 evaluation
examples building upon 285 traditional cultural-specific concepts across 10
countries. Based on a systematic manual annotation of cultural-relevant
features per concept, we calculate the cultural association between any pair of
cross-cultural concepts. Built upon this dataset, we design a contrastive
matching task to evaluate the LLMs' capability to identify highly associated
cross-cultural concept pairs. We evaluate 3 strong LLMs, using 3 popular
prompting strategies, under the settings of either giving all extracted concept
features or no features at all on CUNIT Interestingly, we find that cultural
associations across countries regarding clothing concepts largely differ from
food. Our analysis shows that LLMs are still limited to capturing
cross-cultural associations between concepts compared to humans. Moreover,
geo-cultural proximity shows a weak influence on model performance in capturing
cross-cultural associations.

摘要：許多關於大型語言模型（LLM）的文化意識研究都集中在模型對地緣文化多樣性的敏感度上。然而，除了跨文化差異之外，各文化之間也存在共通點。例如，美國的新娘面紗在文化上扮演的角色與中國的鳳冠霞帔類似。在本研究中，我們引入了基準資料集 CUNIT，用於評估僅解碼器 LLM 在理解概念文化統一性方面的能力。具體來說，CUNIT 包含 1,425 個評估範例，建立在 10 個國家/地區的 285 個傳統文化特定概念之上。根據對每個概念進行的系統性手動標註，我們計算了任何一對跨文化概念之間的文化關聯性。建立在此資料集之上，我們設計了一個對比匹配任務，以評估 LLM 識別高度關聯的跨文化概念對的能力。我們使用 3 種流行的提示策略，在 CUNIT 上給予所有提取的概念特徵或根本不給予任何特徵的設定下，評估了 3 個強大的 LLM。有趣的是，我們發現不同國家/地區之間關於服裝概念的文化關聯性與食物有很大的不同。我們的分析表明，與人類相比，LLM 在捕捉概念之間的跨文化關聯方面仍然有限。此外，地緣文化接近性對模型在捕捉跨文化關聯性方面的效能影響微弱。

##### **MooER: LLM-based Speech Recognition and Translation Models from Moore Threads**
2408.05101v1 by Junhao Xu, Zhenlin Liang, Yi Liu, Yichao Hu, Jian Li, Yajun Zheng, Meng Cai, Hua Wang

In this paper, we present MooER, a LLM-based large-scale automatic speech
recognition (ASR) / automatic speech translation (AST) model of Moore Threads.
A 5000h pseudo labeled dataset containing open source and self collected speech
data is used for training. We achieve performance comparable to other open
source models trained with up to hundreds of thousands of hours of labeled
speech data. Meanwhile, experiments conducted on Covost2 Zh2en testset suggest
that our model outperforms other open source Speech LLMs. A BLEU score of 25.2
can be obtained. The main contributions of this paper are summarized as
follows. First, this paper presents a training strategy for encoders and LLMs
on speech related tasks (including ASR and AST) using a small size of pseudo
labeled data without any extra manual annotation and selection. Second, we
release our ASR and AST models and plan to open-source our training code and
strategy in the near future. Moreover, a model trained on 8wh scale training
data is planned to be released later on.

摘要：在本文中，我们介绍了 MooER，一种基于 LLM 的大规模自动语音识别 (ASR)/自动语音翻译 (AST) 模型，由摩尔线程提供。
一个包含开源和自己收集的语音数据的 5000 小时伪标记数据集用于训练。我们实现的性能可与使用多达数十万小时标记语音数据训练的其他开源模型相媲美。同时，在 Covost2 Zh2en 测试集上进行的实验表明，我们的模型优于其他开源语音 LLM。可以获得 25.2 的 BLEU 分数。本文的主要贡献总结如下。首先，本文提出了一种在语音相关任务（包括 ASR 和 AST）上使用少量伪标记数据（没有任何额外的手动注释和选择）对编码器和 LLM 进行训练的训练策略。其次，我们发布我们的 ASR 和 AST 模型，并计划在不久的将来开源我们的训练代码和策略。此外，计划稍后发布在 8wh 规模训练数据上训练的模型。

##### **AI-driven Java Performance Testing: Balancing Result Quality with Testing Time**
2408.05100v1 by Luca Traini, Federico Di Menna, Vittorio Cortellessa

Performance testing aims at uncovering efficiency issues of software systems.
In order to be both effective and practical, the design of a performance test
must achieve a reasonable trade-off between result quality and testing time.
This becomes particularly challenging in Java context, where the software
undergoes a warm-up phase of execution, due to just-in-time compilation. During
this phase, performance measurements are subject to severe fluctuations, which
may adversely affect quality of performance test results. However, these
approaches often provide suboptimal estimates of the warm-up phase, resulting
in either insufficient or excessive warm-up iterations, which may degrade
result quality or increase testing time. There is still a lack of consensus on
how to properly address this problem. Here, we propose and study an AI-based
framework to dynamically halt warm-up iterations at runtime. Specifically, our
framework leverages recent advances in AI for Time Series Classification (TSC)
to predict the end of the warm-up phase during test execution. We conduct
experiments by training three different TSC models on half a million of
measurement segments obtained from JMH microbenchmark executions. We find that
our framework significantly improves the accuracy of the warm-up estimates
provided by state-of-practice and state-of-the-art methods. This higher
estimation accuracy results in a net improvement in either result quality or
testing time for up to +35.3% of the microbenchmarks. Our study highlights that
integrating AI to dynamically estimate the end of the warm-up phase can enhance
the cost-effectiveness of Java performance testing.

摘要：效能測試旨在找出軟體系統的效率問題。
為了同時兼顧有效性和實用性，效能測試的設計必須在結果品質與測試時間之間取得合理的平衡。
這在 Java 環境中特別具有挑戰性，因為軟體會因為即時編譯而經歷一段暖身執行階段。在這個階段中，效能測量會受到劇烈波動的影響，進而對效能測試結果的品質造成負面影響。然而，這些方法通常會提供次佳的暖身階段估計，導致暖身反覆測試不足或過多，進而降低結果品質或增加測試時間。對於如何妥善解決這個問題，目前尚未達成共識。在此，我們提出並探討一個基於 AI 的架構，可以在執行階段動態暫停暖身反覆測試。具體來說，我們的架構利用 AI 在時間序列分類 (TSC) 的最新進展，在測試執行期間預測暖身階段的結束。我們透過在從 JMH 微基準測試執行中取得的五十萬個測量區段上訓練三個不同的 TSC 模型，來進行實驗。我們發現我們的架構顯著提升了實務上和最先進方法所提供的暖身估計準確度。這個更高的估計準確度導致微基準測試的結果品質或測試時間淨改善幅度最高達 +35.3%。我們的研究強調，整合 AI 以動態估計暖身階段的結束，可以提升 Java 效能測試的成本效益。

##### **Overcoming the Limitations of Layer Synchronization in Spiking Neural Networks**
2408.05098v1 by Roel Koopman, Amirreza Yousefzadeh, Mahyar Shahsavari, Guangzhi Tang, Manolis Sifalakis

Currently, neural-network processing in machine learning applications relies
on layer synchronization, whereby neurons in a layer aggregate incoming
currents from all neurons in the preceding layer, before evaluating their
activation function. This is practiced even in artificial Spiking Neural
Networks (SNNs), which are touted as consistent with neurobiology, in spite of
processing in the brain being, in fact asynchronous. A truly asynchronous
system however would allow all neurons to evaluate concurrently their threshold
and emit spikes upon receiving any presynaptic current. Omitting layer
synchronization is potentially beneficial, for latency and energy efficiency,
but asynchronous execution of models previously trained with layer
synchronization may entail a mismatch in network dynamics and performance. We
present a study that documents and quantifies this problem in three datasets on
our simulation environment that implements network asynchrony, and we show that
models trained with layer synchronization either perform sub-optimally in
absence of the synchronization, or they will fail to benefit from any energy
and latency reduction, when such a mechanism is in place. We then "make ends
meet" and address the problem with unlayered backprop, a novel
backpropagation-based training method, for learning models suitable for
asynchronous processing. We train with it models that use different neuron
execution scheduling strategies, and we show that although their neurons are
more reactive, these models consistently exhibit lower overall spike density
(up to 50%), reach a correct decision faster (up to 2x) without integrating all
spikes, and achieve superior accuracy (up to 10% higher). Our findings suggest
that asynchronous event-based (neuromorphic) AI computing is indeed more
efficient, but we need to seriously rethink how we train our SNN models, to
benefit from it.

摘要：<paragraph>目前，機器學習應用程式中的神經網路處理依賴於層同步，藉此，一層中的神經元會在評估其活化函數之前，彙總前一層中所有神經元的輸入電流。這甚至在人工尖峰神經網路 (SNN) 中也是如此，儘管大腦中的處理實際上是異步的，但 SNN 被吹捧為與神經生物學一致。然而，一個真正的異步系統將允許所有神經元同時評估其閾值，並在接收到任何突觸前電流時發出尖峰。省略層同步在延遲和能源效率方面可能是有益的，但先前使用層同步訓練的模型的異步執行可能會導致網路動態和效能不匹配。我們提出了一項研究，記錄並量化了這個問題，該研究在我們的模擬環境中使用三個資料集，該環境實現了網路異步性，我們表明使用層同步訓練的模型在沒有同步的情況下表現不佳，或者在這種機制到位時，它們將無法從任何能量和延遲減少中受益。然後我們「兩全其美」，並使用非分層反向傳播來解決這個問題，這是一種新穎的反向傳播訓練方法，用於學習適合異步處理的模型。我們使用它訓練使用不同神經元執行排程策略的模型，我們表明，儘管它們的神經元反應更靈敏，但這些模型始終表現出較低的整體尖峰密度（高達 50%），在不整合所有尖峰的情況下更快地做出正確的決策（高達 2 倍），並實現更高的準確度（高達 10%）。我們的發現表明，異步事件驅動（神經形態）人工智慧運算確實更有效率，但我們需要認真重新思考我們如何訓練我們的 SNN 模型，才能從中受益。</paragraph>

##### **Hyperbolic Learning with Multimodal Large Language Models**
2408.05097v1 by Paolo Mandica, Luca Franco, Konstantinos Kallidromitis, Suzanne Petryk, Fabio Galasso

Hyperbolic embeddings have demonstrated their effectiveness in capturing
measures of uncertainty and hierarchical relationships across various
deep-learning tasks, including image segmentation and active learning. However,
their application in modern vision-language models (VLMs) has been limited. A
notable exception is MERU, which leverages the hierarchical properties of
hyperbolic space in the CLIP ViT-large model, consisting of hundreds of
millions parameters. In our work, we address the challenges of scaling
multi-modal hyperbolic models by orders of magnitude in terms of parameters
(billions) and training complexity using the BLIP-2 architecture. Although
hyperbolic embeddings offer potential insights into uncertainty not present in
Euclidean embeddings, our analysis reveals that scaling these models is
particularly difficult. We propose a novel training strategy for a hyperbolic
version of BLIP-2, which allows to achieve comparable performance to its
Euclidean counterpart, while maintaining stability throughout the training
process and showing a meaningful indication of uncertainty with each embedding.

摘要：雙曲嵌入已證明其在捕捉各種深度學習任務中的不確定性和層級關係的測量值（包括影像分割和主動學習）方面有效。然而，它們在現代視覺語言模型 (VLM) 中的應用受到限制。一個值得注意的例外是 MERU，它利用了 CLIP ViT-large 模型中雙曲空間的層級屬性，該模型包含數億個參數。在我們的研究中，我們透過 BLIP-2 架構解決了在參數（數十億）和訓練複雜性方面擴展多模態雙曲模型的挑戰。儘管雙曲嵌入提供了歐幾里得嵌入中不存在的不確定性潛在見解，但我們的分析表明，擴展這些模型特別困難。我們為 BLIP-2 的雙曲版本提出了創新的訓練策略，該策略允許實現與其歐幾里得對應項相當的效能，同時在整個訓練過程中保持穩定性，並顯示每個嵌入的不確定性有意義的指標。

##### **Unlocking Decoding-time Controllability: Gradient-Free Multi-Objective Alignment with Contrastive Prompts**
2408.05094v1 by Tingchen Fu, Yupeng Hou, Julian McAuley, Rui Yan

The task of multi-objective alignment aims at balancing and controlling the
different alignment objectives (e.g., helpfulness, harmlessness and honesty) of
large language models to meet the personalized requirements of different users.
However, previous methods tend to train multiple models to deal with various
user preferences, with the number of trained models growing linearly with the
number of alignment objectives and the number of different preferences.
Meanwhile, existing methods are generally poor in extensibility and require
significant re-training for each new alignment objective considered.
Considering the limitation of previous approaches, we propose MCA
(Multi-objective Contrastive Alignemnt), which constructs an expert prompt and
an adversarial prompt for each objective to contrast at the decoding time and
balances the objectives through combining the contrast. Our approach is
verified to be superior to previous methods in obtaining a well-distributed
Pareto front among different alignment objectives.

摘要：多目標對齊任務旨在平衡和控制大型語言模型的不同對齊目標（例如，有用性、無害性和誠實），以滿足不同使用者的個性化需求。
然而，先前的做法傾向於訓練多個模型來處理各種使用者偏好，而訓練模型的數量會隨著對齊目標數量和不同偏好數量線性增加。
同時，現有方法通常在可擴充性方面表現不佳，並且需要針對每個新的對齊目標進行大量的重新訓練。
考慮到先前方法的限制，我們提出了 MCA（多目標對比式對齊），它為每個目標建構一個專家提示和一個對抗性提示，以便在解碼時進行對比，並透過結合對比來平衡目標。我們的做法被驗證為優於先前的方法，可以在不同的對齊目標之間獲得分佈良好的帕累托前緣。

##### **Order Matters in Hallucination: Reasoning Order as Benchmark and Reflexive Prompting for Large-Language-Models**
2408.05093v1 by Zikai Xie

Large language models (LLMs) have generated significant attention since their
inception, finding applications across various academic and industrial domains.
However, these models often suffer from the "hallucination problem", where
outputs, though grammatically and logically coherent, lack factual accuracy or
are entirely fabricated. A particularly troubling issue discovered and widely
discussed recently is the numerical comparison error where multiple LLMs
incorrectly infer that "9.11$>$9.9". We discovered that the order in which LLMs
generate answers and reasoning impacts their consistency. Specifically, results
vary significantly when an LLM generates an answer first and then provides the
reasoning versus generating the reasoning process first and then the
conclusion. Inspired by this, we propose a new benchmark method for assessing
LLM consistency: comparing responses generated through these two different
approaches. This benchmark effectively identifies instances where LLMs
fabricate answers and subsequently generate justifications. Furthermore, we
introduce a novel and straightforward prompt strategy designed to mitigate this
issue. Experimental results demonstrate that this strategy improves performance
across various LLMs compared to direct questioning. This work not only sheds
light on a critical flaw in LLMs but also offers a practical solution to
enhance their reliability.

摘要：大型語言模型 (LLM) 自推出以來已引起廣泛關注，並在各個學術和產業領域中找到應用。然而，這些模型常常會出現「幻覺問題」，其輸出內容雖然在文法和邏輯上連貫，但缺乏事實依據或完全是捏造的。最近發現並廣泛討論的一個特別令人不安的問題是數值比較錯誤，其中多個 LLM 錯誤地推論出「9.11$>$9.9」。我們發現 LLM 生成答案和推理的順序會影響其一致性。具體來說，當 LLM 先生成答案，然後提供推理，與先生成推理過程，然後生成結論時，結果會有顯著差異。受此啟發，我們提出了一種新的基準方法來評估 LLM 的一致性：比較通過這兩種不同方法生成的回應。此基準有效地識別出 LLM 編造答案並隨後生成理由的實例。此外，我們引入了一種新穎且直接的提示策略，旨在減輕此問題。實驗結果表明，與直接提問相比，此策略改善了各種 LLM 的性能。這項工作不僅揭示了 LLM 的一個關鍵缺陷，還提供了一個實用的解決方案來增強其可靠性。

##### **Generating novel experimental hypotheses from language models: A case study on cross-dative generalization**
2408.05086v1 by Kanishka Misra, Najoung Kim

Neural network language models (LMs) have been shown to successfully capture
complex linguistic knowledge. However, their utility for understanding language
acquisition is still debated. We contribute to this debate by presenting a case
study where we use LMs as simulated learners to derive novel experimental
hypotheses to be tested with humans. We apply this paradigm to study
cross-dative generalization (CDG): productive generalization of novel verbs
across dative constructions (she pilked me the ball/she pilked the ball to me)
-- acquisition of which is known to involve a large space of contextual
features -- using LMs trained on child-directed speech. We specifically ask:
"what properties of the training exposure facilitate a novel verb's
generalization to the (unmodeled) alternate construction?" To answer this, we
systematically vary the exposure context in which a novel dative verb occurs in
terms of the properties of the theme and recipient, and then analyze the LMs'
usage of the novel verb in the unmodeled dative construction. We find LMs to
replicate known patterns of children's CDG, as a precondition to exploring
novel hypotheses. Subsequent simulations reveal a nuanced role of the features
of the novel verbs' exposure context on the LMs' CDG. We find CDG to be
facilitated when the first postverbal argument of the exposure context is
pronominal, definite, short, and conforms to the prototypical animacy
expectations of the exposure dative. These patterns are characteristic of
harmonic alignment in datives, where the argument with features ranking higher
on the discourse prominence scale tends to precede the other. This gives rise
to a novel hypothesis that CDG is facilitated insofar as the features of the
exposure context -- in particular, its first postverbal argument -- are
harmonically aligned. We conclude by proposing future experiments that can test
this hypothesis in children.

摘要：<paragraph>神經網路語言模型 (LM) 已被證明可以成功擷取複雜的語言知識。然而，它們在理解語言習得方面的效用仍有爭議。我們透過提出一個案例研究來為這場辯論做出貢獻，在案例研究中，我們使用 LM 作為模擬學習者，以衍生出新的實驗假設，並在人類身上進行測試。我們將此範例應用於研究交互受詞概化 (CDG)：跨受詞結構產生新動詞的概化（她 pilked 我球／她 pilked 球給我）——已知其習得涉及大量的語境特徵空間——使用針對兒童導向語言訓練的 LM。我們特別詢問：「訓練曝露的哪些特性促進了新動詞概化到（未建模的）替代結構？」為了解答這個問題，我們系統性地改變新受詞動詞出現在曝露語境中的語境，以主題和受詞的特性為依據，然後分析 LM 在未建模的受詞結構中對新動詞的使用。我們發現 LM 會複製已知的兒童 CDG 模式，作為探索新假設的前提。後續模擬揭示了新動詞曝露語境特徵對 LM 的 CDG 的細微作用。我們發現，當曝露語境的動詞後第一個論元是代名詞、明確、簡短且符合曝露受詞的典型有生性預期時，CDG 會被促進。這些模式是受詞中調和對齊的特性，其中在語篇重要性量表上排名較高的論元特徵傾向於先於其他論元。這產生了一個新的假設，即 CDG 會被促進，因為曝露語境的特性——特別是其動詞後第一個論元——是調和對齊的。我們最後提出未來實驗，可以在兒童身上測試此假設。</paragraph>

##### **RT-Surv: Improving Mortality Prediction After Radiotherapy with Large Language Model Structuring of Large-Scale Unstructured Electronic Health Records**
2408.05074v1 by Sangjoon Park, Chan Woo Wee, Seo Hee Choi, Kyung Hwan Kim, Jee Suk Chang, Hong In Yoon, Ik Jae Lee, Yong Bae Kim, Jaeho Cho, Ki Chang Keum, Chang Geol Lee, Hwa Kyung Byun, Woong Sub Koom

Accurate patient selection is critical in radiotherapy (RT) to prevent
ineffective treatments. Traditional survival prediction models, relying on
structured data, often lack precision. This study explores the potential of
large language models (LLMs) to structure unstructured electronic health record
(EHR) data, thereby improving survival prediction accuracy through
comprehensive clinical information integration. Data from 34,276 patients
treated with RT at Yonsei Cancer Center between 2013 and 2023 were analyzed,
encompassing both structured and unstructured data. An open-source LLM was used
to structure the unstructured EHR data via single-shot learning, with its
performance compared against a domain-specific medical LLM and a smaller
variant. Survival prediction models were developed using statistical, machine
learning, and deep learning approaches, incorporating both structured and
LLM-structured data. Clinical experts evaluated the accuracy of the
LLM-structured data. The open-source LLM achieved 87.5% accuracy in structuring
unstructured EHR data without additional training, significantly outperforming
the domain-specific medical LLM, which reached only 35.8% accuracy. Larger LLMs
were more effective, particularly in extracting clinically relevant features
like general condition and disease extent, which closely correlated with
patient survival. Incorporating LLM-structured clinical features into survival
prediction models significantly improved accuracy, with the C-index of deep
learning models increasing from 0.737 to 0.820. These models also became more
interpretable by emphasizing clinically significant factors. This study shows
that general-domain LLMs, even without specific medical training, can
effectively structure large-scale unstructured EHR data, substantially
enhancing the accuracy and interpretability of clinical predictive models.

摘要：<paragraph>在放射治療中，準確的患者選擇至關重要，以防止無效的治療。傳統的存活預測模型依賴於結構化資料，通常缺乏精確度。本研究探討了大型語言模型 (LLM) 結構化非結構化電子健康記錄 (EHR) 資料的潛力，從而通過全面的臨床資訊整合來提高存活預測準確度。分析了 2013 年至 2023 年間在延世癌症中心接受放射治療的 34,276 名患者的資料，包括結構化和非結構化資料。使用開源 LLM 通過單次學習來結構化非結構化 EHR 資料，並將其效能與特定領域的醫療 LLM 和較小的變體進行比較。存活預測模型是使用統計、機器學習和深度學習方法開發的，結合了結構化和 LLM 結構化的資料。臨床專家評估了 LLM 結構化資料的準確性。開源 LLM 在不進行額外訓練的情況下，結構化非結構化 EHR 資料的準確度達到 87.5%，顯著優於特定領域的醫療 LLM，後者的準確度僅達到 35.8%。較大的 LLM 更有效，特別是在提取臨床相關特徵方面，例如一般狀況和疾病程度，這與患者存活率密切相關。將 LLM 結構化的臨床特徵納入存活預測模型顯著提高了準確性，深度學習模型的 C 指數從 0.737 提高到 0.820。這些模型也變得更具可解釋性，因為它們強調了臨床上重要的因素。本研究表明，即使沒有具體的醫療訓練，通用領域的 LLM 也可以有效地結構化大規模的非結構化 EHR 資料，從而顯著提高臨床預測模型的準確性和可解釋性。</paragraph>

##### **A Jailbroken GenAI Model Can Cause Substantial Harm: GenAI-powered Applications are Vulnerable to PromptWares**
2408.05061v1 by Stav Cohen, Ron Bitton, Ben Nassi

In this paper we argue that a jailbroken GenAI model can cause substantial
harm to GenAI-powered applications and facilitate PromptWare, a new type of
attack that flips the GenAI model's behavior from serving an application to
attacking it. PromptWare exploits user inputs to jailbreak a GenAI model to
force/perform malicious activity within the context of a GenAI-powered
application. First, we introduce a naive implementation of PromptWare that
behaves as malware that targets Plan & Execute architectures (a.k.a., ReAct,
function calling). We show that attackers could force a desired execution flow
by creating a user input that produces desired outputs given that the logic of
the GenAI-powered application is known to attackers. We demonstrate the
application of a DoS attack that triggers the execution of a GenAI-powered
assistant to enter an infinite loop that wastes money and computational
resources on redundant API calls to a GenAI engine, preventing the application
from providing service to a user. Next, we introduce a more sophisticated
implementation of PromptWare that we name Advanced PromptWare Threat (APwT)
that targets GenAI-powered applications whose logic is unknown to attackers. We
show that attackers could create user input that exploits the GenAI engine's
advanced AI capabilities to launch a kill chain in inference time consisting of
six steps intended to escalate privileges, analyze the application's context,
identify valuable assets, reason possible malicious activities, decide on one
of them, and execute it. We demonstrate the application of APwT against a
GenAI-powered e-commerce chatbot and show that it can trigger the modification
of SQL tables, potentially leading to unauthorized discounts on the items sold
to the user.

摘要：<paragraph>在本文中，我們論證越獄的 GenAI 模型可能會對 GenAI 驅動的應用程式造成重大傷害，並促成 PromptWare，這是一種新型攻擊，它將 GenAI 模型的行為從服務應用程式轉變為攻擊它。PromptWare 利用使用者輸入越獄 GenAI 模型，以在 GenAI 驅動的應用程式中強制執行惡意活動。首先，我們介紹 PromptWare 的一個天真實作，它表現為針對 Plan & Execute 架構（又稱 ReAct，函式呼叫）的惡意軟體。我們表明，攻擊者可以透過建立使用者輸入來強制執行所需的執行流程，而這些輸入會產生所需的輸出，前提是攻擊者知道 GenAI 驅動的應用程式的邏輯。我們展示了 DoS 攻擊的應用，它會觸發 GenAI 驅動的助理執行無限迴圈，浪費金錢和運算資源在對 GenAI 引擎的重複 API 呼叫上，從而阻止應用程式向使用者提供服務。接下來，我們介紹 PromptWare 的更精緻實作，我們稱之為進階 PromptWare 威脅 (APwT)，它針對邏輯對攻擊者未知的 GenAI 驅動的應用程式。我們表明，攻擊者可以建立使用者輸入，利用 GenAI 引擎的進階 AI 功能，在推論時間啟動一個由六個步驟組成的殺戮鏈，旨在升級權限、分析應用程式的內容、識別有價值的資產、推論可能的惡意活動、決定其中一個，並執行它。我們展示了 APwT 對 GenAI 驅動的電子商務聊天機器人的應用，並表明它可以觸發修改 SQL 表格，可能導致對賣給使用者的商品提供未經授權的折扣。</paragraph>

##### **GLEAMS: Bridging the Gap Between Local and Global Explanations**
2408.05060v1 by Giorgio Visani, Vincenzo Stanzione, Damien Garreau

The explainability of machine learning algorithms is crucial, and numerous
methods have emerged recently. Local, post-hoc methods assign an attribution
score to each feature, indicating its importance for the prediction. However,
these methods require recalculating explanations for each example. On the other
side, while there exist global approaches they often produce explanations that
are either overly simplistic and unreliable or excessively complex. To bridge
this gap, we propose GLEAMS, a novel method that partitions the input space and
learns an interpretable model within each sub-region, thereby providing both
faithful local and global surrogates. We demonstrate GLEAMS' effectiveness on
both synthetic and real-world data, highlighting its desirable properties and
human-understandable insights.

摘要：機器學習演算法的可解釋性至關重要，最近出現許多方法。局部事後方法會將歸因分數指派給每個特徵，表示其對預測的重要性。然而，這些方法需要為每個範例重新計算解釋。另一方面，雖然存在全球方法，但它們通常會產生過於簡化且不可靠或過於複雜的解釋。為了彌補這個差距，我們提出了 GLEAMS，這是一種新的方法，它會分割輸入空間，並在每個子區域中學習可解釋的模型，從而提供忠實的局部和全局替代品。我們在合成和真實世界資料上展示了 GLEAMS 的效能，突顯了其理想的特性和人類可理解的見解。

##### **SELD-Mamba: Selective State-Space Model for Sound Event Localization and Detection with Source Distance Estimation**
2408.05057v1 by Da Mu, Zhicheng Zhang, Haobo Yue, Zehao Wang, Jin Tang, Jianqin Yin

In the Sound Event Localization and Detection (SELD) task, Transformer-based
models have demonstrated impressive capabilities. However, the quadratic
complexity of the Transformer's self-attention mechanism results in
computational inefficiencies. In this paper, we propose a network architecture
for SELD called SELD-Mamba, which utilizes Mamba, a selective state-space
model. We adopt the Event-Independent Network V2 (EINV2) as the foundational
framework and replace its Conformer blocks with bidirectional Mamba blocks to
capture a broader range of contextual information while maintaining
computational efficiency. Additionally, we implement a two-stage training
method, with the first stage focusing on Sound Event Detection (SED) and
Direction of Arrival (DoA) estimation losses, and the second stage
reintroducing the Source Distance Estimation (SDE) loss. Our experimental
results on the 2024 DCASE Challenge Task3 dataset demonstrate the effectiveness
of the selective state-space model in SELD and highlight the benefits of the
two-stage training approach in enhancing SELD performance.

摘要：在聲音事件定位和偵測 (SELD) 任務中，以 Transformer 為基礎的模型已展現令人印象深刻的能力。然而，Transformer 自注意力機制的二次複雜度導致運算效率低落。在本文中，我們提出一個稱為 SELD-Mamba 的 SELD 網路架構，它利用 Mamba，一種選擇性的狀態空間模型。我們採用事件無關網路 V2 (EINV2) 作為基礎架構，並用雙向 Mamba 區塊取代其 Conformer 區塊，以擷取更廣泛的脈絡資訊，同時維持運算效率。此外，我們實作一個兩階段訓練方法，第一階段專注於聲音事件偵測 (SED) 和到達方向 (DoA) 估計損失，而第二階段重新引入來源距離估計 (SDE) 損失。我們在 2024 DCASE Challenge Task3 資料集上的實驗結果證明了選擇性狀態空間模型在 SELD 中的有效性，並突顯了兩階段訓練方法在增強 SELD 效能方面的優點。

##### **A GNN Model with Adaptive Weights for Session-Based Recommendation Systems**
2408.05051v1 by Begüm Özbay, Dr. Resul Tugay, Prof. Dr. Şule Gündüz Öğüdücü

Session-based recommendation systems aim to model users' interests based on
their sequential interactions to predict the next item in an ongoing session.
In this work, we present a novel approach that can be used in session-based
recommendations (SBRs). Our goal is to enhance the prediction accuracy of an
existing session-based recommendation model, the SR-GNN model, by introducing
an adaptive weighting mechanism applied to the graph neural network (GNN)
vectors. This mechanism is designed to incorporate various types of side
information obtained through different methods during the study. Items are
assigned varying degrees of importance within each session as a result of the
weighting mechanism. We hypothesize that this adaptive weighting strategy will
contribute to more accurate predictions and thus improve the overall
performance of SBRs in different scenarios. The adaptive weighting strategy can
be utilized to address the cold start problem in SBRs by dynamically adjusting
the importance of items in each session, thus providing better recommendations
in cold start situations, such as for new users or newly added items. Our
experimental evaluations on the Dressipi dataset demonstrate the effectiveness
of the proposed approach compared to traditional models in enhancing the user
experience and highlighting its potential to optimize the recommendation
results in real-world applications.

摘要：基於會話的推薦系統旨在根據使用者的順序互動來模擬其興趣，以預測進行中會話中的下一個項目。在這項工作中，我們提出了一種新穎的方法，可用於基於會話的推薦 (SBR)。我們的目標是透過在圖形神經網路 (GNN) 向量中導入自適應加權機制，來提升現有基於會話的推薦模型 SR-GNN 模型的預測準確度。此機制旨在納入研究期間透過不同方法取得的各種側邊資訊。由於加權機制，每個會話中的項目會被賦予不同程度的重要性。我們假設這種自適應加權策略將有助於更準確的預測，進而提升 SBR 在不同場景中的整體效能。自適應加權策略可用於解決 SBR 中的冷啟動問題，方法是動態調整每個會話中項目的重要性，從而提供更好的冷啟動建議，例如針對新使用者或新加入的項目。我們在 Dressipi 資料集上的實驗評估證明了所提出的方法與傳統模型相比在提升使用者體驗方面的有效性，並突顯其在現實世界應用中最佳化推薦結果的潛力。

##### **Examining the Behavior of LLM Architectures Within the Framework of Standardized National Exams in Brazil**
2408.05035v1 by Marcelo Sartori Locatelli, Matheus Prado Miranda, Igor Joaquim da Silva Costa, Matheus Torres Prates, Victor Thomé, Mateus Zaparoli Monteiro, Tomas Lacerda, Adriana Pagano, Eduardo Rios Neto, Wagner Meira Jr., Virgilio Almeida

The Exame Nacional do Ensino M\'edio (ENEM) is a pivotal test for Brazilian
students, required for admission to a significant number of universities in
Brazil. The test consists of four objective high-school level tests on Math,
Humanities, Natural Sciences and Languages, and one writing essay. Students'
answers to the test and to the accompanying socioeconomic status questionnaire
are made public every year (albeit anonymized) due to transparency policies
from the Brazilian Government. In the context of large language models (LLMs),
these data lend themselves nicely to comparing different groups of humans with
AI, as we can have access to human and machine answer distributions. We
leverage these characteristics of the ENEM dataset and compare GPT-3.5 and 4,
and MariTalk, a model trained using Portuguese data, to humans, aiming to
ascertain how their answers relate to real societal groups and what that may
reveal about the model biases. We divide the human groups by using
socioeconomic status (SES), and compare their answer distribution with LLMs for
each question and for the essay. We find no significant biases when comparing
LLM performance to humans on the multiple-choice Brazilian Portuguese tests, as
the distance between model and human answers is mostly determined by the human
accuracy. A similar conclusion is found by looking at the generated text as,
when analyzing the essays, we observe that human and LLM essays differ in a few
key factors, one being the choice of words where model essays were easily
separable from human ones. The texts also differ syntactically, with LLM
generated essays exhibiting, on average, smaller sentences and less thought
units, among other differences. These results suggest that, for Brazilian
Portuguese in the ENEM context, LLM outputs represent no group of humans, being
significantly different from the answers from Brazilian students across all
tests.

摘要：巴西國家中學教育考試 (ENEM) 對巴西學生來說是一項關鍵考試，是進入巴西眾多大學的必要條件。考試包含四項數學、人文、自然科學和語言的高中程度客觀測驗，以及一篇寫作論文。由於巴西政府的透明化政策，學生對考試和附帶的社會經濟地位問卷的回答每年都會公開（儘管是匿名）。在大型語言模型 (LLM) 的背景下，這些數據非常適合將不同的人類群體與 AI 進行比較，因為我們可以獲得人類和機器答案的分布。我們利用 ENEM 數據集的這些特徵，並將 GPT-3.5 和 4，以及使用葡萄牙語數據訓練的模型 MariTalk 與人類進行比較，旨在確定他們的答案與真實社會群體的關聯性，以及這可能揭示模型偏見的內容。我們使用社會經濟地位 (SES) 來劃分人類群體，並將他們的答案分佈與每個問題和論文的 LLM 進行比較。在將 LLM 的表現與人類在巴西葡萄牙語多項選擇測驗中的表現進行比較時，我們沒有發現顯著的偏見，因為模型和人類答案之間的距離主要由人類的準確性決定。通過查看生成的文本，我們發現了一個類似的結論，在分析論文時，我們觀察到人類和 LLM 論文在幾個關鍵因素上有所不同，其中一個因素是詞彙選擇，模型論文很容易與人類論文區分開來。這些文本在句法上也有所不同，由 LLM 生成的論文平均來說句子較短，思想單元較少，還有其他不同之處。這些結果表明，在 ENEM 背景下的巴西葡萄牙語中，LLM 輸出不代表任何人類群體，與巴西學生在所有考試中的答案有顯著不同。

##### **Rag and Roll: An End-to-End Evaluation of Indirect Prompt Manipulations in LLM-based Application Frameworks**
2408.05025v1 by Gianluca De Stefano, Giancarlo Pellegrino, Lea Schönherr

Retrieval Augmented Generation (RAG) is a technique commonly used to equip
models with out of distribution knowledge. This process involves collecting,
indexing, retrieving, and providing information to an LLM for generating
responses. Despite its growing popularity due to its flexibility and low cost,
the security implications of RAG have not been extensively studied. The data
for such systems are often collected from public sources, providing an attacker
a gateway for indirect prompt injections to manipulate the responses of the
model. In this paper, we investigate the security of RAG systems against
end-to-end indirect prompt manipulations. First, we review existing RAG
framework pipelines deriving a prototypical architecture and identifying
potentially critical configuration parameters. We then examine prior works
searching for techniques that attackers can use to perform indirect prompt
manipulations. Finally, implemented Rag n Roll, a framework to determine the
effectiveness of attacks against end-to-end RAG applications. Our results show
that existing attacks are mostly optimized to boost the ranking of malicious
documents during the retrieval phase. However, a higher rank does not
immediately translate into a reliable attack. Most attacks, against various
configurations, settle around a 40% success rate, which could rise to 60% when
considering ambiguous answers as successful attacks (those that include the
expected benign one as well). Additionally, when using unoptimized documents,
attackers deploying two of them (or more) for a target query can achieve
similar results as those using optimized ones. Finally, exploration of the
configuration space of a RAG showed limited impact in thwarting the attacks,
where the most successful combination severely undermines functionality.

摘要：檢索擴增生成 (RAG) 是一種常見技術，用於為模型提供分佈知識。此程序包括收集、索引、檢索，並提供資訊給 LLM 以產生回應。儘管 RAG 因其靈活性與低成本而越來越受歡迎，但其安全影響尚未廣泛研究。此類系統的資料通常從公開來源收集，為攻擊者提供了一個間接提示注入的管道，以操縱模型的回應。在本文中，我們針對端到端間接提示操縱探討 RAG 系統的安全性。首先，我們檢視現有的 RAG 框架管道，衍生出一個原型架構並找出潛在關鍵組態參數。接著，我們檢視先前作品，尋找攻擊者可利用來執行間接提示操縱的技術。最後，實作 Rag n Roll，一個用於確定攻擊對端到端 RAG 應用程式的有效性的框架。我們的結果顯示，現有的攻擊大多最佳化為在檢索階段提升惡意文件的排名。然而，較高的排名並不會立即轉化為可靠的攻擊。針對各種組態的大多數攻擊，成功率約為 40%，當將模稜兩可的答案視為成功的攻擊（包含預期的良性答案）時，成功率可能會上升至 60%。此外，當使用未最佳化的文件時，攻擊者為目標查詢部署其中兩個（或更多）文件，可以達到與使用最佳化文件類似的結果。最後，探索 RAG 的組態空間顯示出在阻止攻擊方面影響有限，其中最成功的組合嚴重破壞了功能。

##### **MIDI-to-Tab: Guitar Tablature Inference via Masked Language Modeling**
2408.05024v1 by Drew Edwards, Xavier Riley, Pedro Sarmento, Simon Dixon

Guitar tablatures enrich the structure of traditional music notation by
assigning each note to a string and fret of a guitar in a particular tuning,
indicating precisely where to play the note on the instrument. The problem of
generating tablature from a symbolic music representation involves inferring
this string and fret assignment per note across an entire composition or
performance. On the guitar, multiple string-fret assignments are possible for
most pitches, which leads to a large combinatorial space that prevents
exhaustive search approaches. Most modern methods use constraint-based dynamic
programming to minimize some cost function (e.g.\ hand position movement). In
this work, we introduce a novel deep learning solution to symbolic guitar
tablature estimation. We train an encoder-decoder Transformer model in a masked
language modeling paradigm to assign notes to strings. The model is first
pre-trained on DadaGP, a dataset of over 25K tablatures, and then fine-tuned on
a curated set of professionally transcribed guitar performances. Given the
subjective nature of assessing tablature quality, we conduct a user study
amongst guitarists, wherein we ask participants to rate the playability of
multiple versions of tablature for the same four-bar excerpt. The results
indicate our system significantly outperforms competing algorithms.

摘要：吉他指法譜豐富了傳統樂譜的結構，方法是將每個音符分配給特定調音的吉他弦和品格，準確地指出在樂器上彈奏音符的位置。根據符號音樂表示法生成指法譜的問題涉及推斷整個樂曲或演奏中每個音符的這個弦和品格分配。在吉他上，大多數音高都可以有多個弦格分配，這導致一個龐大的組合空間，從而阻止了窮舉搜索方法。大多數現代方法使用基於約束的動態規劃來最小化某些成本函數（例如手部位置移動）。在這項工作中，我們引入了一種新的深度學習解決方案，用於符號吉他指法譜估計。我們在掩蔽語言建模範例中訓練了一個編碼器-解碼器 Transformer 模型，以將音符分配給弦。該模型首先在 DadaGP（一個包含超過 25K 個指法譜的數據集）上進行預訓練，然後在經過整理的一組專業轉錄的吉他演奏上進行微調。鑑於評估指法譜質量的主觀性，我們在吉他手之間進行了一項用戶研究，其中我們要求參與者對同一四小節選段的指法譜多個版本的可演奏性進行評分。結果表明，我們的系統顯著優於競爭演算法。

##### **Investigating a Benchmark for Training-set free Evaluation of Linguistic Capabilities in Machine Reading Comprehension**
2408.05023v1 by Viktor Schlegel, Goran Nenadic, Riza Batista-Navarro

Performance of NLP systems is typically evaluated by collecting a large-scale
dataset by means of crowd-sourcing to train a data-driven model and evaluate it
on a held-out portion of the data. This approach has been shown to suffer from
spurious correlations and the lack of challenging examples that represent the
diversity of natural language. Instead, we examine a framework for evaluating
optimised models in training-set free setting on synthetically generated
challenge sets. We find that despite the simplicity of the generation method,
the data can compete with crowd-sourced datasets with regard to naturalness and
lexical diversity for the purpose of evaluating the linguistic capabilities of
MRC models. We conduct further experiments and show that state-of-the-art
language model-based MRC systems can learn to succeed on the challenge set
correctly, although, without capturing the general notion of the evaluated
phenomenon.

摘要：NLP 系統的效能通常透過群眾外包的方式收集大型資料集來訓練資料驅動模型，並在資料的保留部分進行評估。此方法已被證明會受到虛假關聯和缺乏代表自然語言多樣性的挑戰範例影響。我們改為探討一個在訓練集自由設定中，使用合成產生的挑戰集來評估最佳化模型的架構。我們發現，儘管生成方法很簡單，但資料在自然性和詞彙多樣性方面，仍可與群眾外包的資料集相媲美，以評估 MRC 模型的語言能力。我們進一步進行實驗，並證明了最先進的基於語言模型的 MRC 系統，可以在挑戰集中正確學習成功，儘管沒有捕捉到所評估現象的一般概念。

##### **Enhancing the Code Debugging Ability of LLMs via Communicative Agent Based Data Refinement**
2408.05006v1 by Weiqing Yang, Hanbin Wang, Zhenghao Liu, Xinze Li, Yukun Yan, Shuo Wang, Yu Gu, Minghe Yu, Zhiyuan Liu, Ge Yu

Debugging is a vital aspect of software development, yet the debugging
capabilities of Large Language Models (LLMs) remain largely unexplored. This
paper first introduces DEBUGEVAL, a comprehensive benchmark designed to
evaluate the debugging capabilities of LLMs. DEBUGEVAL collects data from
existing high-quality datasets and designs four different tasks to evaluate the
debugging effectiveness, including BUG Localization, BUG Identification, Code
Review, and Code Repair. Additionally, to enhance the code debugging ability of
LLMs, this paper proposes a CoMmunicative Agent BaSed DaTa REfinement FRamework
(MASTER), which generates the refined code debugging data for supervised
finetuning. Specifically, MASTER employs the Code Quizzer to generate refined
data according to the defined tasks of DEBUGEVAL. Then the Code Learner acts as
a critic and reserves the generated problems that it can not solve. Finally,
the Code Teacher provides a detailed Chain-of-Thought based solution to deal
with the generated problem. We collect the synthesized data and finetune the
Code Learner to enhance the debugging ability and conduct the NeuDebugger
model. Our experiments evaluate various LLMs and NeuDebugger in the zero-shot
setting on DEBUGEVAL. Experimental results demonstrate that these 7B-scale LLMs
have weaker debugging capabilities, even these code-oriented LLMs. On the
contrary, these larger models (over 70B) show convincing debugging ability. Our
further analyses illustrate that MASTER is an effective method to enhance the
code debugging ability by synthesizing data for Supervised Fine-Tuning (SFT)
LLMs.

摘要：<paragraph>除錯是軟體開發的重要面向，然而大型語言模型 (LLM) 的除錯能力仍鮮少被探討。本文首先介紹 DEBUGEVAL，一個用於評估 LLM 除錯能力的綜合基準測試。DEBUGEVAL 從現有的高品質資料集中收集資料，並設計四種不同的任務來評估除錯的有效性，包括錯誤定位、錯誤識別、程式碼檢閱和程式碼修復。此外，為了增強 LLM 的程式碼除錯能力，本文提出一個基於溝通代理的資料精煉框架 (MASTER)，為監督微調產生精煉的程式碼除錯資料。具體來說，MASTER 使用程式碼測驗產生精煉的資料，根據 DEBUGEVAL 定義的任務。然後，程式碼學習器扮演批評者的角色，保留它無法解決的產生問題。最後，程式碼教師提供一個基於思考鏈的詳細解決方案來處理產生的問題。我們收集合成的資料，並微調程式碼學習器以增強除錯能力，並執行 NeuDebugger 模型。我們的實驗在 DEBUGEVAL 上評估各種 LLM 和 NeuDebugger 的零次學習設定。實驗結果表明，這些 7B 級別的 LLM 具有較弱的除錯能力，即使是這些以程式碼為導向的 LLM。相反地，這些較大的模型 (超過 70B) 表現出令人信服的除錯能力。我們的進一步分析說明，MASTER 是一種通過為監督微調 (SFT) LLM 合成資料來增強程式碼除錯能力的有效方法。</paragraph>

##### **ProFuser: Progressive Fusion of Large Language Models**
2408.04998v1 by Tianyuan Shi, Fanqi Wan, Canbin Huang, Xiaojun Quan, Chenliang Li, Ming Yan, Ji Zhang

While fusing the capacities and advantages of various large language models
(LLMs) offers a pathway to construct more powerful and versatile models, a
fundamental challenge is to properly select advantageous model during the
training. Existing fusion methods primarily focus on the training mode that
uses cross entropy on ground truth in a teacher-forcing setup to measure a
model's advantage, which may provide limited insight towards model advantage.
In this paper, we introduce a novel approach that enhances the fusion process
by incorporating both the training and inference modes. Our method evaluates
model advantage not only through cross entropy during training but also by
considering inference outputs, providing a more comprehensive assessment. To
combine the two modes effectively, we introduce ProFuser to progressively
transition from inference mode to training mode. To validate ProFuser's
effectiveness, we fused three models, including vicuna-7b-v1.5,
Llama-2-7b-chat, and mpt-7b-8k-chat, and demonstrated the improved performance
in knowledge, reasoning, and safety compared to baseline methods.

摘要：<paragraph>在融合各種大型語言模型 (LLM) 的能力和優勢時，提供了建構更強大且多功能模型的途徑，一個基本挑戰是在訓練期間適當地選擇有利的模型。現有的融合方法主要專注於在教師強制設置中對基本事實使用交叉熵的訓練模式，以衡量模型的優勢，這可能會對模型優勢提供有限的見解。在本文中，我們介紹了一種創新的方法，透過結合訓練和推理模式來增強融合過程。我們的模型不僅透過訓練期間的交叉熵評估模型優勢，還透過考慮推理輸出，提供更全面的評估。為了有效結合這兩種模式，我們引入了 ProFuser，以逐步從推理模式過渡到訓練模式。為了驗證 ProFuser 的有效性，我們融合了三個模型，包括 vicuna-7b-v1.5、Llama-2-7b-chat 和 mpt-7b-8k-chat，並展示了與基線方法相比在知識、推理和安全性方面的改進效能。</paragraph>

##### **Get Confused Cautiously: Textual Sequence Memorization Erasure with Selective Entropy Maximization**
2408.04983v1 by Zhaohan Zhang, Ziquan Liu, Ioannis Patras

Large Language Models (LLMs) have been found to memorize and recite some of
the textual sequences from their training set verbatim, raising broad concerns
about privacy and copyright issues when using LLMs. This Textual Sequence
Memorization (TSM) phenomenon leads to a high demand to regulate LLM output to
prevent it from generating certain memorized text to meet user requirements.
However, our empirical study reveals that existing methods for TSM erasure fail
to forget massive memorized samples without substantially jeopardizing the
model utility. To achieve a better trade-off between the effectiveness of TSM
erasure and model utility in LLMs, our paper proposes a new framework based on
Entropy Maximization with Selective Optimization (EMSO), where the updated
weights are chosen with a novel contrastive gradient metric without any
participation of additional model or data. Our analysis shows that training
with the entropy maximization loss has a more stable optimization process and
better keeps model utility than existing methods. The contrastive gradient
metric localizes the most influential weight for TSM erasure by taking both the
gradient magnitude and direction into consideration. Extensive experiments
across three model scales demonstrate that our method excels in handling
large-scale forgetting requests while preserving model ability in language
generation and reasoning.

摘要：大型語言模型 (LLM) 已被發現會死記硬背並逐字背誦其訓練集中的一些文字序列，這引起了人們對使用 LLM 時的隱私和版權問題的廣泛關注。這種文字序列記憶 (TSM) 現象導致了對 LLM 輸出的高度監管需求，以防止其生成某些記憶文本來滿足用戶需求。然而，我們的實證研究表明，現有的 TSM 刪除方法無法忘記大量的記憶樣本，而不會大幅損害模型實用性。為了在 LLM 中 TSM 刪除的有效性與模型實用性之間取得更好的權衡，我們的論文提出了一個基於選擇性優化的熵最大化 (EMSO) 的新框架，其中更新的權重是使用一種新穎的對比梯度度量來選擇的，而無需任何額外的模型或數據參與。我們的分析表明，使用熵最大化損失進行訓練具有更穩定的優化過程，並且比現有方法更好地保持模型實用性。對比梯度度量通過同時考慮梯度大小和方向來定位 TSM 刪除最有影響力的權重。跨三個模型規模的廣泛實驗表明，我們的模型在處理大規模遺忘請求時表現出色，同時保留了模型在語言生成和推理中的能力。

##### **reCSE: Portable Reshaping Features for Sentence Embedding in Self-supervised Contrastive Learning**
2408.04975v2 by Fufangchen Zhao, Gao Jian, Danfeng Yan

We propose reCSE, a self supervised contrastive learning sentence
representation framework based on feature reshaping. This framework is
different from the current advanced models that use discrete data augmentation
methods, but instead reshapes the input features of the original sentence,
aggregates the global information of each token in the sentence, and alleviates
the common problems of representation polarity and GPU memory consumption
linear increase in current advanced models. In addition, our reCSE has achieved
competitive performance in semantic similarity tasks. And the experiment proves
that our proposed feature reshaping method has strong universality, which can
be transplanted to other self supervised contrastive learning frameworks and
enhance their representation ability, even achieving state-of-the-art
performance. Our code is available at https://github.com/heavenhellchen/reCSE.

摘要：我們提出 reCSE，一個基於特徵重塑的自監督對比學習句子表示框架。此框架不同於使用離散數據擴充方法的當前先進模型，而是重塑原始句子的輸入特徵，彙總句子中每個符號的全局資訊，並緩解了表示極性和 GPU 記憶體消耗在當前先進模型中線性增加的常見問題。此外，我們的 reCSE 在語義相似性任務中取得了有競爭力的表現。實驗證明，我們提出的特徵重塑方法具有很強的通用性，可以移植到其他自監督對比學習框架，並增強其表示能力，甚至達到最先進的效能。我們的程式碼可在 https://github.com/heavenhellchen/reCSE 取得。

##### **Generalisation First, Memorisation Second? Memorisation Localisation for Natural Language Classification Tasks**
2408.04965v1 by Verna Dankers, Ivan Titov

Memorisation is a natural part of learning from real-world data: neural
models pick up on atypical input-output combinations and store those training
examples in their parameter space. That this happens is well-known, but how and
where are questions that remain largely unanswered. Given a multi-layered
neural model, where does memorisation occur in the millions of parameters?
Related work reports conflicting findings: a dominant hypothesis based on image
classification is that lower layers learn generalisable features and that
deeper layers specialise and memorise. Work from NLP suggests this does not
apply to language models, but has been mainly focused on memorisation of facts.
We expand the scope of the localisation question to 12 natural language
classification tasks and apply 4 memorisation localisation techniques. Our
results indicate that memorisation is a gradual process rather than a localised
one, establish that memorisation is task-dependent, and give nuance to the
generalisation first, memorisation second hypothesis.

摘要：記憶是從真實世界資料中學習的自然部分：神經模型會接收非典型的輸入輸出組合，並將那些訓練範例儲存在它們的參數空間中。這件事的發生是眾所周知，但如何以及在哪裡仍然是很大程度未解答的問題。給定一個多層神經模型，記憶發生在數百萬個參數中的哪裡？相關工作報告有相互矛盾的發現：一個基於影像分類的主導假設是較低層學習可概括的特徵，而較深層則專門化並記憶。自然語言處理的工作表明這不適用於語言模型，但主要集中於事實的記憶。我們將定位問題的範圍擴展到 12 項自然語言分類任務，並應用 4 種記憶定位技術。我們的結果表明，記憶是一個漸進的過程，而不是一個局部化的過程，確定記憶取決於任務，並對概括優先，記憶其次的假設提供細微差別。

##### **LLaVA-VSD: Large Language-and-Vision Assistant for Visual Spatial Description**
2408.04957v1 by Yizhang Jin, Jian Li, Jiangning Zhang, Jianlong Hu, Zhenye Gan, Xin Tan, Yong Liu, Yabiao Wang, Chengjie Wang, Lizhuang Ma

Visual Spatial Description (VSD) aims to generate texts that describe the
spatial relationships between objects within images. Traditional visual spatial
relationship classification (VSRC) methods typically output the spatial
relationship between two objects in an image, often neglecting world knowledge
and lacking general language capabilities. In this paper, we propose a Large
Language-and-Vision Assistant for Visual Spatial Description, named LLaVA-VSD,
which is designed for the classification, description, and open-ended
description of visual spatial relationships. Specifically, the model first
constructs a VSD instruction-following dataset using given figure-caption pairs
for the three tasks. It then employs LoRA to fine-tune a Large Language and
Vision Assistant for VSD, which has 13 billion parameters and supports
high-resolution images. Finally, a large language model (Qwen-2) is used to
refine the generated sentences, enhancing their diversity and accuracy.
LLaVA-VSD demonstrates excellent multimodal conversational capabilities and can
follow open-ended instructions to assist with inquiries about object
relationships in images.

摘要：視覺空間描述 (VSD) 旨在產生描述影像中物件之間空間關係的文字。傳統的視覺空間關係分類 (VSRC) 方法通常會輸出影像中兩個物件之間的空間關係，但通常會忽略世界知識，且缺乏一般的語言能力。在本文中，我們提出一個大型語言和視覺助理，用於視覺空間描述，稱為 LLaVA-VSD，它被設計用於分類、描述和視覺空間關係的開放式描述。具體來說，該模型首先使用給定的圖形標題對，為這三個任務建構一個 VSD 指令遵循資料集。然後，它採用 LoRA 微調一個大型語言和視覺助理，用於 VSD，它有 130 億個參數，並支援高解析度影像。最後，使用大型語言模型 (Qwen-2) 來改善產生的句子，增強它們的多樣性和準確性。LLaVA-VSD 展示了出色的多模式對話能力，並且可以遵循開放式指令，協助詢問影像中物件的關係。

##### **CROCODILE: Causality aids RObustness via COntrastive DIsentangled LEarning**
2408.04949v1 by Gianluca Carloni, Sotirios A Tsaftaris, Sara Colantonio

Due to domain shift, deep learning image classifiers perform poorly when
applied to a domain different from the training one. For instance, a classifier
trained on chest X-ray (CXR) images from one hospital may not generalize to
images from another hospital due to variations in scanner settings or patient
characteristics. In this paper, we introduce our CROCODILE framework, showing
how tools from causality can foster a model's robustness to domain shift via
feature disentanglement, contrastive learning losses, and the injection of
prior knowledge. This way, the model relies less on spurious correlations,
learns the mechanism bringing from images to prediction better, and outperforms
baselines on out-of-distribution (OOD) data. We apply our method to multi-label
lung disease classification from CXRs, utilizing over 750000 images from four
datasets. Our bias-mitigation method improves domain generalization and
fairness, broadening the applicability and reliability of deep learning models
for a safer medical image analysis. Find our code at:
https://github.com/gianlucarloni/crocodile.

摘要：由於領域轉換，深度學習圖像分類器在應用於與訓練不同的領域時表現不佳。例如，針對一家醫院的胸部 X 光（CXR）影像訓練的分類器，由於掃描儀設定或患者特徵的差異，可能無法概化到另一家醫院的影像。在本文中，我們介紹我們的 CROCODILE 框架，展示因果工具如何透過特徵解糾纏、對比學習損失和注入先驗知識來促進模型對領域轉換的穩健性。這樣一來，模型較不依賴虛假相關性，能更好地學習從影像到預測的機制，並在分佈外（OOD）資料上優於基線。我們將我們的模型應用於 CXR 的多標籤肺部疾病分類，利用來自四個資料集的超過 750,000 張影像。我們的偏差緩解方法改善了領域概化和公平性，擴大了深度學習模型在更安全醫學影像分析中的適用性和可靠性。在以下網址找到我們的程式碼：https://github.com/gianlucarloni/crocodile。

##### **HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction**
2408.04948v1 by Bhaskarjit Sarmah, Benika Hall, Rohan Rao, Sunil Patel, Stefano Pasquali, Dhagash Mehta

Extraction and interpretation of intricate information from unstructured text
data arising in financial applications, such as earnings call transcripts,
present substantial challenges to large language models (LLMs) even using the
current best practices to use Retrieval Augmented Generation (RAG) (referred to
as VectorRAG techniques which utilize vector databases for information
retrieval) due to challenges such as domain specific terminology and complex
formats of the documents. We introduce a novel approach based on a combination,
called HybridRAG, of the Knowledge Graphs (KGs) based RAG techniques (called
GraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for
information extraction from financial documents that is shown to be capable of
generating accurate and contextually relevant answers. Using experiments on a
set of financial earning call transcripts documents which come in the form of
Q&A format, and hence provide a natural set of pairs of ground-truth Q&As, we
show that HybridRAG which retrieves context from both vector database and KG
outperforms both traditional VectorRAG and GraphRAG individually when evaluated
at both the retrieval and generation stages in terms of retrieval accuracy and
answer generation. The proposed technique has applications beyond the financial
domain

摘要：從非結構化文本資料中擷取和詮釋複雜資訊，例如財務應用中產生的收益電話會議記錄，即使使用當前使用檢索擴充生成 (RAG) 的最佳實務（稱為 VectorRAG 技術，它使用向量資料庫來進行資訊檢索），由於領域特定術語和文件格式複雜等挑戰，對大型語言模型 (LLM) 而言仍構成重大挑戰。我們提出一個基於稱為 HybridRAG 的組合的新方法，其結合了基於知識圖譜 (KG) 的 RAG 技術（稱為 GraphRAG）和 VectorRAG 技術，以增強財務文件資訊擷取的問答 (Q&A) 系統，證明它能夠產生準確且與脈絡相關的答案。使用一組以問答格式呈現的財務收益電話會議記錄文件進行實驗，因此提供了自然的一組真實問答對，我們表明 HybridRAG 從向量資料庫和 KG 中擷取脈絡，在檢索和生成階段的檢索準確度和答案生成方面，都優於傳統的 VectorRAG 和 GraphRAG。所提出的技術具有超出財務領域的應用

##### **Quantitative Information Extraction from Humanitarian Documents**
2408.04941v1 by Daniele Liberatore, Kyriaki Kalimeri, Derya Sever, Yelena Mejova

Humanitarian action is accompanied by a mass of reports, summaries, news, and
other documents. To guide its activities, important information must be quickly
extracted from such free-text resources. Quantities, such as the number of
people affected, amount of aid distributed, or the extent of infrastructure
damage, are central to emergency response and anticipatory action. In this
work, we contribute an annotated dataset for the humanitarian domain for the
extraction of such quantitative information, along side its important context,
including units it refers to, any modifiers, and the relevant event. Further,
we develop a custom Natural Language Processing pipeline to extract the
quantities alongside their units, and evaluate it in comparison to baseline and
recent literature. The proposed model achieves a consistent improvement in the
performance, especially in the documents pertaining to the Dominican Republic
and select African countries. We make the dataset and code available to the
research community to continue the improvement of NLP tools for the
humanitarian domain.

摘要：人道主義行動伴隨著大量的報告、摘要、新聞和其他文件。為了指導其活動，必須從此類自由文本資源中快速提取重要資訊。數量，例如受影響的人數、分配的援助金額或基礎設施損壞程度，對於緊急應變和預期行動至關重要。在這項工作中，我們為人道主義領域貢獻了一個註解資料集，用於提取此類量化資訊，以及其重要的背景，包括其所指的單位、任何修飾符和相關事件。此外，我們開發了一個自訂的自然語言處理管道，用於提取數量及其單位，並將其與基線和近期文獻進行比較評估。所提出的模型在效能方面取得了一致的進步，特別是在與多明尼加共和國和部分非洲國家相關的文件中。我們將資料集和程式碼提供給研究社群，以持續改善人道主義領域的 NLP 工具。

##### **UAV-Enhanced Combination to Application: Comprehensive Analysis and Benchmarking of a Human Detection Dataset for Disaster Scenarios**
2408.04922v1 by Ragib Amin Nihal, Benjamin Yen, Katsutoshi Itoyama, Kazuhiro Nakadai

Unmanned aerial vehicles (UAVs) have revolutionized search and rescue (SAR)
operations, but the lack of specialized human detection datasets for training
machine learning models poses a significant challenge.To address this gap, this
paper introduces the Combination to Application (C2A) dataset, synthesized by
overlaying human poses onto UAV-captured disaster scenes. Through extensive
experimentation with state-of-the-art detection models, we demonstrate that
models fine-tuned on the C2A dataset exhibit substantial performance
improvements compared to those pre-trained on generic aerial datasets.
Furthermore, we highlight the importance of combining the C2A dataset with
general human datasets to achieve optimal performance and generalization across
various scenarios. This points out the crucial need for a tailored dataset to
enhance the effectiveness of SAR operations. Our contributions also include
developing dataset creation pipeline and integrating diverse human poses and
disaster scenes information to assess the severity of disaster scenarios. Our
findings advocate for future developments, to ensure that SAR operations
benefit from the most realistic and effective AI-assisted interventions
possible.

摘要：無人機（UAV）徹底改變了搜救（SAR）行動，但缺乏用於訓練機器學習模型的專業人類偵測資料集，這是一個重大的挑戰。為了解決這個差距，本文介紹了組合應用（C2A）資料集，它是透過將人類姿勢疊加到無人機拍攝的災難現場上而合成的。透過對最先進的偵測模型進行廣泛的實驗，我們證明了在 C2A 資料集上微調的模型，與在一般航拍資料集上預先訓練的模型相比，表現出顯著的效能提升。此外，我們強調將 C2A 資料集與一般人類資料集結合起來，對於在各種情境中達到最佳效能和概括化的重要性。這指出了針對性資料集對於提升 SAR 行動效能至關重要的需求。我們的貢獻還包括開發資料集建立管道，並整合多樣化的人類姿勢和災難現場資訊，以評估災難情境的嚴重性。我們的研究結果支持未來的發展，以確保 SAR 行動能從最逼真且有效的 AI 輔助介入中受益。

##### **Avoid Wasted Annotation Costs in Open-set Active Learning with Pre-trained Vision-Language Model**
2408.04917v1 by Jaehyuk Heo, Pilsung Kang

Active learning (AL) aims to enhance model performance by selectively
collecting highly informative data, thereby minimizing annotation costs.
However, in practical scenarios, unlabeled data may contain out-of-distribution
(OOD) samples, leading to wasted annotation costs if data is incorrectly
selected. Recent research has explored methods to apply AL to open-set data,
but these methods often require or incur unavoidable cost losses to minimize
them. To address these challenges, we propose a novel selection strategy, CLIPN
for AL (CLIPNAL), which minimizes cost losses without requiring OOD samples.
CLIPNAL sequentially evaluates the purity and informativeness of data. First,
it utilizes a pre-trained vision-language model to detect and exclude OOD data
by leveraging linguistic and visual information of in-distribution (ID) data
without additional training. Second, it selects highly informative data from
the remaining ID data, and then the selected samples are annotated by human
experts. Experimental results on datasets with various open-set conditions
demonstrate that CLIPNAL achieves the lowest cost loss and highest performance
across all scenarios. Code is available at https://github.com/DSBA-Lab/OpenAL.

摘要：主動學習 (AL) 旨在透過有選擇性地收集高度資訊性的資料來增強模型效能，從而將註解成本降至最低。然而，在實際情況中，未標籤資料可能包含分布外 (OOD) 樣本，如果資料選擇錯誤，將導致註解成本浪費。最近的研究已探討將 AL 應用於開放式資料集的方法，但這些方法通常需要或會產生無法避免的成本損失才能將其降至最低。為了應對這些挑戰，我們提出了一種新的選擇策略，即 AL 用的 CLIPN (CLIPNAL)，它可以在不需要 OOD 樣本的情況下將成本損失降至最低。CLIPNAL 會依序評估資料的純淨度和資訊性。首先，它利用預先訓練好的視覺語言模型來偵測和排除 OOD 資料，方法是利用分佈內 (ID) 資料的語言和視覺資訊，而不需要額外的訓練。其次，它從剩下的 ID 資料中選擇高度資訊性的資料，然後由人類專家對所選樣本進行註解。在具有各種開放式資料集條件的資料集上進行的實驗結果表明，CLIPNAL 在所有情況下都能實現最低的成本損失和最高的效能。程式碼可在 https://github.com/DSBA-Lab/OpenAL 取得。

##### **Knowledge Base Embeddings: Semantics and Theoretical Properties**
2408.04913v1 by Camille Bourgaux, Ricardo Guimarães, Raoul Koudijs, Victor Lacerda, Ana Ozaki

Research on knowledge graph embeddings has recently evolved into knowledge
base embeddings, where the goal is not only to map facts into vector spaces but
also constrain the models so that they take into account the relevant
conceptual knowledge available. This paper examines recent methods that have
been proposed to embed knowledge bases in description logic into vector spaces
through the lens of their geometric-based semantics. We identify several
relevant theoretical properties, which we draw from the literature and
sometimes generalize or unify. We then investigate how concrete embedding
methods fit in this theoretical framework.

摘要：知識圖譜嵌入的研究最近演變成知識庫嵌入，其目標不僅是將事實對應到向量空間，還要約束模型，以便它們考慮可用的相關概念知識。本文探討了近期提出的將描述邏輯中的知識庫嵌入到向量空間的方法，並通過其基於幾何的語義來審視這些方法。我們找出幾個相關的理論屬性，這些屬性來自文獻，有時會進行概括或統一。然後，我們研究具體的嵌入方法如何融入這個理論架構。

##### **Unleashing Artificial Cognition: Integrating Multiple AI Systems**
2408.04910v2 by Muntasir Adnan, Buddhi Gamage, Zhiwei Xu, Damith Herath, Carlos C. N. Kuhn

In this study, we present an innovative fusion of language models and query
analysis techniques to unlock cognition in artificial intelligence. Our system
seamlessly integrates a Chess engine with a language model, enabling it to
predict moves and provide strategic explanations. Leveraging a vector database
through retrievable answer generation, our OpenSI AI system elucidates its
decision-making process, bridging the gap between raw computation and
human-like understanding. Our choice of Chess as the demonstration environment
underscores the versatility of our approach. Beyond Chess, our system holds
promise for diverse applications, from medical diagnostics to financial
forecasting.

摘要：在這項研究中，我們提出語言模型和查詢分析技術的創新融合，以解鎖人工智慧中的認知。我們的系統將西洋棋引擎與語言模型無縫整合，使其能夠預測棋步並提供策略性說明。透過可檢索答案生成的向量資料庫，我們的 OpenSI AI 系統闡明其決策過程，彌合了原始運算與類人理解之間的差距。我們選擇西洋棋作為示範環境，突顯了我們方法的多樣性。除了西洋棋之外，我們的系統有望應用於各種領域，從醫療診斷到財務預測。

##### **Surveying the Landscape of Image Captioning Evaluation: A Comprehensive Taxonomy and Novel Ensemble Method**
2408.04909v1 by Uri Berger, Gabriel Stanovsky, Omri Abend, Lea Frermann

The task of image captioning has recently been gaining popularity, and with
it the complex task of evaluating the quality of image captioning models. In
this work, we present the first survey and taxonomy of over 70 different image
captioning metrics and their usage in hundreds of papers. We find that despite
the diversity of proposed metrics, the vast majority of studies rely on only
five popular metrics, which we show to be weakly correlated with human
judgements. Instead, we propose EnsembEval -- an ensemble of evaluation methods
achieving the highest reported correlation with human judgements across 5 image
captioning datasets, showing there is a lot of room for improvement by
leveraging a diverse set of metrics.

摘要：影像標題生成任務最近獲得廣泛關注，而評估影像標題生成模型品質的複雜任務也隨之而來。在本文中，我們提供首次調查和分類，涵蓋超過 70 種不同的影像標題生成指標，以及它們在數百篇論文中的使用方式。我們發現，儘管提出了多樣化的指標，但絕大多數研究僅依賴五種熱門指標，而我們證明這些指標與人為判斷相關性較弱。相反地，我們提出 EnsembEval，這是一種評估方法的集合，在 5 個影像標題生成資料集上與人為判斷達到最高相關性，顯示透過利用多樣化的指標集合，有很大的改進空間。

##### **Towards a Generative Approach for Emotion Detection and Reasoning**
2408.04906v1 by Ankita Bhaumik, Tomek Strzalkowski

Large language models (LLMs) have demonstrated impressive performance in
mathematical and commonsense reasoning tasks using chain-of-thought (CoT)
prompting techniques. But can they perform emotional reasoning by concatenating
`Let's think step-by-step' to the input prompt? In this paper we investigate
this question along with introducing a novel approach to zero-shot emotion
detection and emotional reasoning using LLMs. Existing state of the art
zero-shot approaches rely on textual entailment models to choose the most
appropriate emotion label for an input text. We argue that this strongly
restricts the model to a fixed set of labels which may not be suitable or
sufficient for many applications where emotion analysis is required. Instead,
we propose framing the problem of emotion analysis as a generative
question-answering (QA) task. Our approach uses a two step methodology of
generating relevant context or background knowledge to answer the emotion
detection question step-by-step. Our paper is the first work on using a
generative approach to jointly address the tasks of emotion detection and
emotional reasoning for texts. We evaluate our approach on two popular emotion
detection datasets and also release the fine-grained emotion labels and
explanations for further training and fine-tuning of emotional reasoning
systems.

摘要：大型語言模型 (LLM) 在使用思想鏈 (CoT) 提示技術的數學和常識推理任務中表現出令人印象深刻的效能。但它們是否能透過將「讓我們逐步思考」串接至輸入提示來執行情緒推理？在本文中，我們將探討這個問題，同時介紹一種使用 LLM 進行零次學習情緒偵測和情緒推理的新穎方法。現有的最先進零次學習方法依賴於文字蘊含模型來為輸入文字選擇最合適的情緒標籤。我們認為這會將模型嚴格限制在可能不適合或不足以用於需要情緒分析的許多應用程式的固定標籤組中。取而代之的是，我們建議將情緒分析問題設定為生成式問答 (QA) 任務。我們的做法使用兩步驟方法來產生相關脈絡或背景知識，以逐步回答情緒偵測問題。我們的論文是第一個使用生成式方法來共同處理文字情緒偵測和情緒推理任務的作品。我們在兩個流行的情緒偵測資料集上評估了我們的做法，並釋出了細粒度情緒標籤和說明，以進一步訓練和微調情緒推理系統。

##### **GlitchProber: Advancing Effective Detection and Mitigation of Glitch Tokens in Large Language Models**
2408.04905v1 by Zhibo Zhang, Wuxia Bai, Yuxi Li, Mark Huasong Meng, Kailong Wang, Ling Shi, Li Li, Jun Wang, Haoyu Wang

Large language models (LLMs) have achieved unprecedented success in the field
of natural language processing. However, the black-box nature of their internal
mechanisms has brought many concerns about their trustworthiness and
interpretability. Recent research has discovered a class of abnormal tokens in
the model's vocabulary space and named them "glitch tokens". Those tokens, once
included in the input, may induce the model to produce incorrect, irrelevant,
or even harmful results, drastically undermining the reliability and
practicality of LLMs.
  In this work, we aim to enhance the understanding of glitch tokens and
propose techniques for their detection and mitigation. We first reveal the
characteristic features induced by glitch tokens on LLMs, which are evidenced
by significant deviations in the distributions of attention patterns and
dynamic information from intermediate model layers. Based on the insights, we
develop GlitchProber, a tool for efficient glitch token detection and
mitigation. GlitchProber utilizes small-scale sampling, principal component
analysis for accelerated feature extraction, and a simple classifier for
efficient vocabulary screening. Taking one step further, GlitchProber rectifies
abnormal model intermediate layer values to mitigate the destructive effects of
glitch tokens. Evaluated on five mainstream open-source LLMs, GlitchProber
demonstrates higher efficiency, precision, and recall compared to existing
approaches, with an average F1 score of 0.86 and an average repair rate of
50.06%. GlitchProber unveils a novel path to address the challenges posed by
glitch tokens and inspires future research toward more robust and interpretable
LLMs.

摘要：大型语言模型 (LLM) 在自然语言处理领域取得了前所未有的成功。然而，其内部机制的黑盒性质引起了人们对其可信度和可解释性的诸多担忧。最近的研究发现模型词汇空间中存在一类异常标记，并将其命名为“故障标记”。这些标记一旦包含在输入中，可能会诱使模型产生不正确、不相关甚至有害的结果，从而极大地损害 LLM 的可靠性和实用性。
在这项工作中，我们旨在增强对故障标记的理解，并提出用于检测和缓解它们的技巧。我们首先揭示了故障标记在 LLM 上诱发的特征，这在注意力模式的分布和来自中间模型层的动态信息的显著偏差中得到了证明。基于这些见解，我们开发了 GlitchProber，这是一种用于高效故障标记检测和缓解的工具。GlitchProber 利用小规模采样、主成分分析进行加速特征提取，以及一个简单的分类器进行高效词汇筛选。更进一步，GlitchProber 纠正了异常模型中间层值，以减轻故障标记的破坏性影响。在五个主流开源 LLM 上进行评估，与现有方法相比，GlitchProber 表现出更高的效率、准确性和召回率，平均 F1 得分为 0.86，平均修复率为 50.06%。GlitchProber 为解决故障标记带来的挑战开辟了一条新途径，并激发了未来研究朝着更强大、更可解释的 LLM 发展。

##### **Communicate to Play: Pragmatic Reasoning for Efficient Cross-Cultural Communication in Codenames**
2408.04900v1 by Isadora White, Sashrika Pandey, Michelle Pan

Cultural differences in common ground may result in pragmatic failure and
misunderstandings during communication. We develop our method Rational Speech
Acts for Cross-Cultural Communication (RSA+C3) to resolve cross-cultural
differences in common ground. To measure the success of our method, we study
RSA+C3 in the collaborative referential game of Codenames Duet and show that
our method successfully improves collaboration between simulated players of
different cultures. Our contributions are threefold: (1) creating Codenames
players using contrastive learning of an embedding space and LLM prompting that
are aligned with human patterns of play, (2) studying culturally induced
differences in common ground reflected in our trained models, and (3)
demonstrating that our method RSA+C3 can ease cross-cultural communication in
gameplay by inferring sociocultural context from interaction. Our code is
publicly available at github.com/icwhite/codenames.

摘要：文化中的共同點差異可能會導致溝通中的實用性失敗和誤解。我們開發出一個名為「跨文化溝通的理性言語行為」（RSA+C3）的方法，以解決跨文化中共同點的差異。為了衡量我們方法的成功，我們在 Codenames Duet 的協作參考遊戲中研究 RSA+C3，並表明我們的這個方法成功改善了不同文化模擬玩家之間的協作。我們的貢獻有三方面：(1) 使用嵌入空間的對比學習和與人類遊戲模式一致的 LLM 提示來創造 Codenames 玩家，(2) 研究我們訓練出來的模型中反映出的文化誘發的共同點差異，以及 (3) 證明我們的 RSA+C3 方法可以透過從互動中推論社會文化背景，來緩解遊戲中的跨文化溝通。我們的程式碼可在 github.com/icwhite/codenames 公開取得。

##### **Unsupervised Episode Detection for Large-Scale News Events**
2408.04873v1 by Priyanka Kargupta, Yunyi Zhang, Yizhu Jiao, Siru Ouyang, Jiawei Han

Episodic structures are inherently interpretable and adaptable to evolving
large-scale key events. However, state-of-the-art automatic event detection
methods overlook event episodes and, therefore, struggle with these crucial
characteristics. This paper introduces a novel task, episode detection, aimed
at identifying episodes from a news corpus containing key event articles. An
episode describes a cohesive cluster of core entities (e.g., "protesters",
"police") performing actions at a specific time and location. Furthermore, an
episode is a significant part of a larger group of episodes under a particular
key event. Automatically detecting episodes is challenging because, unlike key
events and atomic actions, we cannot rely on explicit mentions of times and
locations to distinguish between episodes or use semantic similarity to merge
inconsistent episode co-references. To address these challenges, we introduce
EpiMine, an unsupervised episode detection framework that (1) automatically
identifies the most salient, key-event-relevant terms and segments, (2)
determines candidate episodes in an article based on natural episodic
partitions estimated through shifts in discriminative term combinations, and
(3) refines and forms final episode clusters using large language model-based
reasoning on the candidate episodes. We construct three diverse, real-world
event datasets annotated at the episode level. EpiMine outperforms all
baselines on these datasets by an average 59.2% increase across all metrics.

摘要：情節結構本質上可解讀且可適應不斷演化的、大規模關鍵事件。然而，最先進的自動事件偵測方法忽略了事件情節，因此難以處理這些關鍵特徵。本文介紹了一項新任務，情節偵測，旨在從包含關鍵事件文章的新聞語料庫中識別情節。一個情節描述了一群核心實體（例如「抗議者」、「警察」）在特定時間和地點執行的動作的內聚群集。此外，一個情節是一個特定關鍵事件下更大群組情節中的重要部分。自動偵測情節具有挑戰性，因為與關鍵事件和原子動作不同，我們無法依賴時間和地點的明確提及來區分情節，或使用語義相似性來合併不一致的情節共指。為了應對這些挑戰，我們引入了 EpiMine，一個無監督的情節偵測架構，它（1）自動識別最顯著、與關鍵事件相關的術語和區段，（2）根據透過區分性術語組合的轉移估計的自然情節分割，在文章中確定候選情節，以及（3）使用基於大型語言模型的推理，對候選情節進行優化並形成最終的情節群集。我們建構了三個多樣化、真實世界的事件資料集，並在情節層級進行標註。EpiMine 在這些資料集上優於所有基準，所有指標的平均提升幅度為 59.2%。

##### **SCOI: Syntax-augmented Coverage-based In-context Example Selection for Machine Translation**
2408.04872v1 by Chenming Tang, Zhixiang Wang, Yunfang Wu

In-context learning (ICL) greatly improves the performance of large language
models (LLMs) on various down-stream tasks, where the improvement highly
depends on the quality of demonstrations. In this work, we introduce syntactic
knowledge to select better in-context examples for machine translation (MT). We
propose a new strategy, namely Syntax-augmented COverage-based In-context
example selection (SCOI), leveraging the deep syntactic structure beyond
conventional word matching. Specifically, we measure the set-level syntactic
coverage by computing the coverage of polynomial terms with the help of a
simplified tree-to-polynomial algorithm, and lexical coverage using word
overlap. Furthermore, we devise an alternate selection approach to combine both
coverage measures, taking advantage of syntactic and lexical information. We
conduct experiments with two multi-lingual LLMs on six translation directions.
Empirical results show that our proposed SCOI obtains the highest average COMET
score among all learning-free methods, indicating that combining syntactic and
lexical coverage successfully helps to select better in-context examples for
MT.

摘要：語境學習 (ICL) 大幅提升大型語言模型 (LLM) 在各種下游任務的效能，其中提升幅度高度仰賴示範的品質。在本研究中，我們引入句法知識，為機器翻譯 (MT) 選擇更好的語境範例。我們提出一個新策略，即語法增強覆蓋率基礎的語境範例選擇 (SCOI)，利用超越傳統字詞比對的深度句法結構。具體來說，我們透過簡化的樹到多項式演算法計算多項式項目的覆蓋率來衡量集合層級的句法覆蓋率，並使用字詞重疊來衡量字彙覆蓋率。此外，我們設計一種替代的選擇方式，結合這兩種覆蓋率測量，利用句法和字彙資訊。我們對兩個多語言 LLM 進行六個翻譯方向的實驗。實證結果顯示，我們提出的 SCOI 在所有無學習方法中獲得最高的平均 COMET 分數，這表示結合句法和字彙覆蓋率成功地幫助為 MT 選擇更好的語境範例。

##### **ConfusedPilot: Compromising Enterprise Information Integrity and Confidentiality with Copilot for Microsoft 365**
2408.04870v1 by Ayush RoyChowdhury, Mulong Luo, Prateek Sahu, Sarbartha Banerjee, Mohit Tiwari

Retrieval augmented generation (RAG) is a process where a large language
model (LLM) retrieves useful information from a database and then generates the
responses. It is becoming popular in enterprise settings for daily business
operations. For example, Copilot for Microsoft 365 has accumulated millions of
businesses. However, the security implications of adopting such RAG-based
systems are unclear.
  In this paper, we introduce ConfusedPilot, a class of security
vulnerabilities of RAG systems that confuse Copilot and cause integrity and
confidentiality violations in its responses. First, we investigate a
vulnerability that embeds malicious text in the modified prompt in RAG,
corrupting the responses generated by the LLM. Second, we demonstrate a
vulnerability that leaks secret data, which leverages the caching mechanism
during retrieval. Third, we investigate how both vulnerabilities can be
exploited to propagate misinformation within the enterprise and ultimately
impact its operations, such as sales and manufacturing. We also discuss the
root cause of these attacks by investigating the architecture of a RAG-based
system. This study highlights the security vulnerabilities in today's RAG-based
systems and proposes design guidelines to secure future RAG-based systems.

摘要：檢索擴充生成 (RAG) 是一個大型語言模型 (LLM) 從資料庫中擷取有用資訊，然後生成回應的程序。它在企業環境中正變得普及，可應用於日常業務營運。例如，Microsoft 365 的 Copilot 已累積數百萬筆業務。然而，採用此類基於 RAG 的系統的安全性影響尚不清楚。
在本文中，我們介紹 ConfusedPilot，一種會混淆 Copilot，並導致其回應中出現完整性和機密性漏洞的 RAG 系統安全性漏洞類別。首先，我們研究一種將惡意文字嵌入 RAG 中修改提示的漏洞，破壞 LLM 生成的回應。其次，我們展示一個會洩漏機密資料的漏洞，它利用擷取期間的快取機制。第三，我們研究如何利用這兩個漏洞在企業內部傳播錯誤資訊，並最終影響其營運，例如銷售和製造。我們也透過研究基於 RAG 的系統架構，討論這些攻擊的根本原因。本研究強調當今基於 RAG 的系統中的安全性漏洞，並提出設計準則以保護未來的基於 RAG 的系統。

##### **Ensemble BERT: A student social network text sentiment classification model based on ensemble learning and BERT architecture**
2408.04849v1 by Kai Jiang, Honghao Yang, Yuexian Wang, Qianru Chen, Yiming Luo

The mental health assessment of middle school students has always been one of
the focuses in the field of education. This paper introduces a new ensemble
learning network based on BERT, employing the concept of enhancing model
performance by integrating multiple classifiers. We trained a range of
BERT-based learners, which combined using the majority voting method. We
collect social network text data of middle school students through China's
Weibo and apply the method to the task of classifying emotional tendencies in
middle school students' social network texts. Experimental results suggest that
the ensemble learning network has a better performance than the base model and
the performance of the ensemble learning model, consisting of three
single-layer BERT models, is barely the same as a three-layer BERT model but
requires 11.58% more training time. Therefore, in terms of balancing prediction
effect and efficiency, the deeper BERT network should be preferred for
training. However, for interpretability, network ensembles can provide
acceptable solutions.

摘要：中學生心理健康評估一直是教育領域的關注重點之一。本文介紹了一個基於 BERT 的新集成學習網路，採用整合多個分類器的概念來提升模型效能。我們訓練了一系列基於 BERT 的學習器，並使用多數決投票法進行組合。我們透過中國微博收集中學生的社群網路文字資料，並將此方法應用於分類中學生社群網路文字的情緒傾向的任務中。實驗結果表明，集成學習網路的效能優於基礎模型，且由三個單層 BERT 模型組成的集成學習模型的效能與三層 BERT 模型幾乎相同，但訓練時間卻多了 11.58%。因此，在平衡預測效果和效率方面，應優先考慮較深的 BERT 網路進行訓練。然而，對於可解釋性而言，網路集成可以提供可接受的解決方案。

##### **Counterfactual Explanations with Probabilistic Guarantees on their Robustness to Model Change**
2408.04842v1 by Ignacy Stępka, Mateusz Lango, Jerzy Stefanowski

Counterfactual explanations (CFEs) guide users on how to adjust inputs to
machine learning models to achieve desired outputs. While existing research
primarily addresses static scenarios, real-world applications often involve
data or model changes, potentially invalidating previously generated CFEs and
rendering user-induced input changes ineffective. Current methods addressing
this issue often support only specific models or change types, require
extensive hyperparameter tuning, or fail to provide probabilistic guarantees on
CFE robustness to model changes. This paper proposes a novel approach for
generating CFEs that provides probabilistic guarantees for any model and change
type, while offering interpretable and easy-to-select hyperparameters. We
establish a theoretical framework for probabilistically defining robustness to
model change and demonstrate how our BetaRCE method directly stems from it.
BetaRCE is a post-hoc method applied alongside a chosen base CFE generation
method to enhance the quality of the explanation beyond robustness. It
facilitates a transition from the base explanation to a more robust one with
user-adjusted probability bounds. Through experimental comparisons with
baselines, we show that BetaRCE yields robust, most plausible, and closest to
baseline counterfactual explanations.

摘要：反事實解釋 (CFE) 指引使用者如何調整輸入，以使機器學習模型達成預期的輸出。儘管現有研究主要探討靜態情境，但現實世界的應用通常涉及資料或模型變更，可能會使先前產生的 CFE 失效，並使使用者引發的輸入變更無效。目前處理此問題的方法通常僅支援特定模型或變更類型，需要廣泛的超參數調整，或無法對 CFE 對模型變更的穩健性提供機率保證。本文提出了一種新穎的方法，用於產生 CFE，為任何模型和變更類型提供機率保證，同時提供可解釋且易於選擇的超參數。我們建立了一個理論架構，用於機率性地定義對模型變化的穩健性，並展示我們的 BetaRCE 方法如何直接源自於此。BetaRCE 是一種事後方法，與所選的基礎 CFE 產生方法一起應用，以增強解釋的品質，超越穩健性。它促進從基礎解釋到更穩健的解釋，並具有使用者調整的機率界限。透過與基線的實驗比較，我們表明 BetaRCE 產生穩健、最合理的反事實解釋，且最接近基線。

##### **Kolmogorov-Arnold Network for Online Reinforcement Learning**
2408.04841v1 by Victor Augusto Kich, Jair Augusto Bottega, Raul Steinmetz, Ricardo Bedin Grando, Ayano Yorozu, Akihisa Ohya

Kolmogorov-Arnold Networks (KANs) have shown potential as an alternative to
Multi-Layer Perceptrons (MLPs) in neural networks, providing universal function
approximation with fewer parameters and reduced memory usage. In this paper, we
explore the use of KANs as function approximators within the Proximal Policy
Optimization (PPO) algorithm. We evaluate this approach by comparing its
performance to the original MLP-based PPO using the DeepMind Control Proprio
Robotics benchmark. Our results indicate that the KAN-based reinforcement
learning algorithm can achieve comparable performance to its MLP-based
counterpart, often with fewer parameters. These findings suggest that KANs may
offer a more efficient option for reinforcement learning models.

摘要：Kolmogorov-Arnold 網路 (KANs) 已展現出作為神經網路中多層感知器 (MLP) 的替代方案的潛力，提供具有較少參數和減少記憶體使用量的通用函數逼近。在本文中，我們探討在近端策略最佳化 (PPO) 演算法中使用 KAN 作為函數逼近器。我們透過比較其效能與使用 DeepMind Control Proprio Robotics 基準的基於 MLP 的原始 PPO 來評估此方法。我們的結果表明，基於 KAN 的強化學習演算法可以達到與其基於 MLP 的對應演算法相當的效能，通常參數較少。這些發現表明，KAN 可能為強化學習模型提供更有效率的選項。

##### **mPLUG-Owl3: Towards Long Image-Sequence Understanding in Multi-Modal Large Language Models**
2408.04840v1 by Jiabo Ye, Haiyang Xu, Haowei Liu, Anwen Hu, Ming Yan, Qi Qian, Ji Zhang, Fei Huang, Jingren Zhou

Multi-modal Large Language Models (MLLMs) have demonstrated remarkable
capabilities in executing instructions for a variety of single-image tasks.
Despite this progress, significant challenges remain in modeling long image
sequences. In this work, we introduce the versatile multi-modal large language
model, mPLUG-Owl3, which enhances the capability for long image-sequence
understanding in scenarios that incorporate retrieved image-text knowledge,
interleaved image-text, and lengthy videos. Specifically, we propose novel
hyper attention blocks to efficiently integrate vision and language into a
common language-guided semantic space, thereby facilitating the processing of
extended multi-image scenarios. Extensive experimental results suggest that
mPLUG-Owl3 achieves state-of-the-art performance among models with a similar
size on single-image, multi-image, and video benchmarks. Moreover, we propose a
challenging long visual sequence evaluation named Distractor Resistance to
assess the ability of models to maintain focus amidst distractions. Finally,
with the proposed architecture, mPLUG-Owl3 demonstrates outstanding performance
on ultra-long visual sequence inputs. We hope that mPLUG-Owl3 can contribute to
the development of more efficient and powerful multimodal large language
models.

摘要：多模态大型语言模型 (MLLM) 已展示出执行各种单图像任务指令的非凡能力。尽管取得了这些进展，在对长图像序列进行建模方面仍然存在重大挑战。在这项工作中，我们介绍了多功能多模态大型语言模型 mPLUG-Owl3，它增强了在结合了检索到的图像文本知识、交错图像文本和冗长视频的情况下对长图像序列进行理解的能力。具体来说，我们提出了新颖的超注意力块，以将视觉和语言有效地整合到一个共同的语言引导语义空间中，从而促进了扩展多图像场景的处理。大量的实验结果表明，mPLUG-Owl3 在具有相似大小的模型中实现了单图像、多图像和视频基准的最新性能。此外，我们提出了一个具有挑战性的长视觉序列评估，名为干扰抵抗，以评估模型在干扰中保持专注的能力。最后，凭借所提出的架构，mPLUG-Owl3 在超长视觉序列输入上展示了出色的性能。我们希望 mPLUG-Owl3 能够为开发更高效、更强大的多模态大型语言模型做出贡献。

##### **Self-augmented Gaussian Splatting with Structure-aware Masks for Sparse-view 3D Reconstruction**
2408.04831v1 by Lingbei Meng, Bi'an Du, Wei Hu

Sparse-view 3D reconstruction stands as a formidable challenge in computer
vision, aiming to build complete three-dimensional models from a limited array
of viewing perspectives. This task confronts several difficulties: 1) the
limited number of input images that lack consistent information; 2) dependence
on the quality of input images; and 3) the substantial size of model
parameters. To address these challenges, we propose a self-augmented
coarse-to-fine Gaussian splatting paradigm, enhanced with a structure-aware
mask, for sparse-view 3D reconstruction. In particular, our method initially
employs a coarse Gaussian model to obtain a basic 3D representation from
sparse-view inputs. Subsequently, we develop a fine Gaussian network to enhance
consistent and detailed representation of the output with both 3D geometry
augmentation and perceptual view augmentation. During training, we design a
structure-aware masking strategy to further improve the model's robustness
against sparse inputs and noise.Experimental results on the MipNeRF360 and
OmniObject3D datasets demonstrate that the proposed method achieves
state-of-the-art performances for sparse input views in both perceptual quality
and efficiency.

摘要：稀疏視圖 3D 重建是電腦視覺中的一項艱鉅挑戰，目的是從有限的視角陣列中建立完整的立體模型。此任務面臨數項困難：1) 輸入影像數量有限，且缺乏一致性資訊；2) 依賴輸入影像的品質；3) 模型參數的龐大規模。為了應對這些挑戰，我們提出一個自增強的粗糙到精細高斯噴繪範例，並透過結構感知遮罩增強，進行稀疏視圖 3D 重建。特別是，我們的技術最初採用粗糙高斯模型，從稀疏視圖輸入中取得基本的 3D 呈現。隨後，我們開發一個精細高斯網路，透過 3D 幾何增強和感知視圖增強，來增強輸出的一致性和詳細呈現。在訓練期間，我們設計一個結構感知遮罩策略，進一步提升模型對稀疏輸入和雜訊的穩健性。在 MipNeRF360 和 OmniObject3D 資料集上的實驗結果證明，所提出的技術在稀疏輸入視圖中，無論在感知品質或效率上，都達到了最先進的效能。

##### **Performance Prediction of Hub-Based Swarms**
2408.04822v1 by Puneet Jain, Chaitanya Dwivedi, Vigynesh Bhatt, Nick Smith, Michael A Goodrich

A hub-based colony consists of multiple agents who share a common nest site
called the hub. Agents perform tasks away from the hub like foraging for food
or gathering information about future nest sites. Modeling hub-based colonies
is challenging because the size of the collective state space grows rapidly as
the number of agents grows. This paper presents a graph-based representation of
the colony that can be combined with graph-based encoders to create
low-dimensional representations of collective state that can scale to many
agents for a best-of-N colony problem. We demonstrate how the information in
the low-dimensional embedding can be used with two experiments. First, we show
how the information in the tensor can be used to cluster collective states by
the probability of choosing the best site for a very small problem. Second, we
show how structured collective trajectories emerge when a graph encoder is used
to learn the low-dimensional embedding, and these trajectories have information
that can be used to predict swarm performance.

摘要：以集線器為基礎的群落是由多個代理組成，這些代理共享一個稱為集線器的共同巢穴地點。代理執行遠離集線器的任務，例如覓食或收集有關未來巢穴地點的資訊。建模以集線器為基礎的群落具有挑戰性，因為隨著代理數量增加，集體狀態空間的大小會快速增加。本文提出群落的基於圖形的表示，該表示可以與基於圖形的編碼器結合，以建立集體狀態的低維表示，該表示可以擴展到最佳 N 群落問題的許多代理。我們展示如何將低維嵌入中的資訊用於兩個實驗。首先，我們展示如何將張量中的資訊用於根據選擇最佳地點的機率來對群體狀態進行分群，以解決非常小的問題。其次，我們展示在使用圖形編碼器學習低維嵌入時如何出現結構化的集體軌跡，這些軌跡具有可用于預測群體表現的資訊。

##### **Natural Language Outlines for Code: Literate Programming in the LLM Era**
2408.04820v1 by Kensen Shi, Deniz Altınbüken, Saswat Anand, Mihai Christodorescu, Katja Grünwedel, Alexa Koenings, Sai Naidu, Anurag Pathak, Marc Rasi, Fredde Ribeiro, Brandon Ruffin, Siddhant Sanyam, Maxim Tabachnyk, Sara Toth, Roy Tu, Tobias Welp, Pengcheng Yin, Manzil Zaheer, Satish Chandra, Charles Sutton

We propose using natural language outlines as a novel modality and
interaction surface for providing AI assistance to developers throughout the
software development process. An NL outline for a code function comprises
multiple statements written in concise prose, which partition the code and
summarize its main ideas in the style of literate programming. Crucially, we
find that modern LLMs can generate accurate and high-quality NL outlines in
practice. Moreover, NL outlines enable a bidirectional sync between code and
NL, allowing changes in one to be automatically reflected in the other. We
discuss many use cases for NL outlines: they can accelerate understanding and
navigation of code and diffs, simplify code maintenance, augment code search,
steer code generation, and more. We then propose and compare multiple LLM
prompting techniques for generating outlines and ask professional developers to
judge outline quality. Finally, we present two case studies applying NL
outlines toward code review and the difficult task of malware detection.

摘要：我們建議使用自然語言大綱作為一種新穎的方式和互動介面，在整個軟體開發過程中為開發人員提供 AI 協助。程式碼函式的 NL 大綱包含多個以簡潔散文撰寫的陳述，將程式碼分割並以程式設計文件風格總結其主要概念。至關重要的是，我們發現現代 LLM 在實務上可以產生準確且高品質的 NL 大綱。此外，NL 大綱可以在程式碼和 NL 之間實現雙向同步，讓其中一方的變更可以自動反映在另一方。我們討論了 NL 大綱的許多使用案例：它們可以加速理解和瀏覽程式碼和差異，簡化程式碼維護，擴充程式碼搜尋，引導程式碼產生，等等。然後，我們提出並比較多種 LLM 提示技術以產生大綱，並請專業開發人員判斷大綱品質。最後，我們提出兩個案例研究，將 NL 大綱應用於程式碼檢閱和惡意軟體偵測的困難任務。

##### **Performance Metric for Multiple Anomaly Score Distributions with Discrete Severity Levels**
2408.04817v1 by Wonjun Yi, Yong-Hwa Park, Wonho Jung

The rise of smart factories has heightened the demand for automated
maintenance, and normal-data-based anomaly detection has proved particularly
effective in environments where anomaly data are scarce. This method, which
does not require anomaly data during training, has prompted researchers to
focus not only on detecting anomalies but also on classifying severity levels
by using anomaly scores. However, the existing performance metrics, such as the
area under the receiver operating characteristic curve (AUROC), do not
effectively reflect the performance of models in classifying severity levels
based on anomaly scores. To address this limitation, we propose the weighted
sum of the area under the receiver operating characteristic curve (WS-AUROC),
which combines AUROC with a penalty for severity level differences. We
conducted various experiments using different penalty assignment methods:
uniform penalty regardless of severity level differences, penalty based on
severity level index differences, and penalty based on actual physical
quantities that cause anomalies. The latter method was the most sensitive.
Additionally, we propose an anomaly detector that achieves clear separation of
distributions and outperforms the ablation models on the WS-AUROC and AUROC
metrics.

摘要：智慧工廠的興起提高了對自動化維護的需求，而基於正常資料的異常偵測已證明在異常資料稀少的環境中特別有效。此方法在訓練期間不需要異常資料，已促使研究人員不僅專注於偵測異常，還專注於透過異常分數對嚴重性等級進行分類。然而，現有的效能指標，例如受試者操作特徵曲線下面積 (AUROC)，無法有效反映模型在基於異常分數對嚴重性等級進行分類時的效能。為了解決此限制，我們提出加權受試者操作特徵曲線下面積 (WS-AUROC)，它結合 AUROC 與嚴重性等級差異的懲罰。我們使用不同的懲罰分配方法進行了各種實驗：不論嚴重性等級差異的均勻懲罰、基於嚴重性等級指標差異的懲罰，以及基於導致異常的實際物理量的懲罰。後一種方法最靈敏。此外，我們提出一個異常偵測器，它能清楚區分分佈，且在 WS-AUROC 和 AUROC 指標上優於消融模型。

##### **FUSE-ing Language Models: Zero-Shot Adapter Discovery for Prompt Optimization Across Tokenizers**
2408.04816v1 by Joshua Nathaniel Williams, J. Zico Kolter

The widespread use of large language models has resulted in a multitude of
tokenizers and embedding spaces, making knowledge transfer in prompt discovery
tasks difficult. In this work, we propose FUSE (Flexible Unification of
Semantic Embeddings), an inexpensive approach to approximating an adapter layer
that maps from one model's textual embedding space to another, even across
different tokenizers. We introduce a third-order tensor-based representation of
a model's embedding space that aligns semantic embeddings that have been split
apart by different tokenizers, and use this representation to derive an
approximation of the gradient of one model's outputs with respect to another
model's embedding space. We show the efficacy of our approach via
multi-objective optimization over vision-language and causal language models
for image captioning and sentiment-based image captioning.

摘要：由於廣泛使用大型語言模型，產生了大量的 tokenizers 和嵌入空間，這使得在提示發現任務中進行知識轉移變得困難。在這項工作中，我們提出了 FUSE（語義嵌入的靈活統一），這是一種近似適配器層的低成本方法，該層將一個模型的文本嵌入空間映射到另一個模型的文本嵌入空間，即使跨不同的 tokenizers 也是如此。我們引入了基於三階張量的模型嵌入空間表示，該表示對齊了被不同 tokenizers 分開的語義嵌入，並使用此表示來推導一個模型的輸出相對於另一個模型的嵌入空間的梯度的近似值。我們通過對視覺語言和因果語言模型進行多目標優化來展示我們方法的有效性，以進行圖像標題和基於情緒的圖像標題。

##### **h4rm3l: A Dynamic Benchmark of Composable Jailbreak Attacks for LLM Safety Assessment**
2408.04811v1 by Moussa Koulako Bala Doumbouya, Ananjan Nandi, Gabriel Poesia, Davide Ghilardi, Anna Goldie, Federico Bianchi, Dan Jurafsky, Christopher D. Manning

The safety of Large Language Models (LLMs) remains a critical concern due to
a lack of adequate benchmarks for systematically evaluating their ability to
resist generating harmful content. Previous efforts towards automated red
teaming involve static or templated sets of illicit requests and adversarial
prompts which have limited utility given jailbreak attacks' evolving and
composable nature. We propose a novel dynamic benchmark of composable jailbreak
attacks to move beyond static datasets and taxonomies of attacks and harms. Our
approach consists of three components collectively called h4rm3l: (1) a
domain-specific language that formally expresses jailbreak attacks as
compositions of parameterized prompt transformation primitives, (2)
bandit-based few-shot program synthesis algorithms that generate novel attacks
optimized to penetrate the safety filters of a target black box LLM, and (3)
open-source automated red-teaming software employing the previous two
components. We use h4rm3l to generate a dataset of 2656 successful novel
jailbreak attacks targeting 6 state-of-the-art (SOTA) open-source and
proprietary LLMs. Several of our synthesized attacks are more effective than
previously reported ones, with Attack Success Rates exceeding 90% on SOTA
closed language models such as claude-3-haiku and GPT4-o. By generating
datasets of jailbreak attacks in a unified formal representation, h4rm3l
enables reproducible benchmarking and automated red-teaming, contributes to
understanding LLM safety limitations, and supports the development of robust
defenses in an increasingly LLM-integrated world.
  Warning: This paper and related research artifacts contain offensive and
potentially disturbing prompts and model-generated content.

摘要：大型語言模型 (LLM) 的安全性仍然是一個關鍵問題，因為缺乏適當的基準來系統性評估它們抵抗產生有害內容的能力。先前針對自動化紅隊測試的努力涉及靜態或範本化的非法請求和對抗性提示，由於越獄攻擊不斷演進且可組合的特性，因此其效用有限。我們提出了一個可組合越獄攻擊的新型動態基準，以超越靜態資料集和攻擊與危害分類。我們的做法包含三個組成部分，統稱為 h4rm3l：(1) 一種特定領域語言，正式表達越獄攻擊為參數化提示轉換原語的組合，(2) 基於 bandit 的少量程式合成演算法，產生新穎的攻擊，經過最佳化以穿透目標黑盒 LLM 的安全過濾器，以及 (3) 採用前兩個組件的開源自動化紅隊測試軟體。我們使用 h4rm3l 產生一個資料集，其中包含 2656 次成功的越獄攻擊，針對 6 個最先進 (SOTA) 的開源和專有 LLM。我們的幾次合成攻擊比先前報告的攻擊更有效，在 SOTA 封閉語言模型（例如 claude-3-haiku 和 GPT4-o）上的攻擊成功率超過 90%。透過以統一的形式表示產生越獄攻擊的資料集，h4rm3l 能夠進行可重製的基準測試和自動化紅隊測試，有助於了解 LLM 安全限制，並在 LLM 整合度越來越高的世界中支援穩健防禦的開發。警告：這篇論文和相關研究成果包含攻擊性和潛在令人不安的提示和模型產生的內容。

##### **UniBench: Visual Reasoning Requires Rethinking Vision-Language Beyond Scaling**
2408.04810v1 by Haider Al-Tahan, Quentin Garrido, Randall Balestriero, Diane Bouchacourt, Caner Hazirbas, Mark Ibrahim

Significant research efforts have been made to scale and improve
vision-language model (VLM) training approaches. Yet, with an ever-growing
number of benchmarks, researchers are tasked with the heavy burden of
implementing each protocol, bearing a non-trivial computational cost, and
making sense of how all these benchmarks translate into meaningful axes of
progress. To facilitate a systematic evaluation of VLM progress, we introduce
UniBench: a unified implementation of 50+ VLM benchmarks spanning a
comprehensive range of carefully categorized capabilities from object
recognition to spatial awareness, counting, and much more. We showcase the
utility of UniBench for measuring progress by evaluating nearly 60 publicly
available vision-language models, trained on scales of up to 12.8B samples. We
find that while scaling training data or model size can boost many
vision-language model capabilities, scaling offers little benefit for reasoning
or relations. Surprisingly, we also discover today's best VLMs struggle on
simple digit recognition and counting tasks, e.g. MNIST, which much simpler
networks can solve. Where scale falls short, we find that more precise
interventions, such as data quality or tailored-learning objectives offer more
promise. For practitioners, we also offer guidance on selecting a suitable VLM
for a given application. Finally, we release an easy-to-run UniBench code-base
with the full set of 50+ benchmarks and comparisons across 59 models as well as
a distilled, representative set of benchmarks that runs in 5 minutes on a
single GPU.

摘要：<paragraph>為了擴展和改善視覺語言模型 (VLM) 訓練方法，已經進行了大量的研究工作。然而，隨著基準測試數量不斷增加，研究人員面臨著執行每個協定的沉重負擔，承受著非同小可的計算成本，並且必須理解所有這些基準測試如何轉化為有意義的進展軸。為了促進對 VLM 進展進行系統性評估，我們引入了 UniBench：一個統一實作，涵蓋從物件辨識到空間感知、計數等等，超過 50 個經過仔細分類功能的 VLM 基準測試。我們展示了 UniBench 在評估進度方面的效用，方法是評估近 60 個公開的視覺語言模型，這些模型針對高達 12.8B 個樣本進行訓練。我們發現，雖然擴展訓練資料或模型大小可以提升許多視覺語言模型的功能，但擴展對於推理或關係幾乎沒有好處。令人驚訝的是，我們還發現當今最佳的 VLM 在簡單的數字辨識和計數任務（例如 MNIST）上表現不佳，而更簡單的網路可以解決這些問題。在規模不足的情況下，我們發現更精確的干預措施，例如資料品質或量身打造的學習目標，提供了更多希望。對於實務工作者，我們還提供了有關為特定應用程式選擇適當 VLM 的指南。最後，我們發布了一個易於執行 UniBench 程式碼庫，其中包含 50 多個基準測試和 59 個模型的完整比較，以及一個精簡的、具代表性的基準測試集，可以在單一 GPU 上執行 5 分鐘。</paragraph>

##### **Hybrid Student-Teacher Large Language Model Refinement for Cancer Toxicity Symptom Extraction**
2408.04775v1 by Reza Khanmohammadi, Ahmed I. Ghanem, Kyle Verdecchia, Ryan Hall, Mohamed Elshaikh, Benjamin Movsas, Hassan Bagher-Ebadian, Bing Luo, Indrin J. Chetty, Tuka Alhanai, Kundan Thind, Mohammad M. Ghassemi

Large Language Models (LLMs) offer significant potential for clinical symptom
extraction, but their deployment in healthcare settings is constrained by
privacy concerns, computational limitations, and operational costs. This study
investigates the optimization of compact LLMs for cancer toxicity symptom
extraction using a novel iterative refinement approach. We employ a
student-teacher architecture, utilizing Zephyr-7b-beta and Phi3-mini-128 as
student models and GPT-4o as the teacher, to dynamically select between prompt
refinement, Retrieval-Augmented Generation (RAG), and fine-tuning strategies.
Our experiments on 294 clinical notes covering 12 post-radiotherapy toxicity
symptoms demonstrate the effectiveness of this approach. The RAG method proved
most efficient, improving average accuracy scores from 0.32 to 0.73 for
Zephyr-7b-beta and from 0.40 to 0.87 for Phi3-mini-128 during refinement. In
the test set, both models showed an approximate 0.20 increase in accuracy
across symptoms. Notably, this improvement was achieved at a cost 45 times
lower than GPT-4o for Zephyr and 79 times lower for Phi-3. These results
highlight the potential of iterative refinement techniques in enhancing the
capabilities of compact LLMs for clinical applications, offering a balance
between performance, cost-effectiveness, and privacy preservation in healthcare
settings.

摘要：大型語言模型 (LLM) 在臨床症狀萃取中具有顯著的潛力，但其在醫療保健環境中的應用受到隱私問題、運算限制和營運成本的約束。本研究探討了使用創新的反覆優化方法，優化用於癌症毒性症狀萃取的緊湊型 LLM。我們採用學生-老師架構，利用 Zephyr-7b-beta 和 Phi3-mini-128 作為學生模型，並將 GPT-4o 作為老師，以動態選擇提示優化、檢索擴充生成 (RAG) 和微調策略。我們在涵蓋 12 種放射治療後毒性症狀的 294 份臨床筆記上進行的實驗證明了此方法的有效性。RAG 方法被證明最有效率，在優化過程中將 Zephyr-7b-beta 的平均準確度分數從 0.32 提高到 0.73，將 Phi3-mini-128 的平均準確度分數從 0.40 提高到 0.87。在測試集中，這兩個模型在所有症狀中都顯示出準確度大約增加了 0.20。值得注意的是，此改進是以比 Zephyr 低 45 倍的成本和比 Phi-3 低 79 倍的成本實現的。這些結果突顯了反覆優化技術在增強緊湊型 LLM 在臨床應用中的能力方面的潛力，在醫療保健環境中提供了效能、成本效益和隱私保護之間的平衡。

##### **Data-Driven Pixel Control: Challenges and Prospects**
2408.04767v1 by Saurabh Farkya, Zachary Alan Daniels, Aswin Raghavan, Gooitzen van der Wal, Michael Isnardi, Michael Piacentino, David Zhang

Recent advancements in sensors have led to high resolution and high data
throughput at the pixel level. Simultaneously, the adoption of increasingly
large (deep) neural networks (NNs) has lead to significant progress in computer
vision. Currently, visual intelligence comes at increasingly high computational
complexity, energy, and latency. We study a data-driven system that combines
dynamic sensing at the pixel level with computer vision analytics at the video
level and propose a feedback control loop to minimize data movement between the
sensor front-end and computational back-end without compromising detection and
tracking precision. Our contributions are threefold: (1) We introduce
anticipatory attention and show that it leads to high precision prediction with
sparse activation of pixels; (2) Leveraging the feedback control, we show that
the dimensionality of learned feature vectors can be significantly reduced with
increased sparsity; and (3) We emulate analog design choices (such as varying
RGB or Bayer pixel format and analog noise) and study their impact on the key
metrics of the data-driven system. Comparative analysis with traditional pixel
and deep learning models shows significant performance enhancements. Our system
achieves a 10X reduction in bandwidth and a 15-30X improvement in Energy-Delay
Product (EDP) when activating only 30% of pixels, with a minor reduction in
object detection and tracking precision. Based on analog emulation, our system
can achieve a throughput of 205 megapixels/sec (MP/s) with a power consumption
of only 110 mW per MP, i.e., a theoretical improvement of ~30X in EDP.

摘要：<paragraph>感測器近期的進展已導致高解析度和高資料量在畫素層級的傳輸。同時，採用越來越大的（深度）神經網路（NNs）已導致電腦視覺的顯著進展。目前，視覺智慧的運算複雜度、能源和延遲越來越高。我們研究了一個資料驅動系統，結合了畫素層級的動態感測和影片層級的電腦視覺分析，並提出一個回饋控制迴路，以最小化感測器前端和運算後端之間的資料移動，而不會損害偵測和追蹤的精確度。我們的貢獻有三方面：(1) 我們引入了預期注意力，並表明它會導致畫素稀疏激活的高精確度預測；(2) 透過利用回饋控制，我們表明學習特徵向量的維度可以透過增加稀疏性而顯著降低；(3) 我們模擬類比設計選項（例如變化的 RGB 或 Bayer 畫素格式和類比雜訊），並研究它們對資料驅動系統關鍵指標的影響。與傳統畫素和深度學習模型的比較分析顯示出顯著的效能提升。我們的系統在僅激活 30% 的畫素時，頻寬減少了 10 倍，能量延遲乘積 (EDP) 改善了 15-30 倍，而物體偵測和追蹤精確度僅略有下降。根據類比模擬，我們的系統可以達到 205 百萬畫素/秒 (MP/s) 的傳輸量，每個 MP 的功耗僅為 110 mW，即 EDP 理論上改善了約 30 倍。</paragraph>

##### **Embodied Uncertainty-Aware Object Segmentation**
2408.04760v1 by Xiaolin Fang, Leslie Pack Kaelbling, Tomás Lozano-Pérez

We introduce uncertainty-aware object instance segmentation (UncOS) and
demonstrate its usefulness for embodied interactive segmentation. To deal with
uncertainty in robot perception, we propose a method for generating a
hypothesis distribution of object segmentation. We obtain a set of
region-factored segmentation hypotheses together with confidence estimates by
making multiple queries of large pre-trained models. This process can produce
segmentation results that achieve state-of-the-art performance on unseen object
segmentation problems. The output can also serve as input to a belief-driven
process for selecting robot actions to perturb the scene to reduce ambiguity.
We demonstrate the effectiveness of this method in real-robot experiments.
Website: https://sites.google.com/view/embodied-uncertain-seg

摘要：我們介紹了不確定性感知物件實例分割 (UncOS)，並展示了其在體現交互式分割中的用途。為了處理機器人感知中的不確定性，我們提出了一種生成物件分割假設分佈的方法。我們通過對大型預訓練模型進行多次查詢，獲得了一組區域分解的分割假設以及置信度估計。這個過程可以產生分割結果，在未見過的物件分割問題上達到最先進的效能。輸出也可以作為基於信念的過程的輸入，用於選擇機器人動作以擾動場景以減少模糊性。我們在真實機器人實驗中展示了此方法的有效性。
網站：https://sites.google.com/view/embodied-uncertain-seg

##### **More Questions than Answers? Lessons from Integrating Explainable AI into a Cyber-AI Tool**
2408.04746v1 by Ashley Suh, Harry Li, Caitlin Kenney, Kenneth Alperin, Steven R. Gomez

We share observations and challenges from an ongoing effort to implement
Explainable AI (XAI) in a domain-specific workflow for cybersecurity analysts.
Specifically, we briefly describe a preliminary case study on the use of XAI
for source code classification, where accurate assessment and timeliness are
paramount. We find that the outputs of state-of-the-art saliency explanation
techniques (e.g., SHAP or LIME) are lost in translation when interpreted by
people with little AI expertise, despite these techniques being marketed for
non-technical users. Moreover, we find that popular XAI techniques offer fewer
insights for real-time human-AI workflows when they are post hoc and too
localized in their explanations. Instead, we observe that cyber analysts need
higher-level, easy-to-digest explanations that can offer as little disruption
as possible to their workflows. We outline unaddressed gaps in practical and
effective XAI, then touch on how emerging technologies like Large Language
Models (LLMs) could mitigate these existing obstacles.

摘要：我們分享一個正在進行的專案的觀察和挑戰，目標是在特定網域工作流程中實作可解釋人工智慧 (XAI)，讓網路安全分析師使用。
具體來說，我們簡要說明一個關於使用 XAI 進行原始碼分類的初步案例研究，其中準確評估和時效性至關重要。我們發現，儘管這些技術宣稱適用於非技術使用者，但當由具備少量人工智慧專業知識的人員詮釋時，最先進的顯著度解釋技術 (例如，SHAP 或 LIME) 的輸出會在翻譯過程中遺失。此外，我們發現，當熱門 XAI 技術是事後且在解釋中過於局部化時，它們提供的見解較少適用於即時的人工智慧工作流程。相反地，我們觀察到網路分析師需要更高級、易於消化的解釋，且這些解釋應盡可能少干擾其工作流程。我們概述了實用且有效的 XAI 中未解決的差距，然後探討大型語言模型 (LLM) 等新興技術如何緩解這些現有障礙。

##### **Survey: Transformer-based Models in Data Modality Conversion**
2408.04723v1 by Elyas Rashno, Amir Eskandari, Aman Anand, Farhana Zulkernine

Transformers have made significant strides across various artificial
intelligence domains, including natural language processing, computer vision,
and audio processing. This success has naturally garnered considerable interest
from both academic and industry researchers. Consequently, numerous Transformer
variants (often referred to as X-formers) have been developed for these fields.
However, a thorough and systematic review of these modality-specific
conversions remains lacking. Modality Conversion involves the transformation of
data from one form of representation to another, mimicking the way humans
integrate and interpret sensory information. This paper provides a
comprehensive review of transformer-based models applied to the primary
modalities of text, vision, and speech, discussing their architectures,
conversion methodologies, and applications. By synthesizing the literature on
modality conversion, this survey aims to underline the versatility and
scalability of transformers in advancing AI-driven content generation and
understanding.

摘要：Transformer 在各種人工智能領域取得重大進展，包括自然語言處理、電腦視覺和音訊處理。這項成功自然引起了學術界和產業研究人員的極大興趣。因此，針對這些領域開發了許多 Transformer 變體（通常稱為 X-former）。然而，這些特定於模式的轉換仍缺乏全面且系統性的回顧。模式轉換涉及將資料從一種表示形式轉換為另一種表示形式，模擬人類整合和詮釋感官資訊的方式。本文提供了基於 Transformer 的模型的全面回顧，應用於文字、視覺和語音的主要模式，討論其架構、轉換方法和應用。透過綜合模式轉換的文獻，本調查旨在強調 Transformer 在推動 AI 驅動的內容生成和理解方面的多功能性和可擴充性。

##### **DyGMamba: Efficiently Modeling Long-Term Temporal Dependency on Continuous-Time Dynamic Graphs with State Space Models**
2408.04713v1 by Zifeng Ding, Yifeng Li, Yuan He, Antonio Norelli, Jingcheng Wu, Volker Tresp, Yunpu Ma, Michael Bronstein

Learning useful representations for continuous-time dynamic graphs (CTDGs) is
challenging, due to the concurrent need to span long node interaction histories
and grasp nuanced temporal details. In particular, two problems emerge: (1)
Encoding longer histories requires more computational resources, making it
crucial for CTDG models to maintain low computational complexity to ensure
efficiency; (2) Meanwhile, more powerful models are needed to identify and
select the most critical temporal information within the extended context
provided by longer histories. To address these problems, we propose a CTDG
representation learning model named DyGMamba, originating from the popular
Mamba state space model (SSM). DyGMamba first leverages a node-level SSM to
encode the sequence of historical node interactions. Another time-level SSM is
then employed to exploit the temporal patterns hidden in the historical graph,
where its output is used to dynamically select the critical information from
the interaction history. We validate DyGMamba experimentally on the dynamic
link prediction task. The results show that our model achieves state-of-the-art
in most cases. DyGMamba also maintains high efficiency in terms of
computational resources, making it possible to capture long temporal
dependencies with a limited computation budget.

摘要：學習連續時間動態圖形 (CTDG) 的有用表示很具有挑戰性，因為同時需要跨越節點互動的長歷史記錄，並掌握細微的時間細節。特別是，出現了兩個問題：(1) 編碼更長的歷史需要更多的計算資源，這使得 CTDG 模型必須保持較低的計算複雜度以確保效率；(2) 與此同時，需要更強大的模型來識別和選擇更長的歷史記錄所提供的擴展脈絡中最關鍵的時間資訊。為了解決這些問題，我們提出了一個名為 DyGMamba 的 CTDG 表示學習模型，它源自流行的 Mamba 狀態空間模型 (SSM)。DyGMamba 首先利用節點級別的 SSM 來編碼歷史節點互動的序列。然後採用另一個時間級別的 SSM 來利用隱藏在歷史圖形中的時間模式，其輸出用於動態地從互動歷史中選擇關鍵資訊。我們在動態連結預測任務上對 DyGMamba 進行了實驗驗證。結果表明，在大多數情況下，我們的模型都達到了最先進的水平。DyGMamba 在計算資源方面也保持了很高的效率，這使得在有限的計算預算下捕捉到很長的暫時依賴關係成為可能。

##### **MulliVC: Multi-lingual Voice Conversion With Cycle Consistency**
2408.04708v1 by Jiawei Huang, Chen Zhang, Yi Ren, Ziyue Jiang, Zhenhui Ye, Jinglin Liu, Jinzheng He, Xiang Yin, Zhou Zhao

Voice conversion aims to modify the source speaker's voice to resemble the
target speaker while preserving the original speech content. Despite notable
advancements in voice conversion these days, multi-lingual voice conversion
(including both monolingual and cross-lingual scenarios) has yet to be
extensively studied. It faces two main challenges: 1) the considerable
variability in prosody and articulation habits across languages; and 2) the
rarity of paired multi-lingual datasets from the same speaker. In this paper,
we propose MulliVC, a novel voice conversion system that only converts timbre
and keeps original content and source language prosody without multi-lingual
paired data. Specifically, each training step of MulliVC contains three
substeps: In step one the model is trained with monolingual speech data; then,
steps two and three take inspiration from back translation, construct a
cyclical process to disentangle the timbre and other information (content,
prosody, and other language-related information) in the absence of
multi-lingual data from the same speaker. Both objective and subjective results
indicate that MulliVC significantly surpasses other methods in both monolingual
and cross-lingual contexts, demonstrating the system's efficacy and the
viability of the three-step approach with cycle consistency. Audio samples can
be found on our demo page (mullivc.github.io).

摘要：語音轉換旨在修改來源講者的聲音，以模擬目標講者，同時保留原始的語音內容。儘管現今語音轉換技術已有顯著進展，但多語言語音轉換（包括單一語言和跨語言場景）尚未被廣泛研究。它面臨兩項主要挑戰：1) 不同語言之間在音調和發音習慣上的顯著差異；2) 來自同一位講者的配對多語言資料集的稀少性。在本文中，我們提出了 MulliVC，這是一個新穎的語音轉換系統，它僅轉換音色，並在沒有多語言配對資料的情況下保留原始內容和來源語言的音調。具體來說，MulliVC 的每個訓練步驟包含三個子步驟：在步驟一中，模型使用單一語言語音資料進行訓練；接著，步驟二和步驟三從反向翻譯中汲取靈感，構建一個循環過程，以在沒有來自同一位講者的多語言資料的情況下解開音色和其他資訊（內容、音調和與語言相關的其他資訊）。客觀和主觀結果均表明，MulliVC 在單一語言和跨語言環境中都顯著優於其他方法，證明了該系統的功效以及三步驟方法與循環一致性的可行性。音訊範例可以在我們的展示頁面（mullivc.github.io）上找到。

##### **Arctic-TILT. Business Document Understanding at Sub-Billion Scale**
2408.04632v1 by Łukasz Borchmann, Michał Pietruszka, Wojciech Jaśkowski, Dawid Jurkiewicz, Piotr Halama, Paweł Józiak, Łukasz Garncarek, Paweł Liskowski, Karolina Szyndler, Andrzej Gretkowski, Julita Ołtusek, Gabriela Nowakowska, Artur Zawłocki, Łukasz Duhr, Paweł Dyda, Michał Turski

The vast portion of workloads employing LLMs involves answering questions
grounded on PDF or scan content. We introduce the Arctic-TILT achieving
accuracy on par with models 1000$\times$ its size on these use cases. It can be
fine-tuned and deployed on a single 24GB GPU, lowering operational costs while
processing Visually Rich Documents with up to 400k tokens. The model
establishes state-of-the-art results on seven diverse Document Understanding
benchmarks, as well as provides reliable confidence scores and quick inference,
which are essential for processing files in large-scale or time-sensitive
enterprise environments.

摘要：絕大多數使用大型語言模型的工作負載，都涉及回答基於 PDF 或掃描內容的問題。我們介紹了 Arctic-TILT，在這些用例上實現了與其大小 1000 倍的模型相當的準確度。它可以在單個 24GB GPU 上進行微調和部署，在處理多達 400k 個令牌的視覺豐富文件時降低運營成本。該模型在七個不同的文件理解基準上建立了最先進的結果，並提供了可靠的置信度分數和快速推理，這對於在大型或時間敏感的企業環境中處理文件至關重要。

##### **Puppet-Master: Scaling Interactive Video Generation as a Motion Prior for Part-Level Dynamics**
2408.04631v1 by Ruining Li, Chuanxia Zheng, Christian Rupprecht, Andrea Vedaldi

We present Puppet-Master, an interactive video generative model that can
serve as a motion prior for part-level dynamics. At test time, given a single
image and a sparse set of motion trajectories (i.e., drags), Puppet-Master can
synthesize a video depicting realistic part-level motion faithful to the given
drag interactions. This is achieved by fine-tuning a large-scale pre-trained
video diffusion model, for which we propose a new conditioning architecture to
inject the dragging control effectively. More importantly, we introduce the
all-to-first attention mechanism, a drop-in replacement for the widely adopted
spatial attention modules, which significantly improves generation quality by
addressing the appearance and background issues in existing models. Unlike
other motion-conditioned video generators that are trained on in-the-wild
videos and mostly move an entire object, Puppet-Master is learned from
Objaverse-Animation-HQ, a new dataset of curated part-level motion clips. We
propose a strategy to automatically filter out sub-optimal animations and
augment the synthetic renderings with meaningful motion trajectories.
Puppet-Master generalizes well to real images across various categories and
outperforms existing methods in a zero-shot manner on a real-world benchmark.
See our project page for more results: vgg-puppetmaster.github.io.

摘要：我們提出 Puppet-Master，一個互動式影片生成模型，可用作部分層級動態的動作先驗。在測試時，給定單一影像和一組稀疏的動作軌跡（即拖曳），Puppet-Master 可以合成影片，描繪出符合給定拖曳互動的逼真部分層級動作。這是透過微調大型預先訓練影片擴散模型來實現的，我們為此提出新的制約架構，以有效注入拖曳控制。更重要的是，我們引入全對一注意力機制，這是廣泛採用的空間注意力模組的替代方案，透過解決現有模型中的外觀和背景問題，顯著改善生成品質。與其他在野外影片上訓練且主要移動整個物體的動作條件影片生成器不同，Puppet-Master 是從 Objaverse-Animation-HQ（一種經過整理的部分層級動作片段的新資料集）學習的。我們提出策略，自動過濾掉次佳動畫，並使用有意義的動作軌跡擴充合成渲染。Puppet-Master 在各種類別的真實影像中都能很好地概括，並在真實世界的基準上以零次學習的方式優於現有方法。請參閱我們的專案頁面以取得更多結果：vgg-puppetmaster.github.io。

##### **LogogramNLP: Comparing Visual and Textual Representations of Ancient Logographic Writing Systems for NLP**
2408.04628v1 by Danlu Chen, Freda Shi, Aditi Agarwal, Jacobo Myerston, Taylor Berg-Kirkpatrick

Standard natural language processing (NLP) pipelines operate on symbolic
representations of language, which typically consist of sequences of discrete
tokens. However, creating an analogous representation for ancient logographic
writing systems is an extremely labor intensive process that requires expert
knowledge. At present, a large portion of logographic data persists in a purely
visual form due to the absence of transcription -- this issue poses a
bottleneck for researchers seeking to apply NLP toolkits to study ancient
logographic languages: most of the relevant data are images of writing.
  This paper investigates whether direct processing of visual representations
of language offers a potential solution. We introduce LogogramNLP, the first
benchmark enabling NLP analysis of ancient logographic languages, featuring
both transcribed and visual datasets for four writing systems along with
annotations for tasks like classification, translation, and parsing. Our
experiments compare systems that employ recent visual and text encoding
strategies as backbones. The results demonstrate that visual representations
outperform textual representations for some investigated tasks, suggesting that
visual processing pipelines may unlock a large amount of cultural heritage data
of logographic languages for NLP-based analyses.

摘要：標準自然語言處理 (NLP) 管線運作在語言的符號表示上，通常由離散記號序列組成。然而，為古代表意文字系統建立類比表示法是一個極度勞力的過程，需要專家知識。目前，由於缺乏轉錄，大部分表意資料仍以純粹視覺形式存在——這個問題對尋求使用 NLP 工具包研究古代表意文字的的研究人員構成瓶頸：大部分相關資料都是文字影像。
本文探討是否直接處理語言的視覺表示能提供潛在解決方案。我們介紹 LogogramNLP，這是第一個能對古代表意文字進行 NLP 分析的基準測試，提供四個文字系統的轉錄和視覺資料集，以及分類、翻譯和剖析等任務的註解。我們的實驗比較採用近期視覺和文字編碼策略作為主幹的系統。結果顯示，對於一些研究任務，視覺表示的表現優於文字表示，這表示視覺處理管線可能為 NLP 分析解鎖大量表意文字的文化遺產資料。

##### **Transformer Explainer: Interactive Learning of Text-Generative Models**
2408.04619v1 by Aeree Cho, Grace C. Kim, Alexander Karpekov, Alec Helbling, Zijie J. Wang, Seongmin Lee, Benjamin Hoover, Duen Horng Chau

Transformers have revolutionized machine learning, yet their inner workings
remain opaque to many. We present Transformer Explainer, an interactive
visualization tool designed for non-experts to learn about Transformers through
the GPT-2 model. Our tool helps users understand complex Transformer concepts
by integrating a model overview and enabling smooth transitions across
abstraction levels of mathematical operations and model structures. It runs a
live GPT-2 instance locally in the user's browser, empowering users to
experiment with their own input and observe in real-time how the internal
components and parameters of the Transformer work together to predict the next
tokens. Our tool requires no installation or special hardware, broadening the
public's education access to modern generative AI techniques. Our open-sourced
tool is available at https://poloclub.github.io/transformer-explainer/. A video
demo is available at https://youtu.be/ECR4oAwocjs.

摘要：Transformer 徹底改變了機器學習，但其內部運作對許多人來說仍然不透明。我們展示 Transformer Explainer，這是一個互動式視覺化工具，專為非專家設計，透過 GPT-2 模型來了解 Transformer。我們的工具透過整合模型概觀並在數學運算和模型結構的抽象層級之間實現平滑過渡，幫助使用者了解複雜的 Transformer 概念。它在使用者的瀏覽器中本地執行一個即時的 GPT-2 執行個體，使用戶能夠使用自己的輸入進行實驗，並即時觀察 Transformer 的內部組件和參數如何協同運作來預測下一個代幣。我們的工具不需要安裝或特殊硬體，擴大了大眾對現代生成式 AI 技術的教育管道。我們的開源工具可在 https://poloclub.github.io/transformer-explainer/ 取得。影片示範可在 https://youtu.be/ECR4oAwocjs 取得。

##### **Better Alignment with Instruction Back-and-Forth Translation**
2408.04614v1 by Thao Nguyen, Jeffrey Li, Sewoong Oh, Ludwig Schmidt, Jason Weston, Luke Zettlemoyer, Xian Li

We propose a new method, instruction back-and-forth translation, to construct
high-quality synthetic data grounded in world knowledge for aligning large
language models (LLMs). Given documents from a web corpus, we generate and
curate synthetic instructions using the backtranslation approach proposed by Li
et al.(2023a), and rewrite the responses to improve their quality further based
on the initial documents. Fine-tuning with the resulting (backtranslated
instruction, rewritten response) pairs yields higher win rates on AlpacaEval
than using other common instruction datasets such as Humpback, ShareGPT, Open
Orca, Alpaca-GPT4 and Self-instruct. We also demonstrate that rewriting the
responses with an LLM outperforms direct distillation, and the two generated
text distributions exhibit significant distinction in embedding space. Further
analysis shows that our backtranslated instructions are of higher quality than
other sources of synthetic instructions, while our responses are more diverse
and complex than those obtained from distillation. Overall we find that
instruction back-and-forth translation combines the best of both worlds --
making use of the information diversity and quantity found on the web, while
ensuring the quality of the responses which is necessary for effective
alignment.

摘要：我們提出了一種新的方法，即指令來回翻譯，用於構建
基於世界知識的高品質合成資料，以對齊大型
語言模型 (LLM)。給定來自網路語料庫的文件，我們生成並
使用 Li
et al.(2023a) 提出的回譯方法整理合成指令，並根據
原始文件進一步改寫回應以提升其品質。使用產生的（回譯
指令、改寫回應）配對進行微調，在 AlpacaEval 上產生的獲勝率
高於使用其他常見指令資料集，例如 Humpback、ShareGPT、Open
Orca、Alpaca-GPT4 和 Self-instruct。我們也證明了使用 LLM 改寫
回應的表現優於直接萃取，而且這兩個生成的
文字分佈在嵌入空間中展現出顯著的區別。進一步的分析顯示，我們的回譯
指令品質高於其他合成指令來源，而我們的回應則比從萃取中獲得的
回應更為多元且複雜。總體而言，我們發現指令來回翻譯結合了兩全其美的優點
——利用網路上的資訊多元性和數量，同時
確保回應的品質，這對於有效的對齊是必要的。

##### **Code-switching in text and speech reveals information-theoretic audience design**
2408.04596v1 by Debasmita Bhattacharya, Marten van Schijndel

In this work, we use language modeling to investigate the factors that
influence code-switching. Code-switching occurs when a speaker alternates
between one language variety (the primary language) and another (the secondary
language), and is widely observed in multilingual contexts. Recent work has
shown that code-switching is often correlated with areas of high information
load in the primary language, but it is unclear whether high primary language
load only makes the secondary language relatively easier to produce at
code-switching points (speaker-driven code-switching), or whether
code-switching is additionally used by speakers to signal the need for greater
attention on the part of listeners (audience-driven code-switching). In this
paper, we use bilingual Chinese-English online forum posts and transcripts of
spontaneous Chinese-English speech to replicate prior findings that high
primary language (Chinese) information load is correlated with switches to the
secondary language (English). We then demonstrate that the information load of
the English productions is even higher than that of meaning equivalent Chinese
alternatives, and these are therefore not easier to produce, providing evidence
of audience-driven influences in code-switching at the level of the
communication channel, not just at the sociolinguistic level, in both writing
and speech.

摘要：在這項工作中，我們使用語言模型來探討影響代碼轉換的因素。代碼轉換發生在說話者在一個語言變體（主要語言）和另一個（次要語言）之間交替時，並且在多語言環境中廣泛觀察到。最近的研究表明，代碼轉換通常與主要語言中資訊負載高的區域相關，但目前尚不清楚高主要語言負載是否僅使次要語言在代碼轉換點更容易產生（說話者驅動的代碼轉換），或是否代碼轉換進一步由說話者用於傳達聽眾需要更多注意的需要（受眾驅動的代碼轉換）。在本文中，我們使用雙語中英語線上論壇文章和自發中英語語音的轉錄，以複製先前的發現，即高主要語言（中文）資訊負載與轉換到次要語言（英語）相關。然後，我們證明英語產出的資訊負載甚至高於意義等價的中文選項，因此這些選項並不容易產生，提供了在代碼轉換中受眾驅動影響的證據，不僅在社會語言層面，也在寫作和語音中，在溝通管道層面。

##### **Img-Diff: Contrastive Data Synthesis for Multimodal Large Language Models**
2408.04594v2 by Qirui Jiao, Daoyuan Chen, Yilun Huang, Yaliang Li, Ying Shen

High-performance Multimodal Large Language Models (MLLMs) rely heavily on
data quality. This study introduces a novel dataset named Img-Diff, designed to
enhance fine-grained image recognition in MLLMs by leveraging insights from
contrastive learning and image difference captioning. By analyzing object
differences between similar images, we challenge models to identify both
matching and distinct components. We utilize the Stable-Diffusion-XL model and
advanced image editing techniques to create pairs of similar images that
highlight object replacements. Our methodology includes a Difference Area
Generator for object differences identifying, followed by a Difference Captions
Generator for detailed difference descriptions. The result is a relatively
small but high-quality dataset of "object replacement" samples. We use the the
proposed dataset to finetune state-of-the-art (SOTA) MLLMs such as MGM-7B,
yielding comprehensive improvements of performance scores over SOTA models that
trained with larger-scale datasets, in numerous image difference and Visual
Question Answering tasks. For instance, our trained models notably surpass the
SOTA models GPT-4V and Gemini on the MMVP benchmark. Besides, we investigate
alternative methods for generating image difference data through "object
removal" and conduct a thorough evaluation to confirm the dataset's diversity,
quality, and robustness, presenting several insights on the synthesis of such a
contrastive dataset. To encourage further research and advance the field of
multimodal data synthesis and enhancement of MLLMs' fundamental capabilities
for image understanding, we release our codes and dataset at
https://github.com/modelscope/data-juicer/tree/ImgDiff.

摘要：高性能多模态大型语言模型 (MLLM) 严重依赖数据质量。本研究引入了一个名为 Img-Diff 的新数据集，旨在通过利用对比学习和图像差异描述中的见解来增强 MLLM 中的细粒度图像识别。通过分析类似图像之间的对象差异，我们挑战模型识别匹配和不同的组件。我们利用 Stable-Diffusion-XL 模型和高级图像编辑技术来创建成对的相似图像，以突出对象替换。我们的方法包括一个用于识别对象差异的差异区域生成器，然后是一个用于详细差异描述的差异描述生成器。结果是一个相对较小但高质量的“对象替换”样本数据集。我们使用所提出的数据集对最先进 (SOTA) MLLM（例如 MGM-7B）进行微调，在众多图像差异和视觉问答任务中产生比使用更大规模数据集训练的 SOTA 模型更全面的性能得分改进。例如，我们训练的模型在 MMVP 基准上明显超过了 SOTA 模型 GPT-4V 和 Gemini。此外，我们研究了通过“对象移除”生成图像差异数据的替代方法，并进行了彻底的评估以确认数据集的多样性、质量和鲁棒性，并提出了对这种对比数据集合成的若干见解。为了鼓励进一步的研究和推进多模态数据合成和增强 MLLM 的图像理解基本能力的领域，我们在 https://github.com/modelscope/data-juicer/tree/ImgDiff 上发布了我们的代码和数据集。

##### **HiLo: A Learning Framework for Generalized Category Discovery Robust to Domain Shifts**
2408.04591v1 by Hongjun Wang, Sagar Vaze, Kai Han

Generalized Category Discovery (GCD) is a challenging task in which, given a
partially labelled dataset, models must categorize all unlabelled instances,
regardless of whether they come from labelled categories or from new ones. In
this paper, we challenge a remaining assumption in this task: that all images
share the same domain. Specifically, we introduce a new task and method to
handle GCD when the unlabelled data also contains images from different domains
to the labelled set. Our proposed `HiLo' networks extract High-level semantic
and Low-level domain features, before minimizing the mutual information between
the representations. Our intuition is that the clusterings based on domain
information and semantic information should be independent. We further extend
our method with a specialized domain augmentation tailored for the GCD task, as
well as a curriculum learning approach. Finally, we construct a benchmark from
corrupted fine-grained datasets as well as a large-scale evaluation on
DomainNet with real-world domain shifts, reimplementing a number of GCD
baselines in this setting. We demonstrate that HiLo outperforms SoTA category
discovery models by a large margin on all evaluations.

摘要：廣義類別發現 (GCD) 是一項具有挑戰性的任務，其中，在給定部分標籤資料集的情況下，模型必須對所有未標籤實例進行分類，無論它們來自標籤類別還是新類別。在本文中，我們挑戰了這項任務中的一個剩餘假設：所有圖像共享相同的網域。具體來說，我們引入了一個新任務和方法來處理 GCD，當未標籤資料也包含來自與標籤集不同網域的圖像時。我們提出的 `HiLo` 網路提取高級語義和低級網域特徵，然後最小化表示之間的互信息。我們的直覺是基於網域信息和語義信息的聚類應該是獨立的。我們進一步擴展了我們的方法，使用專門針對 GCD 任務量身定制的網域擴充，以及課程學習方法。最後，我們從損壞的細粒度資料集構建了一個基準，以及在具有真實世界網域轉移的 DomainNet 上進行大規模評估，在此設置中重新實現了許多 GCD 基線。我們證明 HiLo 在所有評估中都比 SoTA 類別發現模型表現出色。

##### **Towards Resilient and Efficient LLMs: A Comparative Study of Efficiency, Performance, and Adversarial Robustness**
2408.04585v2 by Xiaojing Fan, Chunliang Tao

With the increasing demand for practical applications of Large Language
Models (LLMs), many attention-efficient models have been developed to balance
performance and computational cost. However, the adversarial robustness of
these models remains under-explored. In this work, we design a framework to
investigate the trade-off between efficiency, performance, and adversarial
robustness of LLMs by comparing three prominent models with varying levels of
complexity and efficiency -- Transformer++, Gated Linear Attention (GLA)
Transformer, and MatMul-Free LM -- utilizing the GLUE and AdvGLUE datasets. The
AdvGLUE dataset extends the GLUE dataset with adversarial samples designed to
challenge model robustness. Our results show that while the GLA Transformer and
MatMul-Free LM achieve slightly lower accuracy on GLUE tasks, they demonstrate
higher efficiency and either superior or comparative robustness on AdvGLUE
tasks compared to Transformer++ across different attack levels. These findings
highlight the potential of simplified architectures to achieve a compelling
balance between efficiency, performance, and adversarial robustness, offering
valuable insights for applications where resource constraints and resilience to
adversarial attacks are critical.

摘要：随着大型语言模型（LLM）在实际应用中的需求不断增加，许多注重效率的模型已被开发出来，以平衡性能和计算成本。然而，这些模型的对抗鲁棒性仍未得到充分探索。在这项工作中，我们设计了一个框架，通过比较三个具有不同复杂性和效率水平的突出模型——Transformer++、门控线性注意力（GLA）Transformer 和无 MatMul LM——利用 GLUE 和 AdvGLUE 数据集，来研究 LLM 的效率、性能和对抗鲁棒性之间的权衡。AdvGLUE 数据集扩展了 GLUE 数据集，其中包含旨在挑战模型鲁棒性的对抗样本。我们的结果表明，虽然 GLA Transformer 和无 MatMul LM 在 GLUE 任务上的准确度略低，但它们展示了更高的效率，并且在不同攻击级别上与 Transformer++ 相比，在 AdvGLUE 任务上具有更高或相当的鲁棒性。这些发现突出了简化架构在实现效率、性能和对抗鲁棒性之间引人注目的平衡的潜力，为资源受限和对抗攻击弹性至关重要的应用提供了有价值的见解。

##### **SCENE: Evaluating Explainable AI Techniques Using Soft Counterfactuals**
2408.04575v1 by Haoran Zheng, Utku Pamuksuz

Explainable Artificial Intelligence (XAI) is essential for enhancing the
transparency and accountability of AI models, especially in natural language
processing (NLP) tasks. This paper introduces SCENE (Soft Counterfactual
Evaluation for Natural language Explainability), a novel evaluation method that
leverages large language models (LLMs) to generate Soft Counterfactual
explanations in a zero-shot manner. By focusing on token-based substitutions,
SCENE creates contextually appropriate and seman-tically meaningful Soft
Counterfactuals without extensive fine-tuning. SCENE adopts Validitysoft and
Csoft metrics to evaluate the effectiveness of model-agnostic XAI methods in
text classification tasks. Applied to CNN, RNN, and BERT architectures, SCENE
provides valuable insights into the strengths and limitations of various XAI
techniques.

摘要：可解釋人工智慧 (XAI) 對於提升人工智慧模型的透明度與可問責性至關重要，特別是在自然語言處理 (NLP) 任務中。本文介紹 SCENE（自然語言可解釋性的軟反事實評估），這是一種新穎的評估方法，利用大型語言模型 (LLM) 以零次學習的方式產生軟反事實解釋。SCENE 專注於基於代碼的替換，在不進行廣泛微調的情況下，建立符合脈絡且具有語義意義的軟反事實。SCENE 採用 Validitysoft 和 Csoft 指標來評估模型不可知 XAI 方法在文字分類任務中的有效性。SCENE 應用於 CNN、RNN 和 BERT 架構，提供了寶貴的見解，了解各種 XAI 技術的優點和限制。

##### **Learning Fine-Grained Grounded Citations for Attributed Large Language Models**
2408.04568v1 by Lei Huang, Xiaocheng Feng, Weitao Ma, Yuxuan Gu, Weihong Zhong, Xiachong Feng, Weijiang Yu, Weihua Peng, Duyu Tang, Dandan Tu, Bing Qin

Despite the impressive performance on information-seeking tasks, large
language models (LLMs) still struggle with hallucinations. Attributed LLMs,
which augment generated text with in-line citations, have shown potential in
mitigating hallucinations and improving verifiability. However, current
approaches suffer from suboptimal citation quality due to their reliance on
in-context learning. Furthermore, the practice of citing only coarse document
identifiers makes it challenging for users to perform fine-grained
verification. In this work, we introduce FRONT, a training framework designed
to teach LLMs to generate Fine-Grained Grounded Citations. By grounding model
outputs in fine-grained supporting quotes, these quotes guide the generation of
grounded and consistent responses, not only improving citation quality but also
facilitating fine-grained verification. Experiments on the ALCE benchmark
demonstrate the efficacy of FRONT in generating superior grounded responses and
highly supportive citations. With LLaMA-2-7B, the framework significantly
outperforms all the baselines, achieving an average of 14.21% improvement in
citation quality across all datasets, even surpassing ChatGPT.

摘要：儘管在資訊搜尋任務中表現出色，大型語言模型 (LLM) 仍難以克服幻覺問題。具歸因功能的 LLM 可在產生的文字中加入內文引文，已展現出減輕幻覺並提升可驗證性的潛力。然而，現行的做法仰賴於情境學習，因此引文品質不佳。此外，僅引述粗略的文件識別碼，使用戶難以進行細微的驗證。在本文中，我們介紹 FRONT，一種訓練架構，旨在教導 LLM 產生細微的 обосно引文。透過將模型輸出建立在細微的支援引文中，這些引文可引導產生 обосно且一致的回應，不僅提升引文品質，還能促進細微的驗證。在 ALCE 基準上的實驗證明了 FRONT 在產生優異的 обосно回應和高度支持性引文方面的效能。透過 LLaMA-2-7B，此架構大幅優於所有基線，在所有資料集中的引文品質平均提升 14.21%，甚至超越了 ChatGPT。

##### **Understanding the Performance and Estimating the Cost of LLM Fine-Tuning**
2408.04693v1 by Yuchen Xia, Jiho Kim, Yuhan Chen, Haojie Ye, Souvik Kundu, Cong, Hao, Nishil Talati

Due to the cost-prohibitive nature of training Large Language Models (LLMs),
fine-tuning has emerged as an attractive alternative for specializing LLMs for
specific tasks using limited compute resources in a cost-effective manner. In
this paper, we characterize sparse Mixture of Experts (MoE) based LLM
fine-tuning to understand their accuracy and runtime performance on a single
GPU. Our evaluation provides unique insights into the training efficacy of
sparse and dense versions of MoE models, as well as their runtime
characteristics, including maximum batch size, execution time breakdown,
end-to-end throughput, GPU hardware utilization, and load distribution. Our
study identifies the optimization of the MoE layer as crucial for further
improving the performance of LLM fine-tuning. Using our profiling results, we
also develop and validate an analytical model to estimate the cost of LLM
fine-tuning on the cloud. This model, based on parameters of the model and GPU
architecture, estimates LLM throughput and the cost of training, aiding
practitioners in industry and academia to budget the cost of fine-tuning a
specific model.

摘要：由於訓練大型語言模型 (LLM) 的成本過高，微調已成為一種有吸引力的替代方案，可以利用有限的運算資源以具有成本效益的方式將 LLM 專門化於特定任務。在本文中，我們描述了稀疏專家混合 (MoE) 基於 LLM 的微調，以了解它們在單一 GPU 上的準確度和執行時間效能。我們的評估提供了對稀疏和密集版本的 MoE 模型訓練效能的獨特見解，以及它們的執行時間特性，包括最大批次大小、執行時間細目、端到端吞吐量、GPU 硬體使用率和負載分佈。我們的研究發現，MoE 層的最佳化對於進一步提升 LLM 微調效能至關重要。利用我們的分析結果，我們還開發並驗證了一個分析模型，以估計雲端上 LLM 微調的成本。此模型基於模型和 GPU 架構的參數，估計 LLM 吞吐量和訓練成本，協助業界和學術界的從業人員預算微調特定模型的成本。

##### **Conversational Prompt Engineering**
2408.04560v1 by Liat Ein-Dor, Orith Toledo-Ronen, Artem Spector, Shai Gretz, Lena Dankin, Alon Halfon, Yoav Katz, Noam Slonim

Prompts are how humans communicate with LLMs. Informative prompts are
essential for guiding LLMs to produce the desired output. However, prompt
engineering is often tedious and time-consuming, requiring significant
expertise, limiting its widespread use. We propose Conversational Prompt
Engineering (CPE), a user-friendly tool that helps users create personalized
prompts for their specific tasks. CPE uses a chat model to briefly interact
with users, helping them articulate their output preferences and integrating
these into the prompt. The process includes two main stages: first, the model
uses user-provided unlabeled data to generate data-driven questions and utilize
user responses to shape the initial instruction. Then, the model shares the
outputs generated by the instruction and uses user feedback to further refine
the instruction and the outputs. The final result is a few-shot prompt, where
the outputs approved by the user serve as few-shot examples. A user study on
summarization tasks demonstrates the value of CPE in creating personalized,
high-performing prompts. The results suggest that the zero-shot prompt obtained
is comparable to its - much longer - few-shot counterpart, indicating
significant savings in scenarios involving repetitive tasks with large text
volumes.

摘要：提示是人類與 LLM 溝通的方式。提供資訊的提示對於引導 LLM 產生所需的輸出至關重要。然而，提示工程通常既乏味又耗時，需要大量的專業知識，限制了其廣泛使用。我們提出對話式提示工程 (CPE)，這是一個使用者友善的工具，可協助使用者為其特定任務建立個人化的提示。CPE 使用聊天模型與使用者進行簡短的互動，協助他們表達其輸出偏好並將這些偏好整合到提示中。這個過程包含兩個主要階段：首先，模型使用使用者提供的未標記資料來產生資料驅動的問題，並利用使用者的回應來塑造初始指令。然後，模型分享由指令產生的輸出，並使用使用者的回饋進一步改善指令和輸出。最終結果是一個少次提示，其中使用者核准的輸出作為少次範例。針對摘要任務進行的使用者研究證明了 CPE 在建立個人化、高執行效能提示方面的價值。結果顯示，獲得的零次提示與其長得多的少次對應提示相當，這表示在涉及大量文字內容的重複性任務中可以大幅節省。

##### **Bias-Aware Low-Rank Adaptation: Mitigating Catastrophic Inheritance of Large Language Models**
2408.04556v1 by Yupeng Chang, Yi Chang, Yuan Wu

Large language models (LLMs) have exhibited remarkable proficiency across a
diverse array of natural language processing (NLP) tasks. However, adapting
LLMs to downstream applications typically necessitates computationally
intensive and memory-demanding fine-tuning procedures. To mitigate these
burdens, parameter-efficient fine-tuning (PEFT) techniques have emerged as a
promising approach to tailor LLMs with minimal computational overhead. While
PEFT methods offer substantial advantages, they do not fully address the
pervasive issue of bias propagation from pre-training data. In this work, we
introduce Bias-Aware Low-Rank Adaptation (BA-LoRA), a novel PEFT method
designed to counteract bias inheritance. BA-LoRA incorporates three distinct
regularization terms: (1) consistency regularizer, (2) diversity regularizer,
and (3) singular vector decomposition regularizer. These regularizers
collectively aim to improve the generative models' consistency, diversity, and
generalization capabilities during the fine-tuning process. Through extensive
experiments on a variety of natural language understanding (NLU) and natural
language generation (NLG) tasks, employing prominent LLMs such as LLaMA,
Mistral, and Gemma, we demonstrate that BA-LoRA surpasses the performance of
LoRA and its state-of-the-art variants. Moreover, our method effectively
mitigates the deleterious effects of pre-training bias, leading to more
reliable and robust model outputs. The code is available at
https://github.com/cyp-jlu-ai/BA-LoRA.

摘要：大型語言模型 (LLM) 已在各種自然語言處理 (NLP) 任務中展現出卓越的能力。然而，要將 LLM 調整到下游應用程式通常需要計算密集且需要大量記憶體的微調程序。為了減輕這些負擔，參數有效微調 (PEFT) 技術已成為一種有前途的方法，可針對 LLM 進行客製化，且計算負擔最小。儘管 PEFT 方法具有顯著的優勢，但它們並未完全解決預訓練資料中偏差傳播的普遍問題。在這項工作中，我們引入了具備偏差感知能力的低秩適應 (BA-LoRA)，這是一種新穎的 PEFT 方法，旨在對抗偏差遺傳。BA-LoRA 結合了三個不同的正則化項目：(1) 一致性正則化器、(2) 多樣性正則化器，以及 (3) 奇異值分解正則化器。這些正則化器共同旨在改善生成模型在微調過程中的一致性、多樣性和泛化能力。透過在各種自然語言理解 (NLU) 和自然語言生成 (NLG) 任務上進行廣泛的實驗，採用 LLaMA、Mistral 和 Gemma 等著名的 LLM，我們證明了 BA-LoRA 超越了 LoRA 及其最先進的變體的效能。此外，我們的模型有效減輕了預訓練偏差的有害影響，進而產生更可靠且穩健的模型輸出。程式碼可在 https://github.com/cyp-jlu-ai/BA-LoRA 取得。

##### **Molyé: A Corpus-based Approach to Language Contact in Colonial France**
2408.04554v1 by Rasul Dent, Juliette Janès, Thibault Clérice, Pedro Ortiz Suarez, Benoît Sagot

Whether or not several Creole languages which developed during the early
modern period can be considered genetic descendants of European languages has
been the subject of intense debate. This is in large part due to the absence of
evidence of intermediate forms. This work introduces a new open corpus, the
Moly\'e corpus, which combines stereotypical representations of three kinds of
language variation in Europe with early attestations of French-based Creole
languages across a period of 400 years. It is intended to facilitate future
research on the continuity between contact situations in Europe and Creolophone
(former) colonies.

摘要：早期現代時期發展出的幾種克里奧爾語是否可以視為歐洲語言的遺傳後裔，一直是爭論激烈的議題。這在很大程度上是因為缺乏中間形式的證據。這項研究引入了新的開放語料庫，即 Moly\'e 語料庫，結合了歐洲三種語言變體的刻板印象，以及 400 年來以法語為基礎的克里奧爾語的早期證明。其目的是促進未來對歐洲接觸狀況與克里奧爾語（前）殖民地之間的連續性的研究。

##### **MemeMind at ArAIEval Shared Task: Spotting Persuasive Spans in Arabic Text with Persuasion Techniques Identification**
2408.04540v1 by Md Rafiul Biswas, Zubair Shah, Wajdi Zaghouani

This paper focuses on detecting propagandistic spans and persuasion
techniques in Arabic text from tweets and news paragraphs. Each entry in the
dataset contains a text sample and corresponding labels that indicate the start
and end positions of propaganda techniques within the text. Tokens falling
within a labeled span were assigned "B" (Begin) or "I" (Inside), "O",
corresponding to the specific propaganda technique. Using attention masks, we
created uniform lengths for each span and assigned BIO tags to each token based
on the provided labels. Then, we used AraBERT-base pre-trained model for Arabic
text tokenization and embeddings with a token classification layer to identify
propaganda techniques. Our training process involves a two-phase fine-tuning
approach. First, we train only the classification layer for a few epochs,
followed by full model fine-tuning, updating all parameters. This methodology
allows the model to adapt to the specific characteristics of the propaganda
detection task while leveraging the knowledge captured by the pre-trained
AraBERT model. Our approach achieved an F1 score of 0.2774, securing the 3rd
position in the leaderboard of Task 1.

摘要：本文重點在於偵測推文和新聞段落中的阿拉伯語宣傳範圍和說服技巧。資料集中每個條目包含一個文字範本和對應標籤，標籤會指出文字中宣傳技巧的開始和結束位置。落在標籤範圍內的標記會被指定為「B」（開頭）或「I」（中間）、「O」，對應到特定的宣傳技巧。我們使用注意力遮罩，為每個範圍建立統一長度，並根據提供的標籤為每個標記指定 BIO 標籤。然後，我們使用 AraBERT-base 預訓練模型進行阿拉伯語文字標記化和內嵌，並使用標記分類層來識別宣傳技巧。我們的訓練過程包含一個兩階段微調方法。首先，我們只訓練分類層幾個時期，接著進行完整模型微調，更新所有參數。這種方法讓模型能夠適應宣傳偵測任務的特定特徵，同時運用預訓練 AraBERT 模型擷取的知識。我們的做法達到 0.2774 的 F1 分數，在任務 1 的排行榜中取得第 3 名。

##### **Exploring Scalability in Large-Scale Time Series in DeepVATS framework**
2408.04692v1 by Inmaculada Santamaria-Valenzuela, Victor Rodriguez-Fernandez, David Camacho

Visual analytics is essential for studying large time series due to its
ability to reveal trends, anomalies, and insights. DeepVATS is a tool that
merges Deep Learning (Deep) with Visual Analytics (VA) for the analysis of
large time series data (TS). It has three interconnected modules. The Deep
Learning module, developed in R, manages the load of datasets and Deep Learning
models from and to the Storage module. This module also supports models
training and the acquisition of the embeddings from the latent space of the
trained model. The Storage module operates using the Weights and Biases system.
Subsequently, these embeddings can be analyzed in the Visual Analytics module.
This module, based on an R Shiny application, allows the adjustment of the
parameters related to the projection and clustering of the embeddings space.
Once these parameters are set, interactive plots representing both the
embeddings, and the time series are shown. This paper introduces the tool and
examines its scalability through log analytics. The execution time evolution is
examined while the length of the time series is varied. This is achieved by
resampling a large data series into smaller subsets and logging the main
execution and rendering times for later analysis of scalability.

摘要：視覺分析對於研究大型時間序列至關重要，因為它能夠揭示趨勢、異常和見解。DeepVATS 是一個將深度學習 (Deep) 與視覺分析 (VA) 合併用於分析大型時間序列資料 (TS) 的工具。它有三個相互連接的模組。在 R 中開發的深度學習模組管理資料集和深度學習模型從儲存模組到儲存模組。此模組還支援模型訓練和從訓練模型的潛在空間中擷取嵌入。儲存模組使用權重和偏差系統運作。隨後，可以在視覺分析模組中分析這些嵌入。此模組基於 R Shiny 應用程式，允許調整與嵌入空間的投影和叢集相關的參數。設定這些參數後，會顯示同時表示嵌入和時間序列的互動式圖表。本文介紹該工具，並透過日誌分析探討其可擴充性。在時間序列長度不同的情況下，會檢查執行時間演進。這是透過將大型資料序列重新取樣為較小的子集，並記錄主要執行和渲染時間以供稍後分析可擴充性來實現的。

##### **Compromesso! Italian Many-Shot Jailbreaks Undermine the Safety of Large Language Models**
2408.04522v1 by Fabio Pernisi, Dirk Hovy, Paul Röttger

As diverse linguistic communities and users adopt large language models
(LLMs), assessing their safety across languages becomes critical. Despite
ongoing efforts to make LLMs safe, they can still be made to behave unsafely
with jailbreaking, a technique in which models are prompted to act outside
their operational guidelines. Research on LLM safety and jailbreaking, however,
has so far mostly focused on English, limiting our understanding of LLM safety
in other languages. We contribute towards closing this gap by investigating the
effectiveness of many-shot jailbreaking, where models are prompted with unsafe
demonstrations to induce unsafe behaviour, in Italian. To enable our analysis,
we create a new dataset of unsafe Italian question-answer pairs. With this
dataset, we identify clear safety vulnerabilities in four families of
open-weight LLMs. We find that the models exhibit unsafe behaviors even when
prompted with few unsafe demonstrations, and -- more alarmingly -- that this
tendency rapidly escalates with more demonstrations.

摘要：隨著多元的語言社群和使用者採用大型語言模型 (LLM)，評估其跨語言安全性變得至關重要。儘管持續努力讓 LLM 安全，但仍可透過越獄技術讓它們表現得並不安全，這是一種提示模型在運作準則之外採取行動的技術。然而，針對 LLM 安全性和越獄的研究迄今主要集中在英文，這限制了我們對其他語言中 LLM 安全性的了解。我們透過調查多發越獄的有效性來縮小這個差距，其中提示模型透過不安全的示範來誘發不安全的行為，以義大利文進行。為了進行分析，我們建立了一個新的不安全義大利文問答配對資料集。透過這個資料集，我們在四個開放權重 LLM 家族中找出明確的安全漏洞。我們發現，即使提示的示範不多，這些模型也會表現出不安全的行為，而且更令人擔憂的是，這種趨勢會隨著示範的增加而迅速升高。

##### **Articulatory Configurations across Genders and Periods in French Radio and TV archives**
2408.04519v1 by Benjamin Elie, David Doukhan, Rémi Uro, Lucas Ondel-Yang, Albert Rilliard, Simon Devauchelle

This paper studies changes in articulatory configurations across genders and
periods using an inversion from acoustic to articulatory parameters. From a
diachronic corpus based on French media archives spanning 60 years from 1955 to
2015, automatic transcription and forced alignment allowed extracting the
central frame of each vowel. More than one million frames were obtained from
over a thousand speakers across gender and age categories. Their formants were
used from these vocalic frames to fit the parameters of Maeda's articulatory
model. Evaluations of the quality of these processes are provided. We focus
here on two parameters of Maeda's model linked to total vocal tract length: the
relative position of the larynx (higher for females) and the lips protrusion
(more protruded for males). Implications for voice quality across genders are
discussed. The effect across periods seems gender independent; thus, the
assertion that females lowered their pitch with time is not supported.

摘要：本文使用從聲學到語音參數的反演研究了跨性別和時期的語音配置變化。從一個基於法語媒體檔案的歷時語料庫，跨越 1955 年至 2015 年的 60 年，自動轉錄和強制對齊允許提取每個元音的中心幀。從跨性別和年齡類別的 1000 多名說話者中獲得了超過一百萬個幀。從這些元音幀中使用它們的共振峰來擬合 Maeda 語音模型的參數。提供了這些過程質量的評估。我們這裡重點關注與總聲道長度相關的 Maeda 模型的兩個參數：喉頭的相對位置（女性較高）和嘴唇突出（男性較突出）。討論了跨性別的聲音品質的影響。跨時期的影響似乎與性別無關；因此，女性隨著時間降低音高的說法得不到支持。

##### **Towards Synergistic Deep Learning Models for Volumetric Cirrhotic Liver Segmentation in MRIs**
2408.04491v1 by Vandan Gorade, Onkar Susladkar, Gorkem Durak, Elif Keles, Ertugrul Aktas, Timurhan Cebeci, Alpay Medetalibeyoglu, Daniela Ladner, Debesh Jha, Ulas Bagci

Liver cirrhosis, a leading cause of global mortality, requires precise
segmentation of ROIs for effective disease monitoring and treatment planning.
Existing segmentation models often fail to capture complex feature interactions
and generalize across diverse datasets. To address these limitations, we
propose a novel synergistic theory that leverages complementary latent spaces
for enhanced feature interaction modeling. Our proposed architecture,
nnSynergyNet3D integrates continuous and discrete latent spaces for 3D volumes
and features auto-configured training. This approach captures both fine-grained
and coarse features, enabling effective modeling of intricate feature
interactions. We empirically validated nnSynergyNet3D on a private dataset of
628 high-resolution T1 abdominal MRI scans from 339 patients. Our model
outperformed the baseline nnUNet3D by approximately 2%. Additionally, zero-shot
testing on healthy liver CT scans from the public LiTS dataset demonstrated
superior cross-modal generalization capabilities. These results highlight the
potential of synergistic latent space models to improve segmentation accuracy
and robustness, thereby enhancing clinical workflows by ensuring consistency
across CT and MRI modalities.

摘要：肝硬化是全球死亡的主要原因，需要对 ROI 进行精确分割，以进行有效的疾病监测和治疗计划。现有的分割模型通常无法捕捉复杂的特征交互，并在不同的数据集上进行泛化。为了解决这些限制，我们提出了一种新颖的协同理论，该理论利用互补的潜在空间来增强特征交互建模。我们提出的架构 nnSynergyNet3D 集成了连续和离散的潜在空间，用于 3D 体积，并具有自动配置的训练。这种方法捕捉到了细粒度和粗粒度特征，从而能够有效地对复杂的特征交互进行建模。我们根据 339 名患者的 628 个高分辨率 T1 腹部 MRI 扫描的私有数据集对 nnSynergyNet3D 进行了实证验证。我们的模型比基线 nnUNet3D 的性能提高了大约 2%。此外，在来自公共 LiTS 数据集的健康肝脏 CT 扫描上进行零样本测试证明了其卓越的跨模态泛化能力。这些结果突出了协同潜在空间模型在提高分割精度和鲁棒性方面的潜力，从而通过确保 CT 和 MRI 模态的一致性来增强临床工作流程。

##### **SegXAL: Explainable Active Learning for Semantic Segmentation in Driving Scene Scenarios**
2408.04482v1 by Sriram Mandalika, Athira Nambiar

Most of the sophisticated AI models utilize huge amounts of annotated data
and heavy training to achieve high-end performance. However, there are certain
challenges that hinder the deployment of AI models "in-the-wild" scenarios,
i.e., inefficient use of unlabeled data, lack of incorporation of human
expertise, and lack of interpretation of the results. To mitigate these
challenges, we propose a novel Explainable Active Learning (XAL) model,
XAL-based semantic segmentation model "SegXAL", that can (i) effectively
utilize the unlabeled data, (ii) facilitate the "Human-in-the-loop" paradigm,
and (iii) augment the model decisions in an interpretable way. In particular,
we investigate the application of the SegXAL model for semantic segmentation in
driving scene scenarios. The SegXAL model proposes the image regions that
require labeling assistance from Oracle by dint of explainable AI (XAI) and
uncertainty measures in a weakly-supervised manner. Specifically, we propose a
novel Proximity-aware Explainable-AI (PAE) module and Entropy-based Uncertainty
(EBU) module to get an Explainable Error Mask, which enables the machine
teachers/human experts to provide intuitive reasoning behind the results and to
solicit feedback to the AI system via an active learning strategy. Such a
mechanism bridges the semantic gap between man and machine through
collaborative intelligence, where humans and AI actively enhance each other's
complementary strengths. A novel high-confidence sample selection technique
based on the DICE similarity coefficient is also presented within the SegXAL
framework. Extensive quantitative and qualitative analyses are carried out in
the benchmarking Cityscape dataset. Results show the outperformance of our
proposed SegXAL against other state-of-the-art models.

摘要：大多數先進的 AI 模型都利用大量標註資料和嚴格訓練來達成高階效能。然而，在 AI 模型「在野」場景中部署時，會遇到某些挑戰，例如：非標註資料使用效率不彰、缺乏整合人類專業知識，以及缺乏對結果的詮釋。為了減輕這些挑戰，我們提出一個新穎的可解釋主動學習 (XAL) 模型，基於 XAL 的語意分割模型「SegXAL」，它可以 (i) 有效利用非標註資料，(ii) 促成「人類在迴圈中」的模式，以及 (iii) 以可解釋的方式擴充模型的決策。特別是，我們探討 SegXAL 模型在駕駛場景中用於語意分割的應用。SegXAL 模型提出需要標籤協助的影像區域，藉由可解釋 AI (XAI) 和不確定性測量，以弱監督的方式來達成。具體來說，我們提出一個新穎的鄰近感知可解釋 AI (PAE) 模組和基於熵的不確定性 (EBU) 模組，以取得可解釋錯誤遮罩，這讓機器教師/人類專家能夠對結果提供直覺性的推理，並透過主動學習策略向 AI 系統徵求回饋。這種機制透過協作智慧，縮小人類與機器之間的語意差距，人類與 AI 能夠積極地增強彼此的互補優勢。SegXAL 架構中也提出一個新穎的高信心樣本選取技術，基於 DICE 相似係數。在基準 Cityscape 資料集中進行廣泛的量化和質化分析。結果顯示我們提出的 SegXAL 優於其他現有技術模型。

##### **Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive Debate**
2408.04472v1 by Yiqun Zhang, Xiaocui Yang, Shi Feng, Daling Wang, Yifei Zhang, Kaisong Song

Competitive debate is a comprehensive and complex computational argumentation
task. Large Language Models (LLMs) encounter hallucinations and lack
competitiveness in this task. To address these challenges, we introduce Agent
for Debate (Agent4Debate), a dynamic, multi-agent framework based on LLMs
designed to enhance their capabilities in competitive debate. Drawing
inspiration from human behavior in debate preparation and execution,
Agent4Debate employs a collaborative architecture where four specialized agents
(Searcher, Analyzer, Writer, and Reviewer) dynamically interact and cooperate.
These agents work throughout the debate process, covering multiple stages from
initial research and argument formulation to rebuttal and summary. To
comprehensively evaluate framework performance, we construct the Chinese Debate
Arena, comprising 66 carefully selected Chinese debate motions. We recruite ten
experienced human debaters and collect records of 200 debates involving
Agent4Debate, baseline models, and humans. The evaluation employs the Debatrix
automatic scoring system and professional human reviewers based on the
established Debatrix-Elo and Human-Elo ranking. Experimental results indicate
that the state-of-the-art Agent4Debate exhibits capabilities comparable to
those of humans. Furthermore, ablation studies demonstrate the effectiveness of
each component in the agent structure.

摘要：競爭性辯論是一種全面且複雜的計算論證任務。大型語言模型 (LLM) 在此任務中會遇到幻覺，且缺乏競爭力。為了應對這些挑戰，我們引入了辯論代理 (Agent4Debate)，這是一個基於 LLM 的動態多代理架構，旨在增強其在競爭性辯論中的能力。Agent4Debate 從人類在辯論準備和執行中的行為中汲取靈感，採用協作架構，其中四個專門代理（搜尋者、分析師、撰稿人和審閱者）動態互動並合作。這些代理在整個辯論過程中工作，涵蓋從初始研究和論證制定到反駁和總結的多個階段。為了全面評估框架效能，我們構建了包含 66 個精心挑選的中文辯論動議的中文辯論競技場。我們招募了十位經驗豐富的人類辯論者，並收集了 200 場涉及 Agent4Debate、基線模型和人類的辯論記錄。評估採用 Debatrix 自動評分系統和專業的人類審閱者，根據既定的 Debatrix-Elo 和 Human-Elo 排名。實驗結果表明，最先進的 Agent4Debate 所表現出的能力可與人類相媲美。此外，消融研究證明了代理結構中每個組成的有效性。

##### **Crowd Intelligence for Early Misinformation Prediction on Social Media**
2408.04463v1 by Megha Sundriyal, Harshit Choudhary, Tanmoy Chakraborty, Md Shad Akhtar

Misinformation spreads rapidly on social media, causing serious damage by
influencing public opinion, promoting dangerous behavior, or eroding trust in
reliable sources. It spreads too fast for traditional fact-checking, stressing
the need for predictive methods. We introduce CROWDSHIELD, a crowd
intelligence-based method for early misinformation prediction. We hypothesize
that the crowd's reactions to misinformation reveal its accuracy. Furthermore,
we hinge upon exaggerated assertions/claims and replies with particular
positions/stances on the source post within a conversation thread. We employ
Q-learning to capture the two dimensions -- stances and claims. We utilize deep
Q-learning due to its proficiency in navigating complex decision spaces and
effectively learning network properties. Additionally, we use a
transformer-based encoder to develop a comprehensive understanding of both
content and context. This multifaceted approach helps ensure the model pays
attention to user interaction and stays anchored in the communication's
content. We propose MIST, a manually annotated misinformation detection Twitter
corpus comprising nearly 200 conversation threads with more than 14K replies.
In experiments, CROWDSHIELD outperformed ten baseline systems, achieving an
improvement of ~4% macro-F1 score. We conduct an ablation study and error
analysis to validate our proposed model's performance. The source code and
dataset are available at https://github.com/LCS2-IIITD/CrowdShield.git.

摘要：错误信息在社交媒體上迅速傳播，通過影響公眾輿論、宣傳危險行為或侵蝕對可靠來源的信任，造成嚴重損害。它的傳播速度太快，以至於傳統的事實查核無法應對，這強調了對預測方法的需求。我們引入了 CROWDSHIELD，這是一種基於群眾智慧的早期錯誤信息預測方法。我們假設群眾對錯誤信息的反應揭示了它的準確性。此外，我們依賴於對話線程中源帖子的誇張斷言/主張和具有特定立場/態度的回復。我們採用 Q 學習來捕捉這兩個維度——立場和主張。我們利用深度 Q 學習，因為它擅長在複雜的決策空間中導航並有效地學習網路屬性。此外，我們使用基於 Transformer 的編碼器來全面理解內容和上下文。這種多方面的途徑有助於確保模型關注用戶互動並錨定在通信內容中。我們提出了 MIST，這是一個手動標註的錯誤信息檢測 Twitter 語料庫，包含近 200 個對話線程，其中有超過 14K 條回復。在實驗中，CROWDSHIELD 優於十個基準系統，宏觀 F1 分數提高了約 4%。我們進行消融研究和錯誤分析，以驗證我們提出的模型的性能。源代碼和數據集可在 https://github.com/LCS2-IIITD/CrowdShield.git 上獲得。

##### **RiskAwareBench: Towards Evaluating Physical Risk Awareness for High-level Planning of LLM-based Embodied Agents**
2408.04449v1 by Zihao Zhu, Bingzhe Wu, Zhengyou Zhang, Baoyuan Wu

The integration of large language models (LLMs) into robotics significantly
enhances the capabilities of embodied agents in understanding and executing
complex natural language instructions. However, the unmitigated deployment of
LLM-based embodied systems in real-world environments may pose potential
physical risks, such as property damage and personal injury. Existing security
benchmarks for LLMs overlook risk awareness for LLM-based embodied agents. To
address this gap, we propose RiskAwareBench, an automated framework designed to
assess physical risks awareness in LLM-based embodied agents. RiskAwareBench
consists of four modules: safety tips generation, risky scene generation, plan
generation, and evaluation, enabling comprehensive risk assessment with minimal
manual intervention. Utilizing this framework, we compile the PhysicalRisk
dataset, encompassing diverse scenarios with associated safety tips,
observations, and instructions. Extensive experiments reveal that most LLMs
exhibit insufficient physical risk awareness, and baseline risk mitigation
strategies yield limited enhancement, which emphasizes the urgency and
cruciality of improving risk awareness in LLM-based embodied agents in the
future.

摘要：大型語言模型 (LLM) 整合到機器人技術中，顯著提升了具身代理理解和執行複雜自然語言指令的能力。然而，在現實世界環境中部署基於 LLM 的具身系統可能會造成潛在的物理風險，例如財產損壞和人身傷害。現有的 LLM 安全基準忽略了對基於 LLM 的具身代理的風險意識。為了解決這個問題，我們提出了 RiskAwareBench，這是一個自動化框架，旨在評估基於 LLM 的具身代理中的物理風險意識。RiskAwareBench 包含四個模組：安全提示生成、風險場景生成、計畫生成和評估，以最少的介入實現全面的風險評估。利用這個框架，我們編制了 PhysicalRisk 資料集，其中包含各種場景以及相關的安全提示、觀察和說明。大量的實驗顯示，大多數 LLM 都表現出不足的物理風險意識，而且基準風險緩解策略產生的改善有限，這強調了在未來改善基於 LLM 的具身代理中的風險意識的迫切性和重要性。

##### **FedAD-Bench: A Unified Benchmark for Federated Unsupervised Anomaly Detection in Tabular Data**
2408.04442v1 by Ahmed Anwar, Brian Moser, Dayananda Herurkar, Federico Raue, Vinit Hegiste, Tatjana Legler, Andreas Dengel

The emergence of federated learning (FL) presents a promising approach to
leverage decentralized data while preserving privacy. Furthermore, the
combination of FL and anomaly detection is particularly compelling because it
allows for detecting rare and critical anomalies (usually also rare in locally
gathered data) in sensitive data from multiple sources, such as cybersecurity
and healthcare. However, benchmarking the performance of anomaly detection
methods in FL environments remains an underexplored area. This paper introduces
FedAD-Bench, a unified benchmark for evaluating unsupervised anomaly detection
algorithms within the context of FL. We systematically analyze and compare the
performance of recent deep learning anomaly detection models under federated
settings, which were typically assessed solely in centralized settings.
FedAD-Bench encompasses diverse datasets and metrics to provide a holistic
evaluation. Through extensive experiments, we identify key challenges such as
model aggregation inefficiencies and metric unreliability. We present insights
into FL's regularization effects, revealing scenarios in which it outperforms
centralized approaches due to its inherent ability to mitigate overfitting. Our
work aims to establish a standardized benchmark to guide future research and
development in federated anomaly detection, promoting reproducibility and fair
comparison across studies.

摘要：聯邦學習 (FL) 的出現提供了一個有前途的方法，可以在維護隱私的同時利用分散的數據。此外，FL 和異常檢測的結合特別引人注目，因為它允許從多個來源（例如網路安全和醫療保健）中檢測罕見和關鍵的異常（通常在本地收集的數據中也很罕見）。然而，在 FL 環境中對異常檢測方法的性能進行基準測試仍然是一個未被充分探索的領域。本文介紹了 FedAD-Bench，這是一個用於評估 FL 背景下無監督異常檢測演算法的統一基準。我們系統地分析並比較了最近深度學習異常檢測模型在聯邦設置下的性能，這些模型通常僅在集中式設置中進行評估。FedAD-Bench 涵蓋了多樣化的數據集和指標，以提供全面的評估。通過大量的實驗，我們確定了關鍵挑戰，例如模型聚合效率低下和指標不可靠。我們深入了解 FL 的正則化效應，揭示了由於其固有的減輕過度擬合的能力，它在哪些場景中優於集中式方法。我們的目標是建立一個標準化基準，以指導聯邦異常檢測的未來研究和開發，促進跨研究的可重複性和公平比較。

##### **Improving Relational Database Interactions with Large Language Models: Column Descriptions and Their Impact on Text-to-SQL Performance**
2408.04691v1 by Niklas Wretblad, Oskar Holmström, Erik Larsson, Axel Wiksäter, Oscar Söderlund, Hjalmar Öhman, Ture Pontén, Martin Forsberg, Martin Sörme, Fredrik Heintz

Relational databases often suffer from uninformative descriptors of table
contents, such as ambiguous columns and hard-to-interpret values, impacting
both human users and Text-to-SQL models. This paper explores the use of large
language models (LLMs) to generate informative column descriptions as a
semantic layer for relational databases. Using the BIRD-Bench development set,
we created \textsc{ColSQL}, a dataset with gold-standard column descriptions
generated and refined by LLMs and human annotators. We evaluated several
instruction-tuned models, finding that GPT-4o and Command R+ excelled in
generating high-quality descriptions. Additionally, we applied an
LLM-as-a-judge to evaluate model performance. Although this method does not
align well with human evaluations, we included it to explore its potential and
to identify areas for improvement. More work is needed to improve the
reliability of automatic evaluations for this task. We also find that detailed
column descriptions significantly improve Text-to-SQL execution accuracy,
especially when columns are uninformative. This study establishes LLMs as
effective tools for generating detailed metadata, enhancing the usability of
relational databases.

摘要：<paragraph>關聯資料庫通常會因為表格內容的描述性不足而受害，例如模稜兩可的欄位和難以解讀的值，會影響人類使用者和文字轉 SQL 模型。本文探討使用大型語言模型 (LLM) 來產生資料欄位的描述性資訊，作為關聯資料庫的語意層。我們使用 BIRD-Bench 開發設定，建立了 \textsc{ColSQL}，一個由 LLM 和人類註解者產生並優化的黃金標準欄位描述資料集。我們評估了數個經過指令微調的模型，發現 GPT-4o 和 Command R+ 在產生高品質描述方面表現優異。此外，我們應用 LLM 作為評審者來評估模型效能。雖然這個方法與人類評估不一致，但我們還是納入它來探討其潛力並找出需要改進的地方。需要更多工作來提升這個任務的自動評估的可靠性。我們也發現詳細的欄位描述會顯著提升文字轉 SQL 執行精確度，特別是在欄位描述性不足時。這項研究確立了 LLM 作為產生詳細元資料的有效工具，增強了關聯資料庫的可用性。</paragraph>

##### **Recognizing Emotion Regulation Strategies from Human Behavior with Large Language Models**
2408.04420v1 by Philipp Müller, Alexander Heimerl, Sayed Muddashir Hossain, Lea Siegel, Jan Alexandersson, Patrick Gebhard, Elisabeth André, Tanja Schneeberger

Human emotions are often not expressed directly, but regulated according to
internal processes and social display rules. For affective computing systems,
an understanding of how users regulate their emotions can be highly useful, for
example to provide feedback in job interview training, or in psychotherapeutic
scenarios. However, at present no method to automatically classify different
emotion regulation strategies in a cross-user scenario exists. At the same
time, recent studies showed that instruction-tuned Large Language Models (LLMs)
can reach impressive performance across a variety of affect recognition tasks
such as categorical emotion recognition or sentiment analysis. While these
results are promising, it remains unclear to what extent the representational
power of LLMs can be utilized in the more subtle task of classifying users'
internal emotion regulation strategy. To close this gap, we make use of the
recently introduced \textsc{Deep} corpus for modeling the social display of the
emotion shame, where each point in time is annotated with one of seven
different emotion regulation classes. We fine-tune Llama2-7B as well as the
recently introduced Gemma model using Low-rank Optimization on prompts
generated from different sources of information on the \textsc{Deep} corpus.
These include verbal and nonverbal behavior, person factors, as well as the
results of an in-depth interview after the interaction. Our results show, that
a fine-tuned Llama2-7B LLM is able to classify the utilized emotion regulation
strategy with high accuracy (0.84) without needing access to data from
post-interaction interviews. This represents a significant improvement over
previous approaches based on Bayesian Networks and highlights the importance of
modeling verbal behavior in emotion regulation.

摘要：人類的情緒通常不會直接表達出來，而是根據內部過程和社會展示規則進行調節。對於情感運算系統而言，了解使用者如何調節情緒可能非常有用，例如在面試培訓或心理治療場景中提供回饋。然而，目前尚無方法可在跨使用者場景中自動分類不同的情緒調節策略。同時，最近的研究表明，經過指示調整的大型語言模型 (LLM) 可以在一系列情感辨識任務中達到令人印象深刻的表現，例如分類情緒辨識或情緒分析。雖然這些結果令人振奮，但 LLM 的表徵能力在更細微的使用者內部情緒調節策略分類任務中能發揮多大作用仍不清楚。為了縮小這個差距，我們利用最近推出的「深度」語料庫來建模情緒羞恥的社會展示，其中每個時間點都標註了七種不同的情緒調節類別之一。我們微調了 Llama2-7B 以及最近推出的 Gemma 模型，使用低秩最佳化處理從「深度」語料庫中不同資訊來源產生的提示。這些資訊包括言語和非言語行為、個人因素，以及互動後深入訪談的結果。我們的結果顯示，微調後的 Llama2-7B LLM 能夠以高準確度 (0.84) 分類所使用的情緒調節策略，而不需要存取互動後訪談的資料。這代表相較於基於貝氏網路的先前方法有顯著的進步，並突顯了在情緒調節中建模言語行為的重要性。

##### **Enhancing Robustness of Retrieval-Augmented Language Models with In-Context Learning**
2408.04414v1 by Seong-Il Park, Seung-Woo Choi, Na-Hyun Kim, Jay-Yoon Lee

Retrieval-Augmented Language Models (RALMs) have significantly improved
performance in open-domain question answering (QA) by leveraging external
knowledge. However, RALMs still struggle with unanswerable queries, where the
retrieved contexts do not contain the correct answer, and with conflicting
information, where different sources provide contradictory answers due to
imperfect retrieval. This study introduces an in-context learning-based
approach to enhance the reasoning capabilities of RALMs, making them more
robust in imperfect retrieval scenarios. Our method incorporates Machine
Reading Comprehension (MRC) demonstrations, referred to as cases, to boost the
model's capabilities to identify unanswerabilities and conflicts among the
retrieved contexts. Experiments on two open-domain QA datasets show that our
approach increases accuracy in identifying unanswerable and conflicting
scenarios without requiring additional fine-tuning. This work demonstrates that
in-context learning can effectively enhance the robustness of RALMs in
open-domain QA tasks.

摘要：檢索增強語言模型 (RALM) 透過利用外部知識，大幅提升了開放領域問答 (QA) 的效能。然而，RALM 仍難以應對無法回答的查詢，其中檢索到的脈絡不包含正確答案，以及矛盾資訊，其中不同的來源因檢索不完美而提供相互矛盾的答案。本研究引入基於脈絡中學習的方法，以增強 RALM 的推理能力，使其在不完美的檢索情境中更強健。我們的做法結合了機器閱讀理解 (MRC) 示範，稱為案例，以提升模型辨識檢索到的脈絡中無法回答和矛盾之處的能力。在兩個開放領域 QA 資料集上的實驗顯示，我們的做法提升了辨識無法回答和矛盾情境的準確度，而無需額外的微調。這項工作證明了脈絡中學習可以有效增強 RALM 在開放領域 QA 任務中的強健性。

##### **Design of a Quality Management System based on the EU Artificial Intelligence Act**
2408.04689v1 by Henryk Mustroph, Stefanie Rinderle-Ma

The Artificial Intelligence Act of the European Union mandates that providers
and deployers of high-risk AI systems establish a quality management system
(QMS). Among other criteria, a QMS shall help to i) identify, analyze,
evaluate, and mitigate risks, ii) ensure evidence of compliance with training,
validation, and testing data, and iii) verify and document the AI system design
and quality. Current research mainly addresses conceptual considerations and
framework designs for AI risk assessment and auditing processes. However, it
often overlooks practical tools that actively involve and support humans in
checking and documenting high-risk or general-purpose AI systems. This paper
addresses this gap by proposing requirements derived from legal regulations and
a generic design and architecture of a QMS for AI systems verification and
documentation. A first version of a prototype QMS is implemented, integrating
LLMs as examples of AI systems and focusing on an integrated risk management
sub-service. The prototype is evaluated on i) a user story-based qualitative
requirements assessment using potential stakeholder scenarios and ii) a
technical assessment of the required GPU storage and performance.

摘要：歐盟的人工智慧法規要求高風險 AI 系統的供應商和部署者建立品質管理系統 (QMS)。在其他標準中，QMS 應有助於 i) 識別、分析、評估和減輕風險，ii) 確保符合訓練、驗證和測試資料的證據，以及 iii) 驗證和記錄 AI 系統設計和品質。目前的研究主要針對 AI 風險評估和稽核程序的概念性考量和架構設計。然而，它經常忽略實用的工具，這些工具能積極地讓人類參與並協助檢查和記錄高風險或一般用途的 AI 系統。本文透過提出源自法規要求的規範，以及 AI 系統驗證和記錄的 QMS 通用設計和架構，來解決此一落差。已實作原型 QMS 的第一個版本，整合 LLM 作為 AI 系統的範例，並專注於整合風險管理子服務。原型在 i) 使用潛在利害關係人情境的使用者故事為基礎的定性需求評估，以及 ii) 所需 GPU 儲存和效能的技術評估中進行評估。

##### **Exploring Reasoning Biases in Large Language Models Through Syllogism: Insights from the NeuBAROCO Dataset**
2408.04403v1 by Kentaro Ozeki, Risako Ando, Takanobu Morishita, Hirohiko Abe, Koji Mineshima, Mitsuhiro Okada

This paper explores the question of how accurately current large language
models can perform logical reasoning in natural language, with an emphasis on
whether these models exhibit reasoning biases similar to humans. Specifically,
our study focuses on syllogistic reasoning, a form of deductive reasoning
extensively studied in cognitive science as a natural form of human reasoning.
We present a syllogism dataset called NeuBAROCO, which consists of syllogistic
reasoning problems in English and Japanese. This dataset was originally
designed for psychological experiments to assess human reasoning capabilities
using various forms of syllogisms. Our experiments with leading large language
models indicate that these models exhibit reasoning biases similar to humans,
along with other error tendencies. Notably, there is significant room for
improvement in reasoning problems where the relationship between premises and
hypotheses is neither entailment nor contradiction. We also present
experimental results and in-depth analysis using a new Chain-of-Thought
prompting method, which asks LLMs to translate syllogisms into abstract logical
expressions and then explain their reasoning process. Our analysis using this
method suggests that the primary limitations of LLMs lie in the reasoning
process itself rather than the interpretation of syllogisms.

摘要：這篇論文探討了目前大型語言模型在自然語言中執行邏輯推理的準確性，重點在於這些模型是否表現出與人類類似的推理偏差。具體來說，我們的研究重點在於三段論推理，這是一種演繹推理形式，在認知科學中被廣泛研究為人類推理的自然形式。我們提出了一個名為 NeuBAROCO 的三段論數據集，其中包含英語和日語的三段論推理問題。此數據集最初是為心理實驗設計的，用於使用各種形式的三段論評估人類推理能力。我們與領先的大型語言模型進行的實驗表明，這些模型表現出與人類類似的推理偏差，以及其他錯誤傾向。值得注意的是，在前提和假設之間的關係既不是蘊涵也不是矛盾的推理問題中，有很大的改進空間。我們還使用新的思想鏈提示方法提供了實驗結果和深入分析，該方法要求 LLM 將三段論翻譯成抽象邏輯表達式，然後解釋他們的推理過程。我們使用此方法進行的分析表明，LLM 的主要限制在於推理過程本身，而不是對三段論的解釋。

##### **DIVE: Subgraph Disagreement for Graph Out-of-Distribution Generalization**
2408.04400v1 by Xin Sun, Liang Wang, Qiang Liu, Shu Wu, Zilei Wang, Liang Wang

This paper addresses the challenge of out-of-distribution (OOD)
generalization in graph machine learning, a field rapidly advancing yet
grappling with the discrepancy between source and target data distributions.
Traditional graph learning algorithms, based on the assumption of uniform
distribution between training and test data, falter in real-world scenarios
where this assumption fails, resulting in suboptimal performance. A principal
factor contributing to this suboptimal performance is the inherent simplicity
bias of neural networks trained through Stochastic Gradient Descent (SGD),
which prefer simpler features over more complex yet equally or more predictive
ones. This bias leads to a reliance on spurious correlations, adversely
affecting OOD performance in various tasks such as image recognition, natural
language understanding, and graph classification. Current methodologies,
including subgraph-mixup and information bottleneck approaches, have achieved
partial success but struggle to overcome simplicity bias, often reinforcing
spurious correlations. To tackle this, we propose DIVE, training a collection
of models to focus on all label-predictive subgraphs by encouraging the models
to foster divergence on the subgraph mask, which circumvents the limitation of
a model solely focusing on the subgraph corresponding to simple structural
patterns. Specifically, we employs a regularizer to punish overlap in extracted
subgraphs across models, thereby encouraging different models to concentrate on
distinct structural patterns. Model selection for robust OOD performance is
achieved through validation accuracy. Tested across four datasets from GOOD
benchmark and one dataset from DrugOOD benchmark, our approach demonstrates
significant improvement over existing methods, effectively addressing the
simplicity bias and enhancing generalization in graph machine learning.

摘要：<paragraph>這篇論文探討了圖形機器學習中非分佈 (OOD) 概化的挑戰，這是一個快速發展的領域，但卻在應對來源和目標資料分佈之間的差異上遇到困難。傳統的圖形學習演算法基於訓練資料和測試資料之間均勻分佈的假設，但在這個假設失效的實際情況中會出現問題，導致次佳效能。造成這種次佳效能的主要因素是透過隨機梯度下降 (SGD) 訓練的神經網路固有的簡化偏差，它偏好較簡單的特徵，而非更複雜但預測能力相同或更高的特徵。這種偏差會導致依賴虛假相關性，對各種任務（例如影像辨識、自然語言理解和圖形分類）的 OOD 效能產生負面影響。目前的技術方法，包括子圖混合和資訊瓶頸方法，已取得部分成功，但仍難以克服簡化偏差，而且常常會強化虛假相關性。為了解決這個問題，我們提出了 DIVE，訓練一組模型以關注所有標籤預測子圖，方法是鼓勵模型在子圖遮罩上促進差異，這避開了模型僅關注對應於簡單結構模式的子圖的限制。具體來說，我們採用一個正規化器來懲罰模型之間提取的子圖中的重疊，從而鼓勵不同的模型專注於不同的結構模式。透過驗證準確度，可以選擇模型以獲得穩健的 OOD 效能。我們的做法在 GOOD 基準中的四個資料集和 DrugOOD 基準中的其中一個資料集上進行了測試，結果顯示出比現有方法有顯著的進步，有效地解決了簡化偏差，並增強了圖形機器學習中的概化能力。</paragraph>

##### **Automated Educational Question Generation at Different Bloom's Skill Levels using Large Language Models: Strategies and Evaluation**
2408.04394v1 by Nicy Scaria, Suma Dharani Chenna, Deepak Subramani

Developing questions that are pedagogically sound, relevant, and promote
learning is a challenging and time-consuming task for educators. Modern-day
large language models (LLMs) generate high-quality content across multiple
domains, potentially helping educators to develop high-quality questions.
Automated educational question generation (AEQG) is important in scaling online
education catering to a diverse student population. Past attempts at AEQG have
shown limited abilities to generate questions at higher cognitive levels. In
this study, we examine the ability of five state-of-the-art LLMs of different
sizes to generate diverse and high-quality questions of different cognitive
levels, as defined by Bloom's taxonomy. We use advanced prompting techniques
with varying complexity for AEQG. We conducted expert and LLM-based evaluations
to assess the linguistic and pedagogical relevance and quality of the
questions. Our findings suggest that LLms can generate relevant and
high-quality educational questions of different cognitive levels when prompted
with adequate information, although there is a significant variance in the
performance of the five LLms considered. We also show that automated evaluation
is not on par with human evaluation.

摘要：<paragraph>對於教育工作者來說，制定具有教學意義、相關且能促進學習的問題是一項具有挑戰性且耗時的任務。現代大型語言模型 (LLM) 可產生跨多個領域的高品質內容，潛在有助於教育工作者制定高品質的問題。自動化教育問題產生 (AEQG) 在擴展線上教育以迎合多元的學生族群方面非常重要。過去嘗試 AEQG 已顯示出在產生較高認知層級問題方面的能力有限。在本研究中，我們探討五種不同規模的最新 LLM 產生不同認知層級的多樣化且高品質問題的能力，正如布魯姆分類法所定義的。我們使用具有不同複雜性的進階提示技術進行 AEQG。我們進行專家和基於 LLM 的評估，以評估問題的語言和教學相關性及品質。我們的研究結果表明，當提示提供足夠的資訊時，LLM 可以產生不同認知層級的相關且高品質教育問題，儘管所考慮的五種 LLM 在效能上存在顯著差異。我們也表明，自動化評估無法與人類評估相提並論。</paragraph>

##### **Open-domain Implicit Format Control for Large Language Model Generation**
2408.04392v1 by Yiqun Yao, Wenjia Ma, Xuezhi Fang, Xin Jiang, Xiang Li, Xuying Meng, Peng Han, Jing Li, Aixin Sun, Yequan Wang

Controlling the format of outputs generated by large language models (LLMs)
is a critical functionality in various applications. Current methods typically
employ constrained decoding with rule-based automata or fine-tuning with
manually crafted format instructions, both of which struggle with open-domain
format requirements. To address this limitation, we introduce a novel framework
for controlled generation in LLMs, leveraging user-provided, one-shot QA pairs.
This study investigates LLMs' capabilities to follow open-domain, one-shot
constraints and replicate the format of the example answers. We observe that
this is a non-trivial problem for current LLMs. We also develop a dataset
collection methodology for supervised fine-tuning that enhances the open-domain
format control of LLMs without degrading output quality, as well as a benchmark
on which we evaluate both the helpfulness and format correctness of LLM
outputs. The resulting datasets, named OIFC-SFT, along with the related code,
will be made publicly available at https://github.com/cofe-ai/OIFC.

摘要：控制大型語言模型 (LLM) 生成的輸出格式在各種應用中是一項關鍵功能。目前的方法通常使用基於規則的自動機進行約束解碼或使用人工製作的格式指令進行微調，這兩種方法都難以滿足開放領域的格式要求。為了解決這個限制，我們引入了一個新的框架，用於在 LLM 中進行受控生成，利用用戶提供的單次問答對。這項研究調查了 LLM 遵循開放領域、單次約束和複製範例答案格式的能力。我們觀察到這對於目前的 LLM 來說是一個不平凡的問題。我們還開發了一種用於監督微調的數據集收集方法，該方法增強了 LLM 的開放領域格式控制，而不會降低輸出質量，並建立了一個基準，我們根據此基準評估 LLM 輸出的有用性和格式正確性。生成的數據集名為 OIFC-SFT，連同相關代碼，將在 https://github.com/cofe-ai/OIFC 上公開。

