{"2405.14669": {"publish_time": "2024-05-23", "title": "Efficiency for Free: Ideal Data Are Transportable Representations", "paper_summary": "Data, the seminal opportunity and challenge in modern machine learning,\ncurrently constrains the scalability of representation learning and impedes the\npace of model evolution. Existing paradigms tackle the issue of learning\nefficiency over massive datasets from the perspective of self-supervised\nlearning and dataset distillation independently, while neglecting the untapped\npotential of accelerating representation learning from an intermediate\nstandpoint. In this work, we delve into defining the ideal data properties from\nboth optimization and generalization perspectives. We propose that\nmodel-generated representations, despite being trained on diverse tasks and\narchitectures, converge to a shared linear space, facilitating effective linear\ntransport between models. Furthermore, we demonstrate that these\nrepresentations exhibit properties conducive to the formation of ideal data.\nThe theoretical/empirical insights therein inspire us to propose a\nRepresentation Learning Accelerator (ReLA), which leverages a task- and\narchitecture-agnostic, yet publicly available, free model to form a dynamic\ndata subset and thus accelerate (self-)supervised learning. For instance,\nemploying a CLIP ViT B/16 as a prior model for dynamic data generation,\nReLA-aided BYOL can train a ResNet-50 from scratch with 50% of ImageNet-1K,\nyielding performance surpassing that of training on the full dataset.\nAdditionally, employing a ResNet-18 pre-trained on CIFAR-10 can enhance\nResNet-50 training on 10% of ImageNet-1K, resulting in a 7.7% increase in\naccuracy.", "paper_summary_zh": "<paragraph>\u8cc7\u6599\uff0c\u5728\u73fe\u4ee3\u6a5f\u5668\u5b78\u7fd2\u4e2d\u662f\u958b\u5275\u6027\u7684\u6a5f\u9047\u548c\u6311\u6230\uff0c\n\u76ee\u524d\u9650\u5236\u4e86\u8868\u5fb5\u5b78\u7fd2\u7684\u53ef\u64f4\u5145\u6027\uff0c\u4e26\u963b\u7919\u4e86\u6a21\u578b\u6f14\u5316\u7684\u901f\u5ea6\u3002\u73fe\u6709\u7684\u7bc4\u4f8b\u5f9e\u81ea\u76e3\u7763\u5b78\u7fd2\u548c\u8cc7\u6599\u96c6\u84b8\u993e\u7684\u89c0\u9ede\u4f86\u89e3\u6c7a\u6d77\u91cf\u8cc7\u6599\u96c6\u4e0a\u5b78\u7fd2\u6548\u7387\u7684\u554f\u984c\uff0c\u540c\u6642\u5ffd\u7565\u4e86\u5f9e\u4e2d\u9593\u7acb\u5834\u52a0\u901f\u8868\u5fb5\u5b78\u7fd2\u7684\u672a\u958b\u767c\u6f5b\u529b\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u6df1\u5165\u63a2\u8a0e\u5f9e\u6700\u4f73\u5316\u548c\u6982\u62ec\u7684\u89c0\u9ede\u5b9a\u7fa9\u7406\u60f3\u7684\u8cc7\u6599\u5c6c\u6027\u3002\u6211\u5011\u63d0\u51fa\u6a21\u578b\u7522\u751f\u7684\u8868\u5fb5\uff0c\u5118\u7ba1\u662f\u5728\u4e0d\u540c\u7684\u4efb\u52d9\u548c\u67b6\u69cb\u4e0a\u8a13\u7df4\u7684\uff0c\u4f46\u6703\u6536\u6582\u5230\u4e00\u500b\u5171\u7528\u7684\u7dda\u6027\u7a7a\u9593\uff0c\u4fc3\u9032\u6a21\u578b\u4e4b\u9593\u6709\u6548\u7684\u7dda\u6027\u50b3\u8f38\u3002\u6b64\u5916\uff0c\u6211\u5011\u8b49\u660e\u9019\u4e9b\u8868\u5fb5\u8868\u73fe\u51fa\u6709\u5229\u65bc\u5f62\u6210\u7406\u60f3\u8cc7\u6599\u7684\u5c6c\u6027\u3002\u5176\u4e2d\u7684\u7406\u8ad6/\u7d93\u9a57\u898b\u89e3\u555f\u767c\u6211\u5011\u63d0\u51fa\u8868\u5fb5\u5b78\u7fd2\u52a0\u901f\u5668 (ReLA)\uff0c\u5b83\u5229\u7528\u4efb\u52d9\u548c\u67b6\u69cb\u4e0d\u53ef\u77e5\u7684\uff0c\u4f46\u516c\u958b\u53ef\u7528\u7684\u514d\u8cbb\u6a21\u578b\u4f86\u5f62\u6210\u52d5\u614b\u8cc7\u6599\u5b50\u96c6\uff0c\u5f9e\u800c\u52a0\u901f\uff08\u81ea\u6211\uff09\u76e3\u7763\u5b78\u7fd2\u3002\u4f8b\u5982\uff0c\u4f7f\u7528 CLIP ViT B/16 \u4f5c\u70ba\u52d5\u614b\u8cc7\u6599\u751f\u6210\u7684\u5148\u9a57\u6a21\u578b\uff0cReLA \u8f14\u52a9\u7684 BYOL \u53ef\u4ee5\u5f9e\u982d\u958b\u59cb\u8a13\u7df4\u4e00\u500b ResNet-50\uff0c\u4f7f\u7528 50% \u7684 ImageNet-1K\uff0c\u5176\u6548\u80fd\u512a\u65bc\u5728\u5b8c\u6574\u8cc7\u6599\u96c6\u4e0a\u8a13\u7df4\u7684\u6548\u80fd\u3002\u6b64\u5916\uff0c\u4f7f\u7528\u5728 CIFAR-10 \u4e0a\u9810\u8a13\u7df4\u7684 ResNet-18 \u53ef\u4ee5\u589e\u5f37 ResNet-50 \u5728 10% \u7684 ImageNet-1K \u4e0a\u7684\u8a13\u7df4\uff0c\u5f9e\u800c\u4f7f\u6e96\u78ba\u5ea6\u63d0\u9ad8 7.7%\u3002</paragraph>", "author": "Peng Sun et.al.", "authors": "Peng Sun, Yi Jiang, Tao Lin", "id": "2405.14669v1", "paper_url": "http://arxiv.org/abs/2405.14669v1", "repo": "null"}}