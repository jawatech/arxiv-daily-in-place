{"2408.02503": {"publish_time": "2024-08-05", "title": "UnifiedMLLM: Enabling Unified Representation for Multi-modal Multi-tasks With Large Language Model", "paper_summary": "Significant advancements has recently been achieved in the field of\nmulti-modal large language models (MLLMs), demonstrating their remarkable\ncapabilities in understanding and reasoning across diverse tasks. However,\nthese models are often trained for specific tasks and rely on task-specific\ninput-output formats, limiting their applicability to a broader range of tasks.\nThis raises a fundamental question: Can we develop a unified approach to\nrepresent and handle different multi-modal tasks to maximize the\ngeneralizability of MLLMs? In this paper, we propose UnifiedMLLM, a\ncomprehensive model designed to represent various tasks using a unified\nrepresentation. Our model exhibits strong capabilities in comprehending the\nimplicit intent of user instructions and preforming reasoning. In addition to\ngenerating textual responses, our model also outputs task tokens and grounding\ntokens, serving as indicators of task types and task granularity. These outputs\nare subsequently routed through the task router and directed to specific expert\nmodels for task completion. To train our model, we construct a task-specific\ndataset and an 100k multi-task dataset encompassing complex scenarios.\nEmploying a three-stage training strategy, we equip our model with robust\nreasoning and task processing capabilities while preserving its generalization\ncapacity and knowledge reservoir. Extensive experiments showcase the impressive\nperformance of our unified representation approach across various tasks,\nsurpassing existing methodologies. Furthermore, our approach exhibits\nexceptional scalability and generality. Our code, model, and dataset will be\navailable at \\url{https://github.com/lzw-lzw/UnifiedMLLM}.", "paper_summary_zh": "<paragraph>\u6700\u8fd1\uff0c\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b (MLLM) \u9886\u57df\u53d6\u5f97\u4e86\u91cd\u5927\u8fdb\u5c55\uff0c\u5c55\u793a\u4e86\u5b83\u4eec\u5728\u7406\u89e3\u548c\u63a8\u7406\u5404\u79cd\u4efb\u52a1\u65b9\u9762\u7684\u5353\u8d8a\u80fd\u529b\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u6a21\u578b\u901a\u5e38\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u4f9d\u8d56\u4e8e\u7279\u5b9a\u4efb\u52a1\u7684\u8f93\u5165\u8f93\u51fa\u683c\u5f0f\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728\u66f4\u5e7f\u6cdb\u7684\u4efb\u52a1\u8303\u56f4\u5185\u7684\u9002\u7528\u6027\u3002\u8fd9\u5f15\u53d1\u4e86\u4e00\u4e2a\u57fa\u672c\u95ee\u9898\uff1a\u6211\u4eec\u80fd\u5426\u5f00\u53d1\u4e00\u79cd\u7edf\u4e00\u7684\u65b9\u6cd5\u6765\u8868\u793a\u548c\u5904\u7406\u4e0d\u540c\u7684\u591a\u6a21\u6001\u4efb\u52a1\uff0c\u4ee5\u6700\u5927\u5316 MLLM \u7684\u6cdb\u5316\u80fd\u529b\uff1f\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 UnifiedMLLM\uff0c\u8fd9\u662f\u4e00\u4e2a\u7efc\u5408\u6a21\u578b\uff0c\u65e8\u5728\u4f7f\u7528\u7edf\u4e00\u8868\u793a\u6765\u8868\u793a\u5404\u79cd\u4efb\u52a1\u3002\u6211\u4eec\u7684\u6a21\u578b\u5728\u7406\u89e3\u7528\u6237\u6307\u4ee4\u7684\u9690\u542b\u610f\u56fe\u548c\u8fdb\u884c\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u80fd\u529b\u3002\u9664\u4e86\u751f\u6210\u6587\u672c\u54cd\u5e94\u4e4b\u5916\uff0c\u6211\u4eec\u7684\u6a21\u578b\u8fd8\u8f93\u51fa\u4efb\u52a1\u6807\u8bb0\u548c\u57fa\u7840\u6807\u8bb0\uff0c\u4f5c\u4e3a\u4efb\u52a1\u7c7b\u578b\u548c\u4efb\u52a1\u7c92\u5ea6\u7684\u6307\u6807\u3002\u8fd9\u4e9b\u8f93\u51fa\u968f\u540e\u901a\u8fc7\u4efb\u52a1\u8def\u7531\u5668\u8def\u7531\uff0c\u5e76\u5b9a\u5411\u5230\u7279\u5b9a\u4e13\u5bb6\u6a21\u578b\u4ee5\u5b8c\u6210\u4efb\u52a1\u3002\u4e3a\u4e86\u8bad\u7ec3\u6211\u4eec\u7684\u6a21\u578b\uff0c\u6211\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u7279\u5b9a\u4e8e\u4efb\u52a1\u7684\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u5305\u542b\u590d\u6742\u573a\u666f\u7684 100k \u591a\u4efb\u52a1\u6570\u636e\u96c6\u3002\u91c7\u7528\u4e09\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0c\u6211\u4eec\u4e3a\u6211\u4eec\u7684\u6a21\u578b\u914d\u5907\u4e86\u5f3a\u5927\u7684\u63a8\u7406\u548c\u4efb\u52a1\u5904\u7406\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u5b83\u7684\u6cdb\u5316\u80fd\u529b\u548c\u77e5\u8bc6\u50a8\u5907\u3002\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u5c55\u793a\u4e86\u6211\u4eec\u7684\u7edf\u4e00\u8868\u793a\u65b9\u6cd5\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u7684\u51fa\u8272\u8868\u73b0\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u53ef\u6269\u5c55\u6027\u548c\u901a\u7528\u6027\u3002\u6211\u4eec\u7684\u4ee3\u7801\u3001\u6a21\u578b\u548c\u6570\u636e\u96c6\u5c06\u5728 \\url{https://github.com/lzw-lzw/UnifiedMLLM} \u4e0a\u63d0\u4f9b\u3002</paragraph>", "author": "Zhaowei Li et.al.", "authors": "Zhaowei Li, Wei Wang, YiQing Cai, Xu Qi, Pengyu Wang, Dong Zhang, Hang Song, Botian Jiang, Zhida Huang, Tao Wang", "id": "2408.02503v1", "paper_url": "http://arxiv.org/abs/2408.02503v1", "repo": "null"}}