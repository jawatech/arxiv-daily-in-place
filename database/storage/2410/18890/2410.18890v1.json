{"2410.18890": {"publish_time": "2024-10-24", "title": "Improving Small-Scale Large Language Models Function Calling for Reasoning Tasks", "paper_summary": "Recent advancements in Large Language Models (LLMs) have demonstrated\nexceptional capabilities in natural language understanding and generation.\nWhile these models excel in general complex reasoning tasks, they still face\nchallenges in mathematical problem-solving and logical reasoning. To address\nthese limitations, researchers have explored function calling abilities,\nallowing LLMs to execute provided functions and utilize their outputs for task\ncompletion. However, concentrating on specific tasks can be very inefficient\nfor large-scale LLMs to be used, because of the expensive cost of training and\ninference stages they need in terms of computational resources. This study\nintroduces a novel framework for training smaller language models in function\ncalling, focusing on specific logical and mathematical reasoning tasks. The\napproach aims to improve performances of small-scale models for these tasks\nusing function calling, ensuring a high level of accuracy. Our framework\nemploys an agent that, given a problem and a set of callable functions, queries\nthe LLM by injecting a description and examples of the usable functions into\nthe prompt and managing their calls in a step-by-step reasoning chain. This\nprocess is used to create a dataset of correct and incorrect reasoning chain\nchat completions from a large-scale LLM. This dataset is used to train a\nsmaller LLM using Reinforcement Learning from Human Feedback (RLHF),\nspecifically employing the Direct Preference Optimization (DPO) technique.\nExperimental results demonstrate how the proposed approach balances the\ntrade-off between model size and performance, improving the ability of function\ncalling for reasoning tasks, in smaller models.", "paper_summary_zh": "<paragraph>\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u6700\u65b0\u9032\u5c55\u5df2\u8b49\u660e\u5728\u81ea\u7136\u8a9e\u8a00\u7406\u89e3\u548c\u751f\u6210\u65b9\u9762\u5177\u6709\u975e\u51e1\u7684\u80fd\u529b\u3002\u96d6\u7136\u9019\u4e9b\u6a21\u578b\u5728\u4e00\u822c\u8907\u96dc\u63a8\u7406\u4efb\u52d9\u4e2d\u8868\u73fe\u51fa\u8272\uff0c\u4f46\u5b83\u5011\u5728\u6578\u5b78\u554f\u984c\u89e3\u6c7a\u548c\u908f\u8f2f\u63a8\u7406\u65b9\u9762\u4ecd\u7136\u9762\u81e8\u6311\u6230\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u9650\u5236\uff0c\u7814\u7a76\u4eba\u54e1\u63a2\u7d22\u4e86\u51fd\u6578\u547c\u53eb\u80fd\u529b\uff0c\u5141\u8a31 LLM \u57f7\u884c\u63d0\u4f9b\u7684\u51fd\u6578\u4e26\u5229\u7528\u5176\u8f38\u51fa\u9032\u884c\u4efb\u52d9\u5b8c\u6210\u3002\u7136\u800c\uff0c\u5c08\u6ce8\u65bc\u7279\u5b9a\u4efb\u52d9\u5c0d\u65bc\u4f7f\u7528\u5927\u898f\u6a21 LLM \u4f86\u8aaa\u53ef\u80fd\u975e\u5e38\u4f4e\u6548\uff0c\u56e0\u70ba\u5b83\u5011\u5728\u8a08\u7b97\u8cc7\u6e90\u65b9\u9762\u9700\u8981\u6602\u8cb4\u7684\u8a13\u7df4\u548c\u63a8\u7406\u968e\u6bb5\u6210\u672c\u3002\u672c\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u500b\u65b0\u6846\u67b6\uff0c\u7528\u65bc\u8a13\u7df4\u51fd\u6578\u547c\u53eb\u4e2d\u7684\u8f03\u5c0f\u8a9e\u8a00\u6a21\u578b\uff0c\u91cd\u9ede\u95dc\u6ce8\u5177\u9ad4\u7684\u908f\u8f2f\u548c\u6578\u5b78\u63a8\u7406\u4efb\u52d9\u3002\u8a72\u65b9\u6cd5\u65e8\u5728\u4f7f\u7528\u51fd\u6578\u547c\u53eb\u6539\u5584\u5c0f\u898f\u6a21\u6a21\u578b\u5c0d\u9019\u4e9b\u4efb\u52d9\u7684\u6027\u80fd\uff0c\u78ba\u4fdd\u9ad8\u6e96\u78ba\u5ea6\u3002\u6211\u5011\u7684\u6846\u67b6\u63a1\u7528\u4e86\u4e00\u500b\u4ee3\u7406\uff0c\u7d66\u5b9a\u4e00\u500b\u554f\u984c\u548c\u4e00\u7d44\u53ef\u547c\u53eb\u51fd\u6578\uff0c\u901a\u904e\u5c07\u53ef\u7528\u51fd\u6578\u7684\u63cf\u8ff0\u548c\u7bc4\u4f8b\u6ce8\u5165\u63d0\u793a\u4e2d\u4e26\u9010\u6b65\u63a8\u7406\u93c8\u4e2d\u7ba1\u7406\u5176\u547c\u53eb\uff0c\u5c0d LLM \u9032\u884c\u67e5\u8a62\u3002\u6b64\u6d41\u7a0b\u7528\u65bc\u5f9e\u5927\u898f\u6a21 LLM \u5275\u5efa\u6b63\u78ba\u548c\u4e0d\u6b63\u78ba\u63a8\u7406\u93c8\u804a\u5929\u5b8c\u6210\u9805\u76ee\u7684\u8cc7\u6599\u96c6\u3002\u6b64\u8cc7\u6599\u96c6\u7528\u65bc\u4f7f\u7528\u4eba\u985e\u56de\u994b\u5f37\u5316\u5b78\u7fd2 (RLHF) \u8a13\u7df4\u8f03\u5c0f\u7684 LLM\uff0c\u7279\u5225\u662f\u63a1\u7528\u76f4\u63a5\u504f\u597d\u6700\u4f73\u5316 (DPO) \u6280\u8853\u3002\u5be6\u9a57\u7d50\u679c\u8b49\u660e\u4e86\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5982\u4f55\u5e73\u8861\u6a21\u578b\u5927\u5c0f\u548c\u6027\u80fd\u4e4b\u9593\u7684\u53d6\u6368\uff0c\u5728\u8f03\u5c0f\u7684\u6a21\u578b\u4e2d\u63d0\u9ad8\u51fd\u6578\u547c\u53eb\u63a8\u7406\u4efb\u52d9\u7684\u80fd\u529b\u3002</paragraph>", "author": "Graziano A. Manduzio et.al.", "authors": "Graziano A. Manduzio, Federico A. Galatolo, Mario G. C. A. Cimino, Enzo Pasquale Scilingo, Lorenzo Cominelli", "id": "2410.18890v1", "paper_url": "http://arxiv.org/abs/2410.18890v1", "repo": "null"}}