{"2409.07054": {"publish_time": "2024-09-11", "title": "Native vs Non-Native Language Prompting: A Comparative Analysis", "paper_summary": "Large language models (LLMs) have shown remarkable abilities in different\nfields, including standard Natural Language Processing (NLP) tasks. To elicit\nknowledge from LLMs, prompts play a key role, consisting of natural language\ninstructions. Most open and closed source LLMs are trained on available labeled\nand unlabeled resources--digital content such as text, images, audio, and\nvideos. Hence, these models have better knowledge for high-resourced languages\nbut struggle with low-resourced languages. Since prompts play a crucial role in\nunderstanding their capabilities, the language used for prompts remains an\nimportant research question. Although there has been significant research in\nthis area, it is still limited, and less has been explored for medium to\nlow-resourced languages. In this study, we investigate different prompting\nstrategies (native vs. non-native) on 11 different NLP tasks associated with 12\ndifferent Arabic datasets (9.7K data points). In total, we conducted 197\nexperiments involving 3 LLMs, 12 datasets, and 3 prompting strategies. Our\nfindings suggest that, on average, the non-native prompt performs the best,\nfollowed by mixed and native prompts.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u4e0d\u540c\u9818\u57df\u5c55\u73fe\u51fa\u975e\u51e1\u7684\u80fd\u529b\uff0c\u5305\u62ec\u6a19\u6e96\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u4efb\u52d9\u3002\u70ba\u4e86\u5f9e LLM \u7372\u53d6\u77e5\u8b58\uff0c\u63d0\u793a\u626e\u6f14\u4e86\u95dc\u9375\u89d2\u8272\uff0c\u5305\u542b\u81ea\u7136\u8a9e\u8a00\u6307\u4ee4\u3002\u5927\u591a\u6578\u958b\u653e\u548c\u5c01\u9589\u539f\u59cb\u78bc LLM \u90fd\u5728\u53ef\u7528\u7684\u6a19\u8a18\u548c\u672a\u6a19\u8a18\u8cc7\u6e90\uff08\u6578\u4f4d\u5167\u5bb9\uff0c\u4f8b\u5982\u6587\u5b57\u3001\u5f71\u50cf\u3001\u97f3\u8a0a\u548c\u5f71\u7247\uff09\u4e0a\u9032\u884c\u8a13\u7df4\u3002\u56e0\u6b64\uff0c\u9019\u4e9b\u6a21\u578b\u5c0d\u65bc\u9ad8\u8cc7\u6e90\u8a9e\u8a00\u6709\u66f4\u597d\u7684\u77e5\u8b58\uff0c\u4f46\u5728\u4f4e\u8cc7\u6e90\u8a9e\u8a00\u4e0a\u537b\u5f88\u5403\u529b\u3002\u7531\u65bc\u63d0\u793a\u5728\u7406\u89e3\u5176\u529f\u80fd\u4e2d\u626e\u6f14\u4e86\u81f3\u95dc\u91cd\u8981\u7684\u89d2\u8272\uff0c\u56e0\u6b64\u7528\u65bc\u63d0\u793a\u7684\u8a9e\u8a00\u4ecd\u7136\u662f\u4e00\u500b\u91cd\u8981\u7684\u7814\u7a76\u554f\u984c\u3002\u5118\u7ba1\u9019\u500b\u9818\u57df\u6709\u8a31\u591a\u91cd\u8981\u7684\u7814\u7a76\uff0c\u4f46\u4ecd\u6709\u9650\uff0c\u800c\u4e14\u5c0d\u65bc\u4e2d\u4f4e\u8cc7\u6e90\u8a9e\u8a00\u7684\u7814\u7a76\u8f03\u5c11\u3002\u5728\u9019\u9805\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u91dd\u5c0d 12 \u500b\u4e0d\u540c\u7684\u963f\u62c9\u4f2f\u8a9e\u8cc7\u6599\u96c6\uff089.7K \u8cc7\u6599\u9ede\uff09\u7684 11 \u500b\u4e0d\u540c NLP \u4efb\u52d9\u7814\u7a76\u4e0d\u540c\u7684\u63d0\u793a\u7b56\u7565\uff08\u6bcd\u8a9e vs. \u975e\u6bcd\u8a9e\uff09\u3002\u7e3d\u5171\u9032\u884c\u4e86 197 \u6b21\u5be6\u9a57\uff0c\u6d89\u53ca 3 \u500b LLM\u300112 \u500b\u8cc7\u6599\u96c6\u548c 3 \u500b\u63d0\u793a\u7b56\u7565\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u8868\u660e\uff0c\u5e73\u5747\u800c\u8a00\uff0c\u975e\u6bcd\u8a9e\u63d0\u793a\u8868\u73fe\u6700\u4f73\uff0c\u5176\u6b21\u662f\u6df7\u5408\u548c\u6bcd\u8a9e\u63d0\u793a\u3002", "author": "Mohamed Bayan Kmainasi et.al.", "authors": "Mohamed Bayan Kmainasi, Rakif Khan, Ali Ezzat Shahroor, Boushra Bendou, Maram Hasanain, Firoj Alam", "id": "2409.07054v1", "paper_url": "http://arxiv.org/abs/2409.07054v1", "repo": "null"}}