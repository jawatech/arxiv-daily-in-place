{"2409.02561": {"publish_time": "2024-09-04", "title": "Vision-Language Navigation with Continual Learning", "paper_summary": "Vision-language navigation (VLN) is a critical domain within embedded\nintelligence, requiring agents to navigate 3D environments based on natural\nlanguage instructions. Traditional VLN research has focused on improving\nenvironmental understanding and decision accuracy. However, these approaches\noften exhibit a significant performance gap when agents are deployed in novel\nenvironments, mainly due to the limited diversity of training data. Expanding\ndatasets to cover a broader range of environments is impractical and costly. We\npropose the Vision-Language Navigation with Continual Learning (VLNCL) paradigm\nto address this challenge. In this paradigm, agents incrementally learn new\nenvironments while retaining previously acquired knowledge. VLNCL enables\nagents to maintain an environmental memory and extract relevant knowledge,\nallowing rapid adaptation to new environments while preserving existing\ninformation. We introduce a novel dual-loop scenario replay method (Dual-SR)\ninspired by brain memory replay mechanisms integrated with VLN agents. This\nmethod facilitates consolidating past experiences and enhances generalization\nacross new tasks. By utilizing a multi-scenario memory buffer, the agent\nefficiently organizes and replays task memories, thereby bolstering its ability\nto adapt quickly to new environments and mitigating catastrophic forgetting.\nOur work pioneers continual learning in VLN agents, introducing a novel\nexperimental setup and evaluation metrics. We demonstrate the effectiveness of\nour approach through extensive evaluations and establish a benchmark for the\nVLNCL paradigm. Comparative experiments with existing continual learning and\nVLN methods show significant improvements, achieving state-of-the-art\nperformance in continual learning ability and highlighting the potential of our\napproach in enabling rapid adaptation while preserving prior knowledge.", "paper_summary_zh": "\u8996\u89ba\u8a9e\u8a00\u5c0e\u822a (VLN) \u662f\u5d4c\u5165\u5f0f\u667a\u6167\u4e2d\u7684\u4e00\u500b\u95dc\u9375\u9818\u57df\uff0c\u8981\u6c42\u4ee3\u7406\u6839\u64da\u81ea\u7136\u8a9e\u8a00\u6307\u4ee4\u5728 3D \u74b0\u5883\u4e2d\u5c0e\u822a\u3002\u50b3\u7d71\u7684 VLN \u7814\u7a76\u4e00\u76f4\u5c08\u6ce8\u65bc\u6539\u5584\u74b0\u5883\u7406\u89e3\u548c\u6c7a\u7b56\u6e96\u78ba\u5ea6\u3002\u7136\u800c\uff0c\u7576\u4ee3\u7406\u90e8\u7f72\u5728\u65b0\u7684\u74b0\u5883\u4e2d\u6642\uff0c\u9019\u4e9b\u65b9\u6cd5\u7d93\u5e38\u8868\u73fe\u51fa\u986f\u8457\u7684\u6548\u80fd\u5dee\u8ddd\uff0c\u9019\u4e3b\u8981\u662f\u56e0\u70ba\u8a13\u7df4\u8cc7\u6599\u7684\u591a\u6a23\u6027\u6709\u9650\u3002\u64f4\u5c55\u8cc7\u6599\u96c6\u4ee5\u6db5\u84cb\u66f4\u5ee3\u6cdb\u7684\u74b0\u5883\u65e2\u4e0d\u5207\u5be6\u969b\u53c8\u6602\u8cb4\u3002\u6211\u5011\u63d0\u51fa\u5177\u5099\u6301\u7e8c\u5b78\u7fd2\u7684\u8996\u89ba\u8a9e\u8a00\u5c0e\u822a (VLNCL) \u5178\u7bc4\u4f86\u61c9\u5c0d\u9019\u4e00\u6311\u6230\u3002\u5728\u6b64\u5178\u7bc4\u4e2d\uff0c\u4ee3\u7406\u9010\u6f38\u5b78\u7fd2\u65b0\u7684\u74b0\u5883\uff0c\u540c\u6642\u4fdd\u7559\u5148\u524d\u7372\u5f97\u7684\u77e5\u8b58\u3002VLNCL \u4f7f\u4ee3\u7406\u80fd\u5920\u7dad\u8b77\u74b0\u5883\u8a18\u61b6\u9ad4\u4e26\u63d0\u53d6\u76f8\u95dc\u77e5\u8b58\uff0c\u5f9e\u800c\u5141\u8a31\u5feb\u901f\u9069\u61c9\u65b0\u74b0\u5883\uff0c\u540c\u6642\u4fdd\u7559\u73fe\u6709\u8cc7\u8a0a\u3002\u6211\u5011\u5f15\u5165\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u96d9\u8ff4\u8def\u5834\u666f\u91cd\u64ad\u65b9\u6cd5 (Dual-SR)\uff0c\u5176\u9748\u611f\u4f86\u81ea\u8207 VLN \u4ee3\u7406\u6574\u5408\u7684\u8166\u8a18\u61b6\u91cd\u64ad\u6a5f\u5236\u3002\u6b64\u65b9\u6cd5\u6709\u52a9\u65bc\u6574\u5408\u904e\u53bb\u7684\u7d93\u9a57\u4e26\u589e\u5f37\u8de8\u65b0\u4efb\u52d9\u7684\u6982\u62ec\u6027\u3002\u900f\u904e\u5229\u7528\u591a\u5834\u666f\u8a18\u61b6\u9ad4\u7de9\u885d\u5340\uff0c\u4ee3\u7406\u6709\u6548\u5730\u7d44\u7e54\u548c\u91cd\u64ad\u4efb\u52d9\u8a18\u61b6\u9ad4\uff0c\u5f9e\u800c\u589e\u5f37\u5176\u5feb\u901f\u9069\u61c9\u65b0\u74b0\u5883\u548c\u6e1b\u8f15\u707d\u96e3\u6027\u907a\u5fd8\u7684\u80fd\u529b\u3002\u6211\u5011\u7684\u7814\u7a76\u958b\u5275\u4e86 VLN \u4ee3\u7406\u4e2d\u7684\u6301\u7e8c\u5b78\u7fd2\uff0c\u5f15\u5165\u4e86\u65b0\u7a4e\u7684\u5be6\u9a57\u8a2d\u7f6e\u548c\u8a55\u4f30\u6307\u6a19\u3002\u6211\u5011\u900f\u904e\u5ee3\u6cdb\u7684\u8a55\u4f30\u8b49\u660e\u4e86\u6211\u5011\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4e26\u70ba VLNCL \u5178\u7bc4\u5efa\u7acb\u4e86\u4e00\u500b\u57fa\u6e96\u3002\u8207\u73fe\u6709\u7684\u6301\u7e8c\u5b78\u7fd2\u548c VLN \u65b9\u6cd5\u9032\u884c\u7684\u6bd4\u8f03\u5be6\u9a57\u986f\u793a\u51fa\u986f\u8457\u7684\u6539\u9032\uff0c\u5728\u6301\u7e8c\u5b78\u7fd2\u80fd\u529b\u65b9\u9762\u53d6\u5f97\u4e86\u6700\u5148\u9032\u7684\u6548\u80fd\uff0c\u4e26\u7a81\u51fa\u4e86\u6211\u5011\u65b9\u6cd5\u5728\u4fdd\u7559\u5148\u524d\u77e5\u8b58\u7684\u540c\u6642\u5be6\u73fe\u5feb\u901f\u9069\u61c9\u7684\u6f5b\u529b\u3002", "author": "Zhiyuan Li et.al.", "authors": "Zhiyuan Li, Yanfeng Lv, Ziqin Tu, Di Shang, Hong Qiao", "id": "2409.02561v1", "paper_url": "http://arxiv.org/abs/2409.02561v1", "repo": "null"}}