{"2503.14503": {"publish_time": "2025-03-18", "title": "The Power of Context: How Multimodality Improves Image Super-Resolution", "paper_summary": "Single-image super-resolution (SISR) remains challenging due to the inherent\ndifficulty of recovering fine-grained details and preserving perceptual quality\nfrom low-resolution inputs. Existing methods often rely on limited image\npriors, leading to suboptimal results. We propose a novel approach that\nleverages the rich contextual information available in multiple modalities --\nincluding depth, segmentation, edges, and text prompts -- to learn a powerful\ngenerative prior for SISR within a diffusion model framework. We introduce a\nflexible network architecture that effectively fuses multimodal information,\naccommodating an arbitrary number of input modalities without requiring\nsignificant modifications to the diffusion process. Crucially, we mitigate\nhallucinations, often introduced by text prompts, by using spatial information\nfrom other modalities to guide regional text-based conditioning. Each\nmodality's guidance strength can also be controlled independently, allowing\nsteering outputs toward different directions, such as increasing bokeh through\ndepth or adjusting object prominence via segmentation. Extensive experiments\ndemonstrate that our model surpasses state-of-the-art generative SISR methods,\nachieving superior visual quality and fidelity. See project page at\nhttps://mmsr.kfmei.com/.", "paper_summary_zh": "<paragraph>\u55ae\u5f71\u50cf\u8d85\u89e3\u6790\u5ea6 (SISR) \u4ecd\u7136\u662f\u4e00\u9805\u6311\u6230\uff0c\u56e0\u70ba\u5f9e\u4f4e\u89e3\u6790\u5ea6\u8f38\u5165\u4e2d\u6062\u5fa9\u7d30\u7dfb\u7d30\u7bc0\u4e26\u4fdd\u6301\u611f\u77e5\u54c1\u8cea\u5b58\u5728\u56fa\u6709\u7684\u96e3\u5ea6\u3002\u73fe\u6709\u65b9\u6cd5\u901a\u5e38\u4f9d\u8cf4\u6709\u9650\u7684\u5f71\u50cf\u5148\u9a57\u77e5\u8b58\uff0c\u5c0e\u81f4\u7d50\u679c\u4e0d\u7406\u60f3\u3002\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u65b9\u6cd5\uff0c\u5b83\u5229\u7528\u591a\u7a2e\u6a21\u614b\u4e2d\u8c50\u5bcc\u7684\u4e0a\u4e0b\u6587\u8cc7\u8a0a\u2014\u2014\u5305\u62ec\u6df1\u5ea6\u3001\u5206\u5272\u3001\u908a\u7de3\u548c\u6587\u5b57\u63d0\u793a\u2014\u2014\u5728\u64f4\u6563\u6a21\u578b\u6846\u67b6\u5167\u5b78\u7fd2 SISR \u7684\u5f37\u5927\u751f\u6210\u5148\u9a57\u77e5\u8b58\u3002\u6211\u5011\u5f15\u5165\u4e86\u4e00\u7a2e\u9748\u6d3b\u7684\u7db2\u8def\u67b6\u69cb\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u878d\u5408\u591a\u6a21\u614b\u8cc7\u8a0a\uff0c\u9069\u61c9\u4efb\u610f\u6578\u91cf\u7684\u8f38\u5165\u6a21\u614b\uff0c\u800c\u7121\u9700\u5c0d\u64f4\u6563\u904e\u7a0b\u9032\u884c\u91cd\u5927\u4fee\u6539\u3002\u81f3\u95dc\u91cd\u8981\u7684\u662f\uff0c\u6211\u5011\u900f\u904e\u4f7f\u7528\u4f86\u81ea\u5176\u4ed6\u6a21\u614b\u7684\u7a7a\u9593\u8cc7\u8a0a\u4f86\u5f15\u5c0e\u5340\u57df\u6587\u5b57\u689d\u4ef6\uff0c\u5f9e\u800c\u6e1b\u8f15\u4e86\u6587\u5b57\u63d0\u793a\u7d93\u5e38\u5f15\u5165\u7684\u5e7b\u89ba\u3002\u6bcf\u500b\u6a21\u614b\u7684\u5f15\u5c0e\u5f37\u5ea6\u4e5f\u53ef\u4ee5\u7368\u7acb\u63a7\u5236\uff0c\u5141\u8a31\u5c07\u8f38\u51fa\u5f15\u5c0e\u5230\u4e0d\u540c\u7684\u65b9\u5411\uff0c\u4f8b\u5982\u900f\u904e\u6df1\u5ea6\u589e\u52a0\u6563\u666f\u6216\u900f\u904e\u5206\u5272\u8abf\u6574\u5c0d\u8c61\u7684\u7a81\u51fa\u7a0b\u5ea6\u3002\u5927\u91cf\u5be6\u9a57\u8868\u660e\uff0c\u6211\u5011\u7684\u6a21\u578b\u8d85\u8d8a\u4e86\u6700\u5148\u9032\u7684\u751f\u6210\u5f0f SISR \u65b9\u6cd5\uff0c\u5be6\u73fe\u4e86\u5353\u8d8a\u7684\u8996\u89ba\u54c1\u8cea\u548c\u4fdd\u771f\u5ea6\u3002\u8acb\u53c3\u95b1\u5c08\u6848\u9801\u9762\uff1ahttps://mmsr.kfmei.com/\u3002</paragraph>\n", "author": "Kangfu Mei et.al.", "authors": "Kangfu Mei, Hossein Talebi, Mojtaba Ardakani, Vishal M. Patel, Peyman Milanfar, Mauricio Delbracio", "id": "2503.14503v1", "paper_url": "http://arxiv.org/abs/2503.14503v1", "repo": "null"}}