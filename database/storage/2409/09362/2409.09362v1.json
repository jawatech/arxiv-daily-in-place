{"2409.09362": {"publish_time": "2024-09-14", "title": "Generating Event-oriented Attribution for Movies via Two-Stage Prefix-Enhanced Multimodal LLM", "paper_summary": "The prosperity of social media platforms has raised the urgent demand for\nsemantic-rich services, e.g., event and storyline attribution. However, most\nexisting research focuses on clip-level event understanding, primarily through\nbasic captioning tasks, without analyzing the causes of events across an entire\nmovie. This is a significant challenge, as even advanced multimodal large\nlanguage models (MLLMs) struggle with extensive multimodal information due to\nlimited context length. To address this issue, we propose a Two-Stage\nPrefix-Enhanced MLLM (TSPE) approach for event attribution, i.e., connecting\nassociated events with their causal semantics, in movie videos. In the local\nstage, we introduce an interaction-aware prefix that guides the model to focus\non the relevant multimodal information within a single clip, briefly\nsummarizing the single event. Correspondingly, in the global stage, we\nstrengthen the connections between associated events using an inferential\nknowledge graph, and design an event-aware prefix that directs the model to\nfocus on associated events rather than all preceding clips, resulting in\naccurate event attribution. Comprehensive evaluations of two real-world\ndatasets demonstrate that our framework outperforms state-of-the-art methods.", "paper_summary_zh": "\u793e\u7fa4\u5a92\u9ad4\u5e73\u53f0\u7684\u84ec\u52c3\u767c\u5c55\uff0c\u63d0\u5347\u4e86\u5c0d\u8a9e\u610f\u8c50\u5bcc\u670d\u52d9\uff08\u4f8b\u5982\u4e8b\u4ef6\u548c\u6545\u4e8b\u7dda\u6b78\u56e0\uff09\u7684\u8feb\u5207\u9700\u6c42\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684\u7814\u7a76\u5927\u591a\u8457\u91cd\u65bc\u7247\u6bb5\u5c64\u7d1a\u7684\u4e8b\u4ef6\u7406\u89e3\uff0c\u4e3b\u8981\u662f\u900f\u904e\u57fa\u790e\u7684\u5b57\u5e55\u4efb\u52d9\uff0c\u800c\u672a\u5206\u6790\u6574\u90e8\u96fb\u5f71\u4e2d\u4e8b\u4ef6\u767c\u751f\u7684\u539f\u56e0\u3002\u9019\u662f\u4e00\u500b\u91cd\u5927\u7684\u6311\u6230\uff0c\u56e0\u70ba\u5373\u4f7f\u662f\u9032\u968e\u7684\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM) \u4e5f\u6703\u56e0\u70ba\u53d7\u9650\u7684\u8108\u7d61\u9577\u5ea6\u800c\u96e3\u4ee5\u8655\u7406\u5ee3\u6cdb\u7684\u591a\u6a21\u614b\u8cc7\u8a0a\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u5169\u968e\u6bb5\u524d\u7f6e\u8a5e\u589e\u5f37 MLLM (TSPE) \u65b9\u6cd5\uff0c\u7528\u65bc\u96fb\u5f71\u5f71\u7247\u4e2d\u7684\u4e8b\u4ef6\u6b78\u56e0\uff0c\u4e5f\u5c31\u662f\u5c07\u76f8\u95dc\u4e8b\u4ef6\u8207\u5176\u56e0\u679c\u8a9e\u610f\u9023\u7d50\u8d77\u4f86\u3002\u5728\u5c40\u90e8\u968e\u6bb5\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u4e92\u52d5\u611f\u77e5\u524d\u7f6e\u8a5e\uff0c\u5f15\u5c0e\u6a21\u578b\u5c08\u6ce8\u65bc\u55ae\u4e00\u7247\u6bb5\u4e2d\u7684\u76f8\u95dc\u591a\u6a21\u614b\u8cc7\u8a0a\uff0c\u7c21\u8981\u5730\u7e3d\u7d50\u55ae\u4e00\u4e8b\u4ef6\u3002\u76f8\u61c9\u5730\uff0c\u5728\u6574\u9ad4\u968e\u6bb5\uff0c\u6211\u5011\u4f7f\u7528\u63a8\u7406\u77e5\u8b58\u5716\u8b5c\u5f37\u5316\u76f8\u95dc\u4e8b\u4ef6\u4e4b\u9593\u7684\u9023\u7d50\uff0c\u4e26\u8a2d\u8a08\u4e86\u4e00\u500b\u4e8b\u4ef6\u611f\u77e5\u524d\u7f6e\u8a5e\uff0c\u5f15\u5c0e\u6a21\u578b\u5c08\u6ce8\u65bc\u76f8\u95dc\u4e8b\u4ef6\uff0c\u800c\u975e\u6240\u6709\u524d\u7f6e\u7247\u6bb5\uff0c\u9032\u800c\u7522\u751f\u6e96\u78ba\u7684\u4e8b\u4ef6\u6b78\u56e0\u3002\u5c0d\u5169\u500b\u771f\u5be6\u4e16\u754c\u8cc7\u6599\u96c6\u7684\u5168\u9762\u8a55\u4f30\u986f\u793a\uff0c\u6211\u5011\u7684\u67b6\u69cb\u512a\u65bc\u73fe\u6709\u7684\u6700\u5148\u9032\u65b9\u6cd5\u3002", "author": "Yuanjie Lyu et.al.", "authors": "Yuanjie Lyu, Tong Xu, Zihan Niu, Bo Peng, Jing Ke, Enhong Chen", "id": "2409.09362v1", "paper_url": "http://arxiv.org/abs/2409.09362v1", "repo": "null"}}