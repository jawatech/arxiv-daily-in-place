{"2502.08966": {"publish_time": "2025-02-13", "title": "RTBAS: Defending LLM Agents Against Prompt Injection and Privacy Leakage", "paper_summary": "Tool-Based Agent Systems (TBAS) allow Language Models (LMs) to use external\ntools for tasks beyond their standalone capabilities, such as searching\nwebsites, booking flights, or making financial transactions. However, these\ntools greatly increase the risks of prompt injection attacks, where malicious\ncontent hijacks the LM agent to leak confidential data or trigger harmful\nactions. Existing defenses (OpenAI GPTs) require user confirmation before every\ntool call, placing onerous burdens on users. We introduce Robust TBAS (RTBAS),\nwhich automatically detects and executes tool calls that preserve integrity and\nconfidentiality, requiring user confirmation only when these safeguards cannot\nbe ensured. RTBAS adapts Information Flow Control to the unique challenges\npresented by TBAS. We present two novel dependency screeners, using\nLM-as-a-judge and attention-based saliency, to overcome these challenges.\nExperimental results on the AgentDojo Prompt Injection benchmark show RTBAS\nprevents all targeted attacks with only a 2% loss of task utility when under\nattack, and further tests confirm its ability to obtain near-oracle performance\non detecting both subtle and direct privacy leaks.", "paper_summary_zh": "\u57fa\u65bc\u5de5\u5177\u7684\u4ee3\u7406\u7cfb\u7d71 (TBAS) \u5141\u8a31\u8a9e\u8a00\u6a21\u578b (LM) \u4f7f\u7528\u5916\u90e8\u5de5\u5177\u4f86\u57f7\u884c\u8d85\u51fa\u5176\u7368\u7acb\u529f\u80fd\u7684\u4efb\u52d9\uff0c\u4f8b\u5982\u641c\u5c0b\u7db2\u7ad9\u3001\u9810\u8a02\u822a\u73ed\u6216\u9032\u884c\u91d1\u878d\u4ea4\u6613\u3002\u7136\u800c\uff0c\u9019\u4e9b\u5de5\u5177\u5927\u5e45\u589e\u52a0\u4e86\u63d0\u793a\u6ce8\u5165\u653b\u64ca\u7684\u98a8\u96aa\uff0c\u5176\u4e2d\u60e1\u610f\u5167\u5bb9\u52ab\u6301 LM \u4ee3\u7406\u7a0b\u5f0f\u4ee5\u6d29\u9732\u6a5f\u5bc6\u8cc7\u6599\u6216\u89f8\u767c\u6709\u5bb3\u52d5\u4f5c\u3002\u73fe\u6709\u7684\u9632\u79a6\u63aa\u65bd (OpenAI GPT) \u5728\u6bcf\u6b21\u547c\u53eb\u5de5\u5177\u4e4b\u524d\u90fd\u9700\u8981\u4f7f\u7528\u8005\u78ba\u8a8d\uff0c\u9019\u6703\u5c0d\u4f7f\u7528\u8005\u9020\u6210\u6c89\u91cd\u7684\u8ca0\u64d4\u3002\u6211\u5011\u5f15\u5165\u4e86\u7a69\u5065\u7684 TBAS (RTBAS)\uff0c\u5b83\u6703\u81ea\u52d5\u5075\u6e2c\u4e26\u57f7\u884c\u4fdd\u7559\u5b8c\u6574\u6027\u8207\u6a5f\u5bc6\u6027\u7684\u5de5\u5177\u547c\u53eb\uff0c\u50c5\u5728\u7121\u6cd5\u78ba\u4fdd\u9019\u4e9b\u9632\u8b77\u63aa\u65bd\u6642\u624d\u9700\u8981\u4f7f\u7528\u8005\u78ba\u8a8d\u3002RTBAS \u5c07\u8cc7\u8a0a\u6d41\u63a7\u5236\u8abf\u6574\u70ba TBAS \u5448\u73fe\u7684\u7368\u7279\u6311\u6230\u3002\u6211\u5011\u63d0\u51fa\u5169\u7a2e\u65b0\u7a4e\u7684\u76f8\u4f9d\u6027\u7be9\u9078\u5668\uff0c\u4f7f\u7528 LM \u4f5c\u70ba\u5224\u65b7\u8005\u548c\u57fa\u65bc\u6ce8\u610f\u529b\u7684\u986f\u8457\u6027\uff0c\u4ee5\u514b\u670d\u9019\u4e9b\u6311\u6230\u3002AgentDojo \u63d0\u793a\u6ce8\u5165\u57fa\u6e96\u4e0a\u7684\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0cRTBAS \u5728\u53d7\u5230\u653b\u64ca\u6642\u50c5\u640d\u5931 2% \u7684\u4efb\u52d9\u6548\u7528\uff0c\u5373\u53ef\u9632\u6b62\u6240\u6709\u76ee\u6a19\u653b\u64ca\uff0c\u9032\u4e00\u6b65\u7684\u6e2c\u8a66\u8b49\u5be6\u4e86\u5176\u5728\u5075\u6e2c\u7d30\u5fae\u548c\u76f4\u63a5\u7684\u96b1\u79c1\u6d29\u6f0f\u65b9\u9762\u7372\u5f97\u63a5\u8fd1\u795e\u8aed\u6548\u80fd\u7684\u80fd\u529b\u3002", "author": "Peter Yong Zhong et.al.", "authors": "Peter Yong Zhong, Siyuan Chen, Ruiqi Wang, McKenna McCall, Ben L. Titzer, Heather Miller", "id": "2502.08966v1", "paper_url": "http://arxiv.org/abs/2502.08966v1", "repo": "null"}}