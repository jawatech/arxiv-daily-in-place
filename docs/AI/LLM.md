
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-22**|**LLMmap: Fingerprinting For Large Language Models**|Dario Pasquini et.al.|[2407.15847v1](http://arxiv.org/abs/2407.15847v1)|null|
|**2024-07-22**|**Reconstructing Training Data From Real World Models Trained with Transfer Learning**|Yakir Oz et.al.|[2407.15845v1](http://arxiv.org/abs/2407.15845v1)|null|
|**2024-07-22**|**CarFormer: Self-Driving with Learned Object-Centric Representations**|Shadi Hamdan et.al.|[2407.15843v1](http://arxiv.org/abs/2407.15843v1)|null|
|**2024-07-22**|**Importance Sampling-Guided Meta-Training for Intelligent Agents in Highly Interactive Environments**|Mansur Arief et.al.|[2407.15839v1](http://arxiv.org/abs/2407.15839v1)|null|
|**2024-07-22**|**Towards Latent Masked Image Modeling for Self-Supervised Visual Representation Learning**|Yibing Wei et.al.|[2407.15837v1](http://arxiv.org/abs/2407.15837v1)|[link](https://github.com/yibingwei-1/latentmim)|
|**2024-07-22**|**dMel: Speech Tokenization made Simple**|He Bai et.al.|[2407.15835v1](http://arxiv.org/abs/2407.15835v1)|null|
|**2024-07-22**|**NV-Retriever: Improving text embedding models with effective hard-negative mining**|Gabriel de Souza P. Moreira et.al.|[2407.15831v1](http://arxiv.org/abs/2407.15831v1)|null|
|**2024-07-22**|**J-CHAT: Japanese Large-scale Spoken Dialogue Corpus for Spoken Dialogue Language Modeling**|Wataru Nakata et.al.|[2407.15828v1](http://arxiv.org/abs/2407.15828v1)|null|
|**2024-07-22**|**Perceptions of Linguistic Uncertainty by Language Models and Humans**|Catarina G Belem et.al.|[2407.15814v1](http://arxiv.org/abs/2407.15814v1)|[link](https://github.com/ucidatalab/llm-uncertainty-perceptions)|
|**2024-07-22**|**Stretching Each Dollar: Diffusion Training from Scratch on a Micro-Budget**|Vikash Sehwag et.al.|[2407.15811v1](http://arxiv.org/abs/2407.15811v1)|null|
|**2024-07-22**|**FSboard: Over 3 million characters of ASL fingerspelling collected via smartphones**|Manfred Georg et.al.|[2407.15806v1](http://arxiv.org/abs/2407.15806v1)|null|
|**2024-07-22**|**CLIP with Generative Latent Replay: a Strong Baseline for Incremental Learning**|Emanuele Frascaroli et.al.|[2407.15793v1](http://arxiv.org/abs/2407.15793v1)|[link](https://github.com/aimagelab/mammoth)|
|**2024-07-22**|**Extracting Structured Insights from Financial News: An Augmented LLM Driven Approach**|Rian Dolphin et.al.|[2407.15788v1](http://arxiv.org/abs/2407.15788v1)|null|
|**2024-07-22**|**Concept-Based Interpretable Reinforcement Learning with Limited to No Human Labels**|Zhuorui Ye et.al.|[2407.15786v1](http://arxiv.org/abs/2407.15786v1)|null|
|**2024-07-22**|**Diffusion Model Based Resource Allocation Strategy in Ultra-Reliable Wireless Networked Control Systems**|Amirhassan Babazadeh Darabi et.al.|[2407.15784v1](http://arxiv.org/abs/2407.15784v1)|null|
|**2024-07-22**|**Explaining Decisions in ML Models: a Parameterized Complexity Analysis**|Sebastian Ordyniak et.al.|[2407.15780v1](http://arxiv.org/abs/2407.15780v1)|null|
|**2024-07-22**|**Local Occupancy-Enhanced Object Grasping with Multiple Triplanar Projection**|Kangqi Ma et.al.|[2407.15771v1](http://arxiv.org/abs/2407.15771v1)|null|
|**2024-07-22**|**Conditioned Language Policy: A General Framework for Steerable Multi-Objective Finetuning**|Kaiwen Wang et.al.|[2407.15762v1](http://arxiv.org/abs/2407.15762v1)|null|
|**2024-07-22**|**Model editing for distribution shifts in uranium oxide morphological analysis**|Davis Brown et.al.|[2407.15756v1](http://arxiv.org/abs/2407.15756v1)|null|
|**2024-07-22**|**LongVideoBench: A Benchmark for Long-context Interleaved Video-Language Understanding**|Haoning Wu et.al.|[2407.15754v1](http://arxiv.org/abs/2407.15754v1)|[link](https://github.com/longvideobench/longvideobench)|
|**2024-07-22**|**MoRSE: Bridging the Gap in Cybersecurity Expertise with Retrieval Augmented Generation**|Marco Simoni et.al.|[2407.15748v1](http://arxiv.org/abs/2407.15748v1)|null|
|**2024-07-22**|**Diffusion for Out-of-Distribution Detection on Road Scenes and Beyond**|Silvio Galesso et.al.|[2407.15739v1](http://arxiv.org/abs/2407.15739v1)|[link](https://github.com/lmb-freiburg/diffusion-for-ood)|
|**2024-07-22**|**Parallel Split Learning with Global Sampling**|Mohammad Kohankhaki et.al.|[2407.15738v1](http://arxiv.org/abs/2407.15738v1)|null|
|**2024-07-22**|**OMoS-QA: A Dataset for Cross-Lingual Extractive Question Answering in a German Migration Context**|Steffen Kleinle et.al.|[2407.15736v1](http://arxiv.org/abs/2407.15736v1)|null|
|**2024-07-22**|**TaskGen: A Task-Based, Memory-Infused Agentic Framework using StrictJSON**|John Chong Min Tan et.al.|[2407.15734v1](http://arxiv.org/abs/2407.15734v1)|null|
|**2024-07-22**|**DStruct2Design: Data and Benchmarks for Data Structure Driven Generative Floor Plan Design**|Zhi Hao Luo et.al.|[2407.15723v1](http://arxiv.org/abs/2407.15723v1)|[link](https://github.com/plstory/ds2d)|
|**2024-07-22**|**Do Large Language Models Have Compositional Ability? An Investigation into Limitations and Scalability**|Zhuoyan Xu et.al.|[2407.15720v1](http://arxiv.org/abs/2407.15720v1)|[link](https://github.com/oliverxuzy/llm_compose)|
|**2024-07-22**|**GFE-Mamba: Mamba-based AD Multi-modal Progression Assessment via Generative Feature Extraction from MCI**|Zhaojie Fang et.al.|[2407.15719v1](http://arxiv.org/abs/2407.15719v1)|[link](https://github.com/tinysqua/gfe-mamba)|
|**2024-07-22**|**Mamba meets crack segmentation**|Zhili He et.al.|[2407.15714v1](http://arxiv.org/abs/2407.15714v1)|[link](https://github.com/hzlbbfrog/crackmamba)|
|**2024-07-22**|**AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?**|Ori Yoran et.al.|[2407.15711v1](http://arxiv.org/abs/2407.15711v1)|null|
|**2024-07-22**|**SwinSF: Image Reconstruction from Spatial-Temporal Spike Streams**|Liangyan Jiang et.al.|[2407.15708v1](http://arxiv.org/abs/2407.15708v1)|null|
|**2024-07-22**|**Predicting the Best of N Visual Trackers**|Basit Alawode et.al.|[2407.15707v1](http://arxiv.org/abs/2407.15707v1)|null|
|**2024-07-22**|**Supporting the Digital Autonomy of Elders Through LLM Assistance**|Jesse Roberts et.al.|[2407.15695v1](http://arxiv.org/abs/2407.15695v1)|null|
|**2024-07-22**|**Counter Turing Test ($CT^2$): Investigating AI-Generated Text Detection for Hindi -- Ranking LLMs based on Hindi AI Detectability Index ($ADI_{hi}$)**|Ishan Kavathekar et.al.|[2407.15694v1](http://arxiv.org/abs/2407.15694v1)|null|
|**2024-07-22**|**AI-Driven Fast and Early Detection of IoT Botnet Threats: A Comprehensive Network Traffic Analysis Approach**|Abdelaziz Amara korba et.al.|[2407.15688v1](http://arxiv.org/abs/2407.15688v1)|null|
|**2024-07-22**|**HaloQuest: A Visual Hallucination Dataset for Advancing Multimodal Reasoning**|Zhecan Wang et.al.|[2407.15680v1](http://arxiv.org/abs/2407.15680v1)|null|
|**2024-07-22**|**Flow-guided Motion Prediction with Semantics and Dynamic Occupancy Grid Maps**|Rabbia Asghar et.al.|[2407.15675v1](http://arxiv.org/abs/2407.15675v1)|null|
|**2024-07-22**|**SLVideo: A Sign Language Video Moment Retrieval Framework**|Gonçalo Vinagre Martins et.al.|[2407.15668v1](http://arxiv.org/abs/2407.15668v1)|null|
|**2024-07-22**|**Psychometric Alignment: Capturing Human Knowledge Distributions via Language Models**|Joy He-Yueya et.al.|[2407.15645v1](http://arxiv.org/abs/2407.15645v1)|[link](https://github.com/joyheyueya/psychometric-alignment)|
|**2024-07-22**|**RadioRAG: Factual Large Language Models for Enhanced Diagnostics in Radiology Using Dynamic Retrieval Augmented Generation**|Soroosh Tayebi Arasteh et.al.|[2407.15621v1](http://arxiv.org/abs/2407.15621v1)|null|
|**2024-07-22**|**Can GPT-4 learn to analyze moves in research article abstracts?**|Danni Yu et.al.|[2407.15612v1](http://arxiv.org/abs/2407.15612v1)|null|
|**2024-07-22**|**StylusAI: Stylistic Adaptation for Robust German Handwritten Text Generation**|Nauman Riaz et.al.|[2407.15608v1](http://arxiv.org/abs/2407.15608v1)|null|
|**2024-07-22**|**A Pairwise Comparison Relation-assisted Multi-objective Evolutionary Neural Architecture Search Method with Multi-population Mechanism**|Yu Xue et.al.|[2407.15600v1](http://arxiv.org/abs/2407.15600v1)|null|
|**2024-07-22**|**Discrete Flow Matching**|Itai Gat et.al.|[2407.15595v1](http://arxiv.org/abs/2407.15595v1)|null|
|**2024-07-22**|**Unsupervised Robust Cross-Lingual Entity Alignment via Joint Modeling of Entity and Relation Texts**|Soojin Yoon et.al.|[2407.15588v1](http://arxiv.org/abs/2407.15588v1)|[link](https://github.com/eralign/eralign)|
|**2024-07-22**|**An Empirical Study of Retrieval Augmented Generation with Chain-of-Thought**|Yuetong Zhao et.al.|[2407.15569v1](http://arxiv.org/abs/2407.15569v1)|null|
|**2024-07-22**|**SETTP: Style Extraction and Tunable Inference via Dual-level Transferable Prompt Learning**|Chunzhen Jin et.al.|[2407.15556v1](http://arxiv.org/abs/2407.15556v1)|null|
|**2024-07-22**|**Targeted Latent Adversarial Training Improves Robustness to Persistent Harmful Behaviors in LLMs**|Abhay Sheshadri et.al.|[2407.15549v1](http://arxiv.org/abs/2407.15549v1)|null|
|**2024-07-22**|**Large-scale Time-Varying Portfolio Optimisation using Graph Attention Networks**|Kamesh Korangi et.al.|[2407.15532v1](http://arxiv.org/abs/2407.15532v1)|null|
|**2024-07-22**|**Interpretable Concept-Based Memory Reasoning**|David Debot et.al.|[2407.15527v1](http://arxiv.org/abs/2407.15527v1)|null|
|**2024-07-22**|**Synthetic Image Learning: Preserving Performance and Preventing Membership Inference Attacks**|Eugenio Lomurno et.al.|[2407.15526v1](http://arxiv.org/abs/2407.15526v1)|null|
|**2024-07-22**|**Future-Proofing Mobile Networks: A Digital Twin Approach to Multi-Signal Management**|Roberto Morabito et.al.|[2407.15520v1](http://arxiv.org/abs/2407.15520v1)|null|
|**2024-07-22**|**Attention Is All You Need But You Don't Need All Of It For Inference of Large Language Models**|Georgy Tyukin et.al.|[2407.15516v1](http://arxiv.org/abs/2407.15516v1)|null|
|**2024-07-22**|**Increasing the Robustness of Model Predictions to Missing Sensors in Earth Observation**|Francisco Mena et.al.|[2407.15512v1](http://arxiv.org/abs/2407.15512v1)|null|
|**2024-07-22**|**Compensate Quantization Errors+: Quantized Models Are Inquisitive Learners**|Yifei Gao et.al.|[2407.15508v1](http://arxiv.org/abs/2407.15508v1)|null|
|**2024-07-22**|**Fundamental Limits of Prompt Compression: A Rate-Distortion Framework for Black-Box Language Models**|Adway Girish et.al.|[2407.15504v1](http://arxiv.org/abs/2407.15504v1)|null|
|**2024-07-22**|**Refining Corpora from a Model Calibration Perspective for Chinese Spelling Correction**|Dingyao Yu et.al.|[2407.15498v1](http://arxiv.org/abs/2407.15498v1)|null|
|**2024-07-22**|**Two Stacks Are Better Than One: A Comparison of Language Modeling and Translation as Multilingual Pretraining Objectives**|Zihao Li et.al.|[2407.15489v1](http://arxiv.org/abs/2407.15489v1)|[link](https://github.com/helsinki-nlp/lm-vs-mt)|
|**2024-07-22**|**In-Context Learning Improves Compositional Understanding of Vision-Language Models**|Matteo Nulli et.al.|[2407.15487v1](http://arxiv.org/abs/2407.15487v1)|[link](https://github.com/hoezey/vlm-compositionality)|
|**2024-07-22**|**A Multi-Level Corroborative Approach for Verification and Validation of Autonomous Robotic Swarms**|Dhaminda B. Abeywickrama et.al.|[2407.15475v1](http://arxiv.org/abs/2407.15475v1)|null|
|**2024-07-22**|**Text-to-Battery Recipe: A language modeling-based protocol for automatic battery recipe extraction and retrieval**|Daeun Lee et.al.|[2407.15459v1](http://arxiv.org/abs/2407.15459v1)|null|
|**2024-07-22**|**Developing a Reliable, General-Purpose Hallucination Detection and Mitigation Service: Insights and Lessons Learned**|Song Wang et.al.|[2407.15441v1](http://arxiv.org/abs/2407.15441v1)|null|
|**2024-07-22**|**Pre-Training and Prompting for Few-Shot Node Classification on Text-Attributed Graphs**|Huanjing Zhao et.al.|[2407.15431v1](http://arxiv.org/abs/2407.15431v1)|null|
|**2024-07-22**|**Decoding BACnet Packets: A Large Language Model Approach for Packet Interpretation**|Rashi Sharma et.al.|[2407.15428v1](http://arxiv.org/abs/2407.15428v1)|null|
|**2024-07-22**|**YOLO-pdd: A Novel Multi-scale PCB Defect Detection Method Using Deep Representations with Sequential Images**|Bowen Liu et.al.|[2407.15427v1](http://arxiv.org/abs/2407.15427v1)|null|
|**2024-07-22**|**Empirical Capacity Model for Self-Attention Neural Networks**|Aki Härmä et.al.|[2407.15425v1](http://arxiv.org/abs/2407.15425v1)|null|
|**2024-07-22**|**Integrating IP Broadcasting with Audio Tags: Workflow and Challenges**|Rhys Burchett-Vass et.al.|[2407.15423v2](http://arxiv.org/abs/2407.15423v2)|null|
|**2024-07-22**|**Planning behavior in a recurrent neural network that plays Sokoban**|Adrià Garriga-Alonso et.al.|[2407.15421v1](http://arxiv.org/abs/2407.15421v1)|[link](https://github.com/alignmentresearch/train-learned-planner)|
|**2024-07-22**|**LLaST: Improved End-to-end Speech Translation System Leveraged by Large Language Models**|Xi Chen et.al.|[2407.15415v1](http://arxiv.org/abs/2407.15415v1)|[link](https://github.com/openaudiolab/llast)|
|**2024-07-22**|**Knowledge Mechanisms in Large Language Models: A Survey and Perspective**|Mengru Wang et.al.|[2407.15017v1](http://arxiv.org/abs/2407.15017v1)|null|
|**2024-07-22**|**Tackling Selfish Clients in Federated Learning**|Andrea Augello et.al.|[2407.15402v1](http://arxiv.org/abs/2407.15402v1)|[link](https://github.com/ndslab-group/RFL-Self)|
|**2024-07-22**|**Imposter.AI: Adversarial Attacks with Hidden Intentions towards Aligned Large Language Models**|Xiao Liu et.al.|[2407.15399v1](http://arxiv.org/abs/2407.15399v1)|null|
|**2024-07-22**|**Semantic Diversity-aware Prototype-based Learning for Unbiased Scene Graph Generation**|Jaehyeong Jeon et.al.|[2407.15396v1](http://arxiv.org/abs/2407.15396v1)|null|
|**2024-07-22**|**ALLaM: Large Language Models for Arabic and English**|M Saiful Bari et.al.|[2407.15390v1](http://arxiv.org/abs/2407.15390v1)|null|
|**2024-07-22**|**The Development of a Comprehensive Spanish Dictionary for Phonetic and Lexical Tagging in Socio-phonetic Research (ESPADA)**|Simon Gonzalez et.al.|[2407.15375v1](http://arxiv.org/abs/2407.15375v1)|null|
|**2024-07-22**|**ILiAD: An Interactive Corpus for Linguistic Annotated Data from Twitter Posts**|Simon Gonzalez et.al.|[2407.15374v1](http://arxiv.org/abs/2407.15374v1)|null|
|**2024-07-22**|**A Network Analysis Approach to Conlang Research Literature**|Simon Gonzalez et.al.|[2407.15370v1](http://arxiv.org/abs/2407.15370v1)|null|
|**2024-07-22**|**Walking in Others' Shoes: How Perspective-Taking Guides Large Language Models in Reducing Toxicity and Bias**|Rongwu Xu et.al.|[2407.15366v1](http://arxiv.org/abs/2407.15366v1)|null|
|**2024-07-22**|**A Multimodal Knowledge-enhanced Whole-slide Pathology Foundation Model**|Yingxue Xu et.al.|[2407.15362v1](http://arxiv.org/abs/2407.15362v1)|null|
|**2024-07-22**|**Dissecting Multiplication in Transformers: Insights into LLMs**|Luyu Qiu et.al.|[2407.15360v1](http://arxiv.org/abs/2407.15360v1)|null|
|**2024-07-22**|**UF-HOBI at "Discharge Me!": A Hybrid Solution for Discharge Summary Generation Through Prompt-based Tuning of GatorTronGPT Models**|Mengxian Lyu et.al.|[2407.15359v1](http://arxiv.org/abs/2407.15359v1)|null|
|**2024-07-22**|**X-Recon: Learning-based Patient-specific High-Resolution CT Reconstruction from Orthogonal X-Ray Images**|Yunpeng Wang et.al.|[2407.15356v1](http://arxiv.org/abs/2407.15356v1)|[link](https://github.com/wangyunpengbio/x-recon)|
|**2024-07-22**|**Customized Retrieval Augmented Generation and Benchmarking for EDA Tool Documentation QA**|Yuan Pu et.al.|[2407.15353v1](http://arxiv.org/abs/2407.15353v1)|null|
|**2024-07-22**|**MAVEN-Fact: A Large-scale Event Factuality Detection Dataset**|Chunyang Li et.al.|[2407.15352v1](http://arxiv.org/abs/2407.15352v1)|[link](https://github.com/lcy2723/maven-fact)|
|**2024-07-22**|**LLMExplainer: Large Language Model based Bayesian Inference for Graph Explanation Generation**|Jiaxing Zhang et.al.|[2407.15351v2](http://arxiv.org/abs/2407.15351v2)|null|
|**2024-07-22**|**Knowledge Acquisition Disentanglement for Knowledge-based Visual Question Answering with Large Language Models**|Wenbin An et.al.|[2407.15346v1](http://arxiv.org/abs/2407.15346v1)|null|
|**2024-07-22**|**Improving Minimum Bayes Risk Decoding with Multi-Prompt**|David Heineman et.al.|[2407.15343v1](http://arxiv.org/abs/2407.15343v1)|null|
|**2024-07-22**|**ZZU-NLP at SIGHAN-2024 dimABSA Task: Aspect-Based Sentiment Analysis with Coarse-to-Fine In-context Learning**|Senbin Zhu et.al.|[2407.15341v1](http://arxiv.org/abs/2407.15341v1)|null|
|**2024-07-22**|**Deep Learning for Economists**|Melissa Dell et.al.|[2407.15339v1](http://arxiv.org/abs/2407.15339v1)|null|
|**2024-07-22**|**Robust personalized pricing under uncertainty of purchase probabilities**|Shunnosuke Ikeda et.al.|[2407.15332v1](http://arxiv.org/abs/2407.15332v1)|null|
|**2024-07-22**|**Odyssey: Empowering Agents with Open-World Skills**|Shunyu Liu et.al.|[2407.15325v1](http://arxiv.org/abs/2407.15325v1)|[link](https://github.com/zju-vipa/odyssey)|
|**2024-07-22**|**FMDNN: A Fuzzy-guided Multi-granular Deep Neural Network for Histopathological Image Classification**|Weiping Ding et.al.|[2407.15312v1](http://arxiv.org/abs/2407.15312v1)|null|
|**2024-07-21**|**Weak-to-Strong Compositional Learning from Generative Models for Language-based Object Detection**|Kwanyong Park et.al.|[2407.15296v1](http://arxiv.org/abs/2407.15296v1)|null|
|**2024-07-21**|**Intrinsic Self-correction for Enhanced Morality: An Analysis of Internal Mechanisms and the Superficial Hypothesis**|Guangliang Liu et.al.|[2407.15286v1](http://arxiv.org/abs/2407.15286v1)|null|
|**2024-07-21**|**Enhancing Hardware Fault Tolerance in Machines with Reinforcement Learning Policy Gradient Algorithms**|Sheila Schoepp et.al.|[2407.15283v1](http://arxiv.org/abs/2407.15283v1)|null|
|**2024-07-21**|**SynCPKL: Harnessing LLMs to Generate Synthetic Data for Commonsense Persona Knowledge Linking**|Kuan-Yen Lin et.al.|[2407.15281v1](http://arxiv.org/abs/2407.15281v1)|[link](https://github.com/irislin1006/cpkl)|
|**2024-07-21**|**Unifying Invariant and Variant Features for Graph Out-of-Distribution via Probability of Necessity and Sufficiency**|Xuexin Chen et.al.|[2407.15273v1](http://arxiv.org/abs/2407.15273v1)|null|
|**2024-07-21**|**Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation**|Liwen Sun et.al.|[2407.15268v1](http://arxiv.org/abs/2407.15268v1)|null|
|**2024-07-21**|**Explaining Decisions of Agents in Mixed-Motive Games**|Maayan Orner et.al.|[2407.15255v1](http://arxiv.org/abs/2407.15255v1)|null|
|**2024-07-21**|**XAI meets LLMs: A Survey of the Relation between Explainable AI and Large Language Models**|Erik Cambria et.al.|[2407.15248v1](http://arxiv.org/abs/2407.15248v1)|null|

#### Abstracts
##### **LLMmap: Fingerprinting For Large Language Models**
2407.15847v1 by Dario Pasquini, Evgenios M. Kornaropoulos, Giuseppe Ateniese

We introduce LLMmap, a first-generation fingerprinting attack targeted at
LLM-integrated applications. LLMmap employs an active fingerprinting approach,
sending carefully crafted queries to the application and analyzing the
responses to identify the specific LLM model in use. With as few as 8
interactions, LLMmap can accurately identify LLMs with over 95% accuracy. More
importantly, LLMmap is designed to be robust across different application
layers, allowing it to identify LLMs operating under various system prompts,
stochastic sampling hyperparameters, and even complex generation frameworks
such as RAG or Chain-of-Thought.

摘要：我們介紹 LLMmap，這是一種針對整合 LLM 的應用程式所進行的第一代指紋攻擊。LLMmap 採用主動式指紋辨識方法，將精心設計的查詢傳送至應用程式，並分析回應以識別所使用的特定 LLM 模型。透過僅 8 次互動，LLMmap 便能以超過 95% 的準確度準確識別 LLM。更重要的是，LLMmap 被設計為能夠在不同的應用程式層面中保持穩健性，這使其能夠識別在各種系統提示、隨機抽樣超參數，甚至是複雜生成架構（例如 RAG 或 Chain-of-Thought）下運作的 LLM。

##### **Reconstructing Training Data From Real World Models Trained with Transfer Learning**
2407.15845v1 by Yakir Oz, Gilad Yehudai, Gal Vardi, Itai Antebi, Michal Irani, Niv Haim

Current methods for reconstructing training data from trained classifiers are
restricted to very small models, limited training set sizes, and low-resolution
images. Such restrictions hinder their applicability to real-world scenarios.
In this paper, we present a novel approach enabling data reconstruction in
realistic settings for models trained on high-resolution images. Our method
adapts the reconstruction scheme of arXiv:2206.07758 to real-world scenarios --
specifically, targeting models trained via transfer learning over image
embeddings of large pre-trained models like DINO-ViT and CLIP. Our work employs
data reconstruction in the embedding space rather than in the image space,
showcasing its applicability beyond visual data. Moreover, we introduce a novel
clustering-based method to identify good reconstructions from thousands of
candidates. This significantly improves on previous works that relied on
knowledge of the training set to identify good reconstructed images. Our
findings shed light on a potential privacy risk for data leakage from models
trained using transfer learning.

摘要：目前的訓練資料從訓練好的分類器中重建方法僅限於非常小的模型、有限的訓練集大小和低解析度的影像。這些限制妨礙其適用於真實世界的場景。在本文中，我們提出了一種新的方法，可以在高解析度影像訓練的模型中進行資料重建，以適應真實世界的場景。我們的模型將 arXiv:2206.07758 的重建方案調整到真實世界的場景中——特別是針對透過大型預訓練模型（如 DINO-ViT 和 CLIP）的影像嵌入進行遷移學習訓練的模型。我們的模型在嵌入空間中進行資料重建，而不在影像空間中，展示了其在視覺資料之外的適用性。此外，我們引入了一種新的基於群集的方法，從數千個候選者中找出良好的重建。這顯著改善了以往依賴訓練集知識來找出良好重建影像的方法。我們的研究結果揭示了使用遷移學習訓練的模型中資料外洩的潛在隱私風險。

##### **CarFormer: Self-Driving with Learned Object-Centric Representations**
2407.15843v1 by Shadi Hamdan, Fatma Güney

The choice of representation plays a key role in self-driving. Bird's eye
view (BEV) representations have shown remarkable performance in recent years.
In this paper, we propose to learn object-centric representations in BEV to
distill a complex scene into more actionable information for self-driving. We
first learn to place objects into slots with a slot attention model on BEV
sequences. Based on these object-centric representations, we then train a
transformer to learn to drive as well as reason about the future of other
vehicles. We found that object-centric slot representations outperform both
scene-level and object-level approaches that use the exact attributes of
objects. Slot representations naturally incorporate information about objects
from their spatial and temporal context such as position, heading, and speed
without explicitly providing it. Our model with slots achieves an increased
completion rate of the provided routes and, consequently, a higher driving
score, with a lower variance across multiple runs, affirming slots as a
reliable alternative in object-centric approaches. Additionally, we validate
our model's performance as a world model through forecasting experiments,
demonstrating its capability to predict future slot representations accurately.
The code and the pre-trained models can be found at
https://kuis-ai.github.io/CarFormer/.

摘要：表示的選擇在自動駕駛中扮演著關鍵的角色。鳥瞰圖 (BEV) 表示在近年來展現了卓越的表現。在本文中，我們提出學習 BEV 中以物體為中心的表示，以將複雜的場景提煉成更具可操作性的資訊，用於自動駕駛。我們首先學習使用 BEV 序列上的插槽注意力模型將物體放入插槽中。根據這些以物體為中心的表示，我們接著訓練一個轉換器來學習駕駛，以及推論其他車輛的未來。我們發現以物體為中心的插槽表示優於使用物體確切屬性的場景級別和物體級別方法。插槽表示自然地結合了來自物體空間和時間脈絡的資訊，例如位置、航向和速度，而無需明確提供。我們帶有插槽的模型提高了所提供路線的完成率，因此提高了駕駛分數，並且在多次執行中的差異較低，證實插槽是以物體為中心的方法中可靠的替代方案。此外，我們透過預測實驗驗證了我們模型作為世界模型的效能，證明了其準確預測未來插槽表示的能力。程式碼和預訓練模型可以在 https://kuis-ai.github.io/CarFormer/ 找到。

##### **Importance Sampling-Guided Meta-Training for Intelligent Agents in Highly Interactive Environments**
2407.15839v1 by Mansur Arief, Mike Timmerman, Jiachen Li, David Isele, Mykel J Kochenderfer

Training intelligent agents to navigate highly interactive environments
presents significant challenges. While guided meta reinforcement learning (RL)
approach that first trains a guiding policy to train the ego agent has proven
effective in improving generalizability across various levels of interaction,
the state-of-the-art method tends to be overly sensitive to extreme cases,
impairing the agents' performance in the more common scenarios. This study
introduces a novel training framework that integrates guided meta RL with
importance sampling (IS) to optimize training distributions for navigating
highly interactive driving scenarios, such as T-intersections. Unlike
traditional methods that may underrepresent critical interactions or
overemphasize extreme cases during training, our approach strategically adjusts
the training distribution towards more challenging driving behaviors using IS
proposal distributions and applies the importance ratio to de-bias the result.
By estimating a naturalistic distribution from real-world datasets and
employing a mixture model for iterative training refinements, the framework
ensures a balanced focus across common and extreme driving scenarios.
Experiments conducted with both synthetic dataset and T-intersection scenarios
from the InD dataset demonstrate not only accelerated training but also
improvement in agent performance under naturalistic conditions, showcasing the
efficacy of combining IS with meta RL in training reliable autonomous agents
for highly interactive navigation tasks.

摘要：訓練智能代理程式在高度互動的環境中導航，會面臨重大挑戰。雖然引導元強化學習 (RL) 方法先訓練引導政策來訓練自我代理程式，已被證明可以有效提升在不同互動層級之間的泛化性，但最先進的方法往往對極端案例過度敏感，損害代理程式在更常見場景中的效能。本研究提出一個新的訓練架構，將引導元 RL 與重要性抽樣 (IS) 整合，以最佳化訓練分佈，用於導航高度互動的駕駛場景，例如 T 型路口。與傳統方法不同，傳統方法在訓練過程中可能低估關鍵互動或過度強調極端案例，我們的做法策略性地調整訓練分佈，使用 IS 提議分佈朝向更具挑戰性的駕駛行為，並套用重要性比率來消除結果偏差。透過從真實世界資料集估計自然分佈，並採用混合模型進行反覆訓練調整，該架構確保在常見和極端駕駛場景之間取得平衡的關注。使用合成資料集和 InD 資料集中的 T 型路口場景進行的實驗，不僅證明了訓練加速，也證明了在自然條件下代理程式效能的提升，展示了在訓練可靠的自主代理程式以執行高度互動導航任務時，結合 IS 和元 RL 的效能。

##### **Towards Latent Masked Image Modeling for Self-Supervised Visual Representation Learning**
2407.15837v1 by Yibing Wei, Abhinav Gupta, Pedro Morgado

Masked Image Modeling (MIM) has emerged as a promising method for deriving
visual representations from unlabeled image data by predicting missing pixels
from masked portions of images. It excels in region-aware learning and provides
strong initializations for various tasks, but struggles to capture high-level
semantics without further supervised fine-tuning, likely due to the low-level
nature of its pixel reconstruction objective. A promising yet unrealized
framework is learning representations through masked reconstruction in latent
space, combining the locality of MIM with the high-level targets. However, this
approach poses significant training challenges as the reconstruction targets
are learned in conjunction with the model, potentially leading to trivial or
suboptimal solutions.Our study is among the first to thoroughly analyze and
address the challenges of such framework, which we refer to as Latent MIM.
Through a series of carefully designed experiments and extensive analysis, we
identify the source of these challenges, including representation collapsing
for joint online/target optimization, learning objectives, the high region
correlation in latent space and decoding conditioning. By sequentially
addressing these issues, we demonstrate that Latent MIM can indeed learn
high-level representations while retaining the benefits of MIM models.

摘要：遮蔽影像建模 (MIM) 已成為一種有前途的方法，可用於透過預測影像遮蔽部分的遺失像素，從未標記的影像資料中衍生視覺表示。它在區域感知學習方面表現出色，並為各種任務提供強大的初始設定，但卻難以在沒有進一步監督微調的情況下捕捉到高層次語意，這可能是由於其像素重建目標的低層次本質所致。一個有前途但尚未實現的架構是透過潛在空間中的遮蔽重建來學習表示，結合 MIM 的局部性與高層次目標。然而，這種方法會帶來重大的訓練挑戰，因為重建目標是與模型結合學習的，可能會導致微不足道或次佳的解決方案。我們的研究是第一批徹底分析和解決此類架構挑戰的研究之一，我們稱之為潛在 MIM。透過一系列精心設計的實驗和廣泛的分析，我們找出這些挑戰的根源，包括聯合線上/目標最佳化、學習目標、潛在空間中的高區域相關性和解碼條件的表示崩潰。透過循序漸進地解決這些問題，我們證明潛在 MIM 確實可以在保留 MIM 模型優點的同時學習高層次表示。

##### **dMel: Speech Tokenization made Simple**
2407.15835v1 by He Bai, Tatiana Likhomanenko, Ruixiang Zhang, Zijin Gu, Zakaria Aldeneh, Navdeep Jaitly

Large language models have revolutionized natural language processing by
leveraging self-supervised pretraining on vast textual data. Inspired by this
success, researchers have investigated complicated speech tokenization methods
to discretize continuous speech signals so that language modeling techniques
can be applied to speech data. However, existing approaches either model
semantic tokens, potentially losing acoustic information, or model acoustic
tokens, risking the loss of semantic information. Having multiple token types
also complicates the architecture and requires additional pretraining. Here we
show that discretizing mel-filterbank channels into discrete intensity bins
produces a simple representation (dMel), that performs better than other
existing speech tokenization methods. Using a transformer decoder-only
architecture for speech-text modeling, we comprehensively evaluate different
speech tokenization methods on speech recognition (ASR), speech synthesis
(TTS). Our results demonstrate the effectiveness of dMel in achieving high
performance on both tasks within a unified framework, paving the way for
efficient and effective joint modeling of speech and text.

摘要：大型語言模型透過在大量的文本資料上利用自我監督預訓練，徹底改變了自然語言處理。受到這項成功的啟發，研究人員調查了複雜的語音標記化方法，以便將連續的語音訊號離散化，讓語言建模技術可以應用於語音資料。然而，現有的方法不是對語義標記建模（可能遺失音訊資訊），就是對音訊標記建模（有遺失語義資訊的風險）。擁有多種類型的標記也會使架構複雜化，並需要額外的預訓練。在此，我們展示將梅爾濾波器組通道離散化為離散強度區塊，會產生一個簡單的表示（dMel），其效能優於其他現有的語音標記化方法。我們使用僅具轉換器解碼器的架構進行語音轉文字建模，在語音辨識 (ASR)、語音合成 (TTS) 上全面評估不同的語音標記化方法。我們的結果證明了 dMel 在統一架構中達成這兩個任務的高效能，為有效率且有效的語音和文字聯合建模鋪路。

##### **NV-Retriever: Improving text embedding models with effective hard-negative mining**
2407.15831v1 by Gabriel de Souza P. Moreira, Radek Osmulski, Mengyao Xu, Ronay Ak, Benedikt Schifferer, Even Oldridge

Text embedding models have been popular for information retrieval
applications such as semantic search and Question-Answering systems based on
Retrieval-Augmented Generation (RAG). Those models are typically Transformer
models that are fine-tuned with contrastive learning objectives. Many papers
introduced new embedding model architectures and training approaches, however,
one of the key ingredients, the process of mining negative passages, remains
poorly explored or described. One of the challenging aspects of fine-tuning
embedding models is the selection of high quality hard-negative passages for
contrastive learning. In this paper we propose a family of positive-aware
mining methods that leverage the positive relevance score for more effective
false negatives removal. We also provide a comprehensive ablation study on
hard-negative mining methods over their configurations, exploring different
teacher and base models. We demonstrate the efficacy of our proposed methods by
introducing the NV-Retriever-v1 model, which scores 60.9 on MTEB Retrieval
(BEIR) benchmark and 0.65 points higher than previous methods. The model placed
1st when it was published to MTEB Retrieval on July 07, 2024.

摘要：文本嵌入模型在信息检索应用中很受欢迎，例如基于检索增强生成 (RAG) 的语义搜索和问答系统。这些模型通常是经过对比学习目标微调的 Transformer 模型。许多论文介绍了新的嵌入模型架构和训练方法，然而，其中一个关键要素，即挖掘负面段落的过程，仍然探索或描述得很差。微调嵌入模型的一个具有挑战性的方面是为对比学习选择高质量的困难负面段落。在本文中，我们提出了一系列积极感知挖掘方法，利用积极相关性分数更有效地去除假阴性。我们还对困难负面挖掘方法及其配置进行了全面的消融研究，探索了不同的教师和基础模型。我们通过引入 NV-Retriever-v1 模型来证明我们提出的方法的有效性，该模型在 MTEB 检索 (BEIR) 基准测试中得分 60.9，比以前的方法高 0.65 分。该模型在 2024 年 7 月 07 日发布到 MTEB 检索时排名第一。

##### **J-CHAT: Japanese Large-scale Spoken Dialogue Corpus for Spoken Dialogue Language Modeling**
2407.15828v1 by Wataru Nakata, Kentaro Seki, Hitomi Yanaka, Yuki Saito, Shinnosuke Takamichi, Hiroshi Saruwatari

Spoken dialogue plays a crucial role in human-AI interactions, necessitating
dialogue-oriented spoken language models (SLMs). To develop versatile SLMs,
large-scale and diverse speech datasets are essential. Additionally, to ensure
hiqh-quality speech generation, the data must be spontaneous like in-wild data
and must be acoustically clean with noise removed. Despite the critical need,
no open-source corpus meeting all these criteria has been available. This study
addresses this gap by constructing and releasing a large-scale spoken dialogue
corpus, named Japanese Corpus for Human-AI Talks (J-CHAT), which is publicly
accessible. Furthermore, this paper presents a language-independent method for
corpus construction and describes experiments on dialogue generation using SLMs
trained on J-CHAT. Experimental results indicate that the collected data from
multiple domains by our method improve the naturalness and meaningfulness of
dialogue generation.

摘要：口說對話在人機互動中扮演至關重要的角色，因此需要對話導向的口說語言模型 (SLM)。為了開發通用的 SLM，大規模且多樣的語音資料集至關重要。此外，為了確保高品質的語音生成，資料必須像野外資料一樣自然，且必須在去除雜訊後進行聲學清理。儘管有此關鍵需求，但還沒有任何開源語料庫符合所有這些條件。本研究透過建構和釋出一個名為「人機對話日語語料庫」(J-CHAT) 的大規模口說對話語料庫來解決這個問題，該語料庫可供公眾使用。此外，本文提出了一種與語言無關的語料庫建構方法，並說明了使用在 J-CHAT 上訓練的 SLM 進行對話生成的實驗。實驗結果表明，我們的方法從多個領域收集的資料改善了對話生成的自然性和意義性。

##### **Perceptions of Linguistic Uncertainty by Language Models and Humans**
2407.15814v1 by Catarina G Belem, Markelle Kelly, Mark Steyvers, Sameer Singh, Padhraic Smyth

Uncertainty expressions such as ``probably'' or ``highly unlikely'' are
pervasive in human language. While prior work has established that there is
population-level agreement in terms of how humans interpret these expressions,
there has been little inquiry into the abilities of language models to
interpret such expressions. In this paper, we investigate how language models
map linguistic expressions of uncertainty to numerical responses. Our approach
assesses whether language models can employ theory of mind in this setting:
understanding the uncertainty of another agent about a particular statement,
independently of the model's own certainty about that statement. We evaluate
both humans and 10 popular language models on a task created to assess these
abilities. Unexpectedly, we find that 8 out of 10 models are able to map
uncertainty expressions to probabilistic responses in a human-like manner.
However, we observe systematically different behavior depending on whether a
statement is actually true or false. This sensitivity indicates that language
models are substantially more susceptible to bias based on their prior
knowledge (as compared to humans). These findings raise important questions and
have broad implications for human-AI alignment and AI-AI communication.

摘要：不確定性表達式，例如「可能」或「極不可能」，在人類語言中普遍存在。雖然先前的工作已經確定，在人類如何詮釋這些表達式方面存在著人口層級的共識，但對於語言模型詮釋此類表達式的能力，卻鮮少有探討。在本文中，我們探討語言模型如何將不確定性的語言表達式對應到數值回應。我們的做法評估語言模型在這種情況下是否能運用心智理論：了解另一個主體對特定陳述的不確定性，且與模型對該陳述本身的確定性無關。我們針對人類和 10 個流行的語言模型，評估一項旨在評量這些能力的任務。出乎意料地，我們發現 10 個模型中有 8 個能夠以類似人類的方式，將不確定性表達式對應到機率回應。然而，我們觀察到，視陳述實際為真或假，而有系統性的不同行為。這種敏感性表明，語言模型極容易受到基於其先驗知識的偏差影響（相較於人類）。這些發現提出了重要的問題，並對人類與 AI 的協調，以及 AI 與 AI 之間的溝通，產生廣泛的影響。

##### **Stretching Each Dollar: Diffusion Training from Scratch on a Micro-Budget**
2407.15811v1 by Vikash Sehwag, Xianghao Kong, Jingtao Li, Michael Spranger, Lingjuan Lyu

As scaling laws in generative AI push performance, they also simultaneously
concentrate the development of these models among actors with large
computational resources. With a focus on text-to-image (T2I) generative models,
we aim to address this bottleneck by demonstrating very low-cost training of
large-scale T2I diffusion transformer models. As the computational cost of
transformers increases with the number of patches in each image, we propose to
randomly mask up to 75% of the image patches during training. We propose a
deferred masking strategy that preprocesses all patches using a patch-mixer
before masking, thus significantly reducing the performance degradation with
masking, making it superior to model downscaling in reducing computational
cost. We also incorporate the latest improvements in transformer architecture,
such as the use of mixture-of-experts layers, to improve performance and
further identify the critical benefit of using synthetic images in micro-budget
training. Finally, using only 37M publicly available real and synthetic images,
we train a 1.16 billion parameter sparse transformer with only \$1,890
economical cost and achieve a 12.7 FID in zero-shot generation on the COCO
dataset. Notably, our model achieves competitive FID and high-quality
generations while incurring 118$\times$ lower cost than stable diffusion models
and 14$\times$ lower cost than the current state-of-the-art approach that costs
\$28,400. We aim to release our end-to-end training pipeline to further
democratize the training of large-scale diffusion models on micro-budgets.

摘要：<paragraph>隨著生成式 AI 中的縮放定律提升效能，它們也同時將這些模型的開發集中在擁有龐大運算資源的參與者之間。我們專注於文字轉影像 (T2I) 生成式模型，旨在透過展示大規模 T2I 擴散Transformer模型的極低成本訓練來解決這個瓶頸。由於Transformer的運算成本會隨著每個影像中的貼片數量而增加，我們建議在訓練期間隨機遮蔽最多 75% 的影像貼片。我們提出了一種延遲遮蔽策略，在遮蔽之前使用貼片混合器預處理所有貼片，從而顯著降低遮蔽造成的效能下降，使其在降低運算成本方面優於模型縮放。我們還納入了Transformer架構中的最新改進，例如使用混合專家層，以提升效能並進一步找出在微預算訓練中使用合成影像的重要好處。最後，我們僅使用 3700 萬張公開的真實和合成影像，訓練了一個具有 11.6 億個參數的稀疏Transformer，經濟成本僅為 1,890 美元，並在 COCO 資料集的零次生成中達到了 12.7 FID。值得注意的是，我們的模型達到了有競爭力的 FID 和高品質的生成，同時產生的成本比穩定的擴散模型低 118 倍，比目前最先進且花費 28,400 美元的技術低 14 倍。我們旨在釋出我們的端對端訓練管道，以進一步民主化在微預算上訓練大規模擴散模型。</paragraph>

##### **FSboard: Over 3 million characters of ASL fingerspelling collected via smartphones**
2407.15806v1 by Manfred Georg, Garrett Tanzer, Saad Hassan, Maximus Shengelia, Esha Uboweja, Sam Sepah, Sean Forbes, Thad Starner

Progress in machine understanding of sign languages has been slow and
hampered by limited data. In this paper, we present FSboard, an American Sign
Language fingerspelling dataset situated in a mobile text entry use case,
collected from 147 paid and consenting Deaf signers using Pixel 4A selfie
cameras in a variety of environments. Fingerspelling recognition is an
incomplete solution that is only one small part of sign language translation,
but it could provide some immediate benefit to Deaf/Hard of Hearing signers as
more broadly capable technology develops. At >3 million characters in length
and >250 hours in duration, FSboard is the largest fingerspelling recognition
dataset to date by a factor of >10x. As a simple baseline, we finetune 30 Hz
MediaPipe Holistic landmark inputs into ByT5-Small and achieve 11.1% Character
Error Rate (CER) on a test set with unique phrases and signers. This quality
degrades gracefully when decreasing frame rate and excluding face/body
landmarks: plausible optimizations to help models run on device in real time.

摘要：手語機器理解的進展緩慢，且受到資料有限的阻礙。在本文中，我們提出 FSboard，一個美國手語手指拼寫資料集，位於行動文字輸入用例中，從 147 位付費且同意的聾人手語者中收集，使用 Pixel 4A 自拍相機在各種環境中進行拍攝。手指拼寫辨識是一個不完整的解決方案，僅是手語翻譯的一小部分，但隨著更廣泛功能技術的發展，它可以為聾人/聽障手語者提供一些立即的益處。FSboard 長度超過 300 萬個字元，持續時間超過 250 小時，是迄今為止最大的手指拼寫辨識資料集，係數為 >10x。作為一個簡單的基準，我們微調 30 Hz 的 MediaPipe Holistic 地標輸入到 ByT5-Small 中，並在具有獨特短語和手語者的測試集中達到 11.1% 的字元錯誤率 (CER)。當降低幀率並排除臉部/身體地標時，這種品質會逐漸降低：合理的最佳化有助於模型在裝置上即時執行。

##### **CLIP with Generative Latent Replay: a Strong Baseline for Incremental Learning**
2407.15793v1 by Emanuele Frascaroli, Aniello Panariello, Pietro Buzzega, Lorenzo Bonicelli, Angelo Porrello, Simone Calderara

With the emergence of Transformers and Vision-Language Models (VLMs) such as
CLIP, large pre-trained models have become a common strategy to enhance
performance in Continual Learning scenarios. This led to the development of
numerous prompting strategies to effectively fine-tune transformer-based models
without succumbing to catastrophic forgetting. However, these methods struggle
to specialize the model on domains significantly deviating from the
pre-training and preserving its zero-shot capabilities. In this work, we
propose Continual Generative training for Incremental prompt-Learning, a novel
approach to mitigate forgetting while adapting a VLM, which exploits generative
replay to align prompts to tasks. We also introduce a new metric to evaluate
zero-shot capabilities within CL benchmarks. Through extensive experiments on
different domains, we demonstrate the effectiveness of our framework in
adapting to new tasks while improving zero-shot capabilities. Further analysis
reveals that our approach can bridge the gap with joint prompt tuning. The
codebase is available at https://github.com/aimagelab/mammoth.

摘要：隨著 Transformers 和 CLIP 等視覺語言模型 (VLM) 的出現，大型預訓練模型已成為在持續學習場景中增強效能的常見策略。這導致了許多提示策略的開發，以有效微調基於轉換器的模型，而不會屈服於災難性遺忘。然而，這些方法難以將模型專門化到與預訓練顯著不同的領域，並保留其零次學習能力。在這項工作中，我們提出持續生成訓練以進行增量提示學習，這是一種減輕遺忘同時適應 VLM 的新方法，它利用生成重播將提示與任務對齊。我們還引入了一個新指標來評估 CL 基準中的零次學習能力。通過在不同領域進行廣泛的實驗，我們展示了我們的框架在適應新任務同時提高零次學習能力方面的有效性。進一步的分析表明，我們的做法可以彌合理論提示調整的差距。程式碼庫可在 https://github.com/aimagelab/mammoth 取得。

##### **Extracting Structured Insights from Financial News: An Augmented LLM Driven Approach**
2407.15788v1 by Rian Dolphin, Joe Dursun, Jonathan Chow, Jarrett Blankenship, Katie Adams, Quinton Pike

Financial news plays a crucial role in decision-making processes across the
financial sector, yet the efficient processing of this information into a
structured format remains challenging. This paper presents a novel approach to
financial news processing that leverages Large Language Models (LLMs) to
overcome limitations that previously prevented the extraction of structured
data from unstructured financial news. We introduce a system that extracts
relevant company tickers from raw news article content, performs sentiment
analysis at the company level, and generates summaries, all without relying on
pre-structured data feeds. Our methodology combines the generative capabilities
of LLMs, and recent prompting techniques, with a robust validation framework
that uses a tailored string similarity approach. Evaluation on a dataset of
5530 financial news articles demonstrates the effectiveness of our approach,
with 90% of articles not missing any tickers compared with current data
providers, and 22% of articles having additional relevant tickers. In addition
to this paper, the methodology has been implemented at scale with the resulting
processed data made available through a live API endpoint, which is updated in
real-time with the latest news. To the best of our knowledge, we are the first
data provider to offer granular, per-company sentiment analysis from news
articles, enhancing the depth of information available to market participants.
We also release the evaluation dataset of 5530 processed articles as a static
file, which we hope will facilitate further research leveraging financial news.

摘要：財務新聞在整個金融部門的決策過程中扮演著至關重要的角色，然而將這些資訊有效處理成結構化格式仍具挑戰性。本文提出了一種處理財務新聞的新方法，利用大型語言模型 (LLM) 來克服過去阻礙從非結構化財務新聞中擷取結構化資料的限制。我們引入了一個系統，從原始新聞文章內容中擷取相關公司代號，執行公司層級的情緒分析，並產生摘要，所有這些都不依賴於預先結構化的資料饋送。我們的做法結合了 LLM 的生成能力和最新的提示技術，以及使用客製化字串相似度方法的強健驗證架構。在 5530 篇財務新聞文章的資料集上進行評估，證明了我們方法的有效性，與目前資料供應商相比，90% 的文章沒有遺漏任何代號，而 22% 的文章有額外的相關代號。除了這篇論文之外，該方法已大規模實施，處理後的資料透過即時 API 端點提供，並會根據最新新聞即時更新。據我們所知，我們是第一個提供新聞文章中細緻的、按公司劃分的市場情緒分析資料供應商，這增加了市場參與者可取得的資訊深度。我們也釋出了 5530 篇已處理文章的評估資料集作為靜態檔案，我們希望這將有助於利用財務新聞的進一步研究。

##### **Concept-Based Interpretable Reinforcement Learning with Limited to No Human Labels**
2407.15786v1 by Zhuorui Ye, Stephanie Milani, Geoffrey J. Gordon, Fei Fang

Recent advances in reinforcement learning (RL) have predominantly leveraged
neural network-based policies for decision-making, yet these models often lack
interpretability, posing challenges for stakeholder comprehension and trust.
Concept bottleneck models offer an interpretable alternative by integrating
human-understandable concepts into neural networks. However, a significant
limitation in prior work is the assumption that human annotations for these
concepts are readily available during training, necessitating continuous
real-time input from human annotators. To overcome this limitation, we
introduce a novel training scheme that enables RL algorithms to efficiently
learn a concept-based policy by only querying humans to label a small set of
data, or in the extreme case, without any human labels. Our algorithm,
LICORICE, involves three main contributions: interleaving concept learning and
RL training, using a concept ensembles to actively select informative data
points for labeling, and decorrelating the concept data with a simple strategy.
We show how LICORICE reduces manual labeling efforts to to 500 or fewer concept
labels in three environments. Finally, we present an initial study to explore
how we can use powerful vision-language models to infer concepts from raw
visual inputs without explicit labels at minimal cost to performance.

摘要：強化學習 (RL) 的最新進展主要利用了基於神經網路的政策來進行決策制定，但這些模型通常缺乏可解釋性，對利益相關者的理解和信任構成挑戰。概念瓶頸模型提供了一個可解釋的替代方案，將人類可以理解的概念整合到神經網路中。然而，先前工作的一個重大限制是假設在訓練期間這些概念的人工註解很容易取得，這需要人工註解者持續的即時輸入。為了克服這個限制，我們引入了一種新的訓練方案，使 RL 演算法能夠有效地學習基於概念的政策，只需查詢人類標記少量的資料集，或在極端情況下，完全不使用人工標籤。我們的演算法 LICORICE 涉及三個主要貢獻：交錯概念學習和 RL 訓練、使用概念集合主動選擇有用的資料點進行標記，以及使用簡單策略對概念資料進行去相關。我們展示了 LICORICE 如何將人工標記工作量減少到 500 個或更少的概念標籤，並運用在三個環境中。最後，我們提出了一項初步研究，探討如何使用強大的視覺語言模型從原始視覺輸入中推斷概念，而無需明確標籤，且對效能的影響極小。

##### **Diffusion Model Based Resource Allocation Strategy in Ultra-Reliable Wireless Networked Control Systems**
2407.15784v1 by Amirhassan Babazadeh Darabi, Sinem Coleri

Diffusion models are vastly used in generative AI, leveraging their
capability to capture complex data distributions. However, their potential
remains largely unexplored in the field of resource allocation in wireless
networks. This paper introduces a novel diffusion model-based resource
allocation strategy for Wireless Networked Control Systems (WNCSs) with the
objective of minimizing total power consumption through the optimization of the
sampling period in the control system, and blocklength and packet error
probability in the finite blocklength regime of the communication system. The
problem is first reduced to the optimization of blocklength only based on the
derivation of the optimality conditions. Then, the optimization theory solution
collects a dataset of channel gains and corresponding optimal blocklengths.
Finally, the Denoising Diffusion Probabilistic Model (DDPM) uses this collected
dataset to train the resource allocation algorithm that generates optimal
blocklength values conditioned on the channel state information (CSI). Via
extensive simulations, the proposed approach is shown to outperform previously
proposed Deep Reinforcement Learning (DRL) based approaches with close to
optimal performance regarding total power consumption. Moreover, an improvement
of up to eighteen-fold in the reduction of critical constraint violations is
observed, further underscoring the accuracy of the solution.

摘要：擴散模型廣泛用於生成式 AI，利用其捕捉複雜資料分佈的能力。然而，它們在無線網路資源配置領域的潛力仍未充分探索。本文提出了一種新的基於擴散模型的資源配置策略，用於無線網路控制系統 (WNCS)，目的是透過最佳化控制系統中的取樣週期、區塊長度和通訊系統有限區塊長度方案中的封包錯誤機率，來最小化總功耗。首先，將問題簡化為僅根據最佳化條件的推導來最佳化區塊長度。然後，最佳化理論解收集了一組頻道增益和對應的最佳區塊長度。最後，去噪擴散機率模型 (DDPM) 使用此收集的資料集來訓練資源配置演算法，該演算法會根據頻道狀態資訊 (CSI) 產生最佳區塊長度值。透過廣泛的模擬，已證明所提出的方法優於先前提出的基於深度強化學習 (DRL) 的方法，在總功耗方面接近最佳效能。此外，觀察到在減少關鍵約束違規方面最多可改善十八倍，進一步強調了解決方案的準確性。

##### **Explaining Decisions in ML Models: a Parameterized Complexity Analysis**
2407.15780v1 by Sebastian Ordyniak, Giacomo Paesani, Mateusz Rychlicki, Stefan Szeider

This paper presents a comprehensive theoretical investigation into the
parameterized complexity of explanation problems in various machine learning
(ML) models. Contrary to the prevalent black-box perception, our study focuses
on models with transparent internal mechanisms. We address two principal types
of explanation problems: abductive and contrastive, both in their local and
global variants. Our analysis encompasses diverse ML models, including Decision
Trees, Decision Sets, Decision Lists, Ordered Binary Decision Diagrams, Random
Forests, and Boolean Circuits, and ensembles thereof, each offering unique
explanatory challenges. This research fills a significant gap in explainable AI
(XAI) by providing a foundational understanding of the complexities of
generating explanations for these models. This work provides insights vital for
further research in the domain of XAI, contributing to the broader discourse on
the necessity of transparency and accountability in AI systems.

摘要：本文對各種機器學習 (ML) 模型中解釋問題的參數化複雜性進行了全面的理論研究。與普遍的黑盒感知相反，我們的研究重點在於具有透明內部機制的模型。我們探討了兩種主要的解釋問題類型：演繹和對比，包括它們的局部和全局變體。我們的分析涵蓋了各種 ML 模型，包括決策樹、決策集、決策列表、有序二元決策圖、隨機森林和布林電路及其集合，每個都提供了獨特的解釋挑戰。本研究填補了可解釋 AI (XAI) 的一個重大空白，提供了對這些模型生成解釋的複雜性的基礎理解。這項工作為 XAI 領域的進一步研究提供了至關重要的見解，為關於 AI 系統中透明度和問責制必要性的廣泛討論做出了貢獻。

##### **Local Occupancy-Enhanced Object Grasping with Multiple Triplanar Projection**
2407.15771v1 by Kangqi Ma, Hao Dong, Yadong Mu

This paper addresses the challenge of robotic grasping of general objects.
Similar to prior research, the task reads a single-view 3D observation (i.e.,
point clouds) captured by a depth camera as input. Crucially, the success of
object grasping highly demands a comprehensive understanding of the shape of
objects within the scene. However, single-view observations often suffer from
occlusions (including both self and inter-object occlusions), which lead to
gaps in the point clouds, especially in complex cluttered scenes. This renders
incomplete perception of the object shape and frequently causes failures or
inaccurate pose estimation during object grasping. In this paper, we tackle
this issue with an effective albeit simple solution, namely completing
grasping-related scene regions through local occupancy prediction. Following
prior practice, the proposed model first runs by proposing a number of most
likely grasp points in the scene. Around each grasp point, a module is designed
to infer any voxel in its neighborhood to be either void or occupied by some
object. Importantly, the occupancy map is inferred by fusing both local and
global cues. We implement a multi-group tri-plane scheme for efficiently
aggregating long-distance contextual information. The model further estimates
6-DoF grasp poses utilizing the local occupancy-enhanced object shape
information and returns the top-ranked grasp proposal. Comprehensive
experiments on both the large-scale GraspNet-1Billion benchmark and real
robotic arm demonstrate that the proposed method can effectively complete the
unobserved parts in cluttered and occluded scenes. Benefiting from the
occupancy-enhanced feature, our model clearly outstrips other competing methods
under various performance metrics such as grasping average precision.

摘要：<paragraph>這篇論文探討了機器人抓取一般物體的挑戰。與先前的研究類似，該任務讀取深度相機捕捉到的單視圖 3D 觀測（即，點雲）作為輸入。至關重要的是，物體抓取的成功高度依賴於對場景中物體形狀的全面理解。然而，單視圖觀測通常會受到遮擋（包括自我遮擋和物體間遮擋）的影響，這會導致點雲中的間隙，特別是在複雜的混亂場景中。這會導致對物體形狀的感知不完整，並在物體抓取過程中經常導致失敗或姿勢估計不準確。在本文中，我們採用一種有效且簡單的解決方案來解決這個問題，即通過局部佔用預測完成與抓取相關的場景區域。遵循先前的實踐，所提出的模型首先通過提出場景中一些最可能的抓取點來運行。在每個抓取點周圍，設計一個模組來推斷其鄰域中的任何體素是空的還是被某個物體佔用。重要的是，佔用地圖是通過融合局部和全局線索推斷出來的。我們實作了一個多群組三平面方案，以有效地彙總長距離的上下文資訊。該模型進一步估計 6-DoF 抓取姿勢，利用局部佔用增強的物體形狀資訊，並返回排名最高的抓取建議。在大型 GraspNet-1Billion 基準和真實機器人手臂上的綜合實驗表明，所提出的方法可以在混亂和遮擋的場景中有效地完成未觀察到的部分。受益於佔用增強功能，我們的模型在各種效能指標（例如抓取平均精準度）下明顯優於其他競爭方法。</paragraph>

##### **Conditioned Language Policy: A General Framework for Steerable Multi-Objective Finetuning**
2407.15762v1 by Kaiwen Wang, Rahul Kidambi, Ryan Sullivan, Alekh Agarwal, Christoph Dann, Andrea Michi, Marco Gelmi, Yunxuan Li, Raghav Gupta, Avinava Dubey, Alexandre Ramé, Johan Ferret, Geoffrey Cideron, Le Hou, Hongkun Yu, Amr Ahmed, Aranyak Mehta, Léonard Hussenot, Olivier Bachem, Edouard Leurent

Reward-based finetuning is crucial for aligning language policies with
intended behaviors (e.g., creativity and safety). A key challenge here is to
develop steerable language models that trade-off multiple (conflicting)
objectives in a flexible and efficient manner. This paper presents Conditioned
Language Policy (CLP), a general framework for finetuning language models on
multiple objectives. Building on techniques from multi-task training and
parameter-efficient finetuning, CLP can learn steerable models that effectively
trade-off conflicting objectives at inference time. Notably, this does not
require training or maintaining multiple models to achieve different trade-offs
between the objectives. Through an extensive set of experiments and ablations,
we show that the CLP framework learns steerable models that outperform and
Pareto-dominate the current state-of-the-art approaches for multi-objective
finetuning.

摘要：基於獎勵的微調對於將語言政策與預期的行為（例如，創意和安全性）相符至關重要。此處的主要挑戰是開發可控語言模型，以靈活且有效的方式權衡多個（衝突）目標。本文提出了條件語言政策（CLP），這是一個在多個目標上微調語言模型的通用框架。CLP 建立在多任務訓練和參數有效微調的技術之上，可以學習可控模型，在推理時有效權衡衝突目標。值得注意的是，這不需要訓練或維護多個模型來實現目標之間的不同權衡。通過廣泛的實驗和消融，我們展示了 CLP 框架學習了可控模型，這些模型優於並在帕累托意義上優於當前多目標微調的最新方法。

##### **Model editing for distribution shifts in uranium oxide morphological analysis**
2407.15756v1 by Davis Brown, Cody Nizinski, Madelyn Shapiro, Corey Fallon, Tianzhixi Yin, Henry Kvinge, Jonathan H. Tu

Deep learning still struggles with certain kinds of scientific data. Notably,
pretraining data may not provide coverage of relevant distribution shifts
(e.g., shifts induced via the use of different measurement instruments). We
consider deep learning models trained to classify the synthesis conditions of
uranium ore concentrates (UOCs) and show that model editing is particularly
effective for improving generalization to distribution shifts common in this
domain. In particular, model editing outperforms finetuning on two curated
datasets comprising of micrographs taken of U$_{3}$O$_{8}$ aged in humidity
chambers and micrographs acquired with different scanning electron microscopes,
respectively.

摘要：深度學習仍難以處理特定類型的科學資料。值得注意的是，預訓練資料可能無法涵蓋相關分佈轉移（例如，因使用不同的測量儀器而引發的轉移）。我們考慮訓練深度學習模型以分類鈾礦精礦（UOC）的合成條件，並表明模型編輯對於改善在該領域常見的分佈轉移的泛化特別有效。特別是，模型編輯在兩個策展資料集上的表現優於微調，這些資料集包含在濕度室中老化的 U3O8 的顯微照片以及分別使用不同的掃描電子顯微鏡獲得的顯微照片。

##### **LongVideoBench: A Benchmark for Long-context Interleaved Video-Language Understanding**
2407.15754v1 by Haoning Wu, Dongxu Li, Bei Chen, Junnan Li

Large multimodal models (LMMs) are processing increasingly longer and richer
inputs. Albeit the progress, few public benchmark is available to measure such
development. To mitigate this gap, we introduce LongVideoBench, a
question-answering benchmark that features video-language interleaved inputs up
to an hour long. Our benchmark includes 3,763 varying-length web-collected
videos with their subtitles across diverse themes, designed to comprehensively
evaluate LMMs on long-term multimodal understanding. To achieve this, we
interpret the primary challenge as to accurately retrieve and reason over
detailed multimodal information from long inputs. As such, we formulate a novel
video question-answering task termed referring reasoning. Specifically, as part
of the question, it contains a referring query that references related video
contexts, called referred context. The model is then required to reason over
relevant video details from the referred context. Following the paradigm of
referring reasoning, we curate 6,678 human-annotated multiple-choice questions
in 17 fine-grained categories, establishing one of the most comprehensive
benchmarks for long-form video understanding. Evaluations suggest that the
LongVideoBench presents significant challenges even for the most advanced
proprietary models (e.g. GPT-4o, Gemini-1.5-Pro, GPT-4-Turbo), while their
open-source counterparts show an even larger performance gap. In addition, our
results indicate that model performance on the benchmark improves only when
they are capable of processing more frames, positioning LongVideoBench as a
valuable benchmark for evaluating future-generation long-context LMMs.

摘要：大型多模態模型 (LMM) 正在處理越來越長且豐富的輸入。儘管進展順利，但很少有公開基準可用於衡量此類開發。為了縮小這種差距，我們引入了 LongVideoBench，這是一個問答基準，其特點是長達一小時的視訊語言交錯輸入。我們的基準包括 3,763 個長度不同的網路收集視訊及其字幕，涵蓋各種主題，旨在全面評估 LMM 在長期多模態理解上的表現。為此，我們將主要挑戰詮釋為準確擷取和推論長輸入中的詳細多模態資訊。因此，我們制定了一項新穎的視訊問答任務，稱為指涉推理。具體來說，它包含一個指涉查詢作為問題的一部分，該查詢參考相關視訊內容，稱為指涉內容。然後，模型需要根據指涉內容中的相關視訊細節進行推理。遵循指涉推理的範例，我們策劃了 6,678 個由人工標註的多重選擇題，分為 17 個細緻類別，建立了最全面的長篇視訊理解基準之一。評估表明，即使是最先進的專有模型（例如 GPT-4o、Gemini-1.5-Pro、GPT-4-Turbo），LongVideoBench 也提出了重大挑戰，而它們的開源對應模型則顯示出更大的效能差距。此外，我們的結果表明，模型在基準上的效能只有在它們能夠處理更多幀時才會提升，這使得 LongVideoBench 成為評估未來世代長內容 LMM 的寶貴基準。

##### **MoRSE: Bridging the Gap in Cybersecurity Expertise with Retrieval Augmented Generation**
2407.15748v1 by Marco Simoni, Andrea Saracino, Vinod P., Mauro Conti

In this paper, we introduce MoRSE (Mixture of RAGs Security Experts), the
first specialised AI chatbot for cybersecurity. MoRSE aims to provide
comprehensive and complete knowledge about cybersecurity. MoRSE uses two RAG
(Retrieval Augmented Generation) systems designed to retrieve and organize
information from multidimensional cybersecurity contexts. MoRSE differs from
traditional RAGs by using parallel retrievers that work together to retrieve
semantically related information in different formats and structures. Unlike
traditional Large Language Models (LLMs) that rely on Parametric Knowledge
Bases, MoRSE retrieves relevant documents from Non-Parametric Knowledge Bases
in response to user queries. Subsequently, MoRSE uses this information to
generate accurate answers. In addition, MoRSE benefits from real-time updates
to its knowledge bases, enabling continuous knowledge enrichment without
retraining. We have evaluated the effectiveness of MoRSE against other
state-of-the-art LLMs, evaluating the system on 600 cybersecurity specific
questions. The experimental evaluation has shown that the improvement in terms
of relevance and correctness of the answer is more than 10\% compared to known
solutions such as GPT-4 and Mixtral 7x8.

摘要：在本文中，我們介紹 MoRSE（RAG 安全專家的混合），第一個專門用於網路安全的 AI 聊天機器人。MoRSE 旨在提供關於網路安全的全面且完整的知識。MoRSE 使用兩個 RAG（檢索增強生成）系統，旨在從多維網路安全情境中檢索和整理資訊。MoRSE 與傳統的 RAG 不同，它使用並行檢索器共同運作，以檢索不同格式和結構中的語義相關資訊。與依賴參數化知識庫的傳統大型語言模型 (LLM) 不同，MoRSE 根據使用者查詢從非參數化知識庫中檢索相關文件。隨後，MoRSE 使用這些資訊產生準確的答案。此外，MoRSE 受益於其知識庫的即時更新，可以在不重新訓練的情況下持續豐富知識。我們已經評估了 MoRSE 對比其他最先進的 LLM 的有效性，在 600 個網路安全特定問題上評估系統。實驗評估表明，與已知的解決方案（例如 GPT-4 和 Mixtral 7x8）相比，答案相關性和正確性的改進超過 10%。

##### **Diffusion for Out-of-Distribution Detection on Road Scenes and Beyond**
2407.15739v1 by Silvio Galesso, Philipp Schröppel, Hssan Driss, Thomas Brox

In recent years, research on out-of-distribution (OoD) detection for semantic
segmentation has mainly focused on road scenes -- a domain with a constrained
amount of semantic diversity. In this work, we challenge this constraint and
extend the domain of this task to general natural images. To this end, we
introduce: 1. the ADE-OoD benchmark, which is based on the ADE20k dataset and
includes images from diverse domains with a high semantic diversity, and 2. a
novel approach that uses Diffusion score matching for OoD detection (DOoD) and
is robust to the increased semantic diversity. ADE-OoD features indoor and
outdoor images, defines 150 semantic categories as in-distribution, and
contains a variety of OoD objects. For DOoD, we train a diffusion model with an
MLP architecture on semantic in-distribution embeddings and build on the score
matching interpretation to compute pixel-wise OoD scores at inference time. On
common road scene OoD benchmarks, DOoD performs on par or better than the state
of the art, without using outliers for training or making assumptions about the
data domain. On ADE-OoD, DOoD outperforms previous approaches, but leaves much
room for future improvements.

摘要：近年來，針對語意分割的分布外 (OoD) 偵測研究主要集中在道路場景，這是一個語意多樣性受限的領域。在此研究中，我們挑戰此限制，並將此任務的領域擴展到一般自然影像。為此，我們提出：1. ADE-OoD 基準，它基於 ADE20k 資料集，並包含來自具有高度語意多樣性的不同領域的影像，以及 2. 一種使用擴散分數配對進行 OoD 偵測 (DOoD) 的新穎方法，且對增加的語意多樣性具有魯棒性。ADE-OoD 具有室內和室外影像，定義 150 個語意類別作為分布內，並包含各種 OoD 物件。對於 DOoD，我們使用 MLP 架構訓練一個擴散模型，在語意分布內嵌入中，並建立在分數配對詮釋上，以在推理時計算逐像素的 OoD 分數。在常見道路場景 OoD 基準上，DOoD 的表現與現有技術相當或更好，而無需使用異常值進行訓練或對資料領域做出假設。在 ADE-OoD 上，DOoD 優於先前的做法，但仍有很大的改進空間。

##### **Parallel Split Learning with Global Sampling**
2407.15738v1 by Mohammad Kohankhaki, Ahmad Ayad, Mahdi Barhoush, Anke Schmeink

The expansion of IoT devices and the demands of Deep Learning have
highlighted significant challenges in Distributed Deep Learning (DDL) systems.
Parallel Split Learning (PSL) has emerged as a promising derivative of Split
Learning that is well suited for distributed learning on resource-constrained
devices. However, PSL faces several obstacles, such as large effective batch
sizes, non-IID data distributions, and the straggler effect. We view these
issues as a sampling dilemma and propose to address them by orchestrating the
mini-batch sampling process on the server side. We introduce the Uniform Global
Sampling (UGS) method to decouple the effective batch size from the number of
clients and reduce mini-batch deviation in non-IID settings. To address the
straggler effect, we introduce the Latent Dirichlet Sampling (LDS) method,
which generalizes UGS to balance the trade-off between batch deviation and
training time. Our simulations reveal that our proposed methods enhance model
accuracy by up to 34.1% in non-IID settings and reduce the training time in the
presence of stragglers by up to 62%. In particular, LDS effectively mitigates
the straggler effect without compromising model accuracy or adding significant
computational overhead compared to UGS. Our results demonstrate the potential
of our methods as a promising solution for DDL in real applications.

摘要：物联网设备的扩张和深度学习的需求突出了分布式深度学习 (DDL) 系统中的重大挑战。
并行拆分学习 (PSL) 已成为拆分学习的一个有前途的衍生产品，非常适合在资源受限的设备上进行分布式学习。
然而，PSL 面临着一些障碍，例如有效批次大小大、非 IID 数据分布和掉队者效应。
我们将这些问题视为抽样难题，并提出通过在服务器端编排小批量抽样过程来解决这些问题。
我们引入了统一全局采样 (UGS) 方法，以将有效批次大小与客户端数量解耦，并减少非 IID 设置中的小批量偏差。
为了解决掉队者效应，我们引入了潜在狄利克雷采样 (LDS) 方法，该方法将 UGS 概括为平衡批次偏差和训练时间之间的权衡。
我们的模拟表明，我们提出的方法将非 IID 设置中的模型准确度提高了 34.1%，并在存在掉队者的情况下将训练时间减少了 62%。
特别是，与 UGS 相比，LDS 有效地减轻了掉队者效应，而不会损害模型准确性或增加显着的计算开销。
我们的结果证明了我们的方法作为实际应用中 DDL 的有前途的解决方案的潜力。

##### **OMoS-QA: A Dataset for Cross-Lingual Extractive Question Answering in a German Migration Context**
2407.15736v1 by Steffen Kleinle, Jakob Prange, Annemarie Friedrich

When immigrating to a new country, it is easy to feel overwhelmed by the need
to obtain information on financial support, housing, schooling, language
courses, and other issues. If relocation is rushed or even forced, the
necessity for high-quality answers to such questions is all the more urgent.
Official immigration counselors are usually overbooked, and online systems
could guide newcomers to the requested information or a suitable counseling
service.
  To this end, we present OMoS-QA, a dataset of German and English questions
paired with relevant trustworthy documents and manually annotated answers,
specifically tailored to this scenario. Questions are automatically generated
with an open-source large language model (LLM) and answer sentences are
selected by crowd workers with high agreement. With our data, we conduct a
comparison of 5 pretrained LLMs on the task of extractive question answering
(QA) in German and English. Across all models and both languages, we find high
precision and low-to-mid recall in selecting answer sentences, which is a
favorable trade-off to avoid misleading users. This performance even holds up
when the question language does not match the document language. When it comes
to identifying unanswerable questions given a context, there are larger
differences between the two languages.

摘要：<paragraph>在移民到一个新国家时，很容易因需要获得有关财务支持、住房、教育、语言课程和其他问题的信息而感到不知所措。如果搬迁仓促甚至被迫，那么对这些问题的高质量答案的需求就更加迫切。官方移民顾问通常都很忙，而在线系统可以指导新移民获得所需信息或合适的咨询服务。
为此，我们提出了 OMoS-QA，这是一个德语和英语问题数据集，配有相关的可信文件和手动注释的答案，专门针对这种情况量身定制。问题是使用开源大型语言模型 (LLM) 自动生成的，答案句子是由高度一致的众包工作者选择的。利用我们的数据，我们对 5 个预训练 LLM 在德语和英语的抽取式问题解答 (QA) 任务上进行了比较。在所有模型和两种语言中，我们发现选择答案句子的高精度和中低召回率，这是避免误导用户的有利权衡。即使问题语言与文档语言不匹配，此性能仍然成立。当需要在给定上下文中识别无法回答的问题时，两种语言之间存在较大差异。</paragraph>

##### **TaskGen: A Task-Based, Memory-Infused Agentic Framework using StrictJSON**
2407.15734v1 by John Chong Min Tan, Prince Saroj, Bharat Runwal, Hardik Maheshwari, Brian Lim Yi Sheng, Richard Cottrill, Alankrit Chona, Ambuj Kumar, Mehul Motani

TaskGen is an open-sourced agentic framework which uses an Agent to solve an
arbitrary task by breaking them down into subtasks. Each subtask is mapped to
an Equipped Function or another Agent to execute. In order to reduce verbosity
(and hence token usage), TaskGen uses StrictJSON that ensures JSON output from
the Large Language Model (LLM), along with additional features such as type
checking and iterative error correction. Key to the philosophy of TaskGen is
the management of information/memory on a need-to-know basis. We empirically
evaluate TaskGen on various environments such as 40x40 dynamic maze navigation
with changing obstacle locations (100% solve rate), TextWorld escape room
solving with dense rewards and detailed goals (96% solve rate), web browsing
(69% of actions successful), solving the MATH dataset (71% solve rate over 100
Level-5 problems), Retrieval Augmented Generation on NaturalQuestions dataset
(F1 score of 47.03%)

摘要：TaskGen 是一個開源的代理框架，它使用一個代理來解決任意的任務，方法是將它們分解成子任務。每個子任務都對應到一個裝備功能或另一個代理來執行。為了減少冗長（因此減少令牌使用），TaskGen 使用 StrictJSON，它確保大型語言模型 (LLM) 的 JSON 輸出，以及類型檢查和迭代錯誤修正等額外功能。TaskGen 的哲學關鍵在於根據需要知道來管理資訊/記憶體。我們在各種環境中對 TaskGen 進行經驗評估，例如 40x40 動態迷宮導航，障礙物位置會改變（100% 解決率）、TextWorld 密室逃脫，有密集的獎勵和詳細的目標（96% 解決率）、網頁瀏覽（69% 的動作成功）、解決 MATH 資料集（超過 100 個 5 級問題的 71% 解決率）、自然問題資料集上的檢索擴充生成（F1 分數為 47.03%）

##### **DStruct2Design: Data and Benchmarks for Data Structure Driven Generative Floor Plan Design**
2407.15723v1 by Zhi Hao Luo, Luis Lara, Ge Ya Luo, Florian Golemo, Christopher Beckham, Christopher Pal

Text conditioned generative models for images have yielded impressive
results. Text conditioned floorplan generation as a special type of raster
image generation task also received particular attention. However there are
many use cases in floorpla generation where numerical properties of the
generated result are more important than the aesthetics. For instance, one
might want to specify sizes for certain rooms in a floorplan and compare the
generated floorplan with given specifications Current approaches, datasets and
commonly used evaluations do not support these kinds of constraints. As such,
an attractive strategy is to generate an intermediate data structure that
contains numerical properties of a floorplan which can be used to generate the
final floorplan image. To explore this setting we (1) construct a new dataset
for this data-structure to data-structure formulation of floorplan generation
using two popular image based floorplan datasets RPLAN and ProcTHOR-10k, and
provide the tools to convert further procedurally generated ProcTHOR floorplan
data into our format. (2) We explore the task of floorplan generation given a
partial or complete set of constraints and we design a series of metrics and
benchmarks to enable evaluating how well samples generated from models respect
the constraints. (3) We create multiple baselines by finetuning a large
language model (LLM), Llama3, and demonstrate the feasibility of using
floorplan data structure conditioned LLMs for the problem of floorplan
generation respecting numerical constraints. We hope that our new datasets and
benchmarks will encourage further research on different ways to improve the
performance of LLMs and other generative modelling techniques for generating
designs where quantitative constraints are only partially specified, but must
be respected.

摘要：文本条件生成模型已为图像产生了令人印象深刻的结果。文本条件平面图生成作为光栅图像生成任务的一种特殊类型也受到了特别的关注。然而，在平面图生成中，生成结果的数字属性比美学更重要的用例有很多。例如，人们可能希望指定平面图中某些房间的大小，并将生成的平面图与给定的规格进行比较。当前的方法、数据集和常用的评估不支持这些类型的约束。因此，一个有吸引力的策略是生成一个包含平面图数字属性的中间数据结构，该数据结构可用于生成最终的平面图图像。为了探索此设置，我们 (1) 为此数据结构构建了一个新的数据集，以使用两个流行的基于图像的平面图数据集 RPLAN 和 ProcTHOR-10k 对平面图生成进行数据结构到数据结构的表述，并提供将进一步程序生成的 ProcTHOR 平面图数据转换为我们格式的工具。(2) 我们探索了在给定部分或完整约束集的情况下平面图生成的 任务，并且我们设计了一系列指标和基准来评估从模型生成的样本如何尊重约束。(3) 我们通过微调大型语言模型 (LLM) Llama3 来创建多个基线，并展示了使用平面图数据结构条件 LLM 解决平面图生成问题以尊重数字约束的可行性。我们希望我们的新数据集和基准将鼓励对提高 LLM 和其他生成建模技术性能的不同方式进行进一步的研究，以生成数量约束仅部分指定但必须尊重的设计。

##### **Do Large Language Models Have Compositional Ability? An Investigation into Limitations and Scalability**
2407.15720v1 by Zhuoyan Xu, Zhenmei Shi, Yingyu Liang

Large language models (LLMs) have emerged as powerful tools for many AI
problems and exhibit remarkable in-context learning (ICL) capabilities.
Compositional ability, solving unseen complex tasks that combine two or more
simple tasks, is an essential reasoning ability for Artificial General
Intelligence. Despite LLM's tremendous success, how they approach composite
tasks, especially those not encountered during the pretraining phase, remains
an open question and largely ununderstood. In this study, we delve into the ICL
capabilities of LLMs on composite tasks, with only simple tasks as in-context
examples. We develop a test suite of composite tasks that include linguistic
and logical challenges and perform empirical studies across different LLM
families. We observe that models exhibit divergent behaviors: (1) For simpler
composite tasks that apply distinct mapping mechanisms to different input
segments, the models demonstrate decent compositional ability, while scaling up
the model enhances this ability; (2) for more complex composite tasks that
involving reasoning multiple steps, where each step represent one task, models
typically underperform, and scaling up generally provide no improvements. We
offer theoretical analysis in a simplified setting, explaining that models
exhibit compositional capability when the task handles different input parts
separately. We believe our work sheds new light on the capabilities of LLMs in
solving composite tasks regarding the nature of the tasks and model scale. Our
dataset and code are available at
{\url{https://github.com/OliverXUZY/LLM_Compose}}.

摘要：大型語言模型 (LLM) 已成為許多人工智慧問題的強大工具，並展現出顯著的語境學習 (ICL) 能力。組合能力，解決結合兩個或更多簡單任務的未見過複雜任務，是人工通用智慧的必要推理能力。儘管 LLM 獲得巨大成功，但它們如何處理複合任務，特別是在預訓練階段未遇到的任務，仍然是一個未解且在很大程度上尚未理解的問題。在本研究中，我們深入探討 LLM 在複合任務上的 ICL 能力，僅使用簡單任務作為語境範例。我們開發了一套包含語言和邏輯挑戰的複合任務測試套件，並對不同的 LLM 家族進行實證研究。我們觀察到模型表現出不同的行為：(1) 對於將不同的映射機制應用於不同輸入區段的較簡單的複合任務，模型表現出良好的組合能力，而擴大模型會增強這種能力；(2) 對於涉及多個步驟推理的更複雜的複合任務，其中每個步驟代表一個任務，模型通常表現不佳，而擴大規模通常不會帶來任何改進。我們在簡化的環境中提供理論分析，說明當任務將不同的輸入部分分開處理時，模型會表現出組合能力。我們相信我們的研究為 LLM 在解決複合任務方面的能力提供了新的見解，涉及任務的性質和模型規模。我們的資料集和程式碼可在
{\url{https://github.com/OliverXUZY/LLM_Compose}} 取得。

##### **GFE-Mamba: Mamba-based AD Multi-modal Progression Assessment via Generative Feature Extraction from MCI**
2407.15719v1 by Zhaojie Fang, Shenghao Zhu, Yifei Chen, Binfeng Zou, Fan Jia, Linwei Qiu, Chang Liu, Yiyu Huang, Xiang Feng, Feiwei Qin, Changmiao Wang, Yeru Wang, Jin Fan, Changbiao Chu, Wan-Zhen Wu, Hu Zhao

Alzheimer's Disease (AD) is an irreversible neurodegenerative disorder that
often progresses from Mild Cognitive Impairment (MCI), leading to memory loss
and significantly impacting patients' lives. Clinical trials indicate that
early targeted interventions for MCI patients can potentially slow or halt the
development and progression of AD. Previous research has shown that accurate
medical classification requires the inclusion of extensive multimodal data,
such as assessment scales and various neuroimaging techniques like Magnetic
Resonance Imaging (MRI) and Positron Emission Tomography (PET). However,
consistently tracking the diagnosis of the same individual over time and
simultaneously collecting multimodal data poses significant challenges. To
address this issue, we introduce GFE-Mamba, a classifier based on Generative
Feature Extraction (GFE). This classifier effectively integrates data from
assessment scales, MRI, and PET, enabling deeper multimodal fusion. It
efficiently extracts both long and short sequence information and incorporates
additional information beyond the pixel space. This approach not only improves
classification accuracy but also enhances the interpretability and stability of
the model. We constructed datasets of over 3000 samples based on the
Alzheimer's Disease Neuroimaging Initiative (ADNI) for a two-step training
process. Our experimental results demonstrate that the GFE-Mamba model is
effective in predicting the conversion from MCI to AD and outperforms several
state-of-the-art methods. Our source code and ADNI dataset processing code are
available at https://github.com/Tinysqua/GFE-Mamba.

摘要：阿茲海默症 (AD) 是一種不可逆的神經退化性疾病，
通常會從輕度認知障礙 (MCI) 惡化，導致記憶力減退
並對病患的生活產生重大影響。臨床試驗顯示，
針對 MCI 病患的早期目標性干預措施，有可能減緩或停止
AD 的發展和惡化。先前的研究顯示，精確的
醫療分類需要納入廣泛的多模式數據，
例如評估量表和各種神經影像技術，如磁振造影 (MRI) 和正子斷層掃描 (PET)。然而，
持續追蹤同一位個體的診斷結果，並同時收集多模式數據，會造成重大的挑戰。為了
解決這個問題，我們引入了 GFE-Mamba，一種基於生成特徵萃取 (GFE) 的分類器。此分類器有效整合來自
評估量表、MRI 和 PET 的數據，實現更深入的多模式融合。它
有效率地萃取出長序列和短序列資訊，並納入像素空間以外的額外資訊。這種方法不僅提升了
分類準確度，也增強了模型的可解釋性和穩定性。我們根據
阿茲海默症神經影像倡議組織 (ADNI) 建立了超過 3000 個樣本的資料集，用於兩階段訓練
過程。我們的實驗結果證明，GFE-Mamba 模型在預測從 MCI 轉變為 AD 上是有效的，並且優於多種
最先進的方法。我們的原始程式碼和 ADNI 資料集處理程式碼可於 https://github.com/Tinysqua/GFE-Mamba 取得。

##### **Mamba meets crack segmentation**
2407.15714v1 by Zhili He, Yu-Hsing Wang

Cracks pose safety risks to infrastructure and cannot be overlooked. The
prevailing structures in existing crack segmentation networks predominantly
consist of CNNs or Transformers. However, CNNs exhibit a deficiency in global
modeling capability, hindering the representation to entire crack features.
Transformers can capture long-range dependencies but suffer from high and
quadratic complexity. Recently, Mamba has garnered extensive attention due to
its linear spatial and computational complexity and its powerful global
perception. This study explores the representation capabilities of Mamba to
crack features. Specifically, this paper uncovers the connection between Mamba
and the attention mechanism, providing a profound insight, an attention
perspective, into interpreting Mamba and devising a novel Mamba module
following the principles of attention blocks, namely CrackMamba. We compare
CrackMamba with the most prominent visual Mamba modules, Vim and Vmamba, on two
datasets comprising asphalt pavement and concrete pavement cracks, and steel
cracks, respectively. The quantitative results show that CrackMamba stands out
as the sole Mamba block consistently enhancing the baseline model's performance
across all evaluation measures, while reducing its parameters and computational
costs. Moreover, this paper substantiates that Mamba can achieve global
receptive fields through both theoretical analysis and visual interpretability.
The discoveries of this study offer a dual contribution. First, as a
plug-and-play and simple yet effective Mamba module, CrackMamba exhibits
immense potential for integration into various crack segmentation models.
Second, the proposed innovative Mamba design concept, integrating Mamba with
the attention mechanism, holds significant reference value for all Mamba-based
computer vision models, not limited to crack segmentation networks, as
investigated in this study.

摘要：<paragraph>裂縫會對基礎設施構成安全風險，不可忽視。
現有裂縫分割網路中的主要結構主要由 CNN 或 Transformer 組成。然而，CNN 在全局建模能力方面存在缺陷，阻礙了對整個裂縫特徵的表示。Transformer 可以捕捉長距離依賴關係，但會帶來高二次複雜度。最近，Mamba 因其線性空間和計算複雜度以及強大的全局感知而備受關注。本研究探討了 Mamba 對裂縫特徵的表示能力。具體來說，本文揭示了 Mamba 與注意力機制之間的聯繫，提供了深刻的見解，一種注意力視角，用於解釋 Mamba 並設計一個遵循注意力區塊原理的新 Mamba 模塊，即 CrackMamba。我們在包含瀝青路面和混凝土路面裂縫以及鋼鐵裂縫的兩個數據集上將 CrackMamba 與最突出的視覺 Mamba 模塊 Vim 和 Vmamba 進行了比較。定量結果表明，CrackMamba 脫穎而出，成為唯一始終如一地提高基線模型在所有評估指標上的性能的 Mamba 區塊，同時減少其參數和計算成本。此外，本文通過理論分析和視覺可解釋性證實了 Mamba 可以實現全局感受野。本研究的發現提供了雙重貢獻。首先，作為一個即插即用且簡單但有效的 Mamba 模塊，CrackMamba 展示了巨大的潛力，可以整合到各種裂縫分割模型中。其次，提出的創新的 Mamba 設計概念，將 Mamba 與注意力機制相結合，對所有基於 Mamba 的計算機視覺模型具有重要的參考價值，不僅限於裂縫分割網路，如本研究中所探討的。</paragraph>

##### **AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?**
2407.15711v1 by Ori Yoran, Samuel Joseph Amouyal, Chaitanya Malaviya, Ben Bogin, Ofir Press, Jonathan Berant

Language agents, built on top of language models (LMs), are systems that can
interact with complex environments, such as the open web. In this work, we
examine whether such agents can perform realistic and time-consuming tasks on
the web, e.g., monitoring real-estate markets or locating relevant nearby
businesses. We introduce AssistantBench, a challenging new benchmark consisting
of 214 realistic tasks that can be automatically evaluated, covering different
scenarios and domains. We find that AssistantBench exposes the limitations of
current systems, including language models and retrieval-augmented language
models, as no model reaches an accuracy of more than 25 points. While
closed-book LMs perform well, they exhibit low precision since they tend to
hallucinate facts. State-of-the-art web agents reach a score of near zero.
Additionally, we introduce SeePlanAct (SPA), a new web agent that significantly
outperforms previous agents, and an ensemble of SPA and closed-book models
reaches the best overall performance. Moreover, we analyze failures of current
systems and highlight that web navigation remains a major challenge.

摘要：建構於語言模型 (LM) 之上的語言代理，是能與複雜環境（如開放網路）互動的系統。在此研究中，我們探討此類代理是否能在網路上執行實際且耗時的任務，例如監控房地產市場或尋找鄰近相關商家。我們引進了 AssistantBench，這是一個由 214 個實際任務組成的具挑戰性新基準，可自動評估，涵蓋不同的情境和領域。我們發現 AssistantBench 揭露了當前系統的限制，包括語言模型和檢索增強語言模型，因為沒有任何模型的準確率超過 25 分。雖然閉卷 LM 表現良好，但它們的精確度很低，因為它們傾向於虛構事實。最先進的網路代理達到接近零的分數。此外，我們引進了 SeePlanAct (SPA)，這是一個明顯優於先前代理的新網路代理，而 SPA 和閉卷模型的整體表現達到最佳。此外，我們分析了當前系統的失敗，並強調網路導航仍然是一項重大挑戰。

##### **SwinSF: Image Reconstruction from Spatial-Temporal Spike Streams**
2407.15708v1 by Liangyan Jiang, Chuang Zhu, Yanxu Chen

The spike camera, with its high temporal resolution, low latency, and high
dynamic range, addresses high-speed imaging challenges like motion blur. It
captures photons at each pixel independently, creating binary spike streams
rich in temporal information but challenging for image reconstruction. Current
algorithms, both traditional and deep learning-based, still need to be improved
in the utilization of the rich temporal detail and the restoration of the
details of the reconstructed image. To overcome this, we introduce Swin
Spikeformer (SwinSF), a novel model for dynamic scene reconstruction from spike
streams. SwinSF is composed of Spike Feature Extraction, Spatial-Temporal
Feature Extraction, and Final Reconstruction Module. It combines shifted window
self-attention and proposed temporal spike attention, ensuring a comprehensive
feature extraction that encapsulates both spatial and temporal dynamics,
leading to a more robust and accurate reconstruction of spike streams.
Furthermore, we build a new synthesized dataset for spike image reconstruction
which matches the resolution of the latest spike camera, ensuring its relevance
and applicability to the latest developments in spike camera imaging.
Experimental results demonstrate that the proposed network SwinSF sets a new
benchmark, achieving state-of-the-art performance across a series of datasets,
including both real-world and synthesized data across various resolutions. Our
codes and proposed dataset will be available soon.

摘要：尖峰相機以其高時間解析度、低延遲和高動態範圍，解決了運動模糊等高速影像挑戰。它獨立捕捉每個畫素的光子，產生富含時間資訊的二進位尖峰串流，但對於影像重建而言卻是項挑戰。目前的演算法，無論是傳統的還是基於深度學習的，在利用豐富的時間細節和重建影像的細節方面仍需要改進。為了克服這個問題，我們引入了 Swin Spikeformer (SwinSF)，這是一個從尖峰串流重建動態場景的新穎模型。SwinSF 由尖峰特徵提取、時空特徵提取和最終重建模組組成。它結合了位移視窗自注意力和提出的時序尖峰注意力，確保全面的特徵提取，涵蓋空間和時間動態，從而對尖峰串流進行更強健且準確的重建。此外，我們建立了一個新的合成資料集，用於尖峰影像重建，其解析度與最新的尖峰相機相符，確保其與尖峰相機影像的最新發展相關且適用。實驗結果表明，所提出的 SwinSF 網路樹立了一個新的基準，在各種資料集（包括各種解析度的真實世界和合成資料）中實現了最先進的效能。我們的程式碼和提出的資料集將很快提供。

##### **Predicting the Best of N Visual Trackers**
2407.15707v1 by Basit Alawode, Sajid Javed, Arif Mahmood, Jiri Matas

We observe that the performance of SOTA visual trackers surprisingly strongly
varies across different video attributes and datasets. No single tracker
remains the best performer across all tracking attributes and datasets. To
bridge this gap, for a given video sequence, we predict the "Best of the N
Trackers", called the BofN meta-tracker. At its core, a Tracking Performance
Prediction Network (TP2N) selects a predicted best performing visual tracker
for the given video sequence using only a few initial frames. We also introduce
a frame-level BofN meta-tracker which keeps predicting best performer after
regular temporal intervals. The TP2N is based on self-supervised learning
architectures MocoV2, SwAv, BT, and DINO; experiments show that the DINO with
ViT-S as a backbone performs the best. The video-level BofN meta-tracker
outperforms, by a large margin, existing SOTA trackers on nine standard
benchmarks - LaSOT, TrackingNet, GOT-10K, VOT2019, VOT2021, VOT2022, UAV123,
OTB100, and WebUAV-3M. Further improvement is achieved by the frame-level BofN
meta-tracker effectively handling variations in the tracking scenarios within
long sequences. For instance, on GOT-10k, BofN meta-tracker average overlap is
88.7% and 91.1% with video and frame-level settings respectively. The best
performing tracker, RTS, achieves 85.20% AO. On VOT2022, BofN expected average
overlap is 67.88% and 70.98% with video and frame level settings, compared to
the best performing ARTrack, 64.12%. This work also presents an extensive
evaluation of competitive tracking methods on all commonly used benchmarks,
following their protocols. The code, the trained models, and the results will
soon be made publicly available on
https://github.com/BasitAlawode/Best_of_N_Trackers.

摘要：<paragraph>我們觀察到，SOTA 視覺追蹤器的效能驚人地因不同的影片屬性和資料集而有很大的差異。沒有單一追蹤器能在所有追蹤屬性和資料集上保持最佳效能。為了彌合這個差距，對於給定的影片序列，我們預測「N 個追蹤器中的最佳者」，稱為 BofN 元追蹤器。其核心是一個追蹤效能預測網路 (TP2N)，它使用僅有幾個初始畫格，就能為給定的影片序列選擇預測的最佳效能視覺追蹤器。我們還引進了一個畫格層級的 BofN 元追蹤器，它會在規律的時間間隔後持續預測最佳效能。TP2N 基於自監督學習架構 MocoV2、SwAv、BT 和 DINO；實驗顯示，以 ViT-S 作為主幹的 DINO 效能最佳。影片層級的 BofN 元追蹤器在九個標準基準上大幅優於現有的 SOTA 追蹤器，包括 LaSOT、TrackingNet、GOT-10K、VOT2019、VOT2021、VOT2022、UAV123、OTB100 和 WebUAV-3M。畫格層級的 BofN 元追蹤器有效處理長序列中追蹤場景的變化，進一步提升了效能。例如，在 GOT-10k 上，BofN 元追蹤器平均重疊率分別為 88.7% 和 91.1%，使用影片和畫格層級設定。效能最佳的追蹤器 RTS 達到 85.20% 的 AO。在 VOT2022 上，BofN 預期平均重疊率分別為 67.88% 和 70.98%，使用影片和畫格層級設定，而效能最佳的 ARTrack 為 64.12%。這項工作還根據各個基準的協定，對所有常用的基準進行了競爭追蹤方法的廣泛評估。程式碼、訓練模型和結果將很快在 https://github.com/BasitAlawode/Best_of_N_Trackers 上公開。</paragraph>

##### **Supporting the Digital Autonomy of Elders Through LLM Assistance**
2407.15695v1 by Jesse Roberts, Lindsey Roberts, Alice Reed

The internet offers tremendous access to services, social connections, and
needed products. However, to those without sufficient experience, engaging with
businesses and friends across the internet can be daunting due to the ever
present danger of scammers and thieves, to say nothing of the myriad of
potential computer viruses. Like a forest rich with both edible and poisonous
plants, those familiar with the norms inhabit it safely with ease while
newcomers need a guide. However, reliance on a human digital guide can be
taxing and often impractical. We propose and pilot a simple but unexplored
idea: could an LLM provide the necessary support to help the elderly who are
separated by the digital divide safely achieve digital autonomy?

摘要：網路提供了極大的服務、社交連結，以及必需產品的存取權。然而，對於沒有足夠經驗的人來說，與企業和朋友透過網路互動可能會令人望而生畏，因為詐騙者和小偷無所不在，更別說還有無數潛在的電腦病毒。就像一座富含可食用和有毒植物的森林，熟悉規範的人可以輕鬆安全地居住其中，而新手則需要一位嚮導。然而，依賴人類數位嚮導可能會很累人，而且常常不切實際。我們提出並試行了一個簡單但尚未探索的想法：大型語言模型 (LLM) 能否提供必要的支援，以幫助被數位鴻溝隔開的老年人安全地實現數位自主？

##### **Counter Turing Test ($CT^2$): Investigating AI-Generated Text Detection for Hindi -- Ranking LLMs based on Hindi AI Detectability Index ($ADI_{hi}$)**
2407.15694v1 by Ishan Kavathekar, Anku Rani, Ashmit Chamoli, Ponnurangam Kumaraguru, Amit Sheth, Amitava Das

The widespread adoption of large language models (LLMs) and awareness around
multilingual LLMs have raised concerns regarding the potential risks and
repercussions linked to the misapplication of AI-generated text, necessitating
increased vigilance. While these models are primarily trained for English,
their extensive training on vast datasets covering almost the entire web,
equips them with capabilities to perform well in numerous other languages.
AI-Generated Text Detection (AGTD) has emerged as a topic that has already
received immediate attention in research, with some initial methods having been
proposed, soon followed by the emergence of techniques to bypass detection. In
this paper, we report our investigation on AGTD for an indic language Hindi.
Our major contributions are in four folds: i) examined 26 LLMs to evaluate
their proficiency in generating Hindi text, ii) introducing the AI-generated
news article in Hindi ($AG_{hi}$) dataset, iii) evaluated the effectiveness of
five recently proposed AGTD techniques: ConDA, J-Guard, RADAR, RAIDAR and
Intrinsic Dimension Estimation for detecting AI-generated Hindi text, iv)
proposed Hindi AI Detectability Index ($ADI_{hi}$) which shows a spectrum to
understand the evolving landscape of eloquence of AI-generated text in Hindi.
We will make the codes and datasets available to encourage further research.

摘要：隨著大型語言模型 (LLM) 的廣泛採用，以及對多語言 LLM 的認識，人們開始關注與 AI 生成的文字誤用相關的潛在風險和影響，這需要提高警覺。儘管這些模型主要是針對英語訓練，但由於在涵蓋幾乎整個網路的龐大資料集上進行廣泛訓練，因此它們具備在許多其他語言中表現良好的能力。AI 生成的文字偵測 (AGTD) 已成為一個在研究中已立即受到關注的主題，一些最初的方法已被提出，隨後很快出現了繞過偵測的技術。在本文中，我們報告了我們對印度語言印地語的 AGTD 調查。我們的重大貢獻有四個方面：i) 檢查 26 個 LLM 以評估它們生成印地語文字的能力，ii) 介紹印地語 AI 生成的新聞文章 ($AG_{hi}$) 資料集，iii) 評估五種最近提出的 AGTD 技術的有效性：ConDA、J-Guard、RADAR、RAIDAR 和內在維度估計，以偵測 AI 生成的印地語文字，iv) 提出印地語 AI 可偵測性指標 ($ADI_{hi}$)，它顯示了一個光譜，用於了解印地語中 AI 生成的文字的表達能力不斷變化的現況。我們將提供程式碼和資料集，以鼓勵進一步的研究。

##### **AI-Driven Fast and Early Detection of IoT Botnet Threats: A Comprehensive Network Traffic Analysis Approach**
2407.15688v1 by Abdelaziz Amara korba, Aleddine Diaf, Yacine Ghamri-Doudane

In the rapidly evolving landscape of cyber threats targeting the Internet of
Things (IoT) ecosystem, and in light of the surge in botnet-driven Distributed
Denial of Service (DDoS) and brute force attacks, this study focuses on the
early detection of IoT bots. It specifically addresses the detection of stealth
bot communication that precedes and orchestrates attacks. This study proposes a
comprehensive methodology for analyzing IoT network traffic, including
considerations for both unidirectional and bidirectional flow, as well as
packet formats. It explores a wide spectrum of network features critical for
representing network traffic and characterizing benign IoT traffic patterns
effectively. Moreover, it delves into the modeling of traffic using various
semi-supervised learning techniques. Through extensive experimentation with the
IoT-23 dataset - a comprehensive collection featuring diverse botnet types and
traffic scenarios - we have demonstrated the feasibility of detecting botnet
traffic corresponding to different operations and types of bots, specifically
focusing on stealth command and control (C2) communications. The results
obtained have demonstrated the feasibility of identifying C2 communication with
a 100% success rate through packet-based methods and 94% via flow based
approaches, with a false positive rate of 1.53%.

摘要：在網路威脅快速演變的環境中，針對物聯網 (IoT) 生態系統，以及在機器人程式驅動的分布式阻斷服務 (DDoS) 和暴力破解攻擊激增的情況下，本研究專注於物聯網機器人程式的早期偵測。特別是偵測在攻擊之前和協調攻擊的匿蹤機器人程式通訊。本研究提出一個分析物聯網網路流量的全面方法，包括考量單向和雙向流量，以及封包格式。它探討了表示網路流量和有效表徵良性物聯網流量模式的廣泛網路功能。此外，它深入探討使用各種半監督學習技術對流量建模。透過對 IoT-23 資料集進行廣泛實驗，該資料集是一個包含不同機器人程式類型和流量場景的全面集合，我們已經證明了偵測與不同操作和機器人程式類型相應的機器人程式流量的可行性，特別專注於匿蹤命令和控制 (C2) 通訊。獲得的結果證明了透過封包方法以 100% 的成功率識別 C2 通訊的可行性，而透過流量方法則為 94%，誤判率為 1.53%。

##### **HaloQuest: A Visual Hallucination Dataset for Advancing Multimodal Reasoning**
2407.15680v1 by Zhecan Wang, Garrett Bingham, Adams Yu, Quoc Le, Thang Luong, Golnaz Ghiasi

Hallucination has been a major problem for large language models and remains
a critical challenge when it comes to multimodality in which vision-language
models (VLMs) have to deal with not just textual but also visual inputs.
Despite rapid progress in VLMs, resources for evaluating and addressing
multimodal hallucination are limited and mostly focused on evaluation. This
work introduces HaloQuest, a novel visual question answering dataset that
captures various aspects of multimodal hallucination such as false premises,
insufficient contexts, and visual challenges. A novel idea from HaloQuest is to
leverage synthetic images, apart from real ones, to enable dataset creation at
scale. With over 7.7K examples spanning across a wide variety of categories,
HaloQuest was designed to be both a challenging benchmark for VLMs and a
fine-tuning dataset for advancing multimodal reasoning. Our experiments reveal
that current models struggle with HaloQuest, with all open-source VLMs
achieving below 36% accuracy. On the other hand, fine-tuning on HaloQuest
significantly reduces hallucination rates while preserving performance on
standard reasoning tasks. Our results discover that benchmarking with generated
images is highly correlated (r=0.97) with real images. Last but not least, we
propose a novel Auto-Eval mechanism that is highly correlated with human raters
(r=0.99) for evaluating VLMs. In sum, this work makes concrete strides towards
understanding, evaluating, and mitigating hallucination in VLMs, serving as an
important step towards more reliable multimodal AI systems in the future.

摘要：對於大型語言模型而言，幻覺一直是一個主要問題，當視覺語言模型 (VLM) 不僅要處理文字，還要處理視覺輸入時，這仍然是多模態面臨的一項重大挑戰。儘管 VLM 快速進步，但用於評估和解決多模態幻覺的資源有限，而且大多集中在評估上。本研究引入了 HaloQuest，這是一個新穎的視覺問答資料集，它涵蓋了多模態幻覺的各個方面，例如錯誤前提、背景不足和視覺挑戰。HaloQuest 的一個新穎想法是利用合成影像（除了真實影像之外）來大規模建立資料集。HaloQuest 擁有超過 7.7K 個橫跨各種類別的範例，被設計為 VLM 的一個具有挑戰性的基準，以及一個用於推進多模態推理的微調資料集。我們的實驗表明，目前的模型在 HaloQuest 中掙扎，所有開源 VLM 的準確度都低於 36%。另一方面，在 HaloQuest 上進行微調會顯著降低幻覺率，同時保持標準推理任務的性能。我們的結果發現，使用生成的影像進行基準測試與真實影像高度相關 (r=0.97)。最後但並非最不重要的一點是，我們提出了一種新穎的 Auto-Eval 機制，它與人類評分者高度相關 (r=0.99)，用於評估 VLM。總之，這項工作朝著理解、評估和減輕 VLM 中的幻覺邁出了具體的步伐，成為未來更可靠的多模態 AI 系統的重要一步。

##### **Flow-guided Motion Prediction with Semantics and Dynamic Occupancy Grid Maps**
2407.15675v1 by Rabbia Asghar, Wenqian Liu, Lukas Rummelhard, Anne Spalanzani, Christian Laugier

Accurate prediction of driving scenes is essential for road safety and
autonomous driving. Occupancy Grid Maps (OGMs) are commonly employed for scene
prediction due to their structured spatial representation, flexibility across
sensor modalities and integration of uncertainty. Recent studies have
successfully combined OGMs with deep learning methods to predict the evolution
of scene and learn complex behaviours. These methods, however, do not consider
prediction of flow or velocity vectors in the scene. In this work, we propose a
novel multi-task framework that leverages dynamic OGMs and semantic information
to predict both future vehicle semantic grids and the future flow of the scene.
This incorporation of semantic flow not only offers intermediate scene features
but also enables the generation of warped semantic grids. Evaluation on the
real-world NuScenes dataset demonstrates improved prediction capabilities and
enhanced ability of the model to retain dynamic vehicles within the scene.

摘要：準確預測駕駛場景對於道路安全和自動駕駛至關重要。佔用網格地圖 (OGM) 由於其結構化的空間表示、跨傳感器模式的靈活性以及不確定性的整合，通常用於場景預測。最近的研究已成功地將 OGM 與深度學習方法相結合，以預測場景的演變並學習複雜的行為。然而，這些方法沒有考慮場景中流或速度向量的預測。在這項工作中，我們提出了一個新穎的多任務框架，該框架利用動態 OGM 和語義信息來預測未來的車輛語義網格和場景的未來流動。這種語義流的納入不僅提供了中間場景特徵，而且還能夠生成變形的語義網格。對真實世界 NuScenes 數據集的評估證明了改進的預測能力和模型在場景中保留動態車輛的能力增強。

##### **SLVideo: A Sign Language Video Moment Retrieval Framework**
2407.15668v1 by Gonçalo Vinagre Martins, Afonso Quinaz, Carla Viegas, Sofia Cavaco, João Magalhães

Sign Language Recognition has been studied and developed throughout the years
to help the deaf and hard-of-hearing people in their day-to-day lives. These
technologies leverage manual sign recognition algorithms, however, most of them
lack the recognition of facial expressions, which are also an essential part of
Sign Language as they allow the speaker to add expressiveness to their dialogue
or even change the meaning of certain manual signs. SLVideo is a video moment
retrieval software for Sign Language videos with a focus on both hands and
facial signs. The system extracts embedding representations for the hand and
face signs from video frames to capture the language signs in full. This will
then allow the user to search for a specific sign language video segment with
text queries, or to search by similar sign language videos. To test this
system, a collection of five hours of annotated Sign Language videos is used as
the dataset, and the initial results are promising in a zero-shot
setting.SLVideo is shown to not only address the problem of searching sign
language videos but also supports a Sign Language thesaurus with a search by
similarity technique.
  Project web page: https://novasearch.github.io/SLVideo/

摘要：手語辨識技術多年來不斷研究和開發，
協助聽障人士在日常生活中。這些
技術利用手勢辨識演算法，然而，大多數技術
欠缺對臉部表情的辨識，而臉部表情也是
手語的必要部分，因為它讓說話者能為對話增添
表達力，甚至改變特定手勢的意義。SLVideo 是一款
手語影片的影片片段擷取軟體，專注於手部和
臉部手勢。系統從影片格中擷取手部和
臉部手勢的嵌入式表示，以完整捕捉語言手勢。這將
使用戶能夠以文字查詢搜尋特定手語影片片段，或以
類似手語影片搜尋。為了測試這個
系統，我們使用一系列五小時的註解手語影片作為
資料集，而初始結果在零次學習
設定中很有希望。SLVideo 不僅解決了手語影片搜尋問題，還支援
手語同義詞庫，並以相似度技術搜尋。
專案網頁：https://novasearch.github.io/SLVideo/

##### **Psychometric Alignment: Capturing Human Knowledge Distributions via Language Models**
2407.15645v1 by Joy He-Yueya, Wanjing Anya Ma, Kanishk Gandhi, Benjamin W. Domingue, Emma Brunskill, Noah D. Goodman

Language models (LMs) are increasingly used to simulate human-like responses
in scenarios where accurately mimicking a population's behavior can guide
decision-making, such as in developing educational materials and designing
public policies. The objective of these simulations is for LMs to capture the
variations in human responses, rather than merely providing the expected
correct answers. Prior work has shown that LMs often generate unrealistically
accurate responses, but there are no established metrics to quantify how
closely the knowledge distribution of LMs aligns with that of humans. To
address this, we introduce "psychometric alignment," a metric that measures the
extent to which LMs reflect human knowledge distribution. Assessing this
alignment involves collecting responses from both LMs and humans to the same
set of test items and using Item Response Theory to analyze the differences in
item functioning between the groups. We demonstrate that our metric can capture
important variations in populations that traditional metrics, like differences
in accuracy, fail to capture. We apply this metric to assess existing LMs for
their alignment with human knowledge distributions across three real-world
domains. We find significant misalignment between LMs and human populations,
though using persona-based prompts can improve alignment. Interestingly,
smaller LMs tend to achieve greater psychometric alignment than larger LMs.
Further, training LMs on human response data from the target distribution
enhances their psychometric alignment on unseen test items, but the
effectiveness of such training varies across domains.

摘要：語言模型（LM）越來越常被用於模擬類似人類的回應，在準確模仿群體行為可以引導決策制定（例如開發教育材料和設計公共政策）的場景中。這些模擬的目標是讓 LM 捕捉人類回應的變化，而不仅仅是提供預期的正確答案。先前的研究表明，LM 經常產生不切實際的準確回應，但沒有既定的指標可以量化 LM 的知識分佈與人類的知識分佈有多接近。為了解決這個問題，我們引入了「心理測量對齊」，這是一個衡量 LM 反映人類知識分佈程度的指標。評估這種對齊涉及收集 LM 和人類對同一組測試項目的回應，並使用項目反應理論來分析群組之間項目功能的差異。我們證明我們的指標可以捕捉傳統指標（例如準確性差異）無法捕捉的人群中的重要變化。我們應用這個指標來評估現有的 LM，以評估它們與三個現實世界領域的人類知識分佈的一致性。我們發現 LM 和人類群體之間存在顯著的不一致，儘管使用基於角色的提示可以改善一致性。有趣的是，較小的 LM 往往比較大的 LM 達到更高的心理測量一致性。此外，在來自目標分佈的人類回應數據上訓練 LM 可以增強它們在未見測試項目上的心理測量一致性，但這種訓練的有效性因領域而異。

##### **RadioRAG: Factual Large Language Models for Enhanced Diagnostics in Radiology Using Dynamic Retrieval Augmented Generation**
2407.15621v1 by Soroosh Tayebi Arasteh, Mahshad Lotfinia, Keno Bressem, Robert Siepmann, Dyke Ferber, Christiane Kuhl, Jakob Nikolas Kather, Sven Nebelung, Daniel Truhn

Large language models (LLMs) have advanced the field of artificial
intelligence (AI) in medicine. However LLMs often generate outdated or
inaccurate information based on static training datasets. Retrieval augmented
generation (RAG) mitigates this by integrating outside data sources. While
previous RAG systems used pre-assembled, fixed databases with limited
flexibility, we have developed Radiology RAG (RadioRAG) as an end-to-end
framework that retrieves data from authoritative radiologic online sources in
real-time. RadioRAG is evaluated using a dedicated radiologic
question-and-answer dataset (RadioQA). We evaluate the diagnostic accuracy of
various LLMs when answering radiology-specific questions with and without
access to additional online information via RAG. Using 80 questions from RSNA
Case Collection across radiologic subspecialties and 24 additional
expert-curated questions, for which the correct gold-standard answers were
available, LLMs (GPT-3.5-turbo, GPT-4, Mistral-7B, Mixtral-8x7B, and Llama3 [8B
and 70B]) were prompted with and without RadioRAG. RadioRAG retrieved
context-specific information from www.radiopaedia.org in real-time and
incorporated them into its reply. RadioRAG consistently improved diagnostic
accuracy across all LLMs, with relative improvements ranging from 2% to 54%. It
matched or exceeded question answering without RAG across radiologic
subspecialties, particularly in breast imaging and emergency radiology.
However, degree of improvement varied among models; GPT-3.5-turbo and
Mixtral-8x7B-instruct-v0.1 saw notable gains, while Mistral-7B-instruct-v0.2
showed no improvement, highlighting variability in its effectiveness. LLMs
benefit when provided access to domain-specific data beyond their training
data. For radiology, RadioRAG establishes a robust framework that substantially
improves diagnostic accuracy and factuality in radiological question answering.

摘要：大型語言模型 (LLM) 提升了人工智慧 (AI) 在醫學領域的進展。然而，LLM 經常根據靜態訓練資料集產生過時或不準確的資訊。檢索擴增生成 (RAG) 透過整合外部資料來源來減輕這個問題。雖然先前的 RAG 系統使用預先組裝、具有有限彈性的固定資料庫，但我們已開發放射科 RAG (RadioRAG) 作為一個端對端架構，可從權威的線上放射科來源即時檢索資料。RadioRAG 使用專門的放射科問答資料集 (RadioQA) 進行評估。我們評估各種 LLM 在回答放射科特定問題時的診斷準確性，無論是否透過 RAG 存取額外的線上資訊。使用來自 RSNA 案例彙編的 80 個涵蓋放射科次專科的問題和 24 個額外的專家策劃問題（有正確的金標準答案），提示 LLM（GPT-3.5-turbo、GPT-4、Mistral-7B、Mixtral-8x7B 和 Llama3 [8B 和 70B]），無論是否使用 RadioRAG。RadioRAG 從 www.radiopaedia.org 即時檢索特定於脈絡的資訊，並將其納入回覆中。RadioRAG 持續改善所有 LLM 的診斷準確性，相對改善幅度從 2% 到 54%。它在放射科次專科中達到或超過沒有 RAG 的問答準確性，特別是在乳房影像和急診放射科中。然而，不同模型之間的改善程度有所不同；GPT-3.5-turbo 和 Mixtral-8x7B-instruct-v0.1 有顯著的進步，而 Mistral-7B-instruct-v0.2 沒有改善，突顯其有效性的變異性。LLM 在獲得超出其訓練資料的特定領域資料時會受益。對於放射科，RadioRAG 建立了一個強大的架構，可大幅改善放射科問答中的診斷準確性和真實性。

##### **Can GPT-4 learn to analyze moves in research article abstracts?**
2407.15612v1 by Danni Yu, Marina Bondi, Ken Hylannd

One of the most powerful and enduring ideas in written discourse analysis is
that genres can be described in terms of the moves which structure a writer's
purpose. Considerable research has sought to identify these distinct
communicative acts, but analyses have been beset by problems of subjectivity,
reliability and the time-consuming need for multiple coders to confirm
analyses. In this paper we employ the affordances of GPT-4 to automate the
annotation process by using natural language prompts. Focusing on abstracts
from articles in four applied linguistics journals, we devise prompts which
enable the model to identify moves effectively. The annotated outputs of these
prompts were evaluated by two assessors with a third addressing disagreements.
The results show that an 8-shot prompt was more effective than one using two,
confirming that the inclusion of examples illustrating areas of variability can
enhance GPT-4's ability to recognize multiple moves in a single sentence and
reduce bias related to textual position. We suggest that GPT-4 offers
considerable potential in automating this annotation process, when human actors
with domain specific linguistic expertise inform the prompting process.

摘要：書面論述分析中最強大且歷久不衰的概念之一，是文類可以根據構成作者目的的步驟來描述。大量的研究試圖找出這些不同的溝通行為，但分析一直受到主觀性、可靠性以及確認分析需要多個編碼器而耗時等問題的困擾。在本文中，我們採用 GPT-4 的功能，使用自然語言提示來自動化註解程序。我們專注於四本應用語言學期刊中的摘要，設計提示讓模型能有效識別步驟。這些提示的註解輸出由兩位評估者評估，第三位評估者則解決分歧。結果顯示，使用 8 個步驟的提示比使用 2 個步驟的提示更有效，這證實了包含說明變異性領域的範例，可以增強 GPT-4 在單一句子中識別多個步驟的能力，並減少與文字位置相關的偏差。我們建議，當具有特定語言領域專業知識的人類行為者提供提示程序資訊時，GPT-4 在自動化此註解程序方面具有相當大的潛力。

##### **StylusAI: Stylistic Adaptation for Robust German Handwritten Text Generation**
2407.15608v1 by Nauman Riaz, Saifullah Saifullah, Stefan Agne, Andreas Dengel, Sheraz Ahmed

In this study, we introduce StylusAI, a novel architecture leveraging
diffusion models in the domain of handwriting style generation. StylusAI is
specifically designed to adapt and integrate the stylistic nuances of one
language's handwriting into another, particularly focusing on blending English
handwriting styles into the context of the German writing system. This approach
enables the generation of German text in English handwriting styles and German
handwriting styles into English, enriching machine-generated handwriting
diversity while ensuring that the generated text remains legible across both
languages. To support the development and evaluation of StylusAI, we present
the \lq{Deutscher Handschriften-Datensatz}\rq~(DHSD), a comprehensive dataset
encompassing 37 distinct handwriting styles within the German language. This
dataset provides a fundamental resource for training and benchmarking in the
realm of handwritten text generation. Our results demonstrate that StylusAI not
only introduces a new method for style adaptation in handwritten text
generation but also surpasses existing models in generating handwriting samples
that improve both text quality and stylistic fidelity, evidenced by its
performance on the IAM database and our newly proposed DHSD. Thus, StylusAI
represents a significant advancement in the field of handwriting style
generation, offering promising avenues for future research and applications in
cross-linguistic style adaptation for languages with similar scripts.

摘要：在研究中，我們介紹了 StylusAI，一種在手寫風格生成領域利用擴散模型的新穎架構。StylusAI 經過特別設計，用於適應和整合一種語言的手寫風格的風格細微差別到另一種語言中，特別著重於將英文手寫風格融入德文寫作系統的語境中。這種方法能夠生成英文手寫風格的德文文本和德文手寫風格的英文，豐富機器生成的文字的多樣性，同時確保生成的文字在兩種語言中都能保持易讀性。為了支持 StylusAI 的開發和評估，我們展示了「Deutscher Handschriften-Datensatz」（DHSD），這是一個全面的數據集，涵蓋了德語中 37 種不同的手寫風格。此數據集為手寫文本生成的訓練和基準測試提供了基礎資源。我們的結果表明，StylusAI 不僅為手寫文本生成中的風格適應引入了一種新方法，而且在生成手寫樣本方面也超越了現有模型，這些樣本同時改善了文本品質和風格保真度，這在 IAM 數據庫和我們新提出的 DHSD 上的表現中得到了證明。因此，StylusAI 代表了手寫風格生成領域的重大進步，為具有相似字元的語言的跨語言風格適應提供了未來研究和應用方面的前景。

##### **A Pairwise Comparison Relation-assisted Multi-objective Evolutionary Neural Architecture Search Method with Multi-population Mechanism**
2407.15600v1 by Yu Xue, Chenchen Zhu, MengChu Zhou, Mohamed Wahib, Moncef Gabbouj

Neural architecture search (NAS) enables re-searchers to automatically
explore vast search spaces and find efficient neural networks. But NAS suffers
from a key bottleneck, i.e., numerous architectures need to be evaluated during
the search process, which requires a lot of computing resources and time. In
order to improve the efficiency of NAS, a series of methods have been proposed
to reduce the evaluation time of neural architectures. However, they are not
efficient enough and still only focus on the accuracy of architectures. In
addition to the classification accuracy, more efficient and smaller network
architectures are required in real-world applications. To address the above
problems, we propose the SMEM-NAS, a pairwise com-parison relation-assisted
multi-objective evolutionary algorithm based on a multi-population mechanism.
In the SMEM-NAS, a surrogate model is constructed based on pairwise compari-son
relations to predict the accuracy ranking of architectures, rather than the
absolute accuracy. Moreover, two populations cooperate with each other in the
search process, i.e., a main population guides the evolution, while a vice
population expands the diversity. Our method aims to provide high-performance
models that take into account multiple optimization objectives. We conduct a
series of experiments on the CIFAR-10, CIFAR-100 and ImageNet datasets to
verify its effectiveness. With only a single GPU searching for 0.17 days,
competitive architectures can be found by SMEM-NAS which achieves 78.91%
accuracy with the MAdds of 570M on the ImageNet. This work makes a significant
advance in the important field of NAS.

摘要：<paragraph>神經網路架構搜尋 (NAS) 能讓研究人員自動探索廣大的搜尋空間，並找到有效率的神經網路。但 NAS 會遇到一個主要的瓶頸，也就是在搜尋過程中需要評估大量的架構，這需要大量的運算資源和時間。為了提升 NAS 的效率，已經提出了一系列的方法來減少神經網路架構的評估時間。然而，這些方法還不夠有效率，而且仍然只著重於架構的準確度。除了分類準確度之外，在實際應用中還需要更有效率且更小的網路架構。為了解決上述問題，我們提出 SMEM-NAS，這是一種基於多族群機制的成對比較關係輔助多目標演化演算法。在 SMEM-NAS 中，會根據成對比較關係建構一個代理模型，用來預測架構的準確度排名，而不是絕對準確度。此外，在搜尋過程中，兩個族群會互相合作，也就是說，一個主族群引導演化，而一個副族群則擴展多樣性。我們的方法旨在提供考量多個最佳化目標的高效能模型。我們在 CIFAR-10、CIFAR-100 和 ImageNet 資料集上進行了一系列的實驗，以驗證其有效性。SMEM-NAS 只使用單一 GPU 搜尋 0.17 天，就能找到競爭力的架構，在 ImageNet 上以 570M 的 MAdds 達到 78.91% 的準確度。這項工作在 NAS 的重要領域中取得顯著進展。</paragraph>

##### **Discrete Flow Matching**
2407.15595v1 by Itai Gat, Tal Remez, Neta Shaul, Felix Kreuk, Ricky T. Q. Chen, Gabriel Synnaeve, Yossi Adi, Yaron Lipman

Despite Flow Matching and diffusion models having emerged as powerful
generative paradigms for continuous variables such as images and videos, their
application to high-dimensional discrete data, such as language, is still
limited. In this work, we present Discrete Flow Matching, a novel discrete flow
paradigm designed specifically for generating discrete data. Discrete Flow
Matching offers several key contributions: (i) it works with a general family
of probability paths interpolating between source and target distributions;
(ii) it allows for a generic formula for sampling from these probability paths
using learned posteriors such as the probability denoiser ($x$-prediction) and
noise-prediction ($\epsilon$-prediction); (iii) practically, focusing on
specific probability paths defined with different schedulers considerably
improves generative perplexity compared to previous discrete diffusion and flow
models; and (iv) by scaling Discrete Flow Matching models up to 1.7B
parameters, we reach 6.7% Pass@1 and 13.4% Pass@10 on HumanEval and 6.7% Pass@1
and 20.6% Pass@10 on 1-shot MBPP coding benchmarks. Our approach is capable of
generating high-quality discrete data in a non-autoregressive fashion,
significantly closing the gap between autoregressive models and discrete flow
models.

摘要：儘管流匹配和擴散模型已成為連續變數（例如影像和影片）強大的生成範例，但它們在高維離散資料（例如語言）中的應用仍然有限。在這項工作中，我們提出離散流匹配，一種專門為生成離散資料而設計的新穎離散流範例。離散流匹配提供幾個關鍵貢獻：(i) 它使用一個通用的機率路徑族，在來源和目標分佈之間內插；(ii) 它允許使用已學習的後驗（例如機率去雜訊器（$x$-預測）和雜訊預測（$\epsilon$-預測））從這些機率路徑中抽樣的通用公式；(iii) 實際上，專注於使用不同排程器定義的特定機率路徑，與先前的離散擴散和流模型相比，顯著改善了生成困惑度；以及 (iv) 透過將離散流匹配模型擴充至 1.7B 參數，我們在 HumanEval 上達到 6.7% Pass@1 和 13.4% Pass@10，在 1 次 MBPP 編碼基準上達到 6.7% Pass@1 和 20.6% Pass@10。我們的做法能夠以非自迴歸的方式生成高品質離散資料，顯著縮小自迴歸模型與離散流模型之間的差距。

##### **Unsupervised Robust Cross-Lingual Entity Alignment via Joint Modeling of Entity and Relation Texts**
2407.15588v1 by Soojin Yoon, Sungho Ko, Tongyoung Kim, SeongKu Kang, Jinyoung Yeo, Dongha Lee

Cross-lingual entity alignment (EA) enables the integration of multiple
knowledge graphs (KGs) across different languages, providing users with
seamless access to diverse and comprehensive knowledge.Existing methods, mostly
supervised, face challenges in obtaining labeled entity pairs. To address this,
recent studies have shifted towards a self-supervised and unsupervised
frameworks. Despite their effectiveness, these approaches have limitations: (1)
they mainly focus on entity features, neglecting the semantic information of
relations, (2) they assume isomorphism between source and target graphs,
leading to noise and reduced alignment accuracy, and (3) they are susceptible
to noise in the textual features, especially when encountering inconsistent
translations or Out-Of-Vocabulary (OOV) problems.
  In this paper, we propose ERAlign, an unsupervised and robust cross-lingual
EA framework that jointly performs Entity-level and Relation-level Alignment
using semantic textual features of relations and entities. Its refinement
process iteratively enhances results by fusing entity-level and relation-level
alignments based on neighbor triple matching. The additional verification
process examines the entities' neighbor triples as the linearized text. This
\textit{Align-and-Verify} pipeline that rigorously assesses alignment results,
achieving near-perfect alignment even in the presence of noisy textual features
of entities. Our extensive experiments demonstrate that robustness and general
applicability of \proposed improved the accuracy and effectiveness of EA tasks,
contributing significantly to knowledge-oriented applications.

摘要：跨語言實體對齊 (EA) 能夠整合不同語言中的多個知識圖譜 (KG)，讓使用者能無縫地存取多元且全面的知識。現有方法大多是有監督的，在取得標記實體對時面臨挑戰。為了解決這個問題，最近的研究已轉向自監督和無監督的架構。儘管這些方法很有效，但它們有以下限制：(1) 它們主要關注實體特徵，忽略關係的語義資訊，(2) 它們假設來源圖譜和目標圖譜之間同構，導致雜訊和對齊準確度降低，(3) 它們容易受到文字特徵中的雜訊影響，特別是在遇到不一致的翻譯或詞彙外問題 (OOV) 時。
在本文中，我們提出 ERAlign，一個無監督且穩健的跨語言 EA 架構，它使用關係和實體的語義文字特徵，同時執行實體層級和關係層級對齊。它的精煉程序透過根據鄰接三元組匹配融合實體層級和關係層級對齊，反覆增強結果。額外的驗證程序將實體的鄰接三元組視為線性化文字進行檢查。這個嚴格評估對齊結果的「對齊和驗證」管線，即使在存在實體的雜訊文字特徵時也能達成近乎完美的對齊。我們廣泛的實驗證明，\proposed 的穩健性和普遍適用性提升了 EA 任務的準確度和有效性，對知識導向應用程式有顯著的貢獻。

##### **An Empirical Study of Retrieval Augmented Generation with Chain-of-Thought**
2407.15569v1 by Yuetong Zhao, Hongyu Cao, Xianyu Zhao, Zhijian Ou

Since the launch of ChatGPT at the end of 2022, generative dialogue models
represented by ChatGPT have quickly become essential tools in daily life. As
user expectations increase, enhancing the capability of generative dialogue
models to solve complex problems has become a focal point of current research.
This paper delves into the effectiveness of the RAFT (Retrieval Augmented
Fine-Tuning) method in improving the performance of Generative dialogue models.
RAFT combines chain-of-thought with model supervised fine-tuning (SFT) and
retrieval augmented generation (RAG), which significantly enhanced the model's
information extraction and logical reasoning abilities. We evaluated the RAFT
method across multiple datasets and analysed its performance in various
reasoning tasks, including long-form QA and short-form QA tasks, tasks in both
Chinese and English, and supportive and comparison reasoning tasks. Notably, it
addresses the gaps in previous research regarding long-form QA tasks and
Chinese datasets. Moreover, we also evaluate the benefit of the
chain-of-thought (CoT) in the RAFT method. This work offers valuable insights
for studies focused on enhancing the performance of generative dialogue models.

摘要：自 2022 年底 ChatGPT 推出以来，以 ChatGPT 为代表的生成式对话模型迅速成为日常生活中的必备工具。随着用户期望的提高，增强生成式对话模型解决复杂问题的能力已成为当前研究的重点。本文深入探讨了 RAFT（检索增强微调）方法在提高生成式对话模型性能方面的有效性。RAFT 将思想链与模型监督微调 (SFT) 和检索增强生成 (RAG) 相结合，显着增强了模型的信息提取和逻辑推理能力。我们跨多个数据集评估了 RAFT 方法，并分析了它在各种推理任务中的性能，包括长篇问答和短篇问答任务、中英文任务以及支持性和比较推理任务。值得注意的是，它解决了先前研究中关于长篇问答任务和中文数据集的差距。此外，我们还评估了 RAFT 方法中思想链 (CoT) 的好处。这项工作为专注于增强生成式对话模型性能的研究提供了宝贵的见解。

##### **SETTP: Style Extraction and Tunable Inference via Dual-level Transferable Prompt Learning**
2407.15556v1 by Chunzhen Jin, Yongfeng Huang, Yaqi Wang, Peng Cao, Osmar Zaiane

Text style transfer, an important research direction in natural language
processing, aims to adapt the text to various preferences but often faces
challenges with limited resources. In this work, we introduce a novel method
termed Style Extraction and Tunable Inference via Dual-level Transferable
Prompt Learning (SETTP) for effective style transfer in low-resource scenarios.
First, SETTP learns source style-level prompts containing fundamental style
characteristics from high-resource style transfer. During training, the source
style-level prompts are transferred through an attention module to derive a
target style-level prompt for beneficial knowledge provision in low-resource
style transfer. Additionally, we propose instance-level prompts obtained by
clustering the target resources based on the semantic content to reduce
semantic bias. We also propose an automated evaluation approach of style
similarity based on alignment with human evaluations using ChatGPT-4. Our
experiments across three resourceful styles show that SETTP requires only
1/20th of the data volume to achieve performance comparable to state-of-the-art
methods. In tasks involving scarce data like writing style and role style,
SETTP outperforms previous methods by 16.24\%.

摘要：文字樣式轉移，自然語言處理中一個重要的研究方向，旨在將文字調整至各種偏好，但常常面臨資源有限的挑戰。在這項工作中，我們介紹一種新穎的方法，稱為雙層可轉移提示學習的樣式萃取和可調式推論 (SETTP)，用於在低資源場景中進行有效的樣式轉移。首先，SETTP 學習從高資源樣式轉移中包含基本樣式特徵的來源樣式層級提示。在訓練期間，來源樣式層級提示會透過注意力模組轉移，以衍生一個目標樣式層級提示，在低資源樣式轉移中提供有益的知識。此外，我們提出透過根據語意內容對目標資源進行分群而獲得的實例層級提示，以減少語意偏差。我們還提出一個自動化的樣式相似性評估方法，基於與使用 ChatGPT-4 的人類評估的一致性。我們針對三種豐富的樣式進行的實驗顯示，SETTP 只需要 1/20 的資料量，就能達到與現有技術相當的效能。在涉及稀有資料（例如寫作樣式和角色樣式）的任務中，SETTP 的表現優於先前的技術 16.24%。

##### **Targeted Latent Adversarial Training Improves Robustness to Persistent Harmful Behaviors in LLMs**
2407.15549v1 by Abhay Sheshadri, Aidan Ewart, Phillip Guo, Aengus Lynch, Cindy Wu, Vivek Hebbar, Henry Sleight, Asa Cooper Stickland, Ethan Perez, Dylan Hadfield-Menell, Stephen Casper

Large language models (LLMs) can often be made to behave in undesirable ways
that they are explicitly fine-tuned not to. For example, the LLM red-teaming
literature has produced a wide variety of `jailbreaking' techniques to elicit
harmful text from models that were fine-tuned to be harmless. Recent work on
red-teaming, model editing, and interpretability suggests that this challenge
stems from how (adversarial) fine-tuning largely serves to suppress rather than
remove undesirable capabilities from LLMs. Prior work has introduced latent
adversarial training (LAT) as a way to improve robustness to broad classes of
failures. These prior works have considered untargeted latent space attacks
where the adversary perturbs latent activations to maximize loss on examples of
desirable behavior. Untargeted LAT can provide a generic type of robustness but
does not leverage information about specific failure modes. Here, we experiment
with targeted LAT where the adversary seeks to minimize loss on a specific
competing task. We find that it can augment a wide variety of state-of-the-art
methods. First, we use targeted LAT to improve robustness to jailbreaks,
outperforming a strong R2D2 baseline with orders of magnitude less compute.
Second, we use it to more effectively remove backdoors with no knowledge of the
trigger. Finally, we use it to more effectively unlearn knowledge for specific
undesirable tasks in a way that is also more robust to re-learning. Overall,
our results suggest that targeted LAT can be an effective tool for defending
against harmful behaviors from LLMs.

摘要：大型語言模型 (LLM) 經常會被誘導做出不良行為，即使它們經過明確微調以避免這種行為。例如，LLM 紅隊文獻產生了各種「越獄」技術，從經過微調以確保無害的模型中引出有害文字。最近關於紅隊、模型編輯和可解釋性的研究表明，這個挑戰源於（對抗性的）微調在很大程度上是用於壓制，而不是移除 LLM 中不良的能力。先前的研究引入了潛在對抗訓練 (LAT) 作為一種改善對廣泛類別的故障的健壯性的方法。這些先前的研究考慮了未針對潛在空間攻擊，其中對手擾動潛在激活以最大化對理想行為範例的損失。未針對的 LAT 可以提供一種通用的健壯性，但不會利用有關特定故障模式的資訊。在這裡，我們實驗了目標 LAT，其中對手試圖最小化對特定競爭任務的損失。我們發現它可以擴充各種最先進的方法。首先，我們使用目標 LAT 來改善對越獄的健壯性，以比強大的 R2D2 基線少幾個數量級的計算力表現得更好。其次，我們使用它在不瞭解觸發器的狀況下更有效地移除後門。最後，我們使用它以更有效的方式取消學習特定不良任務的知識，而且這種方式對於重新學習也更健壯。總的來說，我們的結果表明，目標 LAT 可以成為防禦 LLM 有害行為的有效工具。

##### **Large-scale Time-Varying Portfolio Optimisation using Graph Attention Networks**
2407.15532v1 by Kamesh Korangi, Christophe Mues, Cristián Bravo

Apart from assessing individual asset performance, investors in financial
markets also need to consider how a set of firms performs collectively as a
portfolio. Whereas traditional Markowitz-based mean-variance portfolios are
widespread, network-based optimisation techniques have built upon these
developments. However, most studies do not contain firms at risk of default and
remove any firms that drop off indices over a certain time. This is the first
study to incorporate risky firms and use all the firms in portfolio
optimisation. We propose and empirically test a novel method that leverages
Graph Attention networks (GATs), a subclass of Graph Neural Networks (GNNs).
GNNs, as deep learning-based models, can exploit network data to uncover
nonlinear relationships. Their ability to handle high-dimensional features and
accommodate customised layers for specific purposes makes them particularly
appealing for large-scale problems such as mid- and small-cap portfolio
optimization. This study utilises 30 years of data on mid-cap firms, creating
graphs of firms using distance correlation and the Triangulated Maximally
Filtered Graph approach. These graphs are the inputs to a GAT model that we
train using custom layers which impose weight and allocation constraints and a
loss function derived from the Sharpe ratio, thus directly maximising portfolio
risk-adjusted returns. This new model is benchmarked against a network
characteristic-based portfolio, a mean variance-based portfolio, and an
equal-weighted portfolio. The results show that the portfolio produced by the
GAT-based model outperforms all benchmarks and is consistently superior to
other strategies over a long period while also being informative of market
dynamics.

摘要：除了評估個別資產績效，金融市場的投資人還需要考量一組公司作為投資組合的整體表現。傳統的馬科維茲均值-變異數投資組合雖然廣泛使用，但基於網路的最佳化技術已在這些發展的基礎上更進一步。然而，大多數研究並未納入有違約風險的公司，並移除在特定時間內跌出指數的所有公司。本研究首次納入風險公司，並在投資組合最佳化中使用所有公司。我們提出並實證檢驗一種新方法，該方法利用圖注意力網路（GAT），這是圖神經網路（GNN）的一種子類。GNN 作為基於深度學習的模型，可以利用網路資料找出非線性關係。它們處理高維度特徵並針對特定目的容納自訂層的能力，使其特別適合於大規模問題，例如中小型股投資組合最佳化。本研究利用 30 年的中型股公司資料，使用距離相關性和三角形最大濾波圖形方法建立公司圖形。這些圖形是 GAT 模型的輸入，我們使用自訂層訓練該模型，這些層會施加權重和配置限制，以及源自夏普比率的損失函數，從而直接最大化投資組合的風險調整報酬。這個新模型與基於網路特徵的投資組合、基於均值變異數的投資組合和等權重投資組合進行基準比較。結果顯示，基於 GAT 的模型所產生的投資組合優於所有基準，並且在長期內始終優於其他策略，同時也能提供市場動態的資訊。

##### **Interpretable Concept-Based Memory Reasoning**
2407.15527v1 by David Debot, Pietro Barbiero, Francesco Giannini, Gabriele Ciravegna, Michelangelo Diligenti, Giuseppe Marra

The lack of transparency in the decision-making processes of deep learning
systems presents a significant challenge in modern artificial intelligence
(AI), as it impairs users' ability to rely on and verify these systems. To
address this challenge, Concept Bottleneck Models (CBMs) have made significant
progress by incorporating human-interpretable concepts into deep learning
architectures. This approach allows predictions to be traced back to specific
concept patterns that users can understand and potentially intervene on.
However, existing CBMs' task predictors are not fully interpretable, preventing
a thorough analysis and any form of formal verification of their
decision-making process prior to deployment, thereby raising significant
reliability concerns. To bridge this gap, we introduce Concept-based Memory
Reasoner (CMR), a novel CBM designed to provide a human-understandable and
provably-verifiable task prediction process. Our approach is to model each task
prediction as a neural selection mechanism over a memory of learnable logic
rules, followed by a symbolic evaluation of the selected rule. The presence of
an explicit memory and the symbolic evaluation allow domain experts to inspect
and formally verify the validity of certain global properties of interest for
the task prediction process. Experimental results demonstrate that CMR achieves
comparable accuracy-interpretability trade-offs to state-of-the-art CBMs,
discovers logic rules consistent with ground truths, allows for rule
interventions, and allows pre-deployment verification.

摘要：深度學習系統決策過程缺乏透明度，對現代人工智慧 (AI) 來說是一項重大挑戰，因為這會損害使用者依賴和驗證這些系統的能力。為了應對這項挑戰，概念瓶頸模型 (CBM) 透過將人類可解釋的概念納入深度學習架構中，取得了顯著進展。這種方法允許將預測追溯到使用者可以理解並可能介入的特定概念模式。然而，現有的 CBM 任務預測器並非完全可解釋，這會妨礙在部署前徹底分析和正式驗證其決策過程的任何形式，從而引發重大的可靠性疑慮。為了彌補這個差距，我們引入了基於概念的記憶推理器 (CMR)，這是一種新穎的 CBM，旨在提供人類可理解且可證明驗證的任務預測過程。我們的做法是將每個任務預測建模為在可學習邏輯規則的記憶體上進行神經選擇機制，接著對所選規則進行符號評估。明確記憶和符號評估的存在，讓領域專家可以檢查並正式驗證任務預測過程對某些感興趣的全局屬性的有效性。實驗結果證明，CMR 達到了與最先進的 CBM 相當的準確性可解釋性權衡，發現與基本事實一致的邏輯規則，允許規則介入，並允許預部署驗證。

##### **Synthetic Image Learning: Preserving Performance and Preventing Membership Inference Attacks**
2407.15526v1 by Eugenio Lomurno, Matteo Matteucci

Generative artificial intelligence has transformed the generation of
synthetic data, providing innovative solutions to challenges like data scarcity
and privacy, which are particularly critical in fields such as medicine.
However, the effective use of this synthetic data to train high-performance
models remains a significant challenge. This paper addresses this issue by
introducing Knowledge Recycling (KR), a pipeline designed to optimise the
generation and use of synthetic data for training downstream classifiers. At
the heart of this pipeline is Generative Knowledge Distillation (GKD), the
proposed technique that significantly improves the quality and usefulness of
the information provided to classifiers through a synthetic dataset
regeneration and soft labelling mechanism. The KR pipeline has been tested on a
variety of datasets, with a focus on six highly heterogeneous medical image
datasets, ranging from retinal images to organ scans. The results show a
significant reduction in the performance gap between models trained on real and
synthetic data, with models based on synthetic data outperforming those trained
on real data in some cases. Furthermore, the resulting models show almost
complete immunity to Membership Inference Attacks, manifesting privacy
properties missing in models trained with conventional techniques.

摘要：生成式人工智慧已經轉變了合成資料的生成，提供了創新的解決方案來應對資料稀少和隱私等挑戰，這在醫學等領域特別重要。
然而，有效使用這些合成資料來訓練高性能模型仍然是一個重大的挑戰。本文通過引入知識循環 (KR) 來解決這個問題，這是一個旨在優化合成資料的生成和使用以訓練下游分類器的管道。這個管道的核心是生成式知識蒸餾 (GKD)，這是一種提出的技術，它通過合成資料集再生和軟標籤機制顯著提高了提供給分類器的資訊的品質和有用性。KR 管道已經在各種資料集上進行了測試，重點是六個高度異質的醫學影像資料集，範圍從視網膜影像到器官掃描。結果顯示，在真實資料和合成資料上訓練的模型之間的效能差距顯著縮小，在某些情況下，基於合成資料的模型優於在真實資料上訓練的模型。此外，產生的模型顯示出對成員推論攻擊幾乎完全免疫，表現出傳統技術訓練的模型中缺少的隱私屬性。

##### **Future-Proofing Mobile Networks: A Digital Twin Approach to Multi-Signal Management**
2407.15520v1 by Roberto Morabito, Bivek Pandey, Paulius Daubaris, Yasith R Wanigarathna, Sasu Tarkoma

Digital Twins (DTs) are set to become a key enabling technology in future
wireless networks, with their use in network management increasing
significantly. We developed a DT framework that leverages the heterogeneity of
network access technologies as a resource for enhanced network performance and
management, enabling smart data handling in the physical network. Tested in a
\textit{Campus Area Network} environment, our framework integrates diverse data
sources to provide real-time, holistic insights into network performance and
environmental sensing. We also envision that traditional analytics will evolve
to rely on emerging AI models, such as Generative AI (GenAI), while leveraging
current analytics capabilities. This capacity can simplify analytics processes
through advanced ML models, enabling descriptive, diagnostic, predictive, and
prescriptive analytics in a unified fashion. Finally, we present specific
research opportunities concerning interoperability aspects and envision
aligning advancements in DT technology with evolved AI integration.

摘要：數位雙胞胎 (DT) 將成為未來無線網路中的關鍵技術，其在網路管理中的應用將大幅增加。我們開發了一個 DT 架構，利用網路存取技術的異質性作為資源，以增強網路效能和管理，並在實體網路中啟用智慧資料處理。在「校園區域網路」環境中測試後，我們的架構整合了不同的資料來源，以提供網路效能和環境感測的即時、全面的見解。我們也預期傳統分析將演變為依賴新興的 AI 模型，例如生成式 AI (GenAI)，同時利用目前的分析功能。此功能可透過進階 ML 模型簡化分析流程，以統一的方式啟用描述性、診斷性、預測性和規範性分析。最後，我們提出關於互操作性方面的具體研究機會，並預期將 DT 技術的進展與進化的 AI 整合相結合。

##### **Attention Is All You Need But You Don't Need All Of It For Inference of Large Language Models**
2407.15516v1 by Georgy Tyukin, Gbetondji J-S Dovonon, Jean Kaddour, Pasquale Minervini

The inference demand for LLMs has skyrocketed in recent months, and serving
models with low latencies remains challenging due to the quadratic input length
complexity of the attention layers. In this work, we investigate the effect of
dropping MLP and attention layers at inference time on the performance of
Llama-v2 models. We find that dropping dreeper attention layers only marginally
decreases performance but leads to the best speedups alongside dropping entire
layers. For example, removing 33\% of attention layers in a 13B Llama2 model
results in a 1.8\% drop in average performance over the OpenLLM benchmark. We
also observe that skipping layers except the latter layers reduces performances
for more layers skipped, except for skipping the attention layers.

摘要：近几个月来，对 LLM 的推理需求激增，由于注意力层的二次输入长度复杂度，以低延迟提供服务模型仍然具有挑战性。在这项工作中，我们研究了在推理时丢弃 MLP 和注意力层对 Llama-v2 模型性能的影响。我们发现，丢弃更深的注意力层只会轻微降低性能，但会导致最佳加速，同时丢弃整个层。例如，在 13B Llama2 模型中移除 33% 的注意力层会导致 OpenLLM 基准上的平均性能下降 1.8%。我们还观察到，除了后一层之外，跳过层会降低性能以跳过更多层，除了跳过注意力层。

##### **Increasing the Robustness of Model Predictions to Missing Sensors in Earth Observation**
2407.15512v1 by Francisco Mena, Diego Arenas, Andreas Dengel

Multi-sensor ML models for EO aim to enhance prediction accuracy by
integrating data from various sources. However, the presence of missing data
poses a significant challenge, particularly in non-persistent sensors that can
be affected by external factors. Existing literature has explored strategies
like temporal dropout and sensor-invariant models to address the generalization
to missing data issues. Inspired by these works, we study two novel methods
tailored for multi-sensor scenarios, namely Input Sensor Dropout (ISensD) and
Ensemble Sensor Invariant (ESensI). Through experimentation on three
multi-sensor temporal EO datasets, we demonstrate that these methods
effectively increase the robustness of model predictions to missing sensors.
Particularly, we focus on how the predictive performance of models drops when
sensors are missing at different levels. We observe that ensemble multi-sensor
models are the most robust to the lack of sensors. In addition, the sensor
dropout component in ISensD shows promising robustness results.

摘要：多傳感器 ML 模型用於 EO，旨在通過整合來自不同來源的數據來提高預測準確度。然而，缺失數據的存在構成了重大的挑戰，特別是在可能會受到外部因素影響的非持久性傳感器中。現有文獻探索了諸如時間中斷和傳感器不變模型之類的策略，以解決推廣到缺失數據問題。受這些工作的啟發，我們研究了兩種針對多傳感器場景量身定制的新方法，即輸入傳感器中斷 (ISensD) 和集成傳感器不變 (ESensI)。通過對三個多傳感器時間 EO 數據集進行實驗，我們證明了這些方法有效地提高了模型預測對缺失傳感器的魯棒性。特別是，我們重點關注在不同級別缺失傳感器時模型的預測性能如何下降。我們觀察到，集成多傳感器模型對傳感器缺失最為魯棒。此外，ISensD 中的傳感器中斷組件顯示出有希望的魯棒性結果。

##### **Compensate Quantization Errors+: Quantized Models Are Inquisitive Learners**
2407.15508v1 by Yifei Gao, Jie Ou, Lei Wang, Fanhua Shang, Jaji Wu, Jun Cheng

Large Language Models (LLMs) showcase remarkable performance and robust
deductive capabilities, yet their expansive size complicates deployment and
raises environmental concerns due to substantial resource consumption. The
recent development of a quantization technique known as Learnable
Singular-value Increment (LSI) has addressed some of these quantization
challenges. Leveraging insights from LSI and our extensive research, we have
developed innovative methods that enhance the performance of quantized LLMs,
particularly in low-bit settings. Our methods consistently deliver
state-of-the-art results across various quantization scenarios and offer deep
theoretical insights into the quantization process, elucidating the potential
of quantized models for widespread application.

摘要：大型語言模型 (LLM) 展示出卓越的效能和強大的演繹能力，但其龐大的規模使部署變得複雜，並因大量的資源消耗而引發環境問題。最近開發的一種稱為可學習奇異值增量 (LSI) 的量化技術已解決了其中一些量化挑戰。利用 LSI 的見解和我們廣泛的研究，我們開發了創新的方法來增強量化 LLM 的效能，特別是在低位元設定中。我們的技術在各種量化場景中持續提供最先進的結果，並對量化過程提供深入的理論見解，闡明了量化模型廣泛應用的潛力。

##### **Fundamental Limits of Prompt Compression: A Rate-Distortion Framework for Black-Box Language Models**
2407.15504v1 by Adway Girish, Alliot Nagle, Marco Bondaschi, Michael Gastpar, Ashok Vardhan Makkuva, Hyeji Kim

We formalize the problem of prompt compression for large language models
(LLMs) and present a framework to unify token-level prompt compression methods
which create hard prompts for black-box models. We derive the distortion-rate
function for this setup as a linear program, and provide an efficient algorithm
to compute this fundamental limit via the dual of the linear program. Using the
distortion-rate function as the baseline, we study the performance of existing
compression schemes on a synthetic dataset consisting of prompts generated from
a Markov chain, natural language queries, and their respective answers. Our
empirical analysis demonstrates the criticality of query-aware prompt
compression, where the compressor has knowledge of the downstream task/query
for the black-box LLM. We show that there is a large gap between the
performance of current prompt compression methods and the optimal strategy, and
propose a query-aware, variable-rate adaptation of a prior work to close the
gap. We extend our experiments to a small natural language dataset to further
confirm our findings on our synthetic dataset.

摘要：我們將大型語言模型 (LLM) 的提示壓縮問題形式化，並提出一個框架來統一用於為黑盒模型建立硬提示的代幣級提示壓縮方法。我們將此設定的失真率函數導出為一個線性規劃，並提供一個有效率的演算法來透過線性規劃的對偶來計算這個基本限制。使用失真率函數作為基準，我們研究現有壓縮方案在一個由馬可夫鏈、自然語言查詢及其各自答案所產生的提示組成的合成資料集上的效能。我們的實證分析證明了查詢感知提示壓縮的重要性，其中壓縮器具有對黑盒 LLM 的下游任務/查詢的知識。我們表明，目前的提示壓縮方法的效能與最佳策略之間存在很大的差距，並提出一個查詢感知、可變速率的先前工作改編，以縮小差距。我們將我們的實驗擴展到一個小型自然語言資料集，以進一步確認我們在合成資料集上的發現。

##### **Refining Corpora from a Model Calibration Perspective for Chinese Spelling Correction**
2407.15498v1 by Dingyao Yu, Yang An, Wei Ye, Xiongfeng Xiao, Shaoguang Mao, Tao Ge, Shikun Zhang

Chinese Spelling Correction (CSC) commonly lacks large-scale high-quality
corpora, due to the labor-intensive labeling of spelling errors in real-life
human writing or typing scenarios. Two data augmentation methods are widely
adopted: (1) \textit{Random Replacement} with the guidance of confusion sets
and (2) \textit{OCR/ASR-based Generation} that simulates character misusing.
However, both methods inevitably introduce noisy data (e.g., false spelling
errors), potentially leading to over-correction. By carefully analyzing the two
types of corpora, we find that though the latter achieves more robust
generalization performance, the former yields better-calibrated CSC models. We
then provide a theoretical analysis of this empirical observation, based on
which a corpus refining strategy is proposed. Specifically, OCR/ASR-based data
samples are fed into a well-calibrated CSC model trained on random
replacement-based corpora and then filtered based on prediction confidence. By
learning a simple BERT-based model on the refined OCR/ASR-based corpus, we set
up impressive state-of-the-art performance on three widely-used benchmarks,
while significantly alleviating over-correction (e.g., lowering false positive
predictions).

摘要：中文拼寫校正 (CSC) 通常缺乏大量高品質的語料庫，這是因為在現實生活中的人類書寫或打字場景中，拼寫錯誤的標註需要大量的人力。廣泛採用的兩種資料擴充方法：(1) 在混淆集合的指導下進行隨機替換，以及 (2) 模擬字元誤用的 OCR/ASR 基於生成。然而，這兩種方法不可避免地會引入雜訊資料（例如，拼寫錯誤），可能導致過度校正。透過仔細分析這兩種語料庫，我們發現雖然後者達到了更強大的泛化效能，但前者產生的 CSC 模型校準效果較佳。接著，我們針對此經驗觀察提供理論分析，並據此提出語料庫精煉策略。具體來說，將基於 OCR/ASR 的資料範例輸入到基於隨機替換語料庫訓練的良好校準 CSC 模型中，然後根據預測信心進行篩選。透過在精煉的基於 OCR/ASR 的語料庫上學習一個簡單的 BERT 模型，我們在三個廣泛使用的基準上建立了令人印象深刻的最新技術效能，同時大幅減輕了過度校正（例如，降低誤判）。

##### **Two Stacks Are Better Than One: A Comparison of Language Modeling and Translation as Multilingual Pretraining Objectives**
2407.15489v1 by Zihao Li, Shaoxiong Ji, Timothee Mickus, Vincent Segonne, Jörg Tiedemann

Pretrained language models (PLMs) display impressive performances and have
captured the attention of the NLP community. Establishing the best practices in
pretraining has therefore become a major point of focus for much of NLP
research -- especially since the insights developed for monolingual English
models need not carry to more complex multilingual. One significant caveat of
the current state of the art is that different works are rarely comparable:
they often discuss different parameter counts, training data, and evaluation
methodology.
  This paper proposes a comparison of multilingual pretraining objectives in a
controlled methodological environment. We ensure that training data and model
architectures are comparable, and discuss the downstream performances across 6
languages that we observe in probing and fine-tuning scenarios. We make two key
observations: (1) the architecture dictates which pretraining objective is
optimal; (2) multilingual translation is a very effective pre-training
objective under the right conditions. We make our code, data, and model weights
available at \texttt{\url{https://github.com/Helsinki-NLP/lm-vs-mt}}.

摘要：預訓練語言模型（PLM）展現令人印象深刻的表現，並吸引了自然語言處理社群的注意。因此，建立預訓練的最佳實務已成為許多自然語言處理研究的主要重點，特別是針對單語英語模型所發展的見解不必套用在更複雜的多語種上。目前技術的一個重大警示是，不同的作品很少具有可比性：它們經常討論不同的參數數量、訓練資料和評估方法。
本文提出在受控的方法環境中比較多語種預訓練目標。我們確保訓練資料和模型架構具有可比性，並討論我們在探測和微調場景中觀察到的 6 種語言的下游表現。我們提出了兩個關鍵觀察：(1) 架構決定哪個預訓練目標最佳；(2) 在正確的條件下，多語種翻譯是一種非常有效的預訓練目標。我們在 \texttt{\url{https://github.com/Helsinki-NLP/lm-vs-mt}} 提供我們的程式碼、資料和模型權重。

##### **In-Context Learning Improves Compositional Understanding of Vision-Language Models**
2407.15487v1 by Matteo Nulli, Anesa Ibrahimi, Avik Pal, Hoshe Lee, Ivona Najdenkoska

Vision-Language Models (VLMs) have shown remarkable capabilities in a large
number of downstream tasks. Nonetheless, compositional image understanding
remains a rather difficult task due to the object bias present in training
data. In this work, we investigate the reasons for such a lack of capability by
performing an extensive bench-marking of compositional understanding in VLMs.
We compare contrastive models with generative ones and analyze their
differences in architecture, pre-training data, and training tasks and losses.
Furthermore, we leverage In-Context Learning (ICL) as a way to improve the
ability of VLMs to perform more complex reasoning and understanding given an
image. Our extensive experiments demonstrate that our proposed approach
outperforms baseline models across multiple compositional understanding
datasets.

摘要：視覺語言模型 (VLM) 已在大量下游任務中展現出卓越的能力。儘管如此，由於訓練資料中存在的物件偏差，組合式影像理解仍是一項相當困難的任務。在這項工作中，我們透過對 VLM 中組合式理解進行廣泛的基準評量，探討這種能力不足的原因。我們比較對比模型與生成模型，並分析它們在架構、預訓練資料、訓練任務和損失方面的差異。此外，我們利用情境中學習 (ICL) 作為一種方法，以提升 VLM 在給定影像的情況下執行更複雜推理和理解的能力。我們的廣泛實驗證明，我們提出的方法在多個組合式理解資料集上優於基準模型。

##### **A Multi-Level Corroborative Approach for Verification and Validation of Autonomous Robotic Swarms**
2407.15475v1 by Dhaminda B. Abeywickrama, Suet Lee, Chris Bennett, Razanne Abu-Aisheh, Tom Didiot-Cook, Simon Jones, Sabine Hauert, Kerstin Eder

Modelling and characterizing emergent behaviour within a swarm can pose
significant challenges in terms of 'assurance'. Assurance tasks encompass
adherence to standards, certification processes, and the execution of
verification and validation (V&V) methods, such as model checking. In this
study, we propose a holistic, multi-level modelling approach for formally
verifying and validating autonomous robotic swarms, which are defined at the
macroscopic formal modelling, low-fidelity simulation, high-fidelity
simulation, and real-robot levels. Our formal macroscopic models, used for
verification, are characterized by data derived from actual simulations,
ensuring both accuracy and traceability across different system models.
Furthermore, our work combines formal verification with experimental validation
involving real robots. In this way, our corroborative approach for V&V seeks to
enhance confidence in the evidence, in contrast to employing these methods
separately. We explore our approach through a case study focused on a swarm of
robots operating within a public cloakroom.

摘要：模擬和描述群體中出現的行為在「保證」方面可能帶來重大挑戰。保證任務包括遵守標準、認證程序，以及執行驗證和驗證 (V&V) 方法，例如模型檢查。在本研究中，我們提出了一種整體、多層次建模方法，用於正式驗證和驗證自主機器人群體，這些群體定義在巨觀形式化建模、低保真模擬、高保真模擬和真實機器人層級。我們用於驗證的正式巨觀模型的特點是來自實際模擬的數據，確保了不同系統模型之間的準確性和可追溯性。此外，我們的研究將形式化驗證與涉及真實機器人的實驗驗證相結合。通過這種方式，我們用於 V&V 的佐證方法旨在增強對證據的信心，而不是分別採用這些方法。我們通過一個案例研究探討了我們的做法，該案例研究集中在一個在公共衣帽間內運作的機器人群體。

##### **Text-to-Battery Recipe: A language modeling-based protocol for automatic battery recipe extraction and retrieval**
2407.15459v1 by Daeun Lee, Jaewoong Choi, Hiroshi Mizuseki, Byungju Lee

Recent studies have increasingly applied natural language processing (NLP) to
automatically extract experimental research data from the extensive battery
materials literature. Despite the complex process involved in battery
manufacturing -- from material synthesis to cell assembly -- there has been no
comprehensive study systematically organizing this information. In response, we
propose a language modeling-based protocol, Text-to-Battery Recipe (T2BR), for
the automatic extraction of end-to-end battery recipes, validated using a case
study on batteries containing LiFePO4 cathode material. We report machine
learning-based paper filtering models, screening 2,174 relevant papers from the
keyword-based search results, and unsupervised topic models to identify 2,876
paragraphs related to cathode synthesis and 2,958 paragraphs related to cell
assembly. Then, focusing on the two topics, two deep learning-based named
entity recognition models are developed to extract a total of 30 entities --
including precursors, active materials, and synthesis methods -- achieving F1
scores of 88.18% and 94.61%. The accurate extraction of entities enables the
systematic generation of 165 end-toend recipes of LiFePO4 batteries. Our
protocol and results offer valuable insights into specific trends, such as
associations between precursor materials and synthesis methods, or combinations
between different precursor materials. We anticipate that our findings will
serve as a foundational knowledge base for facilitating battery-recipe
information retrieval. The proposed protocol will significantly accelerate the
review of battery material literature and catalyze innovations in battery
design and development.

摘要：近期的研究已日益應用自然語言處理 (NLP) 來自動從廣泛的電池材料文獻中提取實驗研究資料。儘管電池製造涉及複雜的流程，從材料合成到電池組裝，但目前尚未有系統組織這些資訊的全面性研究。為了解決此問題，我們提出一個基於語言模型的協定，Text-to-Battery Recipe (T2BR)，用於自動提取端對端電池配方，並使用包含 LiFePO4 正極材料的電池案例研究進行驗證。我們回報了基於機器學習的論文過濾模型，從基於關鍵字的搜尋結果中篩選出 2,174 篇相關論文，並使用無監督主題模型來找出 2,876 段與正極合成相關的段落和 2,958 段與電池組裝相關的段落。接著，針對這兩個主題，開發兩個基於深度學習的名詞實體辨識模型來提取總計 30 個實體，包括前驅物、活性材料和合成方法，並達成 88.18% 和 94.61% 的 F1 分數。實體的精確提取能系統性地產生 165 個 LiFePO4 電池的端對端配方。我們的協定和結果提供有價值的見解，深入探討特定趨勢，例如前驅材料與合成方法之間的關聯性，或不同前驅材料之間的組合。我們預期我們的發現將作為促進電池配方資訊檢索的基本知識庫。所提出的協定將大幅加速電池材料文獻的審查，並催化電池設計與開發的創新。

##### **Developing a Reliable, General-Purpose Hallucination Detection and Mitigation Service: Insights and Lessons Learned**
2407.15441v1 by Song Wang, Xun Wang, Jie Mei, Yujia Xie, Sean Muarray, Zhang Li, Lingfeng Wu, Si-Qing Chen, Wayne Xiong

Hallucination, a phenomenon where large language models (LLMs) produce output
that is factually incorrect or unrelated to the input, is a major challenge for
LLM applications that require accuracy and dependability. In this paper, we
introduce a reliable and high-speed production system aimed at detecting and
rectifying the hallucination issue within LLMs. Our system encompasses named
entity recognition (NER), natural language inference (NLI), span-based
detection (SBD), and an intricate decision tree-based process to reliably
detect a wide range of hallucinations in LLM responses. Furthermore, our team
has crafted a rewriting mechanism that maintains an optimal mix of precision,
response time, and cost-effectiveness. We detail the core elements of our
framework and underscore the paramount challenges tied to response time,
availability, and performance metrics, which are crucial for real-world
deployment of these technologies. Our extensive evaluation, utilizing offline
data and live production traffic, confirms the efficacy of our proposed
framework and service.

摘要：幻覺，一種大型語言模型 (LLM) 產生輸出結果不符合事實或與輸入無關的現象，對於需要準確性和可靠性的 LLM 應用程式來說是一項重大挑戰。在本文中，我們將介紹一個可靠且高速的生產系統，旨在偵測和修正 LLM 中的幻覺問題。我們的系統包含命名實體辨識 (NER)、自然語言推論 (NLI)、基於區間的偵測 (SBD) 和一個複雜的決策樹為基礎的流程，以可靠地偵測 LLM 回應中的各種幻覺。此外，我們的團隊設計了一個改寫機制，以維持最佳的精準度、回應時間和成本效益組合。我們詳細說明了我們架構的核心元素，並強調與回應時間、可用性和效能指標相關的主要挑戰，這些指標對於這些技術的實際部署至關重要。我們廣泛的評估，利用離線資料和實時生產流量，證實了我們提出的架構和服務的效能。

##### **Pre-Training and Prompting for Few-Shot Node Classification on Text-Attributed Graphs**
2407.15431v1 by Huanjing Zhao, Beining Yang, Yukuo Cen, Junyu Ren, Chenhui Zhang, Yuxiao Dong, Evgeny Kharlamov, Shu Zhao, Jie Tang

The text-attributed graph (TAG) is one kind of important real-world
graph-structured data with each node associated with raw texts. For TAGs,
traditional few-shot node classification methods directly conduct training on
the pre-processed node features and do not consider the raw texts. The
performance is highly dependent on the choice of the feature pre-processing
method. In this paper, we propose P2TAG, a framework designed for few-shot node
classification on TAGs with graph pre-training and prompting. P2TAG first
pre-trains the language model (LM) and graph neural network (GNN) on TAGs with
self-supervised loss. To fully utilize the ability of language models, we adapt
the masked language modeling objective for our framework. The pre-trained model
is then used for the few-shot node classification with a mixed prompt method,
which simultaneously considers both text and graph information. We conduct
experiments on six real-world TAGs, including paper citation networks and
product co-purchasing networks. Experimental results demonstrate that our
proposed framework outperforms existing graph few-shot learning methods on
these datasets with +18.98% ~ +35.98% improvements.

摘要：文本属性图 (TAG) 是一种重要的真实世界图结构化数据，其中每个节点都与原始文本相关联。对于 TAG，传统的少数镜头节点分类方法直接对预处理的节点特征进行训练，而不考虑原始文本。性能在很大程度上取决于特征预处理方法的选择。在本文中，我们提出了 P2TAG，这是一个专为 TAG 上的少数镜头节点分类设计的框架，具有图预训练和提示。P2TAG 首先使用自我监督损失对 TAG 上的语言模型 (LM) 和图神经网络 (GNN) 进行预训练。为了充分利用语言模型的能力，我们为我们的框架调整了掩码语言建模目标。然后使用预训练模型进行少数镜头节点分类，采用混合提示方法，同时考虑文本和图信息。我们对六个真实世界的 TAG 进行了实验，包括论文引用网络和产品共同购买网络。实验结果表明，我们提出的框架在这些数据集上优于现有的图少数镜头学习方法，改进了 +18.98% ~ +35.98%。

##### **Decoding BACnet Packets: A Large Language Model Approach for Packet Interpretation**
2407.15428v1 by Rashi Sharma, Hiroyuki Okada, Tatsumi Oba, Karthikk Subramanian, Naoto Yanai, Sugiri Pranata

The Industrial Control System (ICS) environment encompasses a wide range of
intricate communication protocols, posing substantial challenges for Security
Operations Center (SOC) analysts tasked with monitoring, interpreting, and
addressing network activities and security incidents. Conventional monitoring
tools and techniques often struggle to provide a clear understanding of the
nature and intent of ICS-specific communications. To enhance comprehension, we
propose a software solution powered by a Large Language Model (LLM). This
solution currently focused on BACnet protocol, processes a packet file data and
extracts context by using a mapping database, and contemporary context
retrieval methods for Retrieval Augmented Generation (RAG). The processed
packet information, combined with the extracted context, serves as input to the
LLM, which generates a concise packet file summary for the user. The software
delivers a clear, coherent, and easily understandable summary of network
activities, enabling SOC analysts to better assess the current state of the
control system.

摘要：工業控制系統 (ICS) 環境包含範圍廣泛的複雜通訊協定，對負責監控、解讀和處理網路活動與安全事件的資安營運中心 (SOC) 分析師來說，構成極大的挑戰。傳統的監控工具和技術通常難以提供 ICS 特定通訊性質和意圖的清晰理解。為了增強理解，我們提出一個由大型語言模型 (LLM) 支援的軟體解決方案。這個解決方案目前專注於 BACnet 協定，處理封包檔案資料並使用對應資料庫和用於檢索擴充生成 (RAG) 的當代脈絡檢索方法來萃取脈絡。處理過的封包資訊與萃取的脈絡結合，作為 LLM 的輸入，為使用者產生簡潔的封包檔案摘要。此軟體提供清晰、一致且易於理解的網路活動摘要，讓 SOC 分析師能夠更妥善評估控制系統的當前狀態。

##### **YOLO-pdd: A Novel Multi-scale PCB Defect Detection Method Using Deep Representations with Sequential Images**
2407.15427v1 by Bowen Liu, Dongjie Chen, Xiao Qi

With the rapid growth of the PCB manufacturing industry, there is an
increasing demand for computer vision inspection to detect defects during
production. Improving the accuracy and generalization of PCB defect detection
models remains a significant challenge. This paper proposes a high-precision,
robust, and real-time end-to-end method for PCB defect detection based on deep
Convolutional Neural Networks (CNN). Traditional methods often suffer from low
accuracy and limited applicability. We propose a novel approach combining
YOLOv5 and multiscale modules for hierarchical residual-like connections. In
PCB defect detection, noise can confuse the background and small targets. The
YOLOv5 model provides a strong foundation with its real-time processing and
accurate object detection capabilities. The multi-scale module extends
traditional approaches by incorporating hierarchical residual-like connections
within a single block, enabling multiscale feature extraction. This
plug-and-play module significantly enhances performance by extracting features
at multiple scales and levels, which are useful for identifying defects of
varying sizes and complexities. Our multi-scale architecture integrates feature
extraction, defect localization, and classification into a unified network.
Experiments on a large-scale PCB dataset demonstrate significant improvements
in precision, recall, and F1-score compared to existing methods. This work
advances computer vision inspection for PCB defect detection, providing a
reliable solution for high-precision, robust, real-time, and domain-adaptive
defect detection in the PCB manufacturing industry.

摘要：隨著 PCB 製造產業的快速成長，對於電腦視覺檢測的需求也與日俱增，以在生產過程中偵測出缺陷。提升 PCB 缺陷偵測模型的準確度和泛化能力，仍然是一項重大的挑戰。本文提出一個基於深度卷積神經網路 (CNN) 的高精度、強健且即時端對端方法，用於 PCB 缺陷偵測。傳統方法通常會遇到準確度低和適用性有限的問題。我們提出一個結合 YOLOv5 和多尺度模組的新穎方法，用於分層殘差類連接。在 PCB 缺陷偵測中，雜訊可能會混淆背景和小型目標。YOLOv5 模型以其即時處理和準確的物件偵測能力，提供了強大的基礎。多尺度模組透過在單一區塊中加入分層殘差類連接，來延伸傳統方法，進而實現多尺度特徵萃取。這個即插即用模組透過萃取多個尺度和層級的特徵，大幅提升效能，這些特徵有助於識別各種尺寸和複雜度的缺陷。我們的多尺度架構將特徵萃取、缺陷定位和分類整合到一個統一的網路中。在大規模 PCB 資料集上的實驗，證明與現有方法相比，在精準度、召回率和 F1 分數上都有顯著的提升。這項工作推動了電腦視覺檢查在 PCB 缺陷偵測上的應用，為 PCB 製造產業提供了一個高精度、強健、即時且領域適應性的缺陷偵測可靠解決方案。

##### **Empirical Capacity Model for Self-Attention Neural Networks**
2407.15425v1 by Aki Härmä, Marcin Pietrasik, Anna Wilbik

Large pretrained self-attention neural networks, or transformers, have been
very successful in various tasks recently. The performance of a model on a
given task depends on its ability to memorize and generalize the training data.
Large transformer models, which may have billions of parameters, in theory have
a huge capacity to memorize content. However, the current algorithms for the
optimization fall short of the theoretical capacity, and the capacity is also
highly dependent on the content. In this paper, we focus on the memory capacity
of these models obtained using common training algorithms and synthetic
training data. Based on the results, we derive an empirical capacity model
(ECM) for a generic transformer. The ECM can be used to design task-specific
transformer models with an optimal number of parameters in cases where the
target memorization capability of the task can be defined.

摘要：大型預先訓練的自我注意力神經網路，或Transformer，最近在各種任務上都非常成功。模型在特定任務上的效能取決於其記憶和概括訓練資料的能力。理論上，可能有數十億個參數的大型Transformer模型具有巨大的記憶內容容量。然而，目前用於最佳化的演算法未達到理論容量，而且容量也高度依賴於內容。在本文中，我們專注於使用常見訓練演算法和合成訓練資料取得的這些模型的記憶容量。根據結果，我們為通用Transformer衍生出一個經驗容量模型 (ECM)。在可以定義任務的目標記憶能力的情況下，ECM 可用於設計具有最佳參數數量的特定任務Transformer模型。

##### **Integrating IP Broadcasting with Audio Tags: Workflow and Challenges**
2407.15423v2 by Rhys Burchett-Vass, Arshdeep Singh, Gabriel Bibbó, Mark D. Plumbley

The broadcasting industry is increasingly adopting IP techniques,
revolutionising both live and pre-recorded content production, from news
gathering to live music events. IP broadcasting allows for the transport of
audio and video signals in an easily configurable way, aligning with modern
networking techniques. This shift towards an IP workflow allows for much
greater flexibility, not only in routing signals but with the integration of
tools using standard web development techniques. One possible tool could
include the use of live audio tagging, which has a number of uses in the
production of content. These include from automated closed captioning to
identifying unwanted sound events within a scene. In this paper, we describe
the process of containerising an audio tagging model into a microservice, a
small segregated code module that can be integrated into a multitude of
different network setups. The goal is to develop a modular, accessible, and
flexible tool capable of seamless deployment into broadcasting workflows of all
sizes, from small productions to large corporations. Challenges surrounding
latency of the selected audio tagging model and its effect on the usefulness of
the end product are discussed.

摘要：廣播產業正逐漸採用 IP 技術，
從新聞採集到現場音樂活動，徹底革新現場和預先錄製的內容製作。IP 廣播允許以輕鬆設定的方式傳輸音訊和視訊訊號，符合現代網路技術。這種轉向 IP 工作流程的改變允許更大的靈活性，不僅在路由訊號上，而且還能整合使用標準網路開發技術的工具。一種可能的工具可以包括使用現場音訊標記，這在內容製作中有多種用途。這些用途包括從自動化隱藏式字幕到識別場景中的不必要聲音事件。在本文中，我們描述了將音訊標記模型容器化的過程，變成一個微服務，一個可以整合到多種不同網路設定中的小型分離程式碼模組。目標是開發一個模組化、易於存取且靈活的工具，能夠無縫部署到各種規模的廣播工作流程中，從小型製作到大型企業。討論了與所選音訊標記模型的延遲及其對最終產品實用性的影響相關的挑戰。

##### **Planning behavior in a recurrent neural network that plays Sokoban**
2407.15421v1 by Adrià Garriga-Alonso, Mohammad Taufeeque, Adam Gleave

To predict how advanced neural networks generalize to novel situations, it is
essential to understand how they reason. Guez et al. (2019, "An investigation
of model-free planning") trained a recurrent neural network (RNN) to play
Sokoban with model-free reinforcement learning. They found that adding extra
computation steps to the start of episodes at test time improves the RNN's
success rate. We further investigate this phenomenon, finding that it rapidly
emerges early on in training and then slowly fades, but only for comparatively
easier levels. The RNN also often takes redundant actions at episode starts,
and these are reduced by adding extra computation steps. Our results suggest
that the RNN learns to take time to think by `pacing', despite the per-step
penalties, indicating that training incentivizes planning capabilities. The
small size (1.29M parameters) and interesting behavior of this model make it an
excellent model organism for mechanistic interpretability.

摘要：為了預測先進的神經網路如何概化到新情況，了解它們的推理方式至關重要。Guez 等人（2019 年，「無模型規劃的調查」）訓練了一個遞迴神經網路（RNN）使用無模型強化學習來玩倉庫番。他們發現，在測試時在回合開始時增加額外的運算步驟會提高 RNN 的成功率。我們進一步研究了這種現象，發現它在訓練初期迅速出現，然後慢慢消失，但僅限於相對容易的關卡。RNN 在回合開始時也經常採取冗餘動作，而這些動作會因增加額外的運算步驟而減少。我們的結果表明，RNN 學會了「調整」節奏來思考，儘管有每步懲罰，這表明訓練激勵了規劃能力。這個模型的小尺寸（1.29M 參數）和有趣的行為使其成為機制可解釋性的絕佳模型生物。

##### **LLaST: Improved End-to-end Speech Translation System Leveraged by Large Language Models**
2407.15415v1 by Xi Chen, Songyang Zhang, Qibing Bai, Kai Chen, Satoshi Nakamura

We introduces LLaST, a framework for building high-performance Large Language
model based Speech-to-text Translation systems. We address the limitations of
end-to-end speech translation(E2E ST) models by exploring model architecture
design and optimization techniques tailored for LLMs. Our approach includes
LLM-based speech translation architecture design, ASR-augmented training,
multilingual data augmentation, and dual-LoRA optimization. Our approach
demonstrates superior performance on the CoVoST-2 benchmark and showcases
exceptional scaling capabilities powered by LLMs. We believe this effective
method will serve as a strong baseline for speech translation and provide
insights for future improvements of the LLM-based speech translation framework.
We release the data, code and models in https://github.com/openaudiolab/LLaST.

摘要：我們介紹 LLaST，一個用於建構高性能大型語言模型，基於語音轉文字翻譯系統的框架。我們透過探索模型架構設計和針對 LLM 量身打造的最佳化技術，來解決端對端語音翻譯 (E2E ST) 模型的限制。我們的做法包括基於 LLM 的語音翻譯架構設計、ASR 增強訓練、多語言資料擴充，以及雙 LoRA 最佳化。我們的做法在 CoVoST-2 基準測試中展現出卓越的效能，並展示了由 LLM 提供動力的非凡擴充能力。我們相信這個有效的方法將成為語音翻譯的強大基準，並為 LLM 基礎語音翻譯框架的未來改進提供見解。我們在 https://github.com/openaudiolab/LLaST 中釋出資料、程式碼和模型。

##### **Knowledge Mechanisms in Large Language Models: A Survey and Perspective**
2407.15017v1 by Mengru Wang, Yunzhi Yao, Ziwen Xu, Shuofei Qiao, Shumin Deng, Peng Wang, Xiang Chen, Jia-Chen Gu, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen, Ningyu Zhang

Understanding knowledge mechanisms in Large Language Models (LLMs) is crucial
for advancing towards trustworthy AGI. This paper reviews knowledge mechanism
analysis from a novel taxonomy including knowledge utilization and evolution.
Knowledge utilization delves into the mechanism of memorization, comprehension
and application, and creation. Knowledge evolution focuses on the dynamic
progression of knowledge within individual and group LLMs. Moreover, we discuss
what knowledge LLMs have learned, the reasons for the fragility of parametric
knowledge, and the potential dark knowledge (hypothesis) that will be
challenging to address. We hope this work can help understand knowledge in LLMs
and provide insights for future research.

摘要：理解大型語言模型 (LLM) 中的知識機制對於推進值得信賴的 AGI 至關重要。本文從一個新的分類法回顧了知識機制的分析，包括知識利用和演化。知識利用深入探討了記憶、理解和應用以及創造的機制。知識演化專注於個體和群體 LLM 中知識的動態進程。此外，我們討論了 LLM 學習到的知識、參數化知識脆弱性的原因，以及將會帶來挑戰的潛在黑暗知識（假設）。我們希望這項工作有助於理解 LLM 中的知識，並為未來的研究提供見解。

##### **Tackling Selfish Clients in Federated Learning**
2407.15402v1 by Andrea Augello, Ashish Gupta, Giuseppe Lo Re, Sajal K. Das

Federated Learning (FL) is a distributed machine learning paradigm
facilitating participants to collaboratively train a model without revealing
their local data. However, when FL is deployed into the wild, some intelligent
clients can deliberately deviate from the standard training process to make the
global model inclined toward their local model, thereby prioritizing their
local data distribution. We refer to this novel category of misbehaving clients
as selfish. In this paper, we propose a Robust aggregation strategy for FL
server to mitigate the effect of Selfishness (in short RFL-Self). RFL-Self
incorporates an innovative method to recover (or estimate) the true updates of
selfish clients from the received ones, leveraging robust statistics (median of
norms) of the updates at every round. By including the recovered updates in
aggregation, our strategy offers strong robustness against selfishness. Our
experimental results, obtained on MNIST and CIFAR-10 datasets, demonstrate that
just 2% of clients behaving selfishly can decrease the accuracy by up to 36%,
and RFL-Self can mitigate that effect without degrading the global model
performance.

摘要：聯盟式學習 (FL) 是一種分散式機器學習範例，
促進參與者在不揭露其在地資料的情況下，合作訓練模型。
然而，當 FL 部署到實際環境時，一些智慧型用戶端可以故意偏離標準訓練程序，
使全球模型傾向於其在地模型，從而優先考慮其在地資料分佈。
我們將這類新型態的不當行為用戶端稱為自私。
在本文中，我們提出了一個 FL 伺服器的穩健聚合策略，
以減輕自私的影響（簡稱 RFL-Self）。
RFL-Self 結合了一種創新的方法，
從接收到的更新中恢復（或估計）自私用戶端的真實更新，
利用每輪更新的穩健統計資料（範數的中位數）。
透過將恢復的更新納入聚合中，我們的策略提供了對自私的強大穩健性。
我們在 MNIST 和 CIFAR-10 資料集上獲得的實驗結果表明，
只有 2% 的用戶端表現出自私行為，就會使準確度降低多達 36%，
而 RFL-Self 可以減輕這種影響，而不會降低全球模型的效能。

##### **Imposter.AI: Adversarial Attacks with Hidden Intentions towards Aligned Large Language Models**
2407.15399v1 by Xiao Liu, Liangzhi Li, Tong Xiang, Fuying Ye, Lu Wei, Wangyue Li, Noa Garcia

With the development of large language models (LLMs) like ChatGPT, both their
vast applications and potential vulnerabilities have come to the forefront.
While developers have integrated multiple safety mechanisms to mitigate their
misuse, a risk remains, particularly when models encounter adversarial inputs.
This study unveils an attack mechanism that capitalizes on human conversation
strategies to extract harmful information from LLMs. We delineate three pivotal
strategies: (i) decomposing malicious questions into seemingly innocent
sub-questions; (ii) rewriting overtly malicious questions into more covert,
benign-sounding ones; (iii) enhancing the harmfulness of responses by prompting
models for illustrative examples. Unlike conventional methods that target
explicit malicious responses, our approach delves deeper into the nature of the
information provided in responses. Through our experiments conducted on
GPT-3.5-turbo, GPT-4, and Llama2, our method has demonstrated a marked efficacy
compared to conventional attack methods. In summary, this work introduces a
novel attack method that outperforms previous approaches, raising an important
question: How to discern whether the ultimate intent in a dialogue is
malicious?

摘要：隨著大型語言模型 (LLM) 如 ChatGPT 的發展，其廣泛應用和潛在漏洞都已浮出檯面。雖然開發人員已整合多種安全機制來減輕其被濫用的風險，但風險仍然存在，特別是當模型遇到對抗性輸入時。本研究揭示了一種攻擊機制，利用人類對話策略從 LLM 中提取有害資訊。我們描繪出三個關鍵策略：(i) 將惡意問題分解成看似無害的子問題；(ii) 將明顯惡意的問題改寫成更隱蔽、聽起來良性的問題；(iii) 透過提示模型提供說明性範例，來提升回應的危害性。與針對明確惡意回應的傳統方法不同，我們的做法更深入探討回應中提供的資訊的本質。透過我們在 GPT-3.5-turbo、GPT-4 和 Llama2 上進行的實驗，我們的做法已展現出顯著的功效，優於傳統的攻擊方法。總之，這項工作引進了一種新穎的攻擊方法，其效能優於先前的做法，並提出了一個重要的問題：如何辨別對話中的最終意圖是否惡意？

##### **Semantic Diversity-aware Prototype-based Learning for Unbiased Scene Graph Generation**
2407.15396v1 by Jaehyeong Jeon, Kibum Kim, Kanghoon Yoon, Chanyoung Park

The scene graph generation (SGG) task involves detecting objects within an
image and predicting predicates that represent the relationships between the
objects. However, in SGG benchmark datasets, each subject-object pair is
annotated with a single predicate even though a single predicate may exhibit
diverse semantics (i.e., semantic diversity), existing SGG models are trained
to predict the one and only predicate for each pair. This in turn results in
the SGG models to overlook the semantic diversity that may exist in a
predicate, thus leading to biased predictions. In this paper, we propose a
novel model-agnostic Semantic Diversity-aware Prototype-based Learning (DPL)
framework that enables unbiased predictions based on the understanding of the
semantic diversity of predicates. Specifically, DPL learns the regions in the
semantic space covered by each predicate to distinguish among the various
different semantics that a single predicate can represent. Extensive
experiments demonstrate that our proposed model-agnostic DPL framework brings
significant performance improvement on existing SGG models, and also
effectively understands the semantic diversity of predicates.

摘要：場景圖生成 (SGG) 任務包含在影像中偵測物件，並預測表示物件間關係的謂詞。然而，在 SGG 基準資料集中，每個主詞-受詞對都會註解一個謂詞，即使單一謂詞可能展現出多樣語意（即語意多樣性），現有的 SGG 模型都訓練為預測每個對應的唯一謂詞。這反過來導致 SGG 模型忽略謂詞中可能存在的語意多樣性，進而導致有偏差的預測。在本文中，我們提出一個新的與模型無關的語意多樣性感知原型基礎學習 (DPL) 架構，該架構根據對謂詞語意多樣性的理解，啟用無偏差預測。具體來說，DPL 會學習每個謂詞涵蓋的語意空間區域，以區分單一謂詞可以表示的不同語意。廣泛的實驗證明，我們提出的與模型無關的 DPL 架構為現有的 SGG 模型帶來顯著的效能提升，且有效地理解謂詞的語意多樣性。

##### **ALLaM: Large Language Models for Arabic and English**
2407.15390v1 by M Saiful Bari, Yazeed Alnumay, Norah A. Alzahrani, Nouf M. Alotaibi, Hisham A. Alyahya, Sultan AlRashed, Faisal A. Mirza, Shaykhah Z. Alsubaie, Hassan A. Alahmed, Ghadah Alabduljabbar, Raghad Alkhathran, Yousef Almushayqih, Raneem Alnajim, Salman Alsubaihi, Maryam Al Mansour, Majed Alrubaian, Ali Alammari, Zaki Alawami, Abdulmohsen Al-Thubaity, Ahmed Abdelali, Jeril Kuriakose, Abdalghani Abujabal, Nora Al-Twairesh, Areeb Alowisheq, Haidar Khan

We present ALLaM: Arabic Large Language Model, a series of large language
models to support the ecosystem of Arabic Language Technologies (ALT). ALLaM is
carefully trained considering the values of language alignment and knowledge
transfer at scale. Our autoregressive decoder-only architecture models
demonstrate how second-language acquisition via vocabulary expansion and
pretraining on a mixture of Arabic and English text can steer a model towards a
new language (Arabic) without any catastrophic forgetting in the original
language (English). Furthermore, we highlight the effectiveness of using
parallel/translated data to aid the process of knowledge alignment between
languages. Finally, we show that extensive alignment with human preferences can
significantly enhance the performance of a language model compared to models of
a larger scale with lower quality alignment. ALLaM achieves state-of-the-art
performance in various Arabic benchmarks, including MMLU Arabic, ACVA, and
Arabic Exams. Our aligned models improve both in Arabic and English from their
base aligned models.

摘要：我們展示 ALLaM：阿拉伯大型語言模型，一系列大型語言模型，以支援阿拉伯語言技術 (ALT) 生態系統。ALLaM 經過仔細訓練，考慮了語言對齊和知識轉移的價值。我們的自迴歸僅解碼器架構模型展示了如何透過詞彙擴充和在阿拉伯語和英語文本混合體上進行預訓練，來引導模型朝向一種新語言（阿拉伯語），而不會對原始語言（英語）造成任何災難性遺忘。此外，我們強調使用平行/翻譯資料來協助語言之間知識對齊過程的有效性。最後，我們表明與人類偏好的廣泛對齊可以顯著提升語言模型的效能，與規模較大但對齊品質較低的模型相比。ALLaM 在各種阿拉伯語基準測試中達成最先進的效能，包括 MMLU Arabic、ACVA 和 Arabic Exams。我們對齊的模型從其基礎對齊模型中在阿拉伯語和英語方面都有所改進。

##### **The Development of a Comprehensive Spanish Dictionary for Phonetic and Lexical Tagging in Socio-phonetic Research (ESPADA)**
2407.15375v1 by Simon Gonzalez

Pronunciation dictionaries are an important component in the process of
speech forced alignment. The accuracy of these dictionaries has a strong effect
on the aligned speech data since they help the mapping between orthographic
transcriptions and acoustic signals. In this paper, I present the creation of a
comprehensive pronunciation dictionary in Spanish (ESPADA) that can be used in
most of the dialect variants of Spanish data. Current dictionaries focus on
specific regional variants, but with the flexible nature of our tool, it can be
readily applied to capture the most common phonetic differences across major
dialectal variants. We propose improvements to current pronunciation
dictionaries as well as mapping other relevant annotations such as
morphological and lexical information. In terms of size, it is currently the
most complete dictionary with more than 628,000 entries, representing words
from 16 countries. All entries come with their corresponding pronunciations,
morphological and lexical tagging, and other relevant information for phonetic
analysis: stress patterns, phonotactics, IPA transcriptions, and more. This
aims to equip socio-phonetic researchers with a complete open-source tool that
enhances dialectal research within socio-phonetic frameworks in the Spanish
language.

摘要：發音字典是強制語音比對過程中的一個重要組成部分。這些字典的準確度對比對的語音資料有很大的影響，因為它們有助於正字法轉錄和聲學信號之間的對應。在本文中，我將介紹一個西班牙語發音字典（ESPADA）的建立，該字典可用於大多數西班牙語資料的方言變體。目前的字典側重於特定的區域變體，但通過我們工具的靈活性，可以很容易地應用它來捕捉主要方言變體中最常見的語音差異。我們建議對目前的發音字典進行改進，並對其他相關註釋（如形態和詞彙信息）進行對應。就規模而言，它目前是最完整的字典，擁有超過 628,000 個條目，代表了來自 16 個國家的單詞。所有條目都帶有相應的發音、形態和詞彙標記，以及其他與語音分析相關的信息：重音模式、音位學、IPA 轉錄等。這旨在為社會語音學研究人員提供一個完整的開源工具，增強西班牙語社會語音學框架內的方言研究。

##### **ILiAD: An Interactive Corpus for Linguistic Annotated Data from Twitter Posts**
2407.15374v1 by Simon Gonzalez

Social Media platforms have offered invaluable opportunities for linguistic
research. The availability of up-to-date data, coming from any part in the
world, and coming from natural contexts, has allowed researchers to study
language in real time. One of the fields that has made great use of social
media platforms is Corpus Linguistics. There is currently a wide range of
projects which have been able to successfully create corpora from social media.
In this paper, we present the development and deployment of a linguistic corpus
from Twitter posts in English, coming from 26 news agencies and 27 individuals.
The main goal was to create a fully annotated English corpus for linguistic
analysis. We include information on morphology and syntax, as well as NLP
features such as tokenization, lemmas, and n- grams. The information is
presented through a range of powerful visualisations for users to explore
linguistic patterns in the corpus. With this tool, we aim to contribute to the
area of language technologies applied to linguistic research.

摘要：社群媒体平台为语言研究提供了无价的机会。来自世界任何地方、且源自自然语境的最新资料，让研究人员得以实时研究语言。善用社群媒体平台的领域之一是语料库语言学。目前有许多专案成功地从社群媒体建立语料库。在本文中，我们提出从 26 家新闻机构和 27 位个人发出的 Twitter 贴文中，发展并部署一个语言语料库。主要目标是建立一个完整的英文标注语料库，以利语言分析。我们纳入形态和句法资讯，以及词元化、词干和 n-gram 等 NLP 功能。这些资讯透过一系列强大的视觉化方式呈现，供使用者探索语料库中的语言模式。有了这个工具，我们希望对应用于语言研究的语言技术领域有所贡献。

##### **A Network Analysis Approach to Conlang Research Literature**
2407.15370v1 by Simon Gonzalez

The field of conlang has evidenced an important growth in the last decades.
This has been the product of a wide interest in the use and study of conlangs
for artistic purposes. However, one important question is what it is happening
with conlang in the academic world. This paper aims to have an overall
understanding of the literature on conlang research. With this we aim to give a
realistic picture of the field in present days. We have implemented a
computational linguistic approach, combining bibliometrics and network analysis
to examine all publications available in the Scopus database. Analysing over
2300 academic publications since 1927 until 2022, we have found that Esperanto
is by far the most documented conlang. Three main authors have contributed to
this: Garv\'ia R., Fiedler S., and Blanke D. The 1970s and 1980s have been the
decades where the foundations of current research have been built. In terms of
methodologies, language learning and experimental linguistics are the ones
contributing to most to the preferred approaches of study in the field. We
present the results and discuss our limitations and future work.

摘要：<paragraph>人工語言領域在過去數十年來已經證實了其重要成長。
這是因為人們對於人工語言在藝術目的上的使用和研究產生了廣泛的興趣。
然而，一個重要的問題是人工語言在學術界中發生了什麼事。
這篇論文旨在對人工語言研究的文獻有一個整體的了解。
有了這個，我們希望對當今領域有一個實際的描繪。
我們實施了一種計算語言學方法，結合書目計量學和網路分析
來檢驗 Scopus 資料庫中所有可用的出版物。
分析自 1927 年至 2022 年以來超過 2300 篇學術出版物，我們發現
世界語迄今為止是最有記錄的人工語言。
三位主要作者做出了貢獻：Garv\'ia R.、Fiedler S. 和 Blanke D.
1970 年代和 1980 年代是當前研究基礎建立的年代。
在方法論方面，語言學習和實驗語言學是對該領域
首選的研究方法做出最大貢獻的方法。
我們呈現結果並討論我們的限制和未來工作。</paragraph>

##### **Walking in Others' Shoes: How Perspective-Taking Guides Large Language Models in Reducing Toxicity and Bias**
2407.15366v1 by Rongwu Xu, Zi'an Zhou, Tianwei Zhang, Zehan Qi, Su Yao, Ke Xu, Wei Xu, Han Qiu

The common toxicity and societal bias in contents generated by large language
models (LLMs) necessitate strategies to reduce harm. Present solutions often
demand white-box access to the model or substantial training, which is
impractical for cutting-edge commercial LLMs. Moreover, prevailing prompting
methods depend on external tool feedback and fail to simultaneously lessen
toxicity and bias. Motivated by social psychology principles, we propose a
novel strategy named \textbf{perspective-taking prompting (\textsc{PeT})} that
inspires LLMs to integrate diverse human perspectives and self-regulate their
responses. This self-correction mechanism can significantly diminish toxicity
(up to $89\%$) and bias (up to $73\%$) in LLMs' responses. Rigorous evaluations
and ablation studies are conducted on two commercial LLMs (ChatGPT and GLM) and
three open-source LLMs, revealing \textsc{PeT}'s superiority in producing less
harmful responses, outperforming five strong baselines.

摘要：大型語言模型（LLM）產生的內容中常見的毒性與社會偏見，需要有策略來減少傷害。現有的解決方案通常需要對模型有白盒存取權或大量的訓練，這對於尖端的商業 LLM 來說是不切實際的。此外，流行的提示方法依賴於外部工具回饋，且無法同時減少毒性和偏見。我們受到社會心理學原理的啟發，提出了一種名為「觀點採取提示（PeT）」的新策略，它激勵 LLM 整合多元的人類觀點並自我調節其回應。這種自我修正機制可以顯著減少 LLM 回應中的毒性（高達 89%）和偏見（高達 73%）。對兩個商業 LLM（ChatGPT 和 GLM）和三個開源 LLM 進行了嚴謹的評估和消融研究，揭示了 PeT 在產生較少有害回應方面的優越性，優於五個強大的基線。

##### **A Multimodal Knowledge-enhanced Whole-slide Pathology Foundation Model**
2407.15362v1 by Yingxue Xu, Yihui Wang, Fengtao Zhou, Jiabo Ma, Shu Yang, Huangjing Lin, Xin Wang, Jiguang Wang, Li Liang, Anjia Han, Ronald Cheong Kin Chan, Hao Chen

Remarkable strides in computational pathology have been made in the
task-agnostic foundation model that advances the performance of a wide array of
downstream clinical tasks. Despite the promising performance, there are still
several challenges. First, prior works have resorted to either vision-only or
vision-captions data, disregarding invaluable pathology reports and gene
expression profiles which respectively offer distinct knowledge for versatile
clinical applications. Second, the current progress in pathology FMs
predominantly concentrates on the patch level, where the restricted context of
patch-level pretraining fails to capture whole-slide patterns. Here we curated
the largest multimodal dataset consisting of H\&E diagnostic whole slide images
and their associated pathology reports and RNA-Seq data, resulting in 26,169
slide-level modality pairs from 10,275 patients across 32 cancer types. To
leverage these data for CPath, we propose a novel whole-slide pretraining
paradigm which injects multimodal knowledge at the whole-slide context into the
pathology FM, called Multimodal Self-TAught PRetraining (mSTAR). The proposed
paradigm revolutionizes the workflow of pretraining for CPath, which enables
the pathology FM to acquire the whole-slide context. To our knowledge, this is
the first attempt to incorporate multimodal knowledge at the slide level for
enhancing pathology FMs, expanding the modelling context from unimodal to
multimodal knowledge and from patch-level to slide-level. To systematically
evaluate the capabilities of mSTAR, extensive experiments including slide-level
unimodal and multimodal applications, are conducted across 7 diverse types of
tasks on 43 subtasks, resulting in the largest spectrum of downstream tasks.
The average performance in various slide-level applications consistently
demonstrates significant performance enhancements for mSTAR compared to SOTA
FMs.

摘要：<paragraph>在計算病理學中，任務不可知基礎模型已取得顯著進展，可提升廣泛下游臨床任務的效能。儘管效能令人滿意，但仍有幾個挑戰。首先，先前的研究僅採用僅限影像或影像標題資料，忽略了寶貴的病理報告和基因表現特徵，而這些特徵分別為多功能臨床應用提供了不同的知識。其次，病理 FM 的當前進度主要集中在區塊層級，區塊層級預訓練的受限背景無法擷取全切片模式。在此，我們策劃了最大的多模態資料集，包含 H&E 診斷全切片影像及其相關病理報告和 RNA-Seq 資料，共產生來自 32 種癌症類型的 10,275 名患者的 26,169 個切片層級模態配對。為了將這些資料用於 CPath，我們提出了一種創新的全切片預訓練範例，將全切片背景的多模態知識注入病理 FM，稱為多模態自教預訓練 (mSTAR)。所提出的範例徹底改變了 CPath 的預訓練工作流程，使病理 FM 能夠獲取全切片背景。據我們所知，這是首次嘗試在切片層級納入多模態知識以增強病理 FM，將建模背景從單一模態知識擴展到多模態知識，以及從區塊層級擴展到切片層級。為了系統性地評估 mSTAR 的功能，我們在 43 個子任務中對 7 種不同類型的任務進行了廣泛的實驗，包括切片層級的單一模態和多模態應用，產生了最大的下游任務範圍。在各種切片層級應用中，平均效能持續顯示 mSTAR 與 SOTA FM 相比有顯著的效能提升。</paragraph>

##### **Dissecting Multiplication in Transformers: Insights into LLMs**
2407.15360v1 by Luyu Qiu, Jianing Li, Chi Su, Chen Jason Zhang, Lei Chen

Transformer-based large language models have achieved remarkable performance
across various natural language processing tasks. However, they often struggle
with seemingly easy tasks like arithmetic despite their vast capabilities. This
stark disparity raise human's concerns about their safe and ethical use, hinder
their widespread adoption.In this paper, we focus on a typical arithmetic task,
integer multiplication, to explore and explain the imperfection of transformers
in this domain. We provide comprehensive analysis of a vanilla transformer
trained to perform n-digit integer multiplication. Our observations indicate
that the model decomposes multiplication task into multiple parallel subtasks,
sequentially optimizing each subtask for each digit to complete the final
multiplication. Based on observation and analysis, we infer the reasons of
transformers deficiencies in multiplication tasks lies in their difficulty in
calculating successive carryovers and caching intermediate results, and
confirmed this inference through experiments. Guided by these findings, we
propose improvements to enhance transformers performance on multiplication
tasks. These enhancements are validated through rigorous testing and
mathematical modeling, not only enhance transformer's interpretability, but
also improve its performance, e.g., we achieve over 99.9% accuracy on 5-digit
integer multiplication with a tiny transformer, outperform LLMs GPT-4. Our
method contributes to the broader fields of model understanding and
interpretability, paving the way for analyzing more complex tasks and
Transformer models. This work underscores the importance of explainable AI,
helping to build trust in large language models and promoting their adoption in
critical applications.

摘要：<paragraph>基於 Transformer 的大型語言模型在各種自然語言處理任務中取得了顯著的表現。然而，儘管它們功能強大，但它們經常在算術等看似簡單的任務上遇到困難。這種明顯的差異引起了人們對其安全和道德使用方式的擔憂，阻礙了它們的廣泛採用。在本文中，我們專注於一項典型的算術任務，整數乘法，以探索和解釋 Transformer 在這個領域中的不完美。我們對一個訓練有素的香草 Transformer 進行了全面的分析，以執行 n 位整數乘法。我們的觀察表明，該模型將乘法任務分解為多個並行子任務，對每個數字的每個子任務進行順序優化，以完成最終乘法。根據觀察和分析，我們推斷出 Transformer 在乘法任務中的缺陷原因在於它們難以計算連續進位和快取中間結果，並通過實驗確認了這一推論。在這些發現的指導下，我們提出了改進建議，以增強 Transformer 在乘法任務上的性能。這些改進通過嚴格的測試和數學建模得到驗證，不僅增強了 Transformer 的可解釋性，還提高了它的性能，例如，我們在 5 位整數乘法上實現了超過 99.9% 的準確率，使用一個微小的 Transformer，優於 LLM GPT-4。我們的研究方法有助於模型理解和可解釋性的更廣泛領域，為分析更複雜的任務和 Transformer 模型鋪平了道路。這項工作強調了可解釋 AI 的重要性，有助於建立對大型語言模型的信任，並促進它們在關鍵應用中的採用。</paragraph>

##### **UF-HOBI at "Discharge Me!": A Hybrid Solution for Discharge Summary Generation Through Prompt-based Tuning of GatorTronGPT Models**
2407.15359v1 by Mengxian Lyu, Cheng Peng, Daniel Paredes, Ziyi Chen, Aokun Chen, Jiang Bian, Yonghui Wu

Automatic generation of discharge summaries presents significant challenges
due to the length of clinical documentation, the dispersed nature of patient
information, and the diverse terminology used in healthcare. This paper
presents a hybrid solution for generating discharge summary sections as part of
our participation in the "Discharge Me!" Challenge at the BioNLP 2024 Shared
Task. We developed a two-stage generation method using both extractive and
abstractive techniques, in which we first apply name entity recognition (NER)
to extract key clinical concepts, which are then used as input for a
prompt-tuning-based GatorTronGPT model to generate coherent text for two
important sections including "Brief Hospital Course" and "Discharge
Instructions". Our system was ranked 5th in this challenge, achieving an
overall score of 0.284. The results demonstrate the effectiveness of our hybrid
solution in improving the quality of automated discharge section generation.

摘要：由於臨床文件長度、患者資訊分散以及醫療保健中使用的術語多樣，自動產生出院摘要會面臨重大挑戰。本文提出了一種混合解決方案，用於產生出院摘要部分，作為我們參與 BioNLP 2024 共享任務中的「Discharge Me!」挑戰的一部分。我們開發了一種使用萃取和摘要技術的兩階段產生方法，其中我們首先應用命名實體辨識 (NER) 來萃取關鍵臨床概念，然後將其用作提示調整式 GatorTronGPT 模型的輸入，以產生兩個重要部分的連貫文字，包括「簡要住院病程」和「出院指示」。我們的系統在此挑戰中排名第 5，達到 0.284 的總分。結果證明了我們的混合解決方案在改善自動出院部分產生的品質方面有效。

##### **X-Recon: Learning-based Patient-specific High-Resolution CT Reconstruction from Orthogonal X-Ray Images**
2407.15356v1 by Yunpeng Wang, Kang Wang, Yaoyao Zhuo, Weiya Shi, Fei Shan, Lei Liu

Rapid and accurate diagnosis of pneumothorax, utilizing chest X-ray and
computed tomography (CT), is crucial for assisted diagnosis. Chest X-ray is
commonly used for initial localization of pneumothorax, while CT ensures
accurate quantification. However, CT scans involve high radiation doses and can
be costly. To achieve precise quantitative diagnosis while minimizing radiation
exposure, we proposed X-Recon, a CT ultra-sparse reconstruction network based
on ortho-lateral chest X-ray images. X-Recon integrates generative adversarial
networks (GANs), including a generator with a multi-scale fusion rendering
module and a discriminator enhanced by 3D coordinate convolutional layers,
designed to facilitate CT reconstruction. To improve precision, a projective
spatial transformer is utilized to incorporate multi-angle projection loss.
Additionally, we proposed PTX-Seg, a zero-shot pneumothorax segmentation
algorithm, combining image processing techniques with deep-learning models for
the segmentation of air-accumulated regions and lung structures. Experiments on
a large-scale dataset demonstrate its superiority over existing approaches.
X-Recon achieved a significantly higher reconstruction resolution with a higher
average spatial resolution and a lower average slice thickness. The
reconstruction metrics achieved state-of-the-art performance in terms of
several metrics including peak signal-to-noise ratio. The zero-shot
segmentation algorithm, PTX-Seg, also demonstrated high segmentation precision
for the air-accumulated region, the left lung, and the right lung. Moreover,
the consistency analysis for the pneumothorax chest occupancy ratio between
reconstructed CT and original CT obtained a high correlation coefficient. Code
will be available at: https://github.com/wangyunpengbio/X-Recon

摘要：<paragraph>利用胸部 X 射線和電腦斷層掃描 (CT) 快速準確診斷氣胸，對於輔助診斷至關重要。胸部 X 射線通常用於氣胸的初步定位，而 CT 可確保準確量化。然而，CT 掃描涉及高輻射劑量且可能昂貴。為了在最大程度降低輻射暴露的同時實現精確的定量診斷，我們提出了 X-Recon，這是一個基於正側位胸部 X 射線影像的 CT 超稀疏重建網路。X-Recon 整合了生成對抗網路 (GAN)，包括一個具有多尺度融合渲染模組的生成器和一個由 3D 座標卷積層增強的判別器，旨在促進 CT 重建。為了提高精度，利用射影空間變換器來納入多角度投影損失。此外，我們提出了 PTX-Seg，這是一種零次學習氣胸分割演算法，結合了影像處理技術與深度學習模型，用於分割積氣區域和肺部結構。在大規模資料集上的實驗證明了其優於現有方法。X-Recon 以更高的平均空間解析度和更低的平均切片厚度，實現了顯著更高的重建解析度。重建指標在包括峰值信噪比在內的幾個指標方面達到了最先進的效能。零次學習分割演算法 PTX-Seg 也展示了對積氣區域、左肺和右肺的高分割精度。此外，重建 CT 和原始 CT 之間的氣胸胸腔佔有率的一致性分析獲得了很高的相關係數。程式碼將在以下位置提供：https://github.com/wangyunpengbio/X-Recon</paragraph>

##### **Customized Retrieval Augmented Generation and Benchmarking for EDA Tool Documentation QA**
2407.15353v1 by Yuan Pu, Zhuolun He, Tairu Qiu, Haoyuan Wu, Bei Yu

Retrieval augmented generation (RAG) enhances the accuracy and reliability of
generative AI models by sourcing factual information from external databases,
which is extensively employed in document-grounded question-answering (QA)
tasks. Off-the-shelf RAG flows are well pretrained on general-purpose
documents, yet they encounter significant challenges when being applied to
knowledge-intensive vertical domains, such as electronic design automation
(EDA). This paper addresses such issue by proposing a customized RAG framework
along with three domain-specific techniques for EDA tool documentation QA,
including a contrastive learning scheme for text embedding model fine-tuning, a
reranker distilled from proprietary LLM, and a generative LLM fine-tuned with
high-quality domain corpus. Furthermore, we have developed and released a
documentation QA evaluation benchmark, ORD-QA, for OpenROAD, an advanced
RTL-to-GDSII design platform. Experimental results demonstrate that our
proposed RAG flow and techniques have achieved superior performance on ORD-QA
as well as on a commercial tool, compared with state-of-the-arts. The ORD-QA
benchmark and the training dataset for our customized RAG flow are open-source
at https://github.com/lesliepy99/RAG-EDA.

摘要：检索增强生成 (RAG) 透过从外部数据库撷取事实信息来提升生成式 AI 模型的准确度和可靠度，广泛用于基于文件的问答 (QA) 任务。现成的 RAG 流程在通用文件上经过充分预训练，但在应用于知识密集型垂直领域（例如电子设计自动化 (EDA)）时会遇到重大挑战。本文透过提出一个客制化 RAG 架构以及三个针对 EDA 工具文件 QA 的领域特定技术来解决此问题，包括用于文本嵌入模型微调的对比式学习方案、从专有 LLM 蒸馏出的重新排序器，以及经过高质量领域语料库微调的生成式 LLM。此外，我们已开发并发布文件 QA 评估基准 ORD-QA，供 OpenROAD 使用，OpenROAD 是先进的 RTL 转 GDSII 设计平台。实验结果显示，与最先进的技术相比，我们提出的 RAG 流程和技术在 ORD-QA 以及商用工具上均达到优异的效能。ORD-QA 基准和我们客制化 RAG 流程的训练数据集可在 https://github.com/lesliepy99/RAG-EDA 开源取得。

##### **MAVEN-Fact: A Large-scale Event Factuality Detection Dataset**
2407.15352v1 by Chunyang Li, Hao Peng, Xiaozhi Wang, Yunjia Qi, Lei Hou, Bin Xu, Juanzi Li

Event Factuality Detection (EFD) task determines the factuality of textual
events, i.e., classifying whether an event is a fact, possibility, or
impossibility, which is essential for faithfully understanding and utilizing
event knowledge. However, due to the lack of high-quality large-scale data,
event factuality detection is under-explored in event understanding research,
which limits the development of EFD community. To address these issues and
provide faithful event understanding, we introduce MAVEN-Fact, a large-scale
and high-quality EFD dataset based on the MAVEN dataset. MAVEN-Fact includes
factuality annotations of 112,276 events, making it the largest EFD dataset.
Extensive experiments demonstrate that MAVEN-Fact is challenging for both
conventional fine-tuned models and large language models (LLMs). Thanks to the
comprehensive annotations of event arguments and relations in MAVEN, MAVEN-Fact
also supports some further analyses and we find that adopting event arguments
and relations helps in event factuality detection for fine-tuned models but
does not benefit LLMs. Furthermore, we preliminarily study an application case
of event factuality detection and find it helps in mitigating event-related
hallucination in LLMs. Our dataset and codes can be obtained from
\url{https://github.com/lcy2723/MAVEN-FACT}

摘要：事件真實性偵測 (EFD) 任務是判斷文字事件的真實性，亦即將事件分類為事實、可能性或不可能，這對於忠實理解和利用事件知識至關重要。然而，由於缺乏高品質的大規模資料，事件真實性偵測在事件理解研究中並未獲得充分探索，這限制了 EFD 社群的發展。為了解決這些問題並提供忠實的事件理解，我們引入了 MAVEN-Fact，這是一個基於 MAVEN 資料集的大規模高品質 EFD 資料集。MAVEN-Fact 包含 112,276 個事件的真實性註解，使其成為最大的 EFD 資料集。廣泛的實驗表明，MAVEN-Fact 對傳統微調模型和大型語言模型 (LLM) 來說都是具有挑戰性的。由於 MAVEN 中事件論元和關係的全面註解，MAVEN-Fact 也支援一些進一步的分析，我們發現採用事件論元和關係有助於微調模型的事件真實性偵測，但對 LLM 沒有幫助。此外，我們初步研究了事件真實性偵測的一個應用案例，發現它有助於減輕 LLM 中與事件相關的幻覺。我們的資料集和程式碼可從 \url{https://github.com/lcy2723/MAVEN-FACT} 取得

##### **LLMExplainer: Large Language Model based Bayesian Inference for Graph Explanation Generation**
2407.15351v2 by Jiaxing Zhang, Jiayi Liu, Dongsheng Luo, Jennifer Neville, Hua Wei

Recent studies seek to provide Graph Neural Network (GNN) interpretability
via multiple unsupervised learning models. Due to the scarcity of datasets,
current methods easily suffer from learning bias. To solve this problem, we
embed a Large Language Model (LLM) as knowledge into the GNN explanation
network to avoid the learning bias problem. We inject LLM as a Bayesian
Inference (BI) module to mitigate learning bias. The efficacy of the BI module
has been proven both theoretically and experimentally. We conduct experiments
on both synthetic and real-world datasets. The innovation of our work lies in
two parts: 1. We provide a novel view of the possibility of an LLM functioning
as a Bayesian inference to improve the performance of existing algorithms; 2.
We are the first to discuss the learning bias issues in the GNN explanation
problem.

摘要：近期研究試圖透過多種非監督式學習模型來提供圖神經網路 (GNN) 的可解釋性。由於資料集的稀少，目前的演算法容易受到學習偏差的影響。為了解決這個問題，我們將大型語言模型 (LLM) 作為知識嵌入到 GNN 解釋網路中，以避免學習偏差的問題。我們將 LLM 作為貝氏推論 (BI) 模組注入，以減輕學習偏差。BI 模組的效能已在理論上和實驗上得到證實。我們在合成和真實世界資料集上進行實驗。我們工作的創新之處在於兩部分：1. 我們提供 LLM 作為貝氏推論以改善現有演算法效能的可能性之新觀點；2. 我們率先討論 GNN 解釋問題中的學習偏差問題。

##### **Knowledge Acquisition Disentanglement for Knowledge-based Visual Question Answering with Large Language Models**
2407.15346v1 by Wenbin An, Feng Tian, Jiahao Nie, Wenkai Shi, Haonan Lin, Yan Chen, QianYing Wang, Yaqiang Wu, Guang Dai, Ping Chen

Knowledge-based Visual Question Answering (KVQA) requires both image and
world knowledge to answer questions. Current methods first retrieve knowledge
from the image and external knowledge base with the original complex question,
then generate answers with Large Language Models (LLMs). However, since the
original question contains complex elements that require knowledge from
different sources, acquiring different kinds of knowledge in a coupled manner
may confuse models and hinder them from retrieving precise knowledge.
Furthermore, the ``forward-only'' answering process fails to explicitly capture
the knowledge needs of LLMs, which can further hurt answering quality. To cope
with the above limitations, we propose DKA: Disentangled Knowledge Acquisition
from LLM feedback, a training-free framework that disentangles knowledge
acquisition to avoid confusion and uses LLM's feedback to specify the required
knowledge. Specifically, DKA requires LLMs to specify what knowledge they need
to answer the question and decompose the original complex question into two
simple sub-questions: Image-based sub-question and Knowledge-based
sub-question. Then we use the two sub-questions to retrieve knowledge from the
image and knowledge base, respectively. In this way, two knowledge acquisition
models can focus on the content that corresponds to them and avoid disturbance
of irrelevant elements in the original complex question, which can help to
provide more precise knowledge and better align the knowledge needs of LLMs to
yield correct answers. Experiments on benchmark datasets show that DKA
significantly outperforms SOTA models. To facilitate future research, our data
and code are available at \url{https://github.com/Lackel/DKA}.

摘要：基於知識的視覺問答 (KVQA) 需要影像和世界知識才能回答問題。目前的做法是先用原始的複雜問題從影像和外部知識庫中擷取知識，然後使用大型語言模型 (LLM) 產生答案。然而，由於原始問題包含需要來自不同來源的知識的複雜元素，以結合的方式獲取不同類型的知識可能會讓模型感到困惑，並阻礙它們擷取精確的知識。此外，「僅前向」的回答過程無法明確捕捉 LLM 的知識需求，這可能會進一步損害回答品質。為了應對上述限制，我們提出了 DKA：從 LLM 回饋中解開知識獲取，這是一個無需訓練的架構，它解開知識獲取以避免混淆，並使用 LLM 的回饋來指定所需的知識。具體來說，DKA 要求 LLM 指定他們需要什麼知識來回答問題，並將原始的複雜問題分解成兩個簡單的子問題：基於影像的子問題和基於知識的子問題。然後我們使用這兩個子問題分別從影像和知識庫中擷取知識。透過這種方式，兩個知識獲取模型可以專注於與它們對應的內容，並避免原始複雜問題中無關元素的干擾，這有助於提供更精確的知識，並更好地調整 LLM 的知識需求以產生正確的答案。基準資料集上的實驗顯示，DKA 明顯優於 SOTA 模型。為了促進未來的研究，我們的資料和程式碼可以在 \url{https://github.com/Lackel/DKA} 取得。

##### **Improving Minimum Bayes Risk Decoding with Multi-Prompt**
2407.15343v1 by David Heineman, Yao Dou, Wei Xu

While instruction fine-tuned LLMs are effective text generators, sensitivity
to prompt construction makes performance unstable and sub-optimal in practice.
Relying on a single "best" prompt cannot capture all differing approaches to a
generation problem. Using this observation, we propose multi-prompt decoding,
where many candidate generations are decoded from a prompt bank at
inference-time. To ensemble candidates, we use Minimum Bayes Risk (MBR)
decoding, which selects a final output using a trained value metric. We show
multi-prompt improves MBR across a comprehensive set of conditional generation
tasks, and show this is a result of estimating a more diverse and higher
quality candidate space than that of a single prompt. Further experiments
confirm multi-prompt improves generation across tasks, models and metrics.

摘要：雖然經過微調的 LLM 是有效的文字生成器，但對提示結構的敏感性會導致效能不穩定且在實務上低於最佳狀態。依賴單一的「最佳」提示無法涵蓋所有不同的生成問題方法。利用此觀察結果，我們提出多提示解碼，其中在推論時間從提示庫解碼出許多候選生成。為了組合候選項，我們使用最小貝氏風險 (MBR) 解碼，它使用訓練後的數值指標來選擇最終輸出。我們展示多提示在全面的條件生成任務中改善 MBR，並展示這是估計比單一提示更為多樣且品質更高的候選空間的結果。進一步的實驗確認多提示改善了不同任務、模型和指標的生成。

##### **ZZU-NLP at SIGHAN-2024 dimABSA Task: Aspect-Based Sentiment Analysis with Coarse-to-Fine In-context Learning**
2407.15341v1 by Senbin Zhu, Hanjie Zhao, Xingren Wang, Shanhong Liu, Yuxiang Jia, Hongying Zan

The DimABSA task requires fine-grained sentiment intensity prediction for
restaurant reviews, including scores for Valence and Arousal dimensions for
each Aspect Term. In this study, we propose a Coarse-to-Fine In-context
Learning(CFICL) method based on the Baichuan2-7B model for the DimABSA task in
the SIGHAN 2024 workshop. Our method improves prediction accuracy through a
two-stage optimization process. In the first stage, we use fixed in-context
examples and prompt templates to enhance the model's sentiment recognition
capability and provide initial predictions for the test data. In the second
stage, we encode the Opinion field using BERT and select the most similar
training data as new in-context examples based on similarity. These examples
include the Opinion field and its scores, as well as related opinion words and
their average scores. By filtering for sentiment polarity, we ensure that the
examples are consistent with the test data. Our method significantly improves
prediction accuracy and consistency by effectively utilizing training data and
optimizing in-context examples, as validated by experimental results.

摘要：DimABSA 任務需要對餐廳評論進行細緻的情感強度預測，包括對每個面向術語的情感價和喚醒維度的評分。在本研究中，我們針對 SIGHAN 2024 研討會中的 DimABSA 任務，提出一個基於百川 2-7B 模型的粗到細情境內學習 (CFICL) 方法。我們的模型透過兩階段優化程序來提升預測準確度。在第一階段，我們使用固定的情境內範例和提示範本，來增強模型的情感辨識能力，並提供測試資料的初始預測。在第二階段，我們使用 BERT 對意見欄位進行編碼，並根據相似度，從訓練資料中選出最相似的資料作為新的情境內範例。這些範例包括意見欄位及其評分，以及相關的意見詞和其平均評分。透過對情感極性進行過濾，我們確保這些範例與測試資料一致。我們的模型透過有效利用訓練資料和最佳化情境內範例，大幅提升預測準確度和一致性，實驗結果也證實了這一點。

##### **Deep Learning for Economists**
2407.15339v1 by Melissa Dell

Deep learning provides powerful methods to impute structured information from
large-scale, unstructured text and image datasets. For example, economists
might wish to detect the presence of economic activity in satellite images, or
to measure the topics or entities mentioned in social media, the congressional
record, or firm filings. This review introduces deep neural networks, covering
methods such as classifiers, regression models, generative AI, and embedding
models. Applications include classification, document digitization, record
linkage, and methods for data exploration in massive scale text and image
corpora. When suitable methods are used, deep learning models can be cheap to
tune and can scale affordably to problems involving millions or billions of
data points.. The review is accompanied by a companion website, EconDL, with
user-friendly demo notebooks, software resources, and a knowledge base that
provides technical details and additional applications.

摘要：深度學習提供強大的方法，從大規模、非結構化文字和影像資料集中輸入結構化資訊。例如，經濟學家可能希望在衛星影像中偵測經濟活動的存在，或測量社群媒體、國會記錄或公司檔案中所提到的主題或實體。這篇評論介紹了深度神經網路，涵蓋分類器、迴歸模型、生成式 AI 和嵌入模型等方法。應用包括分類、文件數位化、記錄連結，以及在大量文字和影像語料庫中進行資料探勘的方法。當使用合適的方法時，深度學習模型可以便宜地調整，並且可以負擔得起地擴展到涉及數百萬或數十億個資料點的問題。這篇評論附帶一個配套網站 EconDL，其中包含使用者友善的示範筆記本、軟體資源和一個提供技術細節和額外應用程式的知識庫。

##### **Robust personalized pricing under uncertainty of purchase probabilities**
2407.15332v1 by Shunnosuke Ikeda, Naoki Nishimura, Noriyoshi Sukegawa, Yuichi Takano

This paper is concerned with personalized pricing models aimed at maximizing
the expected revenues or profits for a single item. While it is essential for
personalized pricing to predict the purchase probabilities for each consumer,
these predicted values are inherently subject to unavoidable errors that can
negatively impact the realized revenues and profits. To address this issue, we
focus on robust optimization techniques that yield reliable solutions to
optimization problems under uncertainty. Specifically, we propose a robust
optimization model for personalized pricing that accounts for the uncertainty
of predicted purchase probabilities. This model can be formulated as a
mixed-integer linear optimization problem, which can be solved exactly using
mathematical optimization solvers. We also develop a Lagrangian decomposition
algorithm combined with line search to efficiently find high-quality solutions
for large-scale optimization problems. Experimental results demonstrate the
effectiveness of our robust optimization model and highlight the utility of our
Lagrangian decomposition algorithm in terms of both computational efficiency
and solution quality.

摘要：本文探讨了旨在最大化单个商品预期收入或利润的个性化定价模型。虽然个性化定价对于预测每个消费者的购买概率至关重要，但这些预测值本质上会受到不可避免的错误影响，而这些错误可能会对实现的收入和利润产生负面影响。为了解决这个问题，我们专注于稳健优化技术，该技术在不确定性下为优化问题提供了可靠的解决方案。具体来说，我们提出了一个稳健优化模型，用于个性化定价，该模型考虑了预测购买概率的不确定性。该模型可以表述为混合整数线性优化问题，可以使用数学优化求解器精确求解。我们还开发了一种拉格朗日分解算法，结合线搜索，以有效地为大规模优化问题找到高质量的解决方案。实验结果证明了我们稳健优化模型的有效性，并从计算效率和解决方案质量两方面突出了我们拉格朗日分解算法的效用。

##### **Odyssey: Empowering Agents with Open-World Skills**
2407.15325v1 by Shunyu Liu, Yaoru Li, Kongcheng Zhang, Zhenyu Cui, Wenkai Fang, Yuxuan Zheng, Tongya Zheng, Mingli Song

Recent studies have delved into constructing generalist agents for open-world
embodied environments like Minecraft. Despite the encouraging results, existing
efforts mainly focus on solving basic programmatic tasks, e.g., material
collection and tool-crafting following the Minecraft tech-tree, treating the
ObtainDiamond task as the ultimate goal. This limitation stems from the
narrowly defined set of actions available to agents, requiring them to learn
effective long-horizon strategies from scratch. Consequently, discovering
diverse gameplay opportunities in the open world becomes challenging. In this
work, we introduce ODYSSEY, a new framework that empowers Large Language Model
(LLM)-based agents with open-world skills to explore the vast Minecraft world.
ODYSSEY comprises three key parts: (1) An interactive agent with an open-world
skill library that consists of 40 primitive skills and 183 compositional
skills. (2) A fine-tuned LLaMA-3 model trained on a large question-answering
dataset with 390k+ instruction entries derived from the Minecraft Wiki. (3) A
new open-world benchmark includes thousands of long-term planning tasks, tens
of dynamic-immediate planning tasks, and one autonomous exploration task.
Extensive experiments demonstrate that the proposed ODYSSEY framework can
effectively evaluate the planning and exploration capabilities of agents. All
datasets, model weights, and code are publicly available to motivate future
research on more advanced autonomous agent solutions.

摘要：<paragraph>最近的研究深入探討了為 Minecraft 等開放世界具身環境建構通才代理。儘管結果令人鼓舞，現有的努力主要集中於解決基本的程式化任務，例如材料收集和按照 Minecraft 技術樹製作工具，並將取得鑽石任務視為最終目標。這種限制源於代理可用的動作集定義狹窄，要求它們從頭學習有效的長時程策略。因此，在開放世界中發現多樣化的遊戲機會變得具有挑戰性。在這項工作中，我們介紹了 ODYSSEY，一個新的框架，它賦予基於大型語言模型 (LLM) 的代理具備探索廣闊 Minecraft 世界的開放世界技能。ODYSSEY 包含三個關鍵部分：(1) 具有開放世界技能庫的互動代理，包含 40 個基本技能和 183 個組合技能。(2) 在大型問答資料集上微調的 LLaMA-3 模型，其中包含從 Minecraft Wiki 衍生的 390,000 多個指令條目。(3) 一個新的開放世界基準包括數千個長期規劃任務、數十個動態即時規劃任務和一個自主探索任務。廣泛的實驗表明，所提出的 ODYSSEY 框架可以有效評估代理的規劃和探索能力。所有資料集、模型權重和程式碼都是公開的，以激勵未來對更先進的自主代理解決方案的研究。</paragraph>

##### **FMDNN: A Fuzzy-guided Multi-granular Deep Neural Network for Histopathological Image Classification**
2407.15312v1 by Weiping Ding, Tianyi Zhou, Jiashuang Huang, Shu Jiang, Tao Hou, Chin-Teng Lin

Histopathological image classification constitutes a pivotal task in
computer-aided diagnostics. The precise identification and categorization of
histopathological images are of paramount significance for early disease
detection and treatment. In the diagnostic process of pathologists, a
multi-tiered approach is typically employed to assess abnormalities in cell
regions at different magnifications. However, feature extraction is often
performed at a single granularity, overlooking the multi-granular
characteristics of cells. To address this issue, we propose the Fuzzy-guided
Multi-granularity Deep Neural Network (FMDNN). Inspired by the multi-granular
diagnostic approach of pathologists, we perform feature extraction on cell
structures at coarse, medium, and fine granularity, enabling the model to fully
harness the information in histopathological images. We incorporate the theory
of fuzzy logic to address the challenge of redundant key information arising
during multi-granular feature extraction. Cell features are described from
different perspectives using multiple fuzzy membership functions, which are
fused to create universal fuzzy features. A fuzzy-guided cross-attention module
guides universal fuzzy features toward multi-granular features. We propagate
these features through an encoder to all patch tokens, aiming to achieve
enhanced classification accuracy and robustness. In experiments on multiple
public datasets, our model exhibits a significant improvement in accuracy over
commonly used classification methods for histopathological image classification
and shows commendable interpretability.

摘要：組織病理學影像分類在電腦輔助診斷中扮演著關鍵角色。組織病理學影像的精確辨識和分類對於早期疾病偵測和治療至關重要。在病理學家的診斷過程中，通常採用多層級方法來評估不同放大倍率下細胞區域的異常。然而，特徵萃取通常在單一顆粒度下執行，忽略了細胞的多顆粒特徵。為了解決這個問題，我們提出了模糊導引多顆粒深度神經網路 (FMDNN)。受到病理學家多顆粒診斷方法的啟發，我們對粗、中、細顆粒度的細胞結構執行特徵萃取，使模型能夠充分利用組織病理學影像中的資訊。我們結合模糊邏輯理論來解決多顆粒特徵萃取過程中冗餘關鍵資訊的挑戰。細胞特徵使用多個模糊隸屬函數從不同角度描述，並融合以建立通用模糊特徵。模糊導引交叉注意模組引導通用模糊特徵走向多顆粒特徵。我們透過編碼器將這些特徵傳播到所有 patch 標記，旨在提高分類準確度和穩健性。在多個公開資料集的實驗中，我們的模型在組織病理學影像分類的準確度方面表現出顯著的提升，並展現出值得讚賞的可解釋性。

##### **Weak-to-Strong Compositional Learning from Generative Models for Language-based Object Detection**
2407.15296v1 by Kwanyong Park, Kuniaki Saito, Donghyun Kim

Vision-language (VL) models often exhibit a limited understanding of complex
expressions of visual objects (e.g., attributes, shapes, and their relations),
given complex and diverse language queries. Traditional approaches attempt to
improve VL models using hard negative synthetic text, but their effectiveness
is limited. In this paper, we harness the exceptional compositional
understanding capabilities of generative foundational models. We introduce a
novel method for structured synthetic data generation aimed at enhancing the
compositional understanding of VL models in language-based object detection.
Our framework generates densely paired positive and negative triplets (image,
text descriptions, and bounding boxes) in both image and text domains. By
leveraging these synthetic triplets, we transform 'weaker' VL models into
'stronger' models in terms of compositional understanding, a process we call
"Weak-to-Strong Compositional Learning" (WSCL). To achieve this, we propose a
new compositional contrastive learning formulation that discovers semantics and
structures in complex descriptions from synthetic triplets. As a result, VL
models trained with our synthetic data generation exhibit a significant
performance boost in the Omnilabel benchmark by up to +5AP and the D3 benchmark
by +6.9AP upon existing baselines.

摘要：視覺語言 (VL) 模型往往對視覺物件的複雜表達（例如，屬性、形狀及其關係）理解有限，因為語言查詢複雜且多樣。傳統方法嘗試使用難以否定的合成文字來改善 VL 模型，但其效果有限。在本文中，我們利用生成基礎模型的卓越組合理解能力。我們引入了一種用於結構化合成資料生成的新方法，旨在增強 VL 模型在基於語言的物件偵測中的組合理解。我們的架構在影像和文字領域中產生密集配對的正負三元組（影像、文字描述和邊界框）。透過利用這些合成三元組，我們將「較弱」的 VL 模型轉變為在組合理解方面「較強」的模型，這個過程我們稱之為「弱到強的組合學習」(Weak-to-Strong Compositional Learning, WSCL)。為達成此目的，我們提出一個新的組合對比學習公式，從合成三元組中發現複雜描述中的語義和結構。因此，使用我們的合成資料生成訓練的 VL 模型在 Omnilabel 基準上表現提升顯著，達 +5AP，在 D3 基準上則提升 +6.9AP，優於現有的基準。

##### **Intrinsic Self-correction for Enhanced Morality: An Analysis of Internal Mechanisms and the Superficial Hypothesis**
2407.15286v1 by Guangliang Liu, Haitao Mao, Jiliang Tang, Kristen Marie Johnson

Large Language Models (LLMs) are capable of producing content that
perpetuates stereotypes, discrimination, and toxicity. The recently proposed
moral self-correction is a computationally efficient method for reducing
harmful content in the responses of LLMs. However, the process of how injecting
self-correction instructions can modify the behavior of LLMs remains
under-explored. In this paper, we explore the effectiveness of moral
self-correction by answering three research questions: (1) In what scenarios
does moral self-correction work? (2) What are the internal mechanisms of LLMs,
e.g., hidden states, that are influenced by moral self-correction instructions?
(3) Is intrinsic moral self-correction actually superficial? We argue that
self-correction can help LLMs find a shortcut to more morally correct output,
rather than truly reducing the immorality stored in hidden states. Through
empirical investigation with tasks of language generation and multi-choice
question answering, we conclude: (i) LLMs exhibit good performance across both
tasks, and self-correction instructions are particularly beneficial when the
correct answer is already top-ranked; (ii) The morality levels in intermediate
hidden states are strong indicators as to whether one instruction would be more
effective than another; (iii) Based on our analysis of intermediate hidden
states and task case studies of self-correction behaviors, we are first to
propose the hypothesis that intrinsic moral self-correction is in fact
superficial.

摘要：大型語言模型 (LLM) 能產生延續刻板印象、歧視和毒性的內容。最近提出的道德自我修正是一種計算有效率的方法，用於減少 LLM 回應中的有害內容。然而，注入自我修正指令如何修改 LLM 行為的過程仍未充分探討。在本文中，我們透過回答三個研究問題來探討道德自我修正的有效性：(1) 在哪些情況下道德自我修正有效？(2) LLM 的哪些內部機制（例如隱藏狀態）受到道德自我修正指令的影響？(3) 內在道德自我修正是否真的只是表面功夫？我們認為自我修正可以幫助 LLM 找到捷徑以產生更符合道德的輸出，而不是真正減少儲存在隱藏狀態中的不道德性。透過語言生成和多選題答題任務的實證調查，我們得出以下結論：(i) LLM 在這兩個任務中都表現良好，而且當正確答案已名列前茅時，自我修正指令特別有益；(ii) 中間隱藏狀態中的道德水平是強而有力的指標，可以判斷一個指令是否比另一個指令更有效；(iii) 根據我們對中間隱藏狀態和自我修正行為的任務案例研究分析，我們首次提出假設，即內在道德自我修正實際上只是表面功夫。

##### **Enhancing Hardware Fault Tolerance in Machines with Reinforcement Learning Policy Gradient Algorithms**
2407.15283v1 by Sheila Schoepp, Mehran Taghian, Shotaro Miwa, Yoshihiro Mitsuka, Shadan Golestan, Osmar Zaïane

Industry is rapidly moving towards fully autonomous and interconnected
systems that can detect and adapt to changing conditions, including machine
hardware faults. Traditional methods for adding hardware fault tolerance to
machines involve duplicating components and algorithmically reconfiguring a
machine's processes when a fault occurs. However, the growing interest in
reinforcement learning-based robotic control offers a new perspective on
achieving hardware fault tolerance. However, limited research has explored the
potential of these approaches for hardware fault tolerance in machines. This
paper investigates the potential of two state-of-the-art reinforcement learning
algorithms, Proximal Policy Optimization (PPO) and Soft Actor-Critic (SAC), to
enhance hardware fault tolerance into machines. We assess the performance of
these algorithms in two OpenAI Gym simulated environments, Ant-v2 and
FetchReach-v1. Robot models in these environments are subjected to six
simulated hardware faults. Additionally, we conduct an ablation study to
determine the optimal method for transferring an agent's knowledge, acquired
through learning in a normal (pre-fault) environment, to a (post-)fault
environment in a continual learning setting. Our results demonstrate that
reinforcement learning-based approaches can enhance hardware fault tolerance in
simulated machines, with adaptation occurring within minutes. Specifically, PPO
exhibits the fastest adaptation when retaining the knowledge within its models,
while SAC performs best when discarding all acquired knowledge. Overall, this
study highlights the potential of reinforcement learning-based approaches, such
as PPO and SAC, for hardware fault tolerance in machines. These findings pave
the way for the development of robust and adaptive machines capable of
effectively operating in real-world scenarios.

摘要：<paragraph>產業正快速朝向能偵測和適應變動狀況的完全自主且相互連接的系統邁進，其中包括機器硬體故障。傳統上為機器增加硬體容錯的方法，包含複製組件，以及在發生故障時以演算法方式重新配置機器的程序。然而，對強化學習為基礎的機器人控制的興趣日益增加，提供了達成硬體容錯的新觀點。然而，有限的研究探討了這些方法在機器硬體容錯的潛力。本文探討了兩種最先進的強化學習演算法，近端策略最佳化 (PPO) 和軟性動作-評論家 (SAC)，在提升機器硬體容錯的潛力。我們在兩個 OpenAI Gym 模擬環境，Ant-v2 和 FetchReach-v1，評估這些演算法的效能。這些環境中的機器人模型會受到六種模擬硬體故障影響。此外，我們進行消融研究以決定在持續學習設定中，將代理程式在正常（故障前）環境中透過學習獲得的知識，轉移到（故障後）環境的最佳方法。我們的結果顯示，基於強化學習的方法可以在模擬機器中提升硬體容錯，適應會在幾分鐘內發生。特別是，PPO 在其模型中保留知識時展現最快的適應速度，而 SAC 在捨棄所有已獲得的知識時表現最佳。整體而言，這項研究突顯了基於強化學習的方法，例如 PPO 和 SAC，在機器硬體容錯的潛力。這些發現為開發能在真實世界場景中有效運作的強健且具適應性的機器鋪路。</paragraph>

##### **SynCPKL: Harnessing LLMs to Generate Synthetic Data for Commonsense Persona Knowledge Linking**
2407.15281v1 by Kuan-Yen Lin

Understanding rich dialogues often requires NLP systems to access relevant
commonsense persona knowledge, but retrieving this knowledge is challenging due
to complex contexts and the implicit nature of commonsense. This paper presents
our approach to the Commonsense Persona Knowledge Linking (CPKL) challenge,
addressing the critical need for integrating persona and commonsense knowledge
in open-domain dialogue systems. We introduce SynCPKL Pipeline, a pipeline that
leverages Large Language Models to generate high-quality synthetic datasets for
training commonsense persona knowledge linkers. To demonstrate the efficacy of
our approach, we present SynCPKL, a new dataset specifically designed for this
task. Our experiments validate the effectiveness of SynCPKL for training
commonsense persona knowledge linkers. Additionally, our top-performing model,
Derberta-SynCPKL, secured first place in the CPKL challenge by a 16%
improvement in F1 score. We released both SynCPKL and Derberta-SynCPKL at
https://github.com/irislin1006/CPKL.

摘要：理解豐富的對話通常需要 NLP 系統存取相關的常識人物知識，但由於複雜的脈絡和常識的隱含性質，因此擷取此知識具有挑戰性。本文介紹我們對常識人物知識連結 (CPKL) 挑戰的方法，解決在開放領域對話系統中整合人物和常識知識的關鍵需求。我們介紹 SynCPKL 管線，這是一個利用大型語言模型為訓練常識人物知識連結器產生高品質合成資料集的管線。為了證明我們方法的效能，我們提出 SynCPKL，這是一個專門為此任務設計的新資料集。我們的實驗驗證了 SynCPKL 在訓練常識人物知識連結器方面的效能。此外，我們表現最佳的模型 Derberta-SynCPKL 在 CPKL 挑戰中獲得第一名，F1 分數提升了 16%。我們在 https://github.com/irislin1006/CPKL 發布了 SynCPKL 和 Derberta-SynCPKL。

##### **Unifying Invariant and Variant Features for Graph Out-of-Distribution via Probability of Necessity and Sufficiency**
2407.15273v1 by Xuexin Chen, Ruichu Cai, Kaitao Zheng, Zhifan Jiang, Zhengting Huang, Zhifeng Hao, Zijian Li

Graph Out-of-Distribution (OOD), requiring that models trained on biased data
generalize to the unseen test data, has considerable real-world applications.
One of the most mainstream methods is to extract the invariant subgraph by
aligning the original and augmented data with the help of environment
augmentation. However, these solutions might lead to the loss or redundancy of
semantic subgraphs and result in suboptimal generalization. To address this
challenge, we propose exploiting Probability of Necessity and Sufficiency (PNS)
to extract sufficient and necessary invariant substructures. Beyond that, we
further leverage the domain variant subgraphs related to the labels to boost
the generalization performance in an ensemble manner. Specifically, we first
consider the data generation process for graph data. Under mild conditions, we
show that the sufficient and necessary invariant subgraph can be extracted by
minimizing an upper bound, built on the theoretical advance of the probability
of necessity and sufficiency. To further bridge the theory and algorithm, we
devise the model called Sufficiency and Necessity Inspired Graph Learning
(SNIGL), which ensembles an invariant subgraph classifier on top of latent
sufficient and necessary invariant subgraphs, and a domain variant subgraph
classifier specific to the test domain for generalization enhancement.
Experimental results demonstrate that our SNIGL model outperforms the
state-of-the-art techniques on six public benchmarks, highlighting its
effectiveness in real-world scenarios.

摘要：圖形異常分佈 (OOD) 要求在有偏差的資料上訓練的模型概化為未見的測試資料，這在現實世界中有相當多的應用。最主流的方法之一是透過環境擴充來比對原始資料和擴充資料，以萃取不變子圖。然而，這些解決方案可能會導致語義子圖的遺失或冗餘，並導致次佳的概化。為了應對這個挑戰，我們建議利用必要性和充分性機率 (PNS) 來萃取充分且必要的子結構。除此之外，我們進一步利用與標籤相關的網域變異子圖，以整體的方式提升概化效能。具體來說，我們首先考慮圖形資料的資料產生過程。在溫和的條件下，我們證明了充分且必要的子圖可以透過最小化一個上限來萃取，這個上限建立在必要性和充分性機率的理論進展上。為了進一步橋接理論和演算法，我們設計了一個名為充分性和必要性啟發圖形學習 (SNIGL) 的模型，它在潛在充分且必要的子圖上組合一個不變子圖分類器，以及一個特定於測試網域的網域變異子圖分類器，以增強概化。實驗結果證明，我們的 SNIGL 模型在六個公開基準上優於最先進的技術，突顯了它在現實世界場景中的有效性。

##### **Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation**
2407.15268v1 by Liwen Sun, James Zhao, Megan Han, Chenyan Xiong

Multimodal foundation models hold significant potential for automating
radiology report generation, thereby assisting clinicians in diagnosing cardiac
diseases. However, generated reports often suffer from serious factual
inaccuracy. In this paper, we introduce a fact-aware multimodal
retrieval-augmented pipeline in generating accurate radiology reports
(FactMM-RAG). We first leverage RadGraph to mine factual report pairs, then
integrate factual knowledge to train a universal multimodal retriever. Given a
radiology image, our retriever can identify high-quality reference reports to
augment multimodal foundation models, thus enhancing the factual completeness
and correctness of report generation. Experiments on two benchmark datasets
show that our multimodal retriever outperforms state-of-the-art retrievers on
both language generation and radiology-specific metrics, up to 6.5% and 2%
score in F1CheXbert and F1RadGraph. Further analysis indicates that employing
our factually-informed training strategy imposes an effective supervision
signal, without relying on explicit diagnostic label guidance, and successfully
propagates fact-aware capabilities from the multimodal retriever to the
multimodal foundation model in radiology report generation.

摘要：多模态基础模型在放射报告生成自动化方面具有巨大潜力，从而帮助临床医生诊断心脏疾病。然而，生成的报告常常存在严重的事实不准确性。在本文中，我们引入了一个事实感知的多模态检索增强管道来生成准确的放射报告（FactMM-RAG）。我们首先利用 RadGraph 来挖掘事实报告对，然后整合事实知识来训练一个通用的多模态检索器。给定一个放射图像，我们的检索器可以识别高质量的参考报告来增强多模态基础模型，从而增强报告生成的事实完整性和正确性。在两个基准数据集上的实验表明，我们的多模态检索器在语言生成和放射学特定指标上都优于最先进的检索器，在 F1CheXbert 和 F1RadGraph 中得分高达 6.5% 和 2%。进一步的分析表明，采用我们基于事实的训练策略施加了一个有效的监督信号，而无需依赖明确的诊断标签指导，并成功地将多模态检索器的事实感知能力传播到放射报告生成中的多模态基础模型。

##### **Explaining Decisions of Agents in Mixed-Motive Games**
2407.15255v1 by Maayan Orner, Oleg Maksimov, Akiva Kleinerman, Charles Ortiz, Sarit Kraus

In recent years, agents have become capable of communicating seamlessly via
natural language and navigating in environments that involve cooperation and
competition, a fact that can introduce social dilemmas. Due to the interleaving
of cooperation and competition, understanding agents' decision-making in such
environments is challenging, and humans can benefit from obtaining
explanations. However, such environments and scenarios have rarely been
explored in the context of explainable AI. While some explanation methods for
cooperative environments can be applied in mixed-motive setups, they do not
address inter-agent competition, cheap-talk, or implicit communication by
actions. In this work, we design explanation methods to address these issues.
Then, we proceed to demonstrate their effectiveness and usefulness for humans,
using a non-trivial mixed-motive game as a test case. Lastly, we establish
generality and demonstrate the applicability of the methods to other games,
including one where we mimic human game actions using large language models.

摘要：近年来，代理人已能够通过自然语言无缝沟通，并在涉及合作和竞争的环境中导航，这一事实可能会带来社会困境。由于合作和竞争的交织，理解代理人在这种环境中的决策具有挑战性，而人类可以从获得解释中受益。然而，在可解释人工智能的背景下，这种环境和场景很少被探索。虽然一些针对合作环境的解释方法可以在混合动机设置中应用，但它们不解决代理间竞争、廉价谈话或通过行动进行的隐式沟通。在这项工作中，我们设计了解释方法来解决这些问题。然后，我们继续使用一个非平凡的混合动机游戏作为测试案例，展示它们对人类的有效性和有用性。最后，我们建立了普遍性，并展示了这些方法对其他游戏的适用性，包括我们使用大型语言模型模仿人类游戏动作的游戏。

##### **XAI meets LLMs: A Survey of the Relation between Explainable AI and Large Language Models**
2407.15248v1 by Erik Cambria, Lorenzo Malandri, Fabio Mercorio, Navid Nobani, Andrea Seveso

In this survey, we address the key challenges in Large Language Models (LLM)
research, focusing on the importance of interpretability. Driven by increasing
interest from AI and business sectors, we highlight the need for transparency
in LLMs. We examine the dual paths in current LLM research and eXplainable
Artificial Intelligence (XAI): enhancing performance through XAI and the
emerging focus on model interpretability. Our paper advocates for a balanced
approach that values interpretability equally with functional advancements.
Recognizing the rapid development in LLM research, our survey includes both
peer-reviewed and preprint (arXiv) papers, offering a comprehensive overview of
XAI's role in LLM research. We conclude by urging the research community to
advance both LLM and XAI fields together.

摘要：在這項調查中，我們探討大型語言模型 (LLM) 研究中的關鍵挑戰，重點關注可解釋性的重要性。在 AI 和商業領域日益增長的興趣驅動下，我們強調了 LLM 中透明度的必要性。我們審查了當前 LLM 研究和可解釋人工智慧 (XAI) 的雙重路徑：透過 XAI 提升效能，以及對模型可解釋性的新興關注。我們的論文主張採取一種平衡的方法，將可解釋性與功能進步同等重視。認識到 LLM 研究的快速發展，我們的調查包括同行評審和預印本 (arXiv) 論文，提供 XAI 在 LLM 研究中角色的全面概述。我們最後敦促研究社群共同推進 LLM 和 XAI 領域。

