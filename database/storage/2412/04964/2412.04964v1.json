{"2412.04964": {"publish_time": "2024-12-06", "title": "Flash Communication: Reducing Tensor Parallelization Bottleneck for Fast Large Language Model Inference", "paper_summary": "The ever-increasing sizes of large language models necessitate distributed\nsolutions for fast inference that exploit multi-dimensional parallelism, where\ncomputational loads are split across various accelerators such as GPU clusters.\nHowever, this approach often introduces significant communication overhead,\nespecially on devices with limited bandwidth. In this paper, we introduce\n\\emph{Flash Communication}, a novel low-bit compression technique designed to\nalleviate the tensor-parallelism communication bottleneck during inference. Our\nmethod substantially boosts intra-node communication speed by more than 3x and\nreduces the \\emph{time-to-first-token} by 2x, with nearly no sacrifice in model\naccuracy. Extensive experiments on various up-to-date LLMs demonstrate the\neffectiveness of our approach.", "paper_summary_zh": "\u96a8\u8457\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u898f\u6a21\u4e0d\u65b7\u64f4\u5927\uff0c\u9700\u8981\u5206\u6563\u5f0f\u89e3\u6c7a\u65b9\u6848\u4f86\u5feb\u901f\u63a8\u8ad6\uff0c\u4ee5\u5229\u7528\u591a\u7dad\u4e26\u884c\u6027\uff0c\u5176\u4e2d\u8a08\u7b97\u8ca0\u8f09\u6703\u5206\u6563\u5230\u5404\u7a2e\u52a0\u901f\u5668\uff08\u4f8b\u5982 GPU \u96c6\u7fa4\uff09\u4e0a\u3002\n\u4e0d\u904e\uff0c\u9019\u7a2e\u65b9\u6cd5\u901a\u5e38\u6703\u5f15\u5165\u5927\u91cf\u7684\u901a\u8a0a\u958b\u92b7\uff0c\u7279\u5225\u662f\u5728\u983b\u5bec\u53d7\u9650\u7684\u88dd\u7f6e\u4e0a\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86\u300c\u9583\u96fb\u901a\u8a0a\u300d\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684\u4f4e\u4f4d\u5143\u58d3\u7e2e\u6280\u8853\uff0c\u65e8\u5728\u7de9\u89e3\u63a8\u8ad6\u671f\u9593\u7684\u5f35\u91cf\u4e26\u884c\u901a\u8a0a\u74f6\u9838\u3002\u6211\u5011\u7684\u6280\u8853\u5927\u5e45\u63d0\u5347\u4e86\u7bc0\u9ede\u5167\u901a\u8a0a\u901f\u5ea6\uff0c\u8d85\u904e 3 \u500d\uff0c\u4e26\u5c07\u300c\u9996\u6b21\u6a19\u8a18\u6642\u9593\u300d\u7e2e\u77ed\u4e86 2 \u500d\uff0c\u5e7e\u4e4e\u6c92\u6709\u72a7\u7272\u6a21\u578b\u6e96\u78ba\u5ea6\u3002\u5728\u5404\u7a2e\u6700\u65b0\u7684 LLM \u4e0a\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u8b49\u660e\u4e86\u6211\u5011\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "author": "Qingyuan Li et.al.", "authors": "Qingyuan Li, Bo Zhang, Liang Ye, Yifan Zhang, Wei Wu, Yerui Sun, Lin Ma, Yuchen Xie", "id": "2412.04964v1", "paper_url": "http://arxiv.org/abs/2412.04964v1", "repo": "null"}}