{"2411.10004": {"publish_time": "2024-11-15", "title": "EyeDiff: text-to-image diffusion model improves rare eye disease diagnosis", "paper_summary": "The rising prevalence of vision-threatening retinal diseases poses a\nsignificant burden on the global healthcare systems. Deep learning (DL) offers\na promising solution for automatic disease screening but demands substantial\ndata. Collecting and labeling large volumes of ophthalmic images across various\nmodalities encounters several real-world challenges, especially for rare\ndiseases. Here, we introduce EyeDiff, a text-to-image model designed to\ngenerate multimodal ophthalmic images from natural language prompts and\nevaluate its applicability in diagnosing common and rare diseases. EyeDiff is\ntrained on eight large-scale datasets using the advanced latent diffusion\nmodel, covering 14 ophthalmic image modalities and over 80 ocular diseases, and\nis adapted to ten multi-country external datasets. The generated images\naccurately capture essential lesional characteristics, achieving high alignment\nwith text prompts as evaluated by objective metrics and human experts.\nFurthermore, integrating generated images significantly enhances the accuracy\nof detecting minority classes and rare eye diseases, surpassing traditional\noversampling methods in addressing data imbalance. EyeDiff effectively tackles\nthe issue of data imbalance and insufficiency typically encountered in rare\ndiseases and addresses the challenges of collecting large-scale annotated\nimages, offering a transformative solution to enhance the development of\nexpert-level diseases diagnosis models in ophthalmic field.", "paper_summary_zh": "\u96a8\u8457\u5a01\u8105\u8996\u529b\u7684\u8996\u7db2\u819c\u75be\u75c5\u76db\u884c\u7387\u4e0a\u5347\uff0c\u5c0d\u5168\u7403\u91ab\u7642\u4fdd\u5065\u7cfb\u7d71\u9020\u6210\u91cd\u5927\u8ca0\u64d4\u3002\u6df1\u5ea6\u5b78\u7fd2 (DL) \u70ba\u81ea\u52d5\u75be\u75c5\u7be9\u6aa2\u63d0\u4f9b\u4e86\u4e00\u500b\u6709\u5e0c\u671b\u7684\u89e3\u6c7a\u65b9\u6848\uff0c\u4f46\u9700\u8981\u5927\u91cf\u8cc7\u6599\u3002\u6536\u96c6\u548c\u6a19\u8a18\u5404\u7a2e\u6a21\u5f0f\u7684\u5927\u91cf\u773c\u79d1\u5f71\u50cf\u6703\u9047\u5230\u82e5\u5e72\u5be6\u969b\u6311\u6230\uff0c\u5c24\u5176\u662f\u7f55\u898b\u75be\u75c5\u3002\u5728\u6b64\uff0c\u6211\u5011\u4ecb\u7d39 EyeDiff\uff0c\u9019\u662f\u4e00\u500b\u6587\u5b57\u8f49\u5f71\u50cf\u6a21\u578b\uff0c\u65e8\u5728\u5f9e\u81ea\u7136\u8a9e\u8a00\u63d0\u793a\u4e2d\u751f\u6210\u591a\u6a21\u5f0f\u773c\u79d1\u5f71\u50cf\uff0c\u4e26\u8a55\u4f30\u5176\u5728\u8a3a\u65b7\u5e38\u898b\u548c\u7f55\u898b\u75be\u75c5\u4e2d\u7684\u9069\u7528\u6027\u3002EyeDiff \u4f7f\u7528\u5148\u9032\u7684\u6f5b\u5728\u64f4\u6563\u6a21\u578b\u5728\u516b\u500b\u5927\u578b\u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u8a13\u7df4\uff0c\u6db5\u84cb 14 \u7a2e\u773c\u79d1\u5f71\u50cf\u6a21\u5f0f\u548c\u8d85\u904e 80 \u7a2e\u773c\u90e8\u75be\u75c5\uff0c\u4e26\u9069\u61c9\u5341\u500b\u591a\u570b\u5916\u90e8\u8cc7\u6599\u96c6\u3002\u751f\u6210\u7684\u5f71\u50cf\u7cbe\u6e96\u6355\u6349\u5fc5\u8981\u7684\u75c5\u7076\u7279\u5fb5\uff0c\u8207\u7531\u5ba2\u89c0\u6307\u6a19\u548c\u4eba\u985e\u5c08\u5bb6\u8a55\u4f30\u7684\u6587\u5b57\u63d0\u793a\u9ad8\u5ea6\u4e00\u81f4\u3002\u6b64\u5916\uff0c\u6574\u5408\u751f\u6210\u7684\u5f71\u50cf\u986f\u8457\u589e\u5f37\u4e86\u5075\u6e2c\u5c11\u6578\u985e\u5225\u548c\u7f55\u898b\u773c\u75be\u7684\u6e96\u78ba\u6027\uff0c\u5728\u89e3\u6c7a\u8cc7\u6599\u4e0d\u5e73\u8861\u65b9\u9762\u8d85\u8d8a\u4e86\u50b3\u7d71\u7684\u904e\u5ea6\u62bd\u6a23\u65b9\u6cd5\u3002EyeDiff \u6709\u6548\u89e3\u6c7a\u4e86\u7f55\u898b\u75be\u75c5\u4e2d\u901a\u5e38\u9047\u5230\u7684\u8cc7\u6599\u4e0d\u5e73\u8861\u548c\u4e0d\u8db3\u554f\u984c\uff0c\u4e26\u89e3\u6c7a\u4e86\u6536\u96c6\u5927\u91cf\u6a19\u8a3b\u5f71\u50cf\u7684\u6311\u6230\uff0c\u63d0\u4f9b\u4e86\u4e00\u500b\u8b8a\u9769\u6027\u7684\u89e3\u6c7a\u65b9\u6848\uff0c\u4ee5\u589e\u5f37\u773c\u79d1\u9818\u57df\u5c08\u5bb6\u7d1a\u75be\u75c5\u8a3a\u65b7\u6a21\u578b\u7684\u958b\u767c\u3002", "author": "Ruoyu Chen et.al.", "authors": "Ruoyu Chen, Weiyi Zhang, Bowen Liu, Xiaolan Chen, Pusheng Xu, Shunming Liu, Mingguang He, Danli Shi", "id": "2411.10004v1", "paper_url": "http://arxiv.org/abs/2411.10004v1", "repo": "null"}}