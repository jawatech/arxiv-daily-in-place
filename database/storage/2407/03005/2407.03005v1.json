{"2407.03005": {"publish_time": "2024-07-03", "title": "Human-like Linguistic Biases in Neural Speech Models: Phonetic Categorization and Phonotactic Constraints in Wav2Vec2.0", "paper_summary": "What do deep neural speech models know about phonology? Existing work has\nexamined the encoding of individual linguistic units such as phonemes in these\nmodels. Here we investigate interactions between units. Inspired by classic\nexperiments on human speech perception, we study how Wav2Vec2 resolves\nphonotactic constraints. We synthesize sounds on an acoustic continuum between\n/l/ and /r/ and embed them in controlled contexts where only /l/, only /r/, or\nneither occur in English. Like humans, Wav2Vec2 models show a bias towards the\nphonotactically admissable category in processing such ambiguous sounds. Using\nsimple measures to analyze model internals on the level of individual stimuli,\nwe find that this bias emerges in early layers of the model's Transformer\nmodule. This effect is amplified by ASR finetuning but also present in fully\nself-supervised models. Our approach demonstrates how controlled stimulus\ndesigns can help localize specific linguistic knowledge in neural speech\nmodels.", "paper_summary_zh": "\u6df1\u5ea6\u795e\u7ecf\u8bed\u97f3\u6a21\u578b\u5c0d\u97f3\u97fb\u5b78\u4e86\u89e3\u591a\u5c11\uff1f\u73fe\u6709\u7684\u7814\u7a76\u6aa2\u8996\u4e86\u9019\u4e9b\u6a21\u578b\u4e2d\u500b\u5225\u8a9e\u8a00\u55ae\u4f4d\u7684\u7de8\u78bc\uff0c\u4f8b\u5982\u97f3\u7d20\u3002\u5728\u9019\u88e1\uff0c\u6211\u5011\u63a2\u8a0e\u55ae\u4f4d\u4e4b\u9593\u7684\u4ea4\u4e92\u4f5c\u7528\u3002\u53d7\u4eba\u985e\u8a9e\u97f3\u611f\u77e5\u7d93\u5178\u5be6\u9a57\u7684\u555f\u767c\uff0c\u6211\u5011\u7814\u7a76 Wav2Vec2 \u5982\u4f55\u89e3\u6c7a\u97f3\u4f4d\u7d04\u675f\u3002\u6211\u5011\u5728 /l/ \u548c /r/ \u4e4b\u9593\u7684\u8072\u5b78\u9023\u7e8c\u9ad4\u4e0a\u5408\u6210\u8072\u97f3\uff0c\u4e26\u5c07\u5b83\u5011\u5d4c\u5165\u53d7\u63a7\u7684\u8a9e\u5883\u4e2d\uff0c\u5176\u4e2d\u53ea\u6709 /l/\u3001\u53ea\u6709 /r/ \u6216\u5169\u8005\u90fd\u4e0d\u51fa\u73fe\u5728\u82f1\u8a9e\u4e2d\u3002\u8207\u4eba\u985e\u4e00\u6a23\uff0cWav2Vec2 \u6a21\u578b\u5728\u8655\u7406\u6b64\u985e\u6a21\u7a1c\u5169\u53ef\u7684\u8072\u97f3\u6642\u8868\u73fe\u51fa\u504f\u5411\u97f3\u4f4d\u5b78\u4e0a\u53ef\u63a5\u53d7\u985e\u5225\u7684\u50be\u5411\u3002\u4f7f\u7528\u7c21\u55ae\u7684\u6e2c\u91cf\u65b9\u6cd5\u4f86\u5206\u6790\u6a21\u578b\u5167\u90e8\u5728\u500b\u5225\u523a\u6fc0\u5c64\u7d1a\u4e0a\u7684\u60c5\u6cc1\uff0c\u6211\u5011\u767c\u73fe\u9019\u7a2e\u504f\u898b\u51fa\u73fe\u5728\u6a21\u578b Transformer \u6a21\u7d44\u7684\u65e9\u671f\u5c64\u7d1a\u3002\u9019\u7a2e\u6548\u61c9\u6703\u56e0 ASR \u5fae\u8abf\u800c\u653e\u5927\uff0c\u4f46\u4e5f\u5b58\u5728\u65bc\u5b8c\u5168\u81ea\u6211\u76e3\u7763\u7684\u6a21\u578b\u4e2d\u3002\u6211\u5011\u7684\u505a\u6cd5\u5c55\u793a\u4e86\u53d7\u63a7\u523a\u6fc0\u8a2d\u8a08\u5982\u4f55\u6709\u52a9\u65bc\u5b9a\u4f4d\u795e\u7d93\u8a9e\u97f3\u6a21\u578b\u4e2d\u7684\u7279\u5b9a\u8a9e\u8a00\u77e5\u8b58\u3002", "author": "Marianne de Heer Kloots et.al.", "authors": "Marianne de Heer Kloots, Willem Zuidema", "id": "2407.03005v1", "paper_url": "http://arxiv.org/abs/2407.03005v1", "repo": "https://github.com/mdhk/phonotactic-sensitivity"}}