{"2409.03161": {"publish_time": "2024-09-05", "title": "MaterialBENCH: Evaluating College-Level Materials Science Problem-Solving Abilities of Large Language Models", "paper_summary": "A college-level benchmark dataset for large language models (LLMs) in the\nmaterials science field, MaterialBENCH, is constructed. This dataset consists\nof problem-answer pairs, based on university textbooks. There are two types of\nproblems: one is the free-response answer type, and the other is the\nmultiple-choice type. Multiple-choice problems are constructed by adding three\nincorrect answers as choices to a correct answer, so that LLMs can choose one\nof the four as a response. Most of the problems for free-response answer and\nmultiple-choice types overlap except for the format of the answers. We also\nconduct experiments using the MaterialBENCH on LLMs, including ChatGPT-3.5,\nChatGPT-4, Bard (at the time of the experiments), and GPT-3.5 and GPT-4 with\nthe OpenAI API. The differences and similarities in the performance of LLMs\nmeasured by the MaterialBENCH are analyzed and discussed. Performance\ndifferences between the free-response type and multiple-choice type in the same\nmodels and the influence of using system massages on multiple-choice problems\nare also studied. We anticipate that MaterialBENCH will encourage further\ndevelopments of LLMs in reasoning abilities to solve more complicated problems\nand eventually contribute to materials research and discovery.", "paper_summary_zh": "<paragraph>\u91dd\u5c0d\u6750\u6599\u79d1\u5b78\u9818\u57df\u7684\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5efa\u69cb\u4e86\u5927\u5b78\u7b49\u7d1a\u7684\u57fa\u6e96\u8cc7\u6599\u96c6 MaterialBENCH\u3002\u6b64\u8cc7\u6599\u96c6\u5305\u542b\u57fa\u65bc\u5927\u5b78\u6559\u79d1\u66f8\u7684\u554f\u984c\u89e3\u7b54\u914d\u5c0d\u3002\u554f\u984c\u6709\u5169\u7a2e\uff1a\u4e00\u7a2e\u662f\u81ea\u7531\u56de\u7b54\u985e\u578b\uff0c\u53e6\u4e00\u7a2e\u662f\u591a\u9078\u984c\u985e\u578b\u3002\u591a\u9078\u984c\u554f\u984c\u662f\u900f\u904e\u5728\u6b63\u78ba\u7b54\u6848\u4e2d\u52a0\u5165\u4e09\u500b\u932f\u8aa4\u7b54\u6848\u4f5c\u70ba\u9078\u9805\u4f86\u5efa\u69cb\uff0c\u4ee5\u4fbf LLM \u80fd\u5f9e\u56db\u500b\u9078\u9805\u4e2d\u9078\u64c7\u4e00\u500b\u4f5c\u70ba\u56de\u61c9\u3002\u9664\u4e86\u7b54\u6848\u683c\u5f0f\u5916\uff0c\u81ea\u7531\u56de\u7b54\u985e\u578b\u548c\u591a\u9078\u984c\u985e\u578b\u7684\u5927\u90e8\u5206\u554f\u984c\u662f\u91cd\u758a\u7684\u3002\u6211\u5011\u9084\u4f7f\u7528 MaterialBENCH \u5c0d LLM \u9032\u884c\u5be6\u9a57\uff0c\u5305\u62ec ChatGPT-3.5\u3001ChatGPT-4\u3001Bard\uff08\u5728\u5be6\u9a57\u6642\uff09\u3001\u4ee5\u53ca\u4f7f\u7528 OpenAI API \u7684 GPT-3.5 \u548c GPT-4\u3002\u91dd\u5c0d MaterialBENCH \u6e2c\u91cf\u51fa\u7684 LLM \u6548\u80fd\u5dee\u7570\u548c\u76f8\u4f3c\u6027\u9032\u884c\u5206\u6790\u548c\u8a0e\u8ad6\u3002\u6211\u5011\u4e5f\u7814\u7a76\u4e86\u76f8\u540c\u6a21\u578b\u4e2d\u81ea\u7531\u56de\u7b54\u985e\u578b\u548c\u591a\u9078\u984c\u985e\u578b\u4e4b\u9593\u7684\u6548\u80fd\u5dee\u7570\uff0c\u4ee5\u53ca\u5728\u591a\u9078\u984c\u554f\u984c\u4e2d\u4f7f\u7528\u7cfb\u7d71\u8a0a\u606f\u7684\u5f71\u97ff\u3002\u6211\u5011\u9810\u671f MaterialBENCH \u5c07\u4fc3\u9032 LLM \u5728\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u9032\u4e00\u6b65\u767c\u5c55\uff0c\u4ee5\u89e3\u6c7a\u66f4\u8907\u96dc\u7684\u554f\u984c\uff0c\u4e26\u6700\u7d42\u6709\u52a9\u65bc\u6750\u6599\u7814\u7a76\u548c\u767c\u73fe\u3002</paragraph>", "author": "Michiko Yoshitake et.al.", "authors": "Michiko Yoshitake, Yuta Suzuki, Ryo Igarashi, Yoshitaka Ushiku, Keisuke Nagato", "id": "2409.03161v1", "paper_url": "http://arxiv.org/abs/2409.03161v1", "repo": "null"}}