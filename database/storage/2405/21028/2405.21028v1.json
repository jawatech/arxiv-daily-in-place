{"2405.21028": {"publish_time": "2024-05-31", "title": "LACIE: Listener-Aware Finetuning for Confidence Calibration in Large Language Models", "paper_summary": "When answering questions, LLMs can convey not only an answer, but a level of\nconfidence about the answer being correct. This includes explicit confidence\nmarkers (e.g. giving a numeric score) as well as implicit markers, like an\nauthoritative tone or elaborating with additional knowledge. For LLMs to be\ntrustworthy knowledge sources, the confidence they convey should match their\nactual expertise; however, most current models tend towards overconfidence. To\ncalibrate both implicit and explicit confidence markers, we introduce a\npragmatic, listener-aware finetuning method (LACIE) that models the listener,\nconsidering not only whether an answer is right, but whether it will be\naccepted by a listener. We cast calibration as preference optimization,\ncreating data via a two-agent game, where a speaker model's outputs are judged\nby a simulated listener. We then finetune three LLMs (Mistral-7B, Llama3-8B,\nLlama3-70B) with LACIE, and show that the resulting models are better\ncalibrated w.r.t. a simulated listener. Crucially, these trends transfer to\nhuman listeners, helping them correctly predict model correctness: we conduct a\nhuman evaluation where annotators accept or reject an LLM's answers, finding\nthat training with LACIE results in 47% fewer incorrect answers being accepted\nwhile maintaining the same level of acceptance for correct answers.\nFurthermore, LACIE generalizes to another dataset, resulting in a large\nincrease in truthfulness on TruthfulQA when trained on TriviaQA. Our analysis\nindicates that LACIE leads to a better confidence separation between correct\nand incorrect examples. Qualitatively, we find that a LACIE-trained model\nhedges more and implicitly signals certainty when it is correct by using an\nauthoritative tone or including details. Finally, LACIE finetuning leads to an\nemergent increase in model abstention (e.g. saying \"I don't know\") for answers\nthat are likely wrong.", "paper_summary_zh": "\u5728\u56de\u7b54\u554f\u984c\u6642\uff0cLLM \u4e0d\u50c5\u53ef\u4ee5\u50b3\u9054\u7b54\u6848\uff0c\u9084\u53ef\u4ee5\u50b3\u9054\u5c0d\u7b54\u6848\u6b63\u78ba\u6027\u7684\u4fe1\u5fc3\u7a0b\u5ea6\u3002\u9019\u5305\u62ec\u660e\u78ba\u7684\u4fe1\u5fc3\u6a19\u8a18\uff08\u4f8b\u5982\u7d66\u51fa\u6578\u5b57\u5206\u6578\uff09\u4ee5\u53ca\u96b1\u542b\u7684\u6a19\u8a18\uff0c\u4f8b\u5982\u6b0a\u5a01\u7684\u8a9e\u6c23\u6216\u7528\u984d\u5916\u7684\u77e5\u8b58\u9032\u884c\u95e1\u8ff0\u3002\u5c0d\u65bc LLM \u4f86\u8aaa\uff0c\u8981\u6210\u70ba\u503c\u5f97\u4fe1\u8cf4\u7684\u77e5\u8b58\u4f86\u6e90\uff0c\u5b83\u5011\u50b3\u9054\u7684\u4fe1\u5fc3\u61c9\u8207\u5b83\u5011\u7684\u5be6\u969b\u5c08\u696d\u77e5\u8b58\u76f8\u5339\u914d\uff1b\u7136\u800c\uff0c\u5927\u591a\u6578\u7576\u524d\u6a21\u578b\u90fd\u50be\u5411\u65bc\u904e\u5ea6\u81ea\u4fe1\u3002\u70ba\u4e86\u6821\u6e96\u96b1\u542b\u548c\u660e\u78ba\u7684\u4fe1\u5fc3\u6a19\u8a18\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u7a2e\u5be6\u7528\u7684\u3001\u8003\u616e\u807d\u773e\u7684\u5fae\u8abf\u65b9\u6cd5 (LACIE)\uff0c\u8a72\u65b9\u6cd5\u5c0d\u807d\u773e\u9032\u884c\u5efa\u6a21\uff0c\u4e0d\u50c5\u8003\u616e\u7b54\u6848\u662f\u5426\u6b63\u78ba\uff0c\u9084\u8003\u616e\u7b54\u6848\u662f\u5426\u6703\u88ab\u807d\u773e\u63a5\u53d7\u3002\u6211\u5011\u5c07\u6821\u6e96\u8996\u70ba\u504f\u597d\u512a\u5316\uff0c\u901a\u904e\u4e00\u5834\u96d9\u4eba\u904a\u6232\u5275\u5efa\u6578\u64da\uff0c\u5176\u4e2d\u8aaa\u8a71\u8005\u6a21\u578b\u7684\u8f38\u51fa\u7531\u6a21\u64ec\u807d\u773e\u4f86\u5224\u65b7\u3002\u7136\u5f8c\uff0c\u6211\u5011\u4f7f\u7528 LACIE \u5c0d\u4e09\u500b LLM\uff08Mistral-7B\u3001Llama3-8B\u3001Llama3-70B\uff09\u9032\u884c\u5fae\u8abf\uff0c\u4e26\u8868\u660e\u7531\u6b64\u7522\u751f\u7684\u6a21\u578b\u5728\u6a21\u64ec\u807d\u773e\u65b9\u9762\u6821\u6e96\u5f97\u66f4\u597d\u3002\u81f3\u95dc\u91cd\u8981\u7684\u662f\uff0c\u9019\u4e9b\u8da8\u52e2\u6703\u50b3\u905e\u7d66\u4eba\u985e\u807d\u773e\uff0c\u5e6b\u52a9\u4ed6\u5011\u6b63\u78ba\u9810\u6e2c\u6a21\u578b\u7684\u6b63\u78ba\u6027\uff1a\u6211\u5011\u9032\u884c\u4e86\u4e00\u9805\u4eba\u985e\u8a55\u4f30\uff0c\u5176\u4e2d\u8a3b\u91cb\u8005\u63a5\u53d7\u6216\u62d2\u7d55 LLM \u7684\u7b54\u6848\uff0c\u767c\u73fe\u4f7f\u7528 LACIE \u9032\u884c\u8a13\u7df4\u5c0e\u81f4\u63a5\u53d7\u7684\u932f\u8aa4\u7b54\u6848\u6e1b\u5c11\u4e86 47%\uff0c\u540c\u6642\u4fdd\u6301\u4e86\u5c0d\u6b63\u78ba\u7b54\u6848\u7684\u76f8\u540c\u63a5\u53d7\u7a0b\u5ea6\u3002\u6b64\u5916\uff0cLACIE \u53ef\u4ee5\u63a8\u5ee3\u5230\u53e6\u4e00\u500b\u6578\u64da\u96c6\uff0c\u5f9e\u800c\u5728 TruthfulQA \u4e0a\u8a13\u7df4\u6642\u5927\u5927\u63d0\u9ad8\u4e86\u771f\u5be6\u6027\u3002\u6211\u5011\u7684\u5206\u6790\u8868\u660e\uff0cLACIE \u5c0e\u81f4\u6b63\u78ba\u548c\u4e0d\u6b63\u78ba\u793a\u4f8b\u4e4b\u9593\u7684\u4fe1\u5fc3\u5206\u96e2\u66f4\u597d\u3002\u5f9e\u8cea\u91cf\u4e0a\u8b1b\uff0c\u6211\u5011\u767c\u73fe LACIE \u8a13\u7df4\u7684\u6a21\u578b\u6703\u66f4\u591a\u5730\u8ff4\u907f\uff0c\u4e26\u5728\u6b63\u78ba\u6642\u901a\u904e\u4f7f\u7528\u6b0a\u5a01\u7684\u8a9e\u6c23\u6216\u5305\u542b\u7d30\u7bc0\u4f86\u6697\u793a\u78ba\u5b9a\u6027\u3002\u6700\u5f8c\uff0cLACIE \u5fae\u8abf\u5c0e\u81f4\u6a21\u578b\u5c0d\u53ef\u80fd\u932f\u8aa4\u7684\u7b54\u6848\uff08\u4f8b\u5982\u8aaa\u300c\u6211\u4e0d\u77e5\u9053\u300d\uff09\u7684\u68c4\u6b0a\u51fa\u73fe\u4e86\u65b0\u7684\u589e\u52a0\u3002", "author": "Elias Stengel-Eskin et.al.", "authors": "Elias Stengel-Eskin, Peter Hase, Mohit Bansal", "id": "2405.21028v1", "paper_url": "http://arxiv.org/abs/2405.21028v1", "repo": "https://github.com/esteng/pragmatic_calibration"}}