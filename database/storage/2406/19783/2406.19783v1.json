{"2406.19783": {"publish_time": "2024-06-28", "title": "NLPerturbator: Studying the Robustness of Code LLMs to Natural Language Variations", "paper_summary": "Large language models (LLMs) achieve promising results in code generation\nbased on a given natural language description. They have been integrated into\nopen-source projects and commercial products to facilitate daily coding\nactivities. The natural language description in the prompt is crucial for LLMs\nto comprehend users' requirements. Prior studies uncover that LLMs are\nsensitive to the changes in the prompts, including slight changes that look\ninconspicuous. However, the natural language descriptions often vary in\nreal-world scenarios (e.g., different formats, grammar, and wording). Prior\nstudies on the robustness of LLMs are often based on random perturbations and\nsuch perturbations may not actually happen. In this paper, we conduct a\ncomprehensive study to investigate how are code LLMs robust to variations of\nnatural language description in real-world scenarios. We summarize 18\ncategories of perturbations of natural language and 3 combinations of\nco-occurred categories based on our literature review and an online survey with\npractitioners. We propose an automated framework, NLPerturbator, which can\nperform perturbations of each category given a set of prompts. Through a series\nof experiments on code generation using six code LLMs, we find that the\nperturbed prompts can decrease the performance of code generation by a\nconsiderable margin (e.g., up to 21.2%, and 4.8% to 6.1% on average). Our study\nhighlights the importance of enhancing the robustness of LLMs to real-world\nvariations in the prompts, as well as the essentiality of attentively\nconstructing the prompts.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u57fa\u65bc\u7d66\u5b9a\u7684\u81ea\u7136\u8a9e\u8a00\u63cf\u8ff0\u7684\u7a0b\u5f0f\u78bc\u751f\u6210\u4e2d\u53d6\u5f97\u4e86\u4ee4\u4eba\u6eff\u610f\u7684\u6210\u679c\u3002\u5b83\u5011\u5df2\u88ab\u6574\u5408\u5230\u958b\u6e90\u5c08\u6848\u548c\u5546\u696d\u7522\u54c1\u4e2d\uff0c\u4ee5\u4fc3\u9032\u65e5\u5e38\u7de8\u78bc\u6d3b\u52d5\u3002\u63d0\u793a\u4e2d\u7684\u81ea\u7136\u8a9e\u8a00\u63cf\u8ff0\u5c0d\u65bc LLM \u7406\u89e3\u4f7f\u7528\u8005\u7684\u9700\u6c42\u81f3\u95dc\u91cd\u8981\u3002\u5148\u524d\u7684\u7814\u7a76\u767c\u73fe\uff0cLLM \u5c0d\u63d0\u793a\u7684\u8b8a\u5316\u5f88\u654f\u611f\uff0c\u5305\u62ec\u770b\u8d77\u4f86\u4e0d\u986f\u773c\u7684\u7d30\u5fae\u8b8a\u5316\u3002\u7136\u800c\uff0c\u81ea\u7136\u8a9e\u8a00\u63cf\u8ff0\u5728\u5be6\u969b\u5834\u666f\u4e2d\u901a\u5e38\u6709\u6240\u4e0d\u540c\uff08\u4f8b\u5982\uff0c\u4e0d\u540c\u7684\u683c\u5f0f\u3001\u8a9e\u6cd5\u548c\u63aa\u8fad\uff09\u3002\u5148\u524d\u95dc\u65bc LLM \u7a69\u5065\u6027\u7684\u7814\u7a76\u901a\u5e38\u57fa\u65bc\u96a8\u6a5f\u64fe\u52d5\uff0c\u800c\u9019\u7a2e\u64fe\u52d5\u53ef\u80fd\u4e26\u672a\u5be6\u969b\u767c\u751f\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u9032\u884c\u4e86\u4e00\u9805\u5168\u9762\u7684\u7814\u7a76\uff0c\u4ee5\u8abf\u67e5\u5728\u5be6\u969b\u5834\u666f\u4e2d\uff0c\u7a0b\u5f0f\u78bc LLM \u5982\u4f55\u5c0d\u81ea\u7136\u8a9e\u8a00\u63cf\u8ff0\u7684\u8b8a\u5316\u4fdd\u6301\u7a69\u5065\u6027\u3002\u6211\u5011\u6839\u64da\u6587\u737b\u56de\u9867\u548c\u5f9e\u696d\u4eba\u54e1\u7684\u7dda\u4e0a\u8abf\u67e5\uff0c\u7e3d\u7d50\u4e86 18 \u985e\u81ea\u7136\u8a9e\u8a00\u64fe\u52d5\u548c 3 \u7a2e\u5171\u73fe\u985e\u5225\u7684\u7d44\u5408\u3002\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u81ea\u52d5\u5316\u6846\u67b6 NLPerturbator\uff0c\u5b83\u53ef\u4ee5\u5728\u7d66\u5b9a\u4e00\u7d44\u63d0\u793a\u7684\u60c5\u6cc1\u4e0b\u5c0d\u6bcf\u500b\u985e\u5225\u9032\u884c\u64fe\u52d5\u3002\u900f\u904e\u5c0d\u4f7f\u7528\u516d\u500b\u7a0b\u5f0f\u78bc LLM \u9032\u884c\u7a0b\u5f0f\u78bc\u751f\u6210\u7684\u7cfb\u5217\u5be6\u9a57\uff0c\u6211\u5011\u767c\u73fe\u64fe\u52d5\u7684\u63d0\u793a\u6703\u5728\u76f8\u7576\u5927\u7684\u7a0b\u5ea6\u4e0a\u4e0b\u964d\u7a0b\u5f0f\u78bc\u751f\u6210\u7684\u6548\u80fd\uff08\u4f8b\u5982\uff0c\u6700\u591a 21.2%\uff0c\u5e73\u5747 4.8% \u5230 6.1%\uff09\u3002\u6211\u5011\u7684\u7814\u7a76\u5f37\u8abf\u4e86\u589e\u5f37 LLM \u5c0d\u63d0\u793a\u4e2d\u5be6\u969b\u8b8a\u5316\u7684\u7a69\u5065\u6027\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u53ca\u4ed4\u7d30\u5efa\u69cb\u63d0\u793a\u7684\u5fc5\u8981\u6027\u3002", "author": "Junkai Chen et.al.", "authors": "Junkai Chen, Zhenhao Li, Xing Hu, Xin Xia", "id": "2406.19783v1", "paper_url": "http://arxiv.org/abs/2406.19783v1", "repo": "null"}}