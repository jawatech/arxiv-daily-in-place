{"2501.07108": {"publish_time": "2025-01-13", "title": "How GPT learns layer by layer", "paper_summary": "Large Language Models (LLMs) excel at tasks like language processing,\nstrategy games, and reasoning but struggle to build generalizable internal\nrepresentations essential for adaptive decision-making in agents. For agents to\neffectively navigate complex environments, they must construct reliable world\nmodels. While LLMs perform well on specific benchmarks, they often fail to\ngeneralize, leading to brittle representations that limit their real-world\neffectiveness. Understanding how LLMs build internal world models is key to\ndeveloping agents capable of consistent, adaptive behavior across tasks. We\nanalyze OthelloGPT, a GPT-based model trained on Othello gameplay, as a\ncontrolled testbed for studying representation learning. Despite being trained\nsolely on next-token prediction with random valid moves, OthelloGPT shows\nmeaningful layer-wise progression in understanding board state and gameplay.\nEarly layers capture static attributes like board edges, while deeper layers\nreflect dynamic tile changes. To interpret these representations, we compare\nSparse Autoencoders (SAEs) with linear probes, finding that SAEs offer more\nrobust, disentangled insights into compositional features, whereas linear\nprobes mainly detect features useful for classification. We use SAEs to decode\nfeatures related to tile color and tile stability, a previously unexamined\nfeature that reflects complex gameplay concepts like board control and\nlong-term planning. We study the progression of linear probe accuracy and tile\ncolor using both SAE's and linear probes to compare their effectiveness at\ncapturing what the model is learning. Although we begin with a smaller language\nmodel, OthelloGPT, this study establishes a framework for understanding the\ninternal representations learned by GPT models, transformers, and LLMs more\nbroadly. Our code is publicly available: https://github.com/ALT-JS/OthelloSAE.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u8a9e\u8a00\u8655\u7406\u3001\u7b56\u7565\u904a\u6232\u548c\u63a8\u7406\u7b49\u4efb\u52d9\u4e2d\u8868\u73fe\u51fa\u8272\uff0c\u4f46\u96e3\u4ee5\u5efa\u7acb\u53ef\u9069\u61c9\u4ee3\u7406\u6c7a\u7b56\u5236\u5b9a\u4e2d\u4e0d\u53ef\u6216\u7f3a\u7684\u6982\u62ec\u6027\u5167\u90e8\u8868\u5fb5\u3002\u4ee3\u7406\u8981\u6709\u6548\u5730\u61c9\u5c0d\u8907\u96dc\u7684\u74b0\u5883\uff0c\u4ed6\u5011\u5fc5\u9808\u5efa\u69cb\u53ef\u9760\u7684\u4e16\u754c\u6a21\u578b\u3002\u96d6\u7136 LLM \u5728\u7279\u5b9a\u57fa\u6e96\u4e0a\u8868\u73fe\u826f\u597d\uff0c\u4f46\u5b83\u5011\u5e38\u5e38\u7121\u6cd5\u6982\u62ec\uff0c\u5c0e\u81f4\u8106\u5f31\u7684\u8868\u5fb5\uff0c\u9650\u5236\u4e86\u5b83\u5011\u5728\u73fe\u5be6\u4e16\u754c\u4e2d\u7684\u6709\u6548\u6027\u3002\u4e86\u89e3 LLM \u5982\u4f55\u5efa\u69cb\u5167\u90e8\u4e16\u754c\u6a21\u578b\u662f\u958b\u767c\u5728\u5404\u9805\u4efb\u52d9\u4e2d\u5177\u6709\u4e00\u81f4\u3001\u9069\u61c9\u6027\u884c\u70ba\u7684\u4ee3\u7406\u7684\u95dc\u9375\u3002\u6211\u5011\u5206\u6790\u4e86 OthelloGPT\uff0c\u4e00\u500b\u57fa\u65bc GPT \u7684\u6a21\u578b\uff0c\u5b83\u63a5\u53d7\u5967\u8cfd\u7f85\u904a\u6232\u8a13\u7df4\uff0c\u4f5c\u70ba\u7814\u7a76\u8868\u5fb5\u5b78\u7fd2\u7684\u53d7\u63a7\u6e2c\u8a66\u5e73\u53f0\u3002\u5118\u7ba1\u50c5\u63a5\u53d7\u96a8\u6a5f\u6709\u6548\u79fb\u52d5\u7684\u4e0b\u4e00\u4ee3\u9810\u6e2c\u8a13\u7df4\uff0cOthelloGPT \u4ecd\u986f\u793a\u51fa\u5728\u7406\u89e3\u68cb\u76e4\u72c0\u614b\u548c\u904a\u6232\u73a9\u6cd5\u65b9\u9762\u6709\u610f\u7fa9\u7684\u9010\u5c64\u9032\u5c55\u3002\u65e9\u671f\u5c64\u6b21\u6355\u6349\u975c\u614b\u5c6c\u6027\uff0c\u5982\u68cb\u76e4\u908a\u7de3\uff0c\u800c\u8f03\u6df1\u5c64\u6b21\u5247\u53cd\u6620\u52d5\u614b\u5716\u584a\u8b8a\u5316\u3002\u70ba\u4e86\u8a6e\u91cb\u9019\u4e9b\u8868\u5fb5\uff0c\u6211\u5011\u5c07\u7a00\u758f\u81ea\u52d5\u7de8\u78bc\u5668 (SAE) \u8207\u7dda\u6027\u63a2\u6e2c\u9032\u884c\u6bd4\u8f03\uff0c\u767c\u73fe SAE \u63d0\u4f9b\u4e86\u5c0d\u7d44\u6210\u7279\u5fb5\u66f4\u5f37\u5065\u3001\u66f4\u89e3\u958b\u7684\u898b\u89e3\uff0c\u800c\u7dda\u6027\u63a2\u6e2c\u4e3b\u8981\u6aa2\u6e2c\u5c0d\u5206\u985e\u6709\u7528\u7684\u7279\u5fb5\u3002\u6211\u5011\u4f7f\u7528 SAE \u4f86\u89e3\u78bc\u8207\u5716\u584a\u984f\u8272\u548c\u5716\u584a\u7a69\u5b9a\u6027\u76f8\u95dc\u7684\u7279\u5fb5\uff0c\u9019\u662f\u4e00\u500b\u4ee5\u524d\u672a\u7d93\u6aa2\u9a57\u7684\u7279\u5fb5\uff0c\u5b83\u53cd\u6620\u4e86\u8907\u96dc\u7684\u904a\u6232\u6982\u5ff5\uff0c\u5982\u68cb\u76e4\u63a7\u5236\u548c\u9577\u671f\u898f\u5283\u3002\u6211\u5011\u4f7f\u7528 SAE \u548c\u7dda\u6027\u63a2\u6e2c\u7814\u7a76\u7dda\u6027\u63a2\u6e2c\u6e96\u78ba\u5ea6\u548c\u5716\u584a\u984f\u8272\u7684\u9032\u5c55\uff0c\u4ee5\u6bd4\u8f03\u5b83\u5011\u5728\u6355\u6349\u6a21\u578b\u5b78\u7fd2\u5167\u5bb9\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u96d6\u7136\u6211\u5011\u5f9e\u8f03\u5c0f\u7684\u8a9e\u8a00\u6a21\u578b OthelloGPT \u958b\u59cb\uff0c\u4f46\u9019\u9805\u7814\u7a76\u70ba\u7406\u89e3 GPT \u6a21\u578b\u3001Transformer\u548c LLM \u66f4\u5ee3\u6cdb\u5b78\u7fd2\u7684\u5167\u90e8\u8868\u5fb5\u5efa\u7acb\u4e86\u4e00\u500b\u6846\u67b6\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u516c\u958b\u53ef\u7528\uff1ahttps://github.com/ALT-JS/OthelloSAE\u3002", "author": "Jason Du et.al.", "authors": "Jason Du, Kelly Hong, Alishba Imran, Erfan Jahanparast, Mehdi Khfifi, Kaichun Qiao", "id": "2501.07108v1", "paper_url": "http://arxiv.org/abs/2501.07108v1", "repo": "https://github.com/alt-js/othellosae"}}