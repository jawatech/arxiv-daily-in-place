{"2411.04987": {"publish_time": "2024-11-07", "title": "Few-Shot Task Learning through Inverse Generative Modeling", "paper_summary": "Learning the intents of an agent, defined by its goals or motion style, is\noften extremely challenging from just a few examples. We refer to this problem\nas task concept learning and present our approach, Few-Shot Task Learning\nthrough Inverse Generative Modeling (FTL-IGM), which learns new task concepts\nby leveraging invertible neural generative models. The core idea is to pretrain\na generative model on a set of basic concepts and their demonstrations. Then,\ngiven a few demonstrations of a new concept (such as a new goal or a new\naction), our method learns the underlying concepts through backpropagation\nwithout updating the model weights, thanks to the invertibility of the\ngenerative model. We evaluate our method in five domains -- object\nrearrangement, goal-oriented navigation, motion caption of human actions,\nautonomous driving, and real-world table-top manipulation. Our experimental\nresults demonstrate that via the pretrained generative model, we successfully\nlearn novel concepts and generate agent plans or motion corresponding to these\nconcepts in (1) unseen environments and (2) in composition with training\nconcepts.", "paper_summary_zh": "\u900f\u904e\u5176\u76ee\u6a19\u6216\u52d5\u4f5c\u98a8\u683c\u5b9a\u7fa9\u7684\u4ee3\u7406\u610f\u5716\u5b78\u7fd2\uff0c\u901a\u5e38\u50c5\u5f9e\u5e7e\u500b\u7bc4\u4f8b\u4e2d\u5b78\u7fd2\u6975\u5177\u6311\u6230\u6027\u3002\u6211\u5011\u5c07\u6b64\u554f\u984c\u7a31\u70ba\u4efb\u52d9\u6982\u5ff5\u5b78\u7fd2\uff0c\u4e26\u63d0\u51fa\u6211\u5011\u7684\u505a\u6cd5\uff0c\u900f\u904e\u53cd\u5411\u751f\u6210\u5f0f\u5efa\u6a21\uff08FTL-IGM\uff09\u9032\u884c\u5c11\u91cf\u4efb\u52d9\u5b78\u7fd2\uff0c\u900f\u904e\u5229\u7528\u53ef\u9006\u795e\u7d93\u751f\u6210\u5f0f\u6a21\u578b\u4f86\u5b78\u7fd2\u65b0\u7684\u4efb\u52d9\u6982\u5ff5\u3002\u6838\u5fc3\u6982\u5ff5\u662f\u5728\u4e00\u7d44\u57fa\u672c\u6982\u5ff5\u53ca\u5176\u793a\u7bc4\u4e0a\u9810\u8a13\u7df4\u751f\u6210\u5f0f\u6a21\u578b\u3002\u7136\u5f8c\uff0c\u7d66\u5b9a\u65b0\u6982\u5ff5\u7684\u5e7e\u500b\u793a\u7bc4\uff08\u4f8b\u5982\u65b0\u76ee\u6a19\u6216\u65b0\u52d5\u4f5c\uff09\uff0c\u6211\u5011\u7684\u6a21\u578b\u900f\u904e\u53cd\u5411\u50b3\u64ad\u5b78\u7fd2\u57fa\u790e\u6982\u5ff5\uff0c\u800c\u7121\u9700\u66f4\u65b0\u6a21\u578b\u6b0a\u91cd\uff0c\u9019\u8981\u6b78\u529f\u65bc\u751f\u6210\u5f0f\u6a21\u578b\u7684\u53ef\u9006\u6027\u3002\u6211\u5011\u5728\u4e94\u500b\u9818\u57df\u8a55\u4f30\u6211\u5011\u7684\u6a21\u578b\u2014\u2014\u7269\u9ad4\u91cd\u65b0\u6392\u5217\u3001\u76ee\u6a19\u5c0e\u5411\u5c0e\u822a\u3001\u4eba\u985e\u52d5\u4f5c\u7684\u52d5\u4f5c\u6a19\u984c\u3001\u81ea\u52d5\u99d5\u99db\u548c\u73fe\u5be6\u4e16\u754c\u7684\u684c\u9762\u64cd\u4f5c\u3002\u6211\u5011\u7684\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u900f\u904e\u9810\u8a13\u7df4\u7684\u751f\u6210\u5f0f\u6a21\u578b\uff0c\u6211\u5011\u6210\u529f\u5b78\u7fd2\u65b0\u6982\u5ff5\u4e26\u7522\u751f\u8207\u9019\u4e9b\u6982\u5ff5\u76f8\u61c9\u7684\u4ee3\u7406\u8a08\u756b\u6216\u52d5\u4f5c\uff0c\u5728\uff081\uff09\u672a\u898b\u904e\u7684\u74b0\u5883\u4e2d\uff0c\u4ee5\u53ca\uff082\uff09\u8207\u8a13\u7df4\u6982\u5ff5\u7684\u7d44\u5408\u4e2d\u3002", "author": "Aviv Netanyahu et.al.", "authors": "Aviv Netanyahu, Yilun Du, Antonia Bronars, Jyothish Pari, Joshua Tenenbaum, Tianmin Shu, Pulkit Agrawal", "id": "2411.04987v1", "paper_url": "http://arxiv.org/abs/2411.04987v1", "repo": "null"}}