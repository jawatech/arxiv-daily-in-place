{"2405.19290": {"publish_time": "2024-05-29", "title": "Integrating Multi-scale Contextualized Information for Byte-based Neural Machine Translation", "paper_summary": "Subword tokenization is a common method for vocabulary building in Neural\nMachine Translation (NMT) models. However, increasingly complex tasks have\nrevealed its disadvantages. First, a vocabulary cannot be modified once it is\nlearned, making it hard to adapt to new words. Second, in multilingual\ntranslation, the imbalance in data volumes across different languages spreads\nto the vocabulary, exacerbating translations involving low-resource languages.\nWhile byte-based tokenization addresses these issues, byte-based models\nstruggle with the low information density inherent in UTF-8 byte sequences.\nPrevious works enhance token semantics through local contextualization but fail\nto select an appropriate contextualizing scope based on the input.\nConsequently, we propose the Multi-Scale Contextualization (MSC) method, which\nlearns contextualized information of varying scales across different hidden\nstate dimensions. It then leverages the attention module to dynamically\nintegrate the multi-scale contextualized information. Experiments show that MSC\nsignificantly outperforms subword-based and other byte-based methods in both\nmultilingual and out-of-domain scenarios. Code can be found in\nhttps://github.com/ictnlp/Multiscale-Contextualization.", "paper_summary_zh": "\u6b21\u55ae\u5143\u8a5e\u5f59\u5316\u662f\u795e\u7d93\u6a5f\u5668\u7ffb\u8b6f (NMT) \u6a21\u578b\u4e2d\u5efa\u7acb\u8a5e\u5f59\u7684\u5e38\u898b\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u65e5\u76ca\u8907\u96dc\u7684\u4efb\u52d9\u63ed\u9732\u4e86\u5b83\u7684\u7f3a\u9ede\u3002\u9996\u5148\uff0c\u4e00\u65e6\u8a5e\u5f59\u88ab\u5b78\u7fd2\uff0c\u5b83\u5c31\u4e0d\u80fd\u88ab\u4fee\u6539\uff0c\u9019\u4f7f\u5f97\u5b83\u96e3\u4ee5\u9069\u61c9\u65b0\u8a5e\u5f59\u3002\u5176\u6b21\uff0c\u5728\u591a\u8a9e\u8a00\u7ffb\u8b6f\u4e2d\uff0c\u4e0d\u540c\u8a9e\u8a00\u4e4b\u9593\u7684\u8cc7\u6599\u91cf\u4e0d\u5e73\u8861\u6703\u64f4\u6563\u5230\u8a5e\u5f59\u4e2d\uff0c\u52a0\u5287\u6d89\u53ca\u4f4e\u8cc7\u6e90\u8a9e\u8a00\u7684\u7ffb\u8b6f\u3002\u96d6\u7136\u57fa\u65bc\u4f4d\u5143\u7d44\u7684\u8a5e\u5f59\u5316\u53ef\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u4f46\u57fa\u65bc\u4f4d\u5143\u7d44\u7684\u6a21\u578b\u96e3\u4ee5\u8655\u7406 UTF-8 \u4f4d\u5143\u7d44\u5e8f\u5217\u4e2d\u56fa\u6709\u7684\u4f4e\u8cc7\u8a0a\u5bc6\u5ea6\u3002\u5148\u524d\u7684\u4f5c\u54c1\u900f\u904e\u5c40\u90e8\u8108\u7d61\u5316\u4f86\u589e\u5f37\u8a5e\u5f59\u8a9e\u7fa9\uff0c\u4f46\u7121\u6cd5\u6839\u64da\u8f38\u5165\u9078\u64c7\u9069\u7576\u7684\u8108\u7d61\u5316\u7bc4\u570d\u3002\u56e0\u6b64\uff0c\u6211\u5011\u63d0\u51fa\u591a\u5c3a\u5ea6\u8108\u7d61\u5316 (MSC) \u65b9\u6cd5\uff0c\u5b83\u8de8\u4e0d\u540c\u96b1\u85cf\u72c0\u614b\u7dad\u5ea6\u5b78\u7fd2\u4e0d\u540c\u5c3a\u5ea6\u7684\u8108\u7d61\u5316\u8cc7\u8a0a\u3002\u7136\u5f8c\uff0c\u5b83\u5229\u7528\u6ce8\u610f\u529b\u6a21\u7d44\u52d5\u614b\u6574\u5408\u591a\u5c3a\u5ea6\u8108\u7d61\u5316\u8cc7\u8a0a\u3002\u5be6\u9a57\u8868\u660e\uff0cMSC \u5728\u591a\u8a9e\u8a00\u548c\u9818\u57df\u5916\u5834\u666f\u4e2d\u90fd\u660e\u986f\u512a\u65bc\u57fa\u65bc\u6b21\u55ae\u5143\u8a5e\u548c\u57fa\u65bc\u4f4d\u5143\u7d44\u7684\u5176\u4ed6\u65b9\u6cd5\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/ictnlp/Multiscale-Contextualization \u4e2d\u627e\u5230\u3002", "author": "Langlin Huang et.al.", "authors": "Langlin Huang, Yang Feng", "id": "2405.19290v1", "paper_url": "http://arxiv.org/abs/2405.19290v1", "repo": "https://github.com/ictnlp/multiscale-contextualization"}}