{"2408.15079": {"publish_time": "2024-08-27", "title": "BaichuanSEED: Sharing the Potential of ExtensivE Data Collection and Deduplication by Introducing a Competitive Large Language Model Baseline", "paper_summary": "The general capabilities of Large Language Models (LLM) highly rely on the\ncomposition and selection on extensive pretraining datasets, treated as\ncommercial secrets by several institutions. To mitigate this issue, we\nopen-source the details of a universally applicable data processing pipeline\nand validate its effectiveness and potential by introducing a competitive LLM\nbaseline. Specifically, the data processing pipeline consists of broad\ncollection to scale up and reweighting to improve quality. We then pretrain a\n7B model BaichuanSEED with 3T tokens processed by our pipeline without any\ndeliberate downstream task-related optimization, followed by an easy but\neffective supervised fine-tuning stage. BaichuanSEED demonstrates consistency\nand predictability throughout training and achieves comparable performance on\ncomprehensive benchmarks with several commercial advanced large language\nmodels, such as Qwen1.5 and Llama3. We also conduct several heuristic\nexperiments to discuss the potential for further optimization of downstream\ntasks, such as mathematics and coding.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u4e00\u822c\u529f\u80fd\u9ad8\u5ea6\u4f9d\u8cf4\u65bc\u5ee3\u6cdb\u9810\u8a13\u7df4\u6578\u64da\u96c6\u7684\u7d44\u6210\u548c\u9078\u64c7\uff0c\u800c\u9019\u4e9b\u6578\u64da\u96c6\u88ab\u591a\u5bb6\u6a5f\u69cb\u8996\u70ba\u5546\u696d\u6a5f\u5bc6\u3002\u70ba\u4e86\u6e1b\u8f15\u6b64\u554f\u984c\uff0c\u6211\u5011\u516c\u958b\u4e86\u666e\u904d\u9069\u7528\u7684\u8cc7\u6599\u8655\u7406\u7ba1\u7dda\u7684\u8a73\u7d30\u8cc7\u8a0a\uff0c\u4e26\u900f\u904e\u5f15\u5165\u6709\u7af6\u722d\u529b\u7684 LLM \u57fa\u6e96\u4f86\u9a57\u8b49\u5176\u6709\u6548\u6027\u548c\u6f5b\u529b\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u8cc7\u6599\u8655\u7406\u7ba1\u7dda\u5305\u62ec\u5ee3\u6cdb\u6536\u96c6\u4ee5\u64f4\u5927\u898f\u6a21\u548c\u91cd\u65b0\u52a0\u6b0a\u4ee5\u63d0\u9ad8\u54c1\u8cea\u3002\u7136\u5f8c\uff0c\u6211\u5011\u4f7f\u7528\u6211\u5011\u7684\u7ba1\u7dda\u8655\u7406\u7684 3T \u500b\u4ee3\u5e63\uff0c\u9810\u8a13\u7df4\u4e00\u500b 7B \u6a21\u578b BaichuanSEED\uff0c\u800c\u6c92\u6709\u4efb\u4f55\u6545\u610f\u7684\u4e0b\u6e38\u4efb\u52d9\u76f8\u95dc\u6700\u4f73\u5316\uff0c\u63a5\u8457\u662f\u4e00\u500b\u7c21\u55ae\u4f46\u6709\u6548\u7684\u76e3\u7763\u5fae\u8abf\u968e\u6bb5\u3002BaichuanSEED \u5728\u6574\u500b\u8a13\u7df4\u904e\u7a0b\u4e2d\u5c55\u73fe\u4e86\u4e00\u81f4\u6027\u548c\u53ef\u9810\u6e2c\u6027\uff0c\u4e26\u5728\u5168\u9762\u7684\u57fa\u6e96\u6e2c\u8a66\u4e2d\u9054\u5230\u4e86\u8207\u591a\u500b\u5546\u696d\u9032\u968e\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08\u4f8b\u5982 Qwen1.5 \u548c Llama3\uff09\u76f8\u7576\u7684\u6548\u80fd\u3002\u6211\u5011\u9084\u9032\u884c\u4e86\u591a\u9805\u555f\u767c\u5f0f\u5be6\u9a57\uff0c\u4ee5\u63a2\u8a0e\u9032\u4e00\u6b65\u6700\u4f73\u5316\u4e0b\u6e38\u4efb\u52d9\uff08\u4f8b\u5982\u6578\u5b78\u548c\u7de8\u78bc\uff09\u7684\u6f5b\u529b\u3002", "author": "Guosheng Dong et.al.", "authors": "Guosheng Dong, Da Pan, Yiding Sun, Shusen Zhang, Zheng Liang, Xin Wu, Yanjun Shen, Fan Yang, Haoze Sun, Tianpeng Li, Mingan Lin, Jianhua Xu, Yufan Zhang, Xiaonan Nie, Lei Su, Bingning Wang, Wentao Zhang, Jiaxin Mao, Zenan Zhou, Weipeng Chen", "id": "2408.15079v1", "paper_url": "http://arxiv.org/abs/2408.15079v1", "repo": "null"}}