{"2502.09390": {"publish_time": "2025-02-13", "title": "SQuARE: Sequential Question Answering Reasoning Engine for Enhanced Chain-of-Thought in Large Language Models", "paper_summary": "In the rapidly evolving field of Natural Language Processing, Large Language\nModels (LLMs) are tasked with increasingly complex reasoning challenges.\nTraditional methods like chain-of-thought prompting have shown promise but\noften fall short in fully leveraging a model's reasoning capabilities. This\npaper introduces SQuARE (Sequential Question Answering Reasoning Engine), a\nnovel prompting technique designed to improve reasoning through a\nself-interrogation paradigm. Building upon CoT frameworks, SQuARE prompts\nmodels to generate and resolve multiple auxiliary questions before tackling the\nmain query, promoting a more thorough exploration of various aspects of a\ntopic. Our expansive evaluations, conducted with Llama 3 and GPT-4o models\nacross multiple question-answering datasets, demonstrate that SQuARE\nsignificantly surpasses traditional CoT prompts and existing\nrephrase-and-respond methods. By systematically decomposing queries, SQuARE\nadvances LLM capabilities in reasoning tasks. The code is publicly available at\nhttps://github.com/IntelLabs/RAG-FiT/tree/square.", "paper_summary_zh": "\u5728\u5feb\u901f\u767c\u5c55\u7684\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u9818\u57df\u4e2d\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8ca0\u8cac\u8d8a\u4f86\u8d8a\u8907\u96dc\u7684\u63a8\u7406\u6311\u6230\u3002\n\u50b3\u7d71\u65b9\u6cd5\uff08\u5982\u601d\u8003\u93c8\u63d0\u793a\uff09\u5df2\u5c55\u73fe\u6f5b\u529b\uff0c\u4f46\u901a\u5e38\u7121\u6cd5\u5145\u5206\u5229\u7528\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002\u672c\u6587\u4ecb\u7d39 SQuARE\uff08\u9806\u5e8f\u5f0f\u554f\u7b54\u63a8\u7406\u5f15\u64ce\uff09\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u7a4e\u7684\u63d0\u793a\u6280\u8853\uff0c\u65e8\u5728\u900f\u904e\u81ea\u6211\u63d0\u554f\u6a21\u5f0f\u4f86\u6539\u5584\u63a8\u7406\u3002\u5efa\u7acb\u5728 CoT \u67b6\u69cb\u4e4b\u4e0a\uff0cSQuARE \u63d0\u793a\u6a21\u578b\u5728\u8655\u7406\u4e3b\u8981\u67e5\u8a62\u4e4b\u524d\u7522\u751f\u4e26\u89e3\u6c7a\u591a\u500b\u8f14\u52a9\u554f\u984c\uff0c\u4fc3\u9032\u5c0d\u67d0\u500b\u4e3b\u984c\u7684\u5404\u500b\u9762\u5411\u9032\u884c\u66f4\u5fb9\u5e95\u7684\u63a2\u8a0e\u3002\u6211\u5011\u4f7f\u7528 Llama 3 \u548c GPT-4o \u6a21\u578b\u5c0d\u591a\u500b\u554f\u7b54\u8cc7\u6599\u96c6\u9032\u884c\u5ee3\u6cdb\u8a55\u4f30\uff0c\u7d50\u679c\u986f\u793a SQuARE \u660e\u986f\u512a\u65bc\u50b3\u7d71 CoT \u63d0\u793a\u548c\u73fe\u6709\u7684\u6539\u5beb\u4e26\u56de\u61c9\u65b9\u6cd5\u3002\u900f\u904e\u7cfb\u7d71\u6027\u5730\u5206\u89e3\u67e5\u8a62\uff0cSQuARE \u63d0\u5347\u4e86 LLM \u5728\u63a8\u7406\u4efb\u52d9\u4e2d\u7684\u80fd\u529b\u3002\u7a0b\u5f0f\u78bc\u5df2\u516c\u958b\u65bc https://github.com/IntelLabs/RAG-FiT/tree/square\u3002", "author": "Daniel Fleischer et.al.", "authors": "Daniel Fleischer, Moshe Berchansky, Gad Markovits, Moshe Wasserblat", "id": "2502.09390v1", "paper_url": "http://arxiv.org/abs/2502.09390v1", "repo": "null"}}