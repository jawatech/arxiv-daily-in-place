{"2502.12799": {"publish_time": "2025-02-18", "title": "Towards Text-Image Interleaved Retrieval", "paper_summary": "Current multimodal information retrieval studies mainly focus on single-image\ninputs, which limits real-world applications involving multiple images and\ntext-image interleaved content. In this work, we introduce the text-image\ninterleaved retrieval (TIIR) task, where the query and document are interleaved\ntext-image sequences, and the model is required to understand the semantics\nfrom the interleaved context for effective retrieval. We construct a TIIR\nbenchmark based on naturally interleaved wikiHow tutorials, where a specific\npipeline is designed to generate interleaved queries. To explore the task, we\nadapt several off-the-shelf retrievers and build a dense baseline by\ninterleaved multimodal large language model (MLLM). We then propose a novel\nMatryoshka Multimodal Embedder (MME), which compresses the number of visual\ntokens at different granularity, to address the challenge of excessive visual\ntokens in MLLM-based TIIR models. Experiments demonstrate that simple adaption\nof existing models does not consistently yield effective results. Our MME\nachieves significant improvements over the baseline by substantially fewer\nvisual tokens. We provide extensive analysis and will release the dataset and\ncode to facilitate future research.", "paper_summary_zh": "\u76ee\u524d\u7684\u591a\u6a21\u614b\u8cc7\u8a0a\u6aa2\u7d22\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u55ae\u4e00\u5f71\u50cf\u8f38\u5165\uff0c\u9019\u9650\u5236\u4e86\u6d89\u53ca\u591a\u500b\u5f71\u50cf\u548c\u6587\u5b57\u5f71\u50cf\u4ea4\u932f\u5167\u5bb9\u7684\u5be6\u969b\u61c9\u7528\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86\u6587\u5b57\u5f71\u50cf\u4ea4\u932f\u6aa2\u7d22 (TIIR) \u4efb\u52d9\uff0c\u5176\u4e2d\u67e5\u8a62\u548c\u6587\u4ef6\u662f\u4ea4\u932f\u7684\u6587\u5b57\u5f71\u50cf\u5e8f\u5217\uff0c\u4e26\u4e14\u6a21\u578b\u9700\u8981\u7406\u89e3\u4ea4\u932f\u5167\u5bb9\u7684\u8a9e\u610f\u4ee5\u9032\u884c\u6709\u6548\u6aa2\u7d22\u3002\u6211\u5011\u6839\u64da\u81ea\u7136\u4ea4\u932f\u7684 wikiHow \u6559\u5b78\u8ab2\u7a0b\u5efa\u69cb\u4e86\u4e00\u500b TIIR \u57fa\u6e96\uff0c\u5176\u4e2d\u8a2d\u8a08\u4e86\u4e00\u500b\u7279\u5b9a\u7684\u7ba1\u7dda\u4f86\u7522\u751f\u4ea4\u932f\u67e5\u8a62\u3002\u70ba\u4e86\u63a2\u7d22\u9019\u500b\u4efb\u52d9\uff0c\u6211\u5011\u8abf\u6574\u4e86\u5e7e\u500b\u73fe\u6210\u7684\u6aa2\u7d22\u5668\uff0c\u4e26\u900f\u904e\u4ea4\u932f\u7684\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM) \u5efa\u7acb\u4e86\u4e00\u500b\u5bc6\u96c6\u7684\u57fa\u6e96\u3002\u7136\u5f8c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7a4e\u7684 Matryoshka \u591a\u6a21\u614b\u5d4c\u5165\u5668 (MME)\uff0c\u5b83\u58d3\u7e2e\u4e86\u4e0d\u540c\u7c92\u5ea6\u8996\u89ba\u7b26\u865f\u7684\u6578\u91cf\uff0c\u4ee5\u89e3\u6c7a\u57fa\u65bc MLLM \u7684 TIIR \u6a21\u578b\u4e2d\u904e\u591a\u8996\u89ba\u7b26\u865f\u7684\u6311\u6230\u3002\u5be6\u9a57\u8868\u660e\uff0c\u5c0d\u73fe\u6709\u6a21\u578b\u7684\u7c21\u55ae\u8abf\u6574\u4e26\u672a\u6301\u7e8c\u7522\u751f\u6709\u6548\u7d50\u679c\u3002\u6211\u5011\u7684 MME \u900f\u904e\u5927\u5e45\u6e1b\u5c11\u8996\u89ba\u7b26\u865f\uff0c\u9054\u5230\u4e86\u6bd4\u57fa\u6e96\u986f\u8457\u7684\u6539\u9032\u3002\u6211\u5011\u63d0\u4f9b\u4e86\u5ee3\u6cdb\u7684\u5206\u6790\uff0c\u4e26\u5c07\u91cb\u51fa\u8cc7\u6599\u96c6\u548c\u7a0b\u5f0f\u78bc\u4ee5\u4fc3\u9032\u672a\u4f86\u7684\u7814\u7a76\u3002", "author": "Xin Zhang et.al.", "authors": "Xin Zhang, Ziqi Dai, Yongqi Li, Yanzhao Zhang, Dingkun Long, Pengjun Xie, Meishan Zhang, Jun Yu, Wenjie Li, Min Zhang", "id": "2502.12799v1", "paper_url": "http://arxiv.org/abs/2502.12799v1", "repo": "null"}}