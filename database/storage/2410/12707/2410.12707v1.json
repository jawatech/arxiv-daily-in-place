{"2410.12707": {"publish_time": "2024-10-16", "title": "FusionLLM: A Decentralized LLM Training System on Geo-distributed GPUs with Adaptive Compression", "paper_summary": "To alleviate hardware scarcity in training large deep neural networks (DNNs),\nparticularly large language models (LLMs), we present FusionLLM, a\ndecentralized training system designed and implemented for training DNNs using\ngeo-distributed GPUs across different computing clusters or individual devices.\nDecentralized training faces significant challenges regarding system design and\nefficiency, including: 1) the need for remote automatic differentiation (RAD),\n2) support for flexible model definitions and heterogeneous software, 3)\nheterogeneous hardware leading to low resource utilization or the straggler\nproblem, and 4) slow network communication. To address these challenges, in the\nsystem design, we represent the model as a directed acyclic graph of operators\n(OP-DAG). Each node in the DAG represents the operator in the DNNs, while the\nedge represents the data dependency between operators. Based on this design, 1)\nusers are allowed to customize any DNN without caring low-level operator\nimplementation; 2) we enable the task scheduling with the more fine-grained\nsub-tasks, offering more optimization space; 3) a DAG runtime executor can\nimplement RAD withour requiring the consistent low-level ML framework versions.\n  To enhance system efficiency, we implement a workload estimator and design an\nOP-Fence scheduler to cluster devices with similar bandwidths together and\npartition the DAG to increase throughput. Additionally, we propose an AdaTopK\ncompressor to adaptively compress intermediate activations and gradients at the\nslowest communication links. To evaluate the convergence and efficiency of our\nsystem and algorithms, we train ResNet-101 and GPT-2 on three real-world\ntestbeds using 48 GPUs connected with 8 Mbps~10 Gbps networks. Experimental\nresults demonstrate that our system and method can achieve 1.45 - 9.39x speedup\ncompared to baseline methods while ensuring convergence.", "paper_summary_zh": "<paragraph>\u70ba\u4e86\u6e1b\u8f15\u8a13\u7df4\u5927\u578b\u6df1\u5ea6\u795e\u7d93\u7db2\u8def (DNN) \u7684\u786c\u9ad4\u77ed\u7f3a\u554f\u984c\uff0c\u5c24\u5176\u662f\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)\uff0c\u6211\u5011\u63d0\u51fa\u4e86 FusionLLM\uff0c\u4e00\u500b\u5206\u6563\u5f0f\u8a13\u7df4\u7cfb\u7d71\uff0c\u5176\u8a2d\u8a08\u548c\u5be6\u4f5c\u662f\u7528\u65bc\u8a13\u7df4\u8de8\u4e0d\u540c\u904b\u7b97\u53e2\u96c6\u6216\u500b\u5225\u88dd\u7f6e\u7684\u5730\u7406\u5206\u6563\u5f0f GPU \u7684 DNN\u3002\u5206\u6563\u5f0f\u8a13\u7df4\u5728\u7cfb\u7d71\u8a2d\u8a08\u548c\u6548\u7387\u65b9\u9762\u9762\u81e8\u91cd\u5927\u6311\u6230\uff0c\u5305\u62ec\uff1a1) \u9700\u8981\u9060\u7aef\u81ea\u52d5\u5fae\u5206 (RAD)\uff0c2) \u652f\u63f4\u5f48\u6027\u7684\u6a21\u578b\u5b9a\u7fa9\u548c\u7570\u8cea\u8edf\u9ad4\uff0c3) \u7570\u8cea\u786c\u9ad4\u5c0e\u81f4\u8cc7\u6e90\u5229\u7528\u7387\u4f4e\u6216\u843d\u5f8c\u554f\u984c\uff0c\u4ee5\u53ca 4) \u7db2\u8def\u901a\u8a0a\u901f\u5ea6\u6162\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u5728\u7cfb\u7d71\u8a2d\u8a08\u4e2d\uff0c\u6211\u5011\u5c07\u6a21\u578b\u8868\u793a\u70ba\u4e00\u500b\u6709\u5411\u975e\u5faa\u74b0\u5716 (OP-DAG) \u7684\u904b\u7b97\u5b50\u3002DAG \u4e2d\u7684\u6bcf\u500b\u7bc0\u9ede\u4ee3\u8868 DNN \u4e2d\u7684\u904b\u7b97\u5b50\uff0c\u800c\u908a\u7de3\u4ee3\u8868\u904b\u7b97\u5b50\u4e4b\u9593\u7684\u8cc7\u6599\u4f9d\u8cf4\u6027\u3002\u57fa\u65bc\u6b64\u8a2d\u8a08\uff0c1) \u4f7f\u7528\u8005\u53ef\u4ee5\u81ea\u8a02\u4efb\u4f55 DNN\uff0c\u800c\u4e0d\u7528\u8003\u616e\u4f4e\u968e\u904b\u7b97\u5b50\u5be6\u4f5c\uff1b2) \u6211\u5011\u555f\u7528\u4efb\u52d9\u6392\u7a0b\uff0c\u4e26\u4f7f\u7528\u66f4\u7d30\u7dfb\u7684\u5b50\u4efb\u52d9\uff0c\u63d0\u4f9b\u66f4\u591a\u6700\u4f73\u5316\u7a7a\u9593\uff1b3) DAG \u57f7\u884c\u6642\u9593\u57f7\u884c\u5668\u53ef\u4ee5\u5be6\u4f5c RAD\uff0c\u800c\u4e0d\u9700\u8981\u4e00\u81f4\u7684\u4f4e\u968e ML \u67b6\u69cb\u7248\u672c\u3002\u70ba\u4e86\u63d0\u5347\u7cfb\u7d71\u6548\u7387\uff0c\u6211\u5011\u5be6\u4f5c\u4e00\u500b\u5de5\u4f5c\u8ca0\u8f09\u4f30\u8a08\u5668\uff0c\u4e26\u8a2d\u8a08\u4e00\u500b OP-Fence \u6392\u7a0b\u5668\uff0c\u5c07\u983b\u5bec\u985e\u4f3c\u7684\u88dd\u7f6e\u5206\u7d44\u5728\u4e00\u8d77\uff0c\u4e26\u5206\u5272 DAG \u4ee5\u589e\u52a0\u8655\u7406\u91cf\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b AdaTopK \u58d3\u7e2e\u5668\uff0c\u4ee5\u81ea\u9069\u61c9\u65b9\u5f0f\u58d3\u7e2e\u6700\u6162\u901a\u8a0a\u9023\u7d50\u4e0a\u7684\u4e2d\u9593\u555f\u52d5\u548c\u68af\u5ea6\u3002\u70ba\u4e86\u8a55\u4f30\u6211\u5011\u7cfb\u7d71\u548c\u6f14\u7b97\u6cd5\u7684\u6536\u6582\u6027\u548c\u6548\u7387\uff0c\u6211\u5011\u5728\u4e09\u500b\u771f\u5be6\u4e16\u754c\u7684\u6e2c\u8a66\u5e73\u53f0\u4e0a\u8a13\u7df4 ResNet-101 \u548c GPT-2\uff0c\u4f7f\u7528 48 \u500b GPU \u9023\u63a5\u5230 8 Mbps~10 Gbps \u7db2\u8def\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u6211\u5011\u7684\u7cfb\u7d71\u548c\u65b9\u6cd5\u53ef\u4ee5\u6bd4\u57fa\u6e96\u65b9\u6cd5\u5feb 1.45 - 9.39 \u500d\uff0c\u540c\u6642\u78ba\u4fdd\u6536\u6582\u3002</paragraph>", "author": "Zhenheng Tang et.al.", "authors": "Zhenheng Tang, Xueze Kang, Yiming Yin, Xinglin Pan, Yuxin Wang, Xin He, Qiang Wang, Rongfei Zeng, Kaiyong Zhao, Shaohuai Shi, Amelie Chi Zhou, Bo Li, Bingsheng He, Xiaowen Chu", "id": "2410.12707v1", "paper_url": "http://arxiv.org/abs/2410.12707v1", "repo": "null"}}