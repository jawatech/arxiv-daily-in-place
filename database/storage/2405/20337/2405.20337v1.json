{"2405.20337": {"publish_time": "2024-05-30", "title": "OccSora: 4D Occupancy Generation Models as World Simulators for Autonomous Driving", "paper_summary": "Understanding the evolution of 3D scenes is important for effective\nautonomous driving. While conventional methods mode scene development with the\nmotion of individual instances, world models emerge as a generative framework\nto describe the general scene dynamics. However, most existing methods adopt an\nautoregressive framework to perform next-token prediction, which suffer from\ninefficiency in modeling long-term temporal evolutions. To address this, we\npropose a diffusion-based 4D occupancy generation model, OccSora, to simulate\nthe development of the 3D world for autonomous driving. We employ a 4D scene\ntokenizer to obtain compact discrete spatial-temporal representations for 4D\noccupancy input and achieve high-quality reconstruction for long-sequence\noccupancy videos. We then learn a diffusion transformer on the spatial-temporal\nrepresentations and generate 4D occupancy conditioned on a trajectory prompt.\nWe conduct extensive experiments on the widely used nuScenes dataset with Occ3D\noccupancy annotations. OccSora can generate 16s-videos with authentic 3D layout\nand temporal consistency, demonstrating its ability to understand the spatial\nand temporal distributions of driving scenes. With trajectory-aware 4D\ngeneration, OccSora has the potential to serve as a world simulator for the\ndecision-making of autonomous driving. Code is available at:\nhttps://github.com/wzzheng/OccSora.", "paper_summary_zh": "\u4e86\u89e3 3D \u5834\u666f\u7684\u6f14\u8b8a\u5c0d\u65bc\u6709\u6548\u81ea\u4e3b\u99d5\u99db\u975e\u5e38\u91cd\u8981\u3002\u96d6\u7136\u50b3\u7d71\u65b9\u6cd5\u4f7f\u7528\u500b\u5225\u5be6\u4f8b\u7684\u52d5\u4f5c\u5efa\u6a21\u5834\u666f\u958b\u767c\uff0c\u4f46\u4e16\u754c\u6a21\u578b\u4f5c\u70ba\u751f\u6210\u6846\u67b6\u51fa\u73fe\uff0c\u7528\u65bc\u63cf\u8ff0\u4e00\u822c\u5834\u666f\u52d5\u614b\u3002\u7136\u800c\uff0c\u5927\u591a\u6578\u73fe\u6709\u65b9\u6cd5\u63a1\u7528\u81ea\u8ff4\u6b78\u6846\u67b6\u4f86\u57f7\u884c\u4e0b\u4e00\u500b\u4ee3\u5e63\u9810\u6e2c\uff0c\u9019\u5728\u5efa\u6a21\u9577\u671f\u6642\u9593\u6f14\u8b8a\u65b9\u9762\u6548\u7387\u4f4e\u4e0b\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u57fa\u65bc\u64f4\u6563\u7684 4D \u4f54\u7528\u751f\u6210\u6a21\u578b OccSora\uff0c\u6a21\u64ec 3D \u4e16\u754c\u7684\u767c\u5c55\u4ee5\u9032\u884c\u81ea\u4e3b\u99d5\u99db\u3002\u6211\u5011\u4f7f\u7528 4D \u5834\u666f\u5206\u8a5e\u5668\u70ba 4D \u4f54\u7528\u8f38\u5165\u53d6\u5f97\u7dca\u6e4a\u96e2\u6563\u7684\u6642\u7a7a\u8868\u793a\uff0c\u4e26\u70ba\u9577\u5e8f\u5217\u4f54\u7528\u5f71\u7247\u5be6\u73fe\u9ad8\u54c1\u8cea\u91cd\u5efa\u3002\u7136\u5f8c\uff0c\u6211\u5011\u5728\u6642\u7a7a\u8868\u793a\u4e0a\u5b78\u7fd2\u64f4\u6563Transformer\uff0c\u4e26\u6839\u64da\u8ecc\u8de1\u63d0\u793a\u7522\u751f 4D \u4f54\u7528\u3002\u6211\u5011\u5728\u5ee3\u6cdb\u4f7f\u7528\u7684 nuScenes \u8cc7\u6599\u96c6\u4e0a\u4f7f\u7528 Occ3D \u4f54\u7528\u8a3b\u91cb\u9032\u884c\u5ee3\u6cdb\u7684\u5be6\u9a57\u3002OccSora \u53ef\u4ee5\u7522\u751f\u5177\u6709\u771f\u5be6 3D \u4f48\u5c40\u548c\u6642\u9593\u4e00\u81f4\u6027\u7684 16 \u79d2\u5f71\u7247\uff0c\u8b49\u660e\u5176\u7406\u89e3\u99d5\u99db\u5834\u666f\u6642\u7a7a\u5206\u4f48\u7684\u80fd\u529b\u3002\u900f\u904e\u8ecc\u8de1\u611f\u77e5 4D \u751f\u6210\uff0cOccSora \u6709\u53ef\u80fd\u4f5c\u70ba\u4e16\u754c\u6a21\u64ec\u5668\uff0c\u7528\u65bc\u81ea\u4e3b\u99d5\u99db\u7684\u6c7a\u7b56\u5236\u5b9a\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728\u4ee5\u4e0b\u4f4d\u7f6e\u53d6\u5f97\uff1a\nhttps://github.com/wzzheng/OccSora\u3002", "author": "Lening Wang et.al.", "authors": "Lening Wang, Wenzhao Zheng, Yilong Ren, Han Jiang, Zhiyong Cui, Haiyang Yu, Jiwen Lu", "id": "2405.20337v1", "paper_url": "http://arxiv.org/abs/2405.20337v1", "repo": "https://github.com/wzzheng/occsora"}}