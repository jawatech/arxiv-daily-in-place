{"2410.16770": {"publish_time": "2024-10-22", "title": "The Scene Language: Representing Scenes with Programs, Words, and Embeddings", "paper_summary": "We introduce the Scene Language, a visual scene representation that concisely\nand precisely describes the structure, semantics, and identity of visual\nscenes. It represents a scene with three key components: a program that\nspecifies the hierarchical and relational structure of entities in the scene,\nwords in natural language that summarize the semantic class of each entity, and\nembeddings that capture the visual identity of each entity. This representation\ncan be inferred from pre-trained language models via a training-free inference\ntechnique, given text or image inputs. The resulting scene can be rendered into\nimages using traditional, neural, or hybrid graphics renderers. Together, this\nforms a robust, automated system for high-quality 3D and 4D scene generation.\nCompared with existing representations like scene graphs, our proposed Scene\nLanguage generates complex scenes with higher fidelity, while explicitly\nmodeling the scene structures to enable precise control and editing.", "paper_summary_zh": "\u6211\u5011\u5f15\u5165\u4e86\u5834\u666f\u8a9e\u8a00\uff0c\u9019\u662f\u4e00\u7a2e\u8996\u89ba\u5834\u666f\u8868\u793a\u6cd5\uff0c\u7c21\u6f54\u4e14\u7cbe\u78ba\u5730\u63cf\u8ff0\u4e86\u8996\u89ba\u5834\u666f\u7684\u7d50\u69cb\u3001\u8a9e\u610f\u548c\u8eab\u5206\u3002\u5b83\u4f7f\u7528\u4e09\u500b\u95dc\u9375\u7d44\u6210\u90e8\u5206\u4f86\u8868\u793a\u5834\u666f\uff1a\u4e00\u500b\u7a0b\u5f0f\uff0c\u7528\u65bc\u6307\u5b9a\u5834\u666f\u4e2d\u5be6\u9ad4\u7684\u968e\u5c64\u548c\u95dc\u4fc2\u7d50\u69cb\uff1b\u4ee5\u81ea\u7136\u8a9e\u8a00\u8868\u793a\u7684\u8a5e\u5f59\uff0c\u7528\u65bc\u7e3d\u7d50\u6bcf\u500b\u5be6\u9ad4\u7684\u8a9e\u610f\u985e\u5225\uff1b\u4ee5\u53ca\u7528\u65bc\u64f7\u53d6\u6bcf\u500b\u5be6\u9ad4\u7684\u8996\u89ba\u8eab\u5206\u7684\u5d4c\u5165\u3002\u9019\u500b\u8868\u793a\u6cd5\u53ef\u4ee5\u900f\u904e\u7121\u8a13\u7df4\u63a8\u8ad6\u6280\u8853\u5f9e\u9810\u5148\u8a13\u7df4\u7684\u8a9e\u8a00\u6a21\u578b\u63a8\u8ad6\u51fa\u4f86\uff0c\u7d66\u5b9a\u6587\u5b57\u6216\u5f71\u50cf\u8f38\u5165\u3002\u7522\u751f\u7684\u5834\u666f\u53ef\u4ee5\u4f7f\u7528\u50b3\u7d71\u3001\u795e\u7d93\u6216\u6df7\u5408\u5716\u5f62\u6e32\u67d3\u5668\u6e32\u67d3\u6210\u5f71\u50cf\u3002\u7e3d\u800c\u8a00\u4e4b\uff0c\u9019\u5f62\u6210\u4e86\u4e00\u500b\u5f37\u5065\u7684\u81ea\u52d5\u5316\u7cfb\u7d71\uff0c\u7528\u65bc\u9ad8\u54c1\u8cea 3D \u548c 4D \u5834\u666f\u751f\u6210\u3002\u8207\u73fe\u6709\u7684\u8868\u793a\u6cd5\uff08\u4f8b\u5982\u5834\u666f\u5716\uff09\u76f8\u6bd4\uff0c\u6211\u5011\u63d0\u51fa\u7684\u5834\u666f\u8a9e\u8a00\u53ef\u4ee5\u751f\u6210\u5177\u6709\u66f4\u9ad8\u4fdd\u771f\u5ea6\u7684\u8907\u96dc\u5834\u666f\uff0c\u540c\u6642\u660e\u78ba\u5730\u5efa\u6a21\u5834\u666f\u7d50\u69cb\u4ee5\u5be6\u73fe\u7cbe\u78ba\u63a7\u5236\u548c\u7de8\u8f2f\u3002", "author": "Yunzhi Zhang et.al.", "authors": "Yunzhi Zhang, Zizhang Li, Matt Zhou, Shangzhe Wu, Jiajun Wu", "id": "2410.16770v1", "paper_url": "http://arxiv.org/abs/2410.16770v1", "repo": "null"}}