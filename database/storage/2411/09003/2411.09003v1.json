{"2411.09003": {"publish_time": "2024-11-13", "title": "Refusal in LLMs is an Affine Function", "paper_summary": "We propose affine concept editing (ACE) as an approach for steering language\nmodels' behavior by intervening directly in activations. We begin with an\naffine decomposition of model activation vectors and show that prior methods\nfor steering model behavior correspond to subsets of terms of this\ndecomposition. We then provide a derivation of ACE and test it on refusal using\nLlama 3 8B and Hermes Eagle RWKV v5. ACE ultimately combines affine subspace\nprojection and activation addition to reliably control the model's refusal\nresponses across prompt types. We evaluate the results using LLM-based scoring\non a collection of harmful and harmless prompts. Our experiments demonstrate\nthat ACE consistently achieves more precise control over model behavior and\ngeneralizes to models where directional ablation via affine subspace projection\nalone produces incoherent outputs. Code for reproducing our results is\navailable at https://github.com/EleutherAI/steering-llama3 .", "paper_summary_zh": "\u6211\u5011\u63d0\u51fa\u4eff\u5c04\u6982\u5ff5\u7de8\u8f2f (ACE)\uff0c\u4f5c\u70ba\u4e00\u7a2e\u900f\u904e\u76f4\u63a5\u4ecb\u5165\u6fc0\u52f5\u4f86\u5f15\u5c0e\u8a9e\u8a00\u6a21\u578b\u884c\u70ba\u7684\u65b9\u6cd5\u3002\u6211\u5011\u5f9e\u6a21\u578b\u6fc0\u52f5\u5411\u91cf\u7684\u4eff\u5c04\u5206\u89e3\u958b\u59cb\uff0c\u4e26\u986f\u793a\u51fa\u5f15\u5c0e\u6a21\u578b\u884c\u70ba\u7684\u5148\u524d\u65b9\u6cd5\u5c0d\u61c9\u65bc\u6b64\u5206\u89e3\u7684\u5b50\u96c6\u3002\u7136\u5f8c\uff0c\u6211\u5011\u63d0\u4f9b ACE \u7684\u63a8\u5c0e\uff0c\u4e26\u4f7f\u7528 Llama 3 8B \u548c Hermes Eagle RWKV v5 \u5c0d\u62d2\u7d55\u9032\u884c\u6e2c\u8a66\u3002ACE \u6700\u7d42\u7d50\u5408\u4eff\u5c04\u5b50\u7a7a\u9593\u6295\u5f71\u548c\u6fc0\u52f5\u52a0\u6cd5\uff0c\u4ee5\u53ef\u9760\u5730\u63a7\u5236\u6a21\u578b\u5728\u63d0\u793a\u985e\u578b\u4e2d\u7684\u62d2\u7d55\u56de\u61c9\u3002\u6211\u5011\u4f7f\u7528\u57fa\u65bc LLM \u7684\u8a55\u5206\u5c0d\u6709\u5bb3\u548c\u7121\u5bb3\u63d0\u793a\u7684\u96c6\u5408\u9032\u884c\u8a55\u4f30\u3002\u6211\u5011\u7684\u5be6\u9a57\u8868\u660e\uff0cACE \u6301\u7e8c\u5c0d\u6a21\u578b\u884c\u70ba\u5be6\u73fe\u66f4\u7cbe\u78ba\u7684\u63a7\u5236\uff0c\u4e26\u63a8\u5ee3\u5230\u50c5\u900f\u904e\u4eff\u5c04\u5b50\u7a7a\u9593\u6295\u5f71\u9032\u884c\u65b9\u5411\u6027\u6d88\u878d\u6703\u7522\u751f\u4e0d\u9023\u8cab\u8f38\u51fa\u7684\u6a21\u578b\u3002\u53ef\u7528\u65bc\u91cd\u73fe\u6211\u5011\u7d50\u679c\u7684\u7a0b\u5f0f\u78bc\u4f4d\u65bc https://github.com/EleutherAI/steering-llama3\u3002", "author": "Thomas Marshall et.al.", "authors": "Thomas Marshall, Adam Scherlis, Nora Belrose", "id": "2411.09003v1", "paper_url": "http://arxiv.org/abs/2411.09003v1", "repo": "https://github.com/eleutherai/steering-llama3"}}