{"2409.06635": {"publish_time": "2024-09-10", "title": "MoWE-Audio: Multitask AudioLLMs with Mixture of Weak Encoders", "paper_summary": "The rapid advancements in large language models (LLMs) have significantly\nenhanced natural language processing capabilities, facilitating the development\nof AudioLLMs that process and understand speech and audio inputs alongside\ntext. Existing AudioLLMs typically combine a pre-trained audio encoder with a\npre-trained LLM, which are subsequently finetuned on specific audio tasks.\nHowever, the pre-trained audio encoder has constrained capacity to capture\nfeatures for new tasks and datasets. To address this, we propose to incorporate\nmixtures of `weak' encoders (MoWE) into the AudioLLM framework. MoWE\nsupplements a base encoder with a pool of relatively light weight encoders,\nselectively activated based on the audio input to enhance feature extraction\nwithout significantly increasing model size. Our empirical results demonstrate\nthat MoWE effectively improves multi-task performance, broadening the\napplicability of AudioLLMs to more diverse audio tasks.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5feb\u901f\u9032\u5c55\u986f\u8457\u63d0\u5347\u4e86\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u80fd\u529b\uff0c\u4fc3\u8fdb\u4e86 AudioLLM \u7684\u767c\u5c55\uff0cAudioLLM \u80fd\u8655\u7406\u548c\u7406\u89e3\u8a9e\u97f3\u548c\u97f3\u8a0a\u8f38\u5165\u4ee5\u53ca\u6587\u5b57\u3002\u73fe\u6709\u7684 AudioLLM \u901a\u5e38\u5c07\u9810\u5148\u8a13\u7df4\u7684\u97f3\u8a0a\u7de8\u78bc\u5668\u8207\u9810\u5148\u8a13\u7df4\u7684 LLM \u7d50\u5408\uff0c\u7136\u5f8c\u91dd\u5c0d\u7279\u5b9a\u97f3\u8a0a\u4efb\u52d9\u9032\u884c\u5fae\u8abf\u3002\u7136\u800c\uff0c\u9810\u5148\u8a13\u7df4\u7684\u97f3\u8a0a\u7de8\u78bc\u5668\u5728\u64f7\u53d6\u65b0\u4efb\u52d9\u548c\u8cc7\u6599\u96c6\u7279\u5fb5\u7684\u80fd\u529b\u53d7\u5230\u9650\u5236\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u8b70\u5c07\u300c\u5f31\u300d\u7de8\u78bc\u5668\u6df7\u5408 (MoWE) \u7d0d\u5165 AudioLLM \u67b6\u69cb\u3002MoWE \u4f7f\u7528\u4e00\u7fa4\u76f8\u5c0d\u8f15\u91cf\u7684\u7de8\u78bc\u5668\u88dc\u5145\u57fa\u672c\u7de8\u78bc\u5668\uff0c\u6839\u64da\u97f3\u8a0a\u8f38\u5165\u6709\u9078\u64c7\u5730\u555f\u7528\uff0c\u4ee5\u589e\u5f37\u7279\u5fb5\u64f7\u53d6\uff0c\u800c\u4e0d\u6703\u986f\u8457\u589e\u52a0\u6a21\u578b\u5927\u5c0f\u3002\u6211\u5011\u7684\u5be6\u8b49\u7d50\u679c\u8b49\u660e\uff0cMoWE \u6709\u6548\u5730\u6539\u9032\u4e86\u591a\u4efb\u52d9\u6548\u80fd\uff0c\u64f4\u5927\u4e86 AudioLLM \u5728\u66f4\u591a\u5143\u97f3\u8a0a\u4efb\u52d9\u4e2d\u7684\u9069\u7528\u6027\u3002", "author": "Wenyu Zhang et.al.", "authors": "Wenyu Zhang, Shuo Sun, Bin Wang, Xunlong Zou, Zhuohan Liu, Yingxu He, Geyu Lin, Nancy F. Chen, Ai Ti Aw", "id": "2409.06635v1", "paper_url": "http://arxiv.org/abs/2409.06635v1", "repo": "null"}}