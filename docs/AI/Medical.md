
### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-20**|**Fine-Tuning a Local LLaMA-3 Large Language Model for Automated Privacy-Preserving Physician Letter Generation in Radiation Oncology**|Yihao Hou et.al.|[2408.10715v1](http://arxiv.org/abs/2408.10715v1)|null|
|**2024-08-20**|**NutrifyAI: An AI-Powered System for Real-Time Food Detection, Nutritional Analysis, and Personalized Meal Recommendations**|Michelle Han et.al.|[2408.10532v1](http://arxiv.org/abs/2408.10532v1)|null|
|**2024-08-19**|**Envisioning Possibilities and Challenges of AI for Personalized Cancer Care**|Elaine Kong et.al.|[2408.10108v1](http://arxiv.org/abs/2408.10108v1)|null|
|**2024-08-19**|**Personalizing Reinforcement Learning from Human Feedback with Variational Preference Learning**|Sriyash Poddar et.al.|[2408.10075v1](http://arxiv.org/abs/2408.10075v1)|null|
|**2024-08-19**|**MSDiagnosis: An EMR-based Dataset for Clinical Multi-Step Diagnosis**|Ruihui Hou et.al.|[2408.10039v1](http://arxiv.org/abs/2408.10039v1)|null|
|**2024-08-19**|**LCE: A Framework for Explainability of DNNs for Ultrasound Image Based on Concept Discovery**|Weiji Kong et.al.|[2408.09899v1](http://arxiv.org/abs/2408.09899v1)|null|
|**2024-08-19**|**Preoperative Rotator Cuff Tear Prediction from Shoulder Radiographs using a Convolutional Block Attention Module-Integrated Neural Network**|Chris Hyunchul Jo et.al.|[2408.09894v1](http://arxiv.org/abs/2408.09894v1)|null|
|**2024-08-19**|**New spectral imaging biomarkers for sepsis and mortality in intensive care**|Silvia Seidlitz et.al.|[2408.09873v1](http://arxiv.org/abs/2408.09873v1)|null|
|**2024-08-19**|**Enhanced Cascade Prostate Cancer Classifier in mp-MRI Utilizing Recall Feedback Adaptive Loss and Prior Knowledge-Based Feature Extraction**|Kun Luo et.al.|[2408.09746v1](http://arxiv.org/abs/2408.09746v1)|null|
|**2024-08-19**|**R2GenCSR: Retrieving Context Samples for Large Language Model based X-ray Medical Report Generation**|Xiao Wang et.al.|[2408.09743v1](http://arxiv.org/abs/2408.09743v1)|[link](https://github.com/event-ahu/medical_image_analysis)|
|**2024-08-19**|**HYDEN: Hyperbolic Density Representations for Medical Images and Reports**|Zhi Qiao et.al.|[2408.09715v2](http://arxiv.org/abs/2408.09715v2)|null|
|**2024-08-18**|**PA-LLaVA: A Large Language-Vision Assistant for Human Pathology Image Understanding**|Dawei Dai et.al.|[2408.09530v1](http://arxiv.org/abs/2408.09530v1)|[link](https://github.com/ddw2aigroup2cqupt/pa-llava)|
|**2024-08-18**|**MedMAP: Promoting Incomplete Multi-modal Brain Tumor Segmentation with Alignment**|Tianyi Liu et.al.|[2408.09465v1](http://arxiv.org/abs/2408.09465v1)|null|
|**2024-08-18**|**Deformation-aware GAN for Medical Image Synthesis with Substantially Misaligned Pairs**|Bowen Xin et.al.|[2408.09432v1](http://arxiv.org/abs/2408.09432v1)|null|
|**2024-08-18**|**$\mathbb{BEHR}$NOULLI: A Binary EHR Data-Oriented Medication Recommendation System**|Xihao Piao et.al.|[2408.09410v1](http://arxiv.org/abs/2408.09410v1)|[link](https://github.com/chenzrg/behrmecom)|
|**2024-08-18**|**Panorama Tomosynthesis from Head CBCT with Simulated Projection Geometry**|Anusree P. S. et.al.|[2408.09358v2](http://arxiv.org/abs/2408.09358v2)|null|
|**2024-08-17**|**FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models**|Xiaochen Wang et.al.|[2408.10276v1](http://arxiv.org/abs/2408.10276v1)|null|
|**2024-08-17**|**FEDMEKI: A Benchmark for Scaling Medical Foundation Models via Federated Knowledge Injection**|Jiaqi Wang et.al.|[2408.09227v1](http://arxiv.org/abs/2408.09227v1)|null|
|**2024-08-17**|**FedKBP: Federated dose prediction framework for knowledge-based planning in radiation therapy**|Jingyun Chen et.al.|[2408.10275v1](http://arxiv.org/abs/2408.10275v1)|null|
|**2024-08-17**|**AI Managed Emergency Documentation with a Pretrained Model**|David Menzies et.al.|[2408.09193v1](http://arxiv.org/abs/2408.09193v1)|null|
|**2024-08-17**|**Identifying Technical Debt and Its Types Across Diverse Software Projects Issues**|Karthik Shivashankar et.al.|[2408.09128v1](http://arxiv.org/abs/2408.09128v1)|null|
|**2024-08-17**|**Fragment-Masked Molecular Optimization**|Kun Li et.al.|[2408.09106v1](http://arxiv.org/abs/2408.09106v1)|null|
|**2024-08-16**|**Improving VTE Identification through Language Models from Radiology Reports: A Comparative Study of Mamba, Phi-3 Mini, and BERT**|Jamie Deng et.al.|[2408.09043v1](http://arxiv.org/abs/2408.09043v1)|null|
|**2024-08-16**|**A Disease-Specific Foundation Model Using Over 100K Fundus Images: Release and Validation for Abnormality and Multi-Disease Classification on Downstream Tasks**|Boa Jang et.al.|[2408.08790v1](http://arxiv.org/abs/2408.08790v1)|[link](https://github.com/Jang-Boa/Research-Foundation-Retina)|
|**2024-08-16**|**Beyond the Hype: A dispassionate look at vision-language models in medical scenario**|Yang Nan et.al.|[2408.08704v1](http://arxiv.org/abs/2408.08704v1)|null|
|**2024-08-16**|**TextCAVs: Debugging vision models using text**|Angus Nicolson et.al.|[2408.08652v1](http://arxiv.org/abs/2408.08652v1)|[link](https://github.com/angusnicolson/textcavs)|
|**2024-08-16**|**RealMedQA: A pilot biomedical question answering dataset containing realistic clinical questions**|Gregory Kell et.al.|[2408.08624v1](http://arxiv.org/abs/2408.08624v1)|null|
|**2024-08-16**|**Focus on Focus: Focus-oriented Representation Learning and Multi-view Cross-modal Alignment for Glioma Grading**|Li Pan et.al.|[2408.08527v1](http://arxiv.org/abs/2408.08527v1)|[link](https://github.com/peterlipan/fof)|
|**2024-08-16**|**Adversarial Contrastive Learning Based Physics-Informed Temporal Networks for Cuffless Blood Pressure Estimation**|Rui Wang et.al.|[2408.08488v1](http://arxiv.org/abs/2408.08488v1)|null|
|**2024-08-15**|**Efficient Data-Sketches and Fine-Tuning for Early Detection of Distributional Drift in Medical Imaging**|Yusen Wu et.al.|[2408.08456v1](http://arxiv.org/abs/2408.08456v1)|null|
|**2024-08-15**|**Predictive uncertainty estimation in deep learning for lung carcinoma classification in digital pathology under real dataset shifts**|Abdur R. Fayjie et.al.|[2408.08432v1](http://arxiv.org/abs/2408.08432v1)|null|
|**2024-08-15**|**Assessing and Enhancing Large Language Models in Rare Disease Question-answering**|Guanchu Wang et.al.|[2408.08422v1](http://arxiv.org/abs/2408.08422v1)|null|
|**2024-08-15**|**Decoding the human brain tissue response to radiofrequency excitation using a biophysical-model-free deep MRI on a chip framework**|Dinor Nagar et.al.|[2408.08376v2](http://arxiv.org/abs/2408.08376v2)|null|
|**2024-08-15**|**InVAErt networks for amortized inference and identifiability analysis of lumped parameter hemodynamic models**|Guoxiang Grayson Tong et.al.|[2408.08264v1](http://arxiv.org/abs/2408.08264v1)|[link](https://github.com/desreslab/invaert4cardio)|
|**2024-08-15**|**Your Turn: Real-World Turning Angle Estimation for Parkinson's Disease Severity Assessment**|Qiushuo Cheng et.al.|[2408.08182v1](http://arxiv.org/abs/2408.08182v1)|null|
|**2024-08-15**|**Navigating Data Scarcity using Foundation Models: A Benchmark of Few-Shot and Zero-Shot Learning Approaches in Medical Imaging**|Stefano Woerner et.al.|[2408.08058v1](http://arxiv.org/abs/2408.08058v1)|null|
|**2024-08-15**|**Adaptive User Journeys in Pharma E-Commerce with Reinforcement Learning: Insights from SwipeRx**|Ana Fernández del Río et.al.|[2408.08024v1](http://arxiv.org/abs/2408.08024v1)|null|
|**2024-08-15**|**LLaVA-Surg: Towards Multimodal Surgical Assistant via Structured Surgical Video Learning**|Jiajie Li et.al.|[2408.07981v1](http://arxiv.org/abs/2408.07981v1)|null|
|**2024-08-14**|**Enhancing Equitable Access to AI in Housing and Homelessness System of Care through Federated Learning**|Musa Taib et.al.|[2408.07845v1](http://arxiv.org/abs/2408.07845v1)|null|
|**2024-08-14**|**Deep Learning: a Heuristic Three-stage Mechanism for Grid Searches to Optimize the Future Risk Prediction of Breast Cancer Metastasis Using EHR-based Clinical Data**|Xia Jiang et.al.|[2408.07673v2](http://arxiv.org/abs/2408.07673v2)|null|
|**2024-08-14**|**Adaptive Behavioral AI: Reinforcement Learning to Enhance Pharmacy Services**|Ana Fernández del Río et.al.|[2408.07647v1](http://arxiv.org/abs/2408.07647v1)|null|
|**2024-08-14**|**Optimizing HIV Patient Engagement with Reinforcement Learning in Resource-Limited Settings**|África Periáñez et.al.|[2408.07629v1](http://arxiv.org/abs/2408.07629v1)|null|
|**2024-08-14**|**MetaSeg: MetaFormer-based Global Contexts-aware Network for Efficient Semantic Segmentation**|Beoungwoo Kang et.al.|[2408.07576v2](http://arxiv.org/abs/2408.07576v2)|[link](https://github.com/hyunwoo137/metaseg)|
|**2024-08-14**|**Multi-task Heterogeneous Graph Learning on Electronic Health Records**|Tsai Hor Chan et.al.|[2408.07569v1](http://arxiv.org/abs/2408.07569v1)|[link](https://github.com/hku-medai/mult-ehr)|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531v1](http://arxiv.org/abs/2408.07531v1)|null|
|**2024-08-14**|**Improving Global Parameter-sharing in Physically Heterogeneous Multi-agent Reinforcement Learning with Unified Action Space**|Xiaoyang Yu et.al.|[2408.07395v1](http://arxiv.org/abs/2408.07395v1)|null|
|**2024-08-14**|**The Complexity of Manipulation of k-Coalitional Games on Graphs**|Hodaya Barr et.al.|[2408.07368v1](http://arxiv.org/abs/2408.07368v1)|[link](https://github.com/hodayaBen/The-Complexity-of-Manipulation-of-k-Coalitional-Games-on-Graphs)|
|**2024-08-13**|**Contrastive Learning on Medical Intents for Sequential Prescription Recommendation**|Arya Hadizadeh Moghaddam et.al.|[2408.10259v1](http://arxiv.org/abs/2408.10259v1)|null|
|**2024-08-13**|**Model Counting in the Wild**|Arijit Shaw et.al.|[2408.07059v1](http://arxiv.org/abs/2408.07059v1)|null|
|**2024-08-13**|**KAN You See It? KANs and Sentinel for Effective and Explainable Crop Field Segmentation**|Daniele Rege Cambrin et.al.|[2408.07040v1](http://arxiv.org/abs/2408.07040v1)|[link](https://github.com/darthreca/crop-field-segmentation-ukan)|
|**2024-08-13**|**PathInsight: Instruction Tuning of Multimodal Datasets and Models for Intelligence Assisted Diagnosis in Histopathology**|Xiaomin Wu et.al.|[2408.07037v1](http://arxiv.org/abs/2408.07037v1)|null|
|**2024-08-13**|**Diagnosis extraction from unstructured Dutch echocardiogram reports using span- and document-level characteristic classification**|Bauke Arends et.al.|[2408.06930v2](http://arxiv.org/abs/2408.06930v2)|[link](https://github.com/umcu/echolabeler)|
|**2024-08-13**|**BMFT: Achieving Fairness via Bias-based Weight Masking Fine-tuning**|Yuyang Xue et.al.|[2408.06890v1](http://arxiv.org/abs/2408.06890v1)|null|
|**2024-08-12**|**Synthetic Patient-Physician Dialogue Generation from Clinical Notes Using LLM**|Trisha Das et.al.|[2408.06285v1](http://arxiv.org/abs/2408.06285v1)|null|
|**2024-08-12**|**Decentralized Health Intelligence Network (DHIN)**|Abraham Nash et.al.|[2408.06240v3](http://arxiv.org/abs/2408.06240v3)|null|
|**2024-08-12**|**ACCELERATION: Sequentially-scanning DECT Imaging Using High Temporal Resolution Image Reconstruction And Temporal Extrapolation**|Qiaoxin Li et.al.|[2408.06163v1](http://arxiv.org/abs/2408.06163v1)|null|
|**2024-08-12**|**Med42-v2: A Suite of Clinical LLMs**|Clément Christophe et.al.|[2408.06142v1](http://arxiv.org/abs/2408.06142v1)|null|
|**2024-08-11**|**Real-Time Drowsiness Detection Using Eye Aspect Ratio and Facial Landmark Detection**|Varun Shiva Krishna Rupani et.al.|[2408.05836v1](http://arxiv.org/abs/2408.05836v1)|null|
|**2024-08-11**|**TC-KANRecon: High-Quality and Accelerated MRI Reconstruction via Adaptive KAN Mechanisms and Intelligent Feature Scaling**|Ruiquan Ge et.al.|[2408.05705v1](http://arxiv.org/abs/2408.05705v1)|[link](https://github.com/lcbkmm/tc-kanrecon)|
|**2024-08-11**|**A Novel Momentum-Based Deep Learning Techniques for Medical Image Classification and Segmentation**|Koushik Biswas et.al.|[2408.05692v1](http://arxiv.org/abs/2408.05692v1)|null|
|**2024-08-10**|**Mitigating Metropolitan Carbon Emissions with Dynamic Eco-driving at Scale**|Vindula Jayawardana et.al.|[2408.05609v1](http://arxiv.org/abs/2408.05609v1)|null|
|**2024-08-09**|**Beyond the Eye: A Relational Model for Early Dementia Detection Using Retinal OCTA Images**|Shouyue Liu et.al.|[2408.05117v1](http://arxiv.org/abs/2408.05117v1)|null|
|**2024-08-09**|**RT-Surv: Improving Mortality Prediction After Radiotherapy with Large Language Model Structuring of Large-Scale Unstructured Electronic Health Records**|Sangjoon Park et.al.|[2408.05074v2](http://arxiv.org/abs/2408.05074v2)|null|
|**2024-08-09**|**CROCODILE: Causality aids RObustness via COntrastive DIsentangled LEarning**|Gianluca Carloni et.al.|[2408.04949v1](http://arxiv.org/abs/2408.04949v1)|[link](https://github.com/gianlucarloni/crocodile)|
|**2024-08-09**|**Unleashing Artificial Cognition: Integrating Multiple AI Systems**|Muntasir Adnan et.al.|[2408.04910v3](http://arxiv.org/abs/2408.04910v3)|[link](https://github.com/TheOpenSI/cognitive_AI_experiments)|
|**2024-08-09**|**Ensemble BERT: A student social network text sentiment classification model based on ensemble learning and BERT architecture**|Kai Jiang et.al.|[2408.04849v1](http://arxiv.org/abs/2408.04849v1)|null|
|**2024-08-08**|**Towards Synergistic Deep Learning Models for Volumetric Cirrhotic Liver Segmentation in MRIs**|Vandan Gorade et.al.|[2408.04491v1](http://arxiv.org/abs/2408.04491v1)|null|
|**2024-08-08**|**Advancing oncology with federated learning: transcending boundaries in breast, lung, and prostate cancer. A systematic review**|Anshu Ankolekar et.al.|[2408.05249v1](http://arxiv.org/abs/2408.05249v1)|null|
|**2024-08-08**|**Non-maximizing policies that fulfill multi-criterion aspirations in expectation**|Simon Dima et.al.|[2408.04385v1](http://arxiv.org/abs/2408.04385v1)|null|
|**2024-08-08**|**AI-Driven Chatbot for Intrusion Detection in Edge Networks: Enhancing Cybersecurity with Ethical User Consent**|Mugheez Asif et.al.|[2408.04281v1](http://arxiv.org/abs/2408.04281v1)|null|
|**2024-08-08**|**Dynamic Fog Computing for Enhanced LLM Execution in Medical Applications**|Philipp Zagar et.al.|[2408.04680v1](http://arxiv.org/abs/2408.04680v1)|null|
|**2024-08-08**|**Dynamic Hypergraph-Enhanced Prediction of Sequential Medical Visits**|Wangying Yang et.al.|[2408.07084v2](http://arxiv.org/abs/2408.07084v2)|null|
|**2024-08-08**|**The Data Addition Dilemma**|Judy Hanwen Shen et.al.|[2408.04154v1](http://arxiv.org/abs/2408.04154v1)|[link](https://github.com/the-chen-lab/data-addition-dilemma)|
|**2024-08-08**|**Enhancing Healthcare through Large Language Models: A Study on Medical Question Answering**|Haoran Yu et.al.|[2408.04138v1](http://arxiv.org/abs/2408.04138v1)|null|
|**2024-08-07**|**Can Rule-Based Insights Enhance LLMs for Radiology Report Classification? Introducing the RadPrompt Methodology**|Panagiotis Fytas et.al.|[2408.04121v1](http://arxiv.org/abs/2408.04121v1)|null|
|**2024-08-07**|**Handwritten Code Recognition for Pen-and-Paper CS Education**|Md Sazzad Islam et.al.|[2408.07220v1](http://arxiv.org/abs/2408.07220v1)|[link](https://github.com/mdoumbouya/codeocr)|
|**2024-08-07**|**Multimodal Gender Fairness in Depression Prediction: Insights on Data from the USA & China**|Joseph Cameron et.al.|[2408.04026v1](http://arxiv.org/abs/2408.04026v1)|null|
|**2024-08-07**|**Inter-Series Transformer: Attending to Products in Time Series Forecasting**|Rares Cristian et.al.|[2408.03872v1](http://arxiv.org/abs/2408.03872v1)|null|
|**2024-08-07**|**Anatomical Foundation Models for Brain MRIs**|Carlo Alberto Barbano et.al.|[2408.07079v1](http://arxiv.org/abs/2408.07079v1)|null|
|**2024-08-07**|**HiQuE: Hierarchical Question Embedding Network for Multimodal Depression Detection**|Juho Jung et.al.|[2408.03648v1](http://arxiv.org/abs/2408.03648v1)|[link](https://github.com/JuHo-Jung/HiQuE)|
|**2024-08-07**|**Improving the quality of Persian clinical text with a novel spelling correction system**|Seyed Mohammad Sadegh Dashti et.al.|[2408.03622v1](http://arxiv.org/abs/2408.03622v1)|null|
|**2024-08-06**|**Identifying treatment response subgroups in observational time-to-event data**|Vincent Jeanselme et.al.|[2408.03463v1](http://arxiv.org/abs/2408.03463v1)|[link](https://github.com/Jeanselme/CausalNeuralSurvivalClustering)|
|**2024-08-06**|**Combining Diverse Information for Coordinated Action: Stochastic Bandit Algorithms for Heterogeneous Agents**|Lucia Gordon et.al.|[2408.03405v1](http://arxiv.org/abs/2408.03405v1)|[link](https://github.com/lgordon99/heterogeneous-stochastic-bandits)|
|**2024-08-06**|**MLC-GCN: Multi-Level Generated Connectome Based GCN for AD Analysis**|Wenqi Zhu et.al.|[2408.03358v1](http://arxiv.org/abs/2408.03358v1)|null|
|**2024-08-06**|**Personalizing Federated Instrument Segmentation with Visual Trait Priors in Robotic Surgery**|Jialang Xu et.al.|[2408.03208v2](http://arxiv.org/abs/2408.03208v2)|null|
|**2024-08-06**|**The Use of Large Language Models (LLM) for Cyber Threat Intelligence (CTI) in Cybercrime Forums**|Vanessa Clairoux-Trepanier et.al.|[2408.03354v2](http://arxiv.org/abs/2408.03354v2)|null|
|**2024-08-06**|**VizECGNet: Visual ECG Image Network for Cardiovascular Diseases Classification with Multi-Modal Training and Knowledge Distillation**|Ju-Hyeon Nam et.al.|[2408.02888v1](http://arxiv.org/abs/2408.02888v1)|null|
|**2024-08-05**|**VisionUnite: A Vision-Language Foundation Model for Ophthalmology Enhanced with Clinical Knowledge**|Zihan Li et.al.|[2408.02865v1](http://arxiv.org/abs/2408.02865v1)|[link](https://github.com/HUANGLIZI/VisionUnite)|
|**2024-08-05**|**Multistain Pretraining for Slide Representation Learning in Pathology**|Guillaume Jaume et.al.|[2408.02859v1](http://arxiv.org/abs/2408.02859v1)|[link](https://github.com/mahmoodlab/madeleine)|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**A Review on Organ Deformation Modeling Approaches for Reliable Surgical Navigation using Augmented Reality**|Zheng Han et.al.|[2408.02713v1](http://arxiv.org/abs/2408.02713v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-08-05**|**Active Sensing of Knee Osteoarthritis Progression with Reinforcement Learning**|Khanh Nguyen et.al.|[2408.02349v2](http://arxiv.org/abs/2408.02349v2)|null|
|**2024-08-05**|**A Conceptual Framework for Ethical Evaluation of Machine Learning Systems**|Neha R. Gupta et.al.|[2408.10239v1](http://arxiv.org/abs/2408.10239v1)|null|
|**2024-08-04**|**MetaWearS: A Shortcut in Wearable Systems Lifecycle with Only a Few Shots**|Alireza Amirshahi et.al.|[2408.01988v1](http://arxiv.org/abs/2408.01988v1)|null|
|**2024-08-04**|**DiReCT: Diagnostic Reasoning for Clinical Notes via Large Language Models**|Bowen Wang et.al.|[2408.01933v2](http://arxiv.org/abs/2408.01933v2)|null|
|**2024-08-03**|**MALADE: Orchestration of LLM-powered Agents with Retrieval Augmented Generation for Pharmacovigilance**|Jihye Choi et.al.|[2408.01869v1](http://arxiv.org/abs/2408.01869v1)|[link](https://github.com/jihyechoi77/malade)|
|**2024-08-03**|**U-MedSAM: Uncertainty-aware MedSAM for Medical Image Segmentation**|Xin Wang et.al.|[2408.08881v1](http://arxiv.org/abs/2408.08881v1)|null|
|**2024-08-03**|**Building Trust in Mental Health Chatbots: Safety Metrics and LLM-Based Evaluation Tools**|Jung In Park et.al.|[2408.04650v1](http://arxiv.org/abs/2408.04650v1)|null|

#### Abstracts
##### **Fine-Tuning a Local LLaMA-3 Large Language Model for Automated Privacy-Preserving Physician Letter Generation in Radiation Oncology**
2408.10715v1 by Yihao Hou, Christoph Bert, Ahmed Gomaa, Godehard Lahmer, Daniel Hoefler, Thomas Weissmann, Raphaela Voigt, Philipp Schubert, Charlotte Schmitter, Alina Depardon, Sabine Semrau, Andreas Maier, Rainer Fietkau, Yixing Huang, Florian Putz

Generating physician letters is a time-consuming task in daily clinical
practice. This study investigates local fine-tuning of large language models
(LLMs), specifically LLaMA models, for physician letter generation in a
privacy-preserving manner within the field of radiation oncology. Our findings
demonstrate that base LLaMA models, without fine-tuning, are inadequate for
effectively generating physician letters. The QLoRA algorithm provides an
efficient method for local intra-institutional fine-tuning of LLMs with limited
computational resources (i.e., a single 48 GB GPU workstation within the
hospital). The fine-tuned LLM successfully learns radiation oncology-specific
information and generates physician letters in an institution-specific style.
ROUGE scores of the generated summary reports highlight the superiority of the
8B LLaMA-3 model over the 13B LLaMA-2 model. Further multidimensional physician
evaluations of 10 cases reveal that, although the fine-tuned LLaMA-3 model has
limited capacity to generate content beyond the provided input data, it
successfully generates salutations, diagnoses and treatment histories,
recommendations for further treatment, and planned schedules. Overall, clinical
benefit was rated highly by the clinical experts (average score of 3.44 on a
4-point scale). With careful physician review and correction, automated
LLM-based physician letter generation has significant practical value.

摘要：<paragraph>在日常臨床實務中，生成醫師信函是一項耗時的任務。本研究探討大型語言模型 (LLM) 的局部微調，特別是 LLaMA 模型，在放射腫瘤學領域中以隱私保護的方式生成醫師信函。我們的研究結果表明，基礎 LLaMA 模型在沒有微調的情況下，不足以有效生成醫師信函。QLoRA 演算法提供了一種有效的方法，可以在有限的運算資源（即醫院內單一 48 GB GPU 工作站）下，進行 LLM 的局部院內微調。微調後的 LLM 成功學習了放射腫瘤學的特定資訊，並以特定於機構的風格生成醫師信函。生成的摘要報告的 ROUGE 分數突顯了 8B LLaMA-3 模型優於 13B LLaMA-2 模型。進一步的多維醫師評估顯示，儘管微調後的 LLaMA-3 模型生成超出提供輸入資料的內容的能力有限，但它成功地生成了問候語、診斷和治療病史、進一步治療建議和計畫行程。整體而言，臨床專家對臨床效益的評分很高（在 4 分制中平均得分為 3.44）。透過仔細的醫師審查和更正，基於 LLM 的自動化醫師信函生成具有顯著的實用價值。</paragraph>

##### **NutrifyAI: An AI-Powered System for Real-Time Food Detection, Nutritional Analysis, and Personalized Meal Recommendations**
2408.10532v1 by Michelle Han, Junyao Chen

With diet and nutrition apps reaching 1.4 billion users in 2022 [1], it's no
surprise that health apps like MyFitnessPal, Noom, and Calorie Counter, are
surging in popularity. However, one major setback [2] of nearly all nutrition
applications is that users must enter food data manually, which is
time-consuming and tedious. Thus, there has been an increasing demand for
applications that can accurately identify food items, analyze their nutritional
content, and offer dietary recommendations in real-time. This paper introduces
a comprehensive system that combines advanced computer vision techniques with
nutrition analysis, implemented in a versatile mobile and web application. The
system is divided into three key components: 1) food detection using the YOLOv8
model, 2) nutrient analysis via the Edamam Nutrition Analysis API, and 3)
personalized meal recommendations using the Edamam Meal Planning and Recipe
Search APIs. Designed for both mobile and web platforms, the application
ensures fast processing times with an intuitive user interface, with features
such as data visualizations using Chart.js, a login system, and personalized
settings for dietary preferences, allergies, and cuisine choices. Preliminary
results showcase the system's effectiveness, making it a valuable tool for
users to make informed dietary decisions.

摘要：隨著飲食和營養應用程式在 2022 年達到 14 億使用者 [1]，MyFitnessPal、Noom 和 Calorie Counter 等健康應用程式大幅竄紅也就不足為奇了。然而，幾乎所有營養應用程式的一個主要缺點 [2] 是使用者必須手動輸入食物資料，這既耗時又乏味。因此，對於能夠準確辨識食物品項、分析其營養成分，並即時提供飲食建議的應用程式需求日益增加。本文介紹了一個全面的系統，結合了先進的電腦視覺技術與營養分析，並實作於一個多功能的手機和網路應用程式中。這個系統分為三個關鍵組成部分：1) 使用 YOLOv8 模型進行食物偵測，2) 透過 Edamam 營養分析 API 進行營養分析，以及 3) 使用 Edamam 餐點規劃和食譜搜尋 API 提供個人化餐點建議。此應用程式專為手機和網路平台設計，具備直覺的使用者介面，並提供快速處理時間，其功能包括使用 Chart.js 的資料視覺化、登入系統，以及針對飲食偏好、過敏原和料理選擇的個人化設定。初步結果證明了此系統的有效性，使其成為使用者做出明智飲食決策的寶貴工具。

##### **Envisioning Possibilities and Challenges of AI for Personalized Cancer Care**
2408.10108v1 by Elaine Kong, Kuo-Ting, Huang, Aakash Gautam

The use of Artificial Intelligence (AI) in healthcare, including in caring
for cancer survivors, has gained significant interest. However, gaps remain in
our understanding of how such AI systems can provide care, especially for
ethnic and racial minority groups who continue to face care disparities.
Through interviews with six cancer survivors, we identify critical gaps in
current healthcare systems such as a lack of personalized care and insufficient
cultural and linguistic accommodation. AI, when applied to care, was seen as a
way to address these issues by enabling real-time, culturally aligned, and
linguistically appropriate interactions. We also uncovered concerns about the
implications of AI-driven personalization, such as data privacy, loss of human
touch in caregiving, and the risk of echo chambers that limit exposure to
diverse information. We conclude by discussing the trade-offs between
AI-enhanced personalization and the need for structural changes in healthcare
that go beyond technological solutions, leading us to argue that we should
begin by asking, ``Why personalization?''

摘要：在醫療保健中使用人工智慧 (AI)，包括照護癌症倖存者，已經獲得顯著的關注。然而，我們對於此類 AI 系統如何提供照護，特別是針對持續面臨照護差異的種族和少數族裔群體，仍有理解上的差距。透過與六位癌症倖存者的訪談，我們找出當前醫療保健系統中的重大差距，例如缺乏個人化照護，以及文化和語言適應不足。當 AI 應用於照護時，被視為解決這些問題的方法，它能促成即時、符合文化且在語言上適當的互動。我們也發現對 AI 驅動的個人化照護所帶來的影響感到擔憂，例如資料隱私、照護中失去人際接觸，以及限制接觸多元資訊的同溫層風險。我們最後討論了 AI 增強的個人化照護與醫療保健中結構性變革之間的取捨，而這超越了技術解決方案，這讓我們主張我們應該從詢問「為什麼需要個人化照護？」開始。

##### **Personalizing Reinforcement Learning from Human Feedback with Variational Preference Learning**
2408.10075v1 by Sriyash Poddar, Yanming Wan, Hamish Ivison, Abhishek Gupta, Natasha Jaques

Reinforcement Learning from Human Feedback (RLHF) is a powerful paradigm for
aligning foundation models to human values and preferences. However, current
RLHF techniques cannot account for the naturally occurring differences in
individual human preferences across a diverse population. When these
differences arise, traditional RLHF frameworks simply average over them,
leading to inaccurate rewards and poor performance for individual subgroups. To
address the need for pluralistic alignment, we develop a class of multimodal
RLHF methods. Our proposed techniques are based on a latent variable
formulation - inferring a novel user-specific latent and learning reward models
and policies conditioned on this latent without additional user-specific data.
While conceptually simple, we show that in practice, this reward modeling
requires careful algorithmic considerations around model architecture and
reward scaling. To empirically validate our proposed technique, we first show
that it can provide a way to combat underspecification in simulated control
problems, inferring and optimizing user-specific reward functions. Next, we
conduct experiments on pluralistic language datasets representing diverse user
preferences and demonstrate improved reward function accuracy. We additionally
show the benefits of this probabilistic framework in terms of measuring
uncertainty, and actively learning user preferences. This work enables learning
from diverse populations of users with divergent preferences, an important
challenge that naturally occurs in problems from robot learning to foundation
model alignment.

摘要：人類回饋強化學習 (RLHF) 是一個強大的範例，可以將基礎模型與人類價值觀和偏好保持一致。然而，目前的 RLHF 技術無法說明不同族群中個別人類偏好的自然發生差異。當這些差異出現時，傳統的 RLHF 架構只會對它們進行平均，導致不準確的獎勵和個別子群的表現不佳。為了滿足多元化對齊的需求，我們開發了一類多模態 RLHF 方法。我們提出的技術基於潛在變數公式，推論出新的使用者特定潛在變數，並學習在沒有額外使用者特定資料的情況下，以此潛在變數為條件的獎勵模型和政策。雖然在概念上很簡單，但我們表明在實務上，這種獎勵建模需要仔細考量模型架構和獎勵縮放的演算法考量。為了實證驗證我們提出的技術，我們首先表明它可以提供一種方法來對抗模擬控制問題中的規格不足，推論和最佳化使用者特定的獎勵函數。接下來，我們對代表不同使用者偏好的多元語言資料集進行實驗，並展示改進的獎勵函數準確度。我們另外說明這種機率架構在衡量不確定性和主動學習使用者偏好方面的優點。這項工作能夠從具有不同偏好的不同使用者群體中學習，這是一個在機器人學習到基礎模型對齊問題中自然發生的重要挑戰。

##### **MSDiagnosis: An EMR-based Dataset for Clinical Multi-Step Diagnosis**
2408.10039v1 by Ruihui Hou, Shencheng Chen, Yongqi Fan, Lifeng Zhu, Jing Sun, Jingping Liu, Tong Ruan

Clinical diagnosis is critical in medical practice, typically requiring a
continuous and evolving process that includes primary diagnosis, differential
diagnosis, and final diagnosis. However, most existing clinical diagnostic
tasks are single-step processes, which does not align with the complex
multi-step diagnostic procedures found in real-world clinical settings. In this
paper, we propose a multi-step diagnostic task and annotate a clinical
diagnostic dataset (MSDiagnosis). This dataset includes primary diagnosis,
differential diagnosis, and final diagnosis questions. Additionally, we propose
a novel and effective framework. This framework combines forward inference,
backward inference, reflection, and refinement, enabling the LLM to
self-evaluate and adjust its diagnostic results. To assess the effectiveness of
our proposed method, we design and conduct extensive experiments. The
experimental results demonstrate the effectiveness of the proposed method. We
also provide a comprehensive experimental analysis and suggest future research
directions for this task.

摘要：臨床診斷在醫療實務中至關重要，通常需要一個連續且不斷演進的過程，包括初步診斷、鑑別診斷和最終診斷。然而，現有的臨床診斷任務大多是單步驟的過程，與實際臨床環境中發現的複雜多步驟診斷程序不符。在本文中，我們提出了一項多步驟的診斷任務，並標註了一個臨床診斷資料集 (MSDiagnosis)。此資料集包含初步診斷、鑑別診斷和最終診斷的問題。此外，我們提出了一個新穎且有效的架構。此架構結合了前向推理、後向推理、反思和改善，使 LLM 能自我評估和調整其診斷結果。為了評估我們提出的方法的有效性，我們設計並進行了廣泛的實驗。實驗結果證明了所提出方法的有效性。我們還提供了全面的實驗分析，並建議了此任務的未來研究方向。

##### **LCE: A Framework for Explainability of DNNs for Ultrasound Image Based on Concept Discovery**
2408.09899v1 by Weiji Kong, Xun Gong, Juan Wang

Explaining the decisions of Deep Neural Networks (DNNs) for medical images
has become increasingly important. Existing attribution methods have difficulty
explaining the meaning of pixels while existing concept-based methods are
limited by additional annotations or specific model structures that are
difficult to apply to ultrasound images. In this paper, we propose the Lesion
Concept Explainer (LCE) framework, which combines attribution methods with
concept-based methods. We introduce the Segment Anything Model (SAM),
fine-tuned on a large number of medical images, for concept discovery to enable
a meaningful explanation of ultrasound image DNNs. The proposed framework is
evaluated in terms of both faithfulness and understandability. We point out
deficiencies in the popular faithfulness evaluation metrics and propose a new
evaluation metric. Our evaluation of public and private breast ultrasound
datasets (BUSI and FG-US-B) shows that LCE performs well compared to
commonly-used explainability methods. Finally, we also validate that LCE can
consistently provide reliable explanations for more meaningful fine-grained
diagnostic tasks in breast ultrasound.

摘要：解釋深度神經網路 (DNN) 在醫學影像中的決策已變得越來越重要。現有的歸因方法難以解釋畫素的意義，而現有的基於概念的方法則受到額外註解或難以應用於超音波影像的特定模型結構限制。在本文中，我們提出病灶概念解釋器 (LCE) 架構，它結合了歸因方法與基於概念的方法。我們引入了在大量醫學影像上微調的「任何區段模型」(SAM)，用於概念發現，以實現超音波影像 DNN 的有意義解釋。所提出的架構在忠實度和可理解性方面都經過評估。我們指出了流行的忠實度評估指標中的缺陷，並提出了一個新的評估指標。我們對公共和私人乳房超音波資料集 (BUSI 和 FG-US-B) 的評估顯示，與常用的可解釋性方法相比，LCE 的表現良好。最後，我們還驗證了 LCE 能持續提供乳房超音波中更有意義的細粒度診斷任務的可靠解釋。

##### **Preoperative Rotator Cuff Tear Prediction from Shoulder Radiographs using a Convolutional Block Attention Module-Integrated Neural Network**
2408.09894v1 by Chris Hyunchul Jo, Jiwoong Yang, Byunghwan Jeon, Hackjoon Shim, Ikbeom Jang

Research question: We test whether a plane shoulder radiograph can be used
together with deep learning methods to identify patients with rotator cuff
tears as opposed to using an MRI in standard of care. Findings: By integrating
convolutional block attention modules into a deep neural network, our model
demonstrates high accuracy in detecting patients with rotator cuff tears,
achieving an average AUC of 0.889 and an accuracy of 0.831. Meaning: This study
validates the efficacy of our deep learning model to accurately detect rotation
cuff tears from radiographs, offering a viable pre-assessment or alternative to
more expensive imaging techniques such as MRI.

摘要：研究問題：我們測試平面肩部 X 光片是否可與深度學習方法結合使用，以識別旋轉肌袖撕裂的患者，而非在護理標準中使用 MRI。結果：透過將卷積區塊注意力模組整合到深度神經網路中，我們的模型在偵測旋轉肌袖撕裂的患者方面展現出高度準確性，達到平均 0.889 的 AUC 和 0.831 的準確度。意義：這項研究驗證了我們的深度學習模型從 X 光片中準確偵測旋轉肌袖撕裂的效能，提供了一個可行的預先評估或替代方案，以取代 MRI 等更昂貴的影像技術。

##### **New spectral imaging biomarkers for sepsis and mortality in intensive care**
2408.09873v1 by Silvia Seidlitz, Katharina Hölzl, Ayca von Garrel, Jan Sellner, Stephan Katzenschlager, Tobias Hölle, Dania Fischer, Maik von der Forst, Felix C. F. Schmitt, Markus A. Weigand, Lena Maier-Hein, Maximilian Dietrich

With sepsis remaining a leading cause of mortality, early identification of
septic patients and those at high risk of death is a challenge of high
socioeconomic importance. The driving hypothesis of this study was that
hyperspectral imaging (HSI) could provide novel biomarkers for sepsis diagnosis
and treatment management due to its potential to monitor microcirculatory
alterations. We conducted a comprehensive study involving HSI data of the palm
and fingers from more than 480 patients on the day of their intensive care unit
(ICU) admission. The findings demonstrate that HSI measurements can predict
sepsis with an area under the receiver operating characteristic curve (AUROC)
of 0.80 (95 % confidence interval (CI) [0.76; 0.84]) and mortality with an
AUROC of 0.72 (95 % CI [0.65; 0.79]). The predictive performance improves
substantially when additional clinical data is incorporated, leading to an
AUROC of up to 0.94 (95 % CI [0.92; 0.96]) for sepsis and 0.84 (95 % CI [0.78;
0.89]) for mortality. We conclude that HSI presents novel imaging biomarkers
for the rapid, non-invasive prediction of sepsis and mortality, suggesting its
potential as an important modality for guiding diagnosis and treatment.

摘要：由於敗血症仍然是死亡的主要原因，因此早期識別敗血症患者和死亡風險高的人是一項具有高度社會經濟重要性的挑戰。本研究的驅動假設是，由於高光譜影像 (HSI) 有可能監測微循環改變，因此它可以提供敗血症診斷和治療管理的新型生物標記。我們進行了一項全面的研究，涉及來自 480 多名患者在入住重症監護病房 (ICU) 當天的手掌和手指的 HSI 資料。研究結果表明，HSI 測量可以預測敗血症，其受試者工作特性曲線下面積 (AUROC) 為 0.80（95% 置信區間 (CI) [0.76; 0.84]），死亡率的 AUROC 為 0.72（95% CI [0.65; 0.79]）。當納入其他臨床數據時，預測效能會大幅提高，敗血症的 AUROC 高達 0.94（95% CI [0.92; 0.96]），死亡率的 AUROC 為 0.84（95% CI [0.78; 0.89]）。我們得出結論，HSI 提供了新型的影像生物標記，可快速、非侵入性地預測敗血症和死亡率，這表明它有可能成為指導診斷和治療的重要方式。

##### **Enhanced Cascade Prostate Cancer Classifier in mp-MRI Utilizing Recall Feedback Adaptive Loss and Prior Knowledge-Based Feature Extraction**
2408.09746v1 by Kun Luo, Bowen Zheng, Shidong Lv, Jie Tao, Qiang Wei

Prostate cancer is the second most common cancer in males worldwide, and
mpMRI is commonly used for diagnosis. However, interpreting mpMRI is
challenging and requires expertise from radiologists. This highlights the
urgent need for automated grading in mpMRI. Existing studies lack integration
of clinical prior information and suffer from uneven training sample
distribution due to prevalence. Therefore, we propose a solution that
incorporates prior knowledge, addresses the issue of uneven medical sample
distribution, and maintains high interpretability in mpMRI. Firstly, we
introduce Prior Knowledge-Based Feature Extraction, which mathematically models
the PI-RADS criteria for prostate cancer as diagnostic information into model
training. Secondly, we propose Adaptive Recall Feedback Loss to address the
extremely imbalanced data problem. This method adjusts the training dynamically
based on accuracy and recall in the validation set, resulting in high accuracy
and recall simultaneously in the testing set.Thirdly, we design an Enhanced
Cascade Prostate Cancer Classifier that classifies prostate cancer into
different levels in an interpretable way, which refines the classification
results and helps with clinical intervention. Our method is validated through
experiments on the PI-CAI dataset and outperforms other methods with a more
balanced result in both accuracy and recall rate.

摘要：攝護腺癌是全球男性中第二常見的癌症，而多參數磁振造影（mpMRI）通常用於診斷。然而，mpMRI 的解讀具有挑戰性，需要放射科醫師的專業知識。這突顯了 mpMRI 自動分級的迫切需求。現有的研究缺乏臨床先驗資訊的整合，並且由於患病率而導致訓練樣本分佈不均。因此，我們提出了一個解決方案，它結合了先驗知識，解決了醫學樣本分佈不均的問題，並在 mpMRI 中保持了很高的可解釋性。首先，我們引入了基於先驗知識的特徵提取，它將 PI-RADS 攝護腺癌診斷資訊數學建模成模型訓練。其次，我們提出了自適應召回反饋損失來解決極度不平衡的資料問題。此方法根據驗證集中的準確度和召回率動態調整訓練，從而同時在測試集中獲得高準確度和召回率。第三，我們設計了一個增強型級聯攝護腺癌分類器，它以可解釋的方式將攝護腺癌分類為不同的等級，這可以改善分類結果並有助於臨床介入。我們的模型已通過 PI-CAI 資料集的實驗驗證，並且在準確度和召回率方面都優於其他方法，結果更為平衡。

##### **R2GenCSR: Retrieving Context Samples for Large Language Model based X-ray Medical Report Generation**
2408.09743v1 by Xiao Wang, Yuehang Li, Fuling Wang, Shiao Wang, Chuanfu Li, Bo Jiang

Inspired by the tremendous success of Large Language Models (LLMs), existing
X-ray medical report generation methods attempt to leverage large models to
achieve better performance. They usually adopt a Transformer to extract the
visual features of a given X-ray image, and then, feed them into the LLM for
text generation. How to extract more effective information for the LLMs to help
them improve final results is an urgent problem that needs to be solved.
Additionally, the use of visual Transformer models also brings high
computational complexity. To address these issues, this paper proposes a novel
context-guided efficient X-ray medical report generation framework.
Specifically, we introduce the Mamba as the vision backbone with linear
complexity, and the performance obtained is comparable to that of the strong
Transformer model. More importantly, we perform context retrieval from the
training set for samples within each mini-batch during the training phase,
utilizing both positively and negatively related samples to enhance feature
representation and discriminative learning. Subsequently, we feed the vision
tokens, context information, and prompt statements to invoke the LLM for
generating high-quality medical reports. Extensive experiments on three X-ray
report generation datasets (i.e., IU-Xray, MIMIC-CXR, CheXpert Plus) fully
validated the effectiveness of our proposed model. The source code of this work
will be released on \url{https://github.com/Event-AHU/Medical_Image_Analysis}.

摘要：受到大型語言模型 (LLM) 巨大成功的啟發，現有的 X 光醫學報告生成方法嘗試利用大型模型來達成更好的效能。他們通常採用 Transformer 來擷取特定 X 光影像的視覺特徵，然後將其輸入 LLM 以進行文字生成。如何擷取更有效的資訊以供 LLM 使用，協助他們改善最終結果，是一個亟需解決的迫切問題。此外，視覺 Transformer 模型的使用也帶來了很高的運算複雜度。為了解決這些問題，本文提出了一個新穎的脈絡導引式高效 X 光醫學報告生成架構。具體來說，我們引入 Mamba 作為具有線性複雜度的視覺主幹，且獲得的效能與強大的 Transformer 模型相當。更重要的是，我們在訓練階段從訓練集中執行脈絡檢索，以取得每個小批次中的樣本，利用正相關和負相關樣本來增強特徵表徵和判別式學習。隨後，我們將視覺符號、脈絡資訊和提示陳述輸入 LLM，以生成高品質的醫學報告。在三個 X 光報告生成資料集（即 IU-Xray、MIMIC-CXR、CheXpert Plus）上進行的廣泛實驗，充分驗證了我們提出的模型的有效性。這項工作的原始碼將在 \url{https://github.com/Event-AHU/Medical_Image_Analysis} 上發布。

##### **HYDEN: Hyperbolic Density Representations for Medical Images and Reports**
2408.09715v2 by Zhi Qiao, Linbin Han, Xiantong Zhen, Jia-Hong Gao, Zhen Qian

In light of the inherent entailment relations between images and text,
hyperbolic point vector embeddings, leveraging the hierarchical modeling
advantages of hyperbolic space, have been utilized for visual semantic
representation learning. However, point vector embedding approaches fail to
address the issue of semantic uncertainty, where an image may have multiple
interpretations, and text may refer to different images, a phenomenon
particularly prevalent in the medical domain. Therefor, we propose
\textbf{HYDEN}, a novel hyperbolic density embedding based image-text
representation learning approach tailored for specific medical domain data.
This method integrates text-aware local features alongside global features from
images, mapping image-text features to density features in hyperbolic space via
using hyperbolic pseudo-Gaussian distributions. An encapsulation loss function
is employed to model the partial order relations between image-text density
distributions. Experimental results demonstrate the interpretability of our
approach and its superior performance compared to the baseline methods across
various zero-shot tasks and different datasets.

摘要：鉴于图像和文本之间固有的蕴涵关系，利用双曲空间的分层建模优势，双曲点向量嵌入已被用于视觉语义表示学习。然而，点向量嵌入方法未能解决语义不确定性问题，其中一个图像可能有多种解释，而文本可能指代不同的图像，这种现象在医学领域尤为普遍。因此，我们提出了\textbf{HYDEN}，这是一种新颖的基于双曲密度嵌入的图像-文本表示学习方法，专为特定医学领域数据量身定制。此方法将文本感知局部特征与图像中的全局特征相结合，通过使用双曲伪高斯分布将图像-文本特征映射到双曲空间中的密度特征。封装损失函数用于对图像-文本密度分布之间的偏序关系进行建模。实验结果证明了我们方法的可解释性，并且在各种零样本任务和不同数据集上，其性能优于基线方法。

##### **PA-LLaVA: A Large Language-Vision Assistant for Human Pathology Image Understanding**
2408.09530v1 by Dawei Dai, Yuanhui Zhang, Long Xu, Qianlan Yang, Xiaojing Shen, Shuyin Xia, Guoyin Wang

The previous advancements in pathology image understanding primarily involved
developing models tailored to specific tasks. Recent studies has demonstrated
that the large vision-language model can enhance the performance of various
downstream tasks in medical image understanding. In this study, we developed a
domain-specific large language-vision assistant (PA-LLaVA) for pathology image
understanding. Specifically, (1) we first construct a human pathology
image-text dataset by cleaning the public medical image-text data for
domain-specific alignment; (2) Using the proposed image-text data, we first
train a pathology language-image pretraining (PLIP) model as the specialized
visual encoder for pathology image, and then we developed scale-invariant
connector to avoid the information loss caused by image scaling; (3) We adopt
two-stage learning to train PA-LLaVA, first stage for domain alignment, and
second stage for end to end visual question \& answering (VQA) task. In
experiments, we evaluate our PA-LLaVA on both supervised and zero-shot VQA
datasets, our model achieved the best overall performance among multimodal
models of similar scale. The ablation experiments also confirmed the
effectiveness of our design. We posit that our PA-LLaVA model and the datasets
presented in this work can promote research in field of computational
pathology. All codes are available at:
https://github.com/ddw2AIGROUP2CQUPT/PA-LLaVA}{https://github.com/ddw2AIGROUP2CQUPT/PA-LLaVA

摘要：以往在病理影像理解方面的進展，主要集中於開發針對特定任務量身打造的模型。最近的研究表明，大型視覺語言模型可以增強各種下游任務在醫學影像理解中的表現。在本研究中，我們開發了一個特定領域的大型語言視覺助理 (PA-LLaVA)，用於病理影像理解。具體來說，(1) 我們首先通過清理公共醫學影像文本數據，以進行特定領域校準，來構建人類病理影像文本數據集；(2) 使用提出的影像文本數據，我們首先訓練一個病理語言影像預訓練 (PLIP) 模型，作為病理影像的專用視覺編碼器，然後我們開發了尺度不變連接器，以避免因影像縮放而造成的資訊損失；(3) 我們採用兩階段學習來訓練 PA-LLaVA，第一階段進行領域校準，第二階段進行端到端的視覺問答 (VQA) 任務。在實驗中，我們在監督式和零次 VQA 數據集上評估我們的 PA-LLaVA，我們的模型在規模相似的多模態模型中取得了最佳的整體表現。消融實驗也證實了我們設計的有效性。我們認為，我們的 PA-LLaVA 模型和這項工作中提出的數據集可以促進計算病理學領域的研究。所有程式碼都可以在以下網址取得：
https://github.com/ddw2AIGROUP2CQUPT/PA-LLaVA

##### **MedMAP: Promoting Incomplete Multi-modal Brain Tumor Segmentation with Alignment**
2408.09465v1 by Tianyi Liu, Zhaorui Tan, Muyin Chen, Xi Yang, Haochuan Jiang, Kaizhu Huang

Brain tumor segmentation is often based on multiple magnetic resonance
imaging (MRI). However, in clinical practice, certain modalities of MRI may be
missing, which presents a more difficult scenario. To cope with this challenge,
Knowledge Distillation, Domain Adaption, and Shared Latent Space have emerged
as commonly promising strategies. However, recent efforts typically overlook
the modality gaps and thus fail to learn important invariant feature
representations across different modalities. Such drawback consequently leads
to limited performance for missing modality models. To ameliorate these
problems, pre-trained models are used in natural visual segmentation tasks to
minimize the gaps. However, promising pre-trained models are often unavailable
in medical image segmentation tasks. Along this line, in this paper, we propose
a novel paradigm that aligns latent features of involved modalities to a
well-defined distribution anchor as the substitution of the pre-trained model}.
As a major contribution, we prove that our novel training paradigm ensures a
tight evidence lower bound, thus theoretically certifying its effectiveness.
Extensive experiments on different backbones validate that the proposed
paradigm can enable invariant feature representations and produce models with
narrowed modality gaps. Models with our alignment paradigm show their superior
performance on both BraTS2018 and BraTS2020 datasets.

摘要：腦腫瘤分割通常基於多種磁共振影像 (MRI)。然而，在臨床實務中，某些 MRI 模組可能遺失，這會造成更困難的情況。為了應對這項挑戰，知識萃取、領域適應和共享潛在空間已成為普遍有前景的策略。然而，最近的努力通常會忽略模組間的差距，因此無法學習不同模組間的重要不變特徵表示。這種缺點因此導致遺失模組模型的效能有限。為了改善這些問題，預先訓練的模型用於自然視覺分割任務，以縮小差距。然而，有前景的預先訓練模型通常在醫學影像分割任務中不可用。沿著這條路線，我們在本文中提出一個新穎的範例，將所涉及模組的潛在特徵與明確定義的分布錨點對齊，作為預先訓練模型的替代。作為一項重大貢獻，我們證明了我們的新穎訓練範例確保了緊密的證據下界，因此在理論上證明了其有效性。在不同主幹上進行的廣泛實驗驗證了所提出的範例可以啟用不變特徵表示，並產生模組間差距縮小的模型。採用我們對齊範例的模型在 BraTS2018 和 BraTS2020 資料集上展現出其優異效能。

##### **Deformation-aware GAN for Medical Image Synthesis with Substantially Misaligned Pairs**
2408.09432v1 by Bowen Xin, Tony Young, Claire E Wainwright, Tamara Blake, Leo Lebrat, Thomas Gaass, Thomas Benkert, Alto Stemmer, David Coman, Jason Dowling

Medical image synthesis generates additional imaging modalities that are
costly, invasive or harmful to acquire, which helps to facilitate the clinical
workflow. When training pairs are substantially misaligned (e.g., lung MRI-CT
pairs with respiratory motion), accurate image synthesis remains a critical
challenge. Recent works explored the directional registration module to adjust
misalignment in generative adversarial networks (GANs); however, substantial
misalignment will lead to 1) suboptimal data mapping caused by correspondence
ambiguity, and 2) degraded image fidelity caused by morphology influence on
discriminators. To address the challenges, we propose a novel Deformation-aware
GAN (DA-GAN) to dynamically correct the misalignment during the image synthesis
based on multi-objective inverse consistency. Specifically, in the generative
process, three levels of inverse consistency cohesively optimise symmetric
registration and image generation for improved correspondence. In the
adversarial process, to further improve image fidelity under misalignment, we
design deformation-aware discriminators to disentangle the mismatched spatial
morphology from the judgement of image fidelity. Experimental results show that
DA-GAN achieved superior performance on a public dataset with simulated
misalignments and a real-world lung MRI-CT dataset with respiratory motion
misalignment. The results indicate the potential for a wide range of medical
image synthesis tasks such as radiotherapy planning.

摘要：医学影像合成可生成额外的影像模式，这些模式的获取成本高昂、侵入性强或有害，有助于促进临床工作流程。当训练对出现严重错位（例如，伴有呼吸运动的肺部 MRI-CT 对）时，精确影像合成仍然是一项关键挑战。最近的研究探索了方向性配准模块来调整生成对抗网络 (GAN) 中的错位；然而，严重的错位会导致 1）对应关系模糊导致次优数据映射，以及 2）形态学对判别器产生影响导致影像保真度下降。为了应对这些挑战，我们提出了一种新颖的变形感知 GAN (DA-GAN)，以根据多目标逆一致性在影像合成过程中动态校正错位。具体来说，在生成过程中，三个级别的逆一致性内聚优化了对称配准和影像生成，以改善对应关系。在对抗过程中，为了进一步提高错位下的影像保真度，我们设计了变形感知判别器，以将不匹配的空间形态从影像保真度判断中解耦。实验结果表明，DA-GAN 在具有模拟错位的公共数据集和具有呼吸运动错位的真实肺部 MRI-CT 数据集上取得了优异的性能。结果表明，在放疗计划等广泛的医学影像合成任务中具有潜力。

##### **$\mathbb{BEHR}$NOULLI: A Binary EHR Data-Oriented Medication Recommendation System**
2408.09410v1 by Xihao Piao, Pei Gao, Zheng Chen, Lingwei Zhu, Yasuko Matsubara, Yasushi Sakurai

The medical community believes binary medical event outcomes in EHR data
contain sufficient information for making a sensible recommendation. However,
there are two challenges to effectively utilizing such data: (1) modeling the
relationship between massive 0,1 event outcomes is difficult, even with expert
knowledge; (2) in practice, learning can be stalled by the binary values since
the equally important 0 entries propagate no learning signals. Currently, there
is a large gap between the assumed sufficient information and the reality that
no promising results have been shown by utilizing solely the binary data:
visiting or secondary information is often necessary to reach acceptable
performance. In this paper, we attempt to build the first successful binary EHR
data-oriented drug recommendation system by tackling the two difficulties,
making sensible drug recommendations solely using the binary EHR medical
records. To this end, we take a statistical perspective to view the EHR data as
a sample from its cohorts and transform them into continuous Bernoulli
probabilities. The transformed entries not only model a deterministic binary
event with a distribution but also allow reflecting \emph{event-event}
relationship by conditional probability. A graph neural network is learned on
top of the transformation. It captures event-event correlations while
emphasizing \emph{event-to-patient} features. Extensive results demonstrate
that the proposed method achieves state-of-the-art performance on large-scale
databases, outperforming baseline methods that use secondary information by a
large margin. The source code is available at
\url{https://github.com/chenzRG/BEHRMecom}

摘要：<paragraph>醫療界認為 EHR 資料中的二元醫療事件結果包含足夠資訊，可以做出明智的建議。然而，有效利用此類資料有兩個挑戰：(1) 即使有專家知識，也很難建模大量 0、1 事件結果之間的關係；(2) 在實務上，學習可能會因二元值而停滯，因為同樣重要的 0 輸入不會傳播任何學習訊號。目前，假設的足夠資訊與現實之間存在很大的差距，僅利用二元資料並未顯示有希望的結果：通常需要拜訪或次要資訊才能達到可接受的效能。在本文中，我們嘗試透過解決這兩個難題來建立第一個成功的二元 EHR 資料導向藥物推薦系統，僅使用二元 EHR 病歷做出明智的藥物推薦。為此，我們採取統計觀點，將 EHR 資料視為其同類群的樣本，並將其轉換為連續的 Bernoulli 機率。轉換後的輸入不僅以分佈對確定性的二元事件進行建模，還允許透過條件機率反映「事件-事件」關係。圖神經網路學習轉換的頂端。它擷取事件-事件相關性，同時強調「事件-對患者」特徵。廣泛的結果證明，所提出的方法在大型資料庫上達到最先進的效能，遠遠優於使用次要資訊的基線方法。原始碼可在
\url{https://github.com/chenzRG/BEHRMecom} 取得</paragraph>

##### **Panorama Tomosynthesis from Head CBCT with Simulated Projection Geometry**
2408.09358v2 by Anusree P. S., Bikram Keshari Parida, Seong Yong Moon, Wonsang You

Cone Beam Computed Tomography (CBCT) and Panoramic X-rays are the most
commonly used imaging modalities in dental health care. CBCT can produce
three-dimensional views of a patient's head, providing clinicians with better
diagnostic capability, whereas Panoramic X-ray can capture the entire
maxillofacial region in a single image. If the CBCT is already available, it
can be beneficial to synthesize a Panoramic X-ray, thereby avoiding an
immediate additional scan and extra radiation exposure. Existing methods focus
on delineating an approximate dental arch and creating orthogonal projections
along this arch. However, no golden standard is available for such dental arch
extractions, and this choice can affect the quality of synthesized X-rays. To
avoid such issues, we propose a novel method for synthesizing Panoramic X-rays
from diverse head CBCTs, employing a simulated projection geometry and dynamic
rotation centers. Our method effectively synthesized panoramic views from CBCT,
even for patients with missing or nonexistent teeth and in the presence of
severe metal implants. Our results demonstrate that this method can generate
high-quality panoramic images irrespective of the CBCT scanner geometry.

摘要：錐狀光束電腦斷層掃描 (CBCT) 和全景 X 射線是牙科保健中最常用的影像模式。CBCT 可以產生患者頭部的三維影像，提供給臨床醫師更好的診斷能力，而全景 X 射線則可以在單一影像中擷取整個上顎顏面部區域。如果 CBCT 已經可用，合成全景 X 射線會很有幫助，從而避免立即進行額外的掃描和額外的輻射曝露。現有方法專注於描繪近似的牙弓並沿著此牙弓建立正交投影。然而，沒有黃金標準可用於此類牙弓萃取，而此選擇會影響合成 X 射線的品質。為了避免此類問題，我們提出從多樣的頭部 CBCT 合成全景 X 射線的新方法，採用模擬投影幾何和動態旋轉中心。我們的這種方法有效地從 CBCT 合成了全景影像，即使對於缺牙或無牙的患者以及在有嚴重金屬植入物的情況下也是如此。我們的結果顯示，此方法可以產生高品質的全景影像，而與 CBCT 掃描機幾何無關。

##### **FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models**
2408.10276v1 by Xiaochen Wang, Jiaqi Wang, Houping Xiao, Jinghui Chen, Fenglong Ma

Foundation models have demonstrated remarkable capabilities in handling
diverse modalities and tasks, outperforming conventional artificial
intelligence (AI) approaches that are highly task-specific and
modality-reliant. In the medical domain, however, the development of
comprehensive foundation models is constrained by limited access to diverse
modalities and stringent privacy regulations. To address these constraints,
this study introduces a novel knowledge injection approach, FedKIM, designed to
scale the medical foundation model within a federated learning framework.
FedKIM leverages lightweight local models to extract healthcare knowledge from
private data and integrates this knowledge into a centralized foundation model
using a designed adaptive Multitask Multimodal Mixture Of Experts (M3OE)
module. This method not only preserves privacy but also enhances the model's
ability to handle complex medical tasks involving multiple modalities. Our
extensive experiments across twelve tasks in seven modalities demonstrate the
effectiveness of FedKIM in various settings, highlighting its potential to
scale medical foundation models without direct access to sensitive data.

摘要：基礎模型已展現出處理各種模式和任務的卓越能力，表現優於高度任務特定且依賴模式的傳統人工智慧 (AI) 方法。然而，在醫療領域，全面基礎模型的開發受到取得各種模式的有限管道和嚴格的隱私法規所限制。為了解決這些限制，本研究提出了一種新穎的知識注入方法 FedKIM，旨在擴展聯邦學習架構中的醫療基礎模型。FedKIM 利用輕量級的局部模型從私人資料中提取醫療保健知識，並使用設計的適應性多任務多模態專家混合 (M3OE) 模組將此知識整合到一個集中式基礎模型中。此方法不僅保護隱私，還能增強模型處理涉及多種模式的複雜醫療任務的能力。我們在七種模式的十二項任務中進行的廣泛實驗證明了 FedKIM 在各種設定中的有效性，突顯了其在不直接存取敏感資料的情況下擴展醫療基礎模型的潛力。

##### **FEDMEKI: A Benchmark for Scaling Medical Foundation Models via Federated Knowledge Injection**
2408.09227v1 by Jiaqi Wang, Xiaochen Wang, Lingjuan Lyu, Jinghui Chen, Fenglong Ma

This study introduces the Federated Medical Knowledge Injection (FEDMEKI)
platform, a new benchmark designed to address the unique challenges of
integrating medical knowledge into foundation models under privacy constraints.
By leveraging a cross-silo federated learning approach, FEDMEKI circumvents the
issues associated with centralized data collection, which is often prohibited
under health regulations like the Health Insurance Portability and
Accountability Act (HIPAA) in the USA. The platform is meticulously designed to
handle multi-site, multi-modal, and multi-task medical data, which includes 7
medical modalities, including images, signals, texts, laboratory test results,
vital signs, input variables, and output variables. The curated dataset to
validate FEDMEKI covers 8 medical tasks, including 6 classification tasks (lung
opacity detection, COVID-19 detection, electrocardiogram (ECG) abnormal
detection, mortality prediction, sepsis prediction, and enlarged
cardiomediastinum detection) and 2 generation tasks (medical visual question
answering (MedVQA) and ECG noise clarification). This comprehensive dataset is
partitioned across several clients to facilitate the decentralized training
process under 16 benchmark approaches. FEDMEKI not only preserves data privacy
but also enhances the capability of medical foundation models by allowing them
to learn from a broader spectrum of medical knowledge without direct data
exposure, thereby setting a new benchmark in the application of foundation
models within the healthcare sector.

摘要：這項研究介紹了聯邦式醫療知識注入 (FEDMEKI) 平台，這是一個新的基準，旨在解決在隱私限制下將醫療知識整合到基礎模型中的獨特挑戰。透過利用跨資料孤島的聯邦式學習方法，FEDMEKI 規避了與集中式資料收集相關的問題，而這在健康法規下通常是被禁止的，例如美國的健康保險可攜性和責任法 (HIPAA)。該平台經過精心設計，可處理多站點、多模式和多任務的醫療資料，其中包括 7 種醫療模式，包括影像、訊號、文字、實驗室檢驗結果、生命徵象、輸入變數和輸出變數。用於驗證 FEDMEKI 的精選資料集涵蓋了 8 項醫療任務，包括 6 項分類任務 (肺部混濁偵測、COVID-19 偵測、心電圖 (ECG) 異常偵測、死亡率預測、敗血症預測和擴大縱膈腔偵測) 和 2 項生成任務 (醫療視覺問題解答 (MedVQA) 和 ECG 雜訊澄清)。這個全面的資料集被分割在多個用戶端，以促進在 16 種基準方法下進行分散式訓練流程。FEDMEKI 不僅保護資料隱私，還透過允許醫療基礎模型從更廣泛的醫療知識中學習，而無需直接接觸資料，進而增強其能力，從而為基礎模型在醫療保健領域的應用設定了一個新的基準。

##### **FedKBP: Federated dose prediction framework for knowledge-based planning in radiation therapy**
2408.10275v1 by Jingyun Chen, Martin King, Yading Yuan

Dose prediction plays a key role in knowledge-based planning (KBP) by
automatically generating patient-specific dose distribution. Recent advances in
deep learning-based dose prediction methods necessitates collaboration among
data contributors for improved performance. Federated learning (FL) has emerged
as a solution, enabling medical centers to jointly train deep-learning models
without compromising patient data privacy. We developed the FedKBP framework to
evaluate the performances of centralized, federated, and individual (i.e.
separated) training of dose prediction model on the 340 plans from OpenKBP
dataset. To simulate FL and individual training, we divided the data into 8
training sites. To evaluate the effect of inter-site data variation on model
training, we implemented two types of case distributions: 1) Independent and
identically distributed (IID), where the training and validating cases were
evenly divided among the 8 sites, and 2) non-IID, where some sites have more
cases than others. The results show FL consistently outperforms individual
training on both model optimization speed and out-of-sample testing scores,
highlighting the advantage of FL over individual training. Under IID data
division, FL shows comparable performance to centralized training, underscoring
FL as a promising alternative to traditional pooled-data training. Under
non-IID division, larger sites outperformed smaller sites by up to 19% on
testing scores, confirming the need of collaboration among data owners to
achieve better prediction accuracy. Meanwhile, non-IID FL showed reduced
performance as compared to IID FL, posing the need for more sophisticated FL
method beyond mere model averaging to handle data variation among participating
sites.

摘要：劑量預測在知識型規劃 (KBP) 中扮演著關鍵角色，透過自動產生特定於病患的劑量分佈。深度學習為基礎的劑量預測方法的最新進展，需要資料貢獻者之間的合作才能提升效能。聯邦學習 (FL) 已成為一種解決方案，讓醫療中心能夠共同訓練深度學習模型，同時不損害病患資料隱私。我們開發了 FedKBP 架構，以評估集中式、聯邦式和個別 (即分開) 訓練劑量預測模型在 OpenKBP 資料集的 340 個計畫上的效能。為了模擬 FL 和個別訓練，我們將資料分為 8 個訓練地點。為了評估場址間資料差異對模型訓練的影響，我們實作了兩種案例分佈：1) 獨立同分布 (IID)，其中訓練和驗證案例均平均分佈在 8 個場址，以及 2) 非 IID，其中某些場址的案例多於其他場址。結果顯示 FL 在模型最佳化速度和樣本外測試分數上皆持續優於個別訓練，突顯了 FL 相較於個別訓練的優勢。在 IID 資料區分下，FL 顯示出與集中式訓練相當的效能，強調 FL 是傳統匯集資料訓練的潛在替代方案。在非 IID 區分下，較大型場址在測試分數上比較小型場址高出 19%，確認了資料擁有者之間需要合作才能達成更好的預測準確度。同時，與 IID FL 相比，非 IID FL 顯示出降低的效能，這表示需要更精密的 FL 方法，而不仅仅是模型平均，才能處理參與場址之間的資料差異。

##### **AI Managed Emergency Documentation with a Pretrained Model**
2408.09193v1 by David Menzies, Sean Kirwan, Ahmad Albarqawi

This study investigates the use of a large language model system to improve
efficiency and quality in emergency department (ED) discharge letter writing.
Time constraints and infrastructural deficits make compliance with current
discharge letter targets difficult. We explored potential efficiencies from an
artificial intelligence software in the generation of ED discharge letters and
the attitudes of doctors toward this technology. The evaluated system leverages
advanced techniques to fine-tune a model to generate discharge summaries from
short-hand inputs, including voice, text, and electronic health record data.
Nineteen physicians with emergency medicine experience evaluated the system
text and voice-to-text interfaces against manual typing. The results showed
significant time savings with MedWrite LLM interfaces compared to manual
methods.

摘要：本研究探討使用大型語言模型系統來提升急診室（ED）出院信撰寫的效率和品質。時間限制和基礎設施不足使得遵守目前的出院信目標變得困難。我們探討了人工智慧軟體在產生 ED 出院信中潛在的效率，以及醫生對這項技術的態度。評估系統利用進階技術微調模型，以從速記輸入（包括語音、文字和電子健康紀錄資料）產生出院摘要。19 位具有急診醫學經驗的醫師評估了系統文字和語音轉文字介面，以及手動輸入。結果顯示，與手動方法相比，MedWrite LLM 介面可大幅節省時間。

##### **Identifying Technical Debt and Its Types Across Diverse Software Projects Issues**
2408.09128v1 by Karthik Shivashankar, Mili Orucevic, Maren Maritsdatter Kruke, Antonio Martini

Technical Debt (TD) identification in software projects issues is crucial for
maintaining code quality, reducing long-term maintenance costs, and improving
overall project health. This study advances TD classification using
transformer-based models, addressing the critical need for accurate and
efficient TD identification in large-scale software development.
  Our methodology employs multiple binary classifiers for TD and its type,
combined through ensemble learning, to enhance accuracy and robustness in
detecting various forms of TD. We train and evaluate these models on a
comprehensive dataset from GitHub Archive Issues (2015-2024), supplemented with
industrial data validation.
  We demonstrate that in-project fine-tuned transformer models significantly
outperform task-specific fine-tuned models in TD classification, highlighting
the importance of project-specific context in accurate TD identification. Our
research also reveals the superiority of specialized binary classifiers over
multi-class models for TD and its type identification, enabling more targeted
debt resolution strategies. A comparative analysis shows that the smaller
DistilRoBERTa model is more effective than larger language models like GPTs for
TD classification tasks, especially after fine-tuning, offering insights into
efficient model selection for specific TD detection tasks.
  The study also assesses generalization capabilities using metrics such as
MCC, AUC ROC, Recall, and F1 score, focusing on model effectiveness,
fine-tuning impact, and relative performance. By validating our approach on
out-of-distribution and real-world industrial datasets, we ensure practical
applicability, addressing the diverse nature of software projects.

摘要：<paragraph>在軟體專案議題中，技術債（TD）識別對於維持程式碼品質、降低長期維護成本和改善整體專案健全度至關重要。本研究使用基於 Transformer 的模型推進 TD 分類，解決大型軟體開發中對準確且有效的 TD 識別的關鍵需求。
我們的做法採用多個 TD 及其類型的二元分類器，透過整體學習結合，以提升偵測各種形式 TD 時的準確度和穩健性。我們在來自 GitHub Archive Issues（2015-2024）的綜合資料集上訓練和評估這些模型，並輔以產業資料驗證。
我們證明，專案內微調的 Transformer 模型在 TD 分類中明顯優於特定任務微調的模型，強調了專案特定脈絡在準確 TD 識別中的重要性。我們的研究也揭示了專門的二元分類器優於多類模型，用於 TD 及其類型識別，從而實現更具針對性的債務解決策略。比較分析顯示，較小的 DistilRoBERTa 模型比 GPT 等大型語言模型更有效於 TD 分類任務，尤其是在微調後，為特定 TD 偵測任務的有效模型選擇提供見解。
本研究也使用 MCC、AUC ROC、召回率和 F1 分數等指標評估泛化能力，重點在於模型效能、微調影響和相對效能。透過在分布外和真實世界產業資料集上驗證我們的做法，我們確保了實務適用性，解決了軟體專案的多樣性。</paragraph>

##### **Fragment-Masked Molecular Optimization**
2408.09106v1 by Kun Li, Xiantao Cai, Jia Wu, Bo Du, Wenbin Hu

Molecular optimization is a crucial aspect of drug discovery, aimed at
refining molecular structures to enhance drug efficacy and minimize side
effects, ultimately accelerating the overall drug development process. Many
target-based molecular optimization methods have been proposed, significantly
advancing drug discovery. These methods primarily on understanding the specific
drug target structures or their hypothesized roles in combating diseases.
However, challenges such as a limited number of available targets and a
difficulty capturing clear structures hinder innovative drug development. In
contrast, phenotypic drug discovery (PDD) does not depend on clear target
structures and can identify hits with novel and unbiased polypharmacology
signatures. As a result, PDD-based molecular optimization can reduce potential
safety risks while optimizing phenotypic activity, thereby increasing the
likelihood of clinical success. Therefore, we propose a fragment-masked
molecular optimization method based on PDD (FMOP). FMOP employs a
regression-free diffusion model to conditionally optimize the molecular masked
regions without training, effectively generating new molecules with similar
scaffolds. On the large-scale drug response dataset GDSCv2, we optimize the
potential molecules across all 945 cell lines. The overall experiments
demonstrate that the in-silico optimization success rate reaches 94.4%, with an
average efficacy increase of 5.3%. Additionally, we conduct extensive ablation
and visualization experiments, confirming that FMOP is an effective and robust
molecular optimization method. The code is available
at:https://anonymous.4open.science/r/FMOP-98C2.

摘要：分子優化是藥物發現的關鍵面向，旨在優化分子結構以增強藥物效能並將副作用降至最低，最終加速整體藥物開發流程。許多基於標靶的分子優化方法已被提出，大幅推進了藥物發現。這些方法主要在於了解特定藥物標靶結構或其在對抗疾病中假設的角色。然而，諸如可用標靶數量有限以及難以擷取明確結構等挑戰阻礙了創新藥物開發。相比之下，表型藥物發現 (PDD) 不依賴明確的標靶結構，並且可以識別具有新穎且無偏向多重藥理特徵的先導化合物。因此，基於 PDD 的分子優化可以降低潛在的安全風險，同時優化表型活性，從而增加臨床成功的可能性。因此，我們提出了一種基於 PDD 的片段遮罩分子優化方法 (FMOP)。FMOP 採用無回歸擴散模型在沒有訓練的情況下有條件地優化分子遮罩區域，有效地產生具有類似骨架的新分子。在大型藥物反應數據集 GDSCv2 上，我們優化了所有 945 種細胞系中的潛在分子。整體實驗表明，電腦模擬優化成功率達到 94.4%，平均療效提升 5.3%。此外，我們進行了廣泛的消融和視覺化實驗，證實 FMOP 是一種有效且穩健的分子優化方法。程式碼可於以下網址取得：https://anonymous.4open.science/r/FMOP-98C2。

##### **Improving VTE Identification through Language Models from Radiology Reports: A Comparative Study of Mamba, Phi-3 Mini, and BERT**
2408.09043v1 by Jamie Deng, Yusen Wu, Yelena Yesha, Phuong Nguyen

Venous thromboembolism (VTE) is a critical cardiovascular condition,
encompassing deep vein thrombosis (DVT) and pulmonary embolism (PE). Accurate
and timely identification of VTE is essential for effective medical care. This
study builds upon our previous work, which addressed VTE detection using deep
learning methods for DVT and a hybrid approach combining deep learning and
rule-based classification for PE. Our earlier approaches, while effective, had
two major limitations: they were complex and required expert involvement for
feature engineering of the rule set. To overcome these challenges, we utilize
the Mamba architecture-based classifier. This model achieves remarkable
results, with a 97\% accuracy and F1 score on the DVT dataset and a 98\%
accuracy and F1 score on the PE dataset. In contrast to the previous hybrid
method on PE identification, the Mamba classifier eliminates the need for
hand-engineered rules, significantly reducing model complexity while
maintaining comparable performance. Additionally, we evaluated a lightweight
Large Language Model (LLM), Phi-3 Mini, in detecting VTE. While this model
delivers competitive results, outperforming the baseline BERT models, it proves
to be computationally intensive due to its larger parameter set. Our evaluation
shows that the Mamba-based model demonstrates superior performance and
efficiency in VTE identification, offering an effective solution to the
limitations of previous approaches.

摘要：靜脈血栓栓塞症 (VTE) 是一種危急的心血管疾病，包括深層靜脈血栓 (DVT) 和肺栓塞 (PE)。準確及時地識別 VTE 對於有效的醫療照護至關重要。本研究建立在我們先前的研究之上，該研究使用深度學習方法針對 DVT 進行 VTE 偵測，並結合深度學習和基於規則的分類，針對 PE 採用混合方法。我們較早的方法雖然有效，但有兩個主要的限制：它們很複雜，並且需要專家參與規則集的特徵工程。為了克服這些挑戰，我們利用了基於 Mamba 架構的分類器。此模型取得了顯著的成果，在 DVT 資料集上獲得了 97% 的準確率和 F1 分數，在 PE 資料集上獲得了 98% 的準確率和 F1 分數。與先前的 PE 識別混合方法相比，Mamba 分類器消除了對人工規則的需求，顯著降低了模型複雜度，同時保持了可比較的性能。此外，我們評估了一個輕量級的大語言模型 (LLM) Phi-3 Mini，用於檢測 VTE。雖然此模型提供了有競爭力的結果，優於基準 BERT 模型，但由於其較大的參數集，證明其在計算上很密集。我們的評估表明，基於 Mamba 的模型在 VTE 識別中展現了卓越的性能和效率，為先前方法的限制提供了有效的解決方案。

##### **A Disease-Specific Foundation Model Using Over 100K Fundus Images: Release and Validation for Abnormality and Multi-Disease Classification on Downstream Tasks**
2408.08790v1 by Boa Jang, Youngbin Ahn, Eun Kyung Choe, Chang Ki Yoon, Hyuk Jin Choi, Young-Gon Kim

Artificial intelligence applied to retinal images offers significant
potential for recognizing signs and symptoms of retinal conditions and
expediting the diagnosis of eye diseases and systemic disorders. However,
developing generalized artificial intelligence models for medical data often
requires a large number of labeled images representing various disease signs,
and most models are typically task-specific, focusing on major retinal
diseases. In this study, we developed a Fundus-Specific Pretrained Model
(Image+Fundus), a supervised artificial intelligence model trained to detect
abnormalities in fundus images. A total of 57,803 images were used to develop
this pretrained model, which achieved superior performance across various
downstream tasks, indicating that our proposed model outperforms other general
methods. Our Image+Fundus model offers a generalized approach to improve model
performance while reducing the number of labeled datasets required.
Additionally, it provides more disease-specific insights into fundus images,
with visualizations generated by our model. These disease-specific foundation
models are invaluable in enhancing the performance and efficiency of deep
learning models in the field of fundus imaging.

摘要：人工智慧應用於視網膜影像，在辨識視網膜病變的徵兆和症狀，以及加速診斷眼疾和全身性疾病方面，有顯著的潛力。然而，為醫療資料開發廣泛的人工智慧模型，通常需要大量代表各種疾病徵兆的標籤影像，而且大多數模型通常是針對特定任務，專注於主要的視網膜疾病。在這項研究中，我們開發了眼底專用預訓練模型 (影像 + 眼底)，這是一個監督式的人工智慧模型，訓練用於偵測眼底影像中的異常。總共使用了 57,803 張影像來開發這個預訓練模型，它在各種下游任務中都達到了卓越的效能，這表示我們提出的模型優於其他一般方法。我們的影像 + 眼底模型提供了一種廣泛的方法來改善模型效能，同時減少所需的標籤資料集數量。此外，它還透過我們的模型產生的視覺化，提供了更多針對眼底影像的特定疾病見解。這些特定疾病基礎模型對於增強眼底影像領域中深度學習模型的效能和效率至關重要。

##### **Beyond the Hype: A dispassionate look at vision-language models in medical scenario**
2408.08704v1 by Yang Nan, Huichi Zhou, Xiaodan Xing, Guang Yang

Recent advancements in Large Vision-Language Models (LVLMs) have demonstrated
remarkable capabilities across diverse tasks, garnering significant attention
in AI communities. However, their performance and reliability in specialized
domains such as medicine remain insufficiently assessed. In particular, most
assessments over-concentrate in evaluating VLMs based on simple Visual Question
Answering (VQA) on multi-modality data, while ignoring the in-depth
characteristic of LVLMs. In this study, we introduce RadVUQA, a novel
Radiological Visual Understanding and Question Answering benchmark, to
comprehensively evaluate existing LVLMs. RadVUQA mainly validates LVLMs across
five dimensions: 1) Anatomical understanding, assessing the models' ability to
visually identify biological structures; 2) Multimodal comprehension, which
involves the capability of interpreting linguistic and visual instructions to
produce desired outcomes; 3) Quantitative and spatial reasoning, evaluating the
models' spatial awareness and proficiency in combining quantitative analysis
with visual and linguistic information; 4) Physiological knowledge, measuring
the models' capability to comprehend functions and mechanisms of organs and
systems; and 5) Robustness, which assesses the models' capabilities against
unharmonised and synthetic data. The results indicate that both generalized
LVLMs and medical-specific LVLMs have critical deficiencies with weak
multimodal comprehension and quantitative reasoning capabilities. Our findings
reveal the large gap between existing LVLMs and clinicians, highlighting the
urgent need for more robust and intelligent LVLMs. The code and dataset will be
available after the acceptance of this paper.

摘要：近期大型视觉语言模型 (LVLMs) 的进步已展示了各种任务的非凡能力，在人工智能社群中备受关注。然而，它们在医学等专业领域的效能和可靠性仍未得到充分评估。特别是，大多数评估都过于集中在基于多模态数据进行简单视觉问答 (VQA) 来评估 VLM，而忽略了 VLM 的深入特征。本研究中，我们引入了 RadVUQA，这是一个新颖的放射视觉理解和问答基准，以全面评估现有的 VLM。RadVUQA 主要从五个维度验证 VLM：1) 解剖理解，评估模型视觉识别生物结构的能力；2) 多模态理解，涉及解释语言和视觉指令以产生预期结果的能力；3) 定量和空间推理，评估模型的空间意识和结合定量分析与视觉和语言信息的能力；4) 生理知识，衡量模型理解器官和系统功能和机制的能力；5) 鲁棒性，评估模型对不和谐和合成数据的处理能力。结果表明，通用 VLM 和医学专用 VLM 都存在严重的缺陷，多模态理解和定量推理能力较弱。我们的研究结果揭示了现有 VLM 和临床医生之间存在巨大差距，强调了对更强大和更智能的 VLM 的迫切需求。本文被接受后，代码和数据集将可供使用。

##### **TextCAVs: Debugging vision models using text**
2408.08652v1 by Angus Nicolson, Yarin Gal, J. Alison Noble

Concept-based interpretability methods are a popular form of explanation for
deep learning models which provide explanations in the form of high-level human
interpretable concepts. These methods typically find concept activation vectors
(CAVs) using a probe dataset of concept examples. This requires labelled data
for these concepts -- an expensive task in the medical domain. We introduce
TextCAVs: a novel method which creates CAVs using vision-language models such
as CLIP, allowing for explanations to be created solely using text descriptions
of the concept, as opposed to image exemplars. This reduced cost in testing
concepts allows for many concepts to be tested and for users to interact with
the model, testing new ideas as they are thought of, rather than a delay caused
by image collection and annotation. In early experimental results, we
demonstrate that TextCAVs produces reasonable explanations for a chest x-ray
dataset (MIMIC-CXR) and natural images (ImageNet), and that these explanations
can be used to debug deep learning-based models.

摘要：基於概念的可解釋方法是一種流行的深度學習模型解釋形式，它以高階人類可解釋概念的形式提供解釋。這些方法通常使用概念範例探測資料集來尋找概念啟動向量 (CAV)。這需要標記這些概念的資料，這在醫學領域是一項昂貴的任務。我們介紹 TextCAV：一種使用視覺語言模型（例如 CLIP）建立 CAV 的新方法，它允許僅使用概念的文字描述來建立解釋，而不是影像範例。測試概念的成本降低，允許測試許多概念，並讓使用者與模型互動，在想到新想法時進行測試，而不是因影像收集和註解而造成的延遲。在早期的實驗結果中，我們證明 TextCAV 為胸部 X 光資料集 (MIMIC-CXR) 和自然影像 (ImageNet) 產生合理的解釋，並且這些解釋可用於偵錯基於深度學習的模型。

##### **RealMedQA: A pilot biomedical question answering dataset containing realistic clinical questions**
2408.08624v1 by Gregory Kell, Angus Roberts, Serge Umansky, Yuti Khare, Najma Ahmed, Nikhil Patel, Chloe Simela, Jack Coumbe, Julian Rozario, Ryan-Rhys Griffiths, Iain J. Marshall

Clinical question answering systems have the potential to provide clinicians
with relevant and timely answers to their questions. Nonetheless, despite the
advances that have been made, adoption of these systems in clinical settings
has been slow. One issue is a lack of question-answering datasets which reflect
the real-world needs of health professionals. In this work, we present
RealMedQA, a dataset of realistic clinical questions generated by humans and an
LLM. We describe the process for generating and verifying the QA pairs and
assess several QA models on BioASQ and RealMedQA to assess the relative
difficulty of matching answers to questions. We show that the LLM is more
cost-efficient for generating "ideal" QA pairs. Additionally, we achieve a
lower lexical similarity between questions and answers than BioASQ which
provides an additional challenge to the top two QA models, as per the results.
We release our code and our dataset publicly to encourage further research.

摘要：臨床問答系統具有提供臨床醫生相關且及時的答案的潛力。儘管如此，儘管取得了進展，但在臨床環境中採用這些系統的速度很慢。一個問題是缺乏反映醫療專業人員現實需求的問答資料集。在這項工作中，我們提出了 RealMedQA，這是一個由人類和 LLM 生成的現實臨床問題資料集。我們描述了生成和驗證 QA 對的過程，並在 BioASQ 和 RealMedQA 上評估了幾個 QA 模型，以評估將答案與問題匹配的相對難度。我們表明，LLM 在生成「理想」的 QA 對方面更具成本效益。此外，我們在問題和答案之間實現了比 BioASQ 更低的詞彙相似性，根據結果，這對前兩個 QA 模型提出了額外的挑戰。我們公開發布我們的程式碼和資料集，以鼓勵進一步的研究。

##### **Focus on Focus: Focus-oriented Representation Learning and Multi-view Cross-modal Alignment for Glioma Grading**
2408.08527v1 by Li Pan, Yupei Zhang, Qiushi Yang, Tan Li, Xiaohan Xing, Maximus C. F. Yeung, Zhen Chen

Recently, multimodal deep learning, which integrates histopathology slides
and molecular biomarkers, has achieved a promising performance in glioma
grading. Despite great progress, due to the intra-modality complexity and
inter-modality heterogeneity, existing studies suffer from inadequate
histopathology representation learning and inefficient molecular-pathology
knowledge alignment. These two issues hinder existing methods to precisely
interpret diagnostic molecular-pathology features, thereby limiting their
grading performance. Moreover, the real-world applicability of existing
multimodal approaches is significantly restricted as molecular biomarkers are
not always available during clinical deployment. To address these problems, we
introduce a novel Focus on Focus (FoF) framework with paired pathology-genomic
training and applicable pathology-only inference, enhancing molecular-pathology
representation effectively. Specifically, we propose a Focus-oriented
Representation Learning (FRL) module to encourage the model to identify regions
positively or negatively related to glioma grading and guide it to focus on the
diagnostic areas with a consistency constraint. To effectively link the
molecular biomarkers to morphological features, we propose a Multi-view
Cross-modal Alignment (MCA) module that projects histopathology representations
into molecular subspaces, aligning morphological features with corresponding
molecular biomarker status by supervised contrastive learning. Experiments on
the TCGA GBM-LGG dataset demonstrate that our FoF framework significantly
improves the glioma grading. Remarkably, our FoF achieves superior performance
using only histopathology slides compared to existing multimodal methods. The
source code is available at https://github.com/peterlipan/FoF.

摘要：<paragraph>最近，整合了组织病理学切片和分子生物标记的多模态深度学习在神经胶质瘤分级中取得了可喜的成果。尽管取得了巨大进展，但由于模态内复杂性和模态间异质性，现有研究存在组织病理学表征学习不足和分子病理学知识对齐效率低下的问题。这两个问题阻碍了现有方法精确解释诊断性分子病理学特征，从而限制了它们的评分性能。此外，现有多模态方法的实际适用性受到很大限制，因为在临床部署期间并不总是能获得分子生物标记。为了解决这些问题，我们引入了一个专注于焦点 (FoF) 的新框架，该框架采用配对的病理基因组学训练和适用的仅病理学推断，有效地增强了分子病理学表征。具体来说，我们提出了一个面向焦点的表征学习 (FRL) 模块，以鼓励模型识别与神经胶质瘤分级呈正相关或负相关的区域，并指导其专注于具有稠密约束的诊断区域。为了有效地将分子生物标记与形态学特征联系起来，我们提出了一个多视图跨模态对齐 (MCA) 模块，该模块将组织病理学表征投影到分子子空间，通过监督对比学习将形态学特征与相应的分子生物标记状态对齐。在 TCGA GBM-LGG 数据集上的实验表明，我们的 FoF 框架显着提高了神经胶质瘤分级。值得注意的是，与现有的多模态方法相比，我们的 FoF 仅使用组织病理学切片就取得了优异的性能。源代码可在 https://github.com/peterlipan/FoF 获得。</paragraph>

##### **Adversarial Contrastive Learning Based Physics-Informed Temporal Networks for Cuffless Blood Pressure Estimation**
2408.08488v1 by Rui Wang, Mengshi Qi, Yingxia Shao, Anfu Zhou, Huadong Ma

Time series data mining is immensely important in extensive applications,
such as traffic, medical, and e-commerce. In this paper, we focus on medical
temporal variation modeling, \emph{i.e.,} cuffless blood pressure (BP)
monitoring which has great value in cardiovascular healthcare. Although
providing a comfortable user experience, such methods are suffering from the
demand for a significant amount of realistic data to train an individual model
for each subject, especially considering the invasive or obtrusive BP
ground-truth measurements. To tackle this challenge, we introduce a novel
physics-informed temporal network~(PITN) with adversarial contrastive learning
to enable precise BP estimation with very limited data. Specifically, we first
enhance the physics-informed neural network~(PINN) with the temporal block for
investigating BP dynamics' multi-periodicity for personal cardiovascular cycle
modeling and temporal variation. We then employ adversarial training to
generate extra physiological time series data, improving PITN's robustness in
the face of sparse subject-specific training data. Furthermore, we utilize
contrastive learning to capture the discriminative variations of cardiovascular
physiologic phenomena. This approach aggregates physiological signals with
similar blood pressure values in latent space while separating clusters of
samples with dissimilar blood pressure values. Experiments on three
widely-adopted datasets with different modailties (\emph{i.e.,} bioimpedance,
PPG, millimeter-wave) demonstrate the superiority and effectiveness of the
proposed methods over previous state-of-the-art approaches. The code is
available at~\url{https://github.com/Zest86/ACL-PITN}.

摘要：<paragraph>時間序列資料探勘在廣泛的應用中非常重要，例如交通、醫療和電子商務。在本文中，我們專注於醫療時間變異建模，即無袖血壓 (BP) 監測，這在心血管保健中具有極高的價值。儘管提供了舒適的使用者體驗，但此類方法卻苦於需要大量的實際資料來訓練每個受試者的個別模型，特別是考慮到侵入性或侵入性的 BP 真實測量。為了應對這一挑戰，我們引入了一個新的物理資訊時間網路 (PITN)，並結合對抗對比學習，以極少的資料進行精確的 BP 估計。具體來說，我們首先使用時間區塊增強了物理資訊神經網路 (PINN)，以研究 BP 動態的多週期性，用於個人心血管週期建模和時間變異。然後，我們採用對抗訓練來產生額外的生理時間序列資料，以提高 PITN 在稀疏受試者特定訓練資料面前的魯棒性。此外，我們利用對比學習來捕捉心血管生理現象的區別性變異。此方法將潛在空間中具有類似血壓值的生理訊號聚集在一起，同時將具有不同血壓值的樣本叢集分開。在三個廣泛採用的具有不同模態的資料集（即生物阻抗、PPG、毫米波）上的實驗證明了所提出的方法優於先前的最先進方法。程式碼可在~\url{https://github.com/Zest86/ACL-PITN}取得。</paragraph>

##### **Efficient Data-Sketches and Fine-Tuning for Early Detection of Distributional Drift in Medical Imaging**
2408.08456v1 by Yusen Wu, Hao Chen, Alex Pissinou Makki, Phuong Nguyen, Yelena Yesha

Distributional drift detection is important in medical applications as it
helps ensure the accuracy and reliability of models by identifying changes in
the underlying data distribution that could affect diagnostic or treatment
decisions. However, current methods have limitations in detecting drift; for
example, the inclusion of abnormal datasets can lead to unfair comparisons.
This paper presents an accurate and sensitive approach to detect distributional
drift in CT-scan medical images by leveraging data-sketching and fine-tuning
techniques. We developed a robust baseline library model for real-time anomaly
detection, allowing for efficient comparison of incoming images and
identification of anomalies. Additionally, we fine-tuned a vision transformer
pre-trained model to extract relevant features using breast cancer images as an
example, significantly enhancing model accuracy to 99.11\%. Combining with
data-sketches and fine-tuning, our feature extraction evaluation demonstrated
that cosine similarity scores between similar datasets provide greater
improvements, from around 50\% increased to 100\%. Finally, the sensitivity
evaluation shows that our solutions are highly sensitive to even 1\%
salt-and-pepper and speckle noise, and it is not sensitive to lighting noise
(e.g., lighting conditions have no impact on data drift). The proposed methods
offer a scalable and reliable solution for maintaining the accuracy of
diagnostic models in dynamic clinical environments.

摘要：分配漂移检测在医疗应用中很重要，因为它
有助于确保模型的准确性和可靠性，方法是识别可能影响诊断或治疗的底层数据分布的变化
决定。然而，当前的方法在检测漂移方面存在局限性；例如，异常数据集的包含会导致不公平的比较。
本文提出了一种准确且敏感的方法来检测 CT 扫描医学图像中的分布漂移，方法是利用数据草图和微调
技术。我们开发了一个稳健的基线库模型，用于实时异常检测，允许对传入图像进行高效比较和
识别异常。此外，我们对视觉转换器预训练模型进行了微调，以使用乳腺癌图像作为示例提取相关特征，显着提高了模型准确率至 99.11%。结合
数据草图和微调，我们的特征提取评估表明，相似数据集之间的余弦相似度得分提供了更大的
改进，从增加约 50% 到 100%。最后，敏感性评估表明我们的解决方案对 1% 的椒盐噪声和斑点噪声高度敏感，并且对光照噪声不敏感
（例如，光照条件对数据漂移没有影响）。所提出的方法为保持诊断模型的准确性提供了一个可扩展且可靠的解决方案
在动态临床环境中。

##### **Predictive uncertainty estimation in deep learning for lung carcinoma classification in digital pathology under real dataset shifts**
2408.08432v1 by Abdur R. Fayjie, Jutika Borah, Florencia Carbone, Jan Tack, Patrick Vandewalle

Deep learning has shown tremendous progress in a wide range of digital
pathology and medical image classification tasks. Its integration into safe
clinical decision-making support requires robust and reliable models. However,
real-world data comes with diversities that often lie outside the intended
source distribution. Moreover, when test samples are dramatically different,
clinical decision-making is greatly affected. Quantifying predictive
uncertainty in models is crucial for well-calibrated predictions and
determining when (or not) to trust a model. Unfortunately, many works have
overlooked the importance of predictive uncertainty estimation. This paper
evaluates whether predictive uncertainty estimation adds robustness to deep
learning-based diagnostic decision-making systems. We investigate the effect of
various carcinoma distribution shift scenarios on predictive performance and
calibration. We first systematically investigate three popular methods for
improving predictive uncertainty: Monte Carlo dropout, deep ensemble, and
few-shot learning on lung adenocarcinoma classification as a primary disease in
whole slide images. Secondly, we compare the effectiveness of the methods in
terms of performance and calibration under clinically relevant distribution
shifts such as in-distribution shifts comprising primary disease sub-types and
other characterization analysis data; out-of-distribution shifts comprising
well-differentiated cases, different organ origin, and imaging modality shifts.
While studies on uncertainty estimation exist, to our best knowledge, no
rigorous large-scale benchmark compares predictive uncertainty estimation
including these dataset shifts for lung carcinoma classification.

摘要：深度學習在廣泛的數位病理學和醫學影像分類任務中展現出驚人的進展。它整合到安全的臨床決策支援中需要強健且可靠的模型。然而，真實世界的資料會伴隨著多樣性，而這些多樣性通常超出了預期的來源分佈。此外，當測試樣本有極大的不同時，臨床決策制定會受到很大的影響。量化模型中的預測不確定性對於校準良好的預測以及決定何時（或不）信任模型至關重要。不幸的是，許多作品都忽略了預測不確定性估計的重要性。本文評估預測不確定性估計是否能為基於深度學習的診斷決策制定系統增加穩健性。我們探討各種癌症分佈轉移情境對預測效能和校準的影響。我們首先系統性地探討三種改善預測不確定性的熱門方法：蒙地卡羅輟學、深度整體和少次學習，以肺腺癌分類為主要疾病，在全幻燈片影像中進行。其次，我們比較這些方法在效能和校準方面的有效性，在臨床上相關的分佈轉移中，例如包含主要疾病子類型和其他表徵分析資料的分布內轉移；包含分化良好的病例、不同的器官來源和影像方式轉移的分布外轉移。儘管有關於不確定性估計的研究，但據我們所知，沒有嚴謹的大規模基準比較預測不確定性估計，包括這些資料集轉移以進行肺癌分類。

##### **Assessing and Enhancing Large Language Models in Rare Disease Question-answering**
2408.08422v1 by Guanchu Wang, Junhao Ran, Ruixiang Tang, Chia-Yuan Chang, Chia-Yuan Chang, Yu-Neng Chuang, Zirui Liu, Vladimir Braverman, Zhandong Liu, Xia Hu

Despite the impressive capabilities of Large Language Models (LLMs) in
general medical domains, questions remain about their performance in diagnosing
rare diseases. To answer this question, we aim to assess the diagnostic
performance of LLMs in rare diseases, and explore methods to enhance their
effectiveness in this area. In this work, we introduce a rare disease
question-answering (ReDis-QA) dataset to evaluate the performance of LLMs in
diagnosing rare diseases. Specifically, we collected 1360 high-quality
question-answer pairs within the ReDis-QA dataset, covering 205 rare diseases.
Additionally, we annotated meta-data for each question, facilitating the
extraction of subsets specific to any given disease and its property. Based on
the ReDis-QA dataset, we benchmarked several open-source LLMs, revealing that
diagnosing rare diseases remains a significant challenge for these models.
  To facilitate retrieval augmentation generation for rare disease diagnosis,
we collect the first rare diseases corpus (ReCOP), sourced from the National
Organization for Rare Disorders (NORD) database. Specifically, we split the
report of each rare disease into multiple chunks, each representing a different
property of the disease, including their overview, symptoms, causes, effects,
related disorders, diagnosis, and standard therapies. This structure ensures
that the information within each chunk aligns consistently with a question.
Experiment results demonstrate that ReCOP can effectively improve the accuracy
of LLMs on the ReDis-QA dataset by an average of 8%. Moreover, it significantly
guides LLMs to generate trustworthy answers and explanations that can be traced
back to existing literature.

摘要：儘管大型語言模型 (LLM) 在一般醫學領域擁有令人印象深刻的能力，但對於它們在診斷罕見疾病方面的表現仍有疑問。為了回答這個問題，我們旨在評估 LLM 在罕見疾病中的診斷表現，並探討增強它們在這個領域的有效性的方法。在這項工作中，我們引入了一個罕見疾病問答 (ReDis-QA) 資料集，以評估 LLM 在診斷罕見疾病方面的表現。具體來說，我們在 ReDis-QA 資料集中收集了 1360 個高品質的問題解答對，涵蓋 205 種罕見疾病。此外，我們為每個問題註釋了元資料，以利於提取特定於任何給定疾病及其屬性的子集。根據 ReDis-QA 資料集，我們對幾個開源 LLM 進行了基準測試，結果表明診斷罕見疾病仍然是這些模型的一項重大挑戰。為了促進罕見疾病診斷的檢索增強生成，我們收集了第一個罕見疾病語料庫 (ReCOP)，其來源於國家罕見疾病組織 (NORD) 資料庫。具體來說，我們將每種罕見疾病的報告分成多個區塊，每個區塊代表疾病的不同屬性，包括其概述、症狀、原因、影響、相關疾病、診斷和標準療法。這種結構確保每個區塊中的資訊與問題保持一致。實驗結果表明，ReCOP 可以有效地將 LLM 在 ReDis-QA 資料集上的準確度平均提高 8%。此外，它顯著地引導 LLM 生成可信的答案和解釋，這些答案和解釋可以追溯到現有文獻。

##### **Decoding the human brain tissue response to radiofrequency excitation using a biophysical-model-free deep MRI on a chip framework**
2408.08376v2 by Dinor Nagar, Moritz Zaiss, Or Perlman

Magnetic resonance imaging (MRI) relies on radiofrequency (RF) excitation of
proton spin. Clinical diagnosis requires a comprehensive collation of
biophysical data via multiple MRI contrasts, acquired using a series of RF
sequences that lead to lengthy examinations. Here, we developed a vision
transformer-based framework that captures the spatiotemporal magnetic signal
evolution and decodes the brain tissue response to RF excitation, constituting
an MRI on a chip. Following a per-subject rapid calibration scan (28.2 s), a
wide variety of image contrasts including fully quantitative molecular, water
relaxation, and magnetic field maps can be generated automatically. The method
was validated across healthy subjects and a cancer patient in two different
imaging sites, and proved to be 94% faster than alternative protocols. The deep
MRI on a chip (DeepMonC) framework may reveal the molecular composition of the
human brain tissue in a wide range of pathologies, while offering clinically
attractive scan times.

摘要：磁振造影 (MRI) 仰賴射頻 (RF) 激發質子自旋。臨床診斷需要透過多種 MRI 對比，收集全面的生物物理資料，使用一系列 RF 序列取得，這會導致檢查時間冗長。在此，我們開發了一個基於視覺轉換器的架構，用來擷取時空磁訊號演變，並解碼腦組織對 RF 激發的反應，構成晶片上的 MRI。在每位受試者進行快速校正掃描 (28.2 秒) 之後，可以自動產生各種影像對比，包括完全量化的分子、水弛緩和磁場圖。此方法已在兩個不同的影像地點針對健康受試者和一名癌症患者進行驗證，並證明比替代方案快 94%。晶片上的深度 MRI (DeepMonC) 架構可能會揭示各種病理中人腦組織的分子組成，同時提供臨床上有吸引力的掃描時間。

##### **InVAErt networks for amortized inference and identifiability analysis of lumped parameter hemodynamic models**
2408.08264v1 by Guoxiang Grayson Tong, Carlos A. Sing Long, Daniele E. Schiavazzi

Estimation of cardiovascular model parameters from electronic health records
(EHR) poses a significant challenge primarily due to lack of identifiability.
Structural non-identifiability arises when a manifold in the space of
parameters is mapped to a common output, while practical non-identifiability
can result due to limited data, model misspecification, or noise corruption. To
address the resulting ill-posed inverse problem, optimization-based or Bayesian
inference approaches typically use regularization, thereby limiting the
possibility of discovering multiple solutions. In this study, we use inVAErt
networks, a neural network-based, data-driven framework for enhanced digital
twin analysis of stiff dynamical systems. We demonstrate the flexibility and
effectiveness of inVAErt networks in the context of physiological inversion of
a six-compartment lumped parameter hemodynamic model from synthetic data to
real data with missing components.

摘要：從電子健康紀錄 (EHR) 估計心血管模型參數主要由於缺乏可識別性而構成重大挑戰。
當參數空間中的流形對應到共同輸出時，會產生結構性不可識別性，而由於資料有限、模型錯誤規範或雜訊破壞，可能會導致實際不可識別性。為了解決由此產生的不適定反問題，基於最佳化的貝氏推論方法通常使用正則化，從而限制發現多重解的可能性。在本研究中，我們使用 inVAErt 網路，這是一種基於神經網路、資料驅動的架構，用於增強僵硬動態系統的數位雙胞胎分析。我們展示了 inVAErt 網路在生理反演中的靈活性與有效性，從合成資料到缺少組成的真實資料，反演六隔間集總參數血流動力模型。

##### **Your Turn: Real-World Turning Angle Estimation for Parkinson's Disease Severity Assessment**
2408.08182v1 by Qiushuo Cheng, Catherine Morgan, Arindam Sikdar, Alessandro Masullo, Alan Whone, Majid Mirmehdi

People with Parkinson's Disease (PD) often experience progressively worsening
gait, including changes in how they turn around, as the disease progresses.
Existing clinical rating tools are not capable of capturing hour-by-hour
variations of PD symptoms, as they are confined to brief assessments within
clinic settings. Measuring real-world gait turning angles continuously and
passively is a component step towards using gait characteristics as sensitive
indicators of disease progression in PD. This paper presents a deep
learning-based approach to automatically quantify turning angles by extracting
3D skeletons from videos and calculating the rotation of hip and knee joints.
We utilise state-of-the-art human pose estimation models, Fastpose and Strided
Transformer, on a total of 1386 turning video clips from 24 subjects (12 people
with PD and 12 healthy control volunteers), trimmed from a PD dataset of
unscripted free-living videos in a home-like setting (Turn-REMAP). We also
curate a turning video dataset, Turn-H3.6M, from the public Human3.6M human
pose benchmark with 3D ground truth, to further validate our method. Previous
gait research has primarily taken place in clinics or laboratories evaluating
scripted gait outcomes, but this work focuses on real-world settings where
complexities exist, such as baggy clothing and poor lighting. Due to
difficulties in obtaining accurate ground truth data in a free-living setting,
we quantise the angle into the nearest bin $45^\circ$ based on the manual
labelling of expert clinicians. Our method achieves a turning calculation
accuracy of 41.6%, a Mean Absolute Error (MAE) of 34.7{\deg}, and a weighted
precision WPrec of 68.3% for Turn-REMAP. This is the first work to explore the
use of single monocular camera data to quantify turns by PD patients in a home
setting.

摘要：帕金森氏症 (PD) 患者经常会随着疾病的进展而出现步态逐渐恶化的现象，包括转身方式的变化。现有的临床评定工具无法捕捉到 PD 症状逐小时的变化，因为它们仅限于在临床环境中进行短暂的评估。连续被动地测量现实世界中的步态转弯角度是将步态特征用作 PD 疾病进展的敏感指标的组成部分。本文提出了一种基于深度学习的方法，通过从视频中提取 3D 骨架并计算髋关节和膝关节的旋转，自动量化转弯角度。我们对来自 24 个受试者（12 名 PD 患者和 12 名健康对照志愿者）的总共 1386 个转弯视频剪辑使用了最先进的人体姿势估计模型 Fastpose 和 Strided Transformer，这些剪辑是从家庭环境中无脚本自由生活视频的 PD 数据集（Turn-REMAP）中截取的。我们还从具有 3D 真实的公共 Human3.6M 人体姿势基准中整理了一个转弯视频数据集 Turn-H3.6M，以进一步验证我们的方法。以往的步态研究主要在评估脚本化步态结果的诊所或实验室中进行，但这项工作重点关注存在复杂性的现实世界环境，例如宽松的衣服和光线不足。由于在自由生活环境中难以获得准确的真实数据，我们根据专家临床医生的手动标记，将角度量化为最接近的箱 $45^\circ$。我们的方法对 Turn-REMAP 的转弯计算准确度达到 41.6%，平均绝对误差 (MAE) 为 34.7{\deg}，加权精度 WPrec 为 68.3%。这是首次探索使用单目单眼相机数据来量化 PD 患者在家中转弯情况的工作。

##### **Navigating Data Scarcity using Foundation Models: A Benchmark of Few-Shot and Zero-Shot Learning Approaches in Medical Imaging**
2408.08058v1 by Stefano Woerner, Christian F. Baumgartner

Data scarcity is a major limiting factor for applying modern machine learning
techniques to clinical tasks. Although sufficient data exists for some
well-studied medical tasks, there remains a long tail of clinically relevant
tasks with poor data availability. Recently, numerous foundation models have
demonstrated high suitability for few-shot learning (FSL) and zero-shot
learning (ZSL), potentially making them more accessible to practitioners.
However, it remains unclear which foundation model performs best on FSL medical
image analysis tasks and what the optimal methods are for learning from limited
data. We conducted a comprehensive benchmark study of ZSL and FSL using 16
pretrained foundation models on 19 diverse medical imaging datasets. Our
results indicate that BiomedCLIP, a model pretrained exclusively on medical
data, performs best on average for very small training set sizes, while very
large CLIP models pretrained on LAION-2B perform best with slightly more
training samples. However, simply fine-tuning a ResNet-18 pretrained on
ImageNet performs similarly with more than five training examples per class.
Our findings also highlight the need for further research on foundation models
specifically tailored for medical applications and the collection of more
datasets to train these models.

摘要：資料稀少是將現代機器學習技術應用於臨床任務的主要限制因素。儘管對於一些研究完善的醫療任務而言存在足夠的資料，但仍有許多臨床相關任務的資料可用性不佳。最近，許多基礎模型已展現出非常適合小樣本學習 (FSL) 和零樣本學習 (ZSL)，這有可能讓從業人員更容易使用這些模型。然而，目前仍不清楚哪個基礎模型在 FSL 醫學影像分析任務中的表現最佳，以及從有限資料中學習的最佳方法為何。我們針對 16 個預訓練基礎模型在 19 個不同的醫學影像資料集上執行了一項全面的 ZSL 和 FSL 基準研究。我們的結果顯示，一個專門針對醫療資料進行預訓練的模型 BiomedCLIP 在非常小的訓練集大小下表現最佳，而針對 LAION-2B 進行預訓練的非常大型 CLIP 模型在訓練樣本稍多的情況下表現最佳。然而，針對 ImageNet 進行預訓練的 ResNet-18 只要每類別有超過五個訓練範例，其微調表現就類似。我們的發現也凸顯了進一步針對醫療應用量身打造基礎模型以及收集更多資料集來訓練這些模型的研究需求。

##### **Adaptive User Journeys in Pharma E-Commerce with Reinforcement Learning: Insights from SwipeRx**
2408.08024v1 by Ana Fernández del Río, Michael Brennan Leong, Paulo Saraiva, Ivan Nazarov, Aditya Rastogi, Moiz Hassan, Dexian Tang, África Periáñez

This paper introduces a reinforcement learning (RL) platform that enhances
end-to-end user journeys in healthcare digital tools through personalization.
We explore a case study with SwipeRx, the most popular all-in-one app for
pharmacists in Southeast Asia, demonstrating how the platform can be used to
personalize and adapt user experiences. Our RL framework is tested through a
series of experiments with product recommendations tailored to each pharmacy
based on real-time information on their purchasing history and in-app
engagement, showing a significant increase in basket size. By integrating
adaptive interventions into existing mobile health solutions and enriching user
journeys, our platform offers a scalable solution to improve pharmaceutical
supply chain management, health worker capacity building, and clinical decision
and patient care, ultimately contributing to better healthcare outcomes.

摘要：本論文介紹一個強化學習 (RL) 平台，透過個人化來提升醫療保健數位工具中的使用者旅程。我們探討了一個案例研究，對象是東南亞最受歡迎的藥劑師全方位應用程式 SwipeRx，展示如何使用該平台來個人化和調整使用者體驗。我們的 RL 框架透過一系列實驗進行測試，這些實驗根據每個藥局的購買歷程和應用程式互動的即時資訊，提供量身打造的產品推薦，顯示購物籃大小大幅增加。透過將適應性介入整合到現有的行動健康解決方案，並豐富使用者旅程，我們的平台提供了一個可擴充的解決方案來改善製藥供應鏈管理、醫療人員能力建構、臨床決策和患者照護，最終有助於改善醫療保健成果。

##### **LLaVA-Surg: Towards Multimodal Surgical Assistant via Structured Surgical Video Learning**
2408.07981v1 by Jiajie Li, Garrett Skinner, Gene Yang, Brian R Quaranto, Steven D Schwaitzberg, Peter C W Kim, Jinjun Xiong

Multimodal large language models (LLMs) have achieved notable success across
various domains, while research in the medical field has largely focused on
unimodal images. Meanwhile, current general-domain multimodal models for videos
still lack the capabilities to understand and engage in conversations about
surgical videos. One major contributing factor is the absence of datasets in
the surgical field. In this paper, we create a new dataset, Surg-QA, consisting
of 102,000 surgical video-instruction pairs, the largest of its kind so far. To
build such a dataset, we propose a novel two-stage question-answer generation
pipeline with LLM to learn surgical knowledge in a structured manner from the
publicly available surgical lecture videos. The pipeline breaks down the
generation process into two stages to significantly reduce the task complexity,
allowing us to use a more affordable, locally deployed open-source LLM than the
premium paid LLM services. It also mitigates the risk of LLM hallucinations
during question-answer generation, thereby enhancing the overall quality of the
generated data. We further train LLaVA-Surg, a novel vision-language
conversational assistant capable of answering open-ended questions about
surgical videos, on this Surg-QA dataset, and conduct comprehensive evaluations
on zero-shot surgical video question-answering tasks. We show that LLaVA-Surg
significantly outperforms all previous general-domain models, demonstrating
exceptional multimodal conversational skills in answering open-ended questions
about surgical videos. We will release our code, model, and the
instruction-tuning dataset.

摘要：多模態大型語言模型 (LLM) 在各個領域都取得了顯著的成功，而醫學領域的研究則主要集中在單模態影像上。同時，目前的影片通用領域多模態模型仍缺乏理解和參與外科影片對話的能力。主要的影響因素之一是外科領域中缺乏資料集。在本文中，我們建立了一個新的資料集 Surg-QA，其中包含 102,000 個外科影片教學配對，是目前同類資料集中規模最大的。為了建立這樣的資料集，我們提出了一個新穎的兩階段問答產生管道，使用 LLM 以結構化的方式從公開的外科教學影片中學習外科知識。該管道將產生過程分為兩個階段，以顯著降低任務複雜性，使我們能夠使用比付費 LLM 服務更實惠的本地部署開源 LLM。它還減輕了問答產生過程中 LLM 產生幻覺的風險，從而提高了產生資料的整體品質。我們進一步訓練 LLaVA-Surg，這是一個新穎的視覺語言對話助理，能夠回答有關外科影片的開放式問題，並在 Surg-QA 資料集上進行全面的零次學習外科影片問答任務評估。我們展示了 LLaVA-Surg 明顯優於所有先前的通用領域模型，證明了在回答有關外科影片的開放式問題時具有卓越的多模態對話技能。我們將發布我們的程式碼、模型和教學調整資料集。

##### **Enhancing Equitable Access to AI in Housing and Homelessness System of Care through Federated Learning**
2408.07845v1 by Musa Taib, Jiajun Wu, Steve Drew, Geoffrey G. Messier

The top priority of a Housing and Homelessness System of Care (HHSC) is to
connect people experiencing homelessness to supportive housing. An HHSC
typically consists of many agencies serving the same population. Information
technology platforms differ in type and quality between agencies, so their data
are usually isolated from one agency to another. Larger agencies may have
sufficient data to train and test artificial intelligence (AI) tools but
smaller agencies typically do not. To address this gap, we introduce a
Federated Learning (FL) approach enabling all agencies to train a predictive
model collaboratively without sharing their sensitive data. We demonstrate how
FL can be used within an HHSC to provide all agencies equitable access to
quality AI and further assist human decision-makers in the allocation of
resources within HHSC. This is achieved while preserving the privacy of the
people within the data by not sharing identifying information between agencies
without their consent. Our experimental results using real-world HHSC data from
Calgary, Alberta, demonstrate that our FL approach offers comparable
performance with the idealized scenario of training the predictive model with
data fully shared and linked between agencies.

摘要：住房和無家可歸者照護系統 (HHSC) 的首要任務是
將無家可歸者與支持性住房連結起來。HHSC
通常由許多服務於相同族群的機構組成。資訊
技術平台在各個機構之間的類型和品質不同，因此他們的資料
通常彼此孤立。較大型的機構可能擁有足夠的資料來訓練和測試人工智慧 (AI) 工具，但
較小型機構通常沒有。為了解決這個差距，我們引入了一種
聯合式學習 (FL) 方法，讓所有機構都能夠在不分享其敏感資料的情況下共同訓練一個預測
模型。我們展示了 FL 如何在 HHSC 中使用，以提供所有機構公平取得
優質 AI 的機會，並進一步協助人類決策者在 HHSC 內部分配
資源。這是在不經機構同意的情況下，不分享識別資訊的情況下，保護資料中人們的隱私來實現的。我們使用來自
加拿大艾伯塔省卡加利的真實世界 HHSC 資料進行實驗結果顯示，我們的 FL 方法提供與在機構之間完全分享和連結資料的理想預測模型訓練情境相當的
效能。

##### **Deep Learning: a Heuristic Three-stage Mechanism for Grid Searches to Optimize the Future Risk Prediction of Breast Cancer Metastasis Using EHR-based Clinical Data**
2408.07673v2 by Xia Jiang, Yijun Zhou, Chuhan Xu, Adam Brufsky, Alan Wells

A grid search, at the cost of training and testing a large number of models,
is an effective way to optimize the prediction performance of deep learning
models. A challenging task concerning grid search is the time management.
Without a good time management scheme, a grid search can easily be set off as a
mission that will not finish in our lifetime. In this study, we introduce a
heuristic three-stage mechanism for managing the running time of low-budget
grid searches, and the sweet-spot grid search (SSGS) and randomized grid search
(RGS) strategies for improving model prediction performance, in predicting the
5-year, 10-year, and 15-year risk of breast cancer metastasis. We develop deep
feedforward neural network (DFNN) models and optimize them through grid
searches. We conduct eight cycles of grid searches by applying our three-stage
mechanism and SSGS and RGS strategies. We conduct various SHAP analyses
including unique ones that interpret the importance of the DFNN-model
hyperparameters. Our results show that grid search can greatly improve model
prediction. The grid searches we conducted improved the risk prediction of
5-year, 10-year, and 15-year breast cancer metastasis by 18.6%, 16.3%, and
17.3% respectively, over the average performance of all corresponding models we
trained using the RGS strategy. We not only demonstrate best model performance
but also characterize grid searches from various aspects such as their
capabilities of discovering decent models and the unit grid search time. The
three-stage mechanism worked effectively. It made our low-budget grid searches
feasible and manageable, and in the meantime helped improve model prediction
performance. Our SHAP analyses identified both clinical risk factors important
for the prediction of future risk of breast cancer metastasis, and DFNN-model
hyperparameters important to the prediction of performance scores.

摘要：<paragraph>網格搜尋以訓練和測試大量模型為代價，是一種優化深度學習模型預測效能的有效方法。網格搜尋中一項具有挑戰性的任務是時間管理。沒有良好的時間管理機制，網格搜尋很容易被設定為一項在我們有生之年都無法完成的任務。在本研究中，我們介紹了一種啟發式三階段機制，用於管理低預算網格搜尋的執行時間，以及用於改善模型預測效能的最佳點網格搜尋 (SSGS) 和隨機網格搜尋 (RGS) 策略，以預測乳癌轉移的 5 年、10 年和 15 年風險。我們開發了深度前饋神經網路 (DFNN) 模型，並透過網格搜尋對它們進行優化。我們透過應用三階段機制和 SSGS 和 RGS 策略進行了八個週期的網格搜尋。我們進行了各種 SHAP 分析，包括解釋 DFNN 模型超參數重要性的獨特分析。我們的結果顯示網格搜尋可以大幅改善模型預測。我們進行的網格搜尋分別將 5 年、10 年和 15 年乳癌轉移的風險預測改善了 18.6%、16.3% 和 17.3%，優於我們使用 RGS 策略訓練的所有對應模型的平均效能。我們不僅展示了最佳模型效能，還從各種面向描述網格搜尋，例如它們發現良好模型的能力和單元網格搜尋時間。三階段機制有效運作。它使我們的低預算網格搜尋可行且易於管理，同時也有助於改善模型預測效能。我們的 SHAP 分析確定了對預測未來乳癌轉移風險很重要的臨床風險因子，以及對預測效能評分很重要的 DFNN 模型超參數。</paragraph>

##### **Adaptive Behavioral AI: Reinforcement Learning to Enhance Pharmacy Services**
2408.07647v1 by Ana Fernández del Río, Michael Brennan Leong, Paulo Saraiva, Ivan Nazarov, Aditya Rastogi, Moiz Hassan, Dexian Tang, África Periáñez

Pharmacies are critical in healthcare systems, particularly in low- and
middle-income countries. Procuring pharmacists with the right behavioral
interventions or nudges can enhance their skills, public health awareness, and
pharmacy inventory management, ensuring access to essential medicines that
ultimately benefit their patients. We introduce a reinforcement learning
operational system to deliver personalized behavioral interventions through
mobile health applications. We illustrate its potential by discussing a series
of initial experiments run with SwipeRx, an all-in-one app for pharmacists,
including B2B e-commerce, in Indonesia. The proposed method has broader
applications extending beyond pharmacy operations to optimize healthcare
delivery.

摘要：藥局在醫療保健系統中至關重要，特別是在中低收入國家。透過適當的行為介入措施或推動，藥師的技能、公共衛生意識和藥局庫存管理都能獲得提升，確保取得基本藥物，最終使患者受益。我們引進強化學習操作系統，透過行動健康應用程式提供個人化的行為介入措施。我們透過討論一系列與 SwipeRx（一款專為藥師設計的 B2B 電子商務一站式應用程式）執行的初步實驗，來說明其潛力。所提出的方法具有更廣泛的應用，不僅限於藥局作業，還能最佳化醫療保健的提供。

##### **Optimizing HIV Patient Engagement with Reinforcement Learning in Resource-Limited Settings**
2408.07629v1 by África Periáñez, Kathrin Schmitz, Lazola Makhupula, Moiz Hassan, Moeti Moleko, Ana Fernández del Río, Ivan Nazarov, Aditya Rastogi, Dexian Tang

By providing evidence-based clinical decision support, digital tools and
electronic health records can revolutionize patient management, especially in
resource-poor settings where fewer health workers are available and often need
more training. When these tools are integrated with AI, they can offer
personalized support and adaptive interventions, effectively connecting
community health workers (CHWs) and healthcare facilities. The CHARM (Community
Health Access & Resource Management) app is an AI-native mobile app for CHWs.
Developed through a joint partnership of Causal Foundry (CF) and
mothers2mothers (m2m), CHARM empowers CHWs, mainly local women, by streamlining
case management, enhancing learning, and improving communication. This paper
details CHARM's development, integration, and upcoming reinforcement
learning-based adaptive interventions, all aimed at enhancing health worker
engagement, efficiency, and patient outcomes, thereby enhancing CHWs'
capabilities and community health.

摘要：透過提供基於證據的臨床決策支援，數位工具和電子健康記錄可以徹底改變病患管理，特別是在資源貧乏、醫護人員較少且經常需要更多訓練的環境中。當這些工具與 AI 整合時，它們可以提供個人化支援和適應性介入措施，有效地連結社區衛生工作者 (CHW) 和醫療保健機構。CHARM（社區健康存取與資源管理）應用程式是一款專為 CHW 設計的 AI 原生行動應用程式。CHARM 由 Causal Foundry (CF) 和 mothers2mothers (m2m) 透過聯合夥伴關係共同開發，透過簡化個案管理、加強學習和改善溝通，賦予 CHW（主要是當地婦女）權力。本文詳述 CHARM 的開發、整合和即將推出的基於強化學習的適應性介入措施，所有這些都旨在加強醫護人員的參與度、效率和病患的治療結果，從而提升 CHW 的能力和社區健康。

##### **MetaSeg: MetaFormer-based Global Contexts-aware Network for Efficient Semantic Segmentation**
2408.07576v2 by Beoungwoo Kang, Seunghun Moon, Yubin Cho, Hyunwoo Yu, Suk-Ju Kang

Beyond the Transformer, it is important to explore how to exploit the
capacity of the MetaFormer, an architecture that is fundamental to the
performance improvements of the Transformer. Previous studies have exploited it
only for the backbone network. Unlike previous studies, we explore the capacity
of the Metaformer architecture more extensively in the semantic segmentation
task. We propose a powerful semantic segmentation network, MetaSeg, which
leverages the Metaformer architecture from the backbone to the decoder. Our
MetaSeg shows that the MetaFormer architecture plays a significant role in
capturing the useful contexts for the decoder as well as for the backbone. In
addition, recent segmentation methods have shown that using a CNN-based
backbone for extracting the spatial information and a decoder for extracting
the global information is more effective than using a transformer-based
backbone with a CNN-based decoder. This motivates us to adopt the CNN-based
backbone using the MetaFormer block and design our MetaFormer-based decoder,
which consists of a novel self-attention module to capture the global contexts.
To consider both the global contexts extraction and the computational
efficiency of the self-attention for semantic segmentation, we propose a
Channel Reduction Attention (CRA) module that reduces the channel dimension of
the query and key into the one dimension. In this way, our proposed MetaSeg
outperforms the previous state-of-the-art methods with more efficient
computational costs on popular semantic segmentation and a medical image
segmentation benchmark, including ADE20K, Cityscapes, COCO-stuff, and Synapse.
The code is available at https://github.com/hyunwoo137/MetaSeg.

摘要：<paragraph>除了 Transformer 之外，探索如何利用 MetaFormer 的容量非常重要，MetaFormer 是一种对 Transformer 性能改进至关重要的架构。以往的研究仅将其用于主干网络。与以往的研究不同，我们在语义分割任务中更广泛地探索了 Metaformer 架构的容量。我们提出了一个强大的语义分割网络 MetaSeg，它利用了从主干到解码器的 Metaformer 架构。我们的 MetaSeg 表明，MetaFormer 架构在为解码器和主干捕获有用上下文方面发挥了重要作用。此外，最近的分割方法表明，使用基于 CNN 的主干提取空间信息和使用解码器提取全局信息比使用基于 Transformer 的主干和基于 CNN 的解码器更有效。这促使我们采用使用 MetaFormer 块的基于 CNN 的主干，并设计了基于 MetaFormer 的解码器，该解码器包含一个新颖的自注意力模块来捕获全局上下文。为了同时考虑全局上下文提取和语义分割的自注意力的计算效率，我们提出了一种通道缩减注意力 (CRA) 模块，它将查询和键的通道维度缩减为一个维度。通过这种方式，我们提出的 MetaSeg 在流行的语义分割和医学图像分割基准（包括 ADE20K、Cityscapes、COCO-stuff 和 Synapse）上以更有效的计算成本优于以往的最新方法。代码可在 https://github.com/hyunwoo137/MetaSeg 获得。</paragraph>

##### **Multi-task Heterogeneous Graph Learning on Electronic Health Records**
2408.07569v1 by Tsai Hor Chan, Guosheng Yin, Kyongtae Bae, Lequan Yu

Learning electronic health records (EHRs) has received emerging attention
because of its capability to facilitate accurate medical diagnosis. Since the
EHRs contain enriched information specifying complex interactions between
entities, modeling EHRs with graphs is shown to be effective in practice. The
EHRs, however, present a great degree of heterogeneity, sparsity, and
complexity, which hamper the performance of most of the models applied to them.
Moreover, existing approaches modeling EHRs often focus on learning the
representations for a single task, overlooking the multi-task nature of EHR
analysis problems and resulting in limited generalizability across different
tasks. In view of these limitations, we propose a novel framework for EHR
modeling, namely MulT-EHR (Multi-Task EHR), which leverages a heterogeneous
graph to mine the complex relations and model the heterogeneity in the EHRs. To
mitigate the large degree of noise, we introduce a denoising module based on
the causal inference framework to adjust for severe confounding effects and
reduce noise in the EHR data. Additionally, since our model adopts a single
graph neural network for simultaneous multi-task prediction, we design a
multi-task learning module to leverage the inter-task knowledge to regularize
the training process. Extensive empirical studies on MIMIC-III and MIMIC-IV
datasets validate that the proposed method consistently outperforms the
state-of-the-art designs in four popular EHR analysis tasks -- drug
recommendation, and predictions of the length of stay, mortality, and
readmission. Thorough ablation studies demonstrate the robustness of our method
upon variations to key components and hyperparameters.

摘要：<paragraph>學習電子健康紀錄（EHR）由於其促進準確醫療診斷的能力而備受關注。由於 EHR 包含豐富資訊，指定實體之間的複雜互動，因此使用圖形建模 EHR 已被證明在實務上很有效。然而，EHR 呈現出高度的異質性、稀疏性和複雜性，這會阻礙應用於它們的大多數模型的效能。此外，現有的建模 EHR 方法通常專注於學習單一任務的表示，忽略 EHR 分析問題的多任務性質，並導致跨不同任務的概括能力有限。有鑑於這些限制，我們提出了 EHR 建模的新架構，即 MulT-EHR（多任務 EHR），它利用異質圖來挖掘複雜關係並建模 EHR 中的異質性。為了減輕大量的雜訊，我們引入了基於因果推論架構的去雜訊模組，以調整嚴重的混淆效應並減少 EHR 資料中的雜訊。此外，由於我們的模型採用單一圖形神經網路進行同時的多任務預測，因此我們設計了一個多任務學習模組，以利用任務間的知識來規範訓練過程。在 MIMIC-III 和 MIMIC-IV 資料集上的廣泛實證研究驗證了所提出的方法在四項流行的 EHR 分析任務中始終優於最先進的設計——藥物推薦以及預測住院時間、死亡率和再入院率。徹底的消融研究證明了我們的方法在關鍵組成部分和超參數變化上的穩健性。</paragraph>

##### **Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**
2408.07531v1 by Seungjun Han, Wongyung Choi

Emergency department (ED) overcrowding and the complexity of rapid
decision-making in critical care settings pose significant challenges to
healthcare systems worldwide. While clinical decision support systems (CDSS)
have shown promise, the integration of large language models (LLMs) offers new
possibilities for enhancing triage accuracy and clinical decision-making. This
study presents an LLM-driven CDSS designed to assist ED physicians and nurses
in patient triage, treatment planning, and overall emergency care management.
  We developed a multi-agent CDSS utilizing Llama-3-70b as the base LLM,
orchestrated by CrewAI and Langchain. The system comprises four AI agents
emulating key ED roles: Triage Nurse, Emergency Physician, Pharmacist, and ED
Coordinator. It incorporates the Korean Triage and Acuity Scale (KTAS) for
triage assessment and integrates with the RxNorm API for medication management.
  The model was evaluated using the Asclepius dataset, with performance
assessed by a clinical emergency medicine specialist. The CDSS demonstrated
high accuracy in triage decision-making compared to the baseline of a
single-agent system. Furthermore, the system exhibited strong performance in
critical areas, including primary diagnosis, critical findings identification,
disposition decision-making, treatment planning, and resource allocation.
  Our multi-agent CDSS demonstrates significant potential for supporting
comprehensive emergency care management. By leveraging state-of-the-art AI
technologies, this system offers a scalable and adaptable tool that could
enhance emergency medical care delivery, potentially alleviating ED
overcrowding and improving patient outcomes. This work contributes to the
growing field of AI applications in emergency medicine and offers a promising
direction for future research and clinical implementation.

摘要：<paragraph>急診室（ED）人滿為患，以及在重症照護環境中快速做決定的複雜性對全球的醫療保健系統構成重大挑戰。雖然臨床決策支援系統（CDSS）已展現前景，但大型語言模型（LLM）的整合為提升分流準確度和臨床決策提供了新的可能性。本研究提出一個由 LLM 驅動的 CDSS，旨在協助急診室醫師和護理師進行病人分流、治療計畫和整體緊急照護管理。
  我們開發了一個多重代理 CDSS，利用 Llama-3-70b 作為基礎 LLM，由 CrewAI 和 Langchain 編排。此系統包含四個模擬關鍵急診室角色的 AI 代理：分流護理師、急診醫師、藥師和急診室協調員。它整合韓國分流與嚴重指數量表（KTAS）進行分流評估，並與 RxNorm API 整合進行藥物管理。
  該模型使用 Asclepius 資料集進行評估，由臨床急診醫學專家評估其效能。與單一代理系統的基準相比，CDSS 在分流決策方面展現高準確度。此外，該系統在主要診斷、關鍵發現識別、處置決策、治療計畫和資源分配等關鍵領域表現出色。
  我們的多重代理 CDSS 證明了在支援全面的緊急照護管理方面具有顯著的潛力。透過利用最先進的 AI 技術，此系統提供了一個可擴充且可適應的工具，可以提升緊急醫療照護的提供，進而可能緩解急診室人滿為患的情況並改善病患的預後。這項工作促進了 AI 在急診醫學中的應用領域，並為未來的研究和臨床實作提供了有前景的方向。</paragraph>

##### **Improving Global Parameter-sharing in Physically Heterogeneous Multi-agent Reinforcement Learning with Unified Action Space**
2408.07395v1 by Xiaoyang Yu, Youfang Lin, Shuo Wang, Kai Lv, Sheng Han

In a multi-agent system (MAS), action semantics indicates the different
influences of agents' actions toward other entities, and can be used to divide
agents into groups in a physically heterogeneous MAS. Previous multi-agent
reinforcement learning (MARL) algorithms apply global parameter-sharing across
different types of heterogeneous agents without careful discrimination of
different action semantics. This common implementation decreases the
cooperation and coordination between agents in complex situations. However,
fully independent agent parameters dramatically increase the computational cost
and training difficulty. In order to benefit from the usage of different action
semantics while also maintaining a proper parameter-sharing structure, we
introduce the Unified Action Space (UAS) to fulfill the requirement. The UAS is
the union set of all agent actions with different semantics. All agents first
calculate their unified representation in the UAS, and then generate their
heterogeneous action policies using different available-action-masks. To
further improve the training of extra UAS parameters, we introduce a
Cross-Group Inverse (CGI) loss to predict other groups' agent policies with the
trajectory information. As a universal method for solving the physically
heterogeneous MARL problem, we implement the UAS adding to both value-based and
policy-based MARL algorithms, and propose two practical algorithms: U-QMIX and
U-MAPPO. Experimental results in the SMAC environment prove the effectiveness
of both U-QMIX and U-MAPPO compared with several state-of-the-art MARL methods.

摘要：在多智能體系統 (MAS) 中，動作語義表示智能體動作對其他實體的不同影響，可用於將智能體分組到物理異質 MAS 中。先前的多智能體強化學習 (MARL) 演算法對不同類型的異質智能體套用全域參數共享，而未仔細區分不同的動作語義。這種常見的實作會降低智能體在複雜情況下的合作與協調。然而，完全獨立的智能體參數會大幅增加運算成本和訓練難度。為了從使用不同的動作語義中獲益，同時也維持適當的參數共享結構，我們引進統一動作空間 (UAS) 來滿足需求。UAS 是具有不同語義的所有智能體動作的聯集。所有智能體會先在 UAS 中計算其統一表示，然後使用不同的可用動作遮罩產生其異質動作政策。為了進一步改善額外 UAS 參數的訓練，我們引進一個跨群組反向 (CGI) 損失，以使用軌跡資訊預測其他群組的智能體政策。作為解決物理異質 MARL 問題的通用方法，我們實作 UAS 加入基於價值和基於政策的 MARL 演算法，並提出兩種實用的演算法：U-QMIX 和 U-MAPPO。在 SMAC 環境中的實驗結果證明了 U-QMIX 和 U-MAPPO 與幾種最先進的 MARL 方法相比的有效性。

##### **The Complexity of Manipulation of k-Coalitional Games on Graphs**
2408.07368v1 by Hodaya Barr, Yohai Trabelsi, Sarit Kraus, Liam Roditty, Noam Hazon

In many settings, there is an organizer who would like to divide a set of
agents into $k$ coalitions, and cares about the friendships within each
coalition. Specifically, the organizer might want to maximize utilitarian
social welfare, maximize egalitarian social welfare, or simply guarantee that
every agent will have at least one friend within his coalition. However, in
many situations, the organizer is not familiar with the friendship connections,
and he needs to obtain them from the agents. In this setting, a manipulative
agent may falsely report friendship connections in order to increase his
utility. In this paper, we analyze the complexity of finding manipulation in
such $k$-coalitional games on graphs. We also introduce a new type of
manipulation, socially-aware manipulation, in which the manipulator would like
to increase his utility without decreasing the social welfare. We then study
the complexity of finding socially-aware manipulation in our setting. Finally,
we examine the frequency of socially-aware manipulation and the running time of
our algorithms via simulation results.

摘要：在許多情況下，會有一位組織者希望將一組代理劃分為 $k$ 個聯盟，並關心每個聯盟內的友誼。具體而言，組織者可能希望最大化功利主義社會福利、最大化平等主義社會福利，或僅保證每個代理在其聯盟內至少有一位朋友。然而，在許多情況下，組織者並不熟悉友誼關係，他需要從代理中獲取這些關係。在這種情況下，一個具有操縱性的代理可能會虛假報告友誼關係，以增加他的效用。在本文中，我們分析了在圖形上發現這種 $k$-聯盟遊戲中操縱行為的複雜性。我們還引入了一種類型的操縱，即社會意識操縱，其中操縱者希望在不降低社會福利的情況下增加他的效用。然後，我們研究了在我們的環境中發現社會意識操縱的複雜性。最後，我們通過模擬結果檢查了社會意識操縱的頻率和我們演算法的執行時間。

##### **Contrastive Learning on Medical Intents for Sequential Prescription Recommendation**
2408.10259v1 by Arya Hadizadeh Moghaddam, Mohsen Nayebi Kerdabadi, Mei Liu, Zijun Yao

Recent advancements in sequential modeling applied to Electronic Health
Records (EHR) have greatly influenced prescription recommender systems. While
the recent literature on drug recommendation has shown promising performance,
the study of discovering a diversity of coexisting temporal relationships at
the level of medical codes over consecutive visits remains less explored. The
goal of this study can be motivated from two perspectives. First, there is a
need to develop a sophisticated sequential model capable of disentangling the
complex relationships across sequential visits. Second, it is crucial to
establish multiple and diverse health profiles for the same patient to ensure a
comprehensive consideration of different medical intents in drug
recommendation. To achieve this goal, we introduce Attentive Recommendation
with Contrasted Intents (ARCI), a multi-level transformer-based method designed
to capture the different but coexisting temporal paths across a shared sequence
of visits. Specifically, we propose a novel intent-aware method with
contrastive learning, that links specialized medical intents of the patients to
the transformer heads for extracting distinct temporal paths associated with
different health profiles. We conducted experiments on two real-world datasets
for the prescription recommendation task using both ranking and classification
metrics. Our results demonstrate that ARCI has outperformed the
state-of-the-art prescription recommendation methods and is capable of
providing interpretable insights for healthcare practitioners.

摘要：最近將序列建模應用於電子健康紀錄 (EHR) 的進展極大地影響了處方推薦系統。雖然最近關於藥物推薦的文獻顯示出令人滿意的效能，但對於在連續就診中發現共存時間關係的多樣性研究仍較少探討。本研究的目標可以從兩個角度來激勵。首先，需要開發一個複雜的序列模型，能夠解開連續就診中的複雜關係。其次，對於同一位患者建立多個且多樣化的健康檔案至關重要，以確保在藥物推薦中全面考量不同的醫療意圖。為了達成此目標，我們引入了帶有對比意圖的專注推薦 (ARCI)，這是一種基於多層次Transformer的方法，旨在擷取共享就診順序中不同但共存的時間路徑。具體來說，我們提出了一種新的意圖感知方法，採用對比學習，將患者的特殊醫療意圖與Transformer頭端連結，以擷取與不同健康檔案相關的不同時間路徑。我們在兩個真實世界的資料集上進行了處方推薦任務的實驗，同時使用排名和分類指標。我們的結果證明 ARCI 優於最先進的處方推薦方法，並且能夠為醫療保健從業人員提供可解釋的見解。

##### **Model Counting in the Wild**
2408.07059v1 by Arijit Shaw, Kuldeep S. Meel

Model counting is a fundamental problem in automated reasoning with
applications in probabilistic inference, network reliability, neural network
verification, and more. Although model counting is computationally intractable
from a theoretical perspective due to its #P-completeness, the past decade has
seen significant progress in developing state-of-the-art model counters to
address scalability challenges.
  In this work, we conduct a rigorous assessment of the scalability of model
counters in the wild. To this end, we surveyed 11 application domains and
collected an aggregate of 2262 benchmarks from these domains. We then evaluated
six state-of-the-art model counters on these instances to assess scalability
and runtime performance.
  Our empirical evaluation demonstrates that the performance of model counters
varies significantly across different application domains, underscoring the
need for careful selection by the end user. Additionally, we investigated the
behavior of different counters with respect to two parameters suggested by the
model counting community, finding only a weak correlation. Our analysis
highlights the challenges and opportunities for portfolio-based approaches in
model counting.

摘要：模型計數是自動推理中的基本問題，在機率推論、網路可靠度、神經網路驗證等領域有其應用。儘管模型計數在理論上因其 #P-completeness 而在計算上難以處理，過去十年來，在開發最先進的模型計數器以解決可擴充性挑戰方面已取得顯著進展。
在本文中，我們對模型計數器的可擴充性進行了嚴謹的評估。為此，我們調查了 11 個應用領域，並從這些領域收集了 2262 個基準。然後，我們在這些實例上評估了六個最先進的模型計數器，以評估可擴充性和執行時間效能。
我們的實證評估表明，模型計數器的效能因不同的應用領域而異，這凸顯了最終使用者仔細選擇的必要性。此外，我們研究了不同計數器相對於模型計數社群建議的兩個參數的行為，發現只有微弱的相關性。我們的分析重點說明了模型計數中基於投資組合的方法所面臨的挑戰和機會。

##### **KAN You See It? KANs and Sentinel for Effective and Explainable Crop Field Segmentation**
2408.07040v1 by Daniele Rege Cambrin, Eleonora Poeta, Eliana Pastor, Tania Cerquitelli, Elena Baralis, Paolo Garza

Segmentation of crop fields is essential for enhancing agricultural
productivity, monitoring crop health, and promoting sustainable practices. Deep
learning models adopted for this task must ensure accurate and reliable
predictions to avoid economic losses and environmental impact. The newly
proposed Kolmogorov-Arnold networks (KANs) offer promising advancements in the
performance of neural networks. This paper analyzes the integration of KAN
layers into the U-Net architecture (U-KAN) to segment crop fields using
Sentinel-2 and Sentinel-1 satellite images and provides an analysis of the
performance and explainability of these networks. Our findings indicate a 2\%
improvement in IoU compared to the traditional full-convolutional U-Net model
in fewer GFLOPs. Furthermore, gradient-based explanation techniques show that
U-KAN predictions are highly plausible and that the network has a very high
ability to focus on the boundaries of cultivated areas rather than on the areas
themselves. The per-channel relevance analysis also reveals that some channels
are irrelevant to this task.

摘要：農作物田區分割對於提升農業生產力、監控作物健康和促進永續實務至關重要。採用於此任務的深度學習模型必須確保準確且可靠的預測，以避免經濟損失和環境影響。新提出的柯爾莫哥洛夫-阿諾德網路 (KAN) 為神經網路的效能提供了有希望的進展。本文分析將 KAN 層整合到 U-Net 架構 (U-KAN) 中，以使用 Sentinel-2 和 Sentinel-1 衛星影像分割農作物田區，並提供對這些網路效能和可解釋性的分析。我們的研究結果顯示，與傳統的全卷積 U-Net 模型相比，IoU 提升了 2%，而 GFLOP 較少。此外，基於梯度的解釋技術顯示 U-KAN 預測非常合理，而且網路非常有能力專注於耕作區域的邊界，而不是區域本身。每個通道關聯性分析也顯示，有些通道與此任務無關。

##### **PathInsight: Instruction Tuning of Multimodal Datasets and Models for Intelligence Assisted Diagnosis in Histopathology**
2408.07037v1 by Xiaomin Wu, Rui Xu, Pengchen Wei, Wenkang Qin, Peixiang Huang, Ziheng Li, Lin Luo

Pathological diagnosis remains the definitive standard for identifying
tumors. The rise of multimodal large models has simplified the process of
integrating image analysis with textual descriptions. Despite this advancement,
the substantial costs associated with training and deploying these complex
multimodal models, together with a scarcity of high-quality training datasets,
create a significant divide between cutting-edge technology and its application
in the clinical setting. We had meticulously compiled a dataset of
approximately 45,000 cases, covering over 6 different tasks, including the
classification of organ tissues, generating pathology report descriptions, and
addressing pathology-related questions and answers. We have fine-tuned
multimodal large models, specifically LLaVA, Qwen-VL, InternLM, with this
dataset to enhance instruction-based performance. We conducted a qualitative
assessment of the capabilities of the base model and the fine-tuned model in
performing image captioning and classification tasks on the specific dataset.
The evaluation results demonstrate that the fine-tuned model exhibits
proficiency in addressing typical pathological questions. We hope that by
making both our models and datasets publicly available, they can be valuable to
the medical and research communities.

摘要：病理診斷仍然是識別腫瘤的明確標準。多模態大型模型的興起簡化了將影像分析與文字描述整合的過程。儘管有此進展，但訓練和部署這些複雜的多模態模型相關的龐大成本，以及缺乏高品質的訓練資料集，導致尖端技術與其在臨床環境中的應用之間產生了顯著的差距。我們已細心編制了一個包含約 45,000 個案例的資料集，涵蓋 6 項不同的任務，包括器官組織分類、產生病理報告描述，以及回答與病理相關的問題。我們使用這個資料集微調了多模態大型模型，特別是 LLaVA、Qwen-VL、InternLM，以增強基於指令的效能。我們對基礎模型和微調模型在特定資料集上執行影像標題和分類任務的能力進行了定性評估。評估結果表明，微調模型在回答典型病理問題方面表現出熟練度。我們希望透過公開我們的模型和資料集，它們能對醫療和研究社群有價值。

##### **Diagnosis extraction from unstructured Dutch echocardiogram reports using span- and document-level characteristic classification**
2408.06930v2 by Bauke Arends, Melle Vessies, Dirk van Osch, Arco Teske, Pim van der Harst, René van Es, Bram van Es

Clinical machine learning research and AI driven clinical decision support
models rely on clinically accurate labels. Manually extracting these labels
with the help of clinical specialists is often time-consuming and expensive.
This study tests the feasibility of automatic span- and document-level
diagnosis extraction from unstructured Dutch echocardiogram reports. We
included 115,692 unstructured echocardiogram reports from the UMCU a large
university hospital in the Netherlands. A randomly selected subset was manually
annotated for the occurrence and severity of eleven commonly described cardiac
characteristics. We developed and tested several automatic labelling techniques
at both span and document levels, using weighted and macro F1-score, precision,
and recall for performance evaluation. We compared the performance of span
labelling against document labelling methods, which included both direct
document classifiers and indirect document classifiers that rely on span
classification results. The SpanCategorizer and MedRoBERTa$.$nl models
outperformed all other span and document classifiers, respectively. The
weighted F1-score varied between characteristics, ranging from 0.60 to 0.93 in
SpanCategorizer and 0.96 to 0.98 in MedRoBERTa$.$nl. Direct document
classification was superior to indirect document classification using span
classifiers. SetFit achieved competitive document classification performance
using only 10% of the training data. Utilizing a reduced label set yielded
near-perfect document classification results. We recommend using our published
SpanCategorizer and MedRoBERTa$.$nl models for span- and document-level
diagnosis extraction from Dutch echocardiography reports. For settings with
limited training data, SetFit may be a promising alternative for document
classification.

摘要：<paragraph>臨床機器學習研究和人工智慧驅動的臨床決策支援
模型依賴於臨床準確的標籤。在臨床專家的協助下，手動提取這些標籤通常既耗時又昂貴。
本研究測試了從非結構化荷蘭超音波心動圖報告中自動提取跨度和文件級別診斷的可行性。我們
納入了來自荷蘭一家大型大學醫院 UMCU 的 115,692 份非結構化超音波心動圖報告。隨機選擇的子集經過手動註解，以了解十一種常見描述的心臟
特徵的發生和嚴重程度。我們開發並測試了跨度和文件級別的幾種自動標籤技術，使用加權和巨集 F1 分數、精確度，
以及召回率進行效能評估。我們比較了跨度
標籤與文件標籤方法的效能，其中包括直接
文件分類器和依賴於跨度
分類結果的間接文件分類器。SpanCategorizer 和 MedRoBERTa$.$nl 模型
分別優於所有其他跨度和文件分類器。
加權 F1 分數因特徵而異，SpanCategorizer 中的範圍從 0.60 到 0.93，MedRoBERTa$.$nl 中的範圍從 0.96 到 0.98。使用跨度
分類器的間接文件分類不如直接文件分類。SetFit 僅使用 10% 的訓練資料就達到了具有競爭力的文件分類效能。利用減少的標籤集產生了近乎完美的文件分類結果。我們建議使用我們發布的 SpanCategorizer 和 MedRoBERTa$.$nl 模型從荷蘭超音波心動圖報告中提取跨度和文件級別診斷。對於訓練資料有限的設定，SetFit 可能是一種有前途的文件
分類替代方案。</paragraph>

##### **BMFT: Achieving Fairness via Bias-based Weight Masking Fine-tuning**
2408.06890v1 by Yuyang Xue, Junyu Yan, Raman Dutt, Fasih Haider, Jingshuai Liu, Steven McDonagh, Sotirios A. Tsaftaris

Developing models with robust group fairness properties is paramount,
particularly in ethically sensitive domains such as medical diagnosis. Recent
approaches to achieving fairness in machine learning require a substantial
amount of training data and depend on model retraining, which may not be
practical in real-world scenarios. To mitigate these challenges, we propose
Bias-based Weight Masking Fine-Tuning (BMFT), a novel post-processing method
that enhances the fairness of a trained model in significantly fewer epochs
without requiring access to the original training data. BMFT produces a mask
over model parameters, which efficiently identifies the weights contributing
the most towards biased predictions. Furthermore, we propose a two-step
debiasing strategy, wherein the feature extractor undergoes initial fine-tuning
on the identified bias-influenced weights, succeeded by a fine-tuning phase on
a reinitialised classification layer to uphold discriminative performance.
Extensive experiments across four dermatological datasets and two sensitive
attributes demonstrate that BMFT outperforms existing state-of-the-art (SOTA)
techniques in both diagnostic accuracy and fairness metrics. Our findings
underscore the efficacy and robustness of BMFT in advancing fairness across
various out-of-distribution (OOD) settings. Our code is available at:
https://github.com/vios-s/BMFT

摘要：<paragraph>開發具有穩健群組公平性特性的模型至關重要，特別是在醫療診斷等道德敏感領域。最近實現機器學習公平性的方法需要大量的訓練資料，並且依賴於模型再訓練，這在現實情況中可能不切實際。為了緩解這些挑戰，我們提出了基於偏差的權重遮罩微調 (BMFT)，這是一種新穎的後處理方法，可以在顯著更少的輪次中增強訓練模型的公平性，而無需訪問原始訓練資料。BMFT 在模型參數上產生一個遮罩，有效地識別出對偏差預測貢獻最大的權重。此外，我們提出了一種兩步去偏策略，其中特徵提取器對識別出的偏差影響權重進行初始微調，然後在重新初始化的分類層上進行微調階段以維持區分效能。在四個皮膚科資料集和兩個敏感屬性的廣泛實驗中證明，BMFT 在診斷準確性和公平性指標上都優於現有的最先進 (SOTA) 技術。我們的研究結果強調了 BMFT 在推進各種非分佈 (OOD) 設定中的公平性方面的效力和穩健性。我們的程式碼可在以下位置獲得：
https://github.com/vios-s/BMFT</paragraph>

##### **Synthetic Patient-Physician Dialogue Generation from Clinical Notes Using LLM**
2408.06285v1 by Trisha Das, Dina Albassam, Jimeng Sun

Medical dialogue systems (MDS) enhance patient-physician communication,
improve healthcare accessibility, and reduce costs. However, acquiring suitable
data to train these systems poses significant challenges. Privacy concerns
prevent the use of real conversations, necessitating synthetic alternatives.
Synthetic dialogue generation from publicly available clinical notes offers a
promising solution to this issue, providing realistic data while safeguarding
privacy. Our approach, SynDial, uses a single LLM iteratively with zero-shot
prompting and a feedback loop to generate and refine high-quality synthetic
dialogues. The feedback consists of weighted evaluation scores for similarity
and extractiveness. The iterative process ensures dialogues meet predefined
thresholds, achieving superior extractiveness as a result of the feedback loop.
Additionally, evaluation shows that the generated dialogues excel in factuality
metric compared to the baselines and has comparable diversity scores with GPT4.

摘要：醫療對話系統 (MDS) 可增強病患與醫師的溝通、改善醫療保健的可近性，並降低成本。然而，取得適當的資料來訓練這些系統會造成重大的挑戰。隱私問題會妨礙真實對話的使用，因此需要合成替代方案。從公開可取得的臨床筆記生成合成對話提供了這個問題一個有前景的解決方案，在保護隱私的同時提供真實的資料。我們的 SynDial 方法使用單一 LLM 透過零次提示和回饋迴路，反覆生成和改善高品質的合成對話。回饋包含相似性和抽取性的加權評分。反覆的程序可確保對話符合預先定義的閾值，並因回饋迴路而達成優異的抽取性。此外，評估顯示生成的對話在事實性指標上優於基準，且與 GPT4 具有相當的多樣性評分。

##### **Decentralized Health Intelligence Network (DHIN)**
2408.06240v3 by Abraham Nash

Decentralized Health Intelligence Network (DHIN) is a theoretical framework
addressing significant challenges of health data sovereignty and AI utilization
in healthcare caused by data fragmentation across providers and institutions.
It establishes a sovereign architecture for healthcare provision as a
prerequisite to a sovereign health network, then facilitates effective AI
utilization by overcoming barriers to accessing diverse medical data sources.
This comprehensive framework leverages: 1) self-sovereign identity architecture
coupled with a personal health record (PHR) as a prerequisite for health data
sovereignty; 2) a scalable federated learning (FL) protocol implemented on a
public blockchain for decentralized AI training in healthcare, where health
data remains with participants and only model parameter updates are shared; and
3) a scalable, trustless rewards mechanism to incentivize participation and
ensure fair reward distribution. This framework ensures that no entity can
prevent or control access to training on health data offered by participants or
determine financial benefits, as these processes operate on a public blockchain
with an immutable record and without a third party. It supports effective AI
training in healthcare, allowing patients to maintain control over their health
data, benefit financially, and contribute to a decentralized, scalable
ecosystem that leverages collective AI to develop beneficial healthcare
algorithms. Patients receive rewards into their digital wallets as an incentive
to opt-in to the FL protocol, with a long-term roadmap to funding decentralized
insurance solutions. This approach introduces a novel, self-financed healthcare
model that adapts to individual needs, complements existing systems, and
redefines universal coverage. It highlights the potential to transform
healthcare data management and AI utilization while empowering patients.

摘要：分散式健康情報網路 (DHIN) 是個理論架構，
用來解決醫療保健中因資料分散在各個供應商和機構而產生的健康資料主權和 AI 使用的重大挑戰。
它建立了一個主權架構來提供醫療保健，作為主權健康網路的先決條件，然後透過克服取得多樣化醫療資料來源的障礙，促進有效的 AI 使用。
這個全面的架構利用：1) 自主權身分架構，結合個人健康紀錄 (PHR) 作為健康資料主權的先決條件；2) 在公共區塊鏈上實作的可擴充聯合學習 (FL) 協定，用於醫療保健中的分散式 AI 訓練，其中健康資料仍由參與者持有，只有模型參數更新會被分享；3) 可擴充的、無信任的獎勵機制，用於激勵參與並確保公平的獎勵分配。這個架構確保沒有任何實體可以阻止或控制參與者提供的健康資料訓練存取，或決定財務利益，因為這些程序是在公共區塊鏈上運作，具有不可變更的紀錄，而且沒有第三方。它支援在醫療保健中進行有效的 AI 訓練，讓患者可以維持對其健康資料的控制權，獲得財務利益，並貢獻到一個分散式、可擴充的生態系統，利用集體 AI 來開發有益的醫療保健演算法。患者會收到獎勵到他們的數位錢包中，作為選擇加入 FL 協定的誘因，長期目標是為分散式保險解決方案提供資金。這種方法引進了一個新穎的、自我資助的醫療保健模式，可以適應個別需求，補充現有系統，並重新定義全民健保。它突顯了轉型醫療保健資料管理和 AI 使用的潛力，同時賦予患者權力。

##### **ACCELERATION: Sequentially-scanning DECT Imaging Using High Temporal Resolution Image Reconstruction And Temporal Extrapolation**
2408.06163v1 by Qiaoxin Li, Dong Liang, Yinsheng Li

Dual-energy computed tomography (DECT) has been widely used to obtain
quantitative elemental composition of imaged subjects for personalized and
precise medical diagnosis. Compared with existing high-end DECT leveraging
advanced X-ray source and/or detector technologies, the use of the
sequentially-scanning data acquisition scheme to implement DECT may make
broader impact on clinical practice because this scheme requires no specialized
hardware designs. However, since the concentration of iodinated contrast agent
in the imaged subject varies over time, sequentially-scanned data sets acquired
at two tube potentials are temporally inconsistent. As existing material
decomposition approaches for DECT assume that the data sets acquired at two
tube potentials are temporally consistent, the violation of this assumption
results in inaccurate quantification accuracy of iodine concentration. In this
work, we developed a technique to achieve sequentially-scanning DECT imaging
using high temporal resolution image reconstruction and temporal extrapolation,
ACCELERATION in short, to address the technical challenge induced by temporal
inconsistency of sequentially-scanned data sets and improve iodine
quantification accuracy in sequentially-scanning DECT. ACCELERATION has been
validated and evaluated using numerical simulation data sets generated from
clinical human subject exams. Results demonstrated the improvement of iodine
quantification accuracy using ACCELERATION.

摘要：雙能電腦斷層掃描 (DECT) 已廣泛用於取得影像化受試者的定量元素組成，以進行個人化且精確的醫療診斷。與利用先進 X 光源和/或偵測器技術的現有高階 DECT 相比，使用連續掃描資料擷取方案來實作 DECT 可能對臨床實務造成更廣泛的影響，因為此方案不需要專門的硬體設計。然而，由於影像化受試者中碘化對比劑的濃度會隨著時間而變化，因此在兩個管電位下擷取的連續掃描資料集在時間上並不一致。由於 DECT 現有的材料分解方法假設在兩個管電位下擷取的資料集在時間上是一致的，因此違反此假設會導致碘濃度的定量準確度不準確。在這項工作中，我們開發了一種技術，使用高時間解析度影像重建和時間外推法來達成連續掃描 DECT 影像，簡稱 ACCELERATION，以解決連續掃描資料集的時間不一致性所造成的技術挑戰，並改善連續掃描 DECT 中的碘定量準確度。ACCELERATION 已使用從臨床人體受試者檢查中產生的數值模擬資料集進行驗證和評估。結果證明使用 ACCELERATION 可改善碘定量準確度。

##### **Med42-v2: A Suite of Clinical LLMs**
2408.06142v1 by Clément Christophe, Praveen K Kanithi, Tathagata Raha, Shadab Khan, Marco AF Pimentel

Med42-v2 introduces a suite of clinical large language models (LLMs) designed
to address the limitations of generic models in healthcare settings. These
models are built on Llama3 architecture and fine-tuned using specialized
clinical data. They underwent multi-stage preference alignment to effectively
respond to natural prompts. While generic models are often preference-aligned
to avoid answering clinical queries as a precaution, Med42-v2 is specifically
trained to overcome this limitation, enabling its use in clinical settings.
Med42-v2 models demonstrate superior performance compared to the original
Llama3 models in both 8B and 70B parameter configurations and GPT-4 across
various medical benchmarks. These LLMs are developed to understand clinical
queries, perform reasoning tasks, and provide valuable assistance in clinical
environments. The models are now publicly available at
\href{https://huggingface.co/m42-health}{https://huggingface.co/m42-health}.

摘要：Med42-v2 引進了一套臨床大型語言模型 (LLM)，旨在解決醫療保健環境中通用模型的限制。這些模型建立在 Llama3 架構上，並使用專業臨床資料進行微調。它們經歷了多階段偏好調整，以有效回應自然提示。雖然通用模型通常偏好調整為避免預防性回答臨床查詢，但 Med42-v2 經過特別訓練以克服此限制，使其能夠在臨床環境中使用。與原始 Llama3 模型相比，Med42-v2 模型在 8B 和 70B 參數配置以及 GPT-4 中表現出優異的效能，橫跨各種醫療基準。這些 LLM 被開發用於理解臨床查詢、執行推理任務，並在臨床環境中提供有價值的協助。這些模型現在已於 \href{https://huggingface.co/m42-health}{https://huggingface.co/m42-health} 公開提供。

##### **Real-Time Drowsiness Detection Using Eye Aspect Ratio and Facial Landmark Detection**
2408.05836v1 by Varun Shiva Krishna Rupani, Velpooru Venkata Sai Thushar, Kondadi Tejith

Drowsiness detection is essential for improving safety in areas such as
transportation and workplace health. This study presents a real-time system
designed to detect drowsiness using the Eye Aspect Ratio (EAR) and facial
landmark detection techniques. The system leverages Dlibs pre-trained shape
predictor model to accurately detect and monitor 68 facial landmarks, which are
used to compute the EAR. By establishing a threshold for the EAR, the system
identifies when eyes are closed, indicating potential drowsiness. The process
involves capturing a live video stream, detecting faces in each frame,
extracting eye landmarks, and calculating the EAR to assess alertness. Our
experiments show that the system reliably detects drowsiness with high accuracy
while maintaining low computational demands. This study offers a strong
solution for real-time drowsiness detection, with promising applications in
driver monitoring and workplace safety. Future research will investigate
incorporating additional physiological and contextual data to further enhance
detection accuracy and reliability.

摘要：瞌睡檢測對於改善運輸和職場健康等領域的安全至關重要。本研究提出一個即時系統，旨在使用眼睛長寬比 (EAR) 和面部特徵檢測技術來檢測瞌睡。該系統利用 Dlibs 預先訓練的形狀預測模型來準確檢測和監控 68 個面部特徵，這些特徵用於計算 EAR。通過為 EAR 設定一個閾值，該系統可以識別眼睛閉上的時間，表明可能有瞌睡。這個過程包括擷取即時視訊串流、檢測每一幀中的臉部、提取眼睛特徵，並計算 EAR 來評估警覺性。我們的實驗表明，該系統可以可靠地檢測瞌睡，準確度高，同時保持低運算需求。本研究為即時瞌睡檢測提供了一個強大的解決方案，在駕駛員監控和職場安全方面有廣泛的應用前景。未來的研究將探討整合額外的生理和環境資料，以進一步提高檢測準確度和可靠性。

##### **TC-KANRecon: High-Quality and Accelerated MRI Reconstruction via Adaptive KAN Mechanisms and Intelligent Feature Scaling**
2408.05705v1 by Ruiquan Ge, Xiao Yu, Yifei Chen, Fan Jia, Shenghao Zhu, Guanyu Zhou, Yiyu Huang, Chenyan Zhang, Dong Zeng, Changmiao Wang, Qiegen Liu, Shanzhou Niu

Magnetic Resonance Imaging (MRI) has become essential in clinical diagnosis
due to its high resolution and multiple contrast mechanisms. However, the
relatively long acquisition time limits its broader application. To address
this issue, this study presents an innovative conditional guided diffusion
model, named as TC-KANRecon, which incorporates the Multi-Free U-KAN (MF-UKAN)
module and a dynamic clipping strategy. TC-KANRecon model aims to accelerate
the MRI reconstruction process through deep learning methods while maintaining
the quality of the reconstructed images. The MF-UKAN module can effectively
balance the tradeoff between image denoising and structure preservation.
Specifically, it presents the multi-head attention mechanisms and scalar
modulation factors, which significantly enhances the model's robustness and
structure preservation capabilities in complex noise environments. Moreover,
the dynamic clipping strategy in TC-KANRecon adjusts the cropping interval
according to the sampling steps, thereby mitigating image detail loss typically
caused by traditional cropping methods and enriching the visual features of the
images. Furthermore, the MC-Model module incorporates full-sampling k-space
information, realizing efficient fusion of conditional information, enhancing
the model's ability to process complex data, and improving the realism and
detail richness of reconstructed images. Experimental results demonstrate that
the proposed method outperforms other MRI reconstruction methods in both
qualitative and quantitative evaluations. Notably, TC-KANRecon method exhibits
excellent reconstruction results when processing high-noise, low-sampling-rate
MRI data. Our source code is available at
https://github.com/lcbkmm/TC-KANRecon.

摘要：磁振造影（MRI）由於其高解析度和多重對比機制，已成為臨床診斷中不可或缺的技術。然而，相對較長的擷取時間限制了其更廣泛的應用。為了解決這個問題，本研究提出了一個創新的條件引導擴散模型，稱為 TC-KANRecon，它結合了多自由 U-KAN（MF-UKAN）模組和一個動態裁剪策略。TC-KANRecon 模型旨在透過深度學習方法加速 MRI 重建過程，同時保持重建影像的品質。MF-UKAN 模組可以有效平衡影像去噪和結構保留之間的取捨。具體來說，它呈現多頭注意力機制和標量調製因子，這顯著增強了模型在複雜噪聲環境中的穩健性和結構保留能力。此外，TC-KANRecon 中的動態裁剪策略根據取樣步驟調整裁剪間隔，從而減輕傳統裁剪方法通常造成的影像細節損失，並豐富影像的視覺特徵。此外，MC-Model 模組結合了全取樣 k 空間資訊，實現條件資訊的有效融合，增強了模型處理複雜資料的能力，並改善了重建影像的真實感和細節豐富度。實驗結果表明，所提出的方法在定性和定量評估中都優於其他 MRI 重建方法。值得注意的是，TC-KANRecon 方法在處理高雜訊、低取樣率 MRI 資料時表現出優異的重建結果。我們的原始程式碼可在 https://github.com/lcbkmm/TC-KANRecon 取得。

##### **A Novel Momentum-Based Deep Learning Techniques for Medical Image Classification and Segmentation**
2408.05692v1 by Koushik Biswas, Ridal Pal, Shaswat Patel, Debesh Jha, Meghana Karri, Amit Reza, Gorkem Durak, Alpay Medetalibeyoglu, Matthew Antalek, Yury Velichko, Daniela Ladner, Amir Borhani, Ulas Bagci

Accurately segmenting different organs from medical images is a critical
prerequisite for computer-assisted diagnosis and intervention planning. This
study proposes a deep learning-based approach for segmenting various organs
from CT and MRI scans and classifying diseases. Our study introduces a novel
technique integrating momentum within residual blocks for enhanced training
dynamics in medical image analysis. We applied our method in two distinct
tasks: segmenting liver, lung, & colon data and classifying abdominal pelvic CT
and MRI scans. The proposed approach has shown promising results, outperforming
state-of-the-art methods on publicly available benchmarking datasets. For
instance, in the lung segmentation dataset, our approach yielded significant
enhancements over the TransNetR model, including a 5.72% increase in dice
score, a 5.04% improvement in mean Intersection over Union (mIoU), an 8.02%
improvement in recall, and a 4.42% improvement in precision. Hence,
incorporating momentum led to state-of-the-art performance in both segmentation
and classification tasks, representing a significant advancement in the field
of medical imaging.

摘要：準確地從醫療影像中分割出不同的器官，是電腦輔助診斷和介入規劃的關鍵先決條件。本研究提出了一種基於深度學習的方法，用於分割 CT 和 MRI 掃描中的各種器官並對疾病進行分類。我們的研究引入了一種新技術，將動量整合到殘差塊中，以增強醫療影像分析中的訓練動態。我們將方法應用於兩個不同的任務：分割肝臟、肺臟和結腸資料，以及對腹部骨盆 CT 和 MRI 掃描進行分類。所提出的方法已顯示出有希望的結果，在公開的基準資料集上優於最先進的方法。例如，在肺部分割資料集中，我們的模型比 TransNetR 模型產生了顯著的提升，包括骰子係數增加了 5.72%，平均聯合交集 (mIoU) 提高了 5.04%，召回率提高了 8.02%，精度提高了 4.42%。因此，結合動量在分割和分類任務中都帶來了最先進的效能，代表了醫療影像領域的重大進展。

##### **Mitigating Metropolitan Carbon Emissions with Dynamic Eco-driving at Scale**
2408.05609v1 by Vindula Jayawardana, Baptiste Freydt, Ao Qu, Cameron Hickert, Edgar Sanchez, Catherine Tang, Mark Taylor, Blaine Leonard, Cathy Wu

The sheer scale and diversity of transportation make it a formidable sector
to decarbonize. Here, we consider an emerging opportunity to reduce carbon
emissions: the growing adoption of semi-autonomous vehicles, which can be
programmed to mitigate stop-and-go traffic through intelligent speed commands
and, thus, reduce emissions. But would such dynamic eco-driving move the needle
on climate change? A comprehensive impact analysis has been out of reach due to
the vast array of traffic scenarios and the complexity of vehicle emissions. We
address this challenge with large-scale scenario modeling efforts and by using
multi-task deep reinforcement learning with a carefully designed network
decomposition strategy. We perform an in-depth prospective impact assessment of
dynamic eco-driving at 6,011 signalized intersections across three major US
metropolitan cities, simulating a million traffic scenarios. Overall, we find
that vehicle trajectories optimized for emissions can cut city-wide
intersection carbon emissions by 11-22%, without harming throughput or safety,
and with reasonable assumptions, equivalent to the national emissions of Israel
and Nigeria, respectively. We find that 10% eco-driving adoption yields 25%-50%
of the total reduction, and nearly 70% of the benefits come from 20% of
intersections, suggesting near-term implementation pathways. However, the
composition of this high-impact subset of intersections varies considerably
across different adoption levels, with minimal overlap, calling for careful
strategic planning for eco-driving deployments. Moreover, the impact of
eco-driving, when considered jointly with projections of vehicle
electrification and hybrid vehicle adoption remains significant. More broadly,
this work paves the way for large-scale analysis of traffic externalities, such
as time, safety, and air quality, and the potential impact of solution
strategies.

摘要：<paragraph>運輸業的規模和多樣性使其成為一個難以脫碳的產業。在此，我們考慮一個新興的機會來減少碳排放：半自動車輛的採用日益增加，這些車輛可透過智慧型速度指令來編程以減少走走停停的交通，從而減少排放。但這種動態生態駕駛是否會對氣候變遷產生影響？由於交通狀況眾多且車輛排放複雜，因此無法進行全面的影響分析。我們透過大規模情境建模工作和使用多任務深度強化學習，以及精心設計的網路分解策略來應對這項挑戰。我們對美國三大都會城市 6,011 個有信號的交叉路口進行深入的前瞻性影響評估，模擬一百萬個交通狀況。總體而言，我們發現針對排放量最佳化的車輛軌跡可以減少 11-22% 的城市交叉路口碳排放，而不會損害吞吐量或安全性，且根據合理的假設，分別等於以色列和奈及利亞的國家排放量。我們發現 10% 的生態駕駛採用率會產生總減量的 25%-50%，而近 70% 的好處來自 20% 的交叉路口，這表明了近期的實施途徑。然而，這個高影響交叉路口子集的組成在不同的採用率之間變化很大，重疊性很小，這需要仔細的策略性規劃來進行生態駕駛部署。此外，生態駕駛的影響，在與車輛電氣化和混合動力車輛採用率的預測共同考量時，仍然顯著。更廣泛而言，這項工作為大規模分析交通外部性（例如時間、安全性和空氣品質）以及解決策略的潛在影響鋪平了道路。</paragraph>

##### **Beyond the Eye: A Relational Model for Early Dementia Detection Using Retinal OCTA Images**
2408.05117v1 by Shouyue Liu, Jinkui Hao, Yonghuai Liu, Huazhu Fu, Xinyu Guo, Shuting Zhang, Yitian Zhao

Early detection of dementia, such as Alzheimer's disease (AD) or mild
cognitive impairment (MCI), is essential to enable timely intervention and
potential treatment. Accurate detection of AD/MCI is challenging due to the
high complexity, cost, and often invasive nature of current diagnostic
techniques, which limit their suitability for large-scale population screening.
Given the shared embryological origins and physiological characteristics of the
retina and brain, retinal imaging is emerging as a potentially rapid and
cost-effective alternative for the identification of individuals with or at
high risk of AD. In this paper, we present a novel PolarNet+ that uses retinal
optical coherence tomography angiography (OCTA) to discriminate early-onset AD
(EOAD) and MCI subjects from controls. Our method first maps OCTA images from
Cartesian coordinates to polar coordinates, allowing approximate sub-region
calculation to implement the clinician-friendly early treatment of diabetic
retinopathy study (ETDRS) grid analysis. We then introduce a multi-view module
to serialize and analyze the images along three dimensions for comprehensive,
clinically useful information extraction. Finally, we abstract the sequence
embedding into a graph, transforming the detection task into a general graph
classification problem. A regional relationship module is applied after the
multi-view module to excavate the relationship between the sub-regions. Such
regional relationship analyses validate known eye-brain links and reveal new
discriminative patterns.

摘要：早期偵測失智症，例如阿茲海默症 (AD) 或輕度認知障礙 (MCI)，對於及時介入和潛在治療至關重要。由於目前診斷技術的複雜性高、成本高，且常常具有侵入性，因此準確偵測 AD/MCI 極具挑戰性，這也限制了其用於大規模人群篩檢的適用性。考量到視網膜和腦部具有相同的胚胎起源和生理特性，視網膜影像正逐漸成為一種潛在的快速且具成本效益的替代方案，用於找出罹患 AD 或具有高風險的個人。在本文中，我們提出了一種創新的 PolarNet+，它使用視網膜光學相干斷層血管造影 (OCTA) 來區分早發性 AD (EOAD) 和 MCI 受試者與對照組。我們的做法首先將 OCTA 影像從笛卡爾坐標轉換為極坐標，讓近似子區域計算得以實作，進而執行對臨床醫師友善的糖尿病視網膜病變早期治療研究 (ETDRS) 格線分析。接著，我們引入一個多視圖模組，用於串列化並沿著三個向度分析影像，以進行全面的、臨床上有用的資訊萃取。最後，我們將序列嵌入抽象化為一個圖形，將偵測任務轉換為一個通用的圖形分類問題。在多視圖模組後應用區域關係模組，以探討子區域之間的關係。此類區域關係分析驗證了已知的視網膜與腦部關聯，並揭示了新的判別模式。

##### **RT-Surv: Improving Mortality Prediction After Radiotherapy with Large Language Model Structuring of Large-Scale Unstructured Electronic Health Records**
2408.05074v2 by Sangjoon Park, Chan Woo Wee, Seo Hee Choi, Kyung Hwan Kim, Jee Suk Chang, Hong In Yoon, Ik Jae Lee, Yong Bae Kim, Jaeho Cho, Ki Chang Keum, Chang Geol Lee, Hwa Kyung Byun, Woong Sub Koom

Accurate patient selection is critical in radiotherapy (RT) to prevent
ineffective treatments. Traditional survival prediction models, relying on
structured data, often lack precision. This study explores the potential of
large language models (LLMs) to structure unstructured electronic health record
(EHR) data, thereby improving survival prediction accuracy through
comprehensive clinical information integration. Data from 34,276 patients
treated with RT at Yonsei Cancer Center between 2013 and 2023 were analyzed,
encompassing both structured and unstructured data. An open-source LLM was used
to structure the unstructured EHR data via single-shot learning, with its
performance compared against a domain-specific medical LLM and a smaller
variant. Survival prediction models were developed using statistical, machine
learning, and deep learning approaches, incorporating both structured and
LLM-structured data. Clinical experts evaluated the accuracy of the
LLM-structured data. The open-source LLM achieved 87.5% accuracy in structuring
unstructured EHR data without additional training, significantly outperforming
the domain-specific medical LLM, which reached only 35.8% accuracy. Larger LLMs
were more effective, particularly in extracting clinically relevant features
like general condition and disease extent, which closely correlated with
patient survival. Incorporating LLM-structured clinical features into survival
prediction models significantly improved accuracy, with the C-index of deep
learning models increasing from 0.737 to 0.820. These models also became more
interpretable by emphasizing clinically significant factors. This study shows
that general-domain LLMs, even without specific medical training, can
effectively structure large-scale unstructured EHR data, substantially
enhancing the accuracy and interpretability of clinical predictive models.

摘要：<paragraph>在放射治療 (RT) 中，準確的患者選擇至關重要，以防止無效的治療。傳統的存活預測模型依賴於結構化數據，往往缺乏精確性。本研究探討了大型語言模型 (LLM) 將非結構化電子健康記錄 (EHR) 數據結構化的潛力，從而通過全面的臨床信息整合來提高存活預測的準確性。對 2013 年至 2023 年間在延世癌症中心接受 RT 治療的 34,276 名患者的數據進行了分析，包括結構化和非結構化數據。使用開源 LLM 通過單次學習來構造非結構化 EHR 數據，並將其性能與特定領域的醫療 LLM 和較小的變體進行了比較。存活預測模型是使用統計、機器學習和深度學習方法開發的，結合了結構化和 LLM 結構化的數據。臨床專家評估了 LLM 結構化數據的準確性。開源 LLM 在沒有額外訓練的情況下，在結構化非結構化 EHR 數據方面達到了 87.5% 的準確度，顯著優於特定領域的醫療 LLM，後者的準確度僅為 35.8%。更大的 LLM 更有效，特別是在提取臨床相關特徵方面，如一般狀況和疾病程度，這與患者存活率密切相關。將 LLM 結構化的臨床特徵納入存活預測模型顯著提高了準確性，深度學習模型的 C 指數從 0.737 增加到 0.820。這些模型也變得更具可解釋性，因為它們強調了臨床上重要的因素。本研究表明，即使沒有具體的醫學訓練，通用領域的 LLM 也可以有效地構造大規模的非結構化 EHR 數據，從而顯著提高臨床預測模型的準確性和可解釋性。</paragraph>

##### **CROCODILE: Causality aids RObustness via COntrastive DIsentangled LEarning**
2408.04949v1 by Gianluca Carloni, Sotirios A Tsaftaris, Sara Colantonio

Due to domain shift, deep learning image classifiers perform poorly when
applied to a domain different from the training one. For instance, a classifier
trained on chest X-ray (CXR) images from one hospital may not generalize to
images from another hospital due to variations in scanner settings or patient
characteristics. In this paper, we introduce our CROCODILE framework, showing
how tools from causality can foster a model's robustness to domain shift via
feature disentanglement, contrastive learning losses, and the injection of
prior knowledge. This way, the model relies less on spurious correlations,
learns the mechanism bringing from images to prediction better, and outperforms
baselines on out-of-distribution (OOD) data. We apply our method to multi-label
lung disease classification from CXRs, utilizing over 750000 images from four
datasets. Our bias-mitigation method improves domain generalization and
fairness, broadening the applicability and reliability of deep learning models
for a safer medical image analysis. Find our code at:
https://github.com/gianlucarloni/crocodile.

摘要：由於領域轉換，深度學習圖像分類器在應用於與訓練不同的領域時表現不佳。例如，針對一家醫院的胸部 X 光（CXR）影像訓練的分類器，由於掃描儀設定或患者特徵的差異，可能無法概化到另一家醫院的影像。在本文中，我們介紹我們的 CROCODILE 框架，展示因果工具如何透過特徵解糾纏、對比學習損失和注入先驗知識來促進模型對領域轉換的穩健性。這樣一來，模型較不依賴虛假相關性，能更好地學習從影像到預測的機制，並在分佈外（OOD）資料上優於基線。我們將我們的模型應用於 CXR 的多標籤肺部疾病分類，利用來自四個資料集的超過 750,000 張影像。我們的偏差緩解方法改善了領域概化和公平性，擴大了深度學習模型在更安全醫學影像分析中的適用性和可靠性。在以下網址找到我們的程式碼：https://github.com/gianlucarloni/crocodile。

##### **Unleashing Artificial Cognition: Integrating Multiple AI Systems**
2408.04910v3 by Muntasir Adnan, Buddhi Gamage, Zhiwei Xu, Damith Herath, Carlos C. N. Kuhn

In this study, we present an innovative fusion of language models and query
analysis techniques to unlock cognition in artificial intelligence. Our system
seamlessly integrates a Chess engine with a language model, enabling it to
predict moves and provide strategic explanations. Leveraging a vector database
to achieve retrievable answer generation, our OpenSI AI system elucidates its
decision-making process, bridging the gap between raw computation and
human-like understanding. Our choice of Chess as the demonstration environment
underscores the versatility of our approach. Beyond Chess, our system holds
promise for diverse applications, from medical diagnostics to financial
forecasting.

摘要：在本次研究中，我們提出了語言模型和查詢分析技術的創新融合，以解鎖人工智慧中的認知。我們的系統將西洋棋引擎與語言模型無縫整合，使其能夠預測棋步並提供策略說明。我們的 OpenSI AI 系統利用向量資料庫來達成可擷取答案的產生，闡明其決策過程，縮小了原始運算與類人理解之間的差距。我們選擇西洋棋作為示範環境，突顯了我們方法的多功能性。除了西洋棋之外，我們的系統有望應用於各種領域，從醫療診斷到財務預測。

##### **Ensemble BERT: A student social network text sentiment classification model based on ensemble learning and BERT architecture**
2408.04849v1 by Kai Jiang, Honghao Yang, Yuexian Wang, Qianru Chen, Yiming Luo

The mental health assessment of middle school students has always been one of
the focuses in the field of education. This paper introduces a new ensemble
learning network based on BERT, employing the concept of enhancing model
performance by integrating multiple classifiers. We trained a range of
BERT-based learners, which combined using the majority voting method. We
collect social network text data of middle school students through China's
Weibo and apply the method to the task of classifying emotional tendencies in
middle school students' social network texts. Experimental results suggest that
the ensemble learning network has a better performance than the base model and
the performance of the ensemble learning model, consisting of three
single-layer BERT models, is barely the same as a three-layer BERT model but
requires 11.58% more training time. Therefore, in terms of balancing prediction
effect and efficiency, the deeper BERT network should be preferred for
training. However, for interpretability, network ensembles can provide
acceptable solutions.

摘要：中學生心理健康評估一直是教育領域的關注重點之一。本文介紹了一個基於 BERT 的新集成學習網路，採用整合多個分類器的概念來提升模型效能。我們訓練了一系列基於 BERT 的學習器，並使用多數決投票法進行組合。我們透過中國微博收集中學生的社群網路文字資料，並將此方法應用於分類中學生社群網路文字的情緒傾向的任務中。實驗結果表明，集成學習網路的效能優於基礎模型，且由三個單層 BERT 模型組成的集成學習模型的效能與三層 BERT 模型幾乎相同，但訓練時間卻多了 11.58%。因此，在平衡預測效果和效率方面，應優先考慮較深的 BERT 網路進行訓練。然而，對於可解釋性而言，網路集成可以提供可接受的解決方案。

##### **Towards Synergistic Deep Learning Models for Volumetric Cirrhotic Liver Segmentation in MRIs**
2408.04491v1 by Vandan Gorade, Onkar Susladkar, Gorkem Durak, Elif Keles, Ertugrul Aktas, Timurhan Cebeci, Alpay Medetalibeyoglu, Daniela Ladner, Debesh Jha, Ulas Bagci

Liver cirrhosis, a leading cause of global mortality, requires precise
segmentation of ROIs for effective disease monitoring and treatment planning.
Existing segmentation models often fail to capture complex feature interactions
and generalize across diverse datasets. To address these limitations, we
propose a novel synergistic theory that leverages complementary latent spaces
for enhanced feature interaction modeling. Our proposed architecture,
nnSynergyNet3D integrates continuous and discrete latent spaces for 3D volumes
and features auto-configured training. This approach captures both fine-grained
and coarse features, enabling effective modeling of intricate feature
interactions. We empirically validated nnSynergyNet3D on a private dataset of
628 high-resolution T1 abdominal MRI scans from 339 patients. Our model
outperformed the baseline nnUNet3D by approximately 2%. Additionally, zero-shot
testing on healthy liver CT scans from the public LiTS dataset demonstrated
superior cross-modal generalization capabilities. These results highlight the
potential of synergistic latent space models to improve segmentation accuracy
and robustness, thereby enhancing clinical workflows by ensuring consistency
across CT and MRI modalities.

摘要：肝硬化是全球死亡的主要原因，需要对 ROI 进行精确分割，以进行有效的疾病监测和治疗计划。现有的分割模型通常无法捕捉复杂的特征交互，并在不同的数据集上进行泛化。为了解决这些限制，我们提出了一种新颖的协同理论，该理论利用互补的潜在空间来增强特征交互建模。我们提出的架构 nnSynergyNet3D 集成了连续和离散的潜在空间，用于 3D 体积，并具有自动配置的训练。这种方法捕捉到了细粒度和粗粒度特征，从而能够有效地对复杂的特征交互进行建模。我们根据 339 名患者的 628 个高分辨率 T1 腹部 MRI 扫描的私有数据集对 nnSynergyNet3D 进行了实证验证。我们的模型比基线 nnUNet3D 的性能提高了大约 2%。此外，在来自公共 LiTS 数据集的健康肝脏 CT 扫描上进行零样本测试证明了其卓越的跨模态泛化能力。这些结果突出了协同潜在空间模型在提高分割精度和鲁棒性方面的潜力，从而通过确保 CT 和 MRI 模态的一致性来增强临床工作流程。

##### **Advancing oncology with federated learning: transcending boundaries in breast, lung, and prostate cancer. A systematic review**
2408.05249v1 by Anshu Ankolekar, Sebastian Boie, Maryam Abdollahyan, Emanuela Gadaleta, Seyed Alireza Hasheminasab, Guang Yang, Charles Beauville, Nikolaos Dikaios, George Anthony Kastis, Michael Bussmann, Sara Khalid, Hagen Kruger, Philippe Lambin, Giorgos Papanastasiou

Federated Learning (FL) has emerged as a promising solution to address the
limitations of centralised machine learning (ML) in oncology, particularly in
overcoming privacy concerns and harnessing the power of diverse, multi-center
data. This systematic review synthesises current knowledge on the
state-of-the-art FL in oncology, focusing on breast, lung, and prostate cancer.
Distinct from previous surveys, our comprehensive review critically evaluates
the real-world implementation and impact of FL on cancer care, demonstrating
its effectiveness in enhancing ML generalisability, performance and data
privacy in clinical settings and data. We evaluated state-of-the-art advances
in FL, demonstrating its growing adoption amid tightening data privacy
regulations. FL outperformed centralised ML in 15 out of the 25 studies
reviewed, spanning diverse ML models and clinical applications, and
facilitating integration of multi-modal information for precision medicine.
Despite the current challenges identified in reproducibility, standardisation
and methodology across studies, the demonstrable benefits of FL in harnessing
real-world data and addressing clinical needs highlight its significant
potential for advancing cancer research. We propose that future research should
focus on addressing these limitations and investigating further advanced FL
methods, to fully harness data diversity and realise the transformative power
of cutting-edge FL in cancer care.

摘要：聯邦學習 (FL) 已成為了解決腫瘤學中集中式機器學習 (ML) 限制的有前途的解決方案，特別是在克服隱私問題和利用多中心異質資料的力量方面。這項系統性回顧綜合了腫瘤學中最新 FL 的現有知識，重點關注乳癌、肺癌和前列腺癌。與先前的調查不同，我們的全面回顧批判性地評估了 FL 在癌症照護中的實際執行和影響，證明了它在增強 ML 的概括性、效能和臨床環境和資料中的資料隱私方面的有效性。我們評估了 FL 的最新進展，證明了它在日益嚴格的資料隱私法規中獲得越來越廣泛的採用。在所回顧的 25 項研究中，FL 在 15 項研究中優於集中式 ML，涵蓋了多種 ML 模型和臨床應用，並促進了多模式資訊整合以進行精準醫療。儘管在各項研究中發現了再現性、標準化和方法方面的現有挑戰，但 FL 在利用真實世界資料和解決臨床需求方面已展現出的好處突顯了其在推進癌症研究方面的巨大潛力。我們建議未來的研究應重點解決這些限制，並進一步研究先進的 FL 方法，以充分利用資料的多樣性，並實現尖端 FL 在癌症照護中的轉化力量。

##### **Non-maximizing policies that fulfill multi-criterion aspirations in expectation**
2408.04385v1 by Simon Dima, Simon Fischer, Jobst Heitzig, Joss Oliver

In dynamic programming and reinforcement learning, the policy for the
sequential decision making of an agent in a stochastic environment is usually
determined by expressing the goal as a scalar reward function and seeking a
policy that maximizes the expected total reward. However, many goals that
humans care about naturally concern multiple aspects of the world, and it may
not be obvious how to condense those into a single reward function.
Furthermore, maximization suffers from specification gaming, where the obtained
policy achieves a high expected total reward in an unintended way, often taking
extreme or nonsensical actions.
  Here we consider finite acyclic Markov Decision Processes with multiple
distinct evaluation metrics, which do not necessarily represent quantities that
the user wants to be maximized. We assume the task of the agent is to ensure
that the vector of expected totals of the evaluation metrics falls into some
given convex set, called the aspiration set. Our algorithm guarantees that this
task is fulfilled by using simplices to approximate feasibility sets and
propagate aspirations forward while ensuring they remain feasible. It has
complexity linear in the number of possible state-action-successor triples and
polynomial in the number of evaluation metrics. Moreover, the explicitly
non-maximizing nature of the chosen policy and goals yields additional degrees
of freedom, which can be used to apply heuristic safety criteria to the choice
of actions. We discuss several such safety criteria that aim to steer the agent
towards more conservative behavior.

摘要：在動態規劃和強化學習中，代理人在隨機環境中進行順序決策的策略通常通過將目標表達為標量獎勵函數並尋求最大化預期總獎勵的策略來確定。然而，人類關心的許多目標自然涉及世界的多個方面，並且可能並不清楚如何將這些目標濃縮成單一的獎勵函數。此外，最大化會受到規範博弈的影響，其中獲得的策略以意外的方式實現了很高的預期總獎勵，通常採取極端或荒謬的行動。
在這裡，我們考慮具有多個不同評估指標的有限無環馬可夫決策過程，這些指標不一定表示用戶希望最大化的數量。我們假設代理人的任務是確保評估指標預期總量的向量落入某個給定的凸集，稱為願望集。我們的演算法保證通過使用單形來逼近可行集並在確保可行性的同時向前傳播願望來完成此任務。它的複雜度與可能的狀態-動作-後繼三元組的數量呈線性關係，與評估指標的數量呈多項式關係。此外，所選策略和目標的顯式非最大化性質產生了額外的自由度，可用於將啟發式安全準則應用於動作的選擇。我們討論了幾個這樣的安全準則，旨在引導代理人採取更保守的行為。

##### **AI-Driven Chatbot for Intrusion Detection in Edge Networks: Enhancing Cybersecurity with Ethical User Consent**
2408.04281v1 by Mugheez Asif, Abdul Manan, Abdul Moiz ur Rehman, Mamoona Naveed Asghar, Muhammad Umair

In today's contemporary digital landscape, chatbots have become indispensable
tools across various sectors, streamlining customer service, providing personal
assistance, automating routine tasks, and offering health advice. However,
their potential remains underexplored in the realm of network security,
particularly for intrusion detection. To bridge this gap, we propose an
architecture chatbot specifically designed to enhance security within edge
networks specifically for intrusion detection. Leveraging advanced machine
learning algorithms, this chatbot will monitor network traffic to identify and
mitigate potential intrusions. By securing the network environment using an
edge network managed by a Raspberry Pi module and ensuring ethical user consent
promoting transparency and trust, this innovative solution aims to safeguard
sensitive data and maintain a secure workplace, thereby addressing the growing
need for robust network security measures in the digital age.

摘要：在當今的現代數位環境中，聊天機器人已成為各個產業不可或缺的工具，簡化客戶服務、提供個人協助、自動化例行工作並提供健康建議。然而，它們在網路安全領域的潛力仍未得到充分探索，特別是在入侵偵測方面。為了彌補這個差距，我們提出了一種專門設計用於增強邊緣網路內部安全性的架構聊天機器人，特別是用於入侵偵測。透過利用先進的機器學習演算法，此聊天機器人將監控網路流量以識別和減輕潛在入侵。透過使用由 Raspberry Pi 模組管理的邊緣網路來保護網路環境，並確保合乎道德的使用者同意以促進透明度和信任，這個創新的解決方案旨在保護敏感資料並維護一個安全的工作場所，從而滿足數位時代對強大網路安全措施日益增長的需求。

##### **Dynamic Fog Computing for Enhanced LLM Execution in Medical Applications**
2408.04680v1 by Philipp Zagar, Vishnu Ravi, Lauren Aalami, Stephan Krusche, Oliver Aalami, Paul Schmiedmayer

The ability of large language models (LLMs) to transform, interpret, and
comprehend vast quantities of heterogeneous data presents a significant
opportunity to enhance data-driven care delivery. However, the sensitive nature
of protected health information (PHI) raises valid concerns about data privacy
and trust in remote LLM platforms. In addition, the cost associated with
cloud-based artificial intelligence (AI) services continues to impede
widespread adoption. To address these challenges, we propose a shift in the LLM
execution environment from opaque, centralized cloud providers to a
decentralized and dynamic fog computing architecture. By executing open-weight
LLMs in more trusted environments, such as the user's edge device or a fog
layer within a local network, we aim to mitigate the privacy, trust, and
financial challenges associated with cloud-based LLMs. We further present
SpeziLLM, an open-source framework designed to facilitate rapid and seamless
leveraging of different LLM execution layers and lowering barriers to LLM
integration in digital health applications. We demonstrate SpeziLLM's broad
applicability across six digital health applications, showcasing its
versatility in various healthcare settings.

摘要：大型語言模型（LLM）轉換、詮釋和理解大量異質資料的能力，為提升資料驅動的照護提供顯著的契機。然而，受保護健康資訊（PHI）的敏感性質引發了對資料隱私和對遠端 LLM 平台信任的正當疑慮。此外，與雲端人工智慧（AI）服務相關的成本持續阻礙廣泛採用。為了解決這些挑戰，我們建議將 LLM 執行環境從不透明的集中式雲端供應商轉移到分散式動態霧運算架構。透過在更受信任的環境中執行開放權重的 LLM，例如使用者的邊緣裝置或區域網路內的霧層，我們旨在減輕與雲端 LLM 相關的隱私、信任和財務挑戰。我們進一步提出 SpeziLLM，一個開放原始碼架構，旨在促進快速且無縫地利用不同的 LLM 執行層，並降低 LLM 整合在數位健康應用程式的障礙。我們展示了 SpeziLLM 在六個數位健康應用程式中的廣泛適用性，展示了其在各種醫療保健環境中的多功能性。

##### **Dynamic Hypergraph-Enhanced Prediction of Sequential Medical Visits**
2408.07084v2 by Wangying Yang, Zitao Zheng, Shi Bo, Zhizhong Wu, Bo Zhang, Yuanfang Yang

This study introduces a pioneering Dynamic Hypergraph Networks (DHCE) model
designed to predict future medical diagnoses from electronic health records
with enhanced accuracy. The DHCE model innovates by identifying and
differentiating acute and chronic diseases within a patient's visit history,
constructing dynamic hypergraphs that capture the complex, high-order
interactions between diseases. It surpasses traditional recurrent neural
networks and graph neural networks by effectively integrating clinical event
data, reflected through medical language model-assisted encoding, into a robust
patient representation. Through extensive experiments on two benchmark
datasets, MIMIC-III and MIMIC-IV, the DHCE model exhibits superior performance,
significantly outpacing established baseline models in the precision of
sequential diagnosis prediction.

摘要：本研究引入了一個開創性的動態超圖網路 (DHCE) 模型，旨在透過電子健康記錄預測未來的醫療診斷，並提高準確性。DHCE 模型透過辨識和區分病患就診病史中的急性病和慢性病，建構動態超圖以擷取疾病之間複雜的高階互動，進而創新。它透過將臨床事件資料有效整合到健全的病患表徵中，並透過醫療語言模型輔助編碼反映出來，超越了傳統的遞迴神經網路和圖神經網路。透過在兩個基準資料集 MIMIC-III 和 MIMIC-IV 上進行廣泛的實驗，DHCE 模型展現出優異的效能，在序貫診斷預測的準確度上顯著超越既定的基準模型。

##### **The Data Addition Dilemma**
2408.04154v1 by Judy Hanwen Shen, Inioluwa Deborah Raji, Irene Y. Chen

In many machine learning for healthcare tasks, standard datasets are
constructed by amassing data across many, often fundamentally dissimilar,
sources. But when does adding more data help, and when does it hinder progress
on desired model outcomes in real-world settings? We identify this situation as
the \textit{Data Addition Dilemma}, demonstrating that adding training data in
this multi-source scaling context can at times result in reduced overall
accuracy, uncertain fairness outcomes, and reduced worst-subgroup performance.
We find that this possibly arises from an empirically observed trade-off
between model performance improvements due to data scaling and model
deterioration from distribution shift. We thus establish baseline strategies
for navigating this dilemma, introducing distribution shift heuristics to guide
decision-making on which data sources to add in data scaling, in order to yield
the expected model performance improvements. We conclude with a discussion of
the required considerations for data collection and suggestions for studying
data composition and scale in the age of increasingly larger models.

摘要：在許多醫療保健任務的機器學習中，標準資料集是透過收集來自許多通常根本不同的來源的資料而建構的。但是，何時新增更多資料有幫助，而何時會阻礙在現實世界設定中達成預期的模型成果？我們將此情況認定為「資料新增困境」，證明在此多來源擴充的背景下新增訓練資料，有時可能會導致整體準確度降低、不確定的公平性結果，以及最差子群體效能降低。我們發現這可能是由於資料擴充導致的模型效能提升與分配轉移導致的模型劣化之間的經驗性權衡所致。因此，我們建立了應對此困境的基本策略，引入了分配轉移啟發法，以指導有關在資料擴充中新增哪些資料來源的決策制定，以產生預期的模型效能提升。我們最後討論了資料收集所需的考量因素，並建議研究資料組成和規模在模型規模日益擴大的時代。

##### **Enhancing Healthcare through Large Language Models: A Study on Medical Question Answering**
2408.04138v1 by Haoran Yu, Chang Yu, Zihan Wang, Dongxian Zou, Hao Qin

In recent years, the application of Large Language Models (LLMs) in
healthcare has shown significant promise in improving the accessibility and
dissemination of medical knowledge. This paper presents a detailed study of
various LLMs trained on the MedQuAD medical question-answering dataset, with a
focus on identifying the most effective model for providing accurate medical
information. Among the models tested, the Sentence-t5 combined with Mistral 7B
demonstrated superior performance, achieving a precision score of 0.762. This
model's enhanced capabilities are attributed to its advanced pretraining
techniques, robust architecture, and effective prompt construction
methodologies. By leveraging these strengths, the Sentence-t5 + Mistral 7B
model excels in understanding and generating precise medical answers. Our
findings highlight the potential of integrating sophisticated LLMs in medical
contexts to facilitate efficient and accurate medical knowledge retrieval, thus
significantly enhancing patient education and support.

摘要：近年來，大型語言模型 (LLM) 在醫療保健中的應用已展現出顯著的希望，可改善醫療知識的可及性和傳播。本文針對在 MedQuAD 醫療問答資料集上訓練的各種 LLM 進行詳細研究，重點在於找出提供準確醫療資訊最有效的模型。在測試的模型中，Sentence-t5 結合 Mistral 7B 表現優異，達到 0.762 的精準度分數。此模型的增強功能歸功於其先進的預訓練技術、強大的架構和有效的提示建構方法。Sentence-t5 + Mistral 7B 模型藉由運用這些優勢，在理解和產生精確的醫療答案方面表現出色。我們的研究結果突顯了將複雜的 LLM 整合到醫療背景中的潛力，以促進有效率且準確的醫療知識擷取，進而顯著提升病患教育和支持。

##### **Can Rule-Based Insights Enhance LLMs for Radiology Report Classification? Introducing the RadPrompt Methodology**
2408.04121v1 by Panagiotis Fytas, Anna Breger, Ian Selby, Simon Baker, Shahab Shahipasand, Anna Korhonen

Developing imaging models capable of detecting pathologies from chest X-rays
can be cost and time-prohibitive for large datasets as it requires supervision
to attain state-of-the-art performance. Instead, labels extracted from
radiology reports may serve as distant supervision since these are routinely
generated as part of clinical practice. Despite their widespread use, current
rule-based methods for label extraction rely on extensive rule sets that are
limited in their robustness to syntactic variability. To alleviate these
limitations, we introduce RadPert, a rule-based system that integrates an
uncertainty-aware information schema with a streamlined set of rules, enhancing
performance. Additionally, we have developed RadPrompt, a multi-turn prompting
strategy that leverages RadPert to bolster the zero-shot predictive
capabilities of large language models, achieving a statistically significant
improvement in weighted average F1 score over GPT-4 Turbo. Most notably,
RadPrompt surpasses both its underlying models, showcasing the synergistic
potential of LLMs with rule-based models. We have evaluated our methods on two
English Corpora: the MIMIC-CXR gold-standard test set and a gold-standard
dataset collected from the Cambridge University Hospitals.

摘要：開發出能夠從胸部 X 光檢測病理的影像模型，對於大型資料集來說，在成本和時間上都可能是禁止的，因為它需要監督才能達到最先進的效能。相反地，從放射科報告中提取的標籤可以用作遠端監督，因為這些標籤通常作為臨床實務的一部分而產生。儘管廣泛使用，但目前用於標籤提取的基於規則的方法依賴於廣泛的規則集，其對語法變異的健壯性有限。為了減輕這些限制，我們引入了 RadPert，這是一個基於規則的系統，它將一個不確定性感知資訊架構與一組簡化的規則整合在一起，從而增強了效能。此外，我們還開發了 RadPrompt，這是一個多輪提示策略，它利用 RadPert 來加強大型語言模型的零次學習預測能力，在加權平均 F1 分數上實現了相對於 GPT-4 Turbo 的統計顯著改進。最值得注意的是，RadPrompt 超越了其基礎模型，展示了基於規則的模型與 LLM 的協同潛力。我們已在兩個英文語料庫上評估了我們的方法：MIMIC-CXR 黃金標準測試集和從劍橋大學醫院收集的黃金標準資料集。

##### **Handwritten Code Recognition for Pen-and-Paper CS Education**
2408.07220v1 by Md Sazzad Islam, Moussa Koulako Bala Doumbouya, Christopher D. Manning, Chris Piech

Teaching Computer Science (CS) by having students write programs by hand on
paper has key pedagogical advantages: It allows focused learning and requires
careful thinking compared to the use of Integrated Development Environments
(IDEs) with intelligent support tools or "just trying things out". The familiar
environment of pens and paper also lessens the cognitive load of students with
no prior experience with computers, for whom the mere basic usage of computers
can be intimidating. Finally, this teaching approach opens learning
opportunities to students with limited access to computers.
  However, a key obstacle is the current lack of teaching methods and support
software for working with and running handwritten programs. Optical character
recognition (OCR) of handwritten code is challenging: Minor OCR errors, perhaps
due to varied handwriting styles, easily make code not run, and recognizing
indentation is crucial for languages like Python but is difficult to do due to
inconsistent horizontal spacing in handwriting. Our approach integrates two
innovative methods. The first combines OCR with an indentation recognition
module and a language model designed for post-OCR error correction without
introducing hallucinations. This method, to our knowledge, surpasses all
existing systems in handwritten code recognition. It reduces error from 30\% in
the state of the art to 5\% with minimal hallucination of logical fixes to
student programs. The second method leverages a multimodal language model to
recognize handwritten programs in an end-to-end fashion. We hope this
contribution can stimulate further pedagogical research and contribute to the
goal of making CS education universally accessible. We release a dataset of
handwritten programs and code to support future research at
https://github.com/mdoumbouya/codeocr

摘要：透過讓學生手寫程式在紙上，教授電腦科學 (CS) 具有關鍵的教學優勢：它允許專注學習，並需要仔細思考，與使用具備智慧支援工具或「只是嘗試」的整合開發環境 (IDE) 相比。熟悉筆和紙的環境也會減輕沒有電腦經驗學生的認知負擔，對他們來說，光是電腦的基本使用就可能令人望而生畏。最後，這種教學方法為電腦使用受限的學生開啟了學習機會。
然而，一個主要的障礙是目前缺乏支援手寫程式編寫和執行的教學方法和軟體。手寫程式碼的光學字元辨識 (OCR) 具有挑戰性：輕微的 OCR 錯誤，可能是由於不同的手寫風格，很容易讓程式無法執行，而辨識縮排對 Python 等語言至關重要，但由於手寫的水平間距不一致，因此很難做到。我們的做法整合了兩種創新的方法。第一個方法結合 OCR、縮排辨識模組和語言模型，該模型專門用於 OCR 後的錯誤修正，而不會引入幻覺。據我們所知，此方法超越了所有現有的手寫程式碼辨識系統。它將錯誤從現有技術的 30% 降低到 5%，並將學生程式的邏輯修正幻覺降至最低。第二種方法利用多模式語言模型以端到端的方式辨識手寫程式。我們希望此貢獻能激勵進一步的教學研究，並有助於實現讓 CS 教育普及的目標。我們釋出了手寫程式和程式碼的資料集，以支援未來的研究，網址為 https://github.com/mdoumbouya/codeocr

##### **Multimodal Gender Fairness in Depression Prediction: Insights on Data from the USA & China**
2408.04026v1 by Joseph Cameron, Jiaee Cheong, Micol Spitale, Hatice Gunes

Social agents and robots are increasingly being used in wellbeing settings.
However, a key challenge is that these agents and robots typically rely on
machine learning (ML) algorithms to detect and analyse an individual's mental
wellbeing. The problem of bias and fairness in ML algorithms is becoming an
increasingly greater source of concern. In concurrence, existing literature has
also indicated that mental health conditions can manifest differently across
genders and cultures. We hypothesise that the representation of features
(acoustic, textual, and visual) and their inter-modal relations would vary
among subjects from different cultures and genders, thus impacting the
performance and fairness of various ML models. We present the very first
evaluation of multimodal gender fairness in depression manifestation by
undertaking a study on two different datasets from the USA and China. We
undertake thorough statistical and ML experimentation and repeat the
experiments for several different algorithms to ensure that the results are not
algorithm-dependent. Our findings indicate that though there are differences
between both datasets, it is not conclusive whether this is due to the
difference in depression manifestation as hypothesised or other external
factors such as differences in data collection methodology. Our findings
further motivate a call for a more consistent and culturally aware data
collection process in order to address the problem of ML bias in depression
detection and to promote the development of fairer agents and robots for
wellbeing.

摘要：社群代理人和機器人在幸福感設定中正越來越廣泛地被使用。
然而，一個關鍵的挑戰是這些代理人和機器人通常依賴機器學習 (ML) 演算法來偵測和分析個人心理健康。ML 演算法中的偏差和公平性問題正成為越來越大的關注來源。同時，現有文獻也指出心理健康狀況會在不同性別和文化中以不同的方式顯現。我們假設特徵（聲音、文字和視覺）的呈現及其跨模態關係會因不同文化和性別的受試者而異，從而影響各種 ML 模型的效能和公平性。我們透過對來自美國和中國的兩個不同資料集進行研究，提出首次對憂鬱症表現的多模態性別公平性評估。我們進行徹底的統計和 ML 實驗，並針對多種不同的演算法重複實驗，以確保結果不依賴於演算法。我們的研究結果表明，儘管兩個資料集之間存在差異，但無法確定這是否是由於假設的憂鬱症表現差異或其他外部因素（例如資料收集方法的差異）所造成。我們的研究結果進一步呼籲採用更一致且具有文化意識的資料收集程序，以解決憂鬱症偵測中的 ML 偏差問題，並促進開發更公平的代理人和機器人，以提升幸福感。

##### **Inter-Series Transformer: Attending to Products in Time Series Forecasting**
2408.03872v1 by Rares Cristian, Pavithra Harsha, Clemente Ocejo, Georgia Perakis, Brian Quanz, Ioannis Spantidakis, Hamza Zerhouni

Time series forecasting is an important task in many fields ranging from
supply chain management to weather forecasting. Recently, Transformer neural
network architectures have shown promising results in forecasting on common
time series benchmark datasets. However, application to supply chain demand
forecasting, which can have challenging characteristics such as sparsity and
cross-series effects, has been limited.
  In this work, we explore the application of Transformer-based models to
supply chain demand forecasting. In particular, we develop a new
Transformer-based forecasting approach using a shared, multi-task per-time
series network with an initial component applying attention across time series,
to capture interactions and help address sparsity. We provide a case study
applying our approach to successfully improve demand prediction for a medical
device manufacturing company. To further validate our approach, we also apply
it to public demand forecasting datasets as well and demonstrate competitive to
superior performance compared to a variety of baseline and state-of-the-art
forecast methods across the private and public datasets.

摘要：時間序列預測在許多領域中都是一項重要的任務，從供應鏈管理到天氣預測都有涉及。最近，Transformer 神經網路架構在常見時間序列基準資料集的預測中展現了令人滿意的成果。然而，應用於供應鏈需求預測的範疇受到限制，因為供應鏈需求預測可能具有稀疏性和跨系列效應等具挑戰性的特徵。
  在這項工作中，我們探討了將基於 Transformer 的模型應用於供應鏈需求預測。特別是，我們開發了一種新的基於 Transformer 的預測方法，使用一個共用的、每個時間序列的多任務網路，並在初始元件中套用跨時間序列的注意力，以擷取互動並協助解決稀疏性問題。我們提供了一個案例研究，應用我們的做法成功改善了一家醫療器材製造公司的需求預測。為了進一步驗證我們的做法，我們也將其應用於公開的需求預測資料集，並證明與各種基線和最先進的預測方法相比，在私有和公開資料集中的表現具有競爭力或優於這些方法。

##### **Anatomical Foundation Models for Brain MRIs**
2408.07079v1 by Carlo Alberto Barbano, Matteo Brunello, Benoit Dufumier, Marco Grangetto

Deep Learning (DL) in neuroimaging has become increasingly relevant for
detecting neurological conditions and neurodegenerative disorders. One of the
most predominant biomarkers in neuroimaging is represented by brain age, which
has been shown to be a good indicator for different conditions, such as
Alzheimer's Disease. Using brain age for pretraining DL models in transfer
learning settings has also recently shown promising results, especially when
dealing with data scarcity of different conditions. On the other hand,
anatomical information of brain MRIs (e.g. cortical thickness) can provide
important information for learning good representations that can be transferred
to many downstream tasks. In this work, we propose AnatCL, an anatomical
foundation model for brain MRIs that i.) leverages anatomical information with
a weakly contrastive learning approach and ii.) achieves state-of-the-art
performances in many different downstream tasks. To validate our approach we
consider 12 different downstream tasks for diagnosis classification, and
prediction of 10 different clinical assessment scores.

摘要：深度學習 (DL) 在神經影像學中已變得越來越重要，可用於偵測神經系統疾病和神經退化性疾病。神經影像學中最重要的生物標記之一是大腦年齡，已顯示為各種疾病（例如阿茲海默症）的良好指標。最近，使用大腦年齡進行預訓練 DL 模型以用於遷移學習設定也顯示出有希望的結果，特別是在處理各種疾病的資料稀少時。另一方面，大腦 MRI 的解剖資訊（例如皮質厚度）可以提供重要資訊，用於學習可以轉移到許多下游任務的良好表示。在這項工作中，我們提出 AnatCL，這是一個用於大腦 MRI 的解剖基礎模型，它 i.) 利用解剖資訊和弱對比學習方法，以及 ii.) 在許多不同的下游任務中實現最先進的效能。為了驗證我們的做法，我們考慮了 12 個不同的下游任務，用於診斷分類和預測 10 個不同的臨床評分。

##### **HiQuE: Hierarchical Question Embedding Network for Multimodal Depression Detection**
2408.03648v1 by Juho Jung, Chaewon Kang, Jeewoo Yoon, Seungbae Kim, Jinyoung Han

The utilization of automated depression detection significantly enhances
early intervention for individuals experiencing depression. Despite numerous
proposals on automated depression detection using recorded clinical interview
videos, limited attention has been paid to considering the hierarchical
structure of the interview questions. In clinical interviews for diagnosing
depression, clinicians use a structured questionnaire that includes routine
baseline questions and follow-up questions to assess the interviewee's
condition. This paper introduces HiQuE (Hierarchical Question Embedding
network), a novel depression detection framework that leverages the
hierarchical relationship between primary and follow-up questions in clinical
interviews. HiQuE can effectively capture the importance of each question in
diagnosing depression by learning mutual information across multiple
modalities. We conduct extensive experiments on the widely-used clinical
interview data, DAIC-WOZ, where our model outperforms other state-of-the-art
multimodal depression detection models and emotion recognition models,
showcasing its clinical utility in depression detection.

摘要：自動憂鬱症偵測的利用顯著提升了憂鬱症患者的早期介入。儘管有許多使用錄製臨床訪談影片的自動憂鬱症偵測提案，但對於考量訪談問題的階層結構這方面卻鮮少關注。在用於診斷憂鬱症的臨床訪談中，臨床醫師會使用包含例行基準問題和追蹤問題的結構化問卷來評估受訪者的狀況。本文介紹了 HiQuE（階層式問題嵌入網路），這是一種新穎的憂鬱症偵測架構，它利用了臨床訪談中主要問題和追蹤問題之間的階層關係。HiQuE 能夠透過學習多種方式之間的互惠資訊，有效地擷取每個問題在憂鬱症診斷中的重要性。我們在廣泛使用的臨床訪談資料 DAIC-WOZ 上進行了廣泛的實驗，我們的模型優於其他最先進的多模態憂鬱症偵測模型和情緒辨識模型，展示了其在憂鬱症偵測中的臨床效用。

##### **Improving the quality of Persian clinical text with a novel spelling correction system**
2408.03622v1 by Seyed Mohammad Sadegh Dashti, Seyedeh Fatemeh Dashti

Background: The accuracy of spelling in Electronic Health Records (EHRs) is a
critical factor for efficient clinical care, research, and ensuring patient
safety. The Persian language, with its abundant vocabulary and complex
characteristics, poses unique challenges for real-word error correction. This
research aimed to develop an innovative approach for detecting and correcting
spelling errors in Persian clinical text.
  Methods: Our strategy employs a state-of-the-art pre-trained model that has
been meticulously fine-tuned specifically for the task of spelling correction
in the Persian clinical domain. This model is complemented by an innovative
orthographic similarity matching algorithm, PERTO, which uses visual similarity
of characters for ranking correction candidates.
  Results: The evaluation of our approach demonstrated its robustness and
precision in detecting and rectifying word errors in Persian clinical text. In
terms of non-word error correction, our model achieved an F1-Score of 90.0%
when the PERTO algorithm was employed. For real-word error detection, our model
demonstrated its highest performance, achieving an F1-Score of 90.6%.
Furthermore, the model reached its highest F1-Score of 91.5% for real-word
error correction when the PERTO algorithm was employed.
  Conclusions: Despite certain limitations, our method represents a substantial
advancement in the field of spelling error detection and correction for Persian
clinical text. By effectively addressing the unique challenges posed by the
Persian language, our approach paves the way for more accurate and efficient
clinical documentation, contributing to improved patient care and safety.
Future research could explore its use in other areas of the Persian medical
domain, enhancing its impact and utility.

摘要：背景：電子病歷 (EHR) 中拼寫的準確性是有效臨床照護、研究和確保患者安全性的關鍵因素。波斯語擁有豐富的詞彙和複雜的特徵，對真實世界的錯誤更正提出了獨特的挑戰。本研究旨在開發一種創新的方法來偵測和更正波斯語臨床文本中的拼寫錯誤。
方法：我們的策略採用了最先進的預訓練模型，該模型經過精心微調，專門用於波斯語臨床領域中的拼寫更正任務。此模型由創新的正字法相似性匹配演算法 PERTO 補充，該演算法使用字元的視覺相似性來對更正候選項進行排名。
結果：對我們方法的評估證明了其在偵測和糾正波斯語臨床文本中的文字錯誤方面的穩健性和準確性。在非文字錯誤更正方面，當使用 PERTO 演算法時，我們的模型實現了 90.0% 的 F1 分數。對於真實世界的錯誤偵測，我們的模型展示了其最高的效能，實現了 90.6% 的 F1 分數。此外，當使用 PERTO 演算法時，該模型達到了其最高的 F1 分數 91.5%，用於真實世界的錯誤更正。
結論：儘管存在某些限制，但我們的模型代表了波斯語臨床文本拼寫錯誤偵測和更正領域的重大進展。透過有效解決波斯語所帶來的獨特挑戰，我們的做法為更準確和有效的臨床文件鋪路，有助於改善患者照護和安全性。未來的研究可以探討其在波斯語醫學領域其他領域的應用，以增強其影響力和實用性。

##### **Identifying treatment response subgroups in observational time-to-event data**
2408.03463v1 by Vincent Jeanselme, Chang Ho Yoon, Fabian Falck, Brian Tom, Jessica Barrett

Identifying patient subgroups with different treatment responses is an
important task to inform medical recommendations, guidelines, and the design of
future clinical trials. Existing approaches for subgroup analysis primarily
focus on Randomised Controlled Trials (RCTs), in which treatment assignment is
randomised. Furthermore, the patient cohort of an RCT is often constrained by
cost, and is not representative of the heterogeneity of patients likely to
receive treatment in real-world clinical practice. Therefore, when applied to
observational studies, such approaches suffer from significant statistical
biases because of the non-randomisation of treatment. Our work introduces a
novel, outcome-guided method for identifying treatment response subgroups in
observational studies. Our approach assigns each patient to a subgroup
associated with two time-to-event distributions: one under treatment and one
under control regime. It hence positions itself in between individualised and
average treatment effect estimation. The assumptions of our model result in a
simple correction of the statistical bias from treatment non-randomisation
through inverse propensity weighting. In experiments, our approach
significantly outperforms the current state-of-the-art method for
outcome-guided subgroup analysis in both randomised and observational treatment
regimes.

摘要：識別具有不同治療反應的患者子群是為醫療建議、指南和未來臨床試驗的設計提供資訊的一項重要任務。現有的子群分析方法主要集中於隨機對照試驗 (RCT)，其中治療分配是隨機的。此外，RCT 的患者群體通常受到成本的限制，且無法代表在現實世界臨床實務中可能接受治療的患者異質性。因此，當應用於觀察性研究時，此類方法會因治療的非隨機化而產生顯著的統計偏差。我們的研究引入了一種新的、結果導向的方法，用於識別觀察性研究中的治療反應子群。我們的做法是將每個患者分配到一個子群，該子群與兩個事件發生時間分配相關：一個在治療下，另一個在對照機制下。因此，它介於個別化和平均治療效果估計之間。我們模型的假設導致通過逆向傾向加權對來自治療非隨機化的統計偏差進行簡單校正。在實驗中，我們的做法在隨機和觀察性治療機制中都顯著優於當前最先進的結果導向子群分析方法。

##### **Combining Diverse Information for Coordinated Action: Stochastic Bandit Algorithms for Heterogeneous Agents**
2408.03405v1 by Lucia Gordon, Esther Rolf, Milind Tambe

Stochastic multi-agent multi-armed bandits typically assume that the rewards
from each arm follow a fixed distribution, regardless of which agent pulls the
arm. However, in many real-world settings, rewards can depend on the
sensitivity of each agent to their environment. In medical screening, disease
detection rates can vary by test type; in preference matching, rewards can
depend on user preferences; and in environmental sensing, observation quality
can vary across sensors. Since past work does not specify how to allocate
agents of heterogeneous but known sensitivity of these types in a stochastic
bandit setting, we introduce a UCB-style algorithm, Min-Width, which aggregates
information from diverse agents. In doing so, we address the joint challenges
of (i) aggregating the rewards, which follow different distributions for each
agent-arm pair, and (ii) coordinating the assignments of agents to arms.
Min-Width facilitates efficient collaboration among heterogeneous agents,
exploiting the known structure in the agents' reward functions to weight their
rewards accordingly. We analyze the regret of Min-Width and conduct
pseudo-synthetic and fully synthetic experiments to study the performance of
different levels of information sharing. Our results confirm that the gains to
modeling agent heterogeneity tend to be greater when the sensitivities are more
varied across agents, while combining more information does not always improve
performance.

摘要：隨機多智能體多臂賭徒通常假設每個手臂的回報遵循固定分佈，無論哪個智能體拉動手臂。然而，在許多真實世界設定中，回報可能取決於每個智能體對其環境的敏感度。在醫學篩檢中，疾病檢測率會因測試類型而異；在偏好匹配中，回報可能取決於使用者偏好；在環境感測中，觀察品質可能因感測器而異。由於過去的工作未說明如何配置這些類型異質但已知敏感度的智能體在隨機賭徒設定中，我們引入一種 UCB 風格演算法，Min-Width，它會彙總來自不同智能體的資訊。在這樣做的過程中，我們解決了 (i) 彙總回報的共同挑戰，這些回報遵循每個智能體手臂配對的不同分佈，以及 (ii) 協調將智能體指定給手臂。Min-Width 促進異質智能體之間的有效協作，利用智能體回報函數中的已知結構來適當地加權其回報。我們分析 Min-Width 的遺憾，並進行偽合成和完全合成實驗來研究不同層級資訊共享的效能。我們的結果證實，當敏感度在不同智能體間差異較大時，對智能體異質性建模的收益往往較高，而結合更多資訊並不總是會改善效能。

##### **MLC-GCN: Multi-Level Generated Connectome Based GCN for AD Analysis**
2408.03358v1 by Wenqi Zhu, Yinghua Fu, Ze Wang

Alzheimer's Disease (AD) is a currently incurable neurodegeneartive disease.
Accurately detecting AD, especially in the early stage, represents a high
research priority. AD is characterized by progressive cognitive impairments
that are related to alterations in brain functional connectivity (FC). Based on
this association, many studies have been published over the decades using FC
and machine learning to differentiate AD from healthy aging. The most recent
development in this detection method highlights the use of graph neural network
(GNN) as the brain functionality analysis. In this paper, we proposed a stack
of spatio-temporal feature extraction and graph generation based AD
classification model using resting state fMRI. The proposed multi-level
generated connectome (MLC) based graph convolutional network (GCN) (MLC-GCN)
contains a multi-graph generation block and a GCN prediction block. The
multi-graph generation block consists of a hierarchy of spatio-temporal feature
extraction layers for extracting spatio-temporal rsfMRI features at different
depths and building the corresponding connectomes. The GCN prediction block
takes the learned multi-level connectomes to build and optimize GCNs at each
level and concatenates the learned graphical features as the final predicting
features for AD classification. Through independent cohort validations, MLC-GCN
shows better performance for differentiating MCI, AD, and normal aging than
state-of-art GCN and rsfMRI based AD classifiers. The proposed MLC-GCN also
showed high explainability in terms of learning clinically reasonable
connectome node and connectivity features from two independent datasets. While
we only tested MLC-GCN on AD, the basic rsfMRI-based multi-level learned GCN
based outcome prediction strategy is valid for other diseases or clinical
outcomes.

摘要：阿茲海默症 (AD) 是一種目前無法治癒的神經退化性疾病。
準確地偵測 AD，特別是在早期階段，代表一項高度的研究優先事項。AD 的特徵是會逐漸認知功能受損，這與腦部功能連接性 (FC) 的改變有關。基於這種關聯，在過去的數十年中，許多研究已使用 FC 和機器學習來區分 AD 和健康老化。這種偵測方法的最新發展，突顯了使用圖神經網路 (GNN) 作為腦部功能分析。在本文中，我們提出了一個堆疊的時空特徵萃取和圖形生成，基於 AD 分類模型，使用靜止狀態 fMRI。所提出的多層級生成連接組 (MLC) 基於圖形卷積網路 (GCN) (MLC-GCN) 包含一個多圖形生成區塊和一個 GCN 預測區塊。多圖形生成區塊包含一個時空特徵萃取層的階層，用於萃取不同深度下的時空 rsfMRI 特徵，並建立對應的連接組。GCN 預測區塊採用已學習的多層級連接組，在每個層級建立並最佳化 GCN，並將已學習的圖形特徵串聯成用於 AD 分類的最終預測特徵。透過獨立的群組驗證，MLC-GCN 在區分 MCI、AD 和正常老化方面，表現優於最先進的 GCN 和基於 rsfMRI 的 AD 分類器。所提出的 MLC-GCN 也在從兩個獨立的資料集中學習臨床上合理的連接組節點和連接特徵方面，表現出高度的可解釋性。雖然我們只在 AD 上測試 MLC-GCN，但基本的基於 rsfMRI 的多層級學習 GCN 基於結果預測策略，對其他疾病或臨床結果有效。

##### **Personalizing Federated Instrument Segmentation with Visual Trait Priors in Robotic Surgery**
2408.03208v2 by Jialang Xu, Jiacheng Wang, Lequan Yu, Danail Stoyanov, Yueming Jin, Evangelos B. Mazomenos

Personalized federated learning (PFL) for surgical instrument segmentation
(SIS) is a promising approach. It enables multiple clinical sites to
collaboratively train a series of models in privacy, with each model tailored
to the individual distribution of each site. Existing PFL methods rarely
consider the personalization of multi-headed self-attention, and do not account
for appearance diversity and instrument shape similarity, both inherent in
surgical scenes. We thus propose PFedSIS, a novel PFL method with visual trait
priors for SIS, incorporating global-personalized disentanglement (GPD),
appearance-regulation personalized enhancement (APE), and shape-similarity
global enhancement (SGE), to boost SIS performance in each site. GPD represents
the first attempt at head-wise assignment for multi-headed self-attention
personalization. To preserve the unique appearance representation of each site
and gradually leverage the inter-site difference, APE introduces appearance
regulation and provides customized layer-wise aggregation solutions via
hypernetworks for each site's personalized parameters. The mutual shape
information of instruments is maintained and shared via SGE, which enhances the
cross-style shape consistency on the image level and computes the
shape-similarity contribution of each site on the prediction level for updating
the global parameters. PFedSIS outperforms state-of-the-art methods with +1.51%
Dice, +2.11% IoU, -2.79 ASSD, -15.55 HD95 performance gains. The corresponding
code and models will be released at https://github.com/wzjialang/PFedSIS.

摘要：個人化聯邦學習 (PFL) 對於手術器械分割 (SIS) 來說是一種有前景的方法。它能讓多個臨床地點在隱私中共同訓練一系列模型，每個模型都根據每個地點的個別分佈進行調整。現有的 PFL 方法很少考慮多頭自注意力的個人化，而且沒有考慮外觀多樣性和器械形狀相似性，這兩個特徵都存在於手術場景中。因此，我們提出了 PFedSIS，這是一種具有視覺特徵先驗的 SIS 新型 PFL 方法，它結合了全局個人化解糾纏 (GPD)、外觀調節個性化增強 (APE) 和形狀相似性全局增強 (SGE)，以提升每個地點的 SIS 效能。GPD 代表了多頭自注意力個人化中頭部分配的首次嘗試。為了保留每個地點的獨特外觀表示並逐漸利用地點間的差異，APE 引入了外觀調節，並通過超網路為每個地點的個性化參數提供客製化的分層聚合解決方案。器械的相互形狀資訊會透過 SGE 進行維護和共享，這會增強影像層級上的跨樣式形狀一致性，並計算每個地點在預測層級上的形狀相似性貢獻，以更新全局參數。PFedSIS 在骰子係數上優於現有技術 +1.51%，IoU 上優於現有技術 +2.11%，ASSD 上優於現有技術 -2.79，HD95 效能增益上優於現有技術 -15.55。對應的程式碼和模型將在 https://github.com/wzjialang/PFedSIS 發布。

##### **The Use of Large Language Models (LLM) for Cyber Threat Intelligence (CTI) in Cybercrime Forums**
2408.03354v2 by Vanessa Clairoux-Trepanier, Isa-May Beauchamp, Estelle Ruellan, Masarah Paquet-Clouston, Serge-Olivier Paquette, Eric Clay

Large language models (LLMs) can be used to analyze cyber threat intelligence
(CTI) data from cybercrime forums, which contain extensive information and key
discussions about emerging cyber threats. However, to date, the level of
accuracy and efficiency of LLMs for such critical tasks has yet to be
thoroughly evaluated. Hence, this study assesses the accuracy of an LLM system
built on the OpenAI GPT-3.5-turbo model [7] to extract CTI information. To do
so, a random sample of 500 daily conversations from three cybercrime forums,
XSS, Exploit_in, and RAMP, was extracted, and the LLM system was instructed to
summarize the conversations and code 10 key CTI variables, such as whether a
large organization and/or a critical infrastructure is being targeted. Then,
two coders reviewed each conversation and evaluated whether the information
extracted by the LLM was accurate. The LLM system performed strikingly well,
with an average accuracy score of 98%. Various ways to enhance the model were
uncovered, such as the need to help the LLM distinguish between stories and
past events, as well as being careful with verb tenses in prompts.
Nevertheless, the results of this study highlight the efficiency and relevance
of using LLMs for cyber threat intelligence.

摘要：大型語言模型 (LLM) 可用於分析網路犯罪論壇中的網路威脅情報 (CTI) 資料，其中包含有關新興網路威脅的豐富資訊和關鍵討論。然而，到目前為止，LLM 對此類關鍵任務的準確性和效率尚未得到徹底評估。因此，本研究評估了建立在 OpenAI GPT-3.5-turbo 模型 [7] 上的 LLM 系統提取 CTI 資訊的準確性。為此，從三個網路犯罪論壇 XSS、Exploit_in 和 RAMP 中隨機抽取了 500 個每日對話，並指示 LLM 系統總結對話並編碼 10 個關鍵 CTI 變數，例如是否針對大型組織和/或關鍵基礎設施。然後，兩個編碼器檢閱每個對話並評估 LLM 提取的資訊是否準確。LLM 系統表現出色，平均準確度分數為 98%。發現了增強模型的各種方法，例如需要幫助 LLM 區分故事和過去事件，以及在提示中小心使用時態。儘管如此，本研究的結果突顯了使用 LLM 進行網路威脅情報的效率和相關性。

##### **VizECGNet: Visual ECG Image Network for Cardiovascular Diseases Classification with Multi-Modal Training and Knowledge Distillation**
2408.02888v1 by Ju-Hyeon Nam, Seo-Hyung Park, Su Jung Kim, Sang-Chul Lee

An electrocardiogram (ECG) captures the heart's electrical signal to assess
various heart conditions. In practice, ECG data is stored as either digitized
signals or printed images. Despite the emergence of numerous deep learning
models for digitized signals, many hospitals prefer image storage due to cost
considerations. Recognizing the unavailability of raw ECG signals in many
clinical settings, we propose VizECGNet, which uses only printed ECG graphics
to determine the prognosis of multiple cardiovascular diseases. During
training, cross-modal attention modules (CMAM) are used to integrate
information from two modalities - image and signal, while self-modality
attention modules (SMAM) capture inherent long-range dependencies in ECG data
of each modality. Additionally, we utilize knowledge distillation to improve
the similarity between two distinct predictions from each modality stream. This
innovative multi-modal deep learning architecture enables the utilization of
only ECG images during inference. VizECGNet with image input achieves higher
performance in precision, recall, and F1-Score compared to signal-based ECG
classification models, with improvements of 3.50%, 8.21%, and 7.38%,
respectively.

摘要：心電圖 (ECG) 可擷取心臟的電氣訊號，用於評估各種心臟疾病。實際上，心電圖資料儲存在數位化訊號或列印影像中。儘管已出現許多針對數位化訊號的深度學習模型，但許多醫院基於成本考量，仍偏好影像儲存。鑑於許多臨床環境中缺乏原始心電圖訊號，我們提出 VizECGNet，它僅使用列印的心電圖圖形來判斷多種心血管疾病的預後。在訓練期間，跨模態注意力模組 (CMAM) 用於整合來自兩種模態（影像和訊號）的資訊，而自我模態注意力模組 (SMAM) 則擷取每個模態中心電圖資料中固有的長程依賴性。此外，我們利用知識萃取來改善每個模態串流中兩個不同預測之間的相似性。這種創新的多模態深度學習架構，可以在推論期間僅使用心電圖影像。與基於訊號的心電圖分類模型相比，輸入影像的 VizECGNet 在精準度、召回率和 F1 分數方面獲得更高的效能，分別提升了 3.50%、8.21% 和 7.38%。

##### **VisionUnite: A Vision-Language Foundation Model for Ophthalmology Enhanced with Clinical Knowledge**
2408.02865v1 by Zihan Li, Diping Song, Zefeng Yang, Deming Wang, Fei Li, Xiulan Zhang, Paul E. Kinahan, Yu Qiao

The need for improved diagnostic methods in ophthalmology is acute,
especially in the less developed regions with limited access to specialists and
advanced equipment. Therefore, we introduce VisionUnite, a novel
vision-language foundation model for ophthalmology enhanced with clinical
knowledge. VisionUnite has been pretrained on an extensive dataset comprising
1.24 million image-text pairs, and further refined using our proposed MMFundus
dataset, which includes 296,379 high-quality fundus image-text pairs and
889,137 simulated doctor-patient dialogue instances. Our experiments indicate
that VisionUnite outperforms existing generative foundation models such as
GPT-4V and Gemini Pro. It also demonstrates diagnostic capabilities comparable
to junior ophthalmologists. VisionUnite performs well in various clinical
scenarios including open-ended multi-disease diagnosis, clinical explanation,
and patient interaction, making it a highly versatile tool for initial
ophthalmic disease screening. VisionUnite can also serve as an educational aid
for junior ophthalmologists, accelerating their acquisition of knowledge
regarding both common and rare ophthalmic conditions. VisionUnite represents a
significant advancement in ophthalmology, with broad implications for
diagnostics, medical education, and understanding of disease mechanisms.

摘要：眼科診斷方法改良的必要性十分迫切，特別是在較不發達地區，那裡專科醫師和先進設備取得不易。因此，我們引進 VisionUnite，一種新穎的視覺語言基礎模型，並以臨床知識強化眼科。VisionUnite 已在包含 124 萬張影像文字對的大型資料集上進行預訓練，並透過我們建議的 MMFundus 資料集進一步優化，其中包含 296,379 張高品質眼底影像文字對和 889,137 個模擬的醫師病患對話實例。我們的實驗指出 VisionUnite 優於現有的生成式基礎模型，例如 GPT-4V 和 Gemini Pro。它也展現出與初階眼科醫師相當的診斷能力。VisionUnite 在各種臨床情境中表現良好，包括開放式多疾病診斷、臨床說明和病患互動，使其成為初步眼科疾病篩檢的高度多功能工具。VisionUnite 也可用作初階眼科醫師的教育輔助工具，加速他們對於常見和罕見眼科疾病知識的習得。VisionUnite 代表了眼科的重大進展，對診斷、醫學教育和疾病機轉的理解具有廣泛的影響。

##### **Multistain Pretraining for Slide Representation Learning in Pathology**
2408.02859v1 by Guillaume Jaume, Anurag Vaidya, Andrew Zhang, Andrew H. Song, Richard J. Chen, Sharifa Sahai, Dandan Mo, Emilio Madrigal, Long Phi Le, Faisal Mahmood

Developing self-supervised learning (SSL) models that can learn universal and
transferable representations of H&E gigapixel whole-slide images (WSIs) is
becoming increasingly valuable in computational pathology. These models hold
the potential to advance critical tasks such as few-shot classification, slide
retrieval, and patient stratification. Existing approaches for slide
representation learning extend the principles of SSL from small images (e.g.,
224 x 224 patches) to entire slides, usually by aligning two different
augmentations (or views) of the slide. Yet the resulting representation remains
constrained by the limited clinical and biological diversity of the views.
Instead, we postulate that slides stained with multiple markers, such as
immunohistochemistry, can be used as different views to form a rich
task-agnostic training signal. To this end, we introduce Madeleine, a
multimodal pretraining strategy for slide representation learning. Madeleine is
trained with a dual global-local cross-stain alignment objective on large
cohorts of breast cancer samples (N=4,211 WSIs across five stains) and kidney
transplant samples (N=12,070 WSIs across four stains). We demonstrate the
quality of slide representations learned by Madeleine on various downstream
evaluations, ranging from morphological and molecular classification to
prognostic prediction, comprising 21 tasks using 7,299 WSIs from multiple
medical centers. Code is available at https://github.com/mahmoodlab/MADELEINE.

摘要：開發自監督學習 (SSL) 模型，可以學習 H&E 吉像素全切片影像 (WSI) 的通用且可轉移表示，在計算病理學中正變得越來越有價值。這些模型有潛力推進關鍵任務，例如少次分類、切片檢索和患者分層。現有的切片表示學習方法將 SSL 的原理從小影像（例如 224 x 224 補丁）延伸到整個切片，通常透過對齊切片的兩個不同擴增（或視圖）。然而，生成的表示仍受到視圖有限的臨床和生物多樣性的限制。相反，我們假設使用多種標記染色的切片，例如免疫組織化學染色，可以用作不同的視圖來形成豐富的與任務無關的訓練訊號。為此，我們介紹 Madeleine，一種用於切片表示學習的多模式預訓練策略。Madeleine 使用雙重全局-局部跨染色對齊目標在大量乳癌樣本（N=4,211 個橫跨五種染色的 WSI）和腎臟移植樣本（N=12,070 個橫跨四種染色的 WSI）上進行訓練。我們在各種下游評估中展示了 Madeleine 學習的切片表示的品質，從形態和分子分類到預後預測，包括使用來自多個醫療中心的 7,299 個 WSI 的 21 項任務。程式碼可在 https://github.com/mahmoodlab/MADELEINE 取得。

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah Rösman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

摘要：系統性文獻回顧是研究中證據品質最高的。然而，回顧過程受到顯著資源和資料限制的阻礙。文獻回顧網路 (LRN) 是第一個遵循 PRISMA 2020 標準的可解釋 AI 平台，旨在自動化整個文獻回顧過程。LRN 在外科手套實務領域中進行評估，使用專家開發的 3 個搜尋字串來查詢 PubMed。非專家訓練所有 LRN 模型。效能以專家手動回顧作為基準。可解釋性和效能指標評估 LRN 複製專家回顧的能力。一致性以 Jaccard 指數和混淆矩陣測量。研究人員在研究完成前對彼此的結果保密。重疊的研究整合到 LRN 生成的系統性回顧中。LRN 模型在沒有專家訓練的情況下展現出優異的分類準確率，達到 84.78% 和 85.71% 的準確率。效能最高的模型達到了高評分者間信賴度 (k = 0.4953) 和可解釋性指標，將「減少」、「意外」和「銳利」與「雙重戴手套」連結在一起。另一個 LRN 模型涵蓋了 91.51% 的相關文獻，儘管與非專家的判斷不同 (k = 0.2174)，但包含了「乳膠」、「雙重」（手套）和「適應症」等詞彙。LRN 優於手動回顧（11 個月超過 19,920 分鐘），將整個過程縮短為 5 天超過 288.6 分鐘。這項研究顯示，可解釋的 AI 不需要專家訓練即可成功進行專家等級的 PRISMA 相容系統性文獻回顧。LRN 總結了外科手套研究的結果，並找出與臨床研究人員發現幾乎相同的主题。可解釋的 AI 可以準確地加快我們對臨床實務的理解，有潛力革新醫療保健研究。

##### **A Review on Organ Deformation Modeling Approaches for Reliable Surgical Navigation using Augmented Reality**
2408.02713v1 by Zheng Han, Qi Dou

Augmented Reality (AR) holds the potential to revolutionize surgical
procedures by allowing surgeons to visualize critical structures within the
patient's body. This is achieved through superimposing preoperative organ
models onto the actual anatomy. Challenges arise from dynamic deformations of
organs during surgery, making preoperative models inadequate for faithfully
representing intraoperative anatomy. To enable reliable navigation in augmented
surgery, modeling of intraoperative deformation to obtain an accurate alignment
of the preoperative organ model with the intraoperative anatomy is
indispensable. Despite the existence of various methods proposed to model
intraoperative organ deformation, there are still few literature reviews that
systematically categorize and summarize these approaches. This review aims to
fill this gap by providing a comprehensive and technical-oriented overview of
modeling methods for intraoperative organ deformation in augmented reality in
surgery. Through a systematic search and screening process, 112 closely
relevant papers were included in this review. By presenting the current status
of organ deformation modeling methods and their clinical applications, this
review seeks to enhance the understanding of organ deformation modeling in
AR-guided surgery, and discuss the potential topics for future advancements.

摘要：擴增實境 (AR) 具有透過讓外科醫生可視化患者體內關鍵結構來革新外科手術程序的潛力。這是透過將術前器官模型疊加到實際解剖結構上來實現的。手術過程中器官的動態變形帶來了挑戰，這使得術前模型不足以忠實地呈現術中解剖結構。為了在擴增手術中實現可靠的導航，對術中變形進行建模以獲得術前器官模型與術中解剖結構的準確對齊是不可或缺的。儘管存在各種用於建模術中器官變形的方法，但系統地對這些方法進行分類和總結的文獻回顧仍然很少。本綜述旨在通過提供對擴增實境手術中術中器官變形的建模方法的全面且技術導向的概述來填補這一空白。通過系統的搜尋和篩選過程，本綜述納入了 112 篇密切相關的論文。通過呈現器官變形建模方法的現狀及其臨床應用，本綜述旨在加深對 AR 引導手術中器官變形建模的理解，並探討未來進展的潛在主題。

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

摘要：本研究使用盒子學框架分析混合人工智慧系統的設計模式及其在臨床決策中的有效性。它分類並比較結合機器學習和基於規則的推理的各種架構，以深入了解其結構基礎和醫療保健應用。針對兩個主要問題，如何根據既定的設計模式對這些系統進行分類，以及如何通過比較分析提取見解，本研究使用軟體工程中的設計模式來了解和優化醫療保健人工智慧系統。盒子學有助於識別共性並建立可重複使用的解決方案，從而增強這些系統的可擴充性、可靠性和效能。檢查了五種主要的架構：REML、MLRB、RBML、RMLT 和 PERML。每種架構都有獨特的優缺點，強調了在臨床任務中需要量身打造的方法。REML 在資料有限的資料集中表現出高精度的預測；MLRB 在處理大型資料集和複雜資料整合方面表現出色；RBML 在可解釋性和可信度方面表現出色；RMLT 在管理高維資料方面表現出色；而 PERML 儘管在分析方面有限，但在緊急照護場景中表現出潛力。本研究引入了四種新模式，建立了五種抽象分類模式，並進一步將這五種模式細化為具體的系統。這些貢獻增強了盒子學的分類組織，並提供了將專家知識與機器學習整合的新方法。盒子學的結構化、模組化方法在開發和分析混合人工智慧系統、揭示共性以及推廣可重複使用的解決方案方面具有顯著優勢。總之，本研究強調了混合人工智慧系統在推進醫療保健中的關鍵作用，以及盒子學在推動人工智慧整合進一步創新方面的潛力，最終改善臨床決策支援和患者的治療成果。

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

摘要：由於其強大的預測能力，深度學習已成為許多產業中不可或缺的工具，包括醫療保健。然而，傳統的深度學習模型通常缺乏可解釋性，並且忽略了將預測不確定性納入考量，而這兩個因素是臨床決策制定的關鍵組成部分。為了產生可解釋且具有不確定性意識的預測，本研究提出了一個名為貝氏柯爾莫哥洛夫阿諾德網路 (BKAN) 的新架構，它結合了柯爾莫哥洛夫阿諾德網路的表達能力與貝氏推論。我們在兩個醫學資料集上使用 BKAN，這些資料集是評估機器學習模型在醫學診斷中的廣泛使用基準：皮馬印第安人糖尿病資料集和克里夫蘭心臟病資料集。我們的模型提供了對預測信心和決策邊界的有益見解，並且在預測準確度方面優於傳統的深度學習模型。此外，BKAN 表現隨機和認識不確定性的能力，可確保醫生獲得更可靠且值得信賴的決策支援。根據實驗結果，我們的貝氏策略提高了模型的可解釋性，並大幅減少了過度擬合，這對於小型且不平衡的醫學資料集非常重要。我們提出了可能的擴充功能，以進一步將 BKAN 用於更複雜的多模式資料集，並探討這些發現對於未來建立可靠的醫療保健 AI 系統研究的重要性。這項工作為深度學習模型部署在透明度和可靠性至關重要的重要領域中開啟了一個新的典範。

##### **Active Sensing of Knee Osteoarthritis Progression with Reinforcement Learning**
2408.02349v2 by Khanh Nguyen, Huy Hoang Nguyen, Egor Panfilov, Aleksei Tiulpin

Osteoarthritis (OA) is the most common musculoskeletal disease, which has no
cure. Knee OA (KOA) is one of the highest causes of disability worldwide, and
it costs billions of United States dollars to the global community. Prediction
of KOA progression has been of high interest to the community for years, as it
can advance treatment development through more efficient clinical trials and
improve patient outcomes through more efficient healthcare utilization.
Existing approaches for predicting KOA, however, are predominantly static, i.e.
consider data from a single time point to predict progression many years into
the future, and knee level, i.e. consider progression in a single joint only.
Due to these and related reasons, these methods fail to deliver the level of
predictive performance, which is sufficient to result in cost savings and
better patient outcomes. Collecting extensive data from all patients on a
regular basis could address the issue, but it is limited by the high cost at a
population level. In this work, we propose to go beyond static prediction
models in OA, and bring a novel Active Sensing (AS) approach, designed to
dynamically follow up patients with the objective of maximizing the number of
informative data acquisitions, while minimizing their total cost over a period
of time. Our approach is based on Reinforcement Learning (RL), and it leverages
a novel reward function designed specifically for AS of disease progression in
more than one part of a human body. Our method is end-to-end, relies on
multi-modal Deep Learning, and requires no human input at inference time.
Throughout an exhaustive experimental evaluation, we show that using RL can
provide a higher monetary benefit when compared to state-of-the-art baselines.

摘要：骨關節炎 (OA) 是最常見的肌肉骨骼疾病，目前無法根治。膝關節骨關節炎 (KOA) 是全球殘疾的主要原因之一，對全球社會造成數十億美元的損失。多年來，預測 KOA 的進程一直是人們關注的重點，因為它可以通過更有效的臨床試驗推進治療的發展，並通過更有效地利用醫療保健來改善患者的預後。然而，現有的預測 KOA 的方法主要是靜態的，即考慮單一時刻的數據來預測多年後的進程，並且是膝關節層面的，即只考慮單個關節的進程。由於這些及相關原因，這些方法無法提供足夠的預測性能，從而無法節省成本並改善患者的預後。定期從所有患者那裡收集大量數據可以解決這個問題，但受限於人口層面的高成本。在這項工作中，我們提出超越 OA 中的靜態預測模型，並提出了一種新穎的主動感測 (AS) 方法，旨在動態追蹤患者，以最大化信息數據採集的數量，同時在一段時間內最小化其總成本。我們的做法基於強化學習 (RL)，並利用專門為多於一個人體部位的疾病進程的 AS 設計的新型獎勵函數。我們的模型是端到端的，依賴於多模式深度學習，並且在推理時不需要人工輸入。在詳盡的實驗評估中，我們表明與最先進的基準相比，使用 RL 可以提供更高的經濟效益。

##### **A Conceptual Framework for Ethical Evaluation of Machine Learning Systems**
2408.10239v1 by Neha R. Gupta, Jessica Hullman, Hari Subramonyam

Research in Responsible AI has developed a range of principles and practices
to ensure that machine learning systems are used in a manner that is ethical
and aligned with human values. However, a critical yet often neglected aspect
of ethical ML is the ethical implications that appear when designing
evaluations of ML systems. For instance, teams may have to balance a trade-off
between highly informative tests to ensure downstream product safety, with
potential fairness harms inherent to the implemented testing procedures. We
conceptualize ethics-related concerns in standard ML evaluation techniques.
Specifically, we present a utility framework, characterizing the key trade-off
in ethical evaluation as balancing information gain against potential ethical
harms. The framework is then a tool for characterizing challenges teams face,
and systematically disentangling competing considerations that teams seek to
balance. Differentiating between different types of issues encountered in
evaluation allows us to highlight best practices from analogous domains, such
as clinical trials and automotive crash testing, which navigate these issues in
ways that can offer inspiration to improve evaluation processes in ML. Our
analysis underscores the critical need for development teams to deliberately
assess and manage ethical complexities that arise during the evaluation of ML
systems, and for the industry to move towards designing institutional policies
to support ethical evaluations.

摘要：在負責任的人工智慧的研究中，已經發展出一系列的原則和實務，以確保機器學習系統的使用方式符合道德，且與人類價值觀一致。然而，一個重要的但經常被忽略的道德 ML 面向，是出現在設計 ML 系統評估時的道德意涵。例如，團隊可能必須在確保下游產品安全的極具參考價值的測試，與實施測試程序中潛在的公平性危害之間取得平衡。我們將標準 ML 評估技術中的道德相關疑慮概念化。具體來說，我們提出一個效用架構，將道德評估中的關鍵取捨描述為在資訊獲益與潛在道德危害之間取得平衡。然後，這個架構將成為描述團隊面臨的挑戰的工具，並系統性地解開團隊尋求平衡的相互競爭的考量。區分評估中遇到的不同類型的問題，讓我們能夠從類似的領域（例如臨床試驗和汽車碰撞測試）中找出最佳實務，這些領域以提供靈感的方式來解決這些問題，以改善 ML 中的評估程序。我們的分析強調了開發團隊在 ML 系統評估期間審慎評估和管理道德複雜性的關鍵需求，以及產業朝向設計制度政策以支援道德評估的趨勢。

##### **MetaWearS: A Shortcut in Wearable Systems Lifecycle with Only a Few Shots**
2408.01988v1 by Alireza Amirshahi, Maedeh H. Toosi, Siamak Mohammadi, Stefano Albini, Pasquale Davide Schiavone, Giovanni Ansaloni, Amir Aminifar, David Atienza

Wearable systems provide continuous health monitoring and can lead to early
detection of potential health issues. However, the lifecycle of wearable
systems faces several challenges. First, effective model training for new
wearable devices requires substantial labeled data from various subjects
collected directly by the wearable. Second, subsequent model updates require
further extensive labeled data for retraining. Finally, frequent model updating
on the wearable device can decrease the battery life in long-term data
monitoring. Addressing these challenges, in this paper, we propose MetaWearS, a
meta-learning method to reduce the amount of initial data collection required.
Moreover, our approach incorporates a prototypical updating mechanism,
simplifying the update process by modifying the class prototype rather than
retraining the entire model. We explore the performance of MetaWearS in two
case studies, namely, the detection of epileptic seizures and the detection of
atrial fibrillation. We show that by fine-tuning with just a few samples, we
achieve 70% and 82% AUC for the detection of epileptic seizures and the
detection of atrial fibrillation, respectively. Compared to a conventional
approach, our proposed method performs better with up to 45% AUC. Furthermore,
updating the model with only 16 minutes of additional labeled data increases
the AUC by up to 5.3%. Finally, MetaWearS reduces the energy consumption for
model updates by 456x and 418x for epileptic seizure and AF detection,
respectively.

摘要：<paragraph>穿戴式系統提供持續的健康監測，並可及早偵測潛在的健康問題。然而，穿戴式系統的生命週期面臨幾個挑戰。首先，新穿戴式裝置的有效模型訓練需要從各種受試者收集的大量標籤資料，且資料必須直接由穿戴式裝置收集。其次，後續的模型更新需要進一步的大量標籤資料才能重新訓練。最後，穿戴式裝置上頻繁的模型更新會縮短長期資料監測的電池續航力。為了應對這些挑戰，我們在本文中提出 MetaWearS，這是一種元學習方法，可減少所需的初始資料收集量。此外，我們的方法結合了一個原型更新機制，透過修改類別原型而非重新訓練整個模型來簡化更新過程。我們在兩個案例研究中探討 MetaWearS 的效能，分別是癲癇發作偵測和心房顫動偵測。我們展示了透過微調僅少數樣本，我們分別在癲癇發作偵測和心房顫動偵測中達到 70% 和 82% 的 AUC。與傳統方法相比，我們提出的方法表現更好，AUC 最高可達 45%。此外，僅使用 16 分鐘的額外標籤資料更新模型，即可將 AUC 提高多達 5.3%。最後，MetaWearS 分別將癲癇發作和心房顫動偵測的模型更新能耗降低了 456 倍和 418 倍。</paragraph>

##### **DiReCT: Diagnostic Reasoning for Clinical Notes via Large Language Models**
2408.01933v2 by Bowen Wang, Jiuyang Chang, Yiming Qian, Guoxin Chen, Junhao Chen, Zhouqiang Jiang, Jiahao Zhang, Yuta Nakashima, Hajime Nagahara

Large language models (LLMs) have recently showcased remarkable capabilities,
spanning a wide range of tasks and applications, including those in the medical
domain. Models like GPT-4 excel in medical question answering but may face
challenges in the lack of interpretability when handling complex tasks in real
clinical settings. We thus introduce the diagnostic reasoning dataset for
clinical notes (DiReCT), aiming at evaluating the reasoning ability and
interpretability of LLMs compared to human doctors. It contains 511 clinical
notes, each meticulously annotated by physicians, detailing the diagnostic
reasoning process from observations in a clinical note to the final diagnosis.
Additionally, a diagnostic knowledge graph is provided to offer essential
knowledge for reasoning, which may not be covered in the training data of
existing LLMs. Evaluations of leading LLMs on DiReCT bring out a significant
gap between their reasoning ability and that of human doctors, highlighting the
critical need for models that can reason effectively in real-world clinical
scenarios.

摘要：大型語言模型 (LLM) 最近展示了非凡的能力，涵蓋廣泛的任務和應用，包括醫療領域的任務和應用。GPT-4 等模型在醫療問題解答方面表現出色，但在處理實際臨床場景中的複雜任務時，可能會面臨缺乏可解釋性的挑戰。因此，我們引入了臨床筆記診斷推理數據集 (DiReCT)，旨在評估 LLM 與人類醫生相比的推理能力和可解釋性。它包含 511 個臨床筆記，每個筆記都經過醫生仔細註解，詳細說明了從臨床筆記中的觀察結果到最終診斷的診斷推理過程。此外，還提供了診斷知識圖譜，以提供推理所需的基本知識，這可能未涵蓋在現有 LLM 的訓練數據中。在 DiReCT 上對領先的 LLM 進行評估，發現它們的推理能力與人類醫生的推理能力之間存在顯著差距，這突顯了在現實世界的臨床場景中能夠有效推理的模型的關鍵需求。

##### **MALADE: Orchestration of LLM-powered Agents with Retrieval Augmented Generation for Pharmacovigilance**
2408.01869v1 by Jihye Choi, Nils Palumbo, Prasad Chalasani, Matthew M. Engelhard, Somesh Jha, Anivarya Kumar, David Page

In the era of Large Language Models (LLMs), given their remarkable text
understanding and generation abilities, there is an unprecedented opportunity
to develop new, LLM-based methods for trustworthy medical knowledge synthesis,
extraction and summarization. This paper focuses on the problem of
Pharmacovigilance (PhV), where the significance and challenges lie in
identifying Adverse Drug Events (ADEs) from diverse text sources, such as
medical literature, clinical notes, and drug labels. Unfortunately, this task
is hindered by factors including variations in the terminologies of drugs and
outcomes, and ADE descriptions often being buried in large amounts of narrative
text. We present MALADE, the first effective collaborative multi-agent system
powered by LLM with Retrieval Augmented Generation for ADE extraction from drug
label data. This technique involves augmenting a query to an LLM with relevant
information extracted from text resources, and instructing the LLM to compose a
response consistent with the augmented data. MALADE is a general LLM-agnostic
architecture, and its unique capabilities are: (1) leveraging a variety of
external sources, such as medical literature, drug labels, and FDA tools (e.g.,
OpenFDA drug information API), (2) extracting drug-outcome association in a
structured format along with the strength of the association, and (3) providing
explanations for established associations. Instantiated with GPT-4 Turbo or
GPT-4o, and FDA drug label data, MALADE demonstrates its efficacy with an Area
Under ROC Curve of 0.90 against the OMOP Ground Truth table of ADEs. Our
implementation leverages the Langroid multi-agent LLM framework and can be
found at https://github.com/jihyechoi77/malade.

摘要：在大语言模型 (LLM) 时代，鉴于其卓越的文本理解和生成能力，出现了一个前所未有的机会，可以开发基于 LLM 的新方法，用于可信的医学知识综合、提取和摘要。本文重点关注药物警戒 (PhV) 的问题，其重要性和挑战在于从各种文本来源（如医学文献、临床笔记和药物标签）中识别不良药物事件 (ADE)。不幸的是，这项任务受到多种因素的阻碍，包括药物和结果术语的变化，以及 ADE 描述通常埋没在大量叙述性文本中。我们展示了 MALADE，这是第一个有效的协作多智能体系统，由 LLM 提供支持，并使用检索增强生成来从药物标签数据中提取 ADE。此技术涉及使用从文本资源中提取的相关信息来扩充对 LLM 的查询，并指示 LLM 编写与扩充数据一致的响应。MALADE 是一种通用的 LLM 不可知架构，其独特功能包括：(1) 利用各种外部来源，例如医学文献、药物标签和 FDA 工具（例如 OpenFDA 药物信息 API），(2) 以结构化格式提取药物-结果关联以及关联强度，以及 (3) 为已建立的关联提供解释。MALADE 使用 GPT-4 Turbo 或 GPT-4o 以及 FDA 药物标签数据实例化，并通过针对 ADE 的 OMOP 基本事实表，以 0.90 的 ROC 曲线下面积证明了其有效性。我们的实现利用了 Langroid 多智能体 LLM 框架，可以在 https://github.com/jihyechoi77/malade 中找到。

##### **U-MedSAM: Uncertainty-aware MedSAM for Medical Image Segmentation**
2408.08881v1 by Xin Wang, Xiaoyu Liu, Peng Huang, Pu Huang, Shu Hu, Hongtu Zhu

Medical Image Foundation Models have proven to be powerful tools for mask
prediction across various datasets. However, accurately assessing the
uncertainty of their predictions remains a significant challenge. To address
this, we propose a new model, U-MedSAM, which integrates the MedSAM model with
an uncertainty-aware loss function and the Sharpness-Aware Minimization
(SharpMin) optimizer. The uncertainty-aware loss function automatically
combines region-based, distribution-based, and pixel-based loss designs to
enhance segmentation accuracy and robustness. SharpMin improves generalization
by finding flat minima in the loss landscape, thereby reducing overfitting. Our
method was evaluated in the CVPR24 MedSAM on Laptop challenge, where U-MedSAM
demonstrated promising performance.

摘要：醫學影像基礎模型已被證明是各種資料集中的遮罩預測強大工具。然而，準確評估其預測的不確定性仍然是一項重大挑戰。為了解決這個問題，我們提出了一個新模型 U-MedSAM，它將 MedSAM 模型與不確定性感知損失函數和銳利度感知最小化（SharpMin）最佳化器整合在一起。不確定性感知損失函數自動結合基於區域、基於分布和基於像素的損失設計，以增強分割精度和穩健性。SharpMin 通過在損失景觀中尋找平坦的最小值來改善泛化，從而減少過度擬合。我們的模型在 CVPR24 MedSAM on Laptop 挑戰中得到評估，其中 U-MedSAM 展示了有希望的效能。

##### **Building Trust in Mental Health Chatbots: Safety Metrics and LLM-Based Evaluation Tools**
2408.04650v1 by Jung In Park, Mahyar Abbasian, Iman Azimi, Dawn Bounds, Angela Jun, Jaesu Han, Robert McCarron, Jessica Borelli, Jia Li, Mona Mahmoudi, Carmen Wiedenhoeft, Amir Rahmani

Objective: This study aims to develop and validate an evaluation framework to
ensure the safety and reliability of mental health chatbots, which are
increasingly popular due to their accessibility, human-like interactions, and
context-aware support. Materials and Methods: We created an evaluation
framework with 100 benchmark questions and ideal responses, and five guideline
questions for chatbot responses. This framework, validated by mental health
experts, was tested on a GPT-3.5-turbo-based chatbot. Automated evaluation
methods explored included large language model (LLM)-based scoring, an agentic
approach using real-time data, and embedding models to compare chatbot
responses against ground truth standards. Results: The results highlight the
importance of guidelines and ground truth for improving LLM evaluation
accuracy. The agentic method, dynamically accessing reliable information,
demonstrated the best alignment with human assessments. Adherence to a
standardized, expert-validated framework significantly enhanced chatbot
response safety and reliability. Discussion: Our findings emphasize the need
for comprehensive, expert-tailored safety evaluation metrics for mental health
chatbots. While LLMs have significant potential, careful implementation is
necessary to mitigate risks. The superior performance of the agentic approach
underscores the importance of real-time data access in enhancing chatbot
reliability. Conclusion: The study validated an evaluation framework for mental
health chatbots, proving its effectiveness in improving safety and reliability.
Future work should extend evaluations to accuracy, bias, empathy, and privacy
to ensure holistic assessment and responsible integration into healthcare.
Standardized evaluations will build trust among users and professionals,
facilitating broader adoption and improved mental health support through
technology.

摘要：<paragraph>目標：本研究旨在開發和驗證一個評估架構，以確保心理健康聊天機器人的安全性與可靠性，由於其可及性、擬人化的互動以及情境感知支援，這些聊天機器人正變得越來越受歡迎。材料與方法：我們建立了一個評估架構，其中包含 100 個基準問題和理想回應，以及針對聊天機器人回應的五個指南問題。這個架構經過心理健康專家驗證，並在一個基於 GPT-3.5-turbo 的聊天機器人上進行測試。探討的自動評估方法包括基於大型語言模型 (LLM) 的評分、使用即時資料的能動方法，以及將聊天機器人回應與基本事實標準進行比較的嵌入式模型。結果：結果強調了準則和基本事實對於提升 LLM 評估準確性的重要性。能動方法動態地存取可靠資訊，證明與人類評估最為一致。遵循標準化且經過專家驗證的架構，顯著提升了聊天機器人回應的安全性與可靠性。討論：我們的研究結果強調了針對心理健康聊天機器人制定全面且專家量身打造的安全評估指標的必要性。儘管 LLM 具有顯著的潛力，但仍需要謹慎實施以降低風險。能動方法的優異表現突顯了即時資料存取對於提升聊天機器人可靠性的重要性。結論：本研究驗證了一個針對心理健康聊天機器人的評估架構，證明其在提升安全性與可靠性方面的有效性。未來的研究應將評估擴展至準確性、偏見、同理心和隱私，以確保全面的評估，並負責任地整合至醫療保健中。標準化的評估將建立使用者和專業人士之間的信任，促進更廣泛的採用，並透過科技改善心理健康支援。</paragraph>

