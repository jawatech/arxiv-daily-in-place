{"2411.08409": {"publish_time": "2024-11-13", "title": "DiVR: incorporating context from diverse VR scenes for human trajectory prediction", "paper_summary": "Virtual environments provide a rich and controlled setting for collecting\ndetailed data on human behavior, offering unique opportunities for predicting\nhuman trajectories in dynamic scenes. However, most existing approaches have\noverlooked the potential of these environments, focusing instead on static\ncontexts without considering userspecific factors. Employing the CREATTIVE3D\ndataset, our work models trajectories recorded in virtual reality (VR) scenes\nfor diverse situations including road-crossing tasks with user interactions and\nsimulated visual impairments. We propose Diverse Context VR Human Motion\nPrediction (DiVR), a cross-modal transformer based on the Perceiver\narchitecture that integrates both static and dynamic scene context using a\nheterogeneous graph convolution network. We conduct extensive experiments\ncomparing DiVR against existing architectures including MLP, LSTM, and\ntransformers with gaze and point cloud context. Additionally, we also stress\ntest our model's generalizability across different users, tasks, and scenes.\nResults show that DiVR achieves higher accuracy and adaptability compared to\nother models and to static graphs. This work highlights the advantages of using\nVR datasets for context-aware human trajectory modeling, with potential\napplications in enhancing user experiences in the metaverse. Our source code is\npublicly available at https://gitlab.inria.fr/ffrancog/creattive3d-divr-model.", "paper_summary_zh": "\u865b\u64ec\u74b0\u5883\u63d0\u4f9b\u4e86\u4e00\u500b\u8c50\u5bcc\u4e14\u53d7\u63a7\u7684\u8a2d\u5b9a\uff0c\u7528\u65bc\u6536\u96c6\u4eba\u985e\u884c\u70ba\u7684\u8a73\u7d30\u8cc7\u6599\uff0c\u70ba\u9810\u6e2c\u52d5\u614b\u5834\u666f\u4e2d\u7684\u4eba\u985e\u8ecc\u8de1\u63d0\u4f9b\u7368\u7279\u7684\u6a5f\u6703\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684\u65b9\u6cd5\u5927\u591a\u5ffd\u7565\u4e86\u9019\u4e9b\u74b0\u5883\u7684\u6f5b\u529b\uff0c\u800c\u662f\u5c08\u6ce8\u65bc\u975c\u614b\u60c5\u5883\uff0c\u800c\u4e0d\u8003\u616e\u4f7f\u7528\u8005\u7279\u5b9a\u7684\u56e0\u7d20\u3002\u900f\u904e\u4f7f\u7528 CREATTIVE3D \u8cc7\u6599\u96c6\uff0c\u6211\u5011\u7684\u6a21\u578b\u6703\u91dd\u5c0d\u865b\u64ec\u5be6\u5883 (VR) \u5834\u666f\u4e2d\u8a18\u9304\u7684\u8ecc\u8de1\u9032\u884c\u5efa\u6a21\uff0c\u9069\u7528\u65bc\u5404\u7a2e\u60c5\u6cc1\uff0c\u5305\u62ec\u8207\u4f7f\u7528\u8005\u4e92\u52d5\u7684\u9053\u8def\u7a7f\u8d8a\u4efb\u52d9\u548c\u6a21\u64ec\u8996\u89ba\u969c\u7919\u3002\u6211\u5011\u63d0\u51fa\u591a\u5143\u60c5\u5883 VR \u4eba\u985e\u52d5\u4f5c\u9810\u6e2c (DiVR)\uff0c\u9019\u662f\u4e00\u7a2e\u57fa\u65bc\u611f\u77e5\u5668\u67b6\u69cb\u7684\u8de8\u6a21\u614b\u8f49\u63db\u5668\uff0c\u4f7f\u7528\u7570\u8cea\u5716\u5f62\u6372\u7a4d\u7db2\u8def\u6574\u5408\u975c\u614b\u548c\u52d5\u614b\u5834\u666f\u60c5\u5883\u3002\u6211\u5011\u9032\u884c\u4e86\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0c\u5c07 DiVR \u8207\u73fe\u6709\u7684\u67b6\u69cb\u9032\u884c\u6bd4\u8f03\uff0c\u5305\u62ec MLP\u3001LSTM \u548c\u5177\u6709\u8996\u7dda\u548c\u9ede\u96f2\u60c5\u5883\u7684\u8f49\u63db\u5668\u3002\u6b64\u5916\uff0c\u6211\u5011\u9084\u5f37\u8abf\u6e2c\u8a66\u4e86\u6211\u5011\u7684\u6a21\u578b\u5728\u4e0d\u540c\u4f7f\u7528\u8005\u3001\u4efb\u52d9\u548c\u5834\u666f\u4e2d\u7684\u6cdb\u5316\u6027\u3002\u7d50\u679c\u986f\u793a\uff0c\u8207\u5176\u4ed6\u6a21\u578b\u548c\u975c\u614b\u5716\u5f62\u76f8\u6bd4\uff0cDiVR \u9054\u5230\u4e86\u66f4\u9ad8\u7684\u6e96\u78ba\u5ea6\u548c\u9069\u61c9\u6027\u3002\u9019\u9805\u5de5\u4f5c\u7a81\u986f\u4e86\u4f7f\u7528 VR \u8cc7\u6599\u96c6\u9032\u884c\u60c5\u5883\u611f\u77e5\u4eba\u985e\u8ecc\u8de1\u5efa\u6a21\u7684\u512a\u9ede\uff0c\u5728\u589e\u5f37\u5143\u5b87\u5b99\u4e2d\u7684\u4f7f\u7528\u8005\u9ad4\u9a57\u65b9\u9762\u5177\u6709\u6f5b\u5728\u61c9\u7528\u3002\u6211\u5011\u7684\u539f\u59cb\u7a0b\u5f0f\u78bc\u53ef\u5728 https://gitlab.inria.fr/ffrancog/creattive3d-divr-model \u516c\u958b\u53d6\u5f97\u3002", "author": "Franz Franco Gallo et.al.", "authors": "Franz Franco Gallo, Hui-Yin Wu, Lucile Sassatelli", "id": "2411.08409v1", "paper_url": "http://arxiv.org/abs/2411.08409v1", "repo": "null"}}