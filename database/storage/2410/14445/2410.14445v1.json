{"2410.14445": {"publish_time": "2024-10-18", "title": "Toward Generalizing Visual Brain Decoding to Unseen Subjects", "paper_summary": "Visual brain decoding aims to decode visual information from human brain\nactivities. Despite the great progress, one critical limitation of current\nbrain decoding research lies in the lack of generalization capability to unseen\nsubjects. Prior works typically focus on decoding brain activity of individuals\nbased on the observation that different subjects exhibit different brain\nactivities, while it remains unclear whether brain decoding can be generalized\nto unseen subjects. This study aims to answer this question. We first\nconsolidate an image-fMRI dataset consisting of stimulus-image and\nfMRI-response pairs, involving 177 subjects in the movie-viewing task of the\nHuman Connectome Project (HCP). This dataset allows us to investigate the brain\ndecoding performance with the increase of participants. We then present a\nlearning paradigm that applies uniform processing across all subjects, instead\nof employing different network heads or tokenizers for individuals as in\nprevious methods, which can accommodate a large number of subjects to explore\nthe generalization capability across different subjects. A series of\nexperiments are conducted and we have the following findings. First, the\nnetwork exhibits clear generalization capabilities with the increase of\ntraining subjects. Second, the generalization capability is common to popular\nnetwork architectures (MLP, CNN and Transformer). Third, the generalization\nperformance is affected by the similarity between subjects. Our findings reveal\nthe inherent similarities in brain activities across individuals. With the\nemerging of larger and more comprehensive datasets, it is possible to train a\nbrain decoding foundation model in the future.Codes and models can be found at\nhttps://github.com/Xiangtaokong/TGBD.", "paper_summary_zh": "\u8996\u89ba\u5927\u8166\u89e3\u78bc\u65e8\u5728\u5f9e\u4eba\u8166\u6d3b\u52d5\u4e2d\u89e3\u78bc\u8996\u89ba\u8cc7\u8a0a\u3002\u5118\u7ba1\u53d6\u5f97\u4e86\u5de8\u5927\u9032\u5c55\uff0c\u4f46\u7576\u524d\u5927\u8166\u89e3\u78bc\u7814\u7a76\u7684\u4e00\u500b\u95dc\u9375\u9650\u5236\u5728\u65bc\u7f3a\u4e4f\u5c0d\u672a\u898b\u53d7\u8a66\u8005\u7684\u6982\u5316\u80fd\u529b\u3002\u5148\u524d\u7684\u7814\u7a76\u901a\u5e38\u5c08\u6ce8\u65bc\u6839\u64da\u4e0d\u540c\u53d7\u8a66\u8005\u8868\u73fe\u51fa\u4e0d\u540c\u7684\u8166\u6d3b\u52d5\u4f86\u89e3\u78bc\u500b\u9ad4\u7684\u8166\u6d3b\u52d5\uff0c\u800c\u5927\u8166\u89e3\u78bc\u662f\u5426\u80fd\u6982\u5316\u5230\u672a\u898b\u53d7\u8a66\u8005\u4ecd\u4e0d\u6e05\u695a\u3002\u672c\u7814\u7a76\u65e8\u5728\u56de\u7b54\u9019\u500b\u554f\u984c\u3002\u6211\u5011\u9996\u5148\u6574\u5408\u4e00\u500b\u5f71\u50cf fMRI \u8cc7\u6599\u96c6\uff0c\u5176\u4e2d\u5305\u542b\u523a\u6fc0\u5f71\u50cf\u548c fMRI \u53cd\u61c9\u914d\u5c0d\uff0c\u6d89\u53ca\u96fb\u5f71\u89c0\u770b\u4efb\u52d9\u4e2d\u7684\u4eba\u985e\u9023\u63a5\u7d44\u8a08\u756b (HCP) \u7684 177 \u4f4d\u53d7\u8a66\u8005\u3002\u6b64\u8cc7\u6599\u96c6\u8b93\u6211\u5011\u80fd\u5920\u96a8\u8457\u53c3\u8207\u8005\u589e\u52a0\u4f86\u8abf\u67e5\u5927\u8166\u89e3\u78bc\u6548\u80fd\u3002\u7136\u5f8c\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u5b78\u7fd2\u7bc4\u4f8b\uff0c\u5c0d\u6240\u6709\u53d7\u8a66\u8005\u5957\u7528\u4e00\u81f4\u7684\u8655\u7406\uff0c\u800c\u4e0d\u662f\u50cf\u5148\u524d\u65b9\u6cd5\u90a3\u6a23\u70ba\u500b\u4eba\u63a1\u7528\u4e0d\u540c\u7684\u7db2\u8def\u5340\u584a\u6216\u6a19\u8a18\u5316\u5668\uff0c\u9019\u80fd\u5bb9\u7d0d\u5927\u91cf\u7684\u53d7\u8a66\u8005\u4f86\u63a2\u7d22\u4e0d\u540c\u53d7\u8a66\u8005\u4e4b\u9593\u7684\u6982\u5316\u80fd\u529b\u3002\u9032\u884c\u4e86\u4e00\u7cfb\u5217\u5be6\u9a57\uff0c\u6211\u5011\u6709\u4ee5\u4e0b\u767c\u73fe\u3002\u9996\u5148\uff0c\u7db2\u8def\u96a8\u8457\u8a13\u7df4\u53d7\u8a66\u8005\u7684\u589e\u52a0\u800c\u8868\u73fe\u51fa\u660e\u986f\u7684\u6982\u5316\u80fd\u529b\u3002\u5176\u6b21\uff0c\u6982\u5316\u80fd\u529b\u5728\u6d41\u884c\u7684\u7db2\u8def\u67b6\u69cb\uff08MLP\u3001CNN \u548c Transformer\uff09\u4e2d\u662f\u5e38\u898b\u7684\u3002\u7b2c\u4e09\uff0c\u6982\u5316\u6548\u80fd\u53d7\u53d7\u8a66\u8005\u4e4b\u9593\u76f8\u4f3c\u6027\u7684\u5f71\u97ff\u3002\u6211\u5011\u7684\u767c\u73fe\u63ed\u793a\u4e86\u500b\u4eba\u4e4b\u9593\u8166\u6d3b\u52d5\u7684\u5167\u5728\u76f8\u4f3c\u6027\u3002\u96a8\u8457\u66f4\u5927\u3001\u66f4\u5168\u9762\u7684\u8cc7\u6599\u96c6\u7684\u51fa\u73fe\uff0c\u672a\u4f86\u6709\u53ef\u80fd\u8a13\u7df4\u4e00\u500b\u5927\u8166\u89e3\u78bc\u57fa\u790e\u6a21\u578b\u3002\u7a0b\u5f0f\u78bc\u548c\u6a21\u578b\u53ef\u4ee5\u5728 https://github.com/Xiangtaokong/TGBD \u4e2d\u627e\u5230\u3002", "author": "Xiangtao Kong et.al.", "authors": "Xiangtao Kong, Kexin Huang, Ping Li, Lei Zhang", "id": "2410.14445v1", "paper_url": "http://arxiv.org/abs/2410.14445v1", "repo": "https://github.com/xiangtaokong/tgbd"}}