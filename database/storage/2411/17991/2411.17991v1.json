{"2411.17991": {"publish_time": "2024-11-27", "title": "VideoLLM Knows When to Speak: Enhancing Time-Sensitive Video Comprehension with Video-Text Duet Interaction Format", "paper_summary": "Recent researches on video large language models (VideoLLM) predominantly\nfocus on model architectures and training datasets, leaving the interaction\nformat between the user and the model under-explored. In existing works, users\noften interact with VideoLLMs by using the entire video and a query as input,\nafter which the model generates a response. This interaction format constrains\nthe application of VideoLLMs in scenarios such as live-streaming comprehension\nwhere videos do not end and responses are required in a real-time manner, and\nalso results in unsatisfactory performance on time-sensitive tasks that\nrequires localizing video segments. In this paper, we focus on a video-text\nduet interaction format. This interaction format is characterized by the\ncontinuous playback of the video, and both the user and the model can insert\ntheir text messages at any position during the video playback. When a text\nmessage ends, the video continues to play, akin to the alternative of two\nperformers in a duet. We construct MMDuetIT, a video-text training dataset\ndesigned to adapt VideoLLMs to video-text duet interaction format. We also\nintroduce the Multi-Answer Grounded Video Question Answering (MAGQA) task to\nbenchmark the real-time response ability of VideoLLMs. Trained on MMDuetIT,\nMMDuet demonstrates that adopting the video-text duet interaction format\nenables the model to achieve significant improvements in various time-sensitive\ntasks (76% CIDEr on YouCook2 dense video captioning, 90\\% mAP on QVHighlights\nhighlight detection and 25% R@0.5 on Charades-STA temporal video grounding)\nwith minimal training efforts, and also enable VideoLLMs to reply in a\nreal-time manner as the video plays. Code, data and demo are available at:\nhttps://github.com/yellow-binary-tree/MMDuet.", "paper_summary_zh": "\u8fd1\u671f\u7684\u5f71\u7247\u5927\u578b\u8bed\u8a00\u6a21\u578b (VideoLLM) \u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u4e8e\u6a21\u578b\u67b6\u6784\u548c\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u800c\u4f7f\u7528\u8005\u4e0e\u6a21\u578b\u4e4b\u95f4\u7684\u4e92\u52a8\u65b9\u5f0f\u5219\u8f83\u5c11\u88ab\u63a2\u8ba8\u3002\u5728\u73b0\u6709\u7684\u4f5c\u54c1\u4e2d\uff0c\u4f7f\u7528\u8005\u901a\u5e38\u4f7f\u7528\u6574\u4e2a\u5f71\u7247\u548c\u67e5\u8be2\u4f5c\u4e3a\u8f93\u5165\uff0c\u4e0e VideoLLM \u4e92\u52a8\uff0c\u7136\u540e\u6a21\u578b\u4f1a\u4ea7\u751f\u56de\u5e94\u3002\u8fd9\u79cd\u4e92\u52a8\u65b9\u5f0f\u9650\u5236\u4e86 VideoLLM \u5728\u5f71\u7247\u4e0d\u65ad\u64ad\u653e\u4e14\u9700\u8981\u5b9e\u65f6\u56de\u5e94\u7684\u573a\u666f\uff08\u4f8b\u5982\u76f4\u64ad\u7406\u89e3\uff09\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u4e14\u5728\u9700\u8981\u5b9a\u4f4d\u5f71\u7247\u7247\u6bb5\u7684\u65f6\u95f4\u654f\u611f\u4efb\u52a1\u4e2d\u4e5f\u4f1a\u5bfc\u81f4\u8868\u73b0\u4e0d\u4f73\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u4e13\u6ce8\u4e8e\u5f71\u7247\u6587\u5b57\u4e8c\u91cd\u5531\u4e92\u52a8\u65b9\u5f0f\u3002\u8fd9\u79cd\u4e92\u52a8\u65b9\u5f0f\u7684\u7279\u70b9\u662f\u5f71\u7247\u6301\u7eed\u64ad\u653e\uff0c\u4f7f\u7528\u8005\u548c\u6a21\u578b\u90fd\u53ef\u4ee5\u968f\u65f6\u5728\u5f71\u7247\u64ad\u653e\u671f\u95f4\u63d2\u5165\u4ed6\u4eec\u7684\u6587\u5b57\u8baf\u606f\u3002\u5f53\u6587\u5b57\u8baf\u606f\u7ed3\u675f\u65f6\uff0c\u5f71\u7247\u7ee7\u7eed\u64ad\u653e\uff0c\u7c7b\u4f3c\u4e8e\u4e8c\u91cd\u5531\u4e2d\u4e24\u4f4d\u8868\u6f14\u8005\u7684\u4ea4\u66ff\u3002\u6211\u4eec\u6784\u5efa\u4e86 MMDuetIT\uff0c\u8fd9\u662f\u4e00\u4e2a\u5f71\u7247\u6587\u5b57\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u65e8\u5728\u8ba9 VideoLLM \u9002\u5e94\u5f71\u7247\u6587\u5b57\u4e8c\u91cd\u5531\u4e92\u52a8\u65b9\u5f0f\u3002\u6211\u4eec\u8fd8\u5f15\u5165\u4e86\u591a\u91cd\u7b54\u6848\u57fa\u7840\u5f71\u7247\u95ee\u7b54 (MAGQA) \u4efb\u52a1\uff0c\u4ee5\u6bd4\u8f83 VideoLLM \u7684\u5b9e\u65f6\u56de\u5e94\u80fd\u529b\u3002\u5728 MMDuetIT \u4e0a\u8bad\u7ec3\u540e\uff0cMMDuet \u8bc1\u660e\u91c7\u7528\u5f71\u7247\u6587\u5b57\u4e8c\u91cd\u5531\u4e92\u52a8\u65b9\u5f0f\u80fd\u4f7f\u6a21\u578b\u5728\u5404\u79cd\u65f6\u95f4\u654f\u611f\u4efb\u52a1\u4e2d\u5b9e\u73b0\u663e\u8457\u7684\u6539\u8fdb\uff08YouCook2 \u7a20\u5bc6\u5f71\u7247\u5b57\u5e55\u7684 76% CIDEr\u3001QVHighlights \u91cd\u70b9\u68c0\u6d4b\u7684 90% mAP \u548c Charades-STA \u65f6\u95f4\u5f71\u7247\u57fa\u7840\u7684 25% R@0.5\uff09\uff0c\u4e14\u8bad\u7ec3\u5de5\u4f5c\u91cf\u6781\u5c0f\uff0c\u8fd8\u80fd\u8ba9 VideoLLM \u5728\u5f71\u7247\u64ad\u653e\u65f6\u5b9e\u65f6\u56de\u5e94\u3002\u4ee3\u7801\u3001\u8d44\u6599\u548c\u793a\u8303\u53ef\u4e8e\u6b64\u5904\u53d6\u5f97\uff1ahttps://github.com/yellow-binary-tree/MMDuet\u3002", "author": "Yueqian Wang et.al.", "authors": "Yueqian Wang, Xiaojun Meng, Yuxuan Wang, Jianxin Liang, Jiansheng Wei, Huishuai Zhang, Dongyan Zhao", "id": "2411.17991v1", "paper_url": "http://arxiv.org/abs/2411.17991v1", "repo": "https://github.com/yellow-binary-tree/mmduet"}}