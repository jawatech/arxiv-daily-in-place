{"2411.06655": {"publish_time": "2024-11-11", "title": "Explore the Reasoning Capability of LLMs in the Chess Testbed", "paper_summary": "Reasoning is a central capability of human intelligence. In recent years,\nwith the advent of large-scale datasets, pretrained large language models have\nemerged with new capabilities, including reasoning. However, these models still\nstruggle with long-term, complex reasoning tasks, such as playing chess. Based\non the observation that expert chess players employ a dual approach combining\nlong-term strategic play with short-term tactical play along with language\nexplanation, we propose improving the reasoning capability of large language\nmodels in chess by integrating annotated strategy and tactic. Specifically, we\ncollect a dataset named MATE, which consists of 1 million chess positions with\ncandidate moves annotated by chess experts for strategy and tactics. We\nfinetune the LLaMA-3-8B model and compare it against state-of-the-art\ncommercial language models in the task of selecting better chess moves. Our\nexperiments show that our models perform better than GPT, Claude, and Gemini\nmodels. We find that language explanations can enhance the reasoning capability\nof large language models.", "paper_summary_zh": "\u63a8\u7406\u662f\u4eba\u985e\u667a\u80fd\u7684\u6838\u5fc3\u80fd\u529b\u3002\u8fd1\u5e74\u4f86\uff0c\u96a8\u8457\u5927\u898f\u6a21\u6578\u64da\u96c6\u7684\u51fa\u73fe\uff0c\u9810\u8a13\u7df4\u7684\u5927\u8a9e\u8a00\u6a21\u578b\u5df2\u7d93\u51fa\u73fe\u4e86\u65b0\u7684\u80fd\u529b\uff0c\u5305\u62ec\u63a8\u7406\u3002\u7136\u800c\uff0c\u9019\u4e9b\u6a21\u578b\u4ecd\u7136\u96e3\u4ee5\u61c9\u4ed8\u9577\u671f\u3001\u8907\u96dc\u7684\u63a8\u7406\u4efb\u52d9\uff0c\u4f8b\u5982\u4e0b\u68cb\u3002\u57fa\u65bc\u5c08\u5bb6\u68cb\u624b\u63a1\u7528\u96d9\u91cd\u65b9\u6cd5\u7684\u89c0\u5bdf\uff0c\u5c07\u9577\u671f\u6230\u7565\u535a\u5f08\u8207\u77ed\u671f\u6230\u8853\u535a\u5f08\u7d50\u5408\u8a9e\u8a00\u8aaa\u660e\uff0c\u6211\u5011\u63d0\u51fa\u901a\u904e\u6574\u5408\u8a3b\u89e3\u7b56\u7565\u548c\u6230\u8853\u4f86\u63d0\u9ad8\u5927\u8a9e\u8a00\u6a21\u578b\u5728\u570b\u969b\u8c61\u68cb\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u6536\u96c6\u4e86\u4e00\u500b\u540d\u70ba MATE \u7684\u6578\u64da\u96c6\uff0c\u5176\u4e2d\u5305\u542b 100 \u842c\u500b\u570b\u969b\u8c61\u68cb\u4f4d\u7f6e\uff0c\u5176\u4e2d\u5019\u9078\u79fb\u52d5\u7531\u570b\u969b\u8c61\u68cb\u5c08\u5bb6\u5c0d\u7b56\u7565\u548c\u6230\u8853\u9032\u884c\u4e86\u8a3b\u91cb\u3002\u6211\u5011\u5c0d LLaMA-3-8B \u6a21\u578b\u9032\u884c\u4e86\u5fae\u8abf\uff0c\u4e26\u5728\u9078\u64c7\u66f4\u597d\u7684\u570b\u969b\u8c61\u68cb\u8d70\u6cd5\u4efb\u52d9\u4e2d\u5c07\u5176\u8207\u6700\u5148\u9032\u7684\u5546\u696d\u8a9e\u8a00\u6a21\u578b\u9032\u884c\u4e86\u6bd4\u8f03\u3002\u6211\u5011\u7684\u5be6\u9a57\u8868\u660e\uff0c\u6211\u5011\u7684\u6a21\u578b\u6bd4 GPT\u3001Claude \u548c Gemini \u6a21\u578b\u8868\u73fe\u5f97\u66f4\u597d\u3002\u6211\u5011\u767c\u73fe\u8a9e\u8a00\u89e3\u91cb\u53ef\u4ee5\u589e\u5f37\u5927\u8a9e\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "author": "Shu Wang et.al.", "authors": "Shu Wang, Lei Ji, Renxi Wang, Wenxiao Zhao, Haokun Liu, Yifan Hou, Ying Nian Wu", "id": "2411.06655v1", "paper_url": "http://arxiv.org/abs/2411.06655v1", "repo": "null"}}