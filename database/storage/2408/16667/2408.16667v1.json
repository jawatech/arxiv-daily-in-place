{"2408.16667": {"publish_time": "2024-08-29", "title": "Iterative Graph Alignment", "paper_summary": "By compressing diverse narratives, LLMs go beyond memorization, achieving\nintelligence by capturing generalizable causal relationships. However, they\nsuffer from local 'representation gaps' due to insufficient training data\ndiversity, limiting their real-world utility, especially in tasks requiring\nstrict alignment to rules. Traditional alignment methods relying on heavy human\nannotations are inefficient and unscalable. Recent self-alignment techniques\nalso fall short, as they often depend on self-selection based prompting and\nmemorization-based learning. To address these issues, we introduce Iterative\nGraph Alignment (IGA), an annotation-free rule-based alignment algorithm. A\nteacher model (VLM) employs Iterative Graph Prompting (IGP) to create logical\ngraphs and reference answers. The student model (LLM) identifies local\nknowledge gaps by attempting to align its responses with these references,\ncollaborating with helper models to generate diverse answers. These aligned\nresponses are then used for iterative supervised fine-tuning (SFT). Our\nevaluations across five rule-based scenarios demonstrate IGP's effectiveness,\nwith a 73.12\\% alignment improvement in Claude Sonnet 3.5, and\nLlama3-8B-Instruct achieving an 86.20\\% improvement, outperforming Claude\nSonnet 3.5 in rule-based alignment.", "paper_summary_zh": "\u900f\u904e\u58d3\u7e2e\u5404\u7a2e\u6558\u8ff0\uff0cLLM \u4e0d\u518d\u53ea\u662f\u8a18\u61b6\uff0c\u800c\u662f\u900f\u904e\u64f7\u53d6\u53ef\u6982\u62ec\u7684\u56e0\u679c\u95dc\u4fc2\u4f86\u5be6\u73fe\u667a\u80fd\u3002\u7136\u800c\uff0c\u7531\u65bc\u8a13\u7df4\u8cc7\u6599\u7684\u591a\u6a23\u6027\u4e0d\u8db3\uff0c\u5b83\u5011\u6703\u51fa\u73fe\u5340\u57df\u6027\u7684\u300c\u8868\u793a\u5dee\u8ddd\u300d\uff0c\u9019\u9650\u5236\u4e86\u5b83\u5011\u5728\u73fe\u5be6\u4e16\u754c\u4e2d\u7684\u6548\u7528\uff0c\u7279\u5225\u662f\u5728\u9700\u8981\u56b4\u683c\u9075\u5b88\u898f\u5247\u7684\u4efb\u52d9\u4e2d\u3002\u50b3\u7d71\u7684\u6bd4\u5c0d\u65b9\u6cd5\u4ef0\u8cf4\u5927\u91cf\u7684\u4eba\u5de5\u6a19\u8a3b\uff0c\u65e2\u6c92\u6709\u6548\u7387\u53c8\u7121\u6cd5\u64f4\u5c55\u3002\u6700\u8fd1\u7684\u81ea\u6211\u6bd4\u5c0d\u6280\u8853\u4e5f\u505a\u5f97\u4e0d\u5920\u597d\uff0c\u56e0\u70ba\u5b83\u5011\u901a\u5e38\u4f9d\u8cf4\u65bc\u57fa\u65bc\u63d0\u793a\u7684\u81ea\u6211\u9078\u64c7\u548c\u57fa\u65bc\u8a18\u61b6\u7684\u5b78\u7fd2\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u5f15\u5165\u4e86\u8fed\u4ee3\u5716\u5f62\u6bd4\u5c0d (IGA)\uff0c\u9019\u662f\u4e00\u500b\u7121\u9700\u6a19\u8a3b\u7684\u57fa\u65bc\u898f\u5247\u7684\u6bd4\u5c0d\u6f14\u7b97\u6cd5\u3002\u6559\u5e2b\u6a21\u578b (VLM) \u4f7f\u7528\u8fed\u4ee3\u5716\u5f62\u63d0\u793a (IGP) \u4f86\u5efa\u7acb\u908f\u8f2f\u5716\u5f62\u548c\u53c3\u8003\u7b54\u6848\u3002\u5b78\u751f\u6a21\u578b (LLM) \u5617\u8a66\u5c07\u5176\u56de\u61c9\u8207\u9019\u4e9b\u53c3\u8003\u5167\u5bb9\u6bd4\u5c0d\uff0c\u4e26\u8207\u8f14\u52a9\u6a21\u578b\u5408\u4f5c\u7522\u751f\u591a\u6a23\u5316\u7684\u7b54\u6848\uff0c\u85c9\u6b64\u627e\u51fa\u5c40\u90e8\u77e5\u8b58\u5dee\u8ddd\u3002\u63a5\u8457\uff0c\u9019\u4e9b\u6bd4\u5c0d\u5f8c\u7684\u56de\u61c9\u6703\u7528\u65bc\u53cd\u8986\u7684\u76e3\u7763\u5fae\u8abf (SFT)\u3002\u6211\u5011\u5728\u4e94\u7a2e\u57fa\u65bc\u898f\u5247\u7684\u60c5\u5883\u4e2d\u9032\u884c\u8a55\u4f30\uff0c\u8b49\u660e\u4e86 IGP \u7684\u6709\u6548\u6027\uff0cClaude Sonnet 3.5 \u7684\u6bd4\u5c0d\u6539\u5584\u4e86 73.12%\uff0c\u800c Llama3-8B-Instruct \u7684\u6539\u5584\u9054\u5230 86.20%\uff0c\u5728\u57fa\u65bc\u898f\u5247\u7684\u6bd4\u5c0d\u4e2d\u512a\u65bc Claude Sonnet 3.5\u3002", "author": "Fangyuan Yu et.al.", "authors": "Fangyuan Yu, Hardeep Singh Arora, Matt Johnson", "id": "2408.16667v1", "paper_url": "http://arxiv.org/abs/2408.16667v1", "repo": "null"}}