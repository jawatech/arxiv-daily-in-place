{"2501.07861": {"publish_time": "2025-01-14", "title": "ReARTeR: Retrieval-Augmented Reasoning with Trustworthy Process Rewarding", "paper_summary": "Retrieval-Augmented Generation (RAG) systems for Large Language Models (LLMs)\nhold promise in knowledge-intensive tasks but face limitations in complex\nmulti-step reasoning. While recent methods have integrated RAG with\nchain-of-thought reasoning or test-time search using Process Reward Models\n(PRMs), these approaches encounter challenges such as a lack of explanations,\nbias in PRM training data, early-step bias in PRM scores, and insufficient\npost-training optimization of reasoning potential. To address these issues, we\npropose Retrieval-Augmented Reasoning through Trustworthy Process Rewarding\n(ReARTeR), a framework that enhances RAG systems' reasoning capabilities\nthrough post-training and test-time scaling. At test time, ReARTeR introduces\nTrustworthy Process Rewarding via a Process Reward Model for accurate scalar\nscoring and a Process Explanation Model (PEM) for generating natural language\nexplanations, enabling step refinement. During post-training, it utilizes Monte\nCarlo Tree Search guided by Trustworthy Process Rewarding to collect\nhigh-quality step-level preference data, optimized through Iterative Preference\nOptimization. ReARTeR addresses three core challenges: (1) misalignment between\nPRM and PEM, tackled through off-policy preference learning; (2) bias in PRM\ntraining data, mitigated by balanced annotation methods and stronger\nannotations for challenging examples; and (3) early-step bias in PRM, resolved\nthrough a temporal-difference-based look-ahead search strategy. Experimental\nresults on multi-step reasoning benchmarks demonstrate significant\nimprovements, underscoring ReARTeR's potential to advance the reasoning\ncapabilities of RAG systems.", "paper_summary_zh": "<paragraph>\u91dd\u5c0d\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u6aa2\u7d22\u589e\u5f37\u7522\u751f (RAG) \u7cfb\u7d71\u5728\u77e5\u8b58\u5bc6\u96c6\u578b\u4efb\u52d9\u4e2d\u5927\u6709\u53ef\u70ba\uff0c\u4f46\u5728\u8907\u96dc\u7684\u591a\u6b65\u9a5f\u63a8\u7406\u4e2d\u537b\u9762\u81e8\u9650\u5236\u3002\u96d6\u7136\u6700\u8fd1\u7684\u65b9\u6cd5\u5df2\u5c07 RAG \u8207\u601d\u8003\u93c8\u63a8\u7406\u6216\u4f7f\u7528\u6d41\u7a0b\u734e\u52f5\u6a21\u578b (PRM) \u7684\u6e2c\u8a66\u6642\u9593\u641c\u5c0b\u6574\u5408\u5728\u4e00\u8d77\uff0c\u4f46\u9019\u4e9b\u65b9\u6cd5\u6703\u9047\u5230\u8af8\u5982\u7f3a\u4e4f\u89e3\u91cb\u3001PRM \u8a13\u7df4\u8cc7\u6599\u4e2d\u7684\u504f\u5dee\u3001PRM \u5206\u6578\u4e2d\u7684\u65e9\u671f\u6b65\u9a5f\u504f\u5dee\uff0c\u4ee5\u53ca\u63a8\u7406\u6f5b\u529b\u7684\u8a13\u7df4\u5f8c\u6700\u4f73\u5316\u4e0d\u8db3\u7b49\u6311\u6230\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u900f\u904e\u53ef\u4fe1\u8cf4\u6d41\u7a0b\u734e\u52f5\u7684\u6aa2\u7d22\u589e\u5f37\u63a8\u7406 (ReARTeR)\uff0c\u9019\u662f\u4e00\u500b\u900f\u904e\u8a13\u7df4\u5f8c\u548c\u6e2c\u8a66\u6642\u9593\u7e2e\u653e\u4f86\u589e\u5f37 RAG \u7cfb\u7d71\u63a8\u7406\u80fd\u529b\u7684\u67b6\u69cb\u3002\u5728\u6e2c\u8a66\u6642\u9593\uff0cReARTeR \u900f\u904e\u6d41\u7a0b\u734e\u52f5\u6a21\u578b\u5f15\u5165\u53ef\u4fe1\u8cf4\u6d41\u7a0b\u734e\u52f5\uff0c\u4ee5\u9032\u884c\u6e96\u78ba\u7684\u6a19\u91cf\u8a55\u5206\uff0c\u4e26\u900f\u904e\u6d41\u7a0b\u89e3\u91cb\u6a21\u578b (PEM) \u7522\u751f\u81ea\u7136\u8a9e\u8a00\u89e3\u91cb\uff0c\u9032\u800c\u80fd\u5920\u9032\u884c\u6b65\u9a5f\u7cbe\u7149\u3002\u5728\u8a13\u7df4\u5f8c\u671f\u9593\uff0c\u5b83\u5229\u7528\u7531\u53ef\u4fe1\u8cf4\u6d41\u7a0b\u734e\u52f5\u5f15\u5c0e\u7684\u8499\u5730\u5361\u7f85\u6a39\u72c0\u641c\u5c0b\u4f86\u6536\u96c6\u9ad8\u54c1\u8cea\u7684\u6b65\u9a5f\u5c64\u7d1a\u504f\u597d\u8cc7\u6599\uff0c\u4e26\u900f\u904e\u53cd\u8986\u504f\u597d\u6700\u4f73\u5316\u9032\u884c\u6700\u4f73\u5316\u3002ReARTeR \u89e3\u6c7a\u4e86\u4e09\u500b\u6838\u5fc3\u6311\u6230\uff1a(1) PRM \u548c PEM \u4e4b\u9593\u7684\u932f\u4f4d\uff0c\u900f\u904e\u975e\u7b56\u7565\u504f\u597d\u5b78\u7fd2\u4f86\u89e3\u6c7a\uff1b(2) PRM \u8a13\u7df4\u8cc7\u6599\u4e2d\u7684\u504f\u5dee\uff0c\u900f\u904e\u5e73\u8861\u8a3b\u89e3\u65b9\u6cd5\u548c\u91dd\u5c0d\u5177\u6709\u6311\u6230\u6027\u7bc4\u4f8b\u7684\u66f4\u5f37\u8a3b\u89e3\u4f86\u6e1b\u8f15\uff1b(3) PRM \u4e2d\u7684\u65e9\u671f\u6b65\u9a5f\u504f\u5dee\uff0c\u900f\u904e\u57fa\u65bc\u6642\u9593\u5dee\u7684\u8d85\u524d\u641c\u5c0b\u7b56\u7565\u4f86\u89e3\u6c7a\u3002\u591a\u6b65\u9a5f\u63a8\u7406\u57fa\u6e96\u4e0a\u7684\u5be6\u9a57\u7d50\u679c\u8b49\u660e\u4e86\u986f\u8457\u7684\u6539\u9032\uff0c\u7a81\u986f\u4e86 ReARTeR \u5728\u63d0\u5347 RAG \u7cfb\u7d71\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u6f5b\u529b\u3002</paragraph>", "author": "Zhongxiang Sun et.al.", "authors": "Zhongxiang Sun, Qipeng Wang, Weijie Yu, Xiaoxue Zang, Kai Zheng, Jun Xu, Xiao Zhang, Song Yang, Han Li", "id": "2501.07861v1", "paper_url": "http://arxiv.org/abs/2501.07861v1", "repo": "null"}}