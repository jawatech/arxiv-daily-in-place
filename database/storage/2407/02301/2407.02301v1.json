{"2407.02301": {"publish_time": "2024-07-02", "title": "CFinBench: A Comprehensive Chinese Financial Benchmark for Large Language Models", "paper_summary": "Large language models (LLMs) have achieved remarkable performance on various\nNLP tasks, yet their potential in more challenging and domain-specific task,\nsuch as finance, has not been fully explored. In this paper, we present\nCFinBench: a meticulously crafted, the most comprehensive evaluation benchmark\nto date, for assessing the financial knowledge of LLMs under Chinese context.\nIn practice, to better align with the career trajectory of Chinese financial\npractitioners, we build a systematic evaluation from 4 first-level categories:\n(1) Financial Subject: whether LLMs can memorize the necessary basic knowledge\nof financial subjects, such as economics, statistics and auditing. (2)\nFinancial Qualification: whether LLMs can obtain the needed financial qualified\ncertifications, such as certified public accountant, securities qualification\nand banking qualification. (3) Financial Practice: whether LLMs can fulfill the\npractical financial jobs, such as tax consultant, junior accountant and\nsecurities analyst. (4) Financial Law: whether LLMs can meet the requirement of\nfinancial laws and regulations, such as tax law, insurance law and economic\nlaw. CFinBench comprises 99,100 questions spanning 43 second-level categories\nwith 3 question types: single-choice, multiple-choice and judgment. We conduct\nextensive experiments of 50 representative LLMs with various model size on\nCFinBench. The results show that GPT4 and some Chinese-oriented models lead the\nbenchmark, with the highest average accuracy being 60.16%, highlighting the\nchallenge presented by CFinBench. The dataset and evaluation code are available\nat https://cfinbench.github.io/.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u5404\u7a2e\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4efb\u52d9\u4e0a\u53d6\u5f97\u4e86\u986f\u8457\u7684\u8868\u73fe\uff0c\u4f46\u5b83\u5011\u5728\u66f4\u5177\u6311\u6230\u6027\u548c\u7279\u5b9a\u9818\u57df\u7684\u4efb\u52d9\u4e2d\u7684\u6f5b\u529b\uff0c\u4f8b\u5982\u91d1\u878d\uff0c\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa CFinBench\uff1a\u4e00\u500b\u7cbe\u5fc3\u88fd\u4f5c\u7684\u3001\u8fc4\u4eca\u70ba\u6b62\u6700\u5168\u9762\u7684\u8a55\u4f30\u57fa\u6e96\uff0c\u7528\u65bc\u8a55\u4f30 LLM \u5728\u4e2d\u6587\u80cc\u666f\u4e0b\u7684\u91d1\u878d\u77e5\u8b58\u3002\u5728\u5be6\u52d9\u4e2d\uff0c\u70ba\u4e86\u66f4\u597d\u5730\u8207\u4e2d\u570b\u91d1\u878d\u5f9e\u696d\u4eba\u54e1\u7684\u8077\u696d\u767c\u5c55\u8ecc\u8de1\u4fdd\u6301\u4e00\u81f4\uff0c\u6211\u5011\u5f9e 4 \u500b\u4e00\u7d1a\u985e\u5225\u5efa\u7acb\u4e86\u4e00\u500b\u7cfb\u7d71\u6027\u7684\u8a55\u4f30\uff1a(1) \u91d1\u878d\u79d1\u76ee\uff1aLLM \u662f\u5426\u80fd\u8a18\u4f4f\u5fc5\u8981\u7684\u91d1\u878d\u79d1\u76ee\u57fa\u790e\u77e5\u8b58\uff0c\u4f8b\u5982\u7d93\u6fdf\u5b78\u3001\u7d71\u8a08\u5b78\u548c\u5be9\u8a08\u3002(2) \u91d1\u878d\u8cc7\u683c\uff1aLLM \u662f\u5426\u80fd\u53d6\u5f97\u6240\u9700\u7684\u91d1\u878d\u8cc7\u683c\u8a8d\u8b49\uff0c\u4f8b\u5982\u8a3b\u518a\u6703\u8a08\u5e2b\u3001\u8b49\u5238\u8cc7\u683c\u548c\u9280\u884c\u8cc7\u683c\u3002(3) \u91d1\u878d\u5be6\u52d9\uff1aLLM \u662f\u5426\u80fd\u5c65\u884c\u5be6\u52d9\u7684\u91d1\u878d\u5de5\u4f5c\uff0c\u4f8b\u5982\u7a05\u52d9\u9867\u554f\u3001\u521d\u7d1a\u6703\u8a08\u5e2b\u548c\u8b49\u5238\u5206\u6790\u5e2b\u3002(4) \u91d1\u878d\u6cd5\u898f\uff1aLLM \u662f\u5426\u80fd\u7b26\u5408\u91d1\u878d\u6cd5\u898f\u7684\u8981\u6c42\uff0c\u4f8b\u5982\u7a05\u6cd5\u3001\u4fdd\u96aa\u6cd5\u548c\u7d93\u6fdf\u6cd5\u3002CFinBench \u5305\u542b 99,100 \u500b\u554f\u984c\uff0c\u6db5\u84cb 43 \u500b\u4e8c\u7d1a\u985e\u5225\uff0c\u6709 3 \u7a2e\u985e\u578b\u7684\u554f\u984c\uff1a\u55ae\u9078\u984c\u3001\u591a\u9078\u984c\u548c\u5224\u65b7\u984c\u3002\u6211\u5011\u5c0d 50 \u500b\u5177\u6709\u5404\u7a2e\u6a21\u578b\u5927\u5c0f\u7684\u4ee3\u8868\u6027 LLM \u5728 CFinBench \u4e0a\u9032\u884c\u4e86\u5ee3\u6cdb\u7684\u5be6\u9a57\u3002\u7d50\u679c\u8868\u660e\uff0cGPT4 \u548c\u4e00\u4e9b\u4ee5\u4e2d\u6587\u70ba\u5c0e\u5411\u7684\u6a21\u578b\u9818\u5148\u65bc\u57fa\u6e96\uff0c\u5e73\u5747\u6e96\u78ba\u7387\u6700\u9ad8\u70ba 60.16%\uff0c\u7a81\u986f\u4e86 CFinBench \u6240\u5e36\u4f86\u7684\u6311\u6230\u3002\u8cc7\u6599\u96c6\u548c\u8a55\u4f30\u7a0b\u5f0f\u78bc\u53ef\u5728 https://cfinbench.github.io/ \u53d6\u5f97\u3002", "author": "Ying Nie et.al.", "authors": "Ying Nie, Binwei Yan, Tianyu Guo, Hao Liu, Haoyu Wang, Wei He, Binfan Zheng, Weihao Wang, Qiang Li, Weijian Sun, Yunhe Wang, Dacheng Tao", "id": "2407.02301v1", "paper_url": "http://arxiv.org/abs/2407.02301v1", "repo": "null"}}