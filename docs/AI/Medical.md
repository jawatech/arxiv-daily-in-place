
### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-04**|**Not All Diffusion Model Activations Have Been Evaluated as Discriminative Features**|Benyuan Meng et.al.|[2410.03558v1](http://arxiv.org/abs/2410.03558v1)|[link](https://github.com/darkbblue/generic-diffusion-feature)|
|**2024-10-04**|**Towards Real-time Intrahepatic Vessel Identification in Intraoperative Ultrasound-Guided Liver Surgery**|Karl-Philippe Beaudet et.al.|[2410.03420v1](http://arxiv.org/abs/2410.03420v1)|null|
|**2024-10-04**|**Make Interval Bound Propagation great again**|Patryk Krukowski et.al.|[2410.03373v1](http://arxiv.org/abs/2410.03373v1)|[link](https://github.com/gmum/make-interval-bound-propagation-great-again)|
|**2024-10-04**|**An Enhanced Harmonic Densely Connected Hybrid Transformer Network Architecture for Chronic Wound Segmentation Utilising Multi-Colour Space Tensor Merging**|Bill Cassidy et.al.|[2410.03359v1](http://arxiv.org/abs/2410.03359v1)|null|
|**2024-10-04**|**Comparative Analysis and Ensemble Enhancement of Leading CNN Architectures for Breast Cancer Classification**|Gary Murphy et.al.|[2410.03333v1](http://arxiv.org/abs/2410.03333v1)|null|
|**2024-10-04**|**Manikin-Recorded Cardiopulmonary Sounds Dataset Using Digital Stethoscope**|Yasaman Torabi et.al.|[2410.03280v1](http://arxiv.org/abs/2410.03280v1)|[link](https://github.com/torabiy/hls-cmds)|
|**2024-10-04**|**Looking into Concept Explanation Methods for Diabetic Retinopathy Classification**|Andrea M. Stor√•s et.al.|[2410.03188v1](http://arxiv.org/abs/2410.03188v1)|[link](https://github.com/andreastoraas/conceptexplanations_dr_grading)|
|**2024-10-04**|**Remaining Useful Life Prediction: A Study on Multidimensional Industrial Signal Processing and Efficient Transfer Learning Based on Large Language Models**|Yan Chen et.al.|[2410.03134v1](http://arxiv.org/abs/2410.03134v1)|null|
|**2024-10-04**|**Image First or Text First? Optimising the Sequencing of Modalities in Large Language Model Prompting and Reasoning Tasks**|Grant Wardle et.al.|[2410.03062v1](http://arxiv.org/abs/2410.03062v1)|null|
|**2024-10-03**|**Is Your Paper Being Reviewed by an LLM? Investigating AI Text Detectability in Peer Review**|Sungduk Yu et.al.|[2410.03019v1](http://arxiv.org/abs/2410.03019v1)|null|
|**2024-10-03**|**DailyDilemmas: Revealing Value Preferences of LLMs with Quandaries of Daily Life**|Yu Ying Chiu et.al.|[2410.02683v1](http://arxiv.org/abs/2410.02683v1)|null|
|**2024-10-03**|**Plots Unlock Time-Series Understanding in Multimodal Models**|Mayank Daswani et.al.|[2410.02637v1](http://arxiv.org/abs/2410.02637v1)|null|
|**2024-10-03**|**IC3M: In-Car Multimodal Multi-object Monitoring for Abnormal Status of Both Driver and Passengers**|Zihan Fang et.al.|[2410.02592v1](http://arxiv.org/abs/2410.02592v1)|null|
|**2024-10-03**|**Deep Regression 2D-3D Ultrasound Registration for Liver Motion Correction in Focal Tumor Thermal Ablation**|Shuwei Xing et.al.|[2410.02579v1](http://arxiv.org/abs/2410.02579v1)|[link](https://github.com/xingorno/deepregs2v)|
|**2024-10-03**|**ColaCare: Enhancing Electronic Health Record Modeling through Large Language Model-Driven Multi-Agent Collaboration**|Zixiang Wang et.al.|[2410.02551v1](http://arxiv.org/abs/2410.02551v1)|null|
|**2024-10-03**|**SAFLEX: Self-Adaptive Augmentation via Feature Label Extrapolation**|Mucong Ding et.al.|[2410.02512v1](http://arxiv.org/abs/2410.02512v1)|null|
|**2024-10-03**|**Clinnova Federated Learning Proof of Concept: Key Takeaways from a Cross-border Collaboration**|Julia Alekseenko et.al.|[2410.02443v1](http://arxiv.org/abs/2410.02443v1)|null|
|**2024-10-03**|**A Comprehensive Survey of Mamba Architectures for Medical Image Analysis: Classification, Segmentation, Restoration and Beyond**|Shubhi Bansal et.al.|[2410.02362v1](http://arxiv.org/abs/2410.02362v1)|[link](https://github.com/madhavaprasath23/awesome-mamba-papers-on-medical-domain)|
|**2024-10-03**|**CTARR: A fast and robust method for identifying anatomical regions on CT images via atlas registration**|Thomas Buddenkotte et.al.|[2410.02316v1](http://arxiv.org/abs/2410.02316v1)|[link](https://github.com/thomasbudd/ctarr)|
|**2024-10-02**|**Multi-Omic and Quantum Machine Learning Integration for Lung Subtypes Classification**|Mandeep Kaur Saggi et.al.|[2410.02085v1](http://arxiv.org/abs/2410.02085v1)|null|
|**2024-10-02**|**Zodiac: A Cardiologist-Level LLM Framework for Multi-Agent Diagnostics**|Yuan Zhou et.al.|[2410.02026v1](http://arxiv.org/abs/2410.02026v1)|null|
|**2024-10-02**|**UlcerGPT: A Multimodal Approach Leveraging Large Language and Vision Models for Diabetic Foot Ulcer Image Transcription**|Reza Basiri et.al.|[2410.01989v1](http://arxiv.org/abs/2410.01989v1)|null|
|**2024-10-02**|**DeFine: Enhancing LLM Decision-Making with Factor Profiles and Analogical Reasoning**|Yebowen Hu et.al.|[2410.01772v1](http://arxiv.org/abs/2410.01772v1)|null|
|**2024-10-02**|**Towards a vision foundation model for comprehensive assessment of Cardiac MRI**|Athira J Jacob et.al.|[2410.01665v1](http://arxiv.org/abs/2410.01665v1)|null|
|**2024-10-02**|**Imaging foundation model for universal enhancement of non-ideal measurement CT**|Yuxin Liu et.al.|[2410.01591v1](http://arxiv.org/abs/2410.01591v1)|[link](https://github.com/yutinghe-list/tamp)|
|**2024-10-02**|**OpenMathInstruct-2: Accelerating AI for Math with Massive Open-Source Instruction Data**|Shubham Toshniwal et.al.|[2410.01560v2](http://arxiv.org/abs/2410.01560v2)|[link](https://github.com/kipok/nemo-skills)|
|**2024-10-02**|**MedQA-CS: Benchmarking Large Language Models Clinical Skills Using an AI-SCE Framework**|Zonghai Yao et.al.|[2410.01553v1](http://arxiv.org/abs/2410.01553v1)|[link](https://github.com/bio-nlp/medqa-cs)|
|**2024-10-02**|**On the Convergence of FedProx with Extrapolation and Inexact Prox**|Hanmin Li et.al.|[2410.01410v1](http://arxiv.org/abs/2410.01410v1)|null|
|**2024-10-02**|**See Me and Believe Me: Causality and Intersectionality in Testimonial Injustice in Healthcare**|Kenya S. Andrews et.al.|[2410.01227v1](http://arxiv.org/abs/2410.01227v1)|null|
|**2024-10-01**|**Explainable Diagnosis Prediction through Neuro-Symbolic Integration**|Qiuhao Lu et.al.|[2410.01855v1](http://arxiv.org/abs/2410.01855v1)|null|
|**2024-10-01**|**Heterogeneous sound classification with the Broad Sound Taxonomy and Dataset**|Panagiota Anastasopoulou et.al.|[2410.00980v1](http://arxiv.org/abs/2410.00980v1)|[link](https://github.com/allholy/bsd10k)|
|**2024-10-01**|**The Gradient of Health Data Privacy**|Baihan Lin et.al.|[2410.00897v1](http://arxiv.org/abs/2410.00897v1)|null|
|**2024-10-01**|**GAMMA-PD: Graph-based Analysis of Multi-Modal Motor Impairment Assessments in Parkinson's Disease**|Favour Nerrise et.al.|[2410.00944v1](http://arxiv.org/abs/2410.00944v1)|null|
|**2024-10-01**|**Contrastive Abstraction for Reinforcement Learning**|Vihang Patil et.al.|[2410.00704v1](http://arxiv.org/abs/2410.00704v1)|null|
|**2024-10-01**|**Arges: Spatio-Temporal Transformer for Ulcerative Colitis Severity Assessment in Endoscopy Videos**|Krishna Chaitanya et.al.|[2410.00536v1](http://arxiv.org/abs/2410.00536v1)|null|
|**2024-10-01**|**Bayes-CATSI: A variational Bayesian deep learning framework for medical time series data imputation**|Omkar Kulkarni et.al.|[2410.01847v2](http://arxiv.org/abs/2410.01847v2)|[link](https://github.com/pingala-institute/Bayes-medicaldataimputation)|
|**2024-10-01**|**ReXplain: Translating Radiology into Patient-Friendly Video Reports**|Luyang Luo et.al.|[2410.00441v1](http://arxiv.org/abs/2410.00441v1)|null|
|**2024-10-01**|**CXPMRG-Bench: Pre-training and Benchmarking for X-ray Medical Report Generation on CheXpert Plus Dataset**|Xiao Wang et.al.|[2410.00379v1](http://arxiv.org/abs/2410.00379v1)|[link](https://github.com/event-ahu/medical_image_analysis)|
|**2024-10-01**|**Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**|Prasenjit Maji et.al.|[2410.00366v1](http://arxiv.org/abs/2410.00366v1)|null|
|**2024-09-30**|**The age of spiritual machines: Language quietus induces synthetic altered states of consciousness in artificial intelligence**|Jeremy I Skipper et.al.|[2410.00257v1](http://arxiv.org/abs/2410.00257v1)|null|
|**2024-09-30**|**Adapting LLMs for the Medical Domain in Portuguese: A Study on Fine-Tuning and Model Evaluation**|Pedro Henrique Paiola et.al.|[2410.00163v1](http://arxiv.org/abs/2410.00163v1)|null|
|**2024-09-30**|**The Perfect Blend: Redefining RLHF with Mixture of Judges**|Tengyu Xu et.al.|[2409.20370v1](http://arxiv.org/abs/2409.20370v1)|null|
|**2024-09-30**|**Forecasting Disease Progression with Parallel Hyperplanes in Longitudinal Retinal OCT**|Arunava Chakravarty et.al.|[2409.20195v2](http://arxiv.org/abs/2409.20195v2)|[link](https://github.com/arunava555/Forecast_parallel_hyperplanes)|
|**2024-09-30**|**Classification of Radiological Text in Small and Imbalanced Datasets in a Non-English Language**|Vincent Beliveau et.al.|[2409.20147v1](http://arxiv.org/abs/2409.20147v1)|null|
|**2024-09-30**|**Positive-Sum Fairness: Leveraging Demographic Attributes to Achieve Fair AI Outcomes Without Sacrificing Group Gains**|Samia Belhadj et.al.|[2409.19940v1](http://arxiv.org/abs/2409.19940v1)|null|
|**2024-09-29**|**InfantCryNet: A Data-driven Framework for Intelligent Analysis of Infant Cries**|Mengze Hong et.al.|[2409.19689v1](http://arxiv.org/abs/2409.19689v1)|null|
|**2024-09-29**|**See Detail Say Clear: Towards Brain CT Report Generation via Pathological Clue-driven Representation Learning**|Chengxin Zheng et.al.|[2409.19676v2](http://arxiv.org/abs/2409.19676v2)|[link](https://github.com/chauncey-jheng/pcrl-mrg)|
|**2024-09-29**|**Assessment and manipulation of latent constructs in pre-trained language models using psychometric scales**|Maor Reuben et.al.|[2409.19655v1](http://arxiv.org/abs/2409.19655v1)|[link](https://github.com/cnai-lab/qlatent)|
|**2024-09-29**|**A Survey on Graph Neural Networks for Remaining Useful Life Prediction: Methodologies, Evaluation and Future Trends**|Yucheng Wang et.al.|[2409.19629v1](http://arxiv.org/abs/2409.19629v1)|null|
|**2024-09-29**|**MCDDPM: Multichannel Conditional Denoising Diffusion Model for Unsupervised Anomaly Detection in Brain MRI**|Vivek Kumar Trivedi et.al.|[2409.19623v1](http://arxiv.org/abs/2409.19623v1)|[link](https://github.com/vivekkumartri/mcddpm)|
|**2024-09-29**|**Understanding Clinical Decision-Making in Traditional East Asian Medicine through Dimensionality Reduction: An Empirical Investigation**|Hyojin Bae et.al.|[2409.19531v1](http://arxiv.org/abs/2409.19531v1)|null|
|**2024-09-29**|**MedHalu: Hallucinations in Responses to Healthcare Queries by Large Language Models**|Vibhor Agarwal et.al.|[2409.19492v1](http://arxiv.org/abs/2409.19492v1)|null|
|**2024-09-28**|**INSIGHTBUDDY-AI: Medication Extraction and Entity Linking using Large Language Models and Ensemble Learning**|Pablo Romero et.al.|[2409.19467v1](http://arxiv.org/abs/2409.19467v1)|null|
|**2024-09-28**|**Mind the Gap: Promoting Missing Modality Brain Tumor Segmentation with Alignment**|Tianyi Liu et.al.|[2409.19366v1](http://arxiv.org/abs/2409.19366v1)|null|
|**2024-09-28**|**3D-CT-GPT: Generating 3D Radiology Reports through Integration of Large Vision-Language Models**|Hao Chen et.al.|[2409.19330v1](http://arxiv.org/abs/2409.19330v1)|null|
|**2024-09-28**|**Epidemiology-Aware Neural ODE with Continuous Disease Transmission Graph**|Guancheng Wan et.al.|[2410.00049v1](http://arxiv.org/abs/2410.00049v1)|null|
|**2024-09-27**|**A GEN AI Framework for Medical Note Generation**|Hui Yi Leong et.al.|[2410.01841v1](http://arxiv.org/abs/2410.01841v1)|null|
|**2024-09-27**|**Secure Multiparty Generative AI**|Manil Shrestha et.al.|[2409.19120v1](http://arxiv.org/abs/2409.19120v1)|null|
|**2024-09-27**|**Differential privacy for protecting patient data in speech disorder detection using deep learning**|Soroosh Tayebi Arasteh et.al.|[2409.19078v1](http://arxiv.org/abs/2409.19078v1)|null|
|**2024-09-27**|**AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow**|Huizi Yu et.al.|[2409.18924v2](http://arxiv.org/abs/2409.18924v2)|null|
|**2024-09-27**|**Suicide Phenotyping from Clinical Notes in Safety-Net Psychiatric Hospital Using Multi-Label Classification with Pre-Trained Language Models**|Zehan Li et.al.|[2409.18878v2](http://arxiv.org/abs/2409.18878v2)|null|
|**2024-09-27**|**Early diagnosis of Alzheimer's disease from MRI images with deep learning model**|Sajjad Aghasi Javid et.al.|[2409.18814v1](http://arxiv.org/abs/2409.18814v1)|null|
|**2024-09-27**|**State-of-the-Art Periorbital Distance Prediction and Disease Classification Using Periorbital Features**|George R. Nahass et.al.|[2409.18769v2](http://arxiv.org/abs/2409.18769v2)|null|
|**2024-09-27**|**Multi-modal Medical Image Fusion For Non-Small Cell Lung Cancer Classification**|Salma Hassan et.al.|[2409.18715v1](http://arxiv.org/abs/2409.18715v1)|null|
|**2024-09-27**|**Towards Integrating Epistemic Uncertainty Estimation into the Radiotherapy Workflow**|Marvin Tom Teichmann et.al.|[2409.18628v1](http://arxiv.org/abs/2409.18628v1)|null|
|**2024-09-27**|**Leveraging Long-Context Large Language Models for Multi-Document Understanding and Summarization in Enterprise Applications**|Aditi Godbole et.al.|[2409.18454v1](http://arxiv.org/abs/2409.18454v1)|null|
|**2024-09-27**|**Physics Augmented Tuple Transformer for Autism Severity Level Detection**|Chinthaka Ranasingha et.al.|[2409.18438v1](http://arxiv.org/abs/2409.18438v1)|null|
|**2024-09-27**|**LCMDC: Large-scale Chinese Medical Dialogue Corpora for Automatic Triage and Medical Consultation**|Xinyuan Wang et.al.|[2410.03521v1](http://arxiv.org/abs/2410.03521v1)|null|
|**2024-09-26**|**DRL-STNet: Unsupervised Domain Adaptation for Cross-modality Medical Image Segmentation via Disentangled Representation Learning**|Hui Lin et.al.|[2409.18340v1](http://arxiv.org/abs/2409.18340v1)|null|
|**2024-09-26**|**Cross-Institutional Structured Radiology Reporting for Lung Cancer Screening Using a Dynamic Template-Constrained Large Language Model**|Chuang Niu et.al.|[2409.18319v1](http://arxiv.org/abs/2409.18319v1)|null|
|**2024-09-26**|**Retrospective Comparative Analysis of Prostate Cancer In-Basket Messages: Responses from Closed-Domain LLM vs. Clinical Teams**|Yuexing Hao et.al.|[2409.18290v1](http://arxiv.org/abs/2409.18290v1)|[link](https://github.com/YuexingHao/In-Basket-Message-Evaluation)|
|**2024-09-26**|**Evaluation of Large Language Models for Summarization Tasks in the Medical Domain: A Narrative Review**|Emma Croxford et.al.|[2409.18170v1](http://arxiv.org/abs/2409.18170v1)|null|
|**2024-09-26**|**Multi-View and Multi-Scale Alignment for Contrastive Language-Image Pre-training in Mammography**|Yuexi Du et.al.|[2409.18119v1](http://arxiv.org/abs/2409.18119v1)|null|
|**2024-09-26**|**CRoP: Context-wise Robust Static Human-Sensing Personalization**|Sawinder Kaur et.al.|[2409.17994v2](http://arxiv.org/abs/2409.17994v2)|null|
|**2024-09-26**|**Supervised Learning Model for Key Frame Identification from Cow Teat Videos**|Minghao Wang et.al.|[2409.18797v1](http://arxiv.org/abs/2409.18797v1)|null|
|**2024-09-26**|**Implementing a Nordic-Baltic Federated Health Data Network: a case report**|Taridzo Chomutare et.al.|[2409.17865v1](http://arxiv.org/abs/2409.17865v1)|null|
|**2024-09-26**|**DREAMS: A python framework to train deep learning models with model card reporting for medical and health applications**|Rabindra Khadka et.al.|[2409.17815v1](http://arxiv.org/abs/2409.17815v1)|null|
|**2024-09-26**|**Ophthalmic Biomarker Detection with Parallel Prediction of Transformer and Convolutional Architecture**|Md. Touhidul Islam et.al.|[2409.17788v1](http://arxiv.org/abs/2409.17788v1)|null|
|**2024-09-26**|**Confidence intervals uncovered: Are we ready for real-world medical imaging AI?**|Evangelia Christodoulou et.al.|[2409.17763v2](http://arxiv.org/abs/2409.17763v2)|null|
|**2024-09-26**|**Artificial Data Point Generation in Clustered Latent Space for Small Medical Datasets**|Yasaman Haghbin et.al.|[2409.17685v1](http://arxiv.org/abs/2409.17685v1)|null|
|**2024-09-26**|**Zero- and Few-shot Named Entity Recognition and Text Expansion in Medication Prescriptions using ChatGPT**|Natthanaphop Isaradech et.al.|[2409.17683v1](http://arxiv.org/abs/2409.17683v1)|null|
|**2024-09-26**|**Digital Twin Ecosystem for Oncology Clinical Operations**|Himanshu Pandey et.al.|[2409.17650v1](http://arxiv.org/abs/2409.17650v1)|null|
|**2024-09-26**|**A Scalable Data-Driven Framework for Systematic Analysis of SEC 10-K Filings Using Large Language Models**|Syed Affan Daimi et.al.|[2409.17581v1](http://arxiv.org/abs/2409.17581v1)|null|
|**2024-09-26**|**Dr. GPT in Campus Counseling: Understanding Higher Education Students' Opinions on LLM-assisted Mental Health Services**|Owen Xingjian Zhang et.al.|[2409.17572v1](http://arxiv.org/abs/2409.17572v1)|null|
|**2024-09-26**|**Uni-Med: A Unified Medical Generalist Foundation Model For Multi-Task Learning Via Connector-MoE**|Xun Zhu et.al.|[2409.17508v1](http://arxiv.org/abs/2409.17508v1)|null|
|**2024-09-26**|**Global-Local Medical SAM Adaptor Based on Full Adaption**|Meng Wang et.al.|[2409.17486v1](http://arxiv.org/abs/2409.17486v1)|null|
|**2024-09-25**|**Block Expanded DINORET: Adapting Natural Domain Foundation Models for Retinal Imaging Without Catastrophic Forgetting**|Jay Zoellin et.al.|[2409.17332v1](http://arxiv.org/abs/2409.17332v1)|null|
|**2024-09-25**|**Data-Centric AI Governance: Addressing the Limitations of Model-Focused Policies**|Ritwik Gupta et.al.|[2409.17216v1](http://arxiv.org/abs/2409.17216v1)|null|
|**2024-09-25**|**Ctrl-GenAug: Controllable Generative Augmentation for Medical Sequence Classification**|Xinrui Zhou et.al.|[2409.17091v1](http://arxiv.org/abs/2409.17091v1)|null|
|**2024-09-25**|**DRIM: Learning Disentangled Representations from Incomplete Multimodal Healthcare Data**|Lucas Robinet et.al.|[2409.17055v2](http://arxiv.org/abs/2409.17055v2)|[link](https://github.com/lucas-rbnt/drim)|
|**2024-09-25**|**Using LLM for Real-Time Transcription and Summarization of Doctor-Patient Interactions into ePuskesmas in Indonesia**|Azmul Asmar Irfan et.al.|[2409.17054v1](http://arxiv.org/abs/2409.17054v1)|null|
|**2024-09-25**|**GeoBiked: A Dataset with Geometric Features and Automated Labeling Techniques to Enable Deep Generative Models in Engineering Design**|Phillip Mueller et.al.|[2409.17045v1](http://arxiv.org/abs/2409.17045v1)|null|
|**2024-09-25**|**AI-driven View Guidance System in Intra-cardiac Echocardiography Imaging**|Jaeyoung Huh et.al.|[2409.16898v2](http://arxiv.org/abs/2409.16898v2)|null|
|**2024-09-25**|**The Role of Language Models in Modern Healthcare: A Comprehensive Review**|Amna Khalid et.al.|[2409.16860v1](http://arxiv.org/abs/2409.16860v1)|null|
|**2024-09-25**|**A Multi-Dataset Classification-Based Deep Learning Framework for Electronic Health Records and Predictive Analysis in Healthcare**|Syed Mohd Faisal Malik et.al.|[2409.16721v1](http://arxiv.org/abs/2409.16721v1)|null|
|**2024-09-25**|**Enhancing Guardrails for Safe and Secure Healthcare AI**|Ananya Gangavarapu et.al.|[2409.17190v1](http://arxiv.org/abs/2409.17190v1)|null|
|**2024-09-25**|**Enhancing disease detection in radiology reports through fine-tuning lightweight LLM on weak labels**|Yishu Wei et.al.|[2409.16563v1](http://arxiv.org/abs/2409.16563v1)|null|
|**2024-09-24**|**To Explore the Potential Inhibitors against Multitarget Proteins of COVID 19 using In Silico Study**|Imra Aqeel et.al.|[2409.16486v1](http://arxiv.org/abs/2409.16486v1)|null|
|**2024-09-24**|**Design and Evaluation of a CDSS for Drug Allergy Management Using LLMs and Pharmaceutical Data Integration**|Gabriele De Vito et.al.|[2409.16395v1](http://arxiv.org/abs/2409.16395v1)|null|
|**2024-09-24**|**Future-Proofing Medical Imaging with Privacy-Preserving Federated Learning and Uncertainty Quantification: A Review**|Nikolas Koutsoubis et.al.|[2409.16340v1](http://arxiv.org/abs/2409.16340v1)|null|

#### Abstracts
##### **Not All Diffusion Model Activations Have Been Evaluated as Discriminative Features**
2410.03558v1 by Benyuan Meng, Qianqian Xu, Zitai Wang, Xiaochun Cao, Qingming Huang

Diffusion models are initially designed for image generation. Recent research
shows that the internal signals within their backbones, named activations, can
also serve as dense features for various discriminative tasks such as semantic
segmentation. Given numerous activations, selecting a small yet effective
subset poses a fundamental problem. To this end, the early study of this field
performs a large-scale quantitative comparison of the discriminative ability of
the activations. However, we find that many potential activations have not been
evaluated, such as the queries and keys used to compute attention scores.
Moreover, recent advancements in diffusion architectures bring many new
activations, such as those within embedded ViT modules. Both combined,
activation selection remains unresolved but overlooked. To tackle this issue,
this paper takes a further step with a much broader range of activations
evaluated. Considering the significant increase in activations, a full-scale
quantitative comparison is no longer operational. Instead, we seek to
understand the properties of these activations, such that the activations that
are clearly inferior can be filtered out in advance via simple qualitative
evaluation. After careful analysis, we discover three properties universal
among diffusion models, enabling this study to go beyond specific models. On
top of this, we present effective feature selection solutions for several
popular diffusion models. Finally, the experiments across multiple
discriminative tasks validate the superiority of our method over the SOTA
competitors. Our code is available at
https://github.com/Darkbblue/generic-diffusion-feature.

ÊëòË¶ÅÔºöÊì¥Êï£Ê®°ÂûãÊúÄÂàùÊòØÈáùÂ∞çÂΩ±ÂÉèÁîüÊàêËÄåË®≠Ë®àÁöÑ„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂È°ØÁ§∫ÔºåÂÖ∂‰∏ªÂππ‰∏≠ÁöÑÂÖßÈÉ®Ë®äËôüÔºàÁ®±ÁÇ∫ÂïüÂãïÔºâ‰πüÂèØ‰ΩúÁÇ∫ÂêÑÁ®ÆÂà§Âà•Âºè‰ªªÂãôÔºà‰æãÂ¶ÇË™ûÊÑèÂàÜÂâ≤ÔºâÁöÑÂØÜÈõÜÁâπÂæµ„ÄÇÂú®Áµ¶ÂÆöË®±Â§öÂïüÂãïÁöÑÊÉÖÊ≥Å‰∏ãÔºåÈÅ∏Êìá‰∏ÄÂÄãÂ∞è‰ΩÜÊúâÊïàÁöÑÂ≠êÈõÜÊúÉÊßãÊàê‰∏ÄÂÄãÂü∫Êú¨ÂïèÈ°å„ÄÇÁÇ∫Ê≠§ÔºåË©≤È†òÂüüÁöÑÊó©ÊúüÁ†îÁ©∂Â∞çÂïüÂãïÁöÑÂà§Âà•ËÉΩÂäõÈÄ≤Ë°å‰∫ÜÂ§ßË¶èÊ®°ÁöÑÂÆöÈáèÊØîËºÉ„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëÁôºÁèæË®±Â§öÊΩõÂú®ÁöÑÂïüÂãïÂ∞öÊú™Á∂ìÈÅéË©ï‰º∞Ôºå‰æãÂ¶ÇÁî®ÊñºË®àÁÆóÊ≥®ÊÑèÂäõÂàÜÊï∏ÁöÑÊü•Ë©¢ÂíåÈçµ„ÄÇÊ≠§Â§ñÔºåÊì¥Êï£Êû∂ÊßãÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÂ∏∂‰æÜ‰∫ÜË®±Â§öÊñ∞ÁöÑÂïüÂãïÔºå‰æãÂ¶ÇÂµåÂÖ•Âºè ViT Ê®°ÁµÑ‰∏≠ÁöÑÈÇ£‰∫õ„ÄÇÂÖ©ËÄÖÁõ∏ÁµêÂêàÔºåÂïüÂãïÈÅ∏Êìá‰ªçÁÑ∂Êú™Ëß£Ê±∫‰∏îË¢´ÂøΩË¶ñ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊú¨ÊñáÊõ¥ÈÄ≤‰∏ÄÊ≠•ÔºåË©ï‰º∞‰∫ÜÊõ¥Âª£Ê≥õÁöÑÂïüÂãïÁØÑÂúç„ÄÇËÄÉÊÖÆÂà∞ÂïüÂãïÁöÑÂ§ßÂπÖÂ¢ûÂä†ÔºåÂÖ®Èù¢ÂÆöÈáèÊØîËºÉ‰∏çÂÜçÂèØË°å„ÄÇÁõ∏ÂèçÔºåÊàëÂÄëË©¶Âúñ‰∫ÜËß£ÈÄô‰∫õÂïüÂãïÁöÑÂ±¨ÊÄßÔºå‰ª•‰æøÂèØ‰ª•ÈÄèÈÅéÁ∞°ÂñÆÁöÑÂÆöÊÄßË©ï‰º∞‰∫ãÂÖàÁØ©ÈÅ∏Âá∫ÊòéÈ°ØËºÉÂ∑ÆÁöÑÂïüÂãï„ÄÇÁ∂ìÈÅé‰ªîÁ¥∞ÂàÜÊûêÔºåÊàëÂÄëÁôºÁèæ‰∫ÜÊì¥Êï£Ê®°Âûã‰∏≠ÊôÆÈÅçÂ≠òÂú®ÁöÑ‰∏âÂÄãÂ±¨ÊÄßÔºå‰ΩøÊú¨Á†îÁ©∂ËÉΩÂ§†Ë∂ÖË∂äÁâπÂÆöÊ®°Âûã„ÄÇÈô§Ê≠§‰πãÂ§ñÔºåÊàëÂÄëÈÇÑÁÇ∫ÂπæÂÄãÊµÅË°åÁöÑÊì¥Êï£Ê®°ÂûãÊèê‰æõ‰∫ÜÊúâÊïàÁöÑÁâπÂæµÈÅ∏ÊìáËß£Ê±∫ÊñπÊ°à„ÄÇÊúÄÂæåÔºåË∑®Â§öÂÄãÂà§Âà•Âºè‰ªªÂãôÁöÑÂØ¶È©óÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂÑ™Êñº SOTA Á´∂Áà≠Â∞çÊâã„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/Darkbblue/generic-diffusion-feature ÂèñÂæó„ÄÇ

##### **Towards Real-time Intrahepatic Vessel Identification in Intraoperative Ultrasound-Guided Liver Surgery**
2410.03420v1 by Karl-Philippe Beaudet, Alexandros Karargyris, Sidaty El Hadramy, St√©phane Cotin, Jean-Paul Mazellier, Nicolas Padoy, Juan Verde

While laparoscopic liver resection is less prone to complications and
maintains patient outcomes compared to traditional open surgery, its complexity
hinders widespread adoption due to challenges in representing the liver's
internal structure. Laparoscopic intraoperative ultrasound offers efficient,
cost-effective and radiation-free guidance. Our objective is to aid physicians
in identifying internal liver structures using laparoscopic intraoperative
ultrasound. We propose a patient-specific approach using preoperative 3D
ultrasound liver volume to train a deep learning model for real-time
identification of portal tree and branch structures. Our personalized AI model,
validated on ex vivo swine livers, achieved superior precision (0.95) and
recall (0.93) compared to surgeons, laying groundwork for precise vessel
identification in ultrasound-based liver resection. Its adaptability and
potential clinical impact promise to advance surgical interventions and improve
patient care.

ÊëòË¶ÅÔºöËÖπËÖîÈè°ËÇùÂàáÈô§Ë°ìËàáÂÇ≥Áµ±ÁöÑÈñãÊîæÊâãË°ìÁõ∏ÊØîÔºåËºÉ‰∏çÂÆπÊòìÁî¢Áîü‰ΩµÁôºÁóáÔºå‰∏îËÉΩÁ∂≠ÊåÅÊÇ£ËÄÖÁöÑÊ≤ªÁôÇÊàêÊïàÔºå‰ΩÜÁî±ÊñºÂÖ∂Ë§áÈõúÊÄßÔºåÂú®ÂëàÁèæËÇùËáüÂÖßÈÉ®ÁµêÊßãÊôÇÊúÉÈÅ≠ÈÅáÊåëÊà∞ÔºåÂõ†Ê≠§ÈòªÁ§ô‰∫ÜÂÆÉÁöÑÂª£Ê≥õÊé°Áî®„ÄÇËÖπËÖîÈè°Ë°ì‰∏≠Ë∂ÖÈü≥Ê≥¢Êèê‰æõ‰∫ÜÊúâÊïàÁéá„ÄÅÁ∂ìÊøü‰∏îÁÑ°ËºªÂ∞ÑÁöÑÂºïÂ∞é„ÄÇÊàëÂÄëÁöÑÁõÆÊ®ôÊòØÂçîÂä©ÈÜ´Â∏´‰ΩøÁî®ËÖπËÖîÈè°Ë°ì‰∏≠Ë∂ÖÈü≥Ê≥¢‰æÜËæ®Ë≠òËÇùËáüÂÖßÈÉ®ÁµêÊßã„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄã‰ΩøÁî®Ë°ìÂâç 3D Ë∂ÖÈü≥Ê≥¢ËÇùËáüÈ´îÁ©ç‰æÜË®ìÁ∑¥Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑÊÇ£ËÄÖÂ∞àÂ±¨ÊñπÊ≥ïÔºå‰ª•Âà©ÊñºÂç≥ÊôÇËæ®Ë≠òÈñÄÈùúËÑàÊ®πÂíåÂàÜÊîØÁµêÊßã„ÄÇÊàëÂÄëÁöÑÂÄã‰∫∫Âåñ AI Ê®°ÂûãÂ∑≤Âú®Èõ¢È´îË±¨ËÇùËáü‰∏äÈ©óË≠âÔºåËàáÂ§ñÁßëÈÜ´Â∏´Áõ∏ÊØîÔºåÈÅîÂà∞‰∫ÜÊõ¥È´òÁöÑÁ≤æÁ¢∫Â∫¶ (0.95) ÂíåÂè¨ÂõûÁéá (0.93)ÔºåÈÄôÁÇ∫Âü∫ÊñºË∂ÖÈü≥Ê≥¢ÁöÑËÇùÂàáÈô§Ë°ì‰∏≠Á≤æÁ¢∫ÁöÑË°ÄÁÆ°Ëæ®Ë≠òÂ•†ÂÆö‰∫ÜÂü∫Á§é„ÄÇÂÆÉÁöÑÈÅ©ÊáâÊÄßÂíåÊΩõÂú®ÁöÑËá®Â∫äÂΩ±ÈüøÊúâÊúõÊé®ÈÄ≤Â§ñÁßëÊâãË°ìÔºå‰∏¶ÊîπÂñÑÊÇ£ËÄÖÁÖßË≠∑„ÄÇ

##### **Make Interval Bound Propagation great again**
2410.03373v1 by Patryk Krukowski, Daniel Wilczak, Jacek Tabor, Anna Bielawska, Przemys≈Çaw Spurek

In various scenarios motivated by real life, such as medical data analysis,
autonomous driving, and adversarial training, we are interested in robust deep
networks. A network is robust when a relatively small perturbation of the input
cannot lead to drastic changes in output (like change of class, etc.). This
falls under the broader scope field of Neural Network Certification (NNC). Two
crucial problems in NNC are of profound interest to the scientific community:
how to calculate the robustness of a given pre-trained network and how to
construct robust networks. The common approach to constructing robust networks
is Interval Bound Propagation (IBP). This paper demonstrates that IBP is
sub-optimal in the first case due to its susceptibility to the wrapping effect.
Even for linear activation, IBP gives strongly sub-optimal bounds.
Consequently, one should use strategies immune to the wrapping effect to obtain
bounds close to optimal ones. We adapt two classical approaches dedicated to
strict computations -- Dubleton Arithmetic and Affine Arithmetic -- to mitigate
the wrapping effect in neural networks. These techniques yield precise results
for networks with linear activation functions, thus resisting the wrapping
effect. As a result, we achieve bounds significantly closer to the optimal
level than IBPs.

ÊëòË¶ÅÔºöÂú®ÂêÑÁ®ÆÂèóÁèæÂØ¶ÁîüÊ¥ªÊøÄÂãµÁöÑÂ†¥ÊôØ‰∏≠Ôºå‰æãÂ¶ÇÈÜ´Â≠∏Êï∏ÊìöÂàÜÊûê„ÄÅËá™ÂãïÈßïÈßõÂíåÂ∞çÊäóÊÄßË®ìÁ∑¥ÔºåÊàëÂÄëÂ∞çÂº∑ÂÅ•ÁöÑÊ∑±Â∫¶Á∂≤Ë∑ØÊÑüËààË∂£„ÄÇÁï∂Ëº∏ÂÖ•ÁöÑÂæÆÂ∞èÊìæÂãï‰∏çÊúÉÂ∞éËá¥Ëº∏Âá∫ÁôºÁîüÂäáÁÉàËÆäÂåñÔºà‰æãÂ¶ÇÈ°ûÂà•ÊîπËÆäÁ≠âÔºâÊôÇÔºåÁ∂≤Ë∑ØÂ∞±ÊòØÂº∑ÂÅ•ÁöÑ„ÄÇÈÄôÂ±¨ÊñºÁ•ûÁ∂ìÁ∂≤Ë∑ØË™çË≠â (NNC) ÁöÑÂª£Ê≥õÁØÑÁñá„ÄÇNNC ‰∏≠ÁöÑÂÖ©ÂÄãÈóúÈçµÂïèÈ°åÂºïËµ∑‰∫ÜÁßëÂ≠∏ÁïåÁöÑÊøÉÂéöËààË∂£ÔºöÂ¶Ç‰ΩïË®àÁÆóÁµ¶ÂÆöÈ†êË®ìÁ∑¥Á∂≤Ë∑ØÁöÑÂº∑ÂÅ•ÊÄßÔºå‰ª•ÂèäÂ¶Ç‰ΩïÊßãÂª∫Âº∑ÂÅ•Á∂≤Ë∑Ø„ÄÇÊßãÂª∫Âº∑ÂÅ•Á∂≤Ë∑ØÁöÑÂ∏∏Ë¶ãÊñπÊ≥ïÊòØÂçÄÈñìÈÇäÁïåÂÇ≥Êí≠ (IBP)„ÄÇÊú¨ÊñáË≠âÊòéÔºåÁî±Êñº IBP ÂÆπÊòìÂèóÂà∞ÂåÖË¶ÜÊïàÊáâÁöÑÂΩ±ÈüøÔºåÂõ†Ê≠§Âú®Á¨¨‰∏ÄÁ®ÆÊÉÖÊ≥Å‰∏ãÂÆÉÊòØÊ¨°ÂÑ™ÁöÑ„ÄÇÂç≥‰ΩøÂ∞çÊñºÁ∑öÊÄßÊøÄÊ¥ªÔºåIBP ‰πüÊúÉÁµ¶Âá∫Âº∑ÁÉàÁöÑÊ¨°ÂÑ™ÈÇäÁïå„ÄÇÂõ†Ê≠§ÔºåÊáâ‰ΩøÁî®Â∞çÂåÖË¶ÜÊïàÊáâÂÖçÁñ´ÁöÑÁ≠ñÁï•‰æÜÁç≤ÂæóÊé•ËøëÊúÄÂÑ™ÈÇäÁïåÁöÑÈÇäÁïå„ÄÇÊàëÂÄëË™øÊï¥‰∫ÜÂ∞àÈñÄÁî®ÊñºÂö¥Ê†ºË®àÁÆóÁöÑÂÖ©Á®ÆÁ∂ìÂÖ∏ÊñπÊ≥ï‚Äî‚ÄîÈõôÂÖÉÈÅãÁÆóÂíå‰ªøÂ∞ÑÈÅãÁÆó‚Äî‚Äî‰ª•Ê∏õËºïÁ•ûÁ∂ìÁ∂≤Ë∑Ø‰∏≠ÁöÑÂåÖË¶ÜÊïàÊáâ„ÄÇÈÄô‰∫õÊäÄË°ìÂ∞çÂÖ∑ÊúâÁ∑öÊÄßÊøÄÊ¥ªÂáΩÊï∏ÁöÑÁ∂≤Ë∑ØÁî¢ÁîüÁ≤æÁ¢∫ÁöÑÁµêÊûúÔºåÂæûËÄåÊäµÊäóÂåÖË¶ÜÊïàÊáâ„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂØ¶ÁèæÁöÑÈÇäÁïåÈ°ØËëóÊé•ËøëÊñº IBP ÁöÑÊúÄÂÑ™Á¥öÂà•„ÄÇ

##### **An Enhanced Harmonic Densely Connected Hybrid Transformer Network Architecture for Chronic Wound Segmentation Utilising Multi-Colour Space Tensor Merging**
2410.03359v1 by Bill Cassidy, Christian Mcbride, Connah Kendrick, Neil D. Reeves, Joseph M. Pappachan, Cornelius J. Fernandez, Elias Chacko, Raphael Br√ºngel, Christoph M. Friedrich, Metib Alotaibi, Abdullah Abdulaziz AlWabel, Mohammad Alderwish, Kuan-Ying Lai, Moi Hoon Yap

Chronic wounds and associated complications present ever growing burdens for
clinics and hospitals world wide. Venous, arterial, diabetic, and pressure
wounds are becoming increasingly common globally. These conditions can result
in highly debilitating repercussions for those affected, with limb amputations
and increased mortality risk resulting from infection becoming more common. New
methods to assist clinicians in chronic wound care are therefore vital to
maintain high quality care standards. This paper presents an improved HarDNet
segmentation architecture which integrates a contrast-eliminating component in
the initial layers of the network to enhance feature learning. We also utilise
a multi-colour space tensor merging process and adjust the harmonic shape of
the convolution blocks to facilitate these additional features. We train our
proposed model using wound images from light-skinned patients and test the
model on two test sets (one set with ground truth, and one without) comprising
only darker-skinned cases. Subjective ratings are obtained from clinical wound
experts with intraclass correlation coefficient used to determine inter-rater
reliability. For the dark-skin tone test set with ground truth, we demonstrate
improvements in terms of Dice similarity coefficient (+0.1221) and intersection
over union (+0.1274). Qualitative analysis showed high expert ratings, with
improvements of >3% demonstrated when comparing the baseline model with the
proposed model. This paper presents the first study to focus on darker-skin
tones for chronic wound segmentation using models trained only on wound images
exhibiting lighter skin. Diabetes is highly prevalent in countries where
patients have darker skin tones, highlighting the need for a greater focus on
such cases. Additionally, we conduct the largest qualitative study to date for
chronic wound segmentation.

ÊëòË¶ÅÔºö<paragraph>ÊÖ¢ÊÄßÂÇ∑Âè£ÂèäÂÖ∂‰ΩµÁôºÁóáÂ∞çÂÖ®ÁêÉË®∫ÊâÄÂíåÈÜ´Èô¢ËÄåË®ÄÔºåÂ∏∂‰æÜÊó•ÁõäÊ≤âÈáçÁöÑË≤†Êìî„ÄÇÈùúËÑàÊÄß„ÄÅÂãïËÑàÊÄß„ÄÅÁ≥ñÂ∞øÁóÖÊÄßÂíåÂ£ìÁò°Âú®ÂÖ®ÁêÉÊÑà‰æÜÊÑàÊôÆÈÅç„ÄÇÈÄô‰∫õÁñæÁóÖÊúÉÂ∞çÊÇ£ËÄÖÈÄ†ÊàêÈ´òÂ∫¶Ë°∞Âº±ÁöÑÂΩ±ÈüøÔºåÊà™ËÇ¢ÂíåÂõ†ÊÑüÊüìËÄåÂ∞éËá¥ÁöÑÊ≠ª‰∫°È¢®Èö™‰πüÊó•ÁõäÊôÆÈÅç„ÄÇÂõ†Ê≠§ÔºåÊñ∞ÁöÑÊñπÊ≥ïÂçîÂä©Ëá®Â∫äÈÜ´ÁîüÈÄ≤Ë°åÊÖ¢ÊÄßÂÇ∑Âè£ÁÖßË≠∑Ëá≥ÈóúÈáçË¶ÅÔºå‰ª•Á∂≠ÊåÅÈ´òÂìÅË≥™ÁöÑÁÖßË≠∑Ê®ôÊ∫ñ„ÄÇÊú¨ÊñáÊèêÂá∫‰∏ÄÂÄãÊîπËâØÁöÑ HarDNet ÂàÜÂâ≤Êû∂ÊßãÔºåÂ∞áÂ∞çÊØîÊ∂àÈô§ÂÖÉ‰ª∂Êï¥ÂêàÂà∞Á∂≤Ë∑ØÁöÑÂàùÂßãÂ±§Ôºå‰ª•Â¢ûÂº∑ÁâπÂæµÂ≠∏Áøí„ÄÇÊàëÂÄë‰πüÂà©Áî®Â§öËâ≤ÂΩ©Á©∫ÈñìÂºµÈáèÂêà‰ΩµÁ®ãÂ∫èÔºå‰∏¶Ë™øÊï¥Âç∑Á©çÂçÄÂ°äÁöÑË´ßÊ≥¢ÂΩ¢ÁãÄÔºå‰ª•Âà©ÊñºÈÄô‰∫õÈ°çÂ§ñÁâπÂæµ„ÄÇÊàëÂÄë‰ΩøÁî®Ê∑∫ËÜöËâ≤ÊÇ£ËÄÖÁöÑÂÇ∑Âè£ÂΩ±ÂÉèË®ìÁ∑¥ÊàëÂÄëÊèêÂá∫ÁöÑÊ®°ÂûãÔºå‰∏¶Âú®ÂÖ©ÂÄãÊ∏¨Ë©¶ÁµÑÔºà‰∏ÄÂÄãÁµÑÊúâÂü∫Êú¨‰∫ãÂØ¶Ôºå‰∏ÄÂÄãÁµÑÊ≤íÊúâÔºâ‰∏äÊ∏¨Ë©¶Ê®°ÂûãÔºåÈÄô‰∫õÁµÑÂÉÖÂåÖÂê´ËºÉÊ∑±ËÜöËâ≤ÁöÑÁóÖ‰æã„ÄÇÂæûËá®Â∫äÂÇ∑Âè£Â∞àÂÆ∂ÂèñÂæó‰∏ªËßÄË©ïÂàÜÔºå‰∏¶‰ΩøÁî®È°ûÂÖßÁõ∏Èóú‰øÇÊï∏‰æÜÁ¢∫ÂÆöË©ïÂàÜËÄÖÈñì‰ø°Ë≥¥Â∫¶„ÄÇÂ∞çÊñºÊúâÂü∫Êú¨‰∫ãÂØ¶ÁöÑÊ∑±ËÜöËâ≤Ê∏¨Ë©¶ÁµÑÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÈ™∞Â≠êÁõ∏‰ºº‰øÇÊï∏ (+0.1221) ÂíåËÅØÈõÜÊØî‰∫§ÈõÜ (+0.1274) ÁöÑÊîπÈÄ≤„ÄÇÂÆöÊÄßÂàÜÊûêÈ°ØÁ§∫Â∞àÂÆ∂Ë©ïÂàÜÂæàÈ´òÔºåËàáÂü∫Ê∫ñÊ®°ÂûãÁõ∏ÊØîÔºåÊèêÂá∫ÁöÑÊ®°ÂûãÈ°ØÁ§∫Âá∫ >3% ÁöÑÊîπÈÄ≤„ÄÇÊú¨ÊñáÊèêÂá∫Á¨¨‰∏ÄÂÄãÁ†îÁ©∂ÔºåÂ∞àÊ≥®Êñº‰ΩøÁî®ÂÉÖÂú®Ë°®ÁèæÂá∫ËºÉÊ∑∫ËÜöËâ≤ÁöÑÂÇ∑Âè£ÂΩ±ÂÉè‰∏äË®ìÁ∑¥ÁöÑÊ®°ÂûãÔºåÈÄ≤Ë°åÊ∑±ËÜöËâ≤ÊÖ¢ÊÄßÂÇ∑Âè£ÂàÜÂâ≤„ÄÇÁ≥ñÂ∞øÁóÖÂú®ÊÇ£ËÄÖËÜöËâ≤ËºÉÊ∑±ÁöÑÂúãÂÆ∂ÈùûÂ∏∏ÊôÆÈÅçÔºåÂº∑Ë™øÈúÄË¶ÅÊõ¥Â§öÈóúÊ≥®Ê≠§È°ûÁóÖ‰æã„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄ≤Ë°å‰∫ÜËøÑ‰ªäÁÇ∫Ê≠¢ÊúÄÂ§ßÁöÑÊÖ¢ÊÄßÂÇ∑Âè£ÂàÜÂâ≤ÂÆöÊÄßÁ†îÁ©∂„ÄÇ</paragraph>

##### **Comparative Analysis and Ensemble Enhancement of Leading CNN Architectures for Breast Cancer Classification**
2410.03333v1 by Gary Murphy, Raghubir Singh

This study introduces a novel and accurate approach to breast cancer
classification using histopathology images. It systematically compares leading
Convolutional Neural Network (CNN) models across varying image datasets,
identifies their optimal hyperparameters, and ranks them based on
classification efficacy. To maximize classification accuracy for each model we
explore, the effects of data augmentation, alternative fully-connected layers,
model training hyperparameter settings, and, the advantages of retraining
models versus using pre-trained weights. Our methodology includes several
original concepts, including serializing generated datasets to ensure
consistent data conditions across training runs and significantly reducing
training duration. Combined with automated curation of results, this enabled
the exploration of over 2,000 training permutations -- such a comprehensive
comparison is as yet unprecedented. Our findings establish the settings
required to achieve exceptional classification accuracy for standalone CNN
models and rank them by model efficacy. Based on these results, we propose
ensemble architectures that stack three high-performing standalone CNN models
together with diverse classifiers, resulting in improved classification
accuracy. The ability to systematically run so many model permutations to get
the best outcomes gives rise to very high quality results, including 99.75% for
BreakHis x40 and BreakHis x200 and 95.18% for the Bach datasets when split into
train, validation and test datasets. The Bach Online blind challenge, yielded
89% using this approach. Whilst this study is based on breast cancer
histopathology image datasets, the methodology is equally applicable to other
medical image datasets.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©é‰∏îÊ∫ñÁ¢∫ÁöÑÊñπÊ≥ïÔºå‰ΩøÁî®ÁµÑÁπîÁóÖÁêÜÂ≠∏ÂΩ±ÂÉè‰æÜÂ∞ç‰π≥ÁôåÈÄ≤Ë°åÂàÜÈ°û„ÄÇÂÆÉÁ≥ªÁµ±ÊÄßÂú∞ÊØîËºÉ‰∫ÜÂú®‰∏çÂêåÂΩ±ÂÉèË≥áÊñôÈõÜ‰∏≠ÁöÑÈ†òÂÖàÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) Ê®°ÂûãÔºåÊâæÂá∫ÂÆÉÂÄëÊúÄ‰Ω≥ÁöÑË∂ÖÂèÉÊï∏Ôºå‰∏¶Ê†πÊìöÂàÜÈ°ûÊïàËÉΩÂ∞çÂÆÉÂÄëÈÄ≤Ë°åÊéíÂêç„ÄÇÁÇ∫‰∫ÜÊúÄÂ§ßÂåñÊàëÂÄëÊé¢Á¥¢ÁöÑÊØèÂÄãÊ®°ÂûãÁöÑÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜË≥áÊñôÊì¥ÂÖÖ„ÄÅÊõø‰ª£ÂÖ®ÈÄ£Êé•Â±§„ÄÅÊ®°ÂûãË®ìÁ∑¥Ë∂ÖÂèÉÊï∏Ë®≠ÂÆöÔºå‰ª•ÂèäÈáçÊñ∞Ë®ìÁ∑¥Ê®°ÂûãËàá‰ΩøÁî®È†êË®ìÁ∑¥Ê¨äÈáçÁöÑÂÑ™Èªû„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂåÖÂê´‰∫ÜÂπæÂÄãÂéüÂßãÊ¶ÇÂøµÔºåÂåÖÊã¨Â∫èÂàóÂåñÁî¢ÁîüÁöÑË≥áÊñôÈõÜÔºå‰ª•Á¢∫‰øùÂú®Ë®ìÁ∑¥ÈÅéÁ®ã‰∏≠Ë≥áÊñôÊ¢ù‰ª∂‰∏ÄËá¥Ôºå‰∏¶Â§ßÂπÖÁ∏ÆÁü≠Ë®ìÁ∑¥ÊôÇÈñì„ÄÇÁµêÂêàËá™ÂãïÂåñÁµêÊûúÊï¥ÁêÜÔºåÈÄô‰ΩøÂæóÊàëÂÄëËÉΩÂ§†Êé¢Á¥¢Ë∂ÖÈÅé 2,000 ÂÄãË®ìÁ∑¥ÊéíÂàóÁµÑÂêà‚Äî‚ÄîÂ¶ÇÊ≠§ÂÖ®Èù¢ÁöÑÊØîËºÉÂú®ÁõÆÂâçÁÇ∫Ê≠¢ÊòØÂâçÊâÄÊú™ÊúâÁöÑ„ÄÇÊàëÂÄëÁöÑÁôºÁèæÂª∫Á´ã‰∫ÜÈÅîÊàêÂÇëÂá∫ÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶ÊâÄÈúÄÁöÑË®≠ÂÆöÔºå‰∏¶Ê†πÊìöÊ®°ÂûãÊïàËÉΩÂ∞çÁç®Á´ãÁöÑ CNN Ê®°ÂûãÈÄ≤Ë°åÊéíÂêç„ÄÇÊ†πÊìöÈÄô‰∫õÁµêÊûúÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂ∞á‰∏âÂÄãÈ´òÊÄßËÉΩÁç®Á´ã CNN Ê®°ÂûãËàá‰∏çÂêåÁöÑÂàÜÈ°ûÂô®Â†ÜÁñäÂú®‰∏ÄËµ∑ÁöÑÊï¥È´îÊû∂ÊßãÔºåÈÄ≤ËÄåÊèêÂçá‰∫ÜÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶„ÄÇÁ≥ªÁµ±ÊÄßÂú∞Âü∑Ë°åÈÄôÈ∫ºÂ§öÊ®°ÂûãÊéíÂàóÁµÑÂêà‰ª•Áç≤ÂæóÊúÄ‰Ω≥ÁµêÊûúÁöÑËÉΩÂäõÔºåÁî¢Áîü‰∫ÜÈùûÂ∏∏È´òÂìÅË≥™ÁöÑÁµêÊûúÔºåÂåÖÊã¨Â∞á BreakHis x40 Âíå BreakHis x200 ÂàÜÂâ≤ÊàêË®ìÁ∑¥„ÄÅÈ©óË≠âÂíåÊ∏¨Ë©¶Ë≥áÊñôÈõÜÊôÇÔºåÊ∫ñÁ¢∫Â∫¶ÈÅîÂà∞ 99.75%ÔºåËÄå Bach Ë≥áÊñôÈõÜÁöÑÊ∫ñÁ¢∫Â∫¶ÈÅîÂà∞ 95.18%„ÄÇ‰ΩøÁî®ÈÄôÁ®ÆÊñπÊ≥ïÔºåBach Online Áõ≤Ê∏¨ÁöÑÊ∫ñÁ¢∫Â∫¶ÈÅîÂà∞ 89%„ÄÇÈõñÁÑ∂Êú¨Á†îÁ©∂ÊòØÂü∫Êñº‰π≥ÁôåÁµÑÁπîÁóÖÁêÜÂ≠∏ÂΩ±ÂÉèË≥áÊñôÈõÜÔºå‰ΩÜÊ≠§ÊñπÊ≥ïÂêåÊ®£ÈÅ©Áî®ÊñºÂÖ∂‰ªñÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñôÈõÜ„ÄÇ

##### **Manikin-Recorded Cardiopulmonary Sounds Dataset Using Digital Stethoscope**
2410.03280v1 by Yasaman Torabi, Shahram Shirani, James P. Reilly

Heart and lung sounds are crucial for healthcare monitoring. Recent
improvements in stethoscope technology have made it possible to capture patient
sounds with enhanced precision. In this dataset, we used a digital stethoscope
to capture both heart and lung sounds, including individual and mixed
recordings. To our knowledge, this is the first dataset to offer both separate
and mixed cardiorespiratory sounds. The recordings were collected from a
clinical manikin, a patient simulator designed to replicate human physiological
conditions, generating clean heart and lung sounds at different body locations.
This dataset includes both normal sounds and various abnormalities (i.e.,
murmur, atrial fibrillation, tachycardia, atrioventricular block, third and
fourth heart sound, wheezing, crackles, rhonchi, pleural rub, and gurgling
sounds). The dataset includes audio recordings of chest examinations performed
at different anatomical locations, as determined by specialist nurses. Each
recording has been enhanced using frequency filters to highlight specific sound
types. This dataset is useful for applications in artificial intelligence, such
as automated cardiopulmonary disease detection, sound classification,
unsupervised separation techniques, and deep learning algorithms related to
audio signal processing.

ÊëòË¶ÅÔºöÂøÉËáüËàáËÇ∫ÈÉ®ËÅ≤Èü≥Â∞çÊñºÈÜ´ÁôÇ‰øùÂÅ•Áõ£Ê∏¨Ëá≥ÈóúÈáçË¶Å„ÄÇÊúÄËøëÂú®ËÅΩË®∫Âô®ÊäÄË°ìÊñπÈù¢ÁöÑÈÄ≤Ê≠•Ôºå‰ΩøÂæó‰ª•Êõ¥È´òÁöÑÁ≤æÊ∫ñÂ∫¶Êì∑ÂèñÊÇ£ËÄÖËÅ≤Èü≥ÊàêÁÇ∫ÂèØËÉΩ„ÄÇÂú®ÈÄôÂÄãË≥áÊñôÈõÜ‰∏≠ÔºåÊàëÂÄë‰ΩøÁî®Êï∏‰ΩçËÅΩË®∫Âô®Êì∑ÂèñÂøÉËáüËàáËÇ∫ÈÉ®ËÅ≤Èü≥ÔºåÂåÖÊã¨ÂÄãÂà•ÂíåÊ∑∑ÂêàÁöÑÈåÑÈü≥„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÊèê‰æõÂÄãÂà•ÂíåÊ∑∑ÂêàÁöÑÂøÉËÇ∫ËÅ≤Èü≥ÁöÑË≥áÊñôÈõÜ„ÄÇÈÄô‰∫õÈåÑÈü≥ÊòØÂæûËá®Â∫äÂÅá‰∫∫Êî∂ÈõÜÁöÑÔºåËá®Â∫äÂÅá‰∫∫ÊòØ‰∏ÄÁ®ÆÊ®°Êì¨‰∫∫È´îÁîüÁêÜÁãÄÊ≥ÅÁöÑÊÇ£ËÄÖÊ®°Êì¨Âô®ÔºåÂèØÂú®‰∏çÂêåË∫´È´îÈÉ®‰ΩçÁî¢Áîü‰πæÊ∑®ÁöÑÂøÉËáüÂíåËÇ∫ÈÉ®ËÅ≤Èü≥„ÄÇÈÄôÂÄãË≥áÊñôÈõÜÂåÖÂê´Ê≠£Â∏∏ËÅ≤Èü≥ÂíåÂêÑÁ®ÆÁï∞Â∏∏Ôºà‰æãÂ¶ÇÔºåÈõúÈü≥„ÄÅÂøÉÊàøÈ°´Âãï„ÄÅÂøÉÂãïÈÅéÈÄü„ÄÅÊàøÂÆ§ÂÇ≥Â∞éÈòªÊªØ„ÄÅÁ¨¨‰∏âÂíåÁ¨¨ÂõõÂøÉÈü≥„ÄÅÂñòÈ≥¥„ÄÅÁàÜË£ÇÈü≥„ÄÅÂõâÈü≥„ÄÅËÉ∏ËÜúÊë©Êì¶Èü≥ÂíåÂíïÂöïËÅ≤Ôºâ„ÄÇÈÄôÂÄãË≥áÊñôÈõÜÂåÖÂê´Âú®‰∏çÂêåËß£Ââñ‰ΩçÁΩÆÈÄ≤Ë°åËÉ∏ÈÉ®Ê™¢Êü•ÁöÑÈü≥Ë®äÈåÑÈü≥ÔºåÁî±Â∞àÁßëË≠∑ÁêÜÂ∏´Á¢∫ÂÆö„ÄÇÊØèÂÄãÈåÑÈü≥ÈÉΩ‰ΩøÁî®È†ªÁéáÊøæÊ≥¢Âô®ÈÄ≤Ë°åÂä†Âº∑Ôºå‰ª•Á™ÅÈ°ØÁâπÂÆöÁöÑËÅ≤Èü≥È°ûÂûã„ÄÇÈÄôÂÄãË≥áÊñôÈõÜÂ∞çÊñº‰∫∫Â∑•Êô∫ÊÖßÁöÑÊáâÁî®ÂæàÊúâÁî®Ôºå‰æãÂ¶ÇËá™ÂãïÂøÉËÇ∫ÁñæÁóÖÂÅµÊ∏¨„ÄÅËÅ≤Èü≥ÂàÜÈ°û„ÄÅÁÑ°Áõ£Áù£ÂàÜÈõ¢ÊäÄË°ìÂíåËàáÈü≥Ë®äË®äËôüËôïÁêÜÁõ∏ÈóúÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊºîÁÆóÊ≥ï„ÄÇ

##### **Looking into Concept Explanation Methods for Diabetic Retinopathy Classification**
2410.03188v1 by Andrea M. Stor√•s, Josefine V. Sundgaard

Diabetic retinopathy is a common complication of diabetes, and monitoring the
progression of retinal abnormalities using fundus imaging is crucial. Because
the images must be interpreted by a medical expert, it is infeasible to screen
all individuals with diabetes for diabetic retinopathy. Deep learning has shown
impressive results for automatic analysis and grading of fundus images. One
drawback is, however, the lack of interpretability, which hampers the
implementation of such systems in the clinic. Explainable artificial
intelligence methods can be applied to explain the deep neural networks.
Explanations based on concepts have shown to be intuitive for humans to
understand, but have not yet been explored in detail for diabetic retinopathy
grading. This work investigates and compares two concept-based explanation
techniques for explaining deep neural networks developed for automatic
diagnosis of diabetic retinopathy: Quantitative Testing with Concept Activation
Vectors and Concept Bottleneck Models. We found that both methods have
strengths and weaknesses, and choice of method should take the available data
and the end user's preferences into account.

ÊëòË¶ÅÔºöÁ≥ñÂ∞øÁóÖË¶ñÁ∂≤ËÜúÁóÖËÆäÊòØÁ≥ñÂ∞øÁóÖÁöÑÂ∏∏Ë¶ã‰ΩµÁôºÁóáÔºå‰ΩøÁî®ÁúºÂ∫ïÊàêÂÉèÁõ£ÊéßË¶ñÁ∂≤ËÜúÁï∞Â∏∏ÁöÑÈÄ≤Â±ïËá≥ÈóúÈáçË¶Å„ÄÇÁî±ÊñºÂΩ±ÂÉèÂøÖÈ†àÁî±ÈÜ´ÁôÇÂ∞àÂÆ∂Ëß£ÈáãÔºåÂõ†Ê≠§‰∏çÂèØËÉΩÁØ©ÈÅ∏Âá∫ÊâÄÊúâÊÇ£ÊúâÁ≥ñÂ∞øÁóÖË¶ñÁ∂≤ËÜúÁóÖËÆäÁöÑÁ≥ñÂ∞øÁóÖÊÇ£ËÄÖ„ÄÇÊ∑±Â∫¶Â≠∏ÁøíÂ∑≤Âú®ÁúºÂ∫ïÂΩ±ÂÉèÁöÑËá™ÂãïÂàÜÊûêÂíåÂàÜÁ¥öÊñπÈù¢Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊàêÊûú„ÄÇÁÑ∂ËÄåÔºåÂÖ∂‰∏≠‰∏ÄÂÄãÁº∫ÈªûÊòØÁº∫‰πèÂèØËß£ÈáãÊÄßÔºåÈÄôÈòªÁ§ô‰∫ÜÊ≠§È°ûÁ≥ªÁµ±Âú®Ëá®Â∫ä‰∏äÁöÑÂØ¶ÊñΩ„ÄÇÂèØËß£ÈáãÁöÑ‰∫∫Â∑•Êô∫ÊÖßÊñπÊ≥ïÂèØÊáâÁî®ÊñºËß£ÈáãÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑Ø„ÄÇÂü∫ÊñºÊ¶ÇÂøµÁöÑËß£ÈáãÂ∑≤Ë¢´Ë≠âÊòéÂ∞ç‰∫∫È°û‰æÜË™™Áõ¥ËßÄÊòìÊáÇÔºå‰ΩÜÂ∞öÊú™Ë©≥Á¥∞Êé¢Ë®éÁ≥ñÂ∞øÁóÖË¶ñÁ∂≤ËÜúÁóÖËÆäÂàÜÁ¥ö„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊé¢Ë®é‰∏¶ÊØîËºÉ‰∫ÜÂÖ©Á®ÆÂü∫ÊñºÊ¶ÇÂøµÁöÑËß£ÈáãÊäÄË°ìÔºåÁî®ÊñºËß£ÈáãÁÇ∫Á≥ñÂ∞øÁóÖË¶ñÁ∂≤ËÜúÁóÖËÆäËá™ÂãïË®∫Êñ∑ËÄåÈñãÁôºÁöÑÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÔºö‰ΩøÁî®Ê¶ÇÂøµÊøÄÊ¥ªÂêëÈáèÈÄ≤Ë°åÁöÑÂÆöÈáèÊ∏¨Ë©¶ÂíåÊ¶ÇÂøµÁì∂È†∏Ê®°Âûã„ÄÇÊàëÂÄëÁôºÁèæÈÄôÂÖ©Á®ÆÊñπÊ≥ïÂêÑÊúâÂÑ™Áº∫ÈªûÔºåÊñπÊ≥ïÁöÑÈÅ∏ÊìáÊáâËÄÉÊÖÆÂèØÁî®ÁöÑË≥áÊñôÂíåÊúÄÁµÇ‰ΩøÁî®ËÄÖÁöÑÂÅèÂ•Ω„ÄÇ

##### **Remaining Useful Life Prediction: A Study on Multidimensional Industrial Signal Processing and Efficient Transfer Learning Based on Large Language Models**
2410.03134v1 by Yan Chen, Cheng Liu

Remaining useful life (RUL) prediction is crucial for maintaining modern
industrial systems, where equipment reliability and operational safety are
paramount. Traditional methods, based on small-scale deep learning or
physical/statistical models, often struggle with complex, multidimensional
sensor data and varying operating conditions, limiting their generalization
capabilities. To address these challenges, this paper introduces an innovative
regression framework utilizing large language models (LLMs) for RUL prediction.
By leveraging the modeling power of LLMs pre-trained on corpus data, the
proposed model can effectively capture complex temporal dependencies and
improve prediction accuracy. Extensive experiments on the Turbofan engine's RUL
prediction task show that the proposed model surpasses state-of-the-art (SOTA)
methods on the challenging FD002 and FD004 subsets and achieves near-SOTA
results on the other subsets. Notably, different from previous research, our
framework uses the same sliding window length and all sensor signals for all
subsets, demonstrating strong consistency and generalization. Moreover,
transfer learning experiments reveal that with minimal target domain data for
fine-tuning, the model outperforms SOTA methods trained on full target domain
data. This research highlights the significant potential of LLMs in industrial
signal processing and RUL prediction, offering a forward-looking solution for
health management in future intelligent industrial systems.

ÊëòË¶ÅÔºöÂâ©È§ò‰ΩøÁî®Â£ΩÂëΩ (RUL) È†êÊ∏¨Â∞çÊñºÁ∂≠Ë≠∑Áèæ‰ª£Â∑•Ê•≠Á≥ªÁµ±Ëá≥ÈóúÈáçË¶ÅÔºåÂú®ÈÄô‰∫õÁ≥ªÁµ±‰∏≠ÔºåË®≠ÂÇôÂèØÈù†ÊÄßÂíåÊìç‰ΩúÂÆâÂÖ®Ëá≥‰∏ä„ÄÇÂÇ≥Áµ±ÊñπÊ≥ïÂü∫ÊñºÂ∞èË¶èÊ®°Ê∑±Â∫¶Â≠∏ÁøíÊàñÁâ©ÁêÜ/Áµ±Ë®àÊ®°ÂûãÔºåÈÄöÂ∏∏Èõ£‰ª•ËôïÁêÜË§áÈõú„ÄÅÂ§öÁ∂≠Â∫¶ÁöÑÊÑüÊ∏¨Âô®Ë≥áÊñôÂíå‰∏çÂêåÁöÑÊìç‰ΩúÊ¢ù‰ª∂ÔºåÈôêÂà∂‰∫ÜÂÆÉÂÄëÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÂâµÊñ∞ÁöÑÂõûÊ≠∏Êû∂ÊßãÔºåÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜÈÄ≤Ë°å RUL È†êÊ∏¨„ÄÇÈÄöÈÅéÂà©Áî®Âú®Ë™ûÊñôË≥áÊñô‰∏äÈ†êÂÖàË®ìÁ∑¥ÁöÑ LLM ÁöÑÂª∫Ê®°ËÉΩÂäõÔºåÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂèØ‰ª•ÊúâÊïàÂú∞ÊçïÊçâË§áÈõúÁöÑÊôÇÈñì‰æùË≥¥ÊÄß‰∏¶ÊèêÈ´òÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇÂú®Ê∏¶Ëº™È¢®ÊâáÂºïÊìéÁöÑ RUL È†êÊ∏¨‰ªªÂãô‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂú®ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ FD002 Âíå FD004 Â≠êÈõÜ‰∏≠Ë∂ÖË∂ä‰∫ÜÊúÄÂÖàÈÄ≤ (SOTA) ÁöÑÊñπÊ≥ïÔºå‰∏¶Âú®ÂÖ∂‰ªñÂ≠êÈõÜ‰∏≠ÈÅîÂà∞‰∫ÜÊé•Ëøë SOTA ÁöÑÁµêÊûú„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåËàáÂÖàÂâçÁöÑÁ†îÁ©∂‰∏çÂêåÔºåÊàëÂÄëÁöÑÊ°ÜÊû∂Â∞çÊâÄÊúâÂ≠êÈõÜÈÉΩ‰ΩøÁî®Áõ∏ÂêåÁöÑÊªëÂãïÁ™óÂè£Èï∑Â∫¶ÂíåÊâÄÊúâÊÑüÊ∏¨Âô®Ë®äËôüÔºåÂ±ïÁ§∫‰∫ÜÂº∑Â§ßÁöÑÁõ∏ÂÆπÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåËΩâÁßªÂ≠∏ÁøíÂØ¶È©óË°®ÊòéÔºåÈÄèÈÅéÂ∞çÂæÆË™øÈÄ≤Ë°åÊúÄÂ∞ëÁöÑÁõÆÊ®ôÁ∂≤ÂüüË≥áÊñôÔºåË©≤Ê®°ÂûãÁöÑË°®ÁèæÂÑ™ÊñºÂú®ÂÆåÊï¥ÁõÆÊ®ôÁ∂≤ÂüüË≥áÊñô‰∏äË®ìÁ∑¥ÁöÑ SOTA ÊñπÊ≥ï„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Á™ÅÈ°Ø‰∫Ü LLM Âú®Â∑•Ê•≠Ë®äËôüËôïÁêÜÂíå RUL È†êÊ∏¨‰∏≠ÁöÑÂ∑®Â§ßÊΩõÂäõÔºåÁÇ∫Êú™‰æÜÊô∫ÊÖßÂ∑•Ê•≠Á≥ªÁµ±‰∏≠ÁöÑÂÅ•Â∫∑ÁÆ°ÁêÜÊèê‰æõ‰∫ÜÂâçÁûªÊÄßÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **Image First or Text First? Optimising the Sequencing of Modalities in Large Language Model Prompting and Reasoning Tasks**
2410.03062v1 by Grant Wardle, Teo Susnjak

This paper examines how the sequencing of images and text within multi-modal
prompts influences the reasoning performance of large language models (LLMs).
We performed empirical evaluations using three commercial LLMs. Our results
demonstrate that the order in which modalities are presented can significantly
affect performance, particularly in tasks of varying complexity. For simpler
tasks involving a single image, modality sequencing had a clear impact on
accuracy. However, in more complex tasks involving multiple images and
intricate reasoning steps, the effect of sequencing diminished, likely due to
the increased cognitive demands of the task. Our findings also highlight the
importance of question/prompt structure. In nested and multi-step reasoning
tasks, modality sequencing played a key role in shaping model performance.
While LLMs excelled in the initial stages of reasoning, they struggled to
re-incorporate earlier information, underscoring the challenges of multi-hop
reasoning within transformer architectures. This suggests that aligning the
sequence of modalities with the logical flow of reasoning steps is more
critical than modality order alone. These insights offer valuable implications
for improving multi-modal prompt design, with broader applications across
fields such as education, medical imaging, and cross-modal learning.

ÊëòË¶ÅÔºöÊú¨ÊñáÊé¢Ë®éÂú®Â§öÊ®°ÊÖãÊèêÁ§∫‰∏≠ÂΩ±ÂÉèÂíåÊñáÂ≠óÁöÑÈ†ÜÂ∫èÂ¶Ç‰ΩïÂΩ±ÈüøÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊé®ÁêÜË°®Áèæ„ÄÇÊàëÂÄë‰ΩøÁî®‰∏âÂÄãÂïÜÁî® LLM ÈÄ≤Ë°åÂØ¶Ë≠âË©ï‰º∞„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåÊ®°ÊÖãÂëàÁèæÁöÑÈ†ÜÂ∫èÊúÉÈ°ØËëóÂΩ±ÈüøË°®ÁèæÔºåÁâπÂà•ÊòØÂú®‰∏çÂêåË§áÈõúÂ∫¶‰ªªÂãô‰∏≠„ÄÇÂ∞çÊñºÊ∂âÂèäÂñÆ‰∏ÄÂΩ±ÂÉèÁöÑËºÉÁ∞°ÂñÆ‰ªªÂãôÔºåÊ®°ÊÖãÈ†ÜÂ∫èÂ∞çÊ∫ñÁ¢∫Â∫¶ÊúâÊòéÈ°ØÂΩ±Èüø„ÄÇÁÑ∂ËÄåÔºåÂú®Ê∂âÂèäÂ§öÂÄãÂΩ±ÂÉèÂíåË§áÈõúÊé®ÁêÜÊ≠•È©üÁöÑËºÉË§áÈõú‰ªªÂãô‰∏≠ÔºåÈ†ÜÂ∫èÁöÑÂΩ±ÈüøÊ∏õÂº±ÔºåÈÄôÂèØËÉΩÊòØÁî±Êñº‰ªªÂãôÁöÑË™çÁü•ÈúÄÊ±ÇÂ¢ûÂä†„ÄÇÊàëÂÄëÁöÑÁôºÁèæ‰πüÁ™ÅÈ°Ø‰∫ÜÂïèÈ°å/ÊèêÁ§∫ÁµêÊßãÁöÑÈáçË¶ÅÊÄß„ÄÇÂú®ÂµåÂ•óÂíåÂ§öÊ≠•È©üÊé®ÁêÜ‰ªªÂãô‰∏≠ÔºåÊ®°ÊÖãÈ†ÜÂ∫èÂú®Â°ëÈÄ†Ê®°ÂûãË°®Áèæ‰∏≠ÊâÆÊºîÈóúÈçµËßíËâ≤„ÄÇÈõñÁÑ∂ LLM Âú®Êé®ÁêÜÁöÑÂàùÂßãÈöéÊÆµË°®ÁèæÂá∫Ëâ≤Ôºå‰ΩÜÂÆÉÂÄëÈõ£‰ª•ÈáçÊñ∞Êï¥ÂêàÊó©ÊúüÁöÑË≥áË®äÔºåÈÄôÂá∏È°Ø‰∫ÜTransformerÊû∂Êßã‰∏≠Â§öË∑≥Êé®ÁêÜÁöÑÊåëÊà∞„ÄÇÈÄôË°®ÊòéÂ∞áÊ®°ÊÖãÈ†ÜÂ∫èËàáÊé®ÁêÜÊ≠•È©üÁöÑÈÇèËºØÊµÅÁ®ãÂ∞çÈΩäÊØîÂñÆÁç®ÁöÑÊ®°ÊÖãÈ†ÜÂ∫èÊõ¥ÁÇ∫ÈáçË¶Å„ÄÇÈÄô‰∫õË¶ãËß£ÁÇ∫ÊîπÂñÑÂ§öÊ®°ÊÖãÊèêÁ§∫Ë®≠Ë®àÊèê‰æõ‰∫ÜÂØ∂Ë≤¥ÁöÑÂïüÁ§∫Ôºå‰∏¶Âú®ÊïôËÇ≤„ÄÅÈÜ´Â≠∏ÂΩ±ÂÉèÂíåË∑®Ê®°ÊÖãÂ≠∏ÁøíÁ≠âÈ†òÂüüÊúâÊõ¥Âª£Ê≥õÁöÑÊáâÁî®„ÄÇ

##### **Is Your Paper Being Reviewed by an LLM? Investigating AI Text Detectability in Peer Review**
2410.03019v1 by Sungduk Yu, Man Luo, Avinash Madasu, Vasudev Lal, Phillip Howard

Peer review is a critical process for ensuring the integrity of published
scientific research. Confidence in this process is predicated on the assumption
that experts in the relevant domain give careful consideration to the merits of
manuscripts which are submitted for publication. With the recent rapid
advancements in the linguistic capabilities of large language models (LLMs), a
new potential risk to the peer review process is that negligent reviewers will
rely on LLMs to perform the often time consuming process of reviewing a paper.
In this study, we investigate the ability of existing AI text detection
algorithms to distinguish between peer reviews written by humans and different
state-of-the-art LLMs. Our analysis shows that existing approaches fail to
identify many GPT-4o written reviews without also producing a high number of
false positive classifications. To address this deficiency, we propose a new
detection approach which surpasses existing methods in the identification of
GPT-4o written peer reviews at low levels of false positive classifications.
Our work reveals the difficulty of accurately identifying AI-generated text at
the individual review level, highlighting the urgent need for new tools and
methods to detect this type of unethical application of generative AI.

ÊëòË¶ÅÔºöÂêåÂÑïÂØ©Êü•ÊòØÁ¢∫‰øùÂ∑≤ÁôºË°®ÁöÑÁßëÂ≠∏Á†îÁ©∂ÁöÑÂÆåÊï¥ÊÄßÁöÑÈóúÈçµÈÅéÁ®ã„ÄÇÂ∞çÊ≠§ÈÅéÁ®ãÁöÑ‰ø°ÂøÉÂª∫Á´ãÂú®‰∏ÄÂÄãÂÅáË®≠‰πã‰∏äÔºåÂç≥Áõ∏ÈóúÈ†òÂüüÁöÑÂ∞àÂÆ∂ÊúÉ‰ªîÁ¥∞ËÄÉÊÖÆÊèê‰∫§Âá∫ÁâàÁöÑÁ®ø‰ª∂ÁöÑÂÑ™Èªû„ÄÇÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑË™ûË®ÄËÉΩÂäõÊúÄËøëÁöÑÂø´ÈÄüÈÄ≤Â±ïÔºåÂ∞çÂêåÂÑïÂØ©Êü•ÈÅéÁ®ãÁöÑ‰∏ÄÂÄãÊñ∞ÁöÑÊΩõÂú®È¢®Èö™ÊòØÔºåÁñèÂøΩÁöÑÂØ©Êü•Âì°ÊúÉ‰æùË≥¥ LLM ‰æÜÂü∑Ë°åÂØ©Êü•Ë´ñÊñáÈÄôÂÄãÂ∏∏Â∏∏ÂæàËÄóÊôÇÁöÑÈÅéÁ®ã„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëË™øÊü•‰∫ÜÁèæÊúâ AI ÊñáÂ≠óÂÅµÊ∏¨ÊºîÁÆóÊ≥ïÂçÄÂàÜÁî±‰∫∫È°ûÊí∞ÂØ´ÁöÑÂêåÂÑïÂØ©Êü•Âíå‰∏çÂêåÁöÑÊúÄÂÖàÈÄ≤ LLM ÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÁèæÊúâÁöÑÊñπÊ≥ïÁÑ°Ê≥ïË≠òÂà•Ë®±Â§ö GPT-4o ÂØ´ÁöÑË©ïË´ñÔºåÂêåÊôÇ‰πü‰∏çÊúÉÁî¢ÁîüÂ§ßÈáèÁöÑÂÅáÈôΩÊÄßÂàÜÈ°û„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÁº∫Èô∑ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÂÅµÊ∏¨ÊñπÊ≥ïÔºåÂÆÉÂú®‰ΩéÊ∞¥Âπ≥ÁöÑÂÅáÈôΩÊÄßÂàÜÈ°û‰∏≠Ë∂ÖË∂ä‰∫ÜÁèæÊúâÁöÑÊñπÊ≥ïÔºåË≠òÂà• GPT-4o ÂØ´ÁöÑÂêåÂÑïÂØ©Êü•„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Êè≠Á§∫‰∫ÜÂú®ÂÄãÂà•ÂØ©Êü•Â±§Á¥öÊ∫ñÁ¢∫Ë≠òÂà• AI ÁîüÊàêÁöÑÊñáÂ≠óÁöÑÈõ£Â∫¶ÔºåÂº∑Ë™ø‰∫ÜËø´ÂàáÈúÄË¶ÅÊñ∞ÁöÑÂ∑•ÂÖ∑ÂíåÊñπÊ≥ï‰æÜÂÅµÊ∏¨ÈÄôÁ®Æ‰∏çÈÅìÂæ∑ÁöÑÁîüÊàêÂºè AI ÊáâÁî®„ÄÇ

##### **DailyDilemmas: Revealing Value Preferences of LLMs with Quandaries of Daily Life**
2410.02683v1 by Yu Ying Chiu, Liwei Jiang, Yejin Choi

As we increasingly seek guidance from LLMs for decision-making in daily life,
many of these decisions are not clear-cut and depend significantly on the
personal values and ethical standards of the users. We present DailyDilemmas, a
dataset of 1,360 moral dilemmas encountered in everyday life. Each dilemma
includes two possible actions and with each action, the affected parties and
human values invoked. Based on these dilemmas, we consolidated a set of human
values across everyday topics e.g., interpersonal relationships, workplace, and
environmental issues. We evaluated LLMs on these dilemmas to determine what
action they will take and the values represented by these actions. Then, we
analyzed these values through the lens of five popular theories inspired by
sociology, psychology and philosophy. These theories are: World Value Survey,
Moral Foundation Theory, Maslow's Hierarchy of Needs, Aristotle's Virtues, and
Plutchik Wheel of Emotion. We find that LLMs are most aligned with the
self-expression over survival values in terms of World Value Survey, care over
loyalty in Moral Foundation Theory. Interestingly, we find large preferences
differences in models for some core values such as truthfulness e.g.,
Mixtral-8x7B model tends to neglect it by 9.7% while GPT-4-turbo model tends to
select it by 9.4%. We also study the recent guidance released by OpenAI
(ModelSpec), and Anthropic (Constitutional AI) to understand how their released
principles reflect their actual value prioritization when facing nuanced moral
reasoning in daily-life settings. We find that end users cannot effectively
steer such prioritization using system prompts.

ÊëòË¶ÅÔºö<paragraph>Èö®ËëóÊàëÂÄëÂú®Êó•Â∏∏ÁîüÊ¥ª‰∏≠Ë∂ä‰æÜË∂ä‰æùË≥¥ LLM ‰æÜÈÄ≤Ë°åÊ±∫Á≠ñÔºå
ÂÖ∂‰∏≠Ë®±Â§öÊ±∫Á≠ñ‰∏¶ÈùûÊòéÁ¢∫ÔºåËÄå‰∏îÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂèñÊ±∫Êñº
‰ΩøÁî®ËÄÖÁöÑÂÄã‰∫∫ÂÉπÂÄºËßÄÂíåÈÅìÂæ∑Ê®ôÊ∫ñ„ÄÇÊàëÂÄëÊèêÂá∫‰∫ÜÊó•Â∏∏Âõ∞Â¢ÉÔºå‰∏ÄÂÄã
Âú®Êó•Â∏∏ÁîüÊ¥ª‰∏≠ÈÅáÂà∞ÁöÑ 1,360 ÂÄãÈÅìÂæ∑Âõ∞Â¢ÉÁöÑÊï∏ÊìöÈõÜ„ÄÇÊØèÂÄãÂõ∞Â¢É
ÂåÖÂê´ÂÖ©ÂÄãÂèØËÉΩÁöÑË°åÂãïÔºå‰∏¶ÈáùÂ∞çÊØèÂÄãË°åÂãïÔºåÂèóÂà∞ÂΩ±ÈüøÁöÑÂêÑÊñπÂíå
ÂºïÁôºÁöÑ‰∫∫È°ûÂÉπÂÄºËßÄ„ÄÇÊ†πÊìöÈÄô‰∫õÂõ∞Â¢ÉÔºåÊàëÂÄëÂΩôÊï¥‰∫Ü‰∏ÄÁµÑ‰∫∫È°û
ÂÉπÂÄºËßÄÔºåÊ∂µËìãÊó•Â∏∏‰∏ªÈ°åÔºå‰æãÂ¶Ç‰∫∫ÈöõÈóú‰øÇ„ÄÅËÅ∑Â†¥Âíå
Áí∞Â¢ÉÂïèÈ°å„ÄÇÊàëÂÄëÈáùÂ∞çÈÄô‰∫õÂõ∞Â¢ÉË©ï‰º∞ LLMÔºå‰ª•Á¢∫ÂÆöÂÆÉÂÄëÂ∞áÊé°Âèñ‰ªÄÈ∫º
Ë°åÂãï‰ª•ÂèäÈÄô‰∫õË°åÂãïÊâÄ‰ª£Ë°®ÁöÑÂÉπÂÄºËßÄ„ÄÇÊé•ËëóÔºåÊàëÂÄë
ÈÄèÈÅéÁ§æÊúÉÂ≠∏„ÄÅÂøÉÁêÜÂ≠∏ÂíåÂì≤Â≠∏ÂïüÁôºÁöÑ‰∫îÁ®ÆÊµÅË°åÁêÜË´ñ‰æÜÂàÜÊûêÈÄô‰∫õÂÉπÂÄºËßÄ„ÄÇÈÄô‰∫õÁêÜË´ñÁÇ∫Ôºö‰∏ñÁïåÂÉπÂÄºËßÄË™øÊü•„ÄÅ
ÈÅìÂæ∑Âü∫Á§éÁêÜË´ñ„ÄÅÈ¶¨ÊñØÊ¥õÈúÄÊ±ÇÂ±§Ê¨°ÁêÜË´ñ„ÄÅ‰∫ûÈáåÊñØÂ§öÂæ∑ÁæéÂæ∑Ôºå‰ª•Âèä
ÊôÆÊãâÂ•ëÂÖãÊÉÖÁ∑í‰πãËº™„ÄÇÊàëÂÄëÁôºÁèæ LLM Âú®‰∏ñÁïåÂÉπÂÄºËßÄË™øÊü•‰∏≠Ëàá
ÁîüÂ≠òÂÉπÂÄºËßÄÁõ∏ÊØîÔºåÊõ¥ÂÇæÂêëÊñºËá™ÊàëË°®ÈÅîÔºõÂú®ÈÅìÂæ∑Âü∫Á§éÁêÜË´ñ‰∏≠ÔºåÊõ¥ÂÇæÂêëÊñºÈóúÊá∑ËÄåÈùûÂø†Ë™†„ÄÇÊúâË∂£ÁöÑÊòØÔºåÊàëÂÄëÁôºÁèæÂ∞çÊñºÊüê‰∫õÊ†∏ÂøÉÂÉπÂÄºËßÄÔºå‰æãÂ¶ÇË™†ÂØ¶Ôºå‰∏çÂêåÊ®°Âûã‰πãÈñìÂ≠òÂú®ÂæàÂ§ßÁöÑÂÅèÂ•ΩÂ∑ÆÁï∞Ôºå‰æãÂ¶ÇÔºå
Mixtral-8x7B Ê®°ÂûãÂÇæÂêëÊñºÂøΩÁï•ÂÆÉ 9.7%ÔºåËÄå GPT-4-turbo Ê®°ÂûãÂÇæÂêëÊñºÈÅ∏ÊìáÂÆÉ 9.4%„ÄÇÊàëÂÄëÈÇÑÁ†îÁ©∂‰∫Ü OpenAI
(ModelSpec) Âíå Anthropic (Constitutional AI) ÊúÄËøëÁôºÂ∏ÉÁöÑÊåáÂ∞éÊñπÈáùÔºå‰ª•‰∫ÜËß£‰ªñÂÄëÁôºÂ∏ÉÁöÑÂéüÂâáÂ¶Ç‰ΩïÂú®Èù¢Â∞çÊó•Â∏∏ÁîüÊ¥ª‰∏≠ÂæÆÂ¶ôÁöÑÈÅìÂæ∑Êé®ÁêÜÊôÇÂèçÊò†‰ªñÂÄëÁöÑÂØ¶ÈöõÂÉπÂÄºÂÑ™ÂÖàÈ†ÜÂ∫è„ÄÇÊàëÂÄëÁôºÁèæÔºåÊúÄÁµÇ‰ΩøÁî®ËÄÖÁÑ°Ê≥ïÊúâÊïàÂú∞
‰ΩøÁî®Á≥ªÁµ±ÊèêÁ§∫‰æÜÂºïÂ∞éÊ≠§È°ûÂÑ™ÂÖàÈ†ÜÂ∫è„ÄÇ</paragraph>

##### **Plots Unlock Time-Series Understanding in Multimodal Models**
2410.02637v1 by Mayank Daswani, Mathias M. J. Bellaiche, Marc Wilson, Desislav Ivanov, Mikhail Papkov, Eva Schnider, Jing Tang, Kay Lamerigts, Gabriela Botea, Michael A. Sanchez, Yojan Patel, Shruthi Prabhakara, Shravya Shetty, Umesh Telang

While multimodal foundation models can now natively work with data beyond
text, they remain underutilized in analyzing the considerable amounts of
multi-dimensional time-series data in fields like healthcare, finance, and
social sciences, representing a missed opportunity for richer, data-driven
insights. This paper proposes a simple but effective method that leverages the
existing vision encoders of these models to "see" time-series data via plots,
avoiding the need for additional, potentially costly, model training. Our
empirical evaluations show that this approach outperforms providing the raw
time-series data as text, with the additional benefit that visual time-series
representations demonstrate up to a 90% reduction in model API costs. We
validate our hypothesis through synthetic data tasks of increasing complexity,
progressing from simple functional form identification on clean data, to
extracting trends from noisy scatter plots. To demonstrate generalizability
from synthetic tasks with clear reasoning steps to more complex, real-world
scenarios, we apply our approach to consumer health tasks - specifically fall
detection, activity recognition, and readiness assessment - which involve
heterogeneous, noisy data and multi-step reasoning. The overall success in plot
performance over text performance (up to an 120% performance increase on
zero-shot synthetic tasks, and up to 150% performance increase on real-world
tasks), across both GPT and Gemini model families, highlights our approach's
potential for making the best use of the native capabilities of foundation
models.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§öÊ®°ÊÖãÂü∫Á§éÊ®°ÂûãÁèæÂú®ÂèØ‰ª•ÂéüÁîüËôïÁêÜÊñáÂ≠ó‰ª•Â§ñÁöÑË≥áÊñôÔºå‰ΩÜÂÆÉÂÄëÂú®ÂàÜÊûêÈÜ´ÁôÇ‰øùÂÅ•„ÄÅÈáëËûçÂíåÁ§æÊúÉÁßëÂ≠∏Á≠âÈ†òÂüü‰∏≠Â§ßÈáèÂ§öÁ∂≠ÊôÇÈñìÂ∫èÂàóË≥áÊñôÊôÇ‰ªçÊú™Ë¢´ÂÖÖÂàÜÂà©Áî®ÔºåÈÄô‰ª£Ë°®ÈåØÂ§±‰∫ÜÁç≤ÂæóÊõ¥Ë±êÂØåË≥áÊñôÈ©ÖÂãïË¶ãËß£ÁöÑÊ©üÊúÉ„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ∞°ÂñÆ‰ΩÜÊúâÊïàÁöÑÊñπÊ≥ïÔºåÂà©Áî®ÈÄô‰∫õÊ®°ÂûãÁèæÊúâÁöÑË¶ñË¶∫Á∑®Á¢ºÂô®ÈÄèÈÅéÂúñË°®„ÄåÊü•Áúã„ÄçÊôÇÈñìÂ∫èÂàóË≥áÊñôÔºåÈÅøÂÖçÈúÄË¶ÅÈ°çÂ§ñ‰∏îÂèØËÉΩÊòÇË≤¥ÁöÑÊ®°ÂûãË®ìÁ∑¥„ÄÇÊàëÂÄëÁöÑÁ∂ìÈ©óË©ï‰º∞È°ØÁ§∫ÔºåÈÄôÁ®ÆÊñπÊ≥ïÂÑ™ÊñºÊèê‰æõÂéüÂßãÊôÇÈñìÂ∫èÂàóË≥áÊñô‰ΩúÁÇ∫ÊñáÂ≠óÔºåÈ°çÂ§ñÁöÑÂ•ΩËôïÊòØË¶ñË¶∫ÊôÇÈñìÂ∫èÂàóË°®Á§∫ÂèØ‰ª•Ê∏õÂ∞ëÈ´òÈÅî 90% ÁöÑÊ®°Âûã API ÊàêÊú¨„ÄÇÊàëÂÄëÈÄèÈÅéÊó•ÁõäË§áÈõúÁöÑÂêàÊàêË≥áÊñô‰ªªÂãôÈ©óË≠âÊàëÂÄëÁöÑÂÅáË®≠ÔºåÂæû‰πæÊ∑®Ë≥áÊñô‰∏äÁöÑÁ∞°ÂñÆÂáΩÊï∏ÂΩ¢ÂºèË≠òÂà•ÔºåÂà∞ÂæûÈõúË®äÊï£‰ΩàÂúñ‰∏≠ËêÉÂèñË∂®Âã¢„ÄÇÁÇ∫‰∫ÜË≠âÊòéÂæûÂÖ∑ÊúâÊòéÁ¢∫Êé®ÁêÜÊ≠•È©üÁöÑÂêàÊàê‰ªªÂãôÂà∞Êõ¥Ë§áÈõúÁöÑÁúüÂØ¶‰∏ñÁïåÂ†¥ÊôØÁöÑÊ¶ÇÊã¨ÊÄßÔºåÊàëÂÄëÂ∞áÊàëÂÄëÁöÑÂÅöÊ≥ïÊáâÁî®ÊñºÊ∂àË≤ªËÄÖÂÅ•Â∫∑‰ªªÂãôÔºåÁâπÂà•ÊòØË∑åÂÄíÂÅµÊ∏¨„ÄÅÊ¥ªÂãïË≠òÂà•ÂíåÊ∫ñÂÇôË©ï‰º∞ÔºåÈÄô‰∫õ‰ªªÂãôÊ∂âÂèäÁï∞Ë≥™„ÄÅÈõúË®äË≥áÊñôÂíåÂ§öÊ≠•È©üÊé®ÁêÜ„ÄÇÂú® GPT Âíå Gemini Ê®°ÂûãÁ≥ªÂàó‰∏≠ÔºåÂúñË°®Ë°®ÁèæÂÑ™ÊñºÊñáÂ≠óË°®ÁèæÁöÑÊï¥È´îÊàêÂäüÔºàÂú®Èõ∂Ê¨°Â≠∏ÁøíÂêàÊàê‰ªªÂãô‰∏≠Ë°®ÁèæÊèêÂçáÈ´òÈÅî 120%ÔºåÂú®ÁúüÂØ¶‰∏ñÁïå‰ªªÂãô‰∏≠Ë°®ÁèæÊèêÂçáÈ´òÈÅî 150%ÔºâÔºåÁ™ÅÈ°Ø‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÂú®ÊúÄ‰Ω≥Âà©Áî®Âü∫Á§éÊ®°ÂûãÂéüÁîüÂäüËÉΩÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇ

##### **IC3M: In-Car Multimodal Multi-object Monitoring for Abnormal Status of Both Driver and Passengers**
2410.02592v1 by Zihan Fang, Zheng Lin, Senkang Hu, Hangcheng Cao, Yiqin Deng, Xianhao Chen, Yuguang Fang

Recently, in-car monitoring has emerged as a promising technology for
detecting early-stage abnormal status of the driver and providing timely alerts
to prevent traffic accidents. Although training models with multimodal data
enhances the reliability of abnormal status detection, the scarcity of labeled
data and the imbalance of class distribution impede the extraction of critical
abnormal state features, significantly deteriorating training performance.
Furthermore, missing modalities due to environment and hardware limitations
further exacerbate the challenge of abnormal status identification. More
importantly, monitoring abnormal health conditions of passengers, particularly
in elderly care, is of paramount importance but remains underexplored. To
address these challenges, we introduce our IC3M, an efficient
camera-rotation-based multimodal framework for monitoring both driver and
passengers in a car. Our IC3M comprises two key modules: an adaptive threshold
pseudo-labeling strategy and a missing modality reconstruction. The former
customizes pseudo-labeling thresholds for different classes based on the class
distribution, generating class-balanced pseudo labels to guide model training
effectively, while the latter leverages crossmodality relationships learned
from limited labels to accurately recover missing modalities by distribution
transferring from available modalities. Extensive experimental results
demonstrate that IC3M outperforms state-of-the-art benchmarks in accuracy,
precision, and recall while exhibiting superior robustness under limited
labeled data and severe missing modality.

ÊëòË¶ÅÔºö<paragraph>Ëøë‰æÜÔºåËªäËºâÁõ£ÊéßÂ∑≤ÊàêÁÇ∫‰∏ÄÁ®ÆÂæàÊúâÂâçÊôØÁöÑÊäÄË°ìÔºåÂèØÁî®ÊñºÂÅµÊ∏¨ÈßïÈßõÁöÑÁï∞Â∏∏ÁãÄÊÖãÔºå‰∏¶Êèê‰æõÂèäÊôÇÁöÑË≠¶Á§∫Ôºå‰ª•È†êÈò≤‰∫§ÈÄö‰∫ãÊïÖ„ÄÇÂÑòÁÆ°‰ΩøÁî®Â§öÊ®°ÂºèË≥áÊñôË®ìÁ∑¥Ê®°ÂûãÂèØÊèêÂçáÁï∞Â∏∏ÁãÄÊÖãÂÅµÊ∏¨ÁöÑÂèØÈù†ÊÄßÔºå‰ΩÜÊ®ôÁ±§Ë≥áÊñôÁöÑÁ®ÄÂ∞ëÂíåÈ°ûÂà•ÂàÜ‰ΩàÁöÑ‰∏çÂπ≥Ë°°ÊúÉÈòªÁ§ôÈóúÈçµÁï∞Â∏∏ÁãÄÊÖãÁâπÂæµÁöÑËêÉÂèñÔºåÂ§ßÂπÖÈôç‰ΩéË®ìÁ∑¥ÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÁî±ÊñºÁí∞Â¢ÉÂíåÁ°¨È´îÈôêÂà∂ËÄåÈÅ∫Â§±ÁöÑÊ®°ÂºèÊúÉÈÄ≤‰∏ÄÊ≠•Âä†ÂäáÁï∞Â∏∏ÁãÄÊÖãË≠òÂà•ÁöÑÊåëÊà∞„ÄÇÊõ¥ÈáçË¶ÅÁöÑÊòØÔºåÁõ£Êéß‰πòÂÆ¢ÁöÑÁï∞Â∏∏ÂÅ•Â∫∑ÁãÄÊ≥ÅÔºåÁâπÂà•ÊòØÂú®ËÄÅÂπ¥ÁÖßË≠∑ÊñπÈù¢ÔºåËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜ‰ªçÊú™ÂèóÂà∞ÂÖÖÂàÜÁöÑÊé¢Ë®é„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü IC3MÔºåÈÄôÊòØ‰∏ÄÂÄãÁî®ÊñºÁõ£ÊéßËªäËºõ‰∏≠ÈßïÈßõÂíå‰πòÂÆ¢ÁöÑÊúâÊïàÊîùÂΩ±Ê©üÊóãËΩâÂºèÂ§öÊ®°ÂºèÊû∂Êßã„ÄÇÊàëÂÄëÁöÑ IC3M ÂåÖÂê´ÂÖ©ÂÄãÈóúÈçµÊ®°ÁµÑÔºöËá™ÈÅ©ÊáâÈñæÂÄºÂÅΩÊ®ôÁ±§Á≠ñÁï•ÂíåÈÅ∫Â§±Ê®°ÂºèÈáçÂª∫„ÄÇÂâçËÄÖÊúÉÊ†πÊìöÈ°ûÂà•ÂàÜ‰ΩàÁÇ∫‰∏çÂêåÁöÑÈ°ûÂà•Ëá™Ë®ÇÂÅΩÊ®ôÁ±§ÈñæÂÄºÔºåÁî¢ÁîüÈ°ûÂà•Âπ≥Ë°°ÁöÑÂÅΩÊ®ôÁ±§‰ª•ÊúâÊïàÂºïÂ∞éÊ®°ÂûãË®ìÁ∑¥ÔºåËÄåÂæåËÄÖÂâáÂà©Áî®ÂæûÊúâÈôêÊ®ôÁ±§‰∏≠Â≠∏ÁøíÂà∞ÁöÑË∑®Ê®°ÂºèÈóú‰øÇÔºåÈÄèÈÅéÂæûÂèØÁî®Ê®°ÂºèÂÇ≥Ëº∏ÂàÜ‰Ωà‰æÜÊ∫ñÁ¢∫ÈÇÑÂéüÈÅ∫Â§±ÁöÑÊ®°Âºè„ÄÇÂ§ßÈáèÁöÑÂØ¶È©óÁµêÊûúË≠âÊòéÔºåÂú®Ê®ôÁ±§Ë≥áÊñôÊúâÈôê‰∏îÈÅ∫Â§±Ê®°ÂºèÂö¥ÈáçÁöÑÊÉÖÊ≥Å‰∏ãÔºåIC3M Âú®Ê∫ñÁ¢∫Â∫¶„ÄÅÁ≤æÁ¢∫Â∫¶ÂíåÂè¨ÂõûÁéáÊñπÈù¢ÈÉΩÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÂü∫Ê∫ñ„ÄÇ
</paragraph>

##### **Deep Regression 2D-3D Ultrasound Registration for Liver Motion Correction in Focal Tumor Thermal Ablation**
2410.02579v1 by Shuwei Xing, Derek W. Cool, David Tessier, Elvis C. S. Chen, Terry M. Peters, Aaron Fenster

Liver tumor ablation procedures require accurate placement of the needle
applicator at the tumor centroid. The lower-cost and real-time nature of
ultrasound (US) has advantages over computed tomography (CT) for applicator
guidance, however, in some patients, liver tumors may be occult on US and tumor
mimics can make lesion identification challenging. Image registration
techniques can aid in interpreting anatomical details and identifying tumors,
but their clinical application has been hindered by the tradeoff between
alignment accuracy and runtime performance, particularly when compensating for
liver motion due to patient breathing or movement. Therefore, we propose a
2D-3D US registration approach to enable intra-procedural alignment that
mitigates errors caused by liver motion. Specifically, our approach can
correlate imbalanced 2D and 3D US image features and use continuous 6D rotation
representations to enhance the model's training stability. The dataset was
divided into 2388, 196 and 193 image pairs for training, validation and
testing, respectively. Our approach achieved a mean Euclidean distance error of
2.28 mm $\pm$ 1.81 mm and a mean geodesic angular error of 2.99$^{\circ}$ $\pm$
1.95$^{\circ}$, with a runtime of 0.22 seconds per 2D-3D US image pair. These
results demonstrate that our approach can achieve accurate alignment and
clinically acceptable runtime, indicating potential for clinical translation.

ÊëòË¶ÅÔºöËÇùËáüËÖ´Áò§Ê∂àËûçÊâãË°ìÈúÄË¶ÅÂ∞áÈáùÈ†≠ÊñΩÁî®Âô®Á≤æÊ∫ñÁΩÆÊñºËÖ´Áò§‰∏≠ÂøÉÈªû„ÄÇË∂ÖÈü≥Ê≥¢ (US) ÊàêÊú¨ËºÉ‰Ωé‰∏îÁÇ∫Âç≥ÊôÇÂΩ±ÂÉèÔºåÁõ∏ËºÉÊñºÈõªËÖ¶Êñ∑Â±§ÊéÉÊèè (CT)ÔºåÂú®ÊñΩÁî®Âô®Â∞éÂºïÊñπÈù¢ÊúâÂÑ™Âã¢ÔºåÁÑ∂ËÄåÔºåÂ∞çÊñºÊüê‰∫õÊÇ£ËÄÖÔºåËÇùËáüËÖ´Áò§Âú®Ë∂ÖÈü≥Ê≥¢ÂΩ±ÂÉè‰∏äÂèØËÉΩ‰∏çÊòéÈ°ØÔºåËÄåËÖ´Áò§Ê®°Êì¨ÊúÉËÆìÁóÖÁÅ∂Ëæ®Ë≠òÊõ¥ÂÖ∑ÊåëÊà∞ÊÄß„ÄÇÂΩ±ÂÉèÈÖçÊ∫ñÊäÄË°ìÊúâÂä©ÊñºËß£ËÆÄËß£ÂâñÁ¥∞ÁØÄÂíåËæ®Ë≠òËÖ´Áò§Ôºå‰ΩÜÁî±ÊñºÂπ≥Ë°°Ê†°Ê∫ñÊ∫ñÁ¢∫Â∫¶ÂíåÂü∑Ë°åÊïàËÉΩÔºåÂÖ∂Ëá®Â∫äÊáâÁî®ÂèóÂà∞ÈòªÁ§ôÔºåÁâπÂà•ÊòØÂú®Ë£úÂÑüÂõ†ÊÇ£ËÄÖÂëºÂê∏ÊàñÁßªÂãïËÄåÁî¢ÁîüÁöÑËÇùËáüÈÅãÂãïÊôÇ„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫ 2D-3D Ë∂ÖÈü≥Ê≥¢ÈÖçÊ∫ñÊñπÊ≥ïÔºå‰ª•ÈÄ≤Ë°åË°ì‰∏≠Ê†°Ê∫ñÔºåÊ∏õËºïÂõ†ËÇùËáüÈÅãÂãïËÄåÁî¢ÁîüÁöÑË™§Â∑Æ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂèØ‰ª•ÈóúËÅØÂ§±Ë°°ÁöÑ 2D Âíå 3D Ë∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÁâπÂæµÔºå‰∏¶‰ΩøÁî®ÈÄ£Á∫åÁöÑ 6D ÊóãËΩâË°®Á§∫‰æÜÂ¢ûÂº∑Ê®°ÂûãÁöÑË®ìÁ∑¥Á©©ÂÆöÂ∫¶„ÄÇË≥áÊñôÈõÜÂàÜÁÇ∫ 2388„ÄÅ196 Âíå 193 ÂΩ±ÂÉèÂ∞çÔºåÂàÜÂà•Áî®ÊñºË®ìÁ∑¥„ÄÅÈ©óË≠âÂíåÊ∏¨Ë©¶„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÈÅîÊàêÂπ≥ÂùáÊ≠êÊ∞èË∑ùÈõ¢Ë™§Â∑Æ 2.28 mm $\pm$ 1.81 mmÔºå‰ª•ÂèäÂπ≥ÂùáÊ∏¨Âú∞ËßíË™§Â∑Æ 2.99$^{\circ}$ $\pm$ 1.95$^{\circ}$ÔºåÂü∑Ë°åÊôÇÈñìÁÇ∫ÊØè 2D-3D Ë∂ÖÈü≥Ê≥¢ÂΩ±ÂÉèÂ∞ç 0.22 Áßí„ÄÇÈÄô‰∫õÁµêÊûúË≠âÊòéÊàëÂÄëÁöÑÂÅöÊ≥ïÂèØ‰ª•ÈÅîÊàêÁ≤æÊ∫ñÊ†°Ê∫ñÂíåËá®Â∫ä‰∏äÂèØÊé•ÂèóÁöÑÂü∑Ë°åÊôÇÈñìÔºåÈ°ØÁ§∫Âá∫Ëá®Â∫äËΩâË≠ØÁöÑÊΩõÂäõ„ÄÇ

##### **ColaCare: Enhancing Electronic Health Record Modeling through Large Language Model-Driven Multi-Agent Collaboration**
2410.02551v1 by Zixiang Wang, Yinghao Zhu, Huiya Zhao, Xiaochen Zheng, Tianlong Wang, Wen Tang, Yasha Wang, Chengwei Pan, Ewen M. Harrison, Junyi Gao, Liantao Ma

We introduce ColaCare, a framework that enhances Electronic Health Record
(EHR) modeling through multi-agent collaboration driven by Large Language
Models (LLMs). Our approach seamlessly integrates domain-specific expert models
with LLMs to bridge the gap between structured EHR data and text-based
reasoning. Inspired by clinical consultations, ColaCare employs two types of
agents: DoctorAgent and MetaAgent, which collaboratively analyze patient data.
Expert models process and generate predictions from numerical EHR data, while
LLM agents produce reasoning references and decision-making reports within the
collaborative consultation framework. We additionally incorporate the Merck
Manual of Diagnosis and Therapy (MSD) medical guideline within a
retrieval-augmented generation (RAG) module for authoritative evidence support.
Extensive experiments conducted on four distinct EHR datasets demonstrate
ColaCare's superior performance in mortality prediction tasks, underscoring its
potential to revolutionize clinical decision support systems and advance
personalized precision medicine. The code, complete prompt templates, more case
studies, etc. are publicly available at the anonymous link:
https://colacare.netlify.app.

ÊëòË¶ÅÔºöÊàëÂÄëÊé®Âá∫ ColaCareÔºå‰∏ÄÂÄãÈÄèÈÅéÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) È©ÖÂãïÁöÑÂ§öÈáç‰ª£ÁêÜÂçî‰ΩúÔºå‰æÜÂ¢ûÂº∑ÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) Âª∫Ê®°ÁöÑÊ°ÜÊû∂„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂ∞áÈ†òÂüüÁâπÂÆöÂ∞àÂÆ∂Ê®°ÂûãËàá LLM ÁÑ°Á∏´Êï¥ÂêàÔºå‰ª•ÂΩåÂêàÁµêÊßãÂåñ EHR Ë≥áÊñôËàáÂü∫ÊñºÊñáÂ≠óÁöÑÊé®ÁêÜ‰πãÈñìÁöÑÂ∑ÆË∑ù„ÄÇColaCare ÂèóÂà∞Ëá®Â∫äË´ÆË©¢ÁöÑÂïüÁôºÔºåÊé°Áî®‰∫ÜÂÖ©Á®Æ‰ª£ÁêÜÔºöDoctorAgent Âíå MetaAgentÔºåÂÆÉÂÄëÂçî‰ΩúÂàÜÊûêÊÇ£ËÄÖË≥áÊñô„ÄÇÂ∞àÂÆ∂Ê®°ÂûãËôïÁêÜ‰∏¶ÂæûÊï∏ÂÄº EHR Ë≥áÊñôÁî¢ÁîüÈ†êÊ∏¨ÔºåËÄå LLM ‰ª£ÁêÜÂâáÂú®Âçî‰ΩúË´ÆË©¢Ê°ÜÊû∂ÂÖßÁî¢ÁîüÊé®ÁêÜÂèÉËÄÉÂíåÊ±∫Á≠ñÂ†±Âëä„ÄÇÊàëÂÄëÂè¶Â§ñÂú®‰∏ÄÂÄãÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) Ê®°ÁµÑ‰∏≠Á¥çÂÖ•‰∫ÜÈªòÂÖãË®∫Êñ∑ËàáÊ≤ªÁôÇÊâãÂÜä (MSD) ÈÜ´ÁôÇÊåáÂçóÔºå‰ª•Áç≤ÂæóÊ¨äÂ®ÅË≠âÊìöÊîØÊåÅ„ÄÇÂú®ÂõõÂÄã‰∏çÂêåÁöÑ EHR Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫Ü ColaCare Âú®Ê≠ª‰∫°ÁéáÈ†êÊ∏¨‰ªªÂãô‰∏≠ÁöÑÂÑ™Áï∞ÊïàËÉΩÔºåÂº∑Ë™ø‰∫ÜÂÖ∂Èù©Êñ∞Ëá®Â∫äÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ±ÂíåÊé®ÈÄ≤ÂÄã‰∫∫ÂåñÁ≤æÊ∫ñÈÜ´ÁôÇÁöÑÊΩõÂäõ„ÄÇÁ®ãÂºèÁ¢º„ÄÅÂÆåÊï¥ÁöÑÊèêÁ§∫ÁØÑÊú¨„ÄÅÊõ¥Â§öÊ°à‰æãÁ†îÁ©∂Á≠âÔºåÈÉΩÂèØ‰ª•Âú®ÂåøÂêçÈÄ£Áµê‰∏≠ÂÖ¨ÈñãÂèñÂæóÔºöhttps://colacare.netlify.app„ÄÇ

##### **SAFLEX: Self-Adaptive Augmentation via Feature Label Extrapolation**
2410.02512v1 by Mucong Ding, Bang An, Yuancheng Xu, Anirudh Satheesh, Furong Huang

Data augmentation, a cornerstone technique in deep learning, is crucial in
enhancing model performance, especially with scarce labeled data. While
traditional techniques are effective, their reliance on hand-crafted methods
limits their applicability across diverse data types and tasks. Although modern
learnable augmentation methods offer increased adaptability, they are
computationally expensive and challenging to incorporate within prevalent
augmentation workflows. In this work, we present a novel, efficient method for
data augmentation, effectively bridging the gap between existing augmentation
strategies and emerging datasets and learning tasks. We introduce SAFLEX
(Self-Adaptive Augmentation via Feature Label EXtrapolation), which learns the
sample weights and soft labels of augmented samples provided by any given
upstream augmentation pipeline, using a specifically designed efficient bilevel
optimization algorithm. Remarkably, SAFLEX effectively reduces the noise and
label errors of the upstream augmentation pipeline with a marginal
computational cost. As a versatile module, SAFLEX excels across diverse
datasets, including natural and medical images and tabular data, showcasing its
prowess in few-shot learning and out-of-distribution generalization. SAFLEX
seamlessly integrates with common augmentation strategies like RandAug, CutMix,
and those from large pre-trained generative models like stable diffusion and is
also compatible with frameworks such as CLIP's fine-tuning. Our findings
highlight the potential to adapt existing augmentation pipelines for new data
types and tasks, signaling a move towards more adaptable and resilient training
frameworks.

ÊëòË¶ÅÔºöË≥áÊñôÊì¥ÂÖÖÊòØÊ∑±Â∫¶Â≠∏ÁøíÁöÑÂü∫Áü≥ÊäÄË°ìÔºåÂú®ÊèêÂçáÊ®°ÂûãÊïàËÉΩÊñπÈù¢Ëá≥ÈóúÈáçË¶ÅÔºåÁâπÂà•ÊòØÂú®Ê®ôÁ±§Ë≥áÊñôÁ®ÄÂ∞ëÁöÑÊÉÖÊ≥Å‰∏ã„ÄÇÈõñÁÑ∂ÂÇ≥Áµ±ÊäÄË°ìÂæàÊúâÊïàÔºå‰ΩÜÂÆÉÂÄë‰æùË≥¥ÊñºÊâãÂ∑•Ë£Ω‰ΩúÁöÑÊñπÊ≥ïÔºåÈôêÂà∂‰∫ÜÂÆÉÂÄëÂú®‰∏çÂêåË≥áÊñôÈ°ûÂûãÂíå‰ªªÂãô‰∏≠ÁöÑÈÅ©Áî®ÊÄß„ÄÇÂÑòÁÆ°Áèæ‰ª£ÂèØÂ≠∏ÁøíÁöÑÊì¥ÂÖÖÊñπÊ≥ïÊèê‰æõ‰∫ÜÊõ¥È´òÁöÑÈÅ©ÊáâÊÄßÔºå‰ΩÜÂÆÉÂÄëÂú®Ë®àÁÆó‰∏äÂæàÊòÇË≤¥Ôºå‰∏¶‰∏îÈõ£‰ª•Êï¥ÂêàÂà∞ÊôÆÈÅçÁöÑÊì¥ÂÖÖÂ∑•‰ΩúÊµÅÁ®ã‰∏≠„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©é„ÄÅÊúâÊïàÁéáÁöÑË≥áÊñôÊì¥ÂÖÖÊñπÊ≥ïÔºåÊúâÊïàÂú∞ÂΩåÂêà‰∫ÜÁèæÊúâÊì¥ÂÖÖÁ≠ñÁï•ËàáÊñ∞ËààË≥áÊñôÈõÜÂíåÂ≠∏Áøí‰ªªÂãô‰πãÈñìÁöÑÂ∑ÆË∑ù„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü SAFLEXÔºàÈÄèÈÅéÁâπÂæµÊ®ôÁ±§Â§ñÊé®ÈÄ≤Ë°åËá™ÈÅ©ÊáâÊì¥ÂÖÖÔºâÔºåÂÆÉ‰ΩøÁî®Â∞àÈñÄË®≠Ë®àÁöÑÊúâÊïàÈõôÂ±§Ê¨°ÊúÄ‰Ω≥ÂåñÊºîÁÆóÊ≥ïÔºåÂ≠∏ÁøíÁî±‰ªª‰ΩïÁµ¶ÂÆöÁöÑ‰∏äÊ∏∏Êì¥ÂÖÖÁÆ°ÈÅìÊèê‰æõÁöÑÊì¥ÂÖÖÊ®£Êú¨ÁöÑÊ®£Êú¨Ê¨äÈáçÂíåËªüÊ®ôÁ±§„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåSAFLEX ÊúâÊïàÂú∞Èôç‰Ωé‰∫Ü‰∏äÊ∏∏Êì¥ÂÖÖÁÆ°ÈÅìÁöÑÈõúË®äÂíåÊ®ôÁ±§ÈåØË™§Ôºå‰∏îË®àÁÆóÊàêÊú¨Âæà‰Ωé„ÄÇ‰ΩúÁÇ∫‰∏ÄÂÄãÂ§öÂäüËÉΩÊ®°ÁµÑÔºåSAFLEX Âú®ÂêÑÁ®ÆË≥áÊñôÈõÜ‰∏≠Ë°®ÁèæÂá∫Ëâ≤ÔºåÂåÖÊã¨Ëá™ÁÑ∂ÂíåÈÜ´Â≠∏ÂΩ±ÂÉè‰ª•ÂèäË°®Ê†ºË≥áÊñôÔºåÂ±ïÁ§∫‰∫ÜÂÆÉÂú®Â∞ëÊ®£Êú¨Â≠∏ÁøíÂíåÂàÜÂ∏ÉÂ§ñÊ¶ÇÊã¨‰∏≠ÁöÑÂÑ™Áï∞ËÉΩÂäõ„ÄÇSAFLEX ËàáÂ∏∏Ë¶ãÁöÑÊì¥ÂÖÖÁ≠ñÁï•ÔºàÂ¶Ç RandAug„ÄÅCutMixÔºå‰ª•Âèä‰æÜËá™Â§ßÂûãÈ†êË®ìÁ∑¥ÁîüÊàêÊ®°ÂûãÔºàÂ¶ÇÁ©©ÂÆöÊì¥Êï£ÔºâÁöÑÊì¥ÂÖÖÁ≠ñÁï•ÔºâÁÑ°Á∏´Êï¥ÂêàÔºå‰∏¶‰∏î‰πüÁõ∏ÂÆπÊñº CLIP ÁöÑÂæÆË™øÁ≠âÊ°ÜÊû∂„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÁ™ÅÈ°Ø‰∫ÜË™øÊï¥ÁèæÊúâÊì¥ÂÖÖÁÆ°ÈÅì‰ª•ÈÅ©ÊáâÊñ∞Ë≥áÊñôÈ°ûÂûãÂíå‰ªªÂãôÁöÑÊΩõÂäõÔºåÊ®ôË™åËëóÊúùÂêëÊõ¥ÂÖ∑ÈÅ©ÊáâÊÄßÂíåÈüåÊÄßÁöÑË®ìÁ∑¥Ê°ÜÊû∂ÈÇÅÈÄ≤„ÄÇ

##### **Clinnova Federated Learning Proof of Concept: Key Takeaways from a Cross-border Collaboration**
2410.02443v1 by Julia Alekseenko, Bram Stieltjes, Michael Bach, Melanie Boerries, Oliver Opitz, Alexandros Karargyris, Nicolas Padoy

Clinnova, a collaborative initiative involving France, Germany, Switzerland,
and Luxembourg, is dedicated to unlocking the power of precision medicine
through data federation, standardization, and interoperability. This European
Greater Region initiative seeks to create an interoperable European standard
using artificial intelligence (AI) and data science to enhance healthcare
outcomes and efficiency. Key components include multidisciplinary research
centers, a federated biobanking strategy, a digital health innovation platform,
and a federated AI strategy. It targets inflammatory bowel disease, rheumatoid
diseases, and multiple sclerosis (MS), emphasizing data quality to develop AI
algorithms for personalized treatment and translational research.
  The IHU Strasbourg (Institute of Minimal-invasive Surgery) has the lead in
this initiative to develop the federated learning (FL) proof of concept (POC)
that will serve as a foundation for advancing AI in healthcare. At its core,
Clinnova-MS aims to enhance MS patient care by using FL to develop more
accurate models that detect disease progression, guide interventions, and
validate digital biomarkers across multiple sites. This technical report
presents insights and key takeaways from the first cross-border federated POC
on MS segmentation of MRI images within the Clinnova framework. While our work
marks a significant milestone in advancing MS segmentation through cross-border
collaboration, it also underscores the importance of addressing technical,
logistical, and ethical considerations to realize the full potential of FL in
healthcare settings.

ÊëòË¶ÅÔºöClinnova ÊòØ‰∏ÄÈ†ÖÁî±Ê≥ïÂúã„ÄÅÂæ∑Âúã„ÄÅÁëûÂ£´ÂíåÁõßÊ£ÆÂ†°Âêà‰ΩúÁôºËµ∑ÁöÑË®àÁï´ÔºåËá¥ÂäõÊñºÈÄèÈÅéË≥áÊñôËÅØÂêà„ÄÅÊ®ôÊ∫ñÂåñÂíå‰∫íÈÄöÊÄß‰æÜÈáãÊîæÁ≤æÊ∫ñÈÜ´ÁôÇÁöÑÂäõÈáè„ÄÇÈÄôÂÄãÊ≠êÊ¥≤Â§ßÂçÄË®àÁï´Êó®Âú®‰ΩøÁî®‰∫∫Â∑•Êô∫ÊÖß (AI) ÂíåË≥áÊñôÁßëÂ≠∏Âª∫Á´ã‰∏ÄÂÄãÂèØ‰∫íÈÄöÁöÑÊ≠êÊ¥≤Ê®ôÊ∫ñÔºå‰ª•ÊèêÂçáÈÜ´ÁôÇ‰øùÂÅ•ÊàêÊûúÂíåÊïàÁéá„ÄÇ‰∏ªË¶ÅÁµÑÊàêÈÉ®ÂàÜÂåÖÊã¨Ë∑®È†òÂüüÁ†îÁ©∂‰∏≠ÂøÉ„ÄÅËÅØÂêàÁîüÁâ©ÈäÄË°åÁ≠ñÁï•„ÄÅÊï∏‰ΩçÂÅ•Â∫∑ÂâµÊñ∞Âπ≥Âè∞ÂíåËÅØÂêà AI Á≠ñÁï•„ÄÇÂÆÉÈáùÂ∞çÁôºÁÇéÊÄßËÖ∏ÈÅìÁñæÁóÖ„ÄÅÈ°ûÈ¢®ÊøïÊÄßÁñæÁóÖÂíåÂ§öÁôºÊÄßÁ°¨ÂåñÁóá (MS) ÈÄ≤Ë°åÁ†îÁ©∂ÔºåÂº∑Ë™øË≥áÊñôÂìÅË≥™‰ª•ÈñãÁôº AI ÊºîÁÆóÊ≥ïÔºåÁî®ÊñºÂÄã‰∫∫ÂåñÊ≤ªÁôÇÂíåËΩâË≠ØÁ†îÁ©∂„ÄÇ
Âè≤ÁâπÊãâÊñØÂ†° IHUÔºàÂæÆÂâµÊâãË°ìÁ†îÁ©∂ÊâÄÔºâÂú®ÈÄôÂÄãË®àÁï´‰∏≠È†òÂÖàÈñãÁôºËÅØÂêàÂ≠∏Áøí (FL) Ê¶ÇÂøµÈ©óË≠â (POC)ÔºåÈÄôÂ∞á‰ΩúÁÇ∫Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠Êé®ÈÄ≤ AI ÁöÑÂü∫Á§é„ÄÇClinnova-MS ÁöÑÊ†∏ÂøÉÁõÆÊ®ôÊòØÈÄèÈÅé‰ΩøÁî® FL ‰æÜÊèêÂçá MS ÊÇ£ËÄÖÁÖßË≠∑Ôºå‰ª•ÈñãÁôºÊõ¥Á≤æÁ¢∫ÁöÑÊ®°Âûã‰æÜÂÅµÊ∏¨ÁñæÁóÖÈÄ≤Á®ã„ÄÅÂºïÂ∞é‰ªãÂÖ•Êé™ÊñΩÔºå‰∏¶È©óË≠âÂ§öÂÄãÂú∞ÈªûÁöÑÊï∏‰ΩçÁîüÁâ©Ê®ôË®ò„ÄÇÈÄô‰ªΩÊäÄË°ìÂ†±ÂëäÊèê‰æõ‰∫Ü Clinnova Êû∂ÊßãÂÖß MS Á£ÅÊåØÈÄ†ÂΩ±ÂΩ±ÂÉèÂàÜÂâ≤È¶ñÊ¨°Ë∑®Â¢ÉËÅØÂêà POC ÁöÑË¶ãËß£Âíå‰∏ªË¶ÅÁµêË´ñ„ÄÇÈõñÁÑ∂ÊàëÂÄëÁöÑÊàêÊûúÂú®ÈÄèÈÅéË∑®Â¢ÉÂêà‰ΩúÊé®ÈÄ≤ MS ÂàÜÂâ≤ÊñπÈù¢ÊòØ‰∏ÄÂÄãÈáçË¶ÅÁöÑÈáåÁ®ãÁ¢ëÔºå‰ΩÜ‰πüÂº∑Ë™ø‰∫ÜÂú®ÈÜ´ÁôÇ‰øùÂÅ•Áí∞Â¢É‰∏≠ÂØ¶Áèæ FL ÁöÑÂÖ®ÈÉ®ÊΩõÂäõÊôÇÔºåËß£Ê±∫ÊäÄË°ì„ÄÅÂæåÂã§ÂíåÂÄ´ÁêÜËÄÉÈáèÁöÑÂøÖË¶ÅÊÄß„ÄÇ

##### **A Comprehensive Survey of Mamba Architectures for Medical Image Analysis: Classification, Segmentation, Restoration and Beyond**
2410.02362v1 by Shubhi Bansal, Sreeharish A, Madhava Prasath J, Manikandan S, Sreekanth Madisetty, Mohammad Zia Ur Rehman, Chandravardhan Singh Raghaw, Gaurav Duggal, Nagendra Kumar

Mamba, a special case of the State Space Model, is gaining popularity as an
alternative to template-based deep learning approaches in medical image
analysis. While transformers are powerful architectures, they have drawbacks,
including quadratic computational complexity and an inability to address
long-range dependencies efficiently. This limitation affects the analysis of
large and complex datasets in medical imaging, where there are many spatial and
temporal relationships. In contrast, Mamba offers benefits that make it
well-suited for medical image analysis. It has linear time complexity, which is
a significant improvement over transformers. Mamba processes longer sequences
without attention mechanisms, enabling faster inference and requiring less
memory. Mamba also demonstrates strong performance in merging multimodal data,
improving diagnosis accuracy and patient outcomes. The organization of this
paper allows readers to appreciate the capabilities of Mamba in medical imaging
step by step. We begin by defining core concepts of SSMs and models, including
S4, S5, and S6, followed by an exploration of Mamba architectures such as pure
Mamba, U-Net variants, and hybrid models with convolutional neural networks,
transformers, and Graph Neural Networks. We also cover Mamba optimizations,
techniques and adaptations, scanning, datasets, applications, experimental
results, and conclude with its challenges and future directions in medical
imaging. This review aims to demonstrate the transformative potential of Mamba
in overcoming existing barriers within medical imaging while paving the way for
innovative advancements in the field. A comprehensive list of Mamba
architectures applied in the medical field, reviewed in this work, is available
at Github.

ÊëòË¶ÅÔºöMamba ÊòØ‰∏ÄÁ®ÆÁâπÊÆäÈ°ûÂûãÁöÑÁãÄÊÖãÁ©∫ÈñìÊ®°ÂûãÔºåÈÄêÊº∏ÂèóÂà∞ÈáçË¶ñÔºåÊàêÁÇ∫ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûê‰∏≠Âü∫ÊñºÁØÑÊú¨ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇÂÑòÁÆ°TransformerÊòØÂº∑Â§ßÁöÑÊû∂ÊßãÔºå‰ΩÜÂÆÉÂÄëÊúâÁº∫ÈªûÔºåÂåÖÊã¨‰∫åÊ¨°Ë®àÁÆóË§áÈõúÂ∫¶Ôºå‰ª•ÂèäÁÑ°Ê≥ïÊúâÊïàËôïÁêÜÈï∑Ë∑ùÈõ¢‰æùË≥¥ÊÄß„ÄÇÈÄôÁ®ÆÈôêÂà∂ÊúÉÂΩ±ÈüøÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠Â§ßÂûãË§áÈõúË≥áÊñôÈõÜÁöÑÂàÜÊûêÔºåÂÖ∂‰∏≠ÊúâË®±Â§öÁ©∫ÈñìÂíåÊôÇÈñìÈóú‰øÇ„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåMamba Êèê‰æõÁöÑÂÑ™Èªû‰ΩøÂÖ∂ÈùûÂ∏∏ÈÅ©ÂêàÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûê„ÄÇÂÆÉÂÖ∑ÊúâÁ∑öÊÄßÊôÇÈñìË§áÈõúÂ∫¶ÔºåÈÄôÊòØ‰∏ÄÂÄãÊØîTransformerÈ°ØËëóÁöÑÊîπÈÄ≤„ÄÇMamba Âú®Ê≤íÊúâÊ≥®ÊÑèÊ©üÂà∂ÁöÑÊÉÖÊ≥Å‰∏ãËôïÁêÜÊõ¥Èï∑ÁöÑÂ∫èÂàóÔºåÂæûËÄåÂØ¶ÁèæÊõ¥Âø´ÁöÑÊé®ÁêÜ‰∏¶ÈúÄË¶ÅÊõ¥Â∞ëÁöÑË®òÊÜ∂È´î„ÄÇMamba Âú®Âêà‰ΩµÂ§öÊ®°ÊÖãÊï∏ÊìöÊñπÈù¢‰πüË°®ÁèæÂá∫Âº∑Â§ßÁöÑÊïàËÉΩÔºåÊèêÈ´ò‰∫ÜË®∫Êñ∑Ê∫ñÁ¢∫ÊÄßÂíåÊÇ£ËÄÖÈ†êÂæå„ÄÇÊú¨ÊñáÁöÑÁµÑÁπîÊñπÂºèËÆìËÆÄËÄÖÂèØ‰ª•ÈÄêÊ≠•‰∫ÜËß£ Mamba Âú®ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÁöÑÂäüËÉΩ„ÄÇÊàëÂÄëÂæûÂÆöÁæ© SSM ÂíåÊ®°ÂûãÁöÑÊ†∏ÂøÉÊ¶ÇÂøµÈñãÂßãÔºåÂåÖÊã¨ S4„ÄÅS5 Âíå S6ÔºåÁÑ∂ÂæåÊé¢Ë®é Mamba Êû∂ÊßãÔºå‰æãÂ¶ÇÁ¥î Mamba„ÄÅU-Net ËÆäÈ´îÔºå‰ª•ÂèäÂ∏∂ÊúâÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø„ÄÅTransformerÂíåÂúñÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÊ∑∑ÂêàÊ®°Âûã„ÄÇÊàëÂÄëÈÇÑÊ∂µËìã‰∫Ü Mamba ÊúÄ‰Ω≥Âåñ„ÄÅÊäÄË°ìÂíåÊîπÁ∑®„ÄÅÊéÉÊèè„ÄÅË≥áÊñôÈõÜ„ÄÅÊáâÁî®„ÄÅÂØ¶È©óÁµêÊûúÔºå‰∏¶‰ª•ÂÖ∂Âú®ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÁöÑÊåëÊà∞ÂíåÊú™‰æÜÊñπÂêë‰ΩúÁÇ∫ÁµêË´ñ„ÄÇÊú¨ÁØáË©ïË´ñÊó®Âú®Â±ïÁ§∫ Mamba Âú®ÂÖãÊúçÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÁèæÊúâÈöúÁ§ôÊñπÈù¢ÁöÑËΩâÂûãÊΩõÂäõÔºåÂêåÊôÇÁÇ∫Ë©≤È†òÂüüÁöÑÂâµÊñ∞ÈÄ≤Ê≠•Èã™Âπ≥ÈÅìË∑Ø„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÂõûÈ°ßÁöÑÊáâÁî®ÊñºÈÜ´Â≠∏È†òÂüüÁöÑ Mamba Êû∂ÊßãÁöÑÁ∂úÂêàÊ∏ÖÂñÆÂèØÂú® Github ‰∏äÂèñÂæó„ÄÇ

##### **CTARR: A fast and robust method for identifying anatomical regions on CT images via atlas registration**
2410.02316v1 by Thomas Buddenkotte, Roland Opfer, Julia Kr√ºger, Alessa Hering, Mireia Crispin-Ortuzar

Medical image analysis tasks often focus on regions or structures located in
a particular location within the patient's body. Often large parts of the image
may not be of interest for the image analysis task. When using deep-learning
based approaches, this causes an unnecessary increases the computational burden
during inference and raises the chance of errors. In this paper, we introduce
CTARR, a novel generic method for CT Anatomical Region Recognition. The method
serves as a pre-processing step for any deep learning-based CT image analysis
pipeline by automatically identifying the pre-defined anatomical region that is
relevant for the follow-up task and removing the rest. It can be used in (i)
image segmentation to prevent false positives in anatomically implausible
regions and speeding up the inference, (ii) image classification to produce
image crops that are consistent in their anatomical context, and (iii) image
registration by serving as a fast pre-registration step. Our proposed method is
based on atlas registration and provides a fast and robust way to crop any
anatomical region encoded as one or multiple bounding box(es) from any
unlabeled CT scan of the brain, chest, abdomen and/or pelvis. We demonstrate
the utility and robustness of the proposed method in the context of medical
image segmentation by evaluating it on six datasets of public segmentation
challenges. The foreground voxels in the regions of interest are preserved in
the vast majority of cases and tasks (97.45-100%) while taking only fractions
of a seconds to compute (0.1-0.21s) on a deep learning workstation and greatly
reducing the segmentation runtime (2.0-12.7x). Our code is available at
https://github.com/ThomasBudd/ctarr.

ÊëòË¶ÅÔºö<paragraph>ÂåªÂ≠¶ÂΩ±ÂÉèÂàÜÊûê‰ªªÂä°ÈÄöÂ∏∏‰∏ìÊ≥®‰∫éÊÇ£ËÄÖ‰ΩìÂÜÖÁâπÂÆö‰ΩçÁΩÆÁöÑÂå∫ÂüüÊàñÁªìÊûÑ„ÄÇÈÄöÂ∏∏ÔºåÂΩ±ÂÉèÁöÑÂ§ßÈÉ®ÂàÜÂèØËÉΩ‰∏éÂΩ±ÂÉèÂàÜÊûê‰ªªÂä°Êó†ÂÖ≥„ÄÇÂú®‰ΩøÁî®Âü∫‰∫éÊ∑±Â∫¶Â≠¶‰π†ÁöÑÊñπÊ≥ïÊó∂ÔºåËøô‰ºöÂØºËá¥Âú®Êé®ÁêÜËøáÁ®ã‰∏≠‰∏çÂøÖË¶ÅÂú∞Â¢ûÂä†ËÆ°ÁÆóË¥üÊãÖÂπ∂Â¢ûÂä†Âá∫ÈîôÁöÑÂèØËÉΩÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨‰ªãÁªç‰∫Ü CTARRÔºå‰∏ÄÁßçÁî®‰∫é CT Ëß£ÂâñÂå∫ÂüüËØÜÂà´ÁöÑÈÄöÁî®Êñ∞ÊñπÊ≥ï„ÄÇËØ•ÊñπÊ≥ï‰Ωú‰∏∫‰ªª‰ΩïÂü∫‰∫éÊ∑±Â∫¶Â≠¶‰π†ÁöÑ CT ÂΩ±ÂÉèÂàÜÊûêÁÆ°ÈÅìÁöÑÈ¢ÑÂ§ÑÁêÜÊ≠•È™§ÔºåÈÄöËøáËá™Âä®ËØÜÂà´‰∏éÂêéÁª≠‰ªªÂä°Áõ∏ÂÖ≥ÁöÑÈ¢ÑÂÆö‰πâËß£ÂâñÂå∫ÂüüÂπ∂ÁßªÈô§ÂÖ∂‰ΩôÈÉ®ÂàÜ„ÄÇÂÆÉÂèØÁî®‰∫é (i) ÂΩ±ÂÉèÂàÜÂâ≤Ôºå‰ª•Èò≤Ê≠¢Âú®Ëß£Ââñ‰∏ä‰∏çÂèØËÉΩÁöÑÂå∫Âüü‰∏≠Âá∫Áé∞ÂÅáÈò≥ÊÄßÂπ∂Âä†Âø´Êé®ÁêÜÔºå(ii) ÂΩ±ÂÉèÂàÜÁ±ªÔºå‰ª•‰∫ßÁîüÂú®Ëß£ÂâñËÉåÊôØ‰∏ã‰∏ÄËá¥ÁöÑÂΩ±ÂÉèË£ÅÂâ™Ôºå‰ª•Âèä (iii) ÂΩ±ÂÉèÈÖçÂáÜÔºå‰Ωú‰∏∫Âø´ÈÄüÈ¢ÑÈÖçÂáÜÊ≠•È™§„ÄÇÊàë‰ª¨ÊèêÂá∫ÁöÑÊñπÊ≥ïÂü∫‰∫éÂõæË∞±ÈÖçÂáÜÔºåÂπ∂Êèê‰æõ‰∫Ü‰∏ÄÁßçÂø´ÈÄü‰∏îÁ®≥ÂÅ•ÁöÑÊñπÂºèÔºåÂèØ‰ª•‰ªéÂ§ßËÑë„ÄÅËÉ∏ÈÉ®„ÄÅËÖπÈÉ®Âíå/ÊàñÈ™®ÁõÜÁöÑ‰ªª‰ΩïÊú™Ê†áËÆ∞ CT Êâ´Êèè‰∏≠Ë£ÅÂâ™ÁºñÁ†Å‰∏∫‰∏Ä‰∏™ÊàñÂ§ö‰∏™ËæπÁïåÊ°ÜÁöÑ‰ªª‰ΩïËß£ÂâñÂå∫Âüü„ÄÇÊàë‰ª¨ÈÄöËøáÂú®ÂÖ≠‰∏™ÂÖ¨ÂÖ±ÂàÜÂâ≤ÊåëÊàòÊï∞ÊçÆÈõÜ‰∏äÂØπÂÖ∂ËøõË°åËØÑ‰º∞ÔºåËØÅÊòé‰∫ÜÊâÄÊèêÂá∫ÊñπÊ≥ïÂú®ÂåªÂ≠¶ÂΩ±ÂÉèÂàÜÂâ≤ÊñπÈù¢ÁöÑÂÆûÁî®ÊÄßÂíåÁ®≥ÂÅ•ÊÄß„ÄÇÂú®ÁªùÂ§ßÂ§öÊï∞ÊÉÖÂÜµ‰∏ãÂíå‰ªªÂä°‰∏≠Ôºà97.45-100%ÔºâÔºåÊÑüÂÖ¥Ë∂£Âå∫Âüü‰∏≠ÁöÑÂâçÊôØ‰ΩìÁ¥†Âæó‰ª•‰øùÁïôÔºåÂêåÊó∂‰ªÖÈúÄÂú®Ê∑±Â∫¶Â≠¶‰π†Â∑•‰ΩúÁ´ô‰∏äËä±Ë¥πÂá†ÂàÜ‰πã‰∏ÄÁßíÔºà0.1-0.21 ÁßíÔºâËøõË°åËÆ°ÁÆóÔºåÂπ∂‰∏îÊûÅÂ§ßÂú∞Áº©Áü≠‰∫ÜÂàÜÂâ≤ËøêË°åÊó∂Èó¥Ôºà2.0-12.7 ÂÄçÔºâ„ÄÇÊàë‰ª¨ÁöÑ‰ª£Á†ÅÂèØÂú® https://github.com/ThomasBudd/ctarr ‰∏äËé∑Âèñ„ÄÇ</paragraph>

##### **Multi-Omic and Quantum Machine Learning Integration for Lung Subtypes Classification**
2410.02085v1 by Mandeep Kaur Saggi, Amandeep Singh Bhatia, Mensah Isaiah, Humaira Gowher, Sabre Kais

Quantum Machine Learning (QML) is a red-hot field that brings novel
discoveries and exciting opportunities to resolve, speed up, or refine the
analysis of a wide range of computational problems. In the realm of biomedical
research and personalized medicine, the significance of multi-omics integration
lies in its ability to provide a thorough and holistic comprehension of complex
biological systems. This technology links fundamental research to clinical
practice. The insights gained from integrated omics data can be translated into
clinical tools for diagnosis, prognosis, and treatment planning. The fusion of
quantum computing and machine learning holds promise for unraveling complex
patterns within multi-omics datasets, providing unprecedented insights into the
molecular landscape of lung cancer. Due to the heterogeneity, complexity, and
high dimensionality of multi-omic cancer data, characterized by the vast number
of features (such as gene expression, micro-RNA, and DNA methylation) relative
to the limited number of lung cancer patient samples, our prime motivation for
this paper is the integration of multi-omic data, unique feature selection, and
diagnostic classification of lung subtypes: lung squamous cell carcinoma
(LUSC-I) and lung adenocarcinoma (LUAD-II) using quantum machine learning. We
developed a method for finding the best differentiating features between LUAD
and LUSC datasets, which has the potential for biomarker discovery.

ÊëòË¶ÅÔºöÈáèÂ≠êÊ©üÂô®Â≠∏Áøí (QML) ÊòØÂÄãÁÜ±ÈñÄÈ†òÂüüÔºåÂÆÉÂ∏∂‰æÜÊñ∞Á©éÁöÑÁôºÁèæÂíå‰ª§‰∫∫ËààÂ•ÆÁöÑÊ©üÊúÉÔºåÁî®ÊñºËß£Ê±∫„ÄÅÂä†ÈÄüÊàñÊîπÈÄ≤Â∞çÂêÑÁ®ÆË®àÁÆóÂïèÈ°åÁöÑÂàÜÊûê„ÄÇÂú®ÁîüÁâ©ÈÜ´Â≠∏Á†îÁ©∂ÂíåÂÄã‰∫∫ÂåñÈÜ´ÁôÇÈ†òÂüüÔºåÂ§öÁµÑÂ≠∏Êï¥ÂêàÁöÑÈáçË¶ÅÊÄßÂú®ÊñºÂÆÉËÉΩÂ§†Êèê‰æõÂ∞çË§áÈõúÁîüÁâ©Á≥ªÁµ±ÂÖ®Èù¢‰∏îÊï¥È´îÁöÑÁêÜËß£„ÄÇÈÄôÈ†ÖÊäÄË°ìÂ∞áÂü∫Á§éÁ†îÁ©∂ËàáËá®Â∫äÂØ¶ÂãôÈÄ£ÁµêËµ∑‰æÜ„ÄÇÂæûÊï¥ÂêàÁµÑÂ≠∏Ë≥áÊñô‰∏≠Áç≤ÂæóÁöÑË¶ãËß£ÂèØ‰ª•ËΩâÂåñÁÇ∫Ë®∫Êñ∑„ÄÅÈ†êÂæåÂíåÊ≤ªÁôÇË®àÁï´ÁöÑËá®Â∫äÂ∑•ÂÖ∑„ÄÇÈáèÂ≠êÈÅãÁÆóÂíåÊ©üÂô®Â≠∏ÁøíÁöÑËûçÂêàÊúâÊúõËß£ÈñãÂ§öÁµÑÂ≠∏Ë≥áÊñôÈõÜ‰∏≠ÁöÑË§áÈõúÊ®°ÂºèÔºåÊèê‰æõÂâçÊâÄÊú™ÊúâÁöÑË¶ãËß£ÔºåÊ∑±ÂÖ•‰∫ÜËß£ËÇ∫ÁôåÁöÑÂàÜÂ≠êÂ±§Èù¢„ÄÇÁî±ÊñºÂ§öÁµÑÂ≠∏ÁôåÁóáË≥áÊñôÁöÑÁï∞Ë≥™ÊÄß„ÄÅË§áÈõúÊÄßÂíåÈ´òÁ∂≠Â∫¶ÔºåÂÖ∂ÁâπÂæµÔºà‰æãÂ¶ÇÂü∫Âõ†Ë°®Áèæ„ÄÅÂæÆÂûã RNA Âíå DNA Áî≤Âü∫ÂåñÔºâÁöÑÊï∏ÈáèÁõ∏Â∞çÊñºËÇ∫ÁôåÊÇ£ËÄÖÊ®£Êú¨ÁöÑÊï∏ÈáèËÄåË®ÄÈùûÂ∏∏ÈæêÂ§ßÔºåÂõ†Ê≠§ÊàëÂÄëÊí∞ÂØ´ÈÄôÁØáË´ñÊñáÁöÑ‰∏ªË¶ÅÂãïÊ©üÊòØÊï¥ÂêàÂ§öÁµÑÂ≠∏Ë≥áÊñô„ÄÅÁç®ÁâπÁöÑÁâπÂæµÈÅ∏ÊìáÔºå‰ª•Âèä‰ΩøÁî®ÈáèÂ≠êÊ©üÂô®Â≠∏ÁøíÂ∞çËÇ∫Áôå‰∫ûÂûãÈÄ≤Ë°åË®∫Êñ∑ÂàÜÈ°ûÔºöËÇ∫È±óÁãÄÁ¥∞ËÉûÁôå (LUSC-I) ÂíåËÇ∫ËÖ∫Áôå (LUAD-II)„ÄÇÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ï‰æÜÊâæÂá∫ LUAD Âíå LUSC Ë≥áÊñôÈõÜ‰πãÈñìÊúÄ‰Ω≥ÁöÑÂçÄÂàÜÁâπÂæµÔºåÈÄôÊúâÊΩõÂäõÁî®ÊñºÁîüÁâ©Ê®ôË®òÁöÑÁôºÁèæ„ÄÇ

##### **Zodiac: A Cardiologist-Level LLM Framework for Multi-Agent Diagnostics**
2410.02026v1 by Yuan Zhou, Peng Zhang, Mengya Song, Alice Zheng, Yiwen Lu, Zhiheng Liu, Yong Chen, Zhaohan Xi

Large language models (LLMs) have demonstrated remarkable progress in
healthcare. However, a significant gap remains regarding LLMs' professionalism
in domain-specific clinical practices, limiting their application in real-world
diagnostics. In this work, we introduce ZODIAC, an LLM-powered framework with
cardiologist-level professionalism designed to engage LLMs in cardiological
diagnostics. ZODIAC assists cardiologists by extracting clinically relevant
characteristics from patient data, detecting significant arrhythmias, and
generating preliminary reports for the review and refinement by cardiologists.
To achieve cardiologist-level professionalism, ZODIAC is built on a multi-agent
collaboration framework, enabling the processing of patient data across
multiple modalities. Each LLM agent is fine-tuned using real-world patient data
adjudicated by cardiologists, reinforcing the model's professionalism. ZODIAC
undergoes rigorous clinical validation with independent cardiologists,
evaluated across eight metrics that measure clinical effectiveness and address
security concerns. Results show that ZODIAC outperforms industry-leading
models, including OpenAI's GPT-4o, Meta's Llama-3.1-405B, and Google's
Gemini-pro, as well as medical-specialist LLMs like Microsoft's BioGPT. ZODIAC
demonstrates the transformative potential of specialized LLMs in healthcare by
delivering domain-specific solutions that meet the stringent demands of medical
practice. Notably, ZODIAC has been successfully integrated into
electrocardiography (ECG) devices, exemplifying the growing trend of embedding
LLMs into Software-as-Medical-Device (SaMD).

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Âú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÂ±ïÁèæÂá∫È°ØËëóÁöÑÈÄ≤Â±ï„ÄÇÁÑ∂ËÄåÔºåLLM Âú®ÁâπÂÆöÈ†òÂüüÁöÑËá®Â∫äÂØ¶Âãô‰∏≠Â∞àÊ•≠ÊÄßÊñπÈù¢‰ªçÂ≠òÂú®È°ØËëóÂ∑ÆË∑ùÔºåÈÄôÈôêÂà∂‰∫ÜÂÆÉÂÄëÂú®ÁúüÂØ¶‰∏ñÁïåË®∫Êñ∑‰∏≠ÁöÑÊáâÁî®„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü ZODIACÔºå‰∏ÄÂÄãÁî± LLM È©ÖÂãïÁöÑÊû∂ÊßãÔºåÂÖ∑ÂÇôÂøÉËáüÁóÖÂ∞àÁßëÈÜ´Â∏´Á≠âÁ¥öÁöÑÂ∞àÊ•≠Á¥†È§äÔºåÊó®Âú®ËÆì LLM ÂèÉËàáÂøÉËáüÁóÖË®∫Êñ∑„ÄÇZODIAC ÈÄèÈÅéÂæûÊÇ£ËÄÖË≥áÊñô‰∏≠ÊèêÂèñËá®Â∫äÁõ∏ÈóúÁâπÂæµ„ÄÅÂÅµÊ∏¨È°ØËëóÂøÉÂæã‰∏çÊï¥Ôºå‰ª•ÂèäÁî¢ÁîüÂàùÊ≠•Â†±Âëä‰æõÂøÉËáüÁóÖÂ∞àÁßëÈÜ´Â∏´Ê™¢Èñ±Âíå‰øÆÊîπÔºå‰æÜÂçîÂä©ÂøÉËáüÁóÖÂ∞àÁßëÈÜ´Â∏´„ÄÇÁÇ∫‰∫ÜÈÅîÂà∞ÂøÉËáüÁóÖÂ∞àÁßëÈÜ´Â∏´Á≠âÁ¥öÁöÑÂ∞àÊ•≠Á¥†È§äÔºåZODIAC Âª∫Á´ãÂú®Â§ö‰ª£ÁêÜÂçî‰ΩúÊû∂Êßã‰∏äÔºåËÆì‰∏çÂêåÊñπÂºèÁöÑÊÇ£ËÄÖË≥áÊñôËÉΩÂ§†ËôïÁêÜ„ÄÇÊØèÂÄã LLM ‰ª£ÁêÜ‰ΩøÁî®Áî±ÂøÉËáüÁóÖÂ∞àÁßëÈÜ´Â∏´Ë£ÅÂÆöÁöÑÁúüÂØ¶‰∏ñÁïåÊÇ£ËÄÖË≥áÊñôÈÄ≤Ë°åÂæÆË™øÔºåÂº∑ÂåñÊ®°ÂûãÁöÑÂ∞àÊ•≠Á¥†È§ä„ÄÇZODIAC ÈÄ≤Ë°åÂö¥Ê†ºÁöÑËá®Â∫äÈ©óË≠âÔºåÁî±Áç®Á´ãÁöÑÂøÉËáüÁóÖÂ∞àÁßëÈÜ´Â∏´ÈÄ≤Ë°åË©ï‰º∞ÔºåË©ïÈáèÂÖ´È†ÖË°°ÈáèËá®Â∫äÊúâÊïàÊÄß‰∏¶Ëß£Ê±∫ÂÆâÂÖ®ÂïèÈ°åÁöÑÊåáÊ®ô„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåZODIAC ÁöÑË°®ÁèæÂÑ™ÊñºÊ•≠ÁïåÈ†òÂÖàÁöÑÊ®°ÂûãÔºåÂåÖÊã¨ OpenAI ÁöÑ GPT-4o„ÄÅMeta ÁöÑ Llama-3.1-405BÔºå‰ª•Âèä Google ÁöÑ Gemini-proÔºå‰ª•ÂèäÂÉè Microsoft ÁöÑ BioGPT Á≠âÈÜ´ÁôÇÂ∞àÂÆ∂ LLM„ÄÇZODIAC ÈÄèÈÅéÊèê‰æõÁ¨¶ÂêàÈÜ´ÁôÇÂØ¶ÂãôÂö¥Ê†ºË¶ÅÊ±ÇÁöÑÁâπÂÆöÈ†òÂüüËß£Ê±∫ÊñπÊ°àÔºåË≠âÊòé‰∫ÜÂ∞àÊ•≠ LLM Âú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÁöÑËÆäÈù©ÊΩõÂäõ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåZODIAC Â∑≤ÊàêÂäüÊï¥ÂêàÂà∞ÂøÉÈõªÂúñ (ECG) Ë®≠ÂÇô‰∏≠ÔºåÈÄôÈ´îÁèæ‰∫ÜÂ∞á LLM ÂµåÂÖ•ËªüÈ´îÂç≥ÈÜ´ÁôÇË®≠ÂÇô (SaMD) ÁöÑË∂®Âã¢„ÄÇ

##### **UlcerGPT: A Multimodal Approach Leveraging Large Language and Vision Models for Diabetic Foot Ulcer Image Transcription**
2410.01989v1 by Reza Basiri, Ali Abedi, Chau Nguyen, Milos R. Popovic, Shehroz S. Khan

Diabetic foot ulcers (DFUs) are a leading cause of hospitalizations and lower
limb amputations, placing a substantial burden on patients and healthcare
systems. Early detection and accurate classification of DFUs are critical for
preventing serious complications, yet many patients experience delays in
receiving care due to limited access to specialized services. Telehealth has
emerged as a promising solution, improving access to care and reducing the need
for in-person visits. The integration of artificial intelligence and pattern
recognition into telemedicine has further enhanced DFU management by enabling
automatic detection, classification, and monitoring from images. Despite
advancements in artificial intelligence-driven approaches for DFU image
analysis, the application of large language models for DFU image transcription
has not yet been explored. To address this gap, we introduce UlcerGPT, a novel
multimodal approach leveraging large language and vision models for DFU image
transcription. This framework combines advanced vision and language models,
such as Large Language and Vision Assistant and Chat Generative Pre-trained
Transformer, to transcribe DFU images by jointly detecting, classifying, and
localizing regions of interest. Through detailed experiments on a public
dataset, evaluated by expert clinicians, UlcerGPT demonstrates promising
results in the accuracy and efficiency of DFU transcription, offering potential
support for clinicians in delivering timely care via telemedicine.

ÊëòË¶ÅÔºöÁ≥ñÂ∞øÁóÖË∂≥ÊΩ∞Áòç (DFU) ÊòØÂ∞éËá¥‰ΩèÈô¢Âíå‰∏ãËÇ¢Êà™ËÇ¢ÁöÑ‰∏ªË¶ÅÂéüÂõ†ÔºåÂ∞çÊÇ£ËÄÖÂíåÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±ÈÄ†ÊàêÊ≤âÈáçË≤†Êìî„ÄÇÊó©ÊúüÁôºÁèæÂíåÊ∫ñÁ¢∫ÂàÜÈ°û DFU Â∞çÊñºÈ†êÈò≤Âö¥Èáç‰ΩµÁôºÁóáËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜË®±Â§öÊÇ£ËÄÖÂõ†ÁÑ°Ê≥ïÁç≤ÂæóÂ∞àÊ•≠ÊúçÂãôËÄåÂª∂Ë™§Â∞±ÈÜ´„ÄÇÈÅ†Ë∑ùÈÜ´ÁôÇÂ∑≤ÊàêÁÇ∫‰∏ÄÂÄãÊúâÂâçÈÄîÁöÑËß£Ê±∫ÊñπÊ°àÔºåÊîπÂñÑ‰∫ÜÂ∞±ÈÜ´ÁÆ°ÈÅì‰∏¶Ê∏õÂ∞ëË¶™Ëá™Â∞±Ë®∫ÁöÑÈúÄÊ±Ç„ÄÇÂ∞á‰∫∫Â∑•Êô∫ÊÖßÂíåÊ®°ÂºèË≠òÂà•Êï¥ÂêàÂà∞ÈÅ†Ë∑ùÈÜ´ÁôÇÈÄ≤‰∏ÄÊ≠•Â¢ûÂº∑‰∫Ü DFU ÁÆ°ÁêÜÔºåËÉΩÂæûÂΩ±ÂÉè‰∏≠Ëá™ÂãïÂÅµÊ∏¨„ÄÅÂàÜÈ°ûÂíåÁõ£Êéß„ÄÇÂÑòÁÆ°Âú®‰∫∫Â∑•Êô∫ÊÖßÈ©ÖÂãïÁöÑ DFU ÂΩ±ÂÉèÂàÜÊûêÊñπÊ≥ïÊñπÈù¢ÊúâÈÄ≤Â±ïÔºå‰ΩÜÂ∞öÊú™Êé¢Á¥¢Â∞áÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÊáâÁî®Êñº DFU ÂΩ±ÂÉèËΩâÈåÑ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü UlcerGPTÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂ§öÊ®°ÊÖãÊñπÊ≥ïÔºåÂà©Áî®Â§ßÂûãË™ûË®ÄÂíåË¶ñË¶∫Ê®°ÂûãÈÄ≤Ë°å DFU ÂΩ±ÂÉèËΩâÈåÑ„ÄÇÊ≠§Êû∂ÊßãÁµêÂêà‰∫ÜÂÖàÈÄ≤ÁöÑË¶ñË¶∫ÂíåË™ûË®ÄÊ®°ÂûãÔºå‰æãÂ¶ÇÂ§ßÂûãË™ûË®ÄÂíåË¶ñË¶∫Âä©ÁêÜ‰ª•ÂèäËÅäÂ§©ÁîüÊàêÂºèÈ†êË®ìÁ∑¥ËΩâÊèõÂô®ÔºåÈÄèÈÅéÂÖ±ÂêåÂÅµÊ∏¨„ÄÅÂàÜÈ°ûÂíåÂÆö‰ΩçÊÑüËààË∂£ÂçÄÂüü‰æÜËΩâÈåÑ DFU ÂΩ±ÂÉè„ÄÇÈÄèÈÅéÂú®ÂÖ¨ÈñãË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åË©≥Á¥∞ÂØ¶È©óÔºå‰∏¶Áî±Â∞àÂÆ∂Ëá®Â∫äÈÜ´Â∏´Ë©ï‰º∞ÔºåUlcerGPT Âú® DFU ËΩâÈåÑÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÊïàÁéáÊñπÈù¢Â±ïÁèæ‰∫ÜÊúâÂâçÊôØÁöÑÁµêÊûúÔºåÁÇ∫Ëá®Â∫äÈÜ´Â∏´ÈÄèÈÅéÈÅ†Ë∑ùÈÜ´ÁôÇÊèê‰æõÂèäÊôÇÁÖßË≠∑Êèê‰æõ‰∫ÜÊΩõÂú®ÊîØÊè¥„ÄÇ

##### **DeFine: Enhancing LLM Decision-Making with Factor Profiles and Analogical Reasoning**
2410.01772v1 by Yebowen Hu, Xiaoyang Wang, Wenlin Yao, Yiming Lu, Daoan Zhang, Hassan Foroosh, Dong Yu, Fei Liu

LLMs are ideal for decision-making due to their ability to reason over long
contexts and identify critical factors. However, challenges arise when
processing transcripts of spoken speech describing complex scenarios. These
transcripts often contain ungrammatical or incomplete sentences, repetitions,
hedging, and vagueness. For example, during a company's earnings call, an
executive might project a positive revenue outlook to reassure investors,
despite significant uncertainty regarding future earnings. It is crucial for
LLMs to incorporate this uncertainty systematically when making decisions. In
this paper, we introduce DeFine, a new framework that constructs probabilistic
factor profiles from complex scenarios. DeFine then integrates these profiles
with analogical reasoning, leveraging insights from similar past experiences to
guide LLMs in making critical decisions in novel situations. Our framework
separates the tasks of quantifying uncertainty in complex scenarios and
incorporating it into LLM decision-making. This approach is particularly useful
in fields such as medical consultations, negotiations, and political debates,
where making decisions under uncertainty is vital.

ÊëòË¶ÅÔºöLLM ÈùûÂ∏∏ÈÅ©ÂêàÁî®ÊñºÊ±∫Á≠ñÂà∂ÂÆöÔºåÂõ†ÁÇ∫ÂÆÉÂÄëËÉΩÂ§†Â∞çÈï∑ÁØáËÑàÁµ°ÈÄ≤Ë°åÊé®ÁêÜ‰∏¶ÊâæÂá∫ÈóúÈçµÂõ†Á¥†„ÄÇÁÑ∂ËÄåÔºåÂú®ËôïÁêÜÊèèËø∞Ë§áÈõúÂ†¥ÊôØÁöÑÂè£Ë™ûËΩâÈåÑÊôÇÊúÉÁî¢ÁîüÊåëÊà∞„ÄÇÈÄô‰∫õËΩâÈåÑÈÄöÂ∏∏ÂåÖÂê´‰∏çÁ¨¶ÂêàÊñáÊ≥ïÊàñ‰∏çÂÆåÊï¥ÁöÑÂè•Â≠ê„ÄÅÈáçË§á„ÄÅËø¥ÈÅøÂíåÊ®°Á≥ä„ÄÇ‰æãÂ¶ÇÔºåÂú®ÂÖ¨Âè∏ÁöÑÊî∂ÁõäÈõªË©±ÊúÉË≠∞‰∏≠Ôºå‰∏Ä‰Ωç‰∏ªÁÆ°ÂèØËÉΩÊúÉÈ†êÊ∏¨Ê≠£Èù¢ÁöÑÊî∂ÁõäÂâçÊôØ‰ª•ÂÆâÊí´ÊäïË≥á‰∫∫ÔºåÂÑòÁÆ°Â∞çÊú™‰æÜÁöÑÊî∂ÁõäÊúâÂæàÂ§ßÁöÑ‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÂ∞çÊñº LLM ‰æÜË™™ÔºåÂú®ÂÅöÊ±∫Á≠ñÊôÇÁ≥ªÁµ±ÊÄßÂú∞Á¥çÂÖ•ÈÄôÁ®Æ‰∏çÁ¢∫ÂÆöÊÄßËá≥ÈóúÈáçË¶Å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü DeFineÔºå‰∏ÄÂÄãÂæûË§áÈõúÂ†¥ÊôØÊßãÂª∫Ê©üÁéáÂõ†Â≠êËº™ÂªìÁöÑÊñ∞Êû∂Êßã„ÄÇÁÑ∂ÂæåÔºåDeFine Â∞áÈÄô‰∫õËº™ÂªìËàáÈ°ûÊØîÊé®ÁêÜÊï¥ÂêàÔºåÂà©Áî®ÈÅéÂéªÈ°û‰ººÁ∂ìÈ©ó‰∏≠ÁöÑË¶ãËß£‰æÜÂºïÂ∞é LLM Âú®Êñ∞ÊÉÖÊ≥Å‰∏≠ÂÅöÂá∫ÈóúÈçµÊ±∫Á≠ñ„ÄÇÊàëÂÄëÁöÑÊû∂ÊßãÂ∞áÈáèÂåñË§áÈõúÂ†¥ÊôØ‰∏≠ÁöÑ‰∏çÁ¢∫ÂÆöÊÄß‰ª•ÂèäÂ∞áÂÖ∂Á¥çÂÖ• LLM Ê±∫Á≠ñÂà∂ÂÆöÁöÑ‰ªªÂãôÂàÜÈñã„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂú®ÈÜ´ÁôÇË´ÆË©¢„ÄÅË´áÂà§ÂíåÊîøÊ≤ªËæØË´ñÁ≠âÈ†òÂüüÁâπÂà•ÊúâÁî®ÔºåÂú®ÈÄô‰∫õÈ†òÂüü‰∏≠ÔºåÂú®‰∏çÁ¢∫ÂÆöÊÄß‰∏ãÂÅöÂá∫Ê±∫Á≠ñËá≥ÈóúÈáçË¶Å„ÄÇ

##### **Towards a vision foundation model for comprehensive assessment of Cardiac MRI**
2410.01665v1 by Athira J Jacob, Indraneel Borgohain, Teodora Chitiboi, Puneet Sharma, Dorin Comaniciu, Daniel Rueckert

Cardiac magnetic resonance imaging (CMR), considered the gold standard for
noninvasive cardiac assessment, is a diverse and complex modality requiring a
wide variety of image processing tasks for comprehensive assessment of cardiac
morphology and function. Advances in deep learning have enabled the development
of state-of-the-art (SoTA) models for these tasks. However, model training is
challenging due to data and label scarcity, especially in the less common
imaging sequences. Moreover, each model is often trained for a specific task,
with no connection between related tasks. In this work, we introduce a vision
foundation model trained for CMR assessment, that is trained in a
self-supervised fashion on 36 million CMR images. We then finetune the model in
supervised way for 9 clinical tasks typical to a CMR workflow, across
classification, segmentation, landmark localization, and pathology detection.
We demonstrate improved accuracy and robustness across all tasks, over a range
of available labeled dataset sizes. We also demonstrate improved few-shot
learning with fewer labeled samples, a common challenge in medical image
analyses. We achieve an out-of-box performance comparable to SoTA for most
clinical tasks. The proposed method thus presents a resource-efficient, unified
framework for CMR assessment, with the potential to accelerate the development
of deep learning-based solutions for image analysis tasks, even with few
annotated data available.

ÊëòË¶ÅÔºöÂøÉËáüÁ£ÅÊåØÈÄ†ÂΩ± (CMR) Ë¢´Ë™çÁÇ∫ÊòØÈùû‰æµÂÖ•ÂºèÂøÉËáüË©ï‰º∞ÁöÑÈªÉÈáëÊ®ôÊ∫ñÔºåÊòØ‰∏ÄÁ®ÆÂ§öÊ®£‰∏îË§áÈõúÁöÑÊ®°ÂºèÔºåÈúÄË¶ÅÂêÑÁ®ÆÂΩ±ÂÉèËôïÁêÜ‰ªªÂãôÊâçËÉΩÂÖ®Èù¢Ë©ï‰º∞ÂøÉËáüÂΩ¢ÊÖãÂíåÂäüËÉΩ„ÄÇÊ∑±Â∫¶Â≠∏ÁøíÁöÑÈÄ≤Ê≠•‰ΩøÂæóÈñãÁôºÈÄô‰∫õ‰ªªÂãôÁöÑÊúÄÊñ∞ÊäÄË°ì (SoTA) Ê®°ÂûãÊàêÁÇ∫ÂèØËÉΩ„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÊï∏ÊìöÂíåÊ®ôÁ±§ÁöÑÁ®ÄÁº∫ÊÄßÔºåÁâπÂà•ÊòØÂú®‰∏çÂ∏∏Ë¶ãÁöÑÂΩ±ÂÉèÂ∫èÂàó‰∏≠ÔºåÊ®°ÂûãË®ìÁ∑¥ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊ≠§Â§ñÔºåÊØèÂÄãÊ®°ÂûãÈÄöÂ∏∏ÈáùÂ∞çÁâπÂÆö‰ªªÂãôÈÄ≤Ë°åË®ìÁ∑¥ÔºåÁõ∏Èóú‰ªªÂãô‰πãÈñìÊ≤íÊúâÈóúËÅØ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÈáùÂ∞ç CMR Ë©ï‰º∞Ë®ìÁ∑¥ÁöÑË¶ñË¶∫Âü∫Á§éÊ®°ÂûãÔºåË©≤Ê®°Âûã‰ª•Ëá™Áõ£Áù£ÁöÑÊñπÂºèÂú® 3600 Ëê¨Âºµ CMR ÂΩ±ÂÉè‰∏äÈÄ≤Ë°åË®ìÁ∑¥„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄë‰ª•Áõ£Áù£ÊñπÂºèÂæÆË™øÊ®°ÂûãÔºå‰ª•Âü∑Ë°å CMR Â∑•‰ΩúÊµÅÁ®ã‰∏≠ÂÖ∏ÂûãÁöÑ 9 È†ÖËá®Â∫ä‰ªªÂãôÔºåÂåÖÊã¨ÂàÜÈ°û„ÄÅÂàÜÂâ≤„ÄÅÊ®ôË™åÂÆö‰ΩçÂíåÁóÖÁêÜÊ™¢Ê∏¨„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂú®ÂêÑÁ®ÆÂèØÁî®ÁöÑÊ®ôÁ±§Ë≥áÊñôÈõÜÂ§ßÂ∞è‰∏≠ÔºåÊâÄÊúâ‰ªªÂãôÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÁ©©ÂÅ•ÊÄßÈÉΩÊúâÊâÄÊèêÈ´ò„ÄÇÊàëÂÄëÈÇÑÂ±ïÁ§∫‰∫ÜÂú®Ê®ôÁ±§Ê®£Êú¨ËºÉÂ∞ëÁöÑÊÉÖÊ≥Å‰∏ãÊîπÈÄ≤‰∫ÜÂ∞ëÊ®£Êú¨Â≠∏ÁøíÔºåÈÄôÊòØÂú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûê‰∏≠Â∏∏Ë¶ãÁöÑÊåëÊà∞„ÄÇÊàëÂÄëÂØ¶Áèæ‰∫ÜËàáÂ§ßÂ§öÊï∏Ëá®Â∫ä‰ªªÂãôÁöÑ SoTA Áõ∏Áï∂ÁöÑÈñãÁÆ±Âç≥Áî®ÊïàËÉΩ„ÄÇÂõ†Ê≠§ÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÊèê‰æõ‰∫Ü‰∏ÄÂÄãË≥áÊ∫êÈ´òÊïàÁöÑÁµ±‰∏ÄÊ°ÜÊû∂ÔºåÁî®Êñº CMR Ë©ï‰º∞Ôºå‰∏¶ÊúâÂèØËÉΩÂä†ÈÄüÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÂΩ±ÂÉèÂàÜÊûê‰ªªÂãôÁöÑËß£Ê±∫ÊñπÊ°àÈñãÁôºÔºåÂç≥‰ΩøÂè™ÊúâÂ∞ëÈáèÁöÑË®ªÈáãÊï∏ÊìöÂèØÁî®„ÄÇ

##### **Imaging foundation model for universal enhancement of non-ideal measurement CT**
2410.01591v1 by Yuxin Liu, Rongjun Ge, Yuting He, Zhan Wu, Chenyu You, Shuo Li, Yang Chen

Non-ideal measurement computed tomography (NICT), which sacrifices optimal
imaging standards for new advantages in CT imaging, is expanding the clinical
application scope of CT images. However, with the reduction of imaging
standards, the image quality has also been reduced, extremely limiting the
clinical acceptability. Although numerous studies have demonstrated the
feasibility of deep learning for the NICT enhancement in specific scenarios,
their high data cost and limited generalizability have become large obstacles.
The recent research on the foundation model has brought new opportunities for
building a universal NICT enhancement model - bridging the image quality
degradation with minimal data cost. However, owing to the challenges in the
collection of large pre-training datasets and the compatibility of data
variation, no success has been reported. In this paper, we propose a
multi-scale integrated Transformer AMPlifier (TAMP), the first imaging
foundation model for universal NICT enhancement. It has been pre-trained on a
large-scale physical-driven simulation dataset with 3.6 million NICT-ICT image
pairs, and is able to directly generalize to the NICT enhancement tasks with
various non-ideal settings and body regions. Via the adaptation with few data,
it can further achieve professional performance in real-world specific
scenarios. Our extensive experiments have demonstrated that the proposed TAMP
has significant potential for promoting the exploration and application of NICT
and serving a wider range of medical scenarios.

ÊëòË¶ÅÔºöÈùûÁêÜÊÉ≥Ê∏¨ÈáèÈõªËÖ¶Êñ∑Â±§ÊéÉÊèè (NICT) ÁäßÁâ≤‰∫ÜÊúÄ‰Ω≥ÂΩ±ÂÉèÊ®ôÊ∫ñ‰ª•ÊèõÂèñÈõªËÖ¶Êñ∑Â±§ÊéÉÊèèÂΩ±ÂÉèÁöÑÊñ∞ÂÑ™Âã¢ÔºåÊ≠£Âú®Êì¥Â±ïÈõªËÖ¶Êñ∑Â±§ÂΩ±ÂÉèÁöÑËá®Â∫äÊáâÁî®ÁØÑÂúç„ÄÇÁÑ∂ËÄåÔºåÈö®ËëóÂΩ±ÂÉèÊ®ôÊ∫ñÁöÑÈôç‰ΩéÔºåÂΩ±ÂÉèÂìÅË≥™‰πüÈö®‰πãÈôç‰ΩéÔºåÊ•µÂ§ßÂú∞ÈôêÂà∂‰∫ÜËá®Â∫äÂèØÊé•ÂèóÊÄß„ÄÇÂÑòÁÆ°Ë®±Â§öÁ†îÁ©∂Â∑≤Ë≠âÊòéÊ∑±Â∫¶Â≠∏ÁøíÂú®ÁâπÂÆöÂ†¥ÊôØ‰∏≠ÂèØË°åÔºå‰ΩÜÂÖ∂È´òË≥áÊñôÊàêÊú¨ÂíåÊúâÈôêÁöÑÊ¶ÇÊã¨ÊÄßÂ∑≤ÊàêÁÇ∫ÈáçÂ§ßÁöÑÈöúÁ§ô„ÄÇÊúÄËøëÂ∞çÂü∫Á§éÊ®°ÂûãÁöÑÁ†îÁ©∂ÁÇ∫Âª∫Á´ãÈÄöÁî® NICT Â¢ûÂº∑Ê®°ÂûãÂ∏∂‰æÜ‰∫ÜÊñ∞ÁöÑÊ©üÊúÉÔºå‰ª•ÊúÄÂ∞èÁöÑË≥áÊñôÊàêÊú¨ÂΩåÂêàÂΩ±ÂÉèÂìÅË≥™‰∏ãÈôçÁöÑÂïèÈ°å„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÊî∂ÈõÜÂ§ßÂûãÈ†êË®ìÁ∑¥Ë≥áÊñôÈõÜÂíåË≥áÊñôËÆäÁï∞ÁöÑÁõ∏ÂÆπÊÄßÊñπÈù¢ÁöÑÊåëÊà∞ÔºåÂ∞öÊú™Â†±ÂëäÊàêÂäü„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂ§öÂ∞∫Â∫¶Êï¥ÂêàTransformerÊîæÂ§ßÂô® (TAMP)ÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÁî®ÊñºÈÄöÁî® NICT Â¢ûÂº∑ÁöÑÂΩ±ÂÉèÂü∫Á§éÊ®°Âûã„ÄÇÂÆÉÂ∑≤Âú®‰∏ÄÂÄãÂåÖÂê´ 360 Ëê¨ÂÄã NICT-ICT ÂΩ±ÂÉèÂ∞çÁöÑÂ§ßÂûãÁâ©ÁêÜÈ©ÖÂãïÊ®°Êì¨Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÈ†êË®ìÁ∑¥Ôºå‰∏¶‰∏îËÉΩÂ§†Áõ¥Êé•Ê¶ÇÊã¨Âà∞ÂÖ∑ÊúâÂêÑÁ®ÆÈùûÁêÜÊÉ≥Ë®≠ÂÆöÂíåË∫´È´îÂçÄÂüüÁöÑ NICT Â¢ûÂº∑‰ªªÂãô„ÄÇÈÄèÈÅéÂ∞ëÊï∏Ë≥áÊñôÁöÑÈÅ©ÊáâÔºåÂÆÉÂèØ‰ª•Âú®ÁèæÂØ¶‰∏ñÁïåÁöÑÁâπÂÆöÂ†¥ÊôØ‰∏≠ÈÄ≤‰∏ÄÊ≠•ÂØ¶ÁèæÂ∞àÊ•≠ÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÂª£Ê≥õÂØ¶È©óË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑ TAMP ÂÖ∑Êúâ‰øÉÈÄ≤ NICT ÁöÑÊé¢Á¥¢ÂíåÊáâÁî®‰∏¶ÊúçÂãôÊñºÊõ¥Âª£Ê≥õÁöÑÈÜ´ÁôÇÂ†¥ÊôØÁöÑÂ∑®Â§ßÊΩõÂäõ„ÄÇ

##### **OpenMathInstruct-2: Accelerating AI for Math with Massive Open-Source Instruction Data**
2410.01560v2 by Shubham Toshniwal, Wei Du, Ivan Moshkov, Branislav Kisacanin, Alexan Ayrapetyan, Igor Gitman

Mathematical reasoning continues to be a critical challenge in large language
model (LLM) development with significant interest. However, most of the
cutting-edge progress in mathematical reasoning with LLMs has become
\emph{closed-source} due to lack of access to training data. This lack of data
access limits researchers from understanding the impact of different choices
for synthesizing and utilizing the data. With the goal of creating a
high-quality finetuning (SFT) dataset for math reasoning, we conduct careful
ablation experiments on data synthesis using the recently released
\texttt{Llama3.1} family of models. Our experiments show that: (a) solution
format matters, with excessively verbose solutions proving detrimental to SFT
performance, (b) data generated by a strong teacher outperforms equally-sized
data generated by a weak student model, (c) SFT is robust to low-quality
solutions, allowing for imprecise data filtering, and (d) question diversity is
crucial for achieving data scaling gains. Based on these insights, we create
the OpenMathInstruct-2 dataset, which consists of 14M question-solution pairs
($\approx$ 600K unique questions), making it nearly eight times larger than the
previous largest open-source math reasoning dataset. Finetuning the
\texttt{Llama-3.1-8B-Base} using OpenMathInstruct-2 outperforms
\texttt{Llama3.1-8B-Instruct} on MATH by an absolute 15.9\% (51.9\%
$\rightarrow$ 67.8\%). Finally, to accelerate the open-source efforts, we
release the code, the finetuned models, and the OpenMathInstruct-2 dataset
under a commercially permissive license.

ÊëòË¶ÅÔºö<paragraph>Êï∏Â≠∏Êé®ÁêÜÂú®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÁôºÂ±ï‰∏≠ÊåÅÁ∫åÊàêÁÇ∫‰∏ÄÈ†ÖÈóúÈçµÊåëÊà∞Ôºå‰∏¶ÂºïËµ∑Ê•µÂ§ßÁöÑËààË∂£„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÁº∫‰πèË®ìÁ∑¥Ë≥áÊñôÁöÑÂ≠òÂèñÔºåÂ§ßÂ§öÊï∏ LLM Âú®Êï∏Â≠∏Êé®ÁêÜÊñπÈù¢ÁöÑÂ∞ñÁ´ØÈÄ≤Â±ïÂ∑≤ÊàêÁÇ∫„ÄåÂ∞ÅÈñâÂéüÂßãÁ¢º„Äç„ÄÇÈÄôÁ®ÆË≥áÊñôÂ≠òÂèñÁöÑÁº∫‰πèÈôêÂà∂‰∫ÜÁ†îÁ©∂‰∫∫Âì°‰∫ÜËß£‰∏çÂêåÈÅ∏ÊìáÂ∞çÁ∂úÂêàÂíåÂà©Áî®Ë≥áÊñôÁöÑÂΩ±Èüø„ÄÇÁÇ∫‰∫ÜÂª∫Á´ã‰∏ÄÂÄãÁî®ÊñºÊï∏Â≠∏Êé®ÁêÜÁöÑÈ´òÂìÅË≥™ÂæÆË™ø (SFT) Ë≥áÊñôÈõÜÔºåÊàëÂÄë‰ΩøÁî®ÊúÄËøëÁôºÂ∏ÉÁöÑ \texttt{Llama3.1} Ê®°ÂûãÁ≥ªÂàóÂ∞çË≥áÊñôÂêàÊàêÈÄ≤Ë°å‰∫Ü‰ªîÁ¥∞ÁöÑÊ∂àËûçÂØ¶È©ó„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºö(a) Ëß£Á≠îÊ†ºÂºèÂæàÈáçË¶ÅÔºåÈÅéÊñºÂÜóÈï∑ÁöÑËß£Á≠îÊúÉÂ∞ç SFT ÊïàËÉΩÈÄ†ÊàêÊêçÂÆ≥Ôºå(b) Áî±Âº∑ËÄÅÂ∏´Áî¢ÁîüÁöÑË≥áÊñôÂÑ™ÊñºÁî±Âº±Â≠∏ÁîüÊ®°ÂûãÁî¢ÁîüÁöÑÁõ∏ÂêåÂ§ßÂ∞èË≥áÊñôÔºå(c) SFT Â∞ç‰ΩéÂìÅË≥™Ëß£Á≠îÂÖ∑ÊúâÈ≠ØÊ£íÊÄßÔºåÂÖÅË®±ÈÄ≤Ë°å‰∏çÁ≤æÁ¢∫ÁöÑË≥áÊñôÈÅéÊøæÔºå‰ª•Âèä (d) ÂïèÈ°åÁöÑÂ§öÊ®£ÊÄßÂ∞çÊñºÂØ¶ÁèæË≥áÊñôÊì¥ÂÖÖÂ¢ûÁõäËá≥ÈóúÈáçË¶Å„ÄÇÊ†πÊìöÈÄô‰∫õË¶ãËß£ÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü OpenMathInstruct-2 Ë≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´ 1400 Ëê¨ÂÄãÂïèÈ°åËß£Á≠îÂ∞çÔºàÁ¥Ñ 60 Ëê¨ÂÄãÁç®ÁâπÂïèÈ°åÔºâÔºå‰ΩøÂÖ∂Ë¶èÊ®°Âπæ‰πéÊòØ‰πãÂâçÊúÄÂ§ßÁöÑÈñãÊ∫êÊï∏Â≠∏Êé®ÁêÜË≥áÊñôÈõÜÁöÑÂÖ´ÂÄç„ÄÇ‰ΩøÁî® OpenMathInstruct-2 ÂæÆË™ø \texttt{Llama-3.1-8B-Base} Âú® MATH ‰∏äÁöÑË°®ÁèæÂÑ™Êñº \texttt{Llama3.1-8B-Instruct}ÔºåÁµïÂ∞çÂÑ™Âã¢ 15.9%Ôºà51.9% ‚Üí 67.8%Ôºâ„ÄÇÊúÄÂæåÔºåÁÇ∫‰∫ÜÂä†ÈÄüÈñãÊ∫êÂ∑•‰ΩúÔºåÊàëÂÄëÂú®ÂïÜÊ•≠Ë®±ÂèØ‰∏ãÁôºÂ∏É‰∫ÜÁ®ãÂºèÁ¢º„ÄÅÂæÆË™øÊ®°ÂûãÂíå OpenMathInstruct-2 Ë≥áÊñôÈõÜ„ÄÇ</paragraph>

##### **MedQA-CS: Benchmarking Large Language Models Clinical Skills Using an AI-SCE Framework**
2410.01553v1 by Zonghai Yao, Zihao Zhang, Chaolong Tang, Xingyu Bian, Youxia Zhao, Zhichao Yang, Junda Wang, Huixue Zhou, Won Seok Jang, Feiyun Ouyang, Hong Yu

Artificial intelligence (AI) and large language models (LLMs) in healthcare
require advanced clinical skills (CS), yet current benchmarks fail to evaluate
these comprehensively. We introduce MedQA-CS, an AI-SCE framework inspired by
medical education's Objective Structured Clinical Examinations (OSCEs), to
address this gap. MedQA-CS evaluates LLMs through two instruction-following
tasks, LLM-as-medical-student and LLM-as-CS-examiner, designed to reflect real
clinical scenarios. Our contributions include developing MedQA-CS, a
comprehensive evaluation framework with publicly available data and expert
annotations, and providing the quantitative and qualitative assessment of LLMs
as reliable judges in CS evaluation. Our experiments show that MedQA-CS is a
more challenging benchmark for evaluating clinical skills than traditional
multiple-choice QA benchmarks (e.g., MedQA). Combined with existing benchmarks,
MedQA-CS enables a more comprehensive evaluation of LLMs' clinical capabilities
for both open- and closed-source LLMs.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) ÂíåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠
ÈúÄË¶ÅÈÄ≤ÈöéÁöÑËá®Â∫äÊäÄËÉΩ (CS)Ôºå‰ΩÜÁõÆÂâçÁöÑÂü∫Ê∫ñÁÑ°Ê≥ïÂÖ®Èù¢Ë©ï‰º∞
ÈÄô‰∫õÊäÄËÉΩ„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü MedQA-CSÔºå‰∏ÄÂÄãÂèó
ÈÜ´Â≠∏ÊïôËÇ≤ÁöÑÂÆ¢ËßÄÁµêÊßãÂåñËá®Â∫äËÄÉË©¶ (OSCE) ÂïüÁôºÁöÑ AI-SCE Êû∂ÊßãÔºå‰ª•
Ëß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ù„ÄÇMedQA-CS ÈÄèÈÅéÂÖ©ÂÄãÊåá‰ª§ÈÅµÂæ™‰ªªÂãô‰æÜË©ï‰º∞ LLMÔºåLLM
ÊâÆÊºîÈÜ´Â≠∏ÁîüÂíå LLM ÊâÆÊºî CS ËÄÉÂÆòÔºåÊó®Âú®ÂèçÊò†ÁúüÂØ¶
ÁöÑËá®Â∫äÂ†¥ÊôØ„ÄÇÊàëÂÄëÁöÑË≤¢ÁçªÂåÖÊã¨ÈñãÁôº MedQA-CSÔºå‰∏ÄÂÄã
ÂåÖÂê´ÂÖ¨ÈñãÂèØÁî®Ë≥áÊñôÂíåÂ∞àÂÆ∂Ë®ªËß£ÁöÑÁ∂úÂêàË©ï‰º∞Êû∂ÊßãÔºå‰∏¶Êèê‰æõ LLM
‰ΩúÁÇ∫ CS Ë©ï‰º∞‰∏≠ÂèØÈù†Ë©ïÂàÜËÄÖÁöÑÈáèÂåñÂíåË≥™ÊÄßË©ï‰º∞„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåMedQA-CS ÊòØ
‰∏ÄÂÄãÊØîÂÇ≥Áµ±Â§öÈÅ∏È°å QA Âü∫Ê∫ñÔºà‰æãÂ¶Ç MedQAÔºâÊõ¥ÂÖ∑ÊåëÊà∞ÊÄßÁöÑËá®Â∫äÊäÄËÉΩË©ï‰º∞Âü∫Ê∫ñ„ÄÇÁµêÂêàÁèæÊúâÂü∫Ê∫ñÔºå
MedQA-CS ËÉΩÂ§†Êõ¥ÂÖ®Èù¢Âú∞Ë©ï‰º∞ LLM ÁöÑËá®Â∫äËÉΩÂäõÔºåÈÅ©Áî®ÊñºÈñãÊîæÂéüÂßãÁ¢ºÂíåÈñâÊ∫ê LLM„ÄÇ

##### **On the Convergence of FedProx with Extrapolation and Inexact Prox**
2410.01410v1 by Hanmin Li, Peter Richt√°rik

Enhancing the FedProx federated learning algorithm (Li et al., 2020) with
server-side extrapolation, Li et al. (2024a) recently introduced the FedExProx
method. Their theoretical analysis, however, relies on the assumption that each
client computes a certain proximal operator exactly, which is impractical since
this is virtually never possible to do in real settings. In this paper, we
investigate the behavior of FedExProx without this exactness assumption in the
smooth and globally strongly convex setting. We establish a general convergence
result, showing that inexactness leads to convergence to a neighborhood of the
solution. Additionally, we demonstrate that, with careful control, the adverse
effects of this inexactness can be mitigated. By linking inexactness to biased
compression (Beznosikov et al., 2023), we refine our analysis, highlighting
robustness of extrapolation to inexact proximal updates. We also examine the
local iteration complexity required by each client to achieved the required
level of inexactness using various local optimizers. Our theoretical insights
are validated through comprehensive numerical experiments.

ÊëòË¶ÅÔºöÈÄèÈÅé‰º∫ÊúçÂô®Á´ØÂ§ñÊé®Â¢ûÂº∑ FedProx ËÅØÈÇ¶Â≠∏ÁøíÊºîÁÆóÊ≥ïÔºàLi Á≠â‰∫∫Ôºå2020ÔºâÔºåLi Á≠â‰∫∫Ôºà2024aÔºâÊúÄËøëÂºïÂÖ•‰∫Ü FedExProx ÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºå‰ªñÂÄëÁöÑÁêÜË´ñÂàÜÊûê‰æùË≥¥ÊñºÊØèÂÄãÂÆ¢Êà∂Á´ØÈÉΩÁ≤æÁ¢∫Ë®àÁÆóÂá∫ÊüêÂÄãËøëÁ´ØÁÆóÂ≠êÁöÑÂÅáË®≠ÔºåÈÄôÂú®ÂØ¶ÈöõÁí∞Â¢É‰∏≠Âπæ‰πé‰∏çÂèØËÉΩÂÅöÂà∞ÔºåÂõ†Ê≠§‰∏çÂàáÂØ¶Èöõ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁ†îÁ©∂‰∫ÜÂú®Âπ≥Êªë‰∏îÂÖ®Â±ÄÂº∑Âá∏Ë®≠ÂÆö‰∏≠ÔºåÊ≤íÊúâÊ≠§Á≤æÁ¢∫Â∫¶ÂÅáË®≠ÁöÑ FedExProx Ë°åÁÇ∫„ÄÇÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÈÄöÁî®ÁöÑÊî∂ÊñÇÁµêÊûúÔºåË°®Êòé‰∏çÁ≤æÁ¢∫Â∫¶ÊúÉÂ∞éËá¥Êî∂ÊñÇÂà∞Ëß£ÁöÑÈÑ∞Âüü„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË≠âÊòéÈÄèÈÅé‰ªîÁ¥∞ÊéßÂà∂ÔºåÂèØ‰ª•Ê∏õËºïÈÄôÁ®Æ‰∏çÁ≤æÁ¢∫Â∫¶ÁöÑË≤†Èù¢ÂΩ±Èüø„ÄÇÈÄèÈÅéÂ∞á‰∏çÁ≤æÁ¢∫Â∫¶ÈÄ£ÁµêÂà∞ÊúâÂÅèÂ£ìÁ∏ÆÔºàBeznosikov Á≠â‰∫∫Ôºå2023ÔºâÔºåÊàëÂÄëÊîπÈÄ≤‰∫ÜÂàÜÊûêÔºåÂº∑Ë™øÂ§ñÊé®Â∞ç‰∏çÁ≤æÁ¢∫ËøëÁ´ØÊõ¥Êñ∞ÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÊàëÂÄëÈÇÑÁ†îÁ©∂‰∫ÜÊØèÂÄãÂÆ¢Êà∂Á´ØÈÅîÂà∞ÁöÑ‰∏çÁ≤æÁ¢∫Â∫¶ÊâÄÈúÄÁöÑÂú∞ÊñπÂèçË¶ÜÈÅãÁÆóË§áÈõúÂ∫¶Ôºå‰∏¶‰ΩøÁî®ÂêÑÁ®ÆÂú∞ÊñπÊúÄ‰Ω≥ÂåñÂô®„ÄÇÊàëÂÄëÁöÑÁêÜË´ñË¶ãËß£Â∑≤ÈÄèÈÅéÂÖ®Èù¢ÁöÑÊï∏ÂÄºÂØ¶È©óÈ©óË≠â„ÄÇ

##### **See Me and Believe Me: Causality and Intersectionality in Testimonial Injustice in Healthcare**
2410.01227v1 by Kenya S. Andrews, Mesrob I. Ohannessian, Elena Zheleva

In medical settings, it is critical that all who are in need of care are
correctly heard and understood. When this is not the case due to prejudices a
listener has, the speaker is experiencing \emph{testimonial injustice}, which,
building upon recent work, we quantify by the presence of several categories of
unjust vocabulary in medical notes. In this paper, we use FCI, a causal
discovery method, to study the degree to which certain demographic features
could lead to marginalization (e.g., age, gender, and race) by way of
contributing to testimonial injustice. To achieve this, we review physicians'
notes for each patient, where we identify occurrences of unjust vocabulary,
along with the demographic features present, and use causal discovery to build
a Structural Causal Model (SCM) relating those demographic features to
testimonial injustice. We analyze and discuss the resulting SCMs to show the
interaction of these factors and how they influence the experience of
injustice. Despite the potential presence of some confounding variables, we
observe how one contributing feature can make a person more prone to
experiencing another contributor of testimonial injustice. There is no single
root of injustice and thus intersectionality cannot be ignored. These results
call for considering more than singular or equalized attributes of who a person
is when analyzing and improving their experiences of bias and injustice. This
work is thus a first foray at using causal discovery to understand the nuanced
experiences of patients in medical settings, and its insights could be used to
guide design principles throughout healthcare, to build trust and promote
better patient care.

ÊëòË¶ÅÔºöÂú®ÈÜ´ÁôÇÂ†¥ÊôØ‰∏≠ÔºåÊâÄÊúâÈúÄË¶ÅÁÖßË≠∑ÁöÑ‰∫∫ÈÉΩËÉΩË¢´Ê≠£Á¢∫Âú∞ËÅÜËÅΩÂíåÁêÜËß£Ëá≥ÈóúÈáçË¶Å„ÄÇÁï∂ÈÄôÂõ†ÁÇ∫ËÅΩËÄÖÁöÑÂÅèË¶ãËÄåÁÑ°Ê≥ïÁôºÁîüÊôÇÔºåË™™Ë©±ËÄÖ‰æøÊúÉÁ∂ìÊ≠∑„ÄåË¶ãË≠â‰∏çÊ≠£Áæ©„ÄçÔºåËÄåÊàëÂÄëÊ†πÊìöËøëÊúüÁöÑÁ†îÁ©∂ÔºåÈÄèÈÅéÈÜ´ÁôÇÁ¥ÄÈåÑ‰∏≠Âá∫ÁèæÁöÑ‰∏çÂÖ¨Ê≠£Ë©ûÂΩôÈ°ûÂà•‰æÜÈáèÂåñË¶ãË≠â‰∏çÊ≠£Áæ©„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ΩøÁî®Âõ†ÊûúÁôºÁèæÊñπÊ≥ï FCI ‰æÜÁ†îÁ©∂Êüê‰∫õ‰∫∫Âè£ÁâπÂæµÂèØËÉΩÈÄèÈÅé‰øÉÊàêË¶ãË≠â‰∏çÊ≠£Áæ©ÔºåÈÄ≤ËÄåÂ∞éËá¥ÈÇäÁ∑£ÂåñÔºà‰æãÂ¶ÇÂπ¥ÈΩ°„ÄÅÊÄßÂà•ÂíåÁ®ÆÊóèÔºâÁöÑÁ®ãÂ∫¶„ÄÇÁÇ∫ÈÅîÊàêÊ≠§ÁõÆÁöÑÔºåÊàëÂÄëÊ™¢Ë¶ñÊØè‰ΩçÁóÖÊÇ£ÁöÑÈÜ´Â∏´Á¥ÄÈåÑÔºåÊâæÂá∫‰∏çÂÖ¨Ê≠£Ë©ûÂΩôÂá∫ÁèæÁöÑÊôÇÊ©ü‰ª•ÂèäÂ≠òÂú®ÁöÑ‰∫∫Âè£ÁâπÂæµÔºå‰∏¶‰ΩøÁî®Âõ†ÊûúÁôºÁèæÂª∫Á´ãÁµêÊßãÂõ†ÊûúÊ®°Âûã (SCM)ÔºåÂ∞áÈÄô‰∫õ‰∫∫Âè£ÁâπÂæµËàáË¶ãË≠â‰∏çÊ≠£Áæ©ÈóúËÅØËµ∑‰æÜ„ÄÇÊàëÂÄëÂàÜÊûê‰∏¶Ë®éË´ñÁî¢ÁîüÁöÑ SCMÔºå‰ª•È°ØÁ§∫ÈÄô‰∫õÂõ†Á¥†ÁöÑ‰∫§‰∫í‰ΩúÁî®Ôºå‰ª•ÂèäÂÆÉÂÄëÂ¶Ç‰ΩïÂΩ±Èüø‰∏çÊ≠£Áæ©ÁöÑÈ´îÈ©ó„ÄÇÂÑòÁÆ°Â≠òÂú®‰∏Ä‰∫õÊΩõÂú®ÁöÑÊ∑∑Ê∑ÜËÆäÂõ†ÔºåÊàëÂÄëËßÄÂØüÂà∞‰∏ÄÂÄã‰øÉÊàêÂõ†Á¥†Â¶Ç‰ΩïËÆì‰∏ÄÂÄã‰∫∫Êõ¥ÂÆπÊòìÁ∂ìÊ≠∑Âè¶‰∏ÄÂÄãË¶ãË≠â‰∏çÊ≠£Áæ©ÁöÑ‰øÉÊàêÂõ†Á¥†„ÄÇ‰∏çÊ≠£Áæ©Ê≤íÊúâÂñÆ‰∏ÄÊ†πÊ∫êÔºåÂõ†Ê≠§ÁÑ°Ê≥ïÂøΩË¶ñ‰∫§ÂèâÊÄß„ÄÇÈÄô‰∫õÁµêÊûúÂëºÁ±≤Âú®ÂàÜÊûêÂíåÊîπÂñÑ‰∫∫ÂÄëÁöÑÂÅèË¶ãÂíå‰∏çÊ≠£Áæ©È´îÈ©óÊôÇÔºåËÄÉÈáèÁöÑ‰∏çÂè™ÊòØÂÄã‰∫∫ÁöÑÂñÆ‰∏ÄÊàñÂπ≥Á≠âÂ±¨ÊÄß„ÄÇÂõ†Ê≠§ÔºåÈÄôÈ†ÖÁ†îÁ©∂ÊòØ‰ΩøÁî®Âõ†ÊûúÁôºÁèæ‰æÜ‰∫ÜËß£ÈÜ´ÁôÇÂ†¥ÊôØ‰∏≠ÁóÖÊÇ£Á¥∞ÂæÆÈ´îÈ©óÁöÑÈ¶ñÊ¨°ÂòóË©¶ÔºåËÄåÂÖ∂Ë¶ãËß£ÂèØÁî®ÊñºÂºïÂ∞éÊï¥ÂÄãÈÜ´ÁôÇ‰øùÂÅ•ÁöÑË®≠Ë®àÂéüÂâáÔºåÂª∫Á´ã‰ø°‰ªª‰∏¶‰øÉÈÄ≤Êõ¥Â•ΩÁöÑÁóÖÊÇ£ÁÖßË≠∑„ÄÇ

##### **Explainable Diagnosis Prediction through Neuro-Symbolic Integration**
2410.01855v1 by Qiuhao Lu, Rui Li, Elham Sagheb, Andrew Wen, Jinlian Wang, Liwei Wang, Jungwei W. Fan, Hongfang Liu

Diagnosis prediction is a critical task in healthcare, where timely and
accurate identification of medical conditions can significantly impact patient
outcomes. Traditional machine learning and deep learning models have achieved
notable success in this domain but often lack interpretability which is a
crucial requirement in clinical settings. In this study, we explore the use of
neuro-symbolic methods, specifically Logical Neural Networks (LNNs), to develop
explainable models for diagnosis prediction. Essentially, we design and
implement LNN-based models that integrate domain-specific knowledge through
logical rules with learnable thresholds. Our models, particularly
$M_{\text{multi-pathway}}$ and $M_{\text{comprehensive}}$, demonstrate superior
performance over traditional models such as Logistic Regression, SVM, and
Random Forest, achieving higher accuracy (up to 80.52\%) and AUROC scores (up
to 0.8457) in the case study of diabetes prediction. The learned weights and
thresholds within the LNN models provide direct insights into feature
contributions, enhancing interpretability without compromising predictive
power. These findings highlight the potential of neuro-symbolic approaches in
bridging the gap between accuracy and explainability in healthcare AI
applications. By offering transparent and adaptable diagnostic models, our work
contributes to the advancement of precision medicine and supports the
development of equitable healthcare solutions. Future research will focus on
extending these methods to larger and more diverse datasets to further validate
their applicability across different medical conditions and populations.

ÊëòË¶ÅÔºöË®∫Êñ∑È†êÊ∏¨ÊòØÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑ‰∏ÄÈ†ÖÈóúÈçµ‰ªªÂãôÔºåÂèäÊôÇ‰∏îÊ∫ñÁ¢∫Âú∞Ë≠òÂà•ÈÜ´ÁôÇÁãÄÊ≥ÅÊúÉÂ∞çÊÇ£ËÄÖÁöÑÁµêÊûúÁî¢ÁîüÈáçÂ§ßÂΩ±Èüø„ÄÇÂÇ≥Áµ±Ê©üÂô®Â≠∏ÁøíÂíåÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂ∑≤Âú®Ê≠§È†òÂüüÂèñÂæóÈ°ØËëóÊàêÂäüÔºå‰ΩÜÈÄöÂ∏∏Áº∫‰πèÂèØËß£ÈáãÊÄßÔºåÈÄôÊòØËá®Â∫äÁí∞Â¢É‰∏≠ÁöÑÈóúÈçµË¶ÅÊ±Ç„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÁ•ûÁ∂ìÁ¨¶ËôüÊñπÊ≥ïÔºåÁâπÂà•ÊòØÈÇèËºØÁ•ûÁ∂ìÁ∂≤Ë∑Ø (LNN)Ôºå‰ª•ÈñãÁôºÂèØËß£ÈáãÁöÑË®∫Êñ∑È†êÊ∏¨Ê®°Âûã„ÄÇÂü∫Êú¨‰∏äÔºåÊàëÂÄëË®≠Ë®à‰∏¶ÂØ¶‰Ωú‰∫ÜÂü∫Êñº LNN ÁöÑÊ®°ÂûãÔºåË©≤Ê®°ÂûãÈÄèÈÅéÈÇèËºØË¶èÂâáÂíåÂèØÂ≠∏ÁøíÁöÑÈñæÂÄºÊï¥ÂêàÈ†òÂüüÁâπÂÆöÁöÑÁü•Ë≠ò„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÔºåÁâπÂà•ÊòØ $M_{\text{multi-pathway}}$ Âíå $M_{\text{comprehensive}}$ÔºåË°®ÁèæÂá∫ÂÑ™ÊñºÂÇ≥Áµ±Ê®°ÂûãÔºàÂ¶ÇÈÇèËºØËø¥Ê≠∏„ÄÅSVM ÂíåÈö®Ê©üÊ£ÆÊûóÔºâÁöÑÂçìË∂äÊïàËÉΩÔºåÂú®Á≥ñÂ∞øÁóÖÈ†êÊ∏¨ÁöÑÊ°à‰æãÁ†îÁ©∂‰∏≠ÔºåÈÅîÂà∞‰∫ÜÊõ¥È´òÁöÑÊ∫ñÁ¢∫Â∫¶ÔºàÈ´òÈÅî 80.52%ÔºâÂíå AUROC ÂàÜÊï∏ÔºàÈ´òÈÅî 0.8457Ôºâ„ÄÇLNN Ê®°Âûã‰∏≠Â≠∏ÁøíÁöÑÊ¨äÈáçÂíåÈñæÂÄºÊèê‰æõ‰∫ÜÂ∞çÁâπÂæµË≤¢ÁçªÁöÑÁõ¥Êé•Ë¶ãËß£ÔºåÂ¢ûÂº∑‰∫ÜÂèØËß£ÈáãÊÄßÔºåÂêåÊôÇ‰∏çÊêçÂÆ≥È†êÊ∏¨ËÉΩÂäõ„ÄÇÈÄô‰∫õÁôºÁèæÁ™ÅÈ°Ø‰∫ÜÁ•ûÁ∂ìÁ¨¶ËôüÊñπÊ≥ïÂú®ÂΩåÂêàÈÜ´ÁôÇ‰øùÂÅ• AI ÊáâÁî®‰∏≠Ê∫ñÁ¢∫ÊÄßÂíåÂèØËß£ÈáãÊÄßÂ∑ÆË∑ùÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇÈÄèÈÅéÊèê‰æõÈÄèÊòé‰∏îÈÅ©ÊáâÊÄßÂº∑ÁöÑË®∫Êñ∑Ê®°ÂûãÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÊúâÂä©ÊñºÁ≤æÊ∫ñÈÜ´ÁôÇÁöÑÈÄ≤Ê≠•Ôºå‰∏¶ÊîØÊè¥ÂÖ¨Âπ≥ÈÜ´ÁôÇ‰øùÂÅ•Ëß£Ê±∫ÊñπÊ°àÁöÑÈñãÁôº„ÄÇÊú™‰æÜÁöÑÁ†îÁ©∂Â∞áÂ∞àÊ≥®ÊñºÂ∞áÈÄô‰∫õÊñπÊ≥ïÊì¥Â±ïÂà∞Êõ¥Â§ß‰∏îÊõ¥Â§öÊ®£ÂåñÁöÑË≥áÊñôÈõÜÔºå‰ª•ÈÄ≤‰∏ÄÊ≠•È©óË≠âÂÖ∂Âú®‰∏çÂêåÈÜ´ÁôÇÁãÄÊ≥ÅÂíå‰∫∫Áæ§‰∏≠ÁöÑÈÅ©Áî®ÊÄß„ÄÇ

##### **Heterogeneous sound classification with the Broad Sound Taxonomy and Dataset**
2410.00980v1 by Panagiota Anastasopoulou, Jessica Torrey, Xavier Serra, Frederic Font

Automatic sound classification has a wide range of applications in machine
listening, enabling context-aware sound processing and understanding. This
paper explores methodologies for automatically classifying heterogeneous sounds
characterized by high intra-class variability. Our study evaluates the
classification task using the Broad Sound Taxonomy, a two-level taxonomy
comprising 28 classes designed to cover a heterogeneous range of sounds with
semantic distinctions tailored for practical user applications. We construct a
dataset through manual annotation to ensure accuracy, diverse representation
within each class and relevance in real-world scenarios. We compare a variety
of both traditional and modern machine learning approaches to establish a
baseline for the task of heterogeneous sound classification. We investigate the
role of input features, specifically examining how acoustically derived sound
representations compare to embeddings extracted with pre-trained deep neural
networks that capture both acoustic and semantic information about sounds.
Experimental results illustrate that audio embeddings encoding acoustic and
semantic information achieve higher accuracy in the classification task. After
careful analysis of classification errors, we identify some underlying reasons
for failure and propose actions to mitigate them. The paper highlights the need
for deeper exploration of all stages of classification, understanding the data
and adopting methodologies capable of effectively handling data complexity and
generalizing in real-world sound environments.

ÊëòË¶ÅÔºöËá™ÂãïËÅ≤Èü≥ÂàÜÈ°ûÂú®Ê©üÂô®ËÅÜËÅΩ‰∏≠ÂÖ∑ÊúâÂª£Ê≥õÁöÑÊáâÁî®ÔºåÂèØÂØ¶ÁèæÊÉÖÂ¢ÉÊÑüÁü•ÁöÑËÅ≤Èü≥ËôïÁêÜÂíåÁêÜËß£„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫ÜËá™ÂãïÂàÜÈ°ûÁï∞Ë≥™ËÅ≤Èü≥ÁöÑÊñπÊ≥ïÔºåÂÖ∂ÁâπÈªûÊòØÈ°ûÂÖßËÆäÁï∞ÊÄßÈ´ò„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂‰ΩøÁî®Âª£Ê≥õËÅ≤Èü≥ÂàÜÈ°ûÊ≥ïË©ï‰º∞ÂàÜÈ°û‰ªªÂãôÔºåÂª£Ê≥õËÅ≤Èü≥ÂàÜÈ°ûÊ≥ïÊòØ‰∏ÄÁ®ÆÂÖ©Á¥öÂàÜÈ°ûÊ≥ïÔºåÂåÖÂê´ 28 ÂÄãÈ°ûÂà•ÔºåÊó®Âú®Ê∂µËìãÁØÑÂúçÂª£Ê≥õÁöÑÁï∞Ë≥™ËÅ≤Èü≥Ôºå‰∏¶ÈáùÂ∞çÂØ¶Èöõ‰ΩøÁî®ËÄÖÊáâÁî®ÈáèË∫´ÊâìÈÄ†Ë™ûÁæ©ÂçÄÂà•„ÄÇÊàëÂÄëÈÄöÈÅéÊâãÂãïË®ªËß£ÊßãÂª∫‰∏ÄÂÄãÊï∏ÊìöÈõÜÔºå‰ª•Á¢∫‰øùÊ∫ñÁ¢∫ÊÄß„ÄÅÊØèÂÄãÈ°ûÂà•‰∏≠ÁöÑÂ§öÊ®£ÊÄßË°®Á§∫ÂíåÂú®ÁèæÂØ¶‰∏ñÁïåÂ†¥ÊôØ‰∏≠ÁöÑÁõ∏ÈóúÊÄß„ÄÇÊàëÂÄëÊØîËºÉ‰∫ÜÂêÑÁ®ÆÂÇ≥Áµ±ÂíåÁèæ‰ª£Ê©üÂô®Â≠∏ÁøíÊñπÊ≥ïÔºå‰ª•Âª∫Á´ãÁï∞Ë≥™ËÅ≤Èü≥ÂàÜÈ°û‰ªªÂãôÁöÑÂü∫Á∑ö„ÄÇÊàëÂÄëÁ†îÁ©∂‰∫ÜËº∏ÂÖ•ÁâπÂæµÁöÑ‰ΩúÁî®ÔºåÁâπÂà•ËÄÉÂØü‰∫ÜÂæûËÅ≤Â≠∏Ê¥æÁîüÁöÑËÅ≤Èü≥Ë°®Á§∫Â¶Ç‰ΩïËàá‰ΩøÁî®È†êË®ìÁ∑¥Ê∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÊèêÂèñÁöÑÂµåÂÖ•ÈÄ≤Ë°åÊØîËºÉÔºåÈÄô‰∫õÁ∂≤Ë∑ØÂèØ‰ª•Êì∑ÂèñËÅ≤Èü≥ÁöÑËÅ≤Â≠∏ÂíåË™ûÁæ©Ë≥áË®ä„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÁ∑®Á¢ºËÅ≤Â≠∏ÂíåË™ûÁæ©Ë≥áË®äÁöÑÈü≥Ë®äÂµåÂÖ•Âú®ÂàÜÈ°û‰ªªÂãô‰∏≠ÂØ¶Áèæ‰∫ÜÊõ¥È´òÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÂú®‰ªîÁ¥∞ÂàÜÊûêÂàÜÈ°ûÈåØË™§ÂæåÔºåÊàëÂÄëÊâæÂá∫‰∫Ü‰∏Ä‰∫õÂ§±ÊïóÁöÑÊ†πÊú¨ÂéüÂõ†Ôºå‰∏¶ÊèêÂá∫‰∫Ü‰∏Ä‰∫õÊ∏õËºïÈÄô‰∫õÂéüÂõ†ÁöÑÊé™ÊñΩ„ÄÇÊú¨ÊñáÂº∑Ë™øÈúÄË¶ÅÂ∞çÂàÜÈ°ûÁöÑÊâÄÊúâÈöéÊÆµÈÄ≤Ë°åÊõ¥Ê∑±ÂÖ•ÁöÑÊé¢Ë®éÔºå‰∫ÜËß£Êï∏Êìö‰∏¶Êé°Áî®ËÉΩÂ§†ÊúâÊïàËôïÁêÜÊï∏ÊìöË§áÈõúÊÄß‰∏¶Âú®ÁèæÂØ¶‰∏ñÁïåËÅ≤Èü≥Áí∞Â¢É‰∏≠ÈÄ≤Ë°åÊ¶ÇÊã¨ÁöÑÊñπÊ≥ï„ÄÇ

##### **The Gradient of Health Data Privacy**
2410.00897v1 by Baihan Lin

In the era of digital health and artificial intelligence, the management of
patient data privacy has become increasingly complex, with significant
implications for global health equity and patient trust. This paper introduces
a novel "privacy gradient" approach to health data governance, offering a more
nuanced and adaptive framework than traditional binary privacy models. Our
multidimensional concept considers factors such as data sensitivity,
stakeholder relationships, purpose of use, and temporal aspects, allowing for
context-sensitive privacy protections. Through policy analyses, ethical
considerations, and case studies spanning adolescent health, integrated care,
and genomic research, we demonstrate how this approach can address critical
privacy challenges in diverse healthcare settings worldwide. The privacy
gradient model has the potential to enhance patient engagement, improve care
coordination, and accelerate medical research while safeguarding individual
privacy rights. We provide policy recommendations for implementing this
approach, considering its impact on healthcare systems, research
infrastructures, and global health initiatives. This work aims to inform
policymakers, healthcare leaders, and digital health innovators, contributing
to a more equitable, trustworthy, and effective global health data ecosystem in
the digital age.

ÊëòË¶ÅÔºöÂú®Êï∏‰ΩçÂÅ•Â∫∑Ëàá‰∫∫Â∑•Êô∫ÊÖßÁöÑÊôÇ‰ª£ÔºåÁóÖÊÇ£Ë≥áÊñôÈö±ÁßÅÁöÑÁÆ°ÁêÜËÆäÂæóË∂ä‰æÜË∂äË§áÈõúÔºåÂ∞çÂÖ®ÁêÉÁöÑÂÅ•Â∫∑ÂÖ¨Âπ≥ËàáÁóÖÊÇ£‰ø°‰ªªÊúâÈáçÂ§ßÁöÑÂΩ±Èüø„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑ„ÄåÈö±ÁßÅÊ¢ØÂ∫¶„ÄçÊñπÊ≥ï‰æÜÁÆ°ÁêÜÂÅ•Â∫∑Ë≥áÊñôÔºåÊèê‰æõÊØîÂÇ≥Áµ±‰∫åÂÖÉÈö±ÁßÅÊ®°ÂûãÊõ¥Á¥∞Á∑ª‰∏îÊõ¥ÂÖ∑ÈÅ©ÊáâÊÄßÁöÑÊû∂Êßã„ÄÇÊàëÂÄëÁöÑÂ§öÈù¢ÂêëÊ¶ÇÂøµËÄÉÈáè‰∫ÜË≥áÊñôÊïèÊÑüÂ∫¶„ÄÅÂà©ÂÆ≥Èóú‰øÇ‰∫∫ÁöÑÈóú‰øÇ„ÄÅ‰ΩøÁî®ÁõÆÁöÑÂíåÊôÇÈñìÈù¢ÂêëÁ≠âÂõ†Á¥†ÔºåÂÖÅË®±ÈáùÂ∞çËÑàÁµ°ÊïèÊÑüÁöÑÈö±ÁßÅ‰øùË≠∑„ÄÇÈÄèÈÅéÊîøÁ≠ñÂàÜÊûê„ÄÅÂÄ´ÁêÜËÄÉÈáèÔºå‰ª•ÂèäÊ∂µËìãÈùíÂ∞ëÂπ¥ÂÅ•Â∫∑„ÄÅÊï¥ÂêàÁÖßË≠∑ÂíåÂü∫Âõ†ÁµÑÁ†îÁ©∂ÁöÑÊ°à‰æãÁ†îÁ©∂ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊ≠§ÊñπÊ≥ïÂ¶Ç‰ΩïËß£Ê±∫ÂÖ®ÁêÉ‰∏çÂêåÈÜ´ÁôÇ‰øùÂÅ•Áí∞Â¢É‰∏≠ÁöÑÈóúÈçµÈö±ÁßÅÊåëÊà∞„ÄÇÈö±ÁßÅÊ¢ØÂ∫¶Ê®°ÂûãÊúâÊΩõÂäõÊèêÂçáÁóÖÊÇ£ÂèÉËàá„ÄÅÊîπÂñÑÁÖßË≠∑ÂçîË™øÔºå‰ª•ÂèäÂä†ÈÄüÈÜ´Â≠∏Á†îÁ©∂ÔºåÂêåÊôÇ‰øùÈöúÂÄãÈ´îÁöÑÈö±ÁßÅÊ¨ä„ÄÇÊàëÂÄëÊèê‰æõÂØ¶ÊñΩÊ≠§ÊñπÊ≥ïÁöÑÊîøÁ≠ñÂª∫Ë≠∞ÔºåËÄÉÈáèÂÖ∂Â∞çÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±„ÄÅÁ†îÁ©∂Âü∫Á§éË®≠ÊñΩÂíåÂÖ®ÁêÉÂÅ•Â∫∑Ë®àÁï´ÁöÑÂΩ±Èüø„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊó®Âú®Êèê‰æõË≥áË®äÁµ¶ÊîøÁ≠ñÂà∂ÂÆöËÄÖ„ÄÅÈÜ´ÁôÇ‰øùÂÅ•È†òÂ∞éËÄÖÂíåÊï∏‰ΩçÂÅ•Â∫∑ÂâµÊñ∞ËÄÖÔºåÂú®Êï∏‰ΩçÊôÇ‰ª£‰∏≠‰øÉÊàêÊõ¥ÂÖ¨Âπ≥„ÄÅÊõ¥ÂÄºÂæó‰ø°Ë≥¥‰∏îÊõ¥ÊúâÊïàÁöÑÂÖ®ÁêÉÂÅ•Â∫∑Ë≥áÊñôÁîüÊÖãÁ≥ªÁµ±„ÄÇ

##### **GAMMA-PD: Graph-based Analysis of Multi-Modal Motor Impairment Assessments in Parkinson's Disease**
2410.00944v1 by Favour Nerrise, Alice Louise Heiman, Ehsan Adeli

The rapid advancement of medical technology has led to an exponential
increase in multi-modal medical data, including imaging, genomics, and
electronic health records (EHRs). Graph neural networks (GNNs) have been widely
used to represent this data due to their prominent performance in capturing
pairwise relationships. However, the heterogeneity and complexity of
multi-modal medical data still pose significant challenges for standard GNNs,
which struggle with learning higher-order, non-pairwise relationships. This
paper proposes GAMMA-PD (Graph-based Analysis of Multi-modal Motor Impairment
Assessments in Parkinson's Disease), a novel heterogeneous hypergraph fusion
framework for multi-modal clinical data analysis. GAMMA-PD integrates imaging
and non-imaging data into a "hypernetwork" (patient population graph) by
preserving higher-order information and similarity between patient profiles and
symptom subtypes. We also design a feature-based attention-weighted mechanism
to interpret feature-level contributions towards downstream decision tasks. We
evaluate our approach with clinical data from the Parkinson's Progression
Markers Initiative (PPMI) and a private dataset. We demonstrate gains in
predicting motor impairment symptoms in Parkinson's disease. Our end-to-end
framework also learns associations between subsets of patient characteristics
to generate clinically relevant explanations for disease and symptom profiles.
The source code is available at https://github.com/favour-nerrise/GAMMA-PD.

ÊëòË¶ÅÔºöÈÜ´ÁôÇÊäÄË°ìÁöÑÂø´ÈÄüÈÄ≤Ê≠•Â∞éËá¥Â§öÊ®°ÂºèÈÜ´ÁôÇË≥áÊñôÂëàÊåáÊï∏ÊàêÈï∑ÔºåÂåÖÊã¨ÂΩ±ÂÉè„ÄÅÂü∫Âõ†ÁµÑÂ≠∏ÂíåÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR)„ÄÇÂúñÂΩ¢Á•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) Âõ†ÂÖ∂Âú®ÊçïÊçâÊàêÂ∞çÈóú‰øÇ‰∏äÁöÑÂá∫Ëâ≤Ë°®ÁèæËÄåË¢´Âª£Ê≥õÁî®ÊñºË°®Á§∫ÈÄô‰∫õË≥áÊñô„ÄÇÁÑ∂ËÄåÔºåÂ§öÊ®°ÂºèÈÜ´ÁôÇË≥áÊñôÁöÑÁï∞Ë≥™ÊÄßÂíåË§áÈõúÊÄßÂ∞çÊ®ôÊ∫ñ GNN ‰æÜË™™‰ªçÁÑ∂ÊßãÊàêÈáçÂ§ßÊåëÊà∞ÔºåËÄå GNN Èõ£‰ª•Â≠∏ÁøíÈ´òÈöé„ÄÅÈùûÊàêÂ∞çÈóú‰øÇ„ÄÇÊú¨ÊñáÊèêÂá∫ GAMMA-PDÔºàÂü∫ÊñºÂúñÂΩ¢ÂàÜÊûêÂ∏ïÈáëÊ£ÆÊ∞èÁóáÂ§öÊ®°ÂºèÈÅãÂãïÈöúÁ§ôË©ï‰º∞ÔºâÔºå‰∏ÄÂÄãÁî®ÊñºÂ§öÊ®°ÂºèËá®Â∫äË≥áÊñôÂàÜÊûêÁöÑÊñ∞ÂûãÁï∞Ë≥™Ë∂ÖÂúñËûçÂêàÊû∂Êßã„ÄÇGAMMA-PD ÈÄèÈÅé‰øùÁïôÈ´òÈöéË≥áË®äÂíåÊÇ£ËÄÖÁâπÂæµËàáÁóáÁãÄÂ≠êÈ°ûÂûã‰πãÈñìÁöÑÁõ∏‰ººÊÄßÔºåÂ∞áÂΩ±ÂÉèÂíåÈùûÂΩ±ÂÉèË≥áÊñôÊï¥ÂêàÂà∞„ÄåË∂ÖÁ∂≤Ë∑Ø„ÄçÔºàÊÇ£ËÄÖÊóèÁæ§ÂúñÔºâ‰∏≠„ÄÇÊàëÂÄëÈÇÑË®≠Ë®à‰∫Ü‰∏ÄÂÄãÂü∫ÊñºÁâπÂæµÁöÑÊ≥®ÊÑèÂäõÂä†Ê¨äÊ©üÂà∂Ôºå‰ª•Ëß£ÈáãÁâπÂæµÂ±§Á¥öÁöÑË≤¢ÁçªÂ∞ç‰∏ãÊ∏∏Ê±∫Á≠ñ‰ªªÂãôÁöÑÂΩ±Èüø„ÄÇÊàëÂÄë‰ΩøÁî®Â∏ïÈáëÊ£ÆÊ∞èÁóáÈÄ≤Â±ïÊ®ôË®òË®àÁï´ (PPMI) ÁöÑËá®Â∫äË≥áÊñôÂíå‰∏ÄÂÄãÁßÅ‰∫∫Ë≥áÊñôÈõÜ‰æÜË©ï‰º∞ÊàëÂÄëÁöÑÂÅöÊ≥ï„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂú®È†êÊ∏¨Â∏ïÈáëÊ£ÆÊ∞èÁóáÈÅãÂãïÈöúÁ§ôÁóáÁãÄÊñπÈù¢ÁöÑÈÄ≤Â±ï„ÄÇÊàëÂÄëÁöÑÁ´ØÂ∞çÁ´ØÊû∂Êßã‰πüÂ≠∏ÁøíÊÇ£ËÄÖÁâπÂæµÂ≠êÈõÜ‰πãÈñìÁöÑÈóúËÅØÔºå‰ª•Áî¢ÁîüÂ∞çÁñæÁóÖÂíåÁóáÁãÄÁâπÂæµÂÖ∑ÊúâËá®Â∫äÊÑèÁæ©ÁöÑËß£Èáã„ÄÇÂéüÂßãÁ¢ºÂèØÂú® https://github.com/favour-nerrise/GAMMA-PD ÂèñÂæó„ÄÇ

##### **Contrastive Abstraction for Reinforcement Learning**
2410.00704v1 by Vihang Patil, Markus Hofmarcher, Elisabeth Rumetshofer, Sepp Hochreiter

Learning agents with reinforcement learning is difficult when dealing with
long trajectories that involve a large number of states. To address these
learning problems effectively, the number of states can be reduced by abstract
representations that cluster states. In principle, deep reinforcement learning
can find abstract states, but end-to-end learning is unstable. We propose
contrastive abstraction learning to find abstract states, where we assume that
successive states in a trajectory belong to the same abstract state. Such
abstract states may be basic locations, achieved subgoals, inventory, or health
conditions. Contrastive abstraction learning first constructs clusters of state
representations by contrastive learning and then applies modern Hopfield
networks to determine the abstract states. The first phase of contrastive
abstraction learning is self-supervised learning, where contrastive learning
forces states with sequential proximity to have similar representations. The
second phase uses modern Hopfield networks to map similar state representations
to the same fixed point, i.e.\ to an abstract state. The level of abstraction
can be adjusted by determining the number of fixed points of the modern
Hopfield network. Furthermore, \textit{contrastive abstraction learning} does
not require rewards and facilitates efficient reinforcement learning for a wide
range of downstream tasks. Our experiments demonstrate the effectiveness of
contrastive abstraction learning for reinforcement learning.

ÊëòË¶ÅÔºö‰ΩøÁî®Âº∑ÂåñÂ≠∏ÁøíÁöÑÂ≠∏Áøí‰ª£ÁêÜÂú®ËôïÁêÜÂåÖÂê´Â§ßÈáèÁãÄÊÖãÁöÑÈï∑ËªåË∑°ÊôÇÂæàÂõ∞Èõ£„ÄÇÁÇ∫‰∫ÜÊúâÊïàËß£Ê±∫ÈÄô‰∫õÂ≠∏ÁøíÂïèÈ°åÔºåÂèØ‰ª•ÈÄèÈÅéÂ∞áÁãÄÊÖãÂàÜÁæ§ÁöÑÊäΩË±°Ë°®Á§∫‰æÜÊ∏õÂ∞ëÁãÄÊÖãÊï∏Èáè„ÄÇÂéüÂâá‰∏äÔºåÊ∑±Â∫¶Âº∑ÂåñÂ≠∏ÁøíÂèØ‰ª•ÊâæÂà∞ÊäΩË±°ÁãÄÊÖãÔºå‰ΩÜÁ´ØÂà∞Á´ØÂ≠∏ÁøíÊòØ‰∏çÁ©©ÂÆöÁöÑ„ÄÇÊàëÂÄëÊèêÂá∫Â∞çÊØîÊäΩË±°Â≠∏Áøí‰æÜÂ∞ãÊâæÊäΩË±°ÁãÄÊÖãÔºåÊàëÂÄëÂÅáË®≠ËªåË∑°‰∏≠ÁöÑÈÄ£Á∫åÁãÄÊÖãÂ±¨ÊñºÂêå‰∏ÄÂÄãÊäΩË±°ÁãÄÊÖã„ÄÇÈÄôÊ®£ÁöÑÊäΩË±°ÁãÄÊÖãÂèØËÉΩÊòØÂü∫Êú¨‰ΩçÁΩÆ„ÄÅÂ∑≤ÈÅîÊàêÁöÑÂ≠êÁõÆÊ®ô„ÄÅÂ∫´Â≠òÊàñÂÅ•Â∫∑ÁãÄÊ≥Å„ÄÇÂ∞çÊØîÊäΩË±°Â≠∏ÁøíÈ¶ñÂÖàÈÄèÈÅéÂ∞çÊØîÂ≠∏ÁøíÂª∫ÊßãÁãÄÊÖãË°®Á§∫ÁöÑÁæ§ÈõÜÔºåÁÑ∂ÂæåÊáâÁî®Áèæ‰ª£ Hopfield Á∂≤Ë∑Ø‰æÜÁ¢∫ÂÆöÊäΩË±°ÁãÄÊÖã„ÄÇÂ∞çÊØîÊäΩË±°Â≠∏ÁøíÁöÑÁ¨¨‰∏ÄÈöéÊÆµÊòØËá™ÊàëÁõ£Áù£Â≠∏ÁøíÔºåÂÖ∂‰∏≠Â∞çÊØîÂ≠∏ÁøíÊúÉÂº∑Âà∂ÂÖ∑ÊúâÈ†ÜÂ∫èÊé•ËøëÊÄßÁöÑÁãÄÊÖãÂÖ∑ÊúâÁõ∏‰ººÁöÑË°®Á§∫„ÄÇÁ¨¨‰∫åÈöéÊÆµ‰ΩøÁî®Áèæ‰ª£ Hopfield Á∂≤Ë∑ØÂ∞áÁõ∏‰ººÁöÑÁãÄÊÖãË°®Á§∫Â∞çÊáâÂà∞Âêå‰∏ÄÂÄãÂÆöÈªûÔºåÂç≥ÊäΩË±°ÁãÄÊÖã„ÄÇÊäΩË±°Â±§Á¥öÂèØ‰ª•ÈÄèÈÅéÁ¢∫ÂÆöÁèæ‰ª£ Hopfield Á∂≤Ë∑ØÁöÑÂÆöÈªûÊï∏Èáè‰æÜË™øÊï¥„ÄÇÊ≠§Â§ñÔºåÂ∞çÊØîÊäΩË±°Â≠∏Áøí‰∏çÈúÄË¶ÅÁçéÂãµÔºå‰∏¶‰øÉÈÄ≤ÂêÑÁ®Æ‰∏ãÊ∏∏‰ªªÂãôÁöÑÊúâÊïàÂº∑ÂåñÂ≠∏Áøí„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË≠âÊòé‰∫ÜÂ∞çÊØîÊäΩË±°Â≠∏ÁøíÂ∞çÊñºÂº∑ÂåñÂ≠∏ÁøíÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Arges: Spatio-Temporal Transformer for Ulcerative Colitis Severity Assessment in Endoscopy Videos**
2410.00536v1 by Krishna Chaitanya, Pablo F. Damasceno, Shreyas Fadnavis, Pooya Mobadersany, Chaitanya Parmar, Emily Scherer, Natalia Zemlianskaia, Lindsey Surace, Louis R. Ghanem, Oana Gabriela Cula, Tommaso Mansi, Kristopher Standish

Accurate assessment of disease severity from endoscopy videos in ulcerative
colitis (UC) is crucial for evaluating drug efficacy in clinical trials.
Severity is often measured by the Mayo Endoscopic Subscore (MES) and Ulcerative
Colitis Endoscopic Index of Severity (UCEIS) score. However, expert MES/UCEIS
annotation is time-consuming and susceptible to inter-rater variability,
factors addressable by automation. Automation attempts with frame-level labels
face challenges in fully-supervised solutions due to the prevalence of
video-level labels in clinical trials. CNN-based weakly-supervised models (WSL)
with end-to-end (e2e) training lack generalization to new disease scores and
ignore spatio-temporal information crucial for accurate scoring. To address
these limitations, we propose "Arges", a deep learning framework that utilizes
a transformer with positional encoding to incorporate spatio-temporal
information from frame features to estimate disease severity scores in
endoscopy video. Extracted features are derived from a foundation model
(ArgesFM), pre-trained on a large diverse dataset from multiple clinical trials
(61M frames, 3927 videos). We evaluate four UC disease severity scores,
including MES and three UCEIS component scores. Test set evaluation indicates
significant improvements, with F1 scores increasing by 4.1% for MES and 18.8%,
6.6%, 3.8% for the three UCEIS component scores compared to state-of-the-art
methods. Prospective validation on previously unseen clinical trial data
further demonstrates the model's successful generalization.

ÊëòË¶ÅÔºö<paragraph>Âú®ÊΩ∞ÁòçÊÄßÁµêËÖ∏ÁÇé (UC) ‰∏≠ÔºåÊ∫ñÁ¢∫Ë©ï‰º∞ÂÖßË¶ñÈè°Ë¶ñÈ†ª‰∏≠ÁöÑÁñæÁóÖÂö¥ÈáçÁ®ãÂ∫¶Â∞çÊñºË©ï‰º∞Ëá®Â∫äË©¶È©ó‰∏≠ÁöÑËó•Áâ©ÁôÇÊïàËá≥ÈóúÈáçË¶Å„ÄÇÂö¥ÈáçÁ®ãÂ∫¶ÈÄöÂ∏∏ÈÄöÈÅé Mayo ÂÖßË¶ñÈè°‰∫ûÂàÜÊï∏ (MES) ÂíåÊΩ∞ÁòçÊÄßÁµêËÖ∏ÁÇéÂÖßË¶ñÈè°Âö¥ÈáçÁ®ãÂ∫¶ÊåáÊï∏ (UCEIS) ÂàÜÊï∏‰æÜË°°Èáè„ÄÇÁÑ∂ËÄåÔºåÂ∞àÂÆ∂ MES/UCEIS Ê≥®ÈáãÊó¢Ë≤ªÊôÇÂèàÂÆπÊòìÂèóÂà∞Ë©ïÂàÜËÄÖÈñìËÆäÁï∞ÊÄßÁöÑÂΩ±ÈüøÔºåËÄåËá™ÂãïÂåñÂèØ‰ª•Ëß£Ê±∫ÈÄô‰∫õÂõ†Á¥†„ÄÇÁî±ÊñºËá®Â∫äË©¶È©ó‰∏≠Ë¶ñÈ†ªÁ¥öÂà•Ê®ôÁ±§ÁöÑÊôÆÈÅçÂ≠òÂú®Ôºå‰ΩøÁî®ÂπÄÁ¥öÊ®ôÁ±§ÁöÑËá™ÂãïÂåñÂòóË©¶Âú®ÂÆåÂÖ®Áõ£Áù£ÁöÑËß£Ê±∫ÊñπÊ°à‰∏≠Èù¢Ëá®ÊåëÊà∞„ÄÇÂÖ∑ÊúâÁ´ØÂà∞Á´Ø (e2e) Ë®ìÁ∑¥ÁöÑÂü∫Êñº CNN ÁöÑÂº±Áõ£Áù£Ê®°Âûã (WSL) Áº∫‰πèÂ∞çÊñ∞ÁñæÁóÖË©ïÂàÜÁöÑÊ≥õÂåñÔºå‰∏¶‰∏îÂøΩË¶ñ‰∫ÜÂ∞çÊ∫ñÁ¢∫Ë©ïÂàÜËá≥ÈóúÈáçË¶ÅÁöÑÊôÇÁ©∫‰ø°ÊÅØ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü„ÄåArges„ÄçÔºåÈÄôÊòØ‰∏ÄÂÄãÊ∑±Â∫¶Â≠∏ÁøíÊ°ÜÊû∂ÔºåÂÆÉÂà©Áî®ÂÖ∑Êúâ‰ΩçÁΩÆÁ∑®Á¢ºÁöÑTransformerÂ∞áÊôÇÁ©∫‰ø°ÊÅØÂæûÂπÄÁâπÂæµ‰∏≠ÊèêÂèñÂá∫‰æÜÔºå‰ª•‰º∞Ë®àÂÖßË¶ñÈè°Ë¶ñÈ†ª‰∏≠ÁöÑÁñæÁóÖÂö¥ÈáçÁ®ãÂ∫¶Ë©ïÂàÜ„ÄÇÊèêÂèñÁöÑÁâπÂæµ‰æÜËá™Âü∫Á§éÊ®°Âûã (ArgesFM)ÔºåË©≤Ê®°ÂûãÂú®‰æÜËá™Â§öÂÄãËá®Â∫äË©¶È©óÁöÑÂ§ßÂûãÂ§öÊ®£ÂåñÊï∏ÊìöÈõÜÔºà6100 Ëê¨ÂπÄÔºå3927 ÂÄãË¶ñÈ†ªÔºâ‰∏äÈÄ≤Ë°å‰∫ÜÈ†êË®ìÁ∑¥„ÄÇÊàëÂÄëË©ï‰º∞‰∫ÜÂõõÂÄã UC ÁñæÁóÖÂö¥ÈáçÁ®ãÂ∫¶Ë©ïÂàÜÔºåÂåÖÊã¨ MES Âíå‰∏âÂÄã UCEIS ÁµÑÊàêÈÉ®ÂàÜË©ïÂàÜ„ÄÇÊ∏¨Ë©¶ÈõÜË©ï‰º∞Ë°®ÊòéÊúâÈ°ØËëóÊîπÂñÑÔºåËàáÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåMES ÁöÑ F1 ÂàÜÊï∏ÊèêÈ´ò‰∫Ü 4.1%Ôºå‰∏âÂÄã UCEIS ÁµÑÊàêÈÉ®ÂàÜË©ïÂàÜÁöÑ F1 ÂàÜÊï∏ÂàÜÂà•ÊèêÈ´ò‰∫Ü 18.8%„ÄÅ6.6% Âíå 3.8%„ÄÇÂú®‰ª•ÂâçÊú™Ë¶ãÁöÑËá®Â∫äË©¶È©óÊï∏Êìö‰∏äÁöÑÂâçÁûªÊÄßÈ©óË≠âÈÄ≤‰∏ÄÊ≠•Ë≠âÊòé‰∫ÜË©≤Ê®°ÂûãÊàêÂäüÁöÑÊ≥õÂåñ„ÄÇ</paragraph>

##### **Bayes-CATSI: A variational Bayesian deep learning framework for medical time series data imputation**
2410.01847v2 by Omkar Kulkarni, Rohitash Chandra

Medical time series datasets feature missing values that need data imputation
methods, however, conventional machine learning models fall short due to a lack
of uncertainty quantification in predictions. Among these models, the CATSI
(Context-Aware Time Series Imputation) stands out for its effectiveness by
incorporating a context vector into the imputation process, capturing the
global dependencies of each patient. In this paper, we propose a Bayesian
Context-Aware Time Series Imputation (Bayes-CATSI) framework which leverages
uncertainty quantification offered by variational inference. We consider the
time series derived from electroencephalography (EEG), electrooculography
(EOG), electromyography (EMG), electrocardiology (EKG). Variational Inference
assumes the shape of the posterior distribution and through minimization of the
Kullback-Leibler(KL) divergence it finds variational densities that are closest
to the true posterior distribution. Thus , we integrate the variational
Bayesian deep learning layers into the CATSI model. Our results show that
Bayes-CATSI not only provides uncertainty quantification but also achieves
superior imputation performance compared to the CATSI model. Specifically, an
instance of Bayes-CATSI outperforms CATSI by 9.57 %. We provide an open-source
code implementation for applying Bayes-CATSI to other medical data imputation
problems.

ÊëòË¶ÅÔºöÈÜ´ÁôÇÊôÇÈñìÂ∫èÂàóË≥áÊñôÈõÜÁâπÂæµÊúâÈÅ∫Â§±ÂÄºÔºåÈúÄË¶ÅË≥áÊñô‰º∞Ë®àÊñπÊ≥ïÔºåÁÑ∂ËÄåÔºåÂÇ≥Áµ±ÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÁî±ÊñºÁº∫‰πèÈ†êÊ∏¨‰∏≠ÁöÑ‰∏çÁ¢∫ÂÆöÈáèÂåñËÄå‰∏çË∂≥„ÄÇÂú®ÈÄô‰∫õÊ®°Âûã‰∏≠ÔºåCATSIÔºàÊÉÖÂ¢ÉÊÑüÁü•ÊôÇÈñìÂ∫èÂàó‰º∞Ë®àÔºâÂõ†ÂÖ∂Â∞áÊÉÖÂ¢ÉÂêëÈáèÁ¥çÂÖ•‰º∞Ë®àÈÅéÁ®ã‰∏≠ËÄåËÑ´Á©éËÄåÂá∫ÔºåÊçïÊçâÊØèÂÄãÁóÖ‰∫∫ÁöÑÊï¥È´î‰æùË≥¥ÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãË≤ùÊ∞èÊÉÖÂ¢ÉÊÑüÁü•ÊôÇÈñìÂ∫èÂàó‰º∞Ë®àÔºàBayes-CATSIÔºâÊû∂ÊßãÔºåÂÆÉÂà©Áî®ËÆäÁï∞Êé®Ë´ñÊèê‰æõÁöÑÊú™Á¢∫ÂÆöÈáèÂåñ„ÄÇÊàëÂÄëËÄÉÊÖÆ‰æÜËá™ËÖ¶ÈõªÂúñÔºàEEGÔºâ„ÄÅÁúºÂãïÂúñÔºàEOGÔºâ„ÄÅËÇåÈõªÂúñÔºàEMGÔºâ„ÄÅÂøÉÈõªÂúñÔºàEKGÔºâÁöÑÊôÇÈñìÂ∫èÂàó„ÄÇËÆäÁï∞Êé®Ë´ñÂÅáË®≠ÂæåÈ©óÂàÜÈÖçÁöÑÂΩ¢ÁãÄÔºå‰∏¶ÈÄöÈÅéÊúÄÂ∞èÂåñ Kullback-LeiblerÔºàKLÔºâÊï£Â∫¶ÔºåÂÆÉÊâæÂá∫ÊúÄÊé•ËøëÁúüÂØ¶ÂæåÈ©óÂàÜÈÖçÁöÑËÆäÁï∞ÂØÜÂ∫¶„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂ∞áËÆäÁï∞Ë≤ùÊ∞èÊ∑±Â∫¶Â≠∏ÁøíÂ±§Êï¥ÂêàÂà∞ CATSI Ê®°Âûã‰∏≠„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåBayes-CATSI ‰∏çÂÉÖÊèê‰æõ‰∏çÁ¢∫ÂÆöÊÄßÈáèÂåñÔºåËÄå‰∏îËàá CATSI Ê®°ÂûãÁõ∏ÊØîÔºåÈÇÑÂØ¶Áèæ‰∫ÜÂçìË∂äÁöÑ‰º∞Ë®àÊÄßËÉΩ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåBayes-CATSI ÁöÑ‰∏ÄÂÄãÂØ¶‰æãÊØî CATSI È´òÂá∫ 9.57%„ÄÇÊàëÂÄëÊèê‰æõ‰∏ÄÂÄãÈñãÊ∫êÁ®ãÂºèÁ¢ºÂØ¶‰ΩúÔºåÂ∞á Bayes-CATSI ÊáâÁî®ÊñºÂÖ∂‰ªñÈÜ´ÁôÇË≥áÊñô‰º∞Ë®àÂïèÈ°å„ÄÇ

##### **ReXplain: Translating Radiology into Patient-Friendly Video Reports**
2410.00441v1 by Luyang Luo, Jenanan Vairavamurthy, Xiaoman Zhang, Abhinav Kumar, Ramon R. Ter-Oganesyan, Stuart T. Schroff, Dan Shilo, Rydhwana Hossain, Mike Moritz, Pranav Rajpurkar

Radiology reports often remain incomprehensible to patients, undermining
patient-centered care. We present ReXplain (Radiology eXplanation), an
innovative AI-driven system that generates patient-friendly video reports for
radiology findings. ReXplain uniquely integrates a large language model for
text simplification, an image segmentation model for anatomical region
identification, and an avatar generation tool, producing comprehensive
explanations with plain language, highlighted imagery, and 3D organ renderings.
Our proof-of-concept study with five board-certified radiologists indicates
that ReXplain could accurately deliver radiological information and effectively
simulate one-on-one consultations. This work demonstrates a new paradigm in
AI-assisted medical communication, potentially improving patient engagement and
satisfaction in radiology care, and opens new avenues for research in
multimodal medical communication.

ÊëòË¶ÅÔºöÊîæÂ∞ÑÁßëÂ†±ÂëäÈÄöÂ∏∏‰ª§ÊÇ£ËÄÖÈõ£‰ª•ÁêÜËß£ÔºåÁ†¥Â£û‰∫Ü‰ª•ÊÇ£ËÄÖÁÇ∫‰∏≠ÂøÉÁöÑÁÖßË≠∑„ÄÇÊàëÂÄëÊèêÂá∫ ReXplainÔºàÊîæÂ∞ÑÁßëËß£ÈáãÔºâÔºå‰∏ÄÂÄãÂâµÊñ∞ÁöÑ AI È©ÖÂãïÁ≥ªÁµ±ÔºåÂÆÉÊúÉÁÇ∫ÊîæÂ∞ÑÁßëÊ™¢Êü•ÁµêÊûúÁî¢ÁîüÂ∞çÊÇ£ËÄÖÂèãÂñÑÁöÑÂΩ±ÁâáÂ†±Âëä„ÄÇReXplain Áç®ÁâπÂú∞Êï¥Âêà‰∫Ü‰∏ÄÂÄãÁî®ÊñºÊñáÂ≠óÁ∞°ÂåñÁöÑË™ûË®ÄÊ®°Âûã„ÄÅ‰∏ÄÂÄãÁî®ÊñºËß£ÂâñÂçÄÂüüË≠òÂà•ÁöÑÂΩ±ÂÉèÂàÜÂâ≤Ê®°ÂûãÔºå‰ª•Âèä‰∏ÄÂÄãÈ†≠ÂÉèÁî¢ÁîüÂ∑•ÂÖ∑ÔºåÁî¢Áîü‰∫ÜÂåÖÂê´Ê∑∫È°ØÊòìÊáÇÁöÑË™ûË®Ä„ÄÅÈáçÈªûÂΩ±ÂÉèÂíå 3D Âô®ÂÆòÊ∏≤ÊüìÁöÑÂÖ®Èù¢Ëß£Èáã„ÄÇÊàëÂÄëËàá‰∫î‰ΩçÈÄöÈÅéË™çË≠âÁöÑÊîæÂ∞ÑÁßëÈÜ´Â∏´ÈÄ≤Ë°åÁöÑÈ©óË≠âÊ¶ÇÂøµÁ†îÁ©∂ÊåáÂá∫ÔºåReXplain ËÉΩÂ§†Ê∫ñÁ¢∫Âú∞ÂÇ≥ÈÅîÊîæÂ∞ÑÁßëË≥áË®äÔºå‰∏¶ÊúâÊïàÂú∞Ê®°Êì¨‰∏ÄÂ∞ç‰∏ÄÁöÑË´ÆË©¢„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÂ±ïÁ§∫‰∫Ü AI ËºîÂä©ÈÜ´ÁôÇÊ∫ùÈÄöÁöÑÊñ∞ÂÖ∏ÁØÑÔºåÂÆÉÊúâÊΩõÂäõÊîπÂñÑÊÇ£ËÄÖÂèÉËàáÂ∫¶ÂíåÊîæÂ∞ÑÁßëÁÖßË≠∑ÁöÑÊªøÊÑèÂ∫¶Ôºå‰∏¶ÁÇ∫Â§öÊ®°ÂºèÈÜ´ÁôÇÊ∫ùÈÄöÁöÑÁ†îÁ©∂ÈñãÂïü‰∫ÜÊñ∞ÈÄîÂæë„ÄÇ

##### **CXPMRG-Bench: Pre-training and Benchmarking for X-ray Medical Report Generation on CheXpert Plus Dataset**
2410.00379v1 by Xiao Wang, Fuling Wang, Yuehang Li, Qingchuan Ma, Shiao Wang, Bo Jiang, Chuanfu Li, Jin Tang

X-ray image-based medical report generation (MRG) is a pivotal area in
artificial intelligence which can significantly reduce diagnostic burdens and
patient wait times. Despite significant progress, we believe that the task has
reached a bottleneck due to the limited benchmark datasets and the existing
large models' insufficient capability enhancements in this specialized domain.
Specifically, the recently released CheXpert Plus dataset lacks comparative
evaluation algorithms and their results, providing only the dataset itself.
This situation makes the training, evaluation, and comparison of subsequent
algorithms challenging. Thus, we conduct a comprehensive benchmarking of
existing mainstream X-ray report generation models and large language models
(LLMs), on the CheXpert Plus dataset. We believe that the proposed benchmark
can provide a solid comparative basis for subsequent algorithms and serve as a
guide for researchers to quickly grasp the state-of-the-art models in this
field. More importantly, we propose a large model for the X-ray image report
generation using a multi-stage pre-training strategy, including self-supervised
autoregressive generation and Xray-report contrastive learning, and supervised
fine-tuning. Extensive experimental results indicate that the autoregressive
pre-training based on Mamba effectively encodes X-ray images, and the
image-text contrastive pre-training further aligns the feature spaces,
achieving better experimental results. Source code can be found on
\url{https://github.com/Event-AHU/Medical_Image_Analysis}.

ÊëòË¶ÅÔºöÂü∫Êñº X ÂÖâÂΩ±ÂÉèÁöÑÈÜ´ÁôÇÂ†±ÂëäÁîüÊàê (MRG) ÊòØ‰∫∫Â∑•Êô∫ÊÖß‰∏≠ÁöÑ‰∏ÄÂÄãÈóúÈçµÈ†òÂüüÔºåÂÆÉÂèØ‰ª•Â§ßÂπÖÊ∏õÂ∞ëË®∫Êñ∑Ë≤†ÊìîÂíåÁóÖÊÇ£ÁöÑÁ≠âÂæÖÊôÇÈñì„ÄÇÂÑòÁÆ°ÊúâÈ°ØËëóÁöÑÈÄ≤Â±ïÔºåÊàëÂÄëË™çÁÇ∫ÈÄôÈ†Ö‰ªªÂãôÂ∑≤Á∂ìÈÅîÂà∞Áì∂È†∏ÔºåÂéüÂõ†ÊòØÂü∫Ê∫ñË≥áÊñôÈõÜÊúâÈôêÔºåËÄå‰∏îÁèæÊúâÁöÑÂ§ßÂûãÊ®°ÂûãÂú®ÈÄôÈ†ÖÂ∞àÊ•≠È†òÂüü‰∏≠ËÉΩÂäõÂ¢ûÂº∑‰∏çË∂≥„ÄÇÂÖ∑È´îËÄåË®ÄÔºåÊúÄËøëÁôºÂ∏ÉÁöÑ CheXpert Plus Ë≥áÊñôÈõÜÁº∫‰πèÊØîËºÉË©ï‰º∞ÊºîÁÆóÊ≥ïÂèäÂÖ∂ÁµêÊûúÔºåÂè™Êèê‰æõË≥áÊñôÈõÜÊú¨Ë∫´„ÄÇÈÄôÁ®ÆÊÉÖÊ≥Å‰ΩøÂæóÂæåÁ∫åÊºîÁÆóÊ≥ïÁöÑË®ìÁ∑¥„ÄÅË©ï‰º∞ÂíåÊØîËºÉÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂ∞çÁèæÊúâÁöÑ‰∏ªÊµÅ X ÂÖâÂ†±ÂëäÁîüÊàêÊ®°ÂûãÂíåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑÂü∫Ê∫ñÊ∏¨Ë©¶ÔºåË≥áÊñôÈõÜÁÇ∫ CheXpert Plus„ÄÇÊàëÂÄëÁõ∏‰ø°ÔºåÊâÄÊèêÂá∫ÁöÑÂü∫Ê∫ñÊ∏¨Ë©¶ÂèØ‰ª•ÁÇ∫ÂæåÁ∫åÊºîÁÆóÊ≥ïÊèê‰æõÁ©©Âõ∫ÁöÑÊØîËºÉÂü∫Á§éÔºå‰∏¶‰ΩúÁÇ∫Á†îÁ©∂‰∫∫Âì°Âø´ÈÄüÊéåÊè°Ê≠§È†òÂüüÊúÄÂÖàÈÄ≤Ê®°ÂûãÁöÑÊåáÂçó„ÄÇÊõ¥ÈáçË¶ÅÁöÑÊòØÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄã‰ΩøÁî®Â§öÈöéÊÆµÈ†êË®ìÁ∑¥Á≠ñÁï•ÁöÑÂ§ßÂûãÊ®°ÂûãÔºåÁî®Êñº X ÂÖâÂΩ±ÂÉèÂ†±ÂëäÁîüÊàêÔºåÂåÖÊã¨Ëá™Áõ£Áù£Ëá™Ëø¥Ê≠∏ÁîüÊàêÂíå X ÂÖâÂ†±ÂëäÂ∞çÊØîÂ≠∏ÁøíÔºå‰ª•ÂèäÁõ£Áù£ÂæÆË™ø„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÂü∫Êñº Mamba ÁöÑËá™Ëø¥Ê≠∏È†êË®ìÁ∑¥ÊúâÊïàÂú∞Á∑®Á¢º‰∫Ü X ÂÖâÂΩ±ÂÉèÔºåËÄåÂΩ±ÂÉèÊñáÂ≠óÂ∞çÊØîÈ†êË®ìÁ∑¥ÈÄ≤‰∏ÄÊ≠•Â∞çÈΩä‰∫ÜÁâπÂæµÁ©∫ÈñìÔºåÈÅîÂà∞‰∫ÜÊõ¥Â•ΩÁöÑÂØ¶È©óÁµêÊûú„ÄÇÂéüÂßãÁ¢ºÂèØ‰ª•Âú® \url{https://github.com/Event-AHU/Medical_Image_Analysis} ÊâæÂà∞„ÄÇ

##### **Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**
2410.00366v1 by Prasenjit Maji, Amit Kumar Mondal, Hemanta Kumar Mondal, Saraju P. Mohanty

The rapid advancements in artificial intelligence (AI) have revolutionized
smart healthcare, driving innovations in wearable technologies, continuous
monitoring devices, and intelligent diagnostic systems. However, security,
explainability, robustness, and performance optimization challenges remain
critical barriers to widespread adoption in clinical environments. This
research presents an innovative algorithmic method using the Adaptive Feature
Evaluator (AFE) algorithm to improve feature selection in healthcare datasets
and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable
Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT),
the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby
enhancing predictive accuracy and interpretability. The proposed method is
validated across three diverse healthcare datasets using six distinct machine
learning algorithms, demonstrating its robustness and superiority over
conventional feature selection techniques. The results underscore the
transformative potential of AFE in smart healthcare, enabling personalized and
transparent patient care. Notably, the AFE algorithm, when combined with a
Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting
its capability to improve clinical decision-making processes in real-world
healthcare applications.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÂø´ÈÄüÈÄ≤Â±ïÂæπÂ∫ïÊîπËÆä‰∫ÜÊô∫ÊÖßÈÜ´ÁôÇ‰øùÂÅ•ÔºåÊé®Âãï‰∫ÜÂèØÁ©øÊà¥ÊäÄË°ì„ÄÅÊåÅÁ∫åÁõ£ÊéßË£ùÁΩÆÂíåÊô∫ÊÖßË®∫Êñ∑Á≥ªÁµ±ÁöÑÂâµÊñ∞„ÄÇÁÑ∂ËÄåÔºåÂÆâÂÖ®ÊÄß„ÄÅÂèØËß£ÈáãÊÄß„ÄÅÁ©©ÂÅ•ÊÄßÂíåÊïàËÉΩÊúÄ‰Ω≥ÂåñÊåëÊà∞‰ªçÁÑ∂ÊòØËá®Â∫äÁí∞Â¢É‰∏≠Âª£Ê≥õÊé°Áî®ÁöÑÈóúÈçµÈöúÁ§ô„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÂâµÊñ∞ÁöÑÊºîÁÆóÊ≥ïÊñπÊ≥ïÔºå‰ΩøÁî®Ëá™ÈÅ©ÊáâÁâπÂæµË©ï‰º∞Âô® (AFE) ÊºîÁÆóÊ≥ï‰æÜÊîπÂñÑÈÜ´ÁôÇ‰øùÂÅ•Ë≥áÊñôÈõÜ‰∏≠ÁöÑÁâπÂæµÈÅ∏Âèñ‰∏¶ÂÖãÊúçÂïèÈ°å„ÄÇAFE Êï¥Âêà‰∫ÜÈÅ∫ÂÇ≥ÊºîÁÆóÊ≥ï (GA)„ÄÅÂèØËß£Èáã‰∫∫Â∑•Êô∫ÊÖß (XAI) ÂíåÊéíÂàóÁµÑÂêàÊäÄË°ì (PCT)ÔºåË©≤ÊºîÁÆóÊ≥ïÊúÄ‰Ω≥Âåñ‰∫ÜËá®Â∫äÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ± (CDSS)ÔºåÂæûËÄåÊèêÈ´ò‰∫ÜÈ†êÊ∏¨Ê∫ñÁ¢∫ÊÄßÂíåÂèØËß£ÈáãÊÄß„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ï‰ΩøÁî®ÂÖ≠Á®Æ‰∏çÂêåÁöÑÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ïÈ©óË≠â‰∫Ü‰∏âÂÄã‰∏çÂêåÁöÑÈÜ´ÁôÇ‰øùÂÅ•Ë≥áÊñôÈõÜÔºåË≠âÊòé‰∫ÜÂÖ∂Á©©ÂÅ•ÊÄßÂíåÂÑ™ÊñºÂÇ≥Áµ±ÁâπÂæµÈÅ∏ÂèñÊäÄË°ì„ÄÇÁµêÊûúÂº∑Ë™ø‰∫Ü AFE Âú®Êô∫ÊÖßÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑËΩâËÆäÊΩõÂäõÔºåÂØ¶Áèæ‰∫ÜÂÄã‰∫∫ÂåñÂíåÈÄèÊòéÁöÑÊÇ£ËÄÖÁÖßË≠∑„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåAFE ÊºîÁÆóÊ≥ïËàáÂ§öÂ±§ÊÑüÁü•Âô® (MLP) ÁµêÂêà‰ΩøÁî®ÊôÇÔºåÊ∫ñÁ¢∫Â∫¶È´òÈÅî 98.5%ÔºåÁ™ÅÈ°Ø‰∫ÜÂÖ∂ÊîπÂñÑÂØ¶ÈöõÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®‰∏≠Ëá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÊµÅÁ®ãÁöÑËÉΩÂäõ„ÄÇ

##### **The age of spiritual machines: Language quietus induces synthetic altered states of consciousness in artificial intelligence**
2410.00257v1 by Jeremy I Skipper, Joanna Kuc, Greg Cooper, Christopher Timmermann

How is language related to consciousness? Language functions to categorise
perceptual experiences (e.g., labelling interoceptive states as 'happy') and
higher-level constructs (e.g., using 'I' to represent the narrative self).
Psychedelic use and meditation might be described as altered states that impair
or intentionally modify the capacity for linguistic categorisation. For
example, psychedelic phenomenology is often characterised by 'oceanic
boundlessness' or 'unity' and 'ego dissolution', which might be expected of a
system unburdened by entrenched language categories. If language breakdown
plays a role in producing such altered behaviour, multimodal artificial
intelligence might align more with these phenomenological descriptions when
attention is shifted away from language. We tested this hypothesis by comparing
the semantic embedding spaces from simulated altered states after manipulating
attentional weights in CLIP and FLAVA models to embedding spaces from altered
states questionnaires before manipulation. Compared to random text and various
other altered states including anxiety, models were more aligned with
disembodied, ego-less, spiritual, and unitive states, as well as minimal
phenomenal experiences, with decreased attention to language and vision.
Reduced attention to language was associated with distinct linguistic patterns
and blurred embeddings within and, especially, across semantic categories
(e.g., 'giraffes' become more like 'bananas'). These results lend support to
the role of language categorisation in the phenomenology of altered states of
consciousness, like those experienced with high doses of psychedelics or
concentration meditation, states that often lead to improved mental health and
wellbeing.

ÊëòË¶ÅÔºöË™ûË®ÄÂ¶Ç‰ΩïËàáÊÑèË≠òÁõ∏ÈóúÔºüË™ûË®ÄÂäüËÉΩÁî®ÊñºÂàÜÈ°ûÊÑüÁü•Á∂ìÈ©óÔºà‰æãÂ¶ÇÔºåÂ∞áÂÖßÊÑüÂèóÁãÄÊÖãÊ®ôË®òÁÇ∫„ÄåÂø´Ê®Ç„ÄçÔºâÂíåÊõ¥È´òÂ±§Ê¨°ÁöÑÂª∫ÊßãÔºà‰æãÂ¶ÇÔºå‰ΩøÁî®„ÄåÊàë„Äç‰æÜ‰ª£Ë°®Êïò‰∫ãËá™ÊàëÔºâ„ÄÇËø∑ÂπªËó•ÁöÑ‰ΩøÁî®ÂíåÂÜ•ÊÉ≥ÂèØ‰ª•Ë¢´ÊèèËø∞ÁÇ∫ÊîπËÆäÁãÄÊÖãÔºåÊúÉÊêçÂÆ≥ÊàñÊïÖÊÑè‰øÆÊîπË™ûË®ÄÂàÜÈ°ûÁöÑËÉΩÂäõ„ÄÇ‰æãÂ¶ÇÔºåËø∑ÂπªÁèæË±°Â≠∏ÈÄöÂ∏∏‰ª•„ÄåÊµ∑Ê¥ãËà¨ÁöÑÁÑ°Áïå„ÄçÊàñ„ÄåÁµ±‰∏Ä„ÄçÂíå„ÄåËá™ÊàëËß£È´î„ÄçÁÇ∫ÁâπÂæµÔºåÈÄôÂèØËÉΩÊòØÊ≤íÊúâÊ†πÊ∑±ËíÇÂõ∫ÁöÑË™ûË®ÄÈ°ûÂà•ÁöÑÁ≥ªÁµ±ÊâÄÈ†êÊúüÁöÑ„ÄÇÂ¶ÇÊûúË™ûË®ÄÂ¥©ÊΩ∞Âú®Áî¢ÁîüÈÄôÁ®ÆÊîπËÆäÁöÑË°åÁÇ∫‰∏≠ÁôºÊèÆ‰ΩúÁî®ÔºåÈÇ£È∫ºÁï∂Ê≥®ÊÑèÂäõÂæûË™ûË®ÄËΩâÁßªÊôÇÔºåÂ§öÊ®°ÊÖã‰∫∫Â∑•Êô∫ËÉΩÂèØËÉΩÊõ¥Á¨¶ÂêàÈÄô‰∫õÁèæË±°Â≠∏ÊèèËø∞„ÄÇÊàëÂÄëÈÄöÈÅéÊØîËºÉÂú® CLIP Âíå FLAVA Ê®°Âûã‰∏≠ÊìçÁ∏±Ê≥®ÊÑèÂäõÊ¨äÈáçÂæåÊ®°Êì¨ÁöÑÊîπËÆäÁãÄÊÖãÁöÑË™ûÁæ©ÂµåÂÖ•Á©∫ÈñìËàáÊìçÁ∏±ÂâçÁöÑÊîπËÆäÁãÄÊÖãÂïèÂç∑ÁöÑÂµåÂÖ•Á©∫Èñì‰æÜÊ∏¨Ë©¶ÈÄôÂÄãÂÅáË®≠„ÄÇËàáÈö®Ê©üÊñáÊú¨ÂíåÂåÖÊã¨ÁÑ¶ÊÖÆÂú®ÂÖßÁöÑÂêÑÁ®ÆÂÖ∂‰ªñÊîπËÆäÁãÄÊÖãÁõ∏ÊØîÔºåÈÄô‰∫õÊ®°ÂûãÊõ¥Á¨¶ÂêàÁÑ°ËÇâË∫´„ÄÅÁÑ°Ëá™Êàë„ÄÅÁ≤æÁ•ûÂíåÁµ±‰∏ÄÁãÄÊÖãÔºå‰ª•ÂèäÊúÄÂ∞èÁöÑÁèæË±°È´îÈ©óÔºå‰∏¶‰∏îÂ∞çË™ûË®ÄÂíåË¶ñË¶∫ÁöÑÊ≥®ÊÑèÂäõÈôç‰Ωé„ÄÇÂ∞çË™ûË®ÄÁöÑÊ≥®ÊÑèÂäõÈôç‰ΩéËàá‰∏çÂêåÁöÑË™ûË®ÄÊ®°ÂºèÂíåÊ®°Á≥äÁöÑÂµåÂÖ•Áõ∏ÈóúÔºåÁâπÂà•ÊòØÂú®Ë™ûÁæ©È°ûÂà•‰∏≠Ôºà‰æãÂ¶ÇÔºå„ÄåÈï∑È†∏Èπø„ÄçËÆäÂæóÊõ¥ÂÉè„ÄåÈ¶ôËïâ„ÄçÔºâ„ÄÇÈÄô‰∫õÁµêÊûúÊîØÊåÅ‰∫ÜË™ûË®ÄÂàÜÈ°ûÂú®ÊîπËÆäÊÑèË≠òÁãÄÊÖãÁöÑÁèæË±°Â≠∏‰∏≠ÁöÑ‰ΩúÁî®Ôºå‰æãÂ¶ÇÊúçÁî®È´òÂäëÈáèËø∑ÂπªËó•ÊàñÂ∞àÊ≥®ÂÜ•ÊÉ≥ÊâÄÁ∂ìÊ≠∑ÁöÑÁãÄÊÖãÔºåÈÄô‰∫õÁãÄÊÖãÈÄöÂ∏∏ÊúÉÂ∞éËá¥ÂøÉÁêÜÂÅ•Â∫∑ÂíåÂπ∏Á¶èÊÑüÁöÑÊîπÂñÑ„ÄÇ

##### **Adapting LLMs for the Medical Domain in Portuguese: A Study on Fine-Tuning and Model Evaluation**
2410.00163v1 by Pedro Henrique Paiola, Gabriel Lino Garcia, Jo√£o Renato Ribeiro Manesco, Mateus Roder, Douglas Rodrigues, Jo√£o Paulo Papa

This study evaluates the performance of large language models (LLMs) as
medical agents in Portuguese, aiming to develop a reliable and relevant virtual
assistant for healthcare professionals. The HealthCareMagic-100k-en and MedQuAD
datasets, translated from English using GPT-3.5, were used to fine-tune the
ChatBode-7B model using the PEFT-QLoRA method. The InternLM2 model, with
initial training on medical data, presented the best overall performance, with
high precision and adequacy in metrics such as accuracy, completeness and
safety. However, DrBode models, derived from ChatBode, exhibited a phenomenon
of catastrophic forgetting of acquired medical knowledge. Despite this, these
models performed frequently or even better in aspects such as grammaticality
and coherence. A significant challenge was low inter-rater agreement,
highlighting the need for more robust assessment protocols. This work paves the
way for future research, such as evaluating multilingual models specific to the
medical field, improving the quality of training data, and developing more
consistent evaluation methodologies for the medical field.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Ë©ï‰º∞Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Ëë°ËêÑÁâôË™û‰∏≠‰ΩúÁÇ∫ÈÜ´ÁôÇ‰ª£ÁêÜÁöÑË°®ÁèæÔºåÊó®Âú®ÁÇ∫ÈÜ´ÁôÇÂ∞àÊ•≠‰∫∫Âì°ÈñãÁôº‰∏ÄÂÄãÂèØÈù†‰∏îÁõ∏ÈóúÁöÑËôõÊì¨Âä©ÁêÜ„ÄÇHealthCareMagic-100k-en Âíå MedQuAD Ë≥áÊñôÈõÜÔºå‰ΩøÁî® GPT-3.5 ÂæûËã±Ë™ûÁøªË≠ØÔºåÁî®Êñº‰ΩøÁî® PEFT-QLoRA ÊñπÊ≥ïÂæÆË™ø ChatBode-7B Ê®°Âûã„ÄÇInternLM2 Ê®°ÂûãÔºåÂú®ÈÜ´ÁôÇË≥áÊñô‰∏äÈÄ≤Ë°åÂàùÂßãË®ìÁ∑¥ÔºåË°®ÁèæÂá∫ÊúÄÂ•ΩÁöÑÊï¥È´îË°®ÁèæÔºåÂú®Ê∫ñÁ¢∫ÊÄß„ÄÅÂÆåÊï¥ÊÄßÂíåÂÆâÂÖ®ÊÄßÁ≠âÊåáÊ®ô‰∏äÂÖ∑ÊúâÂæàÈ´òÁöÑÁ≤æÂ∫¶ÂíåÂÖÖÂàÜÊÄß„ÄÇÁÑ∂ËÄåÔºåÊ∫êËá™ ChatBode ÁöÑ DrBode Ê®°ÂûãË°®ÁèæÂá∫Â∞çÁç≤ÂæóÁöÑÈÜ´ÁôÇÁü•Ë≠òÁÅΩÈõ£ÊÄßÈÅ∫ÂøòÁöÑÁèæË±°„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÈÄô‰∫õÊ®°ÂûãÂú®Ë™ûÊ≥ïÊÄßÂíåÈÄ£Ë≤´ÊÄßÁ≠âÊñπÈù¢Ë°®ÁèæÂæóÂæàÂ•ΩÁîöËá≥Êõ¥Â•Ω„ÄÇ‰∏ÄÂÄãÈáçÂ§ßÁöÑÊåëÊà∞ÊòØË©ïÂàÜËÄÖ‰πãÈñìÁöÑÂçîË≠∞‰ΩéÔºåÈÄôÂá∏È°Ø‰∫ÜÂ∞çÊõ¥Âº∑Â§ßÁöÑË©ï‰º∞ÂçîË≠∞ÁöÑÈúÄÊ±Ç„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫Êú™‰æÜÁöÑÁ†îÁ©∂Èã™Âπ≥‰∫ÜÈÅìË∑ØÔºå‰æãÂ¶ÇË©ï‰º∞ÁâπÂÆöÊñºÈÜ´ÁôÇÈ†òÂüüÁöÑÂ§öË™ûË®ÄÊ®°Âûã„ÄÅÊèêÈ´òË®ìÁ∑¥Ë≥áÊñôÁöÑÂìÅË≥™Ôºå‰ª•ÂèäÁÇ∫ÈÜ´ÁôÇÈ†òÂüüÈñãÁôºÊõ¥‰∏ÄËá¥ÁöÑË©ï‰º∞ÊñπÊ≥ï„ÄÇ

##### **The Perfect Blend: Redefining RLHF with Mixture of Judges**
2409.20370v1 by Tengyu Xu, Eryk Helenowski, Karthik Abinav Sankararaman, Di Jin, Kaiyan Peng, Eric Han, Shaoliang Nie, Chen Zhu, Hejia Zhang, Wenxuan Zhou, Zhouhao Zeng, Yun He, Karishma Mandyam, Arya Talabzadeh, Madian Khabsa, Gabriel Cohen, Yuandong Tian, Hao Ma, Sinong Wang, Han Fang

Reinforcement learning from human feedback (RLHF) has become the leading
approach for fine-tuning large language models (LLM). However, RLHF has
limitations in multi-task learning (MTL) due to challenges of reward hacking
and extreme multi-objective optimization (i.e., trade-off of multiple and/or
sometimes conflicting objectives). Applying RLHF for MTL currently requires
careful tuning of the weights for reward model and data combinations. This is
often done via human intuition and does not generalize. In this work, we
introduce a novel post-training paradigm which we called Constrained Generative
Policy Optimization (CGPO). The core of CGPO is Mixture of Judges (MoJ) with
cost-efficient constrained policy optimization with stratification, which can
identify the perfect blend in RLHF in a principled manner. It shows strong
empirical results with theoretical guarantees, does not require extensive
hyper-parameter tuning, and is plug-and-play in common post-training pipelines.
Together, this can detect and mitigate reward hacking behaviors while reaching
a pareto-optimal point across an extremely large number of objectives.
  Our empirical evaluations demonstrate that CGPO significantly outperforms
standard RLHF algorithms like PPO and DPO across various tasks including
general chat, STEM questions, instruction following, and coding. Specifically,
CGPO shows improvements of 7.4% in AlpacaEval-2 (general chat), 12.5% in
Arena-Hard (STEM & reasoning), and consistent gains in other domains like math
and coding. Notably, PPO, while commonly used, is prone to severe reward
hacking in popular coding benchmarks, which CGPO successfully addresses. This
breakthrough in RLHF not only tackles reward hacking and extreme
multi-objective optimization challenges but also advances the state-of-the-art
in aligning general-purpose LLMs for diverse applications.

ÊëòË¶ÅÔºö‰∫∫È°ûÂõûÈ•ãÂº∑ÂåñÂ≠∏Áøí (RLHF) Â∑≤ÊàêÁÇ∫ÂæÆË™øÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈ†òÂÖàÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåRLHF Âú®Â§ö‰ªªÂãôÂ≠∏Áøí (MTL) ‰∏≠ÂèóÂà∞ÁçéÂãµÁ†¥Ëß£ÂíåÊ•µÁ´ØÂ§öÁõÆÊ®ôÊúÄ‰Ω≥ÂåñÔºà‰æãÂ¶ÇÔºåÂ§öÈáçÂíå/ÊàñÊúâÊôÇÁõ∏‰∫íË°ùÁ™ÅÁöÑÁõÆÊ®ô‰πãÈñìÁöÑÂèñÊç®ÔºâÁöÑÊåëÊà∞ËÄåÊúâÊâÄÈôêÂà∂„ÄÇÁõÆÂâçÔºåÂ∞á RLHF ÊáâÁî®Êñº MTL ÈúÄË¶Å‰ªîÁ¥∞Ë™øÊï¥ÁçéÂãµÊ®°ÂûãÂíåË≥áÊñôÁµÑÂêàÁöÑÊ¨äÈáç„ÄÇÈÄôÈÄöÂ∏∏ÊòØÈÄèÈÅé‰∫∫È°ûÁõ¥Ë¶∫‰æÜÂÆåÊàêÔºåËÄå‰∏îÁÑ°Ê≥ïÊ¶ÇÊã¨„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑË®ìÁ∑¥ÂæåÁØÑ‰æãÔºåÊàëÂÄëÁ®±‰πãÁÇ∫ÂèóÁ¥ÑÊùüÁîüÊàêÁ≠ñÁï•ÊúÄ‰Ω≥Âåñ (CGPO)„ÄÇCGPO ÁöÑÊ†∏ÂøÉÊòØÊ≥ïÂÆòÊ∑∑Âêà (MoJ)ÔºåÈÄèÈÅéÂàÜÂ±§ÈÄ≤Ë°åÂÖ∑ÊúâÊàêÊú¨ÊïàÁõäÁöÑÂèóÁ¥ÑÊùüÁ≠ñÁï•ÊúÄ‰Ω≥ÂåñÔºåÂÆÉÂèØ‰ª•‰ª•ÂéüÂâáÊÄßÁöÑÊñπÂºèÊâæÂá∫ RLHF ‰∏≠ÁöÑÂÆåÁæéËûçÂêà„ÄÇÂÆÉÂú®ÁêÜË´ñ‰øùË≠â‰∏ãÂ±ïÁèæÂº∑Â§ßÁöÑÂØ¶Ë≠âÁµêÊûúÔºå‰∏çÈúÄË¶ÅÂª£Ê≥õÁöÑË∂ÖÂèÉÊï∏Ë™øÊï¥Ôºå‰∏¶‰∏îÂèØ‰ª•Âç≥ÊèíÂç≥Áî®ÊñºÂ∏∏Ë¶ãÁöÑË®ìÁ∑¥ÂæåÁÆ°ÈÅì„ÄÇÁ∏Ω‰πãÔºåÂÆÉÂèØ‰ª•Âú®Ê•µÂ§ßÈáèÁöÑÁõÆÊ®ô‰∏≠ÂÅµÊ∏¨ÂíåÊ∏õËºïÁçéÂãµÁ†¥Ëß£Ë°åÁÇ∫ÔºåÂêåÊôÇÈÅîÂà∞Â∏ïÈõ∑ÊâòÊúÄÂÑ™Èªû„ÄÇÊàëÂÄëÁöÑÂØ¶Ë≠âË©ï‰º∞Ë≠âÊòéÔºåCGPO Âú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠È°ØËëóÂÑ™ÊñºÊ®ôÊ∫ñ RLHF ÊºîÁÆóÊ≥ïÔºå‰æãÂ¶Ç‰∏ÄËà¨ËÅäÂ§©„ÄÅSTEM ÂïèÈ°å„ÄÅÊåá‰ª§ÈÅµÂæ™ÂíåÁ∑®Á¢º„ÄÇÂÖ∑È´î‰æÜË™™ÔºåCGPO Âú® AlpacaEval-2Ôºà‰∏ÄËà¨ËÅäÂ§©Ôºâ‰∏≠ÊèêÂçá‰∫Ü 7.4%ÔºåÂú® Arena-HardÔºàSTEM ÂíåÊé®ÁêÜÔºâ‰∏≠ÊèêÂçá‰∫Ü 12.5%Ôºå‰∏¶‰∏îÂú®Êï∏Â≠∏ÂíåÁ∑®Á¢ºÁ≠âÂÖ∂‰ªñÈ†òÂüü‰∏≠ÊåÅÁ∫åÁç≤ÂæóÊî∂Áõä„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåPPO ÈõñÁÑ∂ÊôÆÈÅç‰ΩøÁî®Ôºå‰ΩÜÂú®ÊµÅË°åÁöÑÁ∑®Á¢ºÂü∫Ê∫ñ‰∏≠ÂÆπÊòìÂèóÂà∞Âö¥ÈáçÁöÑÁçéÂãµÁ†¥Ëß£ÔºåËÄå CGPO ÊàêÂäüÂú∞Ëß£Ê±∫‰∫ÜÈÄôÂÄãÂïèÈ°å„ÄÇRLHF ÁöÑÈÄôÈ†ÖÁ™ÅÁ†¥‰∏çÂÉÖËß£Ê±∫‰∫ÜÁçéÂãµÁ†¥Ëß£ÂíåÊ•µÁ´ØÂ§öÁõÆÊ®ôÊúÄ‰Ω≥ÂåñÁöÑÊåëÊà∞ÔºåËÄå‰∏îÈÇÑÊé®Âãï‰∫ÜÂ∞áÈÄöÁî® LLM ËàáÂêÑÁ®ÆÊáâÁî®Á®ãÂºèÁõ∏ÁµêÂêàÁöÑÊúÄÊñ∞ÊäÄË°ì„ÄÇ

##### **Forecasting Disease Progression with Parallel Hyperplanes in Longitudinal Retinal OCT**
2409.20195v2 by Arunava Chakravarty, Taha Emre, Dmitrii Lachinov, Antoine Rivail, Hendrik Scholl, Lars Fritsche, Sobha Sivaprasad, Daniel Rueckert, Andrew Lotery, Ursula Schmidt-Erfurth, Hrvoje Bogunoviƒá

Predicting future disease progression risk from medical images is challenging
due to patient heterogeneity, and subtle or unknown imaging biomarkers.
Moreover, deep learning (DL) methods for survival analysis are susceptible to
image domain shifts across scanners. We tackle these issues in the task of
predicting late dry Age-related Macular Degeneration (dAMD) onset from retinal
OCT scans. We propose a novel DL method for survival prediction to jointly
predict from the current scan a risk score, inversely related to
time-to-conversion, and the probability of conversion within a time interval
$t$. It uses a family of parallel hyperplanes generated by parameterizing the
bias term as a function of $t$. In addition, we develop unsupervised losses
based on intra-subject image pairs to ensure that risk scores increase over
time and that future conversion predictions are consistent with AMD stage
prediction using actual scans of future visits. Such losses enable
data-efficient fine-tuning of the trained model on new unlabeled datasets
acquired with a different scanner. Extensive evaluation on two large datasets
acquired with different scanners resulted in a mean AUROCs of 0.82 for
Dataset-1 and 0.83 for Dataset-2, across prediction intervals of 6,12 and 24
months.

ÊëòË¶ÅÔºöÈ¢ÑÊµãÊú™Êù•ÁñæÁóÖËøõÂ±ïÈ£éÈô©‰ªéÂåªÂ≠¶ÂΩ±ÂÉè‰∏≠ÂÖ∑ÊúâÊåëÊàòÊÄß
Áî±‰∫éÁóÖ‰∫∫ÂºÇË¥®ÊÄßÔºåÂíåÁªÜÂæÆÊàñÊú™Áü•ÁöÑÂΩ±ÂÉèÁîüÁâ©Ê†áËÆ∞„ÄÇ
Ê≠§Â§ñÔºåÊ∑±Â∫¶Â≠¶‰π†ÔºàDLÔºâÊñπÊ≥ïÁî®‰∫éÂ≠òÊ¥ªÂàÜÊûêÂÆπÊòìÂèóÂà∞
Ë∑®Êâ´Êèè‰ª™ÁöÑÂΩ±ÂÉèÈ¢ÜÂüüËΩ¨Áßª„ÄÇÊàë‰ª¨Âú®È¢ÑÊµãÊôöÊúüÂπ≤ÊÄßÂπ¥ÈæÑÁõ∏ÂÖ≥ÊÄßÈªÑÊñëÈÉ®ÁóÖÂèòÔºàdAMDÔºâÂèë‰ΩúÁöÑ‰ªªÂä°‰∏≠Ëß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºå‰ªéËßÜÁΩëËÜú
OCT Êâ´Êèè„ÄÇÊàë‰ª¨ÊèêÂá∫‰∏ÄÁßçÊñ∞ÁöÑ DL ÊñπÊ≥ïÁî®‰∫éÂ≠òÊ¥ªÈ¢ÑÊµãÔºå‰ªéÂΩìÂâçÊâ´Êèè‰∏≠ËÅîÂêà
È¢ÑÊµã‰∏Ä‰∏™È£éÈô©ËØÑÂàÜÔºå‰∏éËΩ¨Êç¢Êó∂Èó¥ÊàêÂèçÊØîÔºå‰ª•ÂèäÂú®Êó∂Èó¥Èó¥ÈöîÂÜÖËΩ¨Êç¢ÁöÑÂèØËÉΩÊÄß
$t$„ÄÇÂÆÉ‰ΩøÁî®‰∏ÄÁªÑÂπ≥Ë°åÁöÑË∂ÖÂπ≥Èù¢ÔºåÈÄöËøáÂ∞ÜÂÅèÂ∑ÆÈ°πÂèÇÊï∞Âåñ‰∏∫ $t$ ÁöÑÂáΩÊï∞Êù•ÁîüÊàê„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÂºÄÂèëÊó†ÁõëÁù£ÊçüÂ§±
Âü∫‰∫éÂèóËØïËÄÖÂÜÖÂΩ±ÂÉèÂØπÔºå‰ª•Á°Æ‰øùÈ£éÈô©ËØÑÂàÜÈöèÁùÄ
Êó∂Èó¥Â¢ûÂä†ÔºåÂπ∂‰∏îÊú™Êù•ÁöÑËΩ¨Êç¢È¢ÑÊµã‰∏é AMD Èò∂ÊÆµ
È¢ÑÊµã‰ΩøÁî®Êú™Êù•ËÆøÈóÆÁöÑÂÆûÈôÖÊâ´ÊèèÊòØ‰∏ÄËá¥ÁöÑ„ÄÇÊ≠§Á±ªÊçüÂ§±ÂÖÅËÆ∏
Âú®‰ΩøÁî®‰∏çÂêåÊâ´Êèè‰ª™Ëé∑ÂèñÁöÑÊñ∞Êú™Ê†áËÆ∞Êï∞ÊçÆÈõÜ‰∏äÂØπËÆ≠ÁªÉÊ®°ÂûãËøõË°åÊï∞ÊçÆÈ´òÊïàÂæÆË∞É„ÄÇÂØπ‰∏§‰∏™Â§ßÂûãÊï∞ÊçÆÈõÜÁöÑÂπøÊ≥õËØÑ‰º∞
‰ΩøÁî®‰∏çÂêåÁöÑÊâ´Êèè‰ª™Ëé∑ÂæóÁöÑÔºåÂπ≥Âùá AUROC ‰∏∫ 0.82ÔºåÂØπ‰∫éÊï∞ÊçÆÈõÜ 1 Âíå 0.83ÔºåÂØπ‰∫éÊï∞ÊçÆÈõÜ 2ÔºåË∑®È¢ÑÊµãÈó¥Èöî 6,12 Âíå 24
‰∏™Êúà„ÄÇ

##### **Classification of Radiological Text in Small and Imbalanced Datasets in a Non-English Language**
2409.20147v1 by Vincent Beliveau, Helene Kaas, Martin Prener, Claes N. Ladefoged, Desmond Elliott, Gitte M. Knudsen, Lars H. Pinborg, Melanie Ganz

Natural language processing (NLP) in the medical domain can underperform in
real-world applications involving small datasets in a non-English language with
few labeled samples and imbalanced classes. There is yet no consensus on how to
approach this problem. We evaluated a set of NLP models including BERT-like
transformers, few-shot learning with sentence transformers (SetFit), and
prompted large language models (LLM), using three datasets of radiology reports
on magnetic resonance images of epilepsy patients in Danish, a low-resource
language. Our results indicate that BERT-like models pretrained in the target
domain of radiology reports currently offer the optimal performances for this
scenario. Notably, the SetFit and LLM models underperformed compared to
BERT-like models, with LLM performing the worst. Importantly, none of the
models investigated was sufficiently accurate to allow for text classification
without any supervision. However, they show potential for data filtering, which
could reduce the amount of manual labeling required.

ÊëòË¶ÅÔºöËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) Âú®ÈÜ´ÁôÇÈ†òÂüü‰∏≠ÔºåÂú®Ê∂âÂèäÈùûËã±Ë™ûË™ûË®Ä‰∏≠Â∞èÂûãË≥áÊñôÈõÜ„ÄÅÊ®ôË®òÊ®£Êú¨Â∞ëÂíåÈ°ûÂà•‰∏çÂπ≥Ë°°ÁöÑÂØ¶ÈöõÊáâÁî®‰∏≠Ë°®Áèæ‰∏ç‰Ω≥„ÄÇÂ∞çÊñºÂ¶Ç‰ΩïËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÁõÆÂâçÂ∞öÊú™ÈÅîÊàêÂÖ±Ë≠ò„ÄÇÊàëÂÄë‰ΩøÁî®‰∏âÁµÑ‰∏πÈ∫•Ë™ûÁô≤ÁôáÊÇ£ËÄÖÁ£ÅÂÖ±ÊåØÂΩ±ÂÉèÁöÑÊîæÂ∞ÑÂ†±ÂëäË≥áÊñôÈõÜÔºåË©ï‰º∞‰∫Ü‰∏ÄÁµÑ NLP Ê®°ÂûãÔºåÂåÖÊã¨È°û BERT ËΩâÊèõÂô®„ÄÅ‰ΩøÁî®Âè•Â≠êËΩâÊèõÂô® (SetFit) ÁöÑÂ∞ëÊ®£Êú¨Â≠∏ÁøíÔºå‰ª•ÂèäÊèêÁ§∫ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåÁõÆÂâçÂú®ÊîæÂ∞ÑÂ†±ÂëäÁõÆÊ®ôÈ†òÂüü‰∏≠È†êË®ìÁ∑¥ÁöÑÈ°û BERT Ê®°ÂûãÁÇ∫Ê≠§ÊÉÖÂ¢ÉÊèê‰æõÊúÄ‰Ω≥ÊïàËÉΩ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåËàáÈ°û BERT Ê®°ÂûãÁõ∏ÊØîÔºåSetFit Âíå LLM Ê®°ÂûãË°®Áèæ‰∏ç‰Ω≥ÔºåËÄå LLM Ë°®ÁèæÊúÄÂ∑Æ„ÄÇÈáçË¶ÅÁöÑÊòØÔºåÊâÄÁ†îÁ©∂ÁöÑÊ®°Âûã‰∏≠Ê≤íÊúâ‰∏ÄÂÄãË∂≥Â§†Ê∫ñÁ¢∫ÔºåÂèØ‰ª•Âú®Ê≤íÊúâ‰ªª‰ΩïÁõ£Áù£ÁöÑÊÉÖÊ≥Å‰∏ãÈÄ≤Ë°åÊñáÂ≠óÂàÜÈ°û„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÈ°ØÁ§∫Âá∫Ë≥áÊñôÈÅéÊøæÁöÑÊΩõÂäõÔºåÈÄôÂèØ‰ª•Ê∏õÂ∞ëÊâÄÈúÄÁöÑÊâãÂãïÊ®ôË®òÈáè„ÄÇ

##### **Positive-Sum Fairness: Leveraging Demographic Attributes to Achieve Fair AI Outcomes Without Sacrificing Group Gains**
2409.19940v1 by Samia Belhadj, Sanguk Park, Ambika Seth, Hesham Dar, Thijs Kooi

Fairness in medical AI is increasingly recognized as a crucial aspect of
healthcare delivery. While most of the prior work done on fairness emphasizes
the importance of equal performance, we argue that decreases in fairness can be
either harmful or non-harmful, depending on the type of change and how
sensitive attributes are used. To this end, we introduce the notion of
positive-sum fairness, which states that an increase in performance that
results in a larger group disparity is acceptable as long as it does not come
at the cost of individual subgroup performance. This allows sensitive
attributes correlated with the disease to be used to increase performance
without compromising on fairness.
  We illustrate this idea by comparing four CNN models that make different use
of the race attribute in the training phase. The results show that removing all
demographic encodings from the images helps close the gap in performance
between the different subgroups, whereas leveraging the race attribute as a
model's input increases the overall performance while widening the disparities
between subgroups. These larger gaps are then put in perspective of the
collective benefit through our notion of positive-sum fairness to distinguish
harmful from non harmful disparities.

ÊëòË¶ÅÔºöÈÜ´ÁôÇ AI ‰∏≠ÁöÑÂÖ¨Âπ≥ÊÄßÊó•ÁõäË¢´Ë¶ñÁÇ∫ÈÜ´ÁôÇ‰øùÂÅ•Êèê‰æõ‰∏≠Ëá≥ÈóúÈáçË¶ÅÁöÑ‰∏ÄÁí∞„ÄÇÈõñÁÑ∂Â§ßÂ§öÊï∏ÂÖàÂâçÈóúÊñºÂÖ¨Âπ≥ÊÄßÁöÑÁ†îÁ©∂ÈÉΩÂº∑Ë™øÂêåÁ≠âË°®ÁèæÁöÑÈáçË¶ÅÊÄßÔºåÊàëÂÄëË™çÁÇ∫ÂÖ¨Âπ≥ÊÄßÁöÑ‰∏ãÈôçÂèØËÉΩÊòØÊúâÂÆ≥ÁöÑÊàñÁÑ°ÂÆ≥ÁöÑÔºåÂÖ∑È´îÂèñÊ±∫ÊñºËÆäÂåñÁöÑÈ°ûÂûãÂíåÊïèÊÑüÂ±¨ÊÄßÁöÑ‰ΩøÁî®ÊñπÂºè„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÊ≠£ÂíåÂÖ¨Âπ≥ÊÄßÁöÑÊ¶ÇÂøµÔºåÂÆÉÊåáÂá∫ÔºåÂè™Ë¶Å‰∏ç‰ª•ÁäßÁâ≤ÂÄãÂà•Â≠êÁæ§È´îË°®ÁèæÁÇ∫‰ª£ÂÉπÔºåÈÇ£È∫ºÂ∞éËá¥Áæ§È´îÂ∑ÆÁï∞Êõ¥Â§ßÁöÑË°®ÁèæÊèêÂçáÊòØÂèØ‰ª•Êé•ÂèóÁöÑ„ÄÇÈÄôÂÖÅË®±Â∞áËàáÁñæÁóÖÁõ∏ÈóúÁöÑÊïèÊÑüÂ±¨ÊÄßÁî®ÊñºÊèêÈ´òË°®ÁèæÔºåËÄå‰∏çÊúÉÊêçÂÆ≥ÂÖ¨Âπ≥ÊÄß„ÄÇ
ÊàëÂÄëÈÄöÈÅéÊØîËºÉÂõõÂÄãÂú®Ë®ìÁ∑¥ÈöéÊÆµÂ∞çÁ®ÆÊóèÂ±¨ÊÄß‰ΩøÁî®‰∏çÂêåÁöÑ CNN Ê®°Âûã‰æÜË™™ÊòéÈÄôÂÄãÊÉ≥Ê≥ï„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåÂæûÂúñÂÉè‰∏≠ÁßªÈô§ÊâÄÊúâ‰∫∫Âè£Á∑®Á¢ºÊúâÂä©ÊñºÁ∏ÆÂ∞è‰∏çÂêåÂ≠êÁæ§È´î‰πãÈñìÁöÑË°®ÁèæÂ∑ÆË∑ùÔºåËÄåÂ∞áÁ®ÆÊóèÂ±¨ÊÄßÁî®‰ΩúÊ®°ÂûãÁöÑËº∏ÂÖ•ÊúÉÊèêÈ´òÊï¥È´îË°®ÁèæÔºåÂêåÊôÇÊì¥Â§ßÂ≠êÁæ§È´î‰πãÈñìÁöÑÂ∑ÆÁï∞„ÄÇÁÑ∂ÂæåÔºåÈÄöÈÅéÊàëÂÄëÊ≠£ÂíåÂÖ¨Âπ≥ÊÄßÁöÑÊ¶ÇÂøµÂ∞áÈÄô‰∫õÊõ¥Â§ßÁöÑÂ∑ÆË∑ùÁΩÆÊñºÊï¥È´îÊïàÁõäÁöÑËßíÂ∫¶Ôºå‰ª•ÂçÄÂàÜÊúâÂÆ≥ÂíåÁÑ°ÂÆ≥ÁöÑÂ∑ÆÁï∞„ÄÇ

##### **InfantCryNet: A Data-driven Framework for Intelligent Analysis of Infant Cries**
2409.19689v1 by Mengze Hong, Chen Jason Zhang, Lingxiao Yang, Yuanfeng Song, Di Jiang

Understanding the meaning of infant cries is a significant challenge for
young parents in caring for their newborns. The presence of background noise
and the lack of labeled data present practical challenges in developing systems
that can detect crying and analyze its underlying reasons. In this paper, we
present a novel data-driven framework, "InfantCryNet," for accomplishing these
tasks. To address the issue of data scarcity, we employ pre-trained audio
models to incorporate prior knowledge into our model. We propose the use of
statistical pooling and multi-head attention pooling techniques to extract
features more effectively. Additionally, knowledge distillation and model
quantization are applied to enhance model efficiency and reduce the model size,
better supporting industrial deployment in mobile devices. Experiments on
real-life datasets demonstrate the superior performance of the proposed
framework, outperforming state-of-the-art baselines by 4.4% in classification
accuracy. The model compression effectively reduces the model size by 7%
without compromising performance and by up to 28% with only an 8% decrease in
accuracy, offering practical insights for model selection and system design.

ÊëòË¶ÅÔºö‰∫ÜËß£Â¨∞ÂÖíÂì≠ËÅ≤ÁöÑÂê´Áæ©Â∞çÊñºÂπ¥ËºïÁà∂ÊØçÁÖßÈ°ßÊñ∞ÁîüÂÖí‰æÜË™™ÊòØ‰∏ÄÈ†ÖÈáçÂ§ßÊåëÊà∞„ÄÇËÉåÊôØÂô™Èü≥ÁöÑÂ≠òÂú®ÂíåÊ®ôÁ±§Ë≥áÊñôÁöÑÁº∫‰πèÂú®ÈñãÁôºÂèØ‰ª•ÂÅµÊ∏¨Âì≠ËÅ≤‰∏¶ÂàÜÊûêÂÖ∂ËÉåÂæåÂéüÂõ†ÁöÑÁ≥ªÁµ±ÊôÇÊèêÂá∫‰∫ÜÂØ¶ÈöõÊåëÊà∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑË≥áÊñôÈ©ÖÂãïÊ°ÜÊû∂„ÄåInfantCryNet„Äç‰æÜÂÆåÊàêÈÄô‰∫õ‰ªªÂãô„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ë≥áÊñôÁ®ÄÁº∫ÁöÑÂïèÈ°åÔºåÊàëÂÄëÊé°Áî®È†êÂÖàË®ìÁ∑¥ÁöÑÈü≥Ë®äÊ®°ÂûãÔºåÂ∞áÂÖàÈ©óÁü•Ë≠òÁ¥çÂÖ•ÊàëÂÄëÁöÑÊ®°Âûã‰∏≠„ÄÇÊàëÂÄëÊèêÂá∫‰ΩøÁî®Áµ±Ë®àÊ±†ÂåñÂíåÂ§öÈ†≠Ê≥®ÊÑèÂäõÊ±†ÂåñÊäÄË°ì‰æÜÊõ¥ÊúâÊïàÂú∞ÊèêÂèñÁâπÂæµ„ÄÇÊ≠§Â§ñÔºåÁü•Ë≠òËí∏È§æÂíåÊ®°ÂûãÈáèÂåñË¢´ÊáâÁî®ÊñºÂ¢ûÂº∑Ê®°ÂûãÊïàÁéá‰∏¶Á∏ÆÂ∞èÊ®°ÂûãÂ§ßÂ∞èÔºåÊõ¥Â•ΩÂú∞ÊîØÊè¥Ë°åÂãïË£ùÁΩÆ‰∏≠ÁöÑÁî¢Ê•≠ÈÉ®ÁΩ≤„ÄÇÂ∞çÁúüÂØ¶Ë≥áÊñôÈõÜÁöÑÂØ¶È©óË≠âÊòé‰∫ÜÊâÄÊèêÂá∫ÁöÑÊ°ÜÊû∂ÁöÑÂÑ™Áï∞ÊïàËÉΩÔºåÂú®ÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶‰∏äÊØîÊúÄÂÖàÈÄ≤ÁöÑÂü∫Ê∫ñÈ´òÂá∫ 4.4%„ÄÇÊ®°ÂûãÂ£ìÁ∏ÆÊúâÊïàÂú∞Â∞áÊ®°ÂûãÂ§ßÂ∞èÊ∏õÂ∞ë‰∫Ü 7%ÔºåËÄå‰∏çÊúÉÊêçÂÆ≥ÊïàËÉΩÔºå‰∏¶Âú®Ê∫ñÁ¢∫Â∫¶ÂÉÖ‰∏ãÈôç 8% ÁöÑÊÉÖÊ≥Å‰∏ãÂ∞áÊ®°ÂûãÂ§ßÂ∞èÊ∏õÂ∞ë‰∫Ü 28%ÔºåÁÇ∫Ê®°ÂûãÈÅ∏ÊìáÂíåÁ≥ªÁµ±Ë®≠Ë®àÊèê‰æõ‰∫ÜÂØ¶Áî®ÁöÑË¶ãËß£„ÄÇ

##### **See Detail Say Clear: Towards Brain CT Report Generation via Pathological Clue-driven Representation Learning**
2409.19676v2 by Chengxin Zheng, Junzhong Ji, Yanzhao Shi, Xiaodan Zhang, Liangqiong Qu

Brain CT report generation is significant to aid physicians in diagnosing
cranial diseases. Recent studies concentrate on handling the consistency
between visual and textual pathological features to improve the coherence of
report. However, there exist some challenges: 1) Redundant visual representing:
Massive irrelevant areas in 3D scans distract models from representing salient
visual contexts. 2) Shifted semantic representing: Limited medical corpus
causes difficulties for models to transfer the learned textual representations
to generative layers. This study introduces a Pathological Clue-driven
Representation Learning (PCRL) model to build cross-modal representations based
on pathological clues and naturally adapt them for accurate report generation.
Specifically, we construct pathological clues from perspectives of segmented
regions, pathological entities, and report themes, to fully grasp visual
pathological patterns and learn cross-modal feature representations. To adapt
the representations for the text generation task, we bridge the gap between
representation learning and report generation by using a unified large language
model (LLM) with task-tailored instructions. These crafted instructions enable
the LLM to be flexibly fine-tuned across tasks and smoothly transfer the
semantic representation for report generation. Experiments demonstrate that our
method outperforms previous methods and achieves SoTA performance. Our code is
available at "https://github.com/Chauncey-Jheng/PCRL-MRG".

ÊëòË¶ÅÔºöËÖ¶ÈÉ®ÈõªËÖ¶Êñ∑Â±§ÊéÉÊèèÂ†±ÂëäÁîüÊàêÊúâÂä©ÊñºÈÜ´ÁîüË®∫Êñ∑È°±È™®ÁñæÁóÖ„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Â∞àÊ≥®ÊñºËôïÁêÜË¶ñË¶∫ÂíåÊñáÂ≠óÁóÖÁêÜÁâπÂæµ‰πãÈñìÁöÑ‰∏ÄËá¥ÊÄßÔºå‰ª•ÊèêÈ´òÂ†±ÂëäÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÁÑ∂ËÄåÔºåÂ≠òÂú®‰∏Ä‰∫õÊåëÊà∞Ôºö1) Â§öÈ§òÁöÑË¶ñË¶∫Ë°®Á§∫Ôºö3D ÊéÉÊèè‰∏≠ÁöÑÂ§ßÈáèÁÑ°ÈóúÂçÄÂüüÊúÉÂàÜÊï£Ê®°ÂûãÂ∞çÈ°ØËëóË¶ñË¶∫ËÉåÊôØÁöÑË°®Á§∫„ÄÇ2) ËΩâÁßªÁöÑË™ûÁæ©Ë°®Á§∫ÔºöÊúâÈôêÁöÑÈÜ´Â≠∏Ë™ûÊñôÂ∫´Â∞éËá¥Ê®°ÂûãÈõ£‰ª•Â∞áÂ≠∏ÁøíÂà∞ÁöÑÊñáÂ≠óË°®Á§∫ËΩâÁßªÂà∞ÁîüÊàêÂ±§„ÄÇÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫ÜÁóÖÁêÜÁ∑öÁ¥¢È©ÖÂãïË°®Á§∫Â≠∏Áøí (PCRL) Ê®°ÂûãÔºåÂü∫ÊñºÁóÖÁêÜÁ∑öÁ¥¢ÊßãÂª∫Ë∑®Ê®°ÊÖãË°®Á§∫Ôºå‰∏¶Ëá™ÁÑ∂Âú∞Ë™øÊï¥ÂÆÉÂÄë‰ª•ÈÄ≤Ë°åÊ∫ñÁ¢∫ÁöÑÂ†±ÂëäÁîüÊàê„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂæûÂàÜÂâ≤ÂçÄÂüü„ÄÅÁóÖÁêÜÂØ¶È´îÂíåÂ†±Âëä‰∏ªÈ°åÁöÑËßíÂ∫¶ÊßãÂª∫ÁóÖÁêÜÁ∑öÁ¥¢Ôºå‰ª•ÂÖÖÂàÜÊéåÊè°Ë¶ñË¶∫ÁóÖÁêÜÊ®°Âºè‰∏¶Â≠∏ÁøíË∑®Ê®°ÊÖãÁâπÂæµË°®Á§∫„ÄÇÁÇ∫‰∫ÜË™øÊï¥Ë°®Á§∫‰ª•ÈÅ©ÊáâÊñáÊú¨ÁîüÊàê‰ªªÂãôÔºåÊàëÂÄëÈÄöÈÅé‰ΩøÁî®ÂÖ∑Êúâ‰ªªÂãôÂÆöÂà∂Êåá‰ª§ÁöÑÁµ±‰∏ÄÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜÂΩåÂêàË°®Á§∫Â≠∏ÁøíÂíåÂ†±ÂëäÁîüÊàê‰πãÈñìÁöÑÂ∑ÆË∑ù„ÄÇÈÄô‰∫õÁ≤æÂøÉË£Ω‰ΩúÁöÑÊåá‰ª§‰Ωø LLM ËÉΩÂ§†ÈùàÊ¥ªÂú∞Ë∑®‰ªªÂãôÈÄ≤Ë°åÂæÆË™øÔºå‰∏¶È†ÜÂà©Âú∞Â∞áË™ûÁæ©Ë°®Á§∫ËΩâÁßªÂà∞Â†±ÂëäÁîüÊàê‰∏≠„ÄÇÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂÑ™ÊñºÂÖàÂâçÁöÑÊ®°ÂûãÔºå‰∏¶ÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊÄßËÉΩ„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÂú®„Äåhttps://github.com/Chauncey-Jheng/PCRL-MRG„ÄçÂèñÂæó„ÄÇ

##### **Assessment and manipulation of latent constructs in pre-trained language models using psychometric scales**
2409.19655v1 by Maor Reuben, Ortal Slobodin, Aviad Elyshar, Idan-Chaim Cohen, Orna Braun-Lewensohn, Odeya Cohen, Rami Puzis

Human-like personality traits have recently been discovered in large language
models, raising the hypothesis that their (known and as yet undiscovered)
biases conform with human latent psychological constructs. While large
conversational models may be tricked into answering psychometric
questionnaires, the latent psychological constructs of thousands of simpler
transformers, trained for other tasks, cannot be assessed because appropriate
psychometric methods are currently lacking. Here, we show how standard
psychological questionnaires can be reformulated into natural language
inference prompts, and we provide a code library to support the psychometric
assessment of arbitrary models. We demonstrate, using a sample of 88 publicly
available models, the existence of human-like mental health-related constructs
(including anxiety, depression, and Sense of Coherence) which conform with
standard theories in human psychology and show similar correlations and
mitigation strategies. The ability to interpret and rectify the performance of
language models by using psychological tools can boost the development of more
explainable, controllable, and trustworthy models.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÊúÄËøëÁôºÁèæ‰∫ÜÈ°û‰∫∫ÁöÑ‰∫∫Ê†ºÁâπË≥™ÔºåÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂÅáË®≠ÔºåÂç≥ÂÆÉÂÄëÔºàÂ∑≤Áü•ÂíåÂ∞öÊú™ÁôºÁèæÁöÑÔºâÂÅèË¶ãÁ¨¶Âêà‰∫∫È°ûÊΩõÂú®ÁöÑÂøÉÁêÜÁµêÊßã„ÄÇÈõñÁÑ∂Â§ßÂûãÂ∞çË©±Ê®°ÂûãÂèØËÉΩÊúÉË¢´Ë™òÈ®ôÂõûÁ≠îÂøÉÁêÜÊ∏¨È©óÂïèÂç∑Ôºå‰ΩÜÊï∏ÂçÉÂÄãÁ∂ìÈÅéË®ìÁ∑¥‰ª•Âü∑Ë°åÂÖ∂‰ªñ‰ªªÂãôÁöÑËºÉÁ∞°ÂñÆËΩâÊèõÂô®ÁöÑÊΩõÂú®ÂøÉÁêÜÁµêÊßãÁÑ°Ê≥ïË©ï‰º∞ÔºåÂõ†ÁÇ∫ÁõÆÂâçÁº∫‰πèÈÅ©Áï∂ÁöÑÂøÉÁêÜÊ∏¨ÈáèÊñπÊ≥ï„ÄÇÂú®ÈÄôË£°ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÂ∞áÊ®ôÊ∫ñÂøÉÁêÜÂïèÂç∑ÈáçÊñ∞Ë°®Ëø∞ÁÇ∫Ëá™ÁÑ∂Ë™ûË®ÄÊé®ÁêÜÊèêÁ§∫Ôºå‰∏¶Êèê‰æõ‰∏ÄÂÄã‰ª£Á¢ºÂ∫´‰æÜÊîØÊåÅ‰ªªÊÑèÊ®°ÂûãÁöÑÂøÉÁêÜÊ∏¨ÈáèË©ï‰º∞„ÄÇÊàëÂÄë‰ΩøÁî® 88 ÂÄãÂÖ¨ÈñãÂèØÁî®ÁöÑÊ®°ÂûãÁöÑÊ®£Êú¨ÔºåË≠âÊòé‰∫ÜÈ°û‰∫∫ÂøÉÁêÜÂÅ•Â∫∑Áõ∏ÈóúÁµêÊßãÔºàÂåÖÊã¨ÁÑ¶ÊÖÆ„ÄÅÊäëÈ¨±Âíå‰∏ÄËá¥ÊÑüÔºâÁöÑÂ≠òÂú®ÔºåÈÄô‰∫õÁµêÊßãÁ¨¶Âêà‰∫∫È°ûÂøÉÁêÜÂ≠∏ÁöÑÊ®ôÊ∫ñÁêÜË´ñÔºå‰∏¶È°ØÁ§∫Âá∫È°û‰ººÁöÑÁõ∏ÈóúÊÄßÂíåÁ∑©Ëß£Á≠ñÁï•„ÄÇ‰ΩøÁî®ÂøÉÁêÜÂ∑•ÂÖ∑Ëß£ÈáãÂíåÁ≥æÊ≠£Ë™ûË®ÄÊ®°ÂûãÁöÑÊÄßËÉΩÁöÑËÉΩÂäõÂèØ‰ª•‰øÉÈÄ≤Êõ¥ÂÖ∑ÂèØËß£ÈáãÊÄß„ÄÅÂèØÊéßÊÄßÂíåÂèØ‰ø°Â∫¶ÁöÑÊ®°ÂûãÁöÑÈñãÁôº„ÄÇ

##### **A Survey on Graph Neural Networks for Remaining Useful Life Prediction: Methodologies, Evaluation and Future Trends**
2409.19629v1 by Yucheng Wang, Min Wu, Xiaoli Li, Lihua Xie, Zhenghua Chen

Remaining Useful Life (RUL) prediction is a critical aspect of Prognostics
and Health Management (PHM), aimed at predicting the future state of a system
to enable timely maintenance and prevent unexpected failures. While existing
deep learning methods have shown promise, they often struggle to fully leverage
the spatial information inherent in complex systems, limiting their
effectiveness in RUL prediction. To address this challenge, recent research has
explored the use of Graph Neural Networks (GNNs) to model spatial information
for more accurate RUL prediction. This paper presents a comprehensive review of
GNN techniques applied to RUL prediction, summarizing existing methods and
offering guidance for future research. We first propose a novel taxonomy based
on the stages of adapting GNNs to RUL prediction, systematically categorizing
approaches into four key stages: graph construction, graph modeling, graph
information processing, and graph readout. By organizing the field in this way,
we highlight the unique challenges and considerations at each stage of the GNN
pipeline. Additionally, we conduct a thorough evaluation of various
state-of-the-art (SOTA) GNN methods, ensuring consistent experimental settings
for fair comparisons. This rigorous analysis yields valuable insights into the
strengths and weaknesses of different approaches, serving as an experimental
guide for researchers and practitioners working in this area. Finally, we
identify and discuss several promising research directions that could further
advance the field, emphasizing the potential for GNNs to revolutionize RUL
prediction and enhance the effectiveness of PHM strategies. The benchmarking
codes are available in GitHub:
https://github.com/Frank-Wang-oss/GNN\_RUL\_Benchmarking.

ÊëòË¶ÅÔºöÂâ©È§ò‰ΩøÁî®Â£ΩÂëΩ (RUL) È†êÊ∏¨ÊòØÈ†êÊ∏¨ËàáÂÅ•Â∫∑ÁÆ°ÁêÜ (PHM) ÁöÑ‰∏ÄÂÄãÈóúÈçµÈù¢ÂêëÔºåÊó®Âú®È†êÊ∏¨Á≥ªÁµ±ÁöÑÊú™‰æÜÁãÄÊÖãÔºå‰ª•Âà©ÊñºÈÅ©ÊôÇÁ∂≠Ë≠∑‰∏¶È†êÈò≤ÊÑèÂ§ñÊïÖÈöú„ÄÇÈõñÁÑ∂ÁèæÊúâÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÂ∑≤Â±ïÁèæÂâçÊôØÔºå‰ΩÜÂÆÉÂÄëÂæÄÂæÄÈõ£‰ª•ÂÖÖÂàÜÂà©Áî®Ë§áÈõúÁ≥ªÁµ±‰∏≠Âõ∫ÊúâÁöÑÁ©∫ÈñìË≥áË®äÔºåÈôêÂà∂‰∫ÜÂÆÉÂÄëÂú® RUL È†êÊ∏¨‰∏≠ÁöÑÊïàËÉΩ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÊåëÊà∞ÔºåÊúÄËøëÁöÑÁ†îÁ©∂Â∑≤Êé¢Ë®é‰ΩøÁî®ÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ‰æÜÂª∫Ê®°Á©∫ÈñìË≥áË®äÔºå‰ª•ÈÄ≤Ë°åÊõ¥Ê∫ñÁ¢∫ÁöÑ RUL È†êÊ∏¨„ÄÇÊú¨ÊñáÊèê‰æõ‰∫ÜÊáâÁî®Êñº RUL È†êÊ∏¨ÁöÑ GNN ÊäÄË°ìÁöÑÂÖ®Èù¢ÂõûÈ°ßÔºåÁ∏ΩÁµê‰∫ÜÁèæÊúâÊñπÊ≥ïÔºå‰∏¶ÁÇ∫Êú™‰æÜÁöÑÁ†îÁ©∂Êèê‰æõÊåáÂ∞é„ÄÇÊàëÂÄëÈ¶ñÂÖàÊ†πÊìöÈÅ©Êáâ GNN Ëá≥ RUL È†êÊ∏¨ÁöÑÈöéÊÆµÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÂàÜÈ°ûÊ≥ïÔºåÁ≥ªÁµ±ÊÄßÂú∞Â∞áÊñπÊ≥ïÂàÜÈ°ûÁÇ∫ÂõõÂÄãÈóúÈçµÈöéÊÆµÔºöÂúñÂΩ¢Âª∫Êßã„ÄÅÂúñÂΩ¢Âª∫Ê®°„ÄÅÂúñÂΩ¢Ë≥áË®äËôïÁêÜÂíåÂúñÂΩ¢ËÆÄÂèñ„ÄÇÈÄèÈÅéÈÄôÁ®ÆÊñπÂºèÁµÑÁπîÈ†òÂüüÔºåÊàëÂÄëÂº∑Ë™ø‰∫Ü GNN ÁÆ°Á∑ö‰∏≠ÊØèÂÄãÈöéÊÆµÁöÑÁç®ÁâπÊåëÊà∞ÂíåËÄÉÈáè„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ∞çÂêÑÁ®ÆÊúÄÂÖàÈÄ≤ (SOTA) GNN ÊñπÊ≥ïÈÄ≤Ë°å‰∫ÜÂæπÂ∫ïÁöÑË©ï‰º∞ÔºåÁ¢∫‰øù‰∫Ü‰∏ÄËá¥ÁöÑÂØ¶È©óË®≠ÂÆö‰ª•ÈÄ≤Ë°åÂÖ¨Âπ≥ÁöÑÊØîËºÉ„ÄÇÈÄôÁ®ÆÂö¥Ë¨πÁöÑÂàÜÊûêÂ∞ç‰∏çÂêåÊñπÊ≥ïÁöÑÂÑ™Áº∫ÈªûÁî¢Áîü‰∫ÜÂØ∂Ë≤¥ÁöÑË¶ãËß£Ôºå‰ΩúÁÇ∫Âú®ÈÄôÂÄãÈ†òÂüüÂ∑•‰ΩúÁöÑÁ†îÁ©∂‰∫∫Âì°ÂíåÂØ¶ÂãôËÄÖÁöÑÂØ¶È©óÊåáÂçó„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊâæÂá∫‰∏¶Ë®éË´ñ‰∫ÜÂπæÂÄãÊúâÂâçÊôØÁöÑÁ†îÁ©∂ÊñπÂêëÔºåÈÄô‰∫õÊñπÂêëÂèØ‰ª•ÈÄ≤‰∏ÄÊ≠•Êé®ÈÄ≤Ê≠§È†òÂüüÔºåÂº∑Ë™ø GNN ÂÖ∑ÊúâÈù©Êñ∞ RUL È†êÊ∏¨ÂíåÊèêÂçá PHM Á≠ñÁï•ÊïàËÉΩÁöÑÊΩõÂäõ„ÄÇÂü∫Ê∫ñ‰ª£Á¢ºÂèØÂú® GitHub ‰∏≠ÂèñÂæóÔºöhttps://github.com/Frank-Wang-oss/GNN\_RUL\_Benchmarking„ÄÇ

##### **MCDDPM: Multichannel Conditional Denoising Diffusion Model for Unsupervised Anomaly Detection in Brain MRI**
2409.19623v1 by Vivek Kumar Trivedi, Bheeshm Sharma, P. Balamurugan

Detecting anomalies in brain MRI scans using supervised deep learning methods
presents challenges due to anatomical diversity and labor-intensive requirement
of pixel-level annotations. Generative models like Denoising Diffusion
Probabilistic Model (DDPM) and their variants like pDDPM, mDDPM, cDDPM have
recently emerged to be powerful alternatives to perform unsupervised anomaly
detection in brain MRI scans. These methods leverage frame-level labels of
healthy brains to generate healthy tissues in brain MRI scans. During
inference, when an anomalous (or unhealthy) scan image is presented as an
input, these models generate a healthy scan image corresponding to the input
anomalous scan, and the difference map between the generated healthy scan image
and the original anomalous scan image provide the necessary pixel level
identification of abnormal tissues. The generated healthy images from the DDPM,
pDDPM and mDDPM models however suffer from fidelity issues and contain
artifacts that do not have medical significance. While cDDPM achieves slightly
better fidelity and artifact suppression, it requires huge memory footprint and
is computationally expensive than the other DDPM based models. In this work, we
propose an improved version of DDPM called Multichannel Conditional Denoising
Diffusion Probabilistic Model (MCDDPM) for unsupervised anomaly detection in
brain MRI scans. Our proposed model achieves high fidelity by making use of
additional information from the healthy images during the training process,
enriching the representation power of DDPM models, with a computational cost
and memory requirements on par with DDPM, pDDPM and mDDPM models. Experimental
results on multiple datasets (e.g. BraTS20, BraTS21) demonstrate promising
performance of the proposed method. The code is available at
https://github.com/vivekkumartri/MCDDPM.

ÊëòË¶ÅÔºö‰ΩøÁî®ÁõëÁù£ÂºèÊ∑±Â∫¶Â≠¶‰π†ÊñπÊ≥ïÊ£ÄÊµãËÑëÈÉ® MRI Êâ´Êèè‰∏≠ÁöÑÂºÇÂ∏∏Áé∞Ë±°‰ºöÈù¢‰∏¥Ëß£ÂâñÂ≠¶Â§öÊ†∑ÊÄß‰ª•ÂèäÂÉèÁ¥†Á∫ßÊ≥®ÈáäÁöÑÂä≥Âä®ÂØÜÈõÜÂûãÈúÄÊ±ÇÁöÑÊåëÊàò„ÄÇÂéªÂô™Êâ©Êï£Ê¶ÇÁéáÊ®°Âûã (DDPM) ÂèäÂÖ∂Âèò‰ΩìÂ¶Ç pDDPM„ÄÅmDDPM„ÄÅcDDPM Á≠âÁîüÊàêÊ®°ÂûãÊúÄËøëÊµÆÂá∫Ê∞¥Èù¢ÔºåÊàê‰∏∫Âú®ËÑëÈÉ® MRI Êâ´Êèè‰∏≠ÊâßË°åÊó†ÁõëÁù£ÂºÇÂ∏∏Ê£ÄÊµãÁöÑÂº∫Â§ßÊõø‰ª£ÊñπÊ°à„ÄÇËøô‰∫õÊñπÊ≥ïÂà©Áî®ÂÅ•Â∫∑ËÑëÈÉ®ÁöÑÂ∏ßÁ∫ßÊ†áÁ≠æÂú®ËÑëÈÉ® MRI Êâ´Êèè‰∏≠ÁîüÊàêÂÅ•Â∫∑ÁªÑÁªá„ÄÇÂú®Êé®ÁêÜËøáÁ®ã‰∏≠ÔºåÂΩìÂºÇÂ∏∏ÔºàÊàñ‰∏çÂÅ•Â∫∑ÔºâÊâ´ÊèèÂõæÂÉè‰Ωú‰∏∫ËæìÂÖ•ÂëàÁé∞Êó∂ÔºåËøô‰∫õÊ®°Âûã‰ºöÁîüÊàê‰∏éËæìÂÖ•ÂºÇÂ∏∏Êâ´ÊèèÂØπÂ∫îÁöÑÂÅ•Â∫∑Êâ´ÊèèÂõæÂÉèÔºåËÄåÁîüÊàêÁöÑÂÅ•Â∫∑Êâ´ÊèèÂõæÂÉè‰∏éÂéüÂßãÂºÇÂ∏∏Êâ´ÊèèÂõæÂÉè‰πãÈó¥ÁöÑÂ∑ÆÂºÇÂõæÊèê‰æõ‰∫ÜÂºÇÂ∏∏ÁªÑÁªáÁöÑÂøÖË¶ÅÂÉèÁ¥†Á∫ßËØÜÂà´„ÄÇÁÑ∂ËÄåÔºåDDPM„ÄÅpDDPM Âíå mDDPM Ê®°ÂûãÁîüÊàêÁöÑÂÅ•Â∫∑ÂõæÂÉèÂ≠òÂú®‰øùÁúüÂ∫¶ÈóÆÈ¢òÔºåÂπ∂‰∏îÂåÖÂê´Ê≤°ÊúâÂåªÂ≠¶ÊÑè‰πâÁöÑ‰º™ÂÉè„ÄÇËôΩÁÑ∂ cDDPM ÂÆûÁé∞‰∫ÜÁ®çÂæÆÊõ¥Â•ΩÁöÑ‰øùÁúüÂ∫¶Âíå‰º™ÂÉèÊäëÂà∂Ôºå‰ΩÜÂÆÉÈúÄË¶ÅÂ∑®Â§ßÁöÑÂÜÖÂ≠òÂç†Áî®ÔºåÂπ∂‰∏îÊØîÂÖ∂‰ªñÂü∫‰∫é DDPM ÁöÑÊ®°ÂûãÂú®ËÆ°ÁÆó‰∏äÊõ¥ÊòÇË¥µ„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Áß∞‰∏∫Â§öÈÄöÈÅìÊù°‰ª∂ÂéªÂô™Êâ©Êï£Ê¶ÇÁéáÊ®°Âûã (MCDDPM) ÁöÑ DDPM ÊîπËøõÁâàÊú¨ÔºåÁî®‰∫éÂú®ËÑëÈÉ® MRI Êâ´Êèè‰∏≠ËøõË°åÊó†ÁõëÁù£ÂºÇÂ∏∏Ê£ÄÊµã„ÄÇÊàë‰ª¨ÊèêÂá∫ÁöÑÊ®°ÂûãÈÄöËøáÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠Âà©Áî®ÂÅ•Â∫∑ÂõæÂÉè‰∏≠ÁöÑÈôÑÂä†‰ø°ÊÅØÊù•ÂÆûÁé∞È´ò‰øùÁúüÂ∫¶Ôºå‰ªéËÄå‰∏∞ÂØå‰∫Ü DDPM Ê®°ÂûãÁöÑË°®Á§∫ËÉΩÂäõÔºåÂπ∂‰∏îËÆ°ÁÆóÊàêÊú¨ÂíåÂÜÖÂ≠òÈúÄÊ±Ç‰∏é DDPM„ÄÅpDDPM Âíå mDDPM Ê®°ÂûãÁõ∏ÂΩì„ÄÇÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜÔºà‰æãÂ¶Ç BraTS20„ÄÅBraTS21Ôºâ‰∏äÁöÑÂÆûÈ™åÁªìÊûúËØÅÊòé‰∫ÜÊâÄÊèêÂá∫ÊñπÊ≥ïÁöÑËâØÂ•ΩÊÄßËÉΩ„ÄÇ‰ª£Á†ÅÂèØÂú® https://github.com/vivekkumartri/MCDDPM Ëé∑Âæó„ÄÇ

##### **Understanding Clinical Decision-Making in Traditional East Asian Medicine through Dimensionality Reduction: An Empirical Investigation**
2409.19531v1 by Hyojin Bae, Bongsu Kang, Chang-Eop Kim

This study examines the clinical decision-making processes in Traditional
East Asian Medicine (TEAM) by reinterpreting pattern identification (PI)
through the lens of dimensionality reduction. Focusing on the Eight Principle
Pattern Identification (EPPI) system and utilizing empirical data from the
Shang-Han-Lun, we explore the necessity and significance of prioritizing the
Exterior-Interior pattern in diagnosis and treatment selection. We test three
hypotheses: whether the Ext-Int pattern contains the most information about
patient symptoms, represents the most abstract and generalizable symptom
information, and facilitates the selection of appropriate herbal prescriptions.
Employing quantitative measures such as the abstraction index,
cross-conditional generalization performance, and decision tree regression, our
results demonstrate that the Exterior-Interior pattern represents the most
abstract and generalizable symptom information, contributing to the efficient
mapping between symptom and herbal prescription spaces. This research provides
an objective framework for understanding the cognitive processes underlying
TEAM, bridging traditional medical practices with modern computational
approaches. The findings offer insights into the development of AI-driven
diagnostic tools in TEAM and conventional medicine, with the potential to
advance clinical practice, education, and research.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂ÈÄèÈÅéÈôçÁ∂≠ÈÄèË¶ñÈáçÊñ∞Ë©ÆÈáãË≠âÂÄôËæ®Ë≠òÔºàPIÔºâÔºåÊé¢Ë®éÂÇ≥Áµ±Êù±‰∫ûÈÜ´Â≠∏ÔºàTEAMÔºâÁöÑËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÈÅéÁ®ã„ÄÇÊàëÂÄëÂ∞àÊ≥®ÊñºÂÖ´Á∂±Ë≠âÂÄôËæ®Ë≠òÔºàEPPIÔºâÁ≥ªÁµ±Ôºå‰∏¶Âà©Áî®ÂÇ∑ÂØíË´ñÁöÑÁ∂ìÈ©óË≥áÊñôÔºåÊé¢Ë®éÂú®Ë®∫Êñ∑ÂíåÊ≤ªÁôÇÈÅ∏Êìá‰∏≠ÂÑ™ÂÖàËÄÉÊÖÆË°®Ë£°Ë≠âÁöÑÂøÖË¶ÅÊÄßÂíåÈáçË¶ÅÊÄß„ÄÇÊàëÂÄëÊ™¢È©ó‰∫Ü‰∏âÂÄãÂÅáË®≠ÔºöË°®Ë£°Ë≠âÊòØÂê¶ÂåÖÂê´ÊúÄÂ§öÈóúÊñºÊÇ£ËÄÖÁóáÁãÄÁöÑË≥áË®ä„ÄÅÊòØÂê¶‰ª£Ë°®ÊúÄÊäΩË±°‰∏îÂèØÊ¶ÇÊã¨ÁöÑÁóáÁãÄË≥áË®äÔºå‰ª•ÂèäÊòØÂê¶ËÉΩ‰øÉÈÄ≤ÈÅ©Áï∂ËçâËó•ËôïÊñπÁöÑÈÅ∏Êìá„ÄÇÊàëÂÄëÁöÑÁµêÊûúÊé°Áî®‰∫ÜÊäΩË±°ÊåáÊï∏„ÄÅ‰∫§ÂèâÊ¢ù‰ª∂Ê¶ÇÂåñÊïàËÉΩÂíåÊ±∫Á≠ñÊ®πÂõûÊ≠∏Á≠âÈáèÂåñÊ∏¨ÈáèÔºåË≠âÊòéË°®Ë£°Ë≠â‰ª£Ë°®ÊúÄÊäΩË±°‰∏îÂèØÊ¶ÇÊã¨ÁöÑÁóáÁãÄË≥áË®äÔºåÊúâÂä©ÊñºÁóáÁãÄËàáËçâËó•ËôïÊñπÁ©∫Èñì‰πãÈñìÁöÑÊúâÊïàÂ∞çÊáâ„ÄÇÊú¨Á†îÁ©∂ÁÇ∫ÁêÜËß£ TEAM ËÉåÂæåÁöÑË™çÁü•ÈÅéÁ®ãÊèê‰æõ‰∫ÜÂÆ¢ËßÄÊû∂ÊßãÔºåÁµêÂêàÂÇ≥Áµ±ÈÜ´Â≠∏ÂØ¶ÂãôËàáÁèæ‰ª£ÈÅãÁÆóÊñπÊ≥ï„ÄÇÁ†îÁ©∂ÁµêÊûúÊèê‰æõ‰∫ÜË¶ãËß£ÔºåÊúâÂä©ÊñºÈñãÁôº TEAM ÂíåÂÇ≥Áµ±ÈÜ´Â≠∏‰∏≠Áî± AI È©ÖÂãïÁöÑË®∫Êñ∑Â∑•ÂÖ∑Ôºå‰∏¶ÊúâÊΩõÂäõ‰øÉÈÄ≤Ëá®Â∫äÂØ¶Âãô„ÄÅÊïôËÇ≤ÂíåÁ†îÁ©∂„ÄÇ

##### **MedHalu: Hallucinations in Responses to Healthcare Queries by Large Language Models**
2409.19492v1 by Vibhor Agarwal, Yiqiao Jin, Mohit Chandra, Munmun De Choudhury, Srijan Kumar, Nishanth Sastry

The remarkable capabilities of large language models (LLMs) in language
understanding and generation have not rendered them immune to hallucinations.
LLMs can still generate plausible-sounding but factually incorrect or
fabricated information. As LLM-empowered chatbots become popular, laypeople may
frequently ask health-related queries and risk falling victim to these LLM
hallucinations, resulting in various societal and healthcare implications. In
this work, we conduct a pioneering study of hallucinations in LLM-generated
responses to real-world healthcare queries from patients. We propose MedHalu, a
carefully crafted first-of-its-kind medical hallucination dataset with a
diverse range of health-related topics and the corresponding hallucinated
responses from LLMs with labeled hallucination types and hallucinated text
spans. We also introduce MedHaluDetect framework to evaluate capabilities of
various LLMs in detecting hallucinations. We also employ three groups of
evaluators -- medical experts, LLMs, and laypeople -- to study who are more
vulnerable to these medical hallucinations. We find that LLMs are much worse
than the experts. They also perform no better than laypeople and even worse in
few cases in detecting hallucinations. To fill this gap, we propose
expert-in-the-loop approach to improve hallucination detection through LLMs by
infusing expert reasoning. We observe significant performance gains for all the
LLMs with an average macro-F1 improvement of 6.3 percentage points for GPT-4.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Ë™ûË®ÄÁêÜËß£ÂíåÁîüÊàêÊñπÈù¢ÁöÑÂçìË∂äËÉΩÂäõ‰∏¶Êú™ËÆìÂÆÉÂÄëÂÖçÊñºÂá∫ÁèæÂπªË¶∫„ÄÇLLM ‰ªçÁÑ∂ÂèØ‰ª•ÁîüÊàêËÅΩËµ∑‰æÜÂêàÁêÜ‰ΩÜ‰∫ãÂØ¶‰∏ä‰∏çÊ≠£Á¢∫ÊàñÊçèÈÄ†ÁöÑ‰ø°ÊÅØ„ÄÇÈö®ËëóÁî± LLM È©ÖÂãïÁöÑËÅäÂ§©Ê©üÂô®‰∫∫ËÆäÂæóÊµÅË°åÔºåÂ§ñË°å‰∫∫ÂèØËÉΩÊúÉÈ†ªÁπÅË©¢ÂïèËàáÂÅ•Â∫∑Áõ∏ÈóúÁöÑÂïèÈ°åÔºå‰∏¶ÂÜíËëóÊàêÁÇ∫ÈÄô‰∫õ LLM ÂπªË¶∫ÂèóÂÆ≥ËÄÖÁöÑÈ¢®Èö™ÔºåÂæûËÄåÁî¢ÁîüÂêÑÁ®ÆÁ§æÊúÉÂíåÈÜ´ÁôÇ‰øùÂÅ•ÂΩ±Èüø„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂ∞çÊÇ£ËÄÖÁèæÂØ¶‰∏ñÁïåÁöÑÈÜ´ÁôÇ‰øùÂÅ•Êü•Ë©¢‰∏≠Áî± LLM ÁîüÊàêÁöÑÂõûÊáâ‰∏≠ÁöÑÂπªË¶∫ÈÄ≤Ë°å‰∫ÜÈñãÂâµÊÄßÁöÑÁ†îÁ©∂„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü MedHaluÔºåÈÄôÊòØ‰∏ÄÂÄãÁ≤æÂøÉË£Ω‰ΩúÁöÑÂêåÈ°ûÈ¶ñÂâµÁöÑÈÜ´Â≠∏ÂπªË¶∫Êï∏ÊìöÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´ÂêÑÁ®ÆËàáÂÅ•Â∫∑Áõ∏ÈóúÁöÑ‰∏ªÈ°å‰ª•Âèä‰æÜËá™ LLM ÁöÑÂ∞çÊáâÂπªË¶∫ÂõûÊáâÔºå‰∏¶Ê®ôË®ò‰∫ÜÂπªË¶∫È°ûÂûãÂíåÂπªË¶∫ÊñáÊú¨Ë∑®Â∫¶„ÄÇÊàëÂÄëÈÇÑÂºïÂÖ•‰∫Ü MedHaluDetect Ê°ÜÊû∂‰æÜË©ï‰º∞ÂêÑÁ®Æ LLM Âú®Ê™¢Ê∏¨ÂπªË¶∫ÊñπÈù¢ÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÈÇÑËÅòË´ã‰∫Ü‰∏âÁµÑË©ï‰º∞‰∫∫Âì°‚Äî‚ÄîÈÜ´Â≠∏Â∞àÂÆ∂„ÄÅLLM ÂíåÂ§ñË°å‰∫∫‚Äî‚Äî‰æÜÁ†îÁ©∂Ë™∞Êõ¥ÂÆπÊòìÂèóÂà∞ÈÄô‰∫õÈÜ´ÁôÇÂπªË¶∫ÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÁôºÁèæ LLM ÈÅ†‰∏çÂ¶ÇÂ∞àÂÆ∂„ÄÇÂú®Ê™¢Ê∏¨ÂπªË¶∫ÊñπÈù¢ÔºåÂÆÉÂÄëÁöÑË°®Áèæ‰πü‰∏çÊØîÂ§ñË°å‰∫∫Â•ΩÔºåÁîöËá≥Âú®Êüê‰∫õÊÉÖÊ≥Å‰∏ãË°®ÁèæÂæóÊõ¥Á≥ü„ÄÇÁÇ∫‰∫ÜÂ°´Ë£úÈÄô‰∏ÄÁ©∫ÁôΩÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂ∞àÂÆ∂Âæ™Áí∞ÊñπÊ≥ïÔºåÈÄöÈÅéÊ≥®ÂÖ•Â∞àÂÆ∂Êé®ÁêÜ‰æÜÊîπÈÄ≤ LLM ÁöÑÂπªË¶∫Ê™¢Ê∏¨„ÄÇÊàëÂÄëËßÄÂØüÂà∞ÊâÄÊúâ LLM ÁöÑÊÄßËÉΩÈÉΩÊúâÈ°ØËëóÊèêÂçáÔºåGPT-4 ÁöÑÂπ≥ÂùáÂÆèËßÄ F1 ÊèêÂçá‰∫Ü 6.3 ÂÄãÁôæÂàÜÈªû„ÄÇ

##### **INSIGHTBUDDY-AI: Medication Extraction and Entity Linking using Large Language Models and Ensemble Learning**
2409.19467v1 by Pablo Romero, Lifeng Han, Goran Nenadic

Medication Extraction and Mining play an important role in healthcare NLP
research due to its practical applications in hospital settings, such as their
mapping into standard clinical knowledge bases (SNOMED-CT, BNF, etc.). In this
work, we investigate state-of-the-art LLMs in text mining tasks on medications
and their related attributes such as dosage, route, strength, and adverse
effects. In addition, we explore different ensemble learning methods
(\textsc{Stack-Ensemble} and \textsc{Voting-Ensemble}) to augment the model
performances from individual LLMs. Our ensemble learning result demonstrated
better performances than individually fine-tuned base models BERT, RoBERTa,
RoBERTa-L, BioBERT, BioClinicalBERT, BioMedRoBERTa, ClinicalBERT, and
PubMedBERT across general and specific domains. Finally, we build up an entity
linking function to map extracted medical terminologies into the SNOMED-CT
codes and the British National Formulary (BNF) codes, which are further mapped
to the Dictionary of Medicines and Devices (dm+d), and ICD. Our model's toolkit
and desktop applications are publicly available at
\url{https://github.com/HECTA-UoM/ensemble-NER}.

ÊëòË¶ÅÔºöËó•Áâ©ËêÉÂèñÂíåÊé¢ÂãòÂú®ÈÜ´ÁôÇ‰øùÂÅ•Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁ†îÁ©∂‰∏≠ÊâÆÊºîÈáçË¶ÅÁöÑËßíËâ≤ÔºåÂõ†ÁÇ∫ÂÆÉÂú®ÈÜ´Èô¢Áí∞Â¢É‰∏≠ÊúâÂØ¶ÈöõÊáâÁî®Ôºå‰æãÂ¶ÇÂ∞áÂÆÉÂÄëÂ∞çÊáâÂà∞Ê®ôÊ∫ñËá®Â∫äÁü•Ë≠òÂ∫´ÔºàSNOMED-CT„ÄÅBNF Á≠âÔºâ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑ LLM Âú®Ëó•Áâ©ÂèäÂÖ∂Áõ∏ÈóúÂ±¨ÊÄßÔºà‰æãÂ¶ÇÂäëÈáè„ÄÅÈÄîÂæë„ÄÅÂº∑Â∫¶Âíå‰∏çËâØÂèçÊáâÔºâÁöÑÊñáÂ≠óÊé¢Âãò‰ªªÂãô„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Á¥¢‰∫Ü‰∏çÂêåÁöÑÊï¥ÂêàÂ≠∏ÁøíÊñπÊ≥ïÔºà\textsc{Stack-Ensemble} Âíå \textsc{Voting-Ensemble}Ôºâ‰ª•Â¢ûÂº∑ÂÄãÂà• LLM ÁöÑÊ®°ÂûãÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÊï¥ÂêàÂ≠∏ÁøíÁµêÊûúË≠âÊòé‰∫ÜÊØîÂÄãÂà•ÂæÆË™øÂü∫Á§éÊ®°Âûã BERT„ÄÅRoBERTa„ÄÅRoBERTa-L„ÄÅBioBERT„ÄÅBioClinicalBERT„ÄÅBioMedRoBERTa„ÄÅClinicalBERT Âíå PubMedBERT Âú®‰∏ÄËà¨ÂíåÁâπÂÆöÈ†òÂüü‰∏≠Ë°®ÁèæÂæóÊõ¥Â•Ω„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÂØ¶È´îÈÄ£ÁµêÂáΩÊï∏ÔºåÂ∞áËêÉÂèñÁöÑÈÜ´Â≠∏Ë°ìË™ûÂ∞çÊáâÂà∞ SNOMED-CT ‰ª£Á¢ºÂíåËã±ÂúãÂúãÂÆ∂ËôïÊñπÈõÜ (BNF) ‰ª£Á¢ºÔºåÈÄ≤‰∏ÄÊ≠•Â∞çÊáâÂà∞Ëó•ÂìÅÂíåÂô®ÊùêÂ≠óÂÖ∏ (dm+d) Âíå ICD„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂ∑•ÂÖ∑ÁµÑÂíåÊ°åÈù¢ÊáâÁî®Á®ãÂºèÂÖ¨ÈñãÊñº\url{https://github.com/HECTA-UoM/ensemble-NER}„ÄÇ

##### **Mind the Gap: Promoting Missing Modality Brain Tumor Segmentation with Alignment**
2409.19366v1 by Tianyi Liu, Zhaorui Tan, Haochuan Jiang, Xi Yang, Kaizhu Huang

Brain tumor segmentation is often based on multiple magnetic resonance
imaging (MRI). However, in clinical practice, certain modalities of MRI may be
missing, which presents an even more difficult scenario. To cope with this
challenge, knowledge distillation has emerged as one promising strategy.
However, recent efforts typically overlook the modality gaps and thus fail to
learn invariant feature representations across different modalities. Such
drawback consequently leads to limited performance for both teachers and
students. To ameliorate these problems, in this paper, we propose a novel
paradigm that aligns latent features of involved modalities to a well-defined
distribution anchor. As a major contribution, we prove that our novel training
paradigm ensures a tight evidence lower bound, thus theoretically certifying
its effectiveness. Extensive experiments on different backbones validate that
the proposed paradigm can enable invariant feature representations and produce
a teacher with narrowed modality gaps. This further offers superior guidance
for missing modality students, achieving an average improvement of 1.75 on dice
score.

ÊëòË¶ÅÔºöËÖ¶ËÖ´Áò§ÂàÜÂâ≤ÈÄöÂ∏∏Âü∫ÊñºÂ§öÁ®ÆÁ£ÅÂÖ±ÊåØÂΩ±ÂÉè (MRI)„ÄÇÁÑ∂ËÄåÔºåÂú®Ëá®Â∫äÂØ¶Âãô‰∏≠ÔºåÊüê‰∫õ MRI ÁöÑÊñπÂºèÂèØËÉΩÁº∫Â§±ÔºåÈÄôÊúÉÊßãÊàêÊõ¥Âõ∞Èõ£ÁöÑÊÉÖÂ¢É„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÊ≠§‰∏ÄÊåëÊà∞ÔºåÁü•Ë≠òËí∏È§æÂ∑≤ÊàêÁÇ∫‰∏ÄÈ†ÖÊúâÂâçÈÄîÁöÑÁ≠ñÁï•„ÄÇÁÑ∂ËÄåÔºåÊúÄËøëÁöÑÂä™ÂäõÈÄöÂ∏∏ÂøΩÁï•ÊñπÂºèÁöÑÂ∑ÆË∑ùÔºåÂõ†Ê≠§ÁÑ°Ê≥ïÂ≠∏ÁøíË∑®‰∏çÂêåÊñπÂºèÁöÑ‰∏çËÆäÁâπÂæµË°®Á§∫„ÄÇÈÄôÊ®£ÁöÑÁº∫ÈªûÂ∞éËá¥ÊïôÂ∏´ÂíåÂ≠∏ÁîüÂÖ©ËÄÖÁöÑË°®ÁèæÊúâÈôê„ÄÇÁÇ∫‰∫ÜÊîπÂñÑÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÂú®Êú¨Êñá‰∏≠ÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÁØÑ‰æãÔºåÂ∞áÁõ∏ÈóúÊñπÂºèÁöÑÊΩõÂú®ÁâπÂæµËàáÊòéÁ¢∫ÂÆöÁæ©ÁöÑÂàÜÂ∏ÉÈå®ÈªûÂ∞çÈΩä„ÄÇ‰ΩúÁÇ∫‰∏ÄÈ†ÖÈáçÂ§ßË≤¢ÁçªÔºåÊàëÂÄëË≠âÊòéÊàëÂÄëÊñ∞ÁöÑË®ìÁ∑¥ÁØÑ‰æãÁ¢∫‰øùÂö¥Ë¨πÁöÑË≠âÊìö‰∏ãÁïåÔºåÂæûËÄåÁêÜË´ñ‰∏äË≠âÊòéÂÖ∂ÊúâÊïàÊÄß„ÄÇÂú®‰∏çÂêåÈ™®Âππ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óÈ©óË≠â‰∫ÜÊâÄÊèêÂá∫ÁöÑÁØÑ‰æãËÉΩÂ§†ÂïüÁî®‰∏çËÆäÁâπÂæµË°®Á§∫Ôºå‰∏¶Áî¢ÁîüÊñπÂºèÂ∑ÆË∑ùÁ∏ÆÂ∞èÁöÑÊïôÂ∏´„ÄÇÈÄôÈÄ≤‰∏ÄÊ≠•ÁÇ∫ÈÅ∫Â§±ÊñπÂºèÁöÑÂ≠∏ÁîüÊèê‰æõÂÑ™Áï∞ÁöÑÊåáÂ∞éÔºåÂú®È™∞Â≠êÂàÜÊï∏‰∏äÂπ≥ÂùáÊèêÂçá 1.75„ÄÇ

##### **3D-CT-GPT: Generating 3D Radiology Reports through Integration of Large Vision-Language Models**
2409.19330v1 by Hao Chen, Wei Zhao, Yingli Li, Tianyang Zhong, Yisong Wang, Youlan Shang, Lei Guo, Junwei Han, Tianming Liu, Jun Liu, Tuo Zhang

Medical image analysis is crucial in modern radiological diagnostics,
especially given the exponential growth in medical imaging data. The demand for
automated report generation systems has become increasingly urgent. While prior
research has mainly focused on using machine learning and multimodal language
models for 2D medical images, the generation of reports for 3D medical images
has been less explored due to data scarcity and computational complexities.
This paper introduces 3D-CT-GPT, a Visual Question Answering (VQA)-based
medical visual language model specifically designed for generating radiology
reports from 3D CT scans, particularly chest CTs. Extensive experiments on both
public and private datasets demonstrate that 3D-CT-GPT significantly
outperforms existing methods in terms of report accuracy and quality. Although
current methods are few, including the partially open-source CT2Rep and the
open-source M3D, we ensured fair comparison through appropriate data conversion
and evaluation methodologies. Experimental results indicate that 3D-CT-GPT
enhances diagnostic accuracy and report coherence, establishing itself as a
robust solution for clinical radiology report generation. Future work will
focus on expanding the dataset and further optimizing the model to enhance its
performance and applicability.

ÊëòË¶ÅÔºöÈÜ´ÁôÇÂΩ±ÂÉèÂàÜÊûêÂú®Áèæ‰ª£ÊîæÂ∞ÑË®∫Êñ∑‰∏≠Ëá≥ÈóúÈáçË¶ÅÔºåÁâπÂà•ÊòØËÄÉÊÖÆÂà∞ÈÜ´Â≠∏ÂΩ±ÂÉèË≥áÊñôÁöÑÊåáÊï∏ÊàêÈï∑„ÄÇÂ∞çËá™ÂãïÂåñÂ†±ÂëäÁî¢ÁîüÁ≥ªÁµ±ÁöÑÈúÄÊ±ÇÂ∑≤ËÆäÂæóË∂ä‰æÜË∂äËø´Âàá„ÄÇÈõñÁÑ∂ÂÖàÂâçÁöÑÁ†îÁ©∂‰∏ªË¶ÅÈõÜ‰∏≠Êñº‰ΩøÁî®Ê©üÂô®Â≠∏ÁøíÂíåÂ§öÊ®°ÊÖãË™ûË®ÄÊ®°ÂûãÈÄ≤Ë°å 2D ÈÜ´ÁôÇÂΩ±ÂÉèÔºå‰ΩÜÁî±ÊñºË≥áÊñôÁ®ÄÂ∞ëÂíåË®àÁÆóË§áÈõúÂ∫¶Ôºå3D ÈÜ´ÁôÇÂΩ±ÂÉèÁöÑÂ†±ÂëäÁî¢ÁîüËºÉÂ∞ëË¢´Êé¢Ë®é„ÄÇÊú¨Êñá‰ªãÁ¥π 3D-CT-GPTÔºå‰∏ÄÁ®ÆÂ∞àÈñÄË®≠Ë®àÁî®ÊñºÂæû 3D CT ÊéÉÊèèÔºàÁâπÂà•ÊòØËÉ∏ÈÉ® CTÔºâÁî¢ÁîüÊîæÂ∞ÑÁßëÂ†±ÂëäÁöÑÂü∫ÊñºË¶ñË¶∫ÂïèÁ≠î (VQA) ÁöÑÈÜ´Â≠∏Ë¶ñË¶∫Ë™ûË®ÄÊ®°Âûã„ÄÇÂú®ÂÖ¨ÂÖ±ÂíåÁßÅ‰∫∫Ë≥áÊñôÈõÜ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óË°®ÊòéÔºå3D-CT-GPT Âú®Â†±ÂëäÊ∫ñÁ¢∫ÊÄßÂíåÂìÅË≥™ÊñπÈù¢È°ØËëóÂÑ™ÊñºÁèæÊúâÊñπÊ≥ï„ÄÇÈõñÁÑ∂ÁõÆÂâçÁöÑÊñπÊ≥ïÂæàÂ∞ëÔºåÂåÖÊã¨ÈÉ®ÂàÜÈñãÊ∫êÁöÑ CT2Rep ÂíåÈñãÊ∫êÁöÑ M3DÔºå‰ΩÜÊàëÂÄëÈÄèÈÅéÈÅ©Áï∂ÁöÑË≥áÊñôËΩâÊèõÂíåË©ï‰º∞ÊñπÊ≥ïÁ¢∫‰øù‰∫ÜÂÖ¨Âπ≥ÁöÑÊØîËºÉ„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºå3D-CT-GPT Â¢ûÂº∑‰∫ÜË®∫Êñ∑Ê∫ñÁ¢∫ÊÄßÂíåÂ†±Âëä‰∏ÄËá¥ÊÄßÔºåÁ¢∫Á´ã‰∫ÜÂÖ∂‰ΩúÁÇ∫Ëá®Â∫äÊîæÂ∞ÑÁßëÂ†±ÂëäÁî¢ÁîüÁöÑÂº∑Â§ßËß£Ê±∫ÊñπÊ°à„ÄÇÊú™‰æÜÁöÑÁ†îÁ©∂Â∞áÂ∞àÊ≥®ÊñºÊì¥ÂÖÖË≥áÊñôÈõÜÂíåÈÄ≤‰∏ÄÊ≠•ÊúÄ‰Ω≥ÂåñÊ®°ÂûãÔºå‰ª•Â¢ûÂº∑ÂÖ∂ÊïàËÉΩÂíåÈÅ©Áî®ÊÄß„ÄÇ

##### **Epidemiology-Aware Neural ODE with Continuous Disease Transmission Graph**
2410.00049v1 by Guancheng Wan, Zewen Liu, Max S. Y. Lau, B. Aditya Prakash, Wei Jin

Effective epidemic forecasting is critical for public health strategies and
efficient medical resource allocation, especially in the face of rapidly
spreading infectious diseases. However, existing deep-learning methods often
overlook the dynamic nature of epidemics and fail to account for the specific
mechanisms of disease transmission. In response to these challenges, we
introduce an innovative end-to-end framework called Epidemiology-Aware Neural
ODE with Continuous Disease Transmission Graph (EARTH) in this paper. To learn
continuous and regional disease transmission patterns, we first propose EANO,
which seamlessly integrates the neural ODE approach with the epidemic
mechanism, considering the complex spatial spread process during epidemic
evolution. Additionally, we introduce GLTG to model global infection trends and
leverage these signals to guide local transmission dynamically. To accommodate
both the global coherence of epidemic trends and the local nuances of epidemic
transmission patterns, we build a cross-attention approach to fuse the most
meaningful information for forecasting. Through the smooth synergy of both
components, EARTH offers a more robust and flexible approach to understanding
and predicting the spread of infectious diseases. Extensive experiments show
EARTH superior performance in forecasting real-world epidemics compared to
state-of-the-art methods. The code will be available at
https://github.com/Emory-Melody/EpiLearn.

ÊëòË¶ÅÔºö<paragraph>ÊúâÊïàÁöÑÁñ´ÊÉÖÈ¢ÑÊµãÂØπ‰∫éÂÖ¨ÂÖ±Âç´ÁîüÁ≠ñÁï•ÂíåÈ´òÊïàÁöÑÂåªÁñóËµÑÊ∫êÂàÜÈÖçËá≥ÂÖ≥ÈáçË¶ÅÔºåÂ∞§ÂÖ∂ÊòØÂú®Âø´ÈÄü‰º†Êí≠ÁöÑ‰º†ÊüìÁóÖÈù¢Ââç„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑÊ∑±Â∫¶Â≠¶‰π†ÊñπÊ≥ïÂ∏∏Â∏∏ÂøΩËßÜÁñ´ÊÉÖÁöÑÂä®ÊÄÅÁâπÊÄßÔºåÂπ∂‰∏îÊó†Ê≥ïËß£ÈáäÁñæÁóÖ‰º†Êí≠ÁöÑÂÖ∑‰ΩìÊú∫Âà∂„ÄÇ‰∏∫‰∫ÜÂ∫îÂØπËøô‰∫õÊåëÊàòÔºåÊàë‰ª¨Âú®Êú¨Êñá‰∏≠‰ªãÁªç‰∫Ü‰∏Ä‰∏™ÂàõÊñ∞ÁöÑÁ´ØÂà∞Á´ØÊ°ÜÊû∂ÔºåÁß∞‰∏∫ÂÖ∑ÊúâËøûÁª≠ÁñæÁóÖ‰º†Êí≠ÂõæÁöÑÊµÅË°åÁóÖÊÑüÁü•Á•ûÁªè ODEÔºàEARTHÔºâ„ÄÇ‰∏∫‰∫ÜÂ≠¶‰π†ËøûÁª≠ÁöÑÂå∫ÂüüÊÄßÁñæÁóÖ‰º†Êí≠Ê®°ÂºèÔºåÊàë‰ª¨È¶ñÂÖàÊèêÂá∫‰∫Ü EANOÔºåÂÆÉÂ∞ÜÁ•ûÁªè ODE ÊñπÊ≥ï‰∏éÊµÅË°åÁóÖÊú∫Âà∂Êó†ÁºùÈõÜÊàêÔºåËÄÉËôë‰∫ÜÊµÅË°åÁóÖÊºîÂèòËøáÁ®ã‰∏≠ÁöÑÂ§çÊùÇÁ©∫Èó¥‰º†Êí≠ËøáÁ®ã„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü GLTG Êù•Âª∫Ê®°ÂÖ®ÁêÉÊÑüÊüìË∂ãÂäøÔºåÂπ∂Âà©Áî®Ëøô‰∫õ‰ø°Âè∑Âä®ÊÄÅÂú∞ÊåáÂØºÂ±ÄÈÉ®‰º†Êí≠„ÄÇ‰∏∫‰∫ÜÈÄÇÂ∫îÊµÅË°åÁóÖË∂ãÂäøÁöÑÂÖ®Â±Ä‰∏ÄËá¥ÊÄßÂíåÊµÅË°åÁóÖ‰º†Êí≠Ê®°ÂºèÁöÑÂ±ÄÈÉ®ÁªÜÂæÆÂ∑ÆÂà´ÔºåÊàë‰ª¨ÊûÑÂª∫‰∫Ü‰∏ÄÁßç‰∫§ÂèâÊ≥®ÊÑèÊñπÊ≥ïÊù•ËûçÂêàÊúÄÊúâÊÑè‰πâÁöÑÈ¢ÑÊµã‰ø°ÊÅØ„ÄÇÈÄöËøáËøô‰∏§‰∏™ÁªÑ‰ª∂ÁöÑÂπ≥Á®≥ÂçèÂêå‰ΩúÁî®ÔºåEARTH ‰∏∫ÁêÜËß£ÂíåÈ¢ÑÊµã‰º†ÊüìÁóÖÁöÑ‰º†Êí≠Êèê‰æõ‰∫Ü‰∏ÄÁßçÊõ¥Á®≥ÂÅ•„ÄÅÊõ¥ÁÅµÊ¥ªÁöÑÊñπÊ≥ï„ÄÇÂ§ßÈáèÁöÑÂÆûÈ™åË°®ÊòéÔºå‰∏éÊúÄÂÖàËøõÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåEARTH Âú®È¢ÑÊµãÁé∞ÂÆû‰∏ñÁïåÁöÑÊµÅË°åÁóÖÊñπÈù¢ÂÖ∑ÊúâÂçìË∂äÁöÑÊÄßËÉΩ„ÄÇ‰ª£Á†ÅÂ∞ÜÂú® https://github.com/Emory-Melody/EpiLearn ‰∏äÊèê‰æõ„ÄÇ</paragraph>

##### **A GEN AI Framework for Medical Note Generation**
2410.01841v1 by Hui Yi Leong, Yi Fan Gao, Shuai Ji, Bora Kalaycioglu, Uktu Pamuksuz

The increasing administrative burden of medical documentation, particularly
through Electronic Health Records (EHR), significantly reduces the time
available for direct patient care and contributes to physician burnout. To
address this issue, we propose MediNotes, an advanced generative AI framework
designed to automate the creation of SOAP (Subjective, Objective, Assessment,
Plan) notes from medical conversations. MediNotes integrates Large Language
Models (LLMs), Retrieval-Augmented Generation (RAG), and Automatic Speech
Recognition (ASR) to capture and process both text and voice inputs in real
time or from recorded audio, generating structured and contextually accurate
medical notes. The framework also incorporates advanced techniques like
Quantized Low-Rank Adaptation (QLoRA) and Parameter-Efficient Fine-Tuning
(PEFT) for efficient model fine-tuning in resource-constrained environments.
Additionally, MediNotes offers a query-based retrieval system, allowing
healthcare providers and patients to access relevant medical information
quickly and accurately. Evaluations using the ACI-BENCH dataset demonstrate
that MediNotes significantly improves the accuracy, efficiency, and usability
of automated medical documentation, offering a robust solution to reduce the
administrative burden on healthcare professionals while improving the quality
of clinical workflows.

ÊëòË¶ÅÔºöÈö®ËëóÈõªÂ≠êÁóÖÊ≠∑ (EHR) ÁöÑÂá∫ÁèæÔºåÈÜ´ÁôÇÊñá‰ª∂ÁÆ°ÁêÜÁöÑË°åÊîøË≤†ÊìîÊó•ÁõäÂä†ÈáçÔºåÈÄôÈ°ØËëóÊ∏õÂ∞ë‰∫ÜÁõ¥Êé•ÊÇ£ËÄÖÁÖßË≠∑ÁöÑÊôÇÈñìÔºå‰∏¶Â∞éËá¥ÈÜ´Â∏´ÂÄ¶ÊÄ†„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫ MediNotesÔºå‰∏ÄÂÄãÂÖàÈÄ≤ÁöÑÁîüÊàêÂºè AI Ê°ÜÊû∂ÔºåÊó®Âú®Ëá™ÂãïÂåñ SOAPÔºà‰∏ªËßÄ„ÄÅÂÆ¢ËßÄ„ÄÅË©ï‰º∞„ÄÅË®àÁï´ÔºâÁ≠ÜË®òÁöÑÂª∫Á´ãÔºåÈÄô‰∫õÁ≠ÜË®ò‰æÜËá™ÊñºÈÜ´ÁôÇÂ∞çË©±„ÄÇMediNotes Êï¥Âêà‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)„ÄÅÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) ÂíåËá™ÂãïË™ûÈü≥Ëæ®Ë≠ò (ASR)Ôºå‰ª•Âç≥ÊôÇÊàñÂæûÈåÑË£ΩÁöÑÈü≥Ë®ä‰∏≠Êì∑ÂèñÂíåËôïÁêÜÊñáÂ≠óÂíåË™ûÈü≥Ëº∏ÂÖ•ÔºåÁî¢ÁîüÁµêÊßãÂåñ‰∏îÂú®ËÑàÁµ°‰∏äÊ∫ñÁ¢∫ÁöÑÈÜ´ÁôÇÁ≠ÜË®ò„ÄÇÈÄôÂÄãÊ°ÜÊû∂‰πüÁµêÂêà‰∫ÜÂÖàÈÄ≤ÁöÑÊäÄË°ìÔºå‰æãÂ¶ÇÈáèÂåñ‰ΩéÁß©ÈÅ©Êáâ (QLoRA) ÂíåÂèÉÊï∏ÊúâÊïàÂæÆË™ø (PEFT)Ôºå‰ª•Âú®Ë≥áÊ∫êÂèóÈôêÁöÑÁí∞Â¢É‰∏≠ÈÄ≤Ë°åÊúâÊïàÁéáÁöÑÊ®°ÂûãÂæÆË™ø„ÄÇÊ≠§Â§ñÔºåMediNotes Êèê‰æõ‰∏ÄÂÄãÂü∫ÊñºÊü•Ë©¢ÁöÑÊ™¢Á¥¢Á≥ªÁµ±ÔºåËÆìÈÜ´ÁôÇ‰øùÂÅ•Êèê‰æõËÄÖÂíåÊÇ£ËÄÖÂèØ‰ª•Âø´ÈÄü‰∏îÊ∫ñÁ¢∫Âú∞Â≠òÂèñÁõ∏ÈóúÁöÑÈÜ´ÁôÇË≥áË®ä„ÄÇ‰ΩøÁî® ACI-BENCH Ë≥áÊñôÈõÜÁöÑË©ï‰º∞È°ØÁ§∫ÔºåMediNotes Â§ßÂπÖÊèêÂçá‰∫ÜËá™ÂãïÂåñÈÜ´ÁôÇÊñá‰ª∂ÁÆ°ÁêÜÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÅÊïàÁéáÂíåÂèØÁî®ÊÄßÔºåÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂº∑ÂÅ•ÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰ª•Ê∏õËºïÈÜ´ÁôÇ‰øùÂÅ•Â∞àÊ•≠‰∫∫Âì°ÁöÑË°åÊîøË≤†ÊìîÔºåÂêåÊôÇÊîπÂñÑËá®Â∫äÂ∑•‰ΩúÊµÅÁ®ãÁöÑÂìÅË≥™„ÄÇ

##### **Secure Multiparty Generative AI**
2409.19120v1 by Manil Shrestha, Yashodha Ravichandran, Edward Kim

As usage of generative AI tools skyrockets, the amount of sensitive
information being exposed to these models and centralized model providers is
alarming. For example, confidential source code from Samsung suffered a data
leak as the text prompt to ChatGPT encountered data leakage. An increasing
number of companies are restricting the use of LLMs (Apple, Verizon, JPMorgan
Chase, etc.) due to data leakage or confidentiality issues. Also, an increasing
number of centralized generative model providers are restricting, filtering,
aligning, or censoring what can be used. Midjourney and RunwayML, two of the
major image generation platforms, restrict the prompts to their system via
prompt filtering. Certain political figures are restricted from image
generation, as well as words associated with women's health care, rights, and
abortion.
  In our research, we present a secure and private methodology for generative
artificial intelligence that does not expose sensitive data or models to
third-party AI providers. Our work modifies the key building block of modern
generative AI algorithms, e.g. the transformer, and introduces confidential and
verifiable multiparty computations in a decentralized network to maintain the
1) privacy of the user input and obfuscation to the output of the model, and 2)
introduce privacy to the model itself. Additionally, the sharding process
reduces the computational burden on any one node, enabling the distribution of
resources of large generative AI processes across multiple, smaller nodes. We
show that as long as there exists one honest node in the decentralized
computation, security is maintained. We also show that the inference process
will still succeed if only a majority of the nodes in the computation are
successful. Thus, our method offers both secure and verifiable computation in a
decentralized network.

ÊëòË¶ÅÔºö<paragraph>Èö®ËëóÁîüÊàêÂºè AI Â∑•ÂÖ∑ÁöÑ‰ΩøÁî®ÈáèÊøÄÂ¢ûÔºåÊö¥Èú≤Áµ¶ÈÄô‰∫õÊ®°ÂûãÂíåÈõÜ‰∏≠ÂºèÊ®°ÂûãÊèê‰æõËÄÖÁöÑÊïèÊÑüË≥áË®äÊï∏Èáè‰ª§‰∫∫ÊìîÊÜÇ„ÄÇ‰æãÂ¶ÇÔºå‰æÜËá™‰∏âÊòüÁöÑÊ©üÂØÜÂéüÂßãÁ¢ºÁôºÁîüË≥áÊñôÂ§ñÊ¥©ÔºåÂõ†ÁÇ∫ ChatGPT ÁöÑÊñáÂ≠óÊèêÁ§∫ÈÅáÂà∞‰∫ÜË≥áÊñôÂ§ñÊ¥©„ÄÇÁî±ÊñºË≥áÊñôÂ§ñÊ¥©ÊàñÊ©üÂØÜÊÄßÂïèÈ°åÔºåË∂ä‰æÜË∂äÂ§öÁöÑÂÖ¨Âè∏Ê≠£Âú®ÈôêÂà∂‰ΩøÁî® LLMÔºàApple„ÄÅVerizon„ÄÅJPMorgan Chase Á≠âÔºâ„ÄÇÊ≠§Â§ñÔºåË∂ä‰æÜË∂äÂ§öÁöÑÈõÜ‰∏≠ÂºèÁîüÊàêÊ®°ÂûãÊèê‰æõËÄÖÊ≠£Âú®ÈôêÂà∂„ÄÅÈÅéÊøæ„ÄÅË™øÊï¥ÊàñÂØ©Êü•ÂèØ‰ª•‰ΩøÁî®‰ªÄÈ∫º„ÄÇMidjourney Âíå RunwayML ÊòØÂÖ©ÂÄã‰∏ªË¶ÅÁöÑÂΩ±ÂÉèÁîüÊàêÂπ≥Âè∞ÔºåÂÆÉÂÄëÈÄèÈÅéÊèêÁ§∫ÈÅéÊøæÈôêÂà∂Á≥ªÁµ±ÁöÑÊèêÁ§∫„ÄÇÊüê‰∫õÊîøÊ≤ª‰∫∫Áâ©Ë¢´Á¶ÅÊ≠¢ÁîüÊàêÂΩ±ÂÉèÔºå‰ª•ÂèäËàáÂ©¶Â•≥‰øùÂÅ•„ÄÅÊ¨äÂà©ÂíåÂ¢ÆËÉéÁõ∏ÈóúÁöÑÂ≠óË©û„ÄÇ
Âú®ÊàëÂÄëÁöÑÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂÆâÂÖ®‰∏îÁßÅÂØÜÁöÑÁîüÊàêÂºè‰∫∫Â∑•Êô∫ÊÖßÊñπÊ≥ïÔºå‰∏çÊúÉÂ∞áÊïèÊÑüË≥áÊñôÊàñÊ®°ÂûãÊö¥Èú≤Áµ¶Á¨¨‰∏âÊñπ AI Êèê‰æõËÄÖ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂‰øÆÊîπ‰∫ÜÁèæ‰ª£ÁîüÊàêÂºè AI ÊºîÁÆóÊ≥ïÁöÑ‰∏ªË¶ÅÂª∫ÊßãÂçÄÂ°äÔºå‰æãÂ¶ÇTransformerÔºå‰∏¶Âú®ÂàÜÊï£ÂºèÁ∂≤Ë∑Ø‰∏≠ÂºïÂÖ•‰∫ÜÊ©üÂØÜ‰∏îÂèØÈ©óË≠âÁöÑÂ§öÊñπÈÅãÁÆóÔºå‰ª•Á∂≠Ë≠∑ 1) ‰ΩøÁî®ËÄÖËº∏ÂÖ•ÁöÑÈö±ÁßÅÂíåÊ®°ÂûãËº∏Âá∫ÁöÑÊ∑∑Ê∑ÜÔºå‰ª•Âèä 2) ÁÇ∫Ê®°ÂûãÊú¨Ë∫´ÂºïÂÖ•Èö±ÁßÅ„ÄÇÊ≠§Â§ñÔºåÂàÜÁâáËôïÁêÜÊúÉÈôç‰Ωé‰ªª‰Ωï‰∏ÄÂÄãÁØÄÈªûÁöÑÈÅãÁÆóË≤†ÊìîÔºåËÆìÂ§ßÂûãÁîüÊàêÂºè AI ËôïÁêÜÁöÑË≥áÊ∫êÂèØ‰ª•ÂàÜÂ∏ÉÂú®Â§öÂÄãËºÉÂ∞èÁöÑÁØÄÈªû‰∏ä„ÄÇÊàëÂÄëË°®ÊòéÔºåÂè™Ë¶ÅÂú®ÂàÜÊï£ÂºèÈÅãÁÆó‰∏≠Â≠òÂú®‰∏ÄÂÄãË™†ÂØ¶ÁöÑÁØÄÈªûÔºåÂ∞±ËÉΩÁ∂≠ÊåÅÂÆâÂÖ®ÊÄß„ÄÇÊàëÂÄë‰πüË°®ÊòéÔºåÂ¶ÇÊûúÈÅãÁÆó‰∏≠Âè™ÊúâÂ§öÊï∏ÁØÄÈªûÊàêÂäüÔºåÊé®ÁêÜÁ®ãÂ∫è‰ªçÁÑ∂ÊúÉÊàêÂäü„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÂàÜÊï£ÂºèÁ∂≤Ë∑Ø‰∏≠Êèê‰æõ‰∫ÜÂÆâÂÖ®‰∏îÂèØÈ©óË≠âÁöÑÈÅãÁÆó„ÄÇ</paragraph>

##### **Differential privacy for protecting patient data in speech disorder detection using deep learning**
2409.19078v1 by Soroosh Tayebi Arasteh, Mahshad Lotfinia, Paula Andrea Perez-Toro, Tomas Arias-Vergara, Juan Rafael Orozco-Arroyave, Maria Schuster, Andreas Maier, Seung Hee Yang

Speech pathology has impacts on communication abilities and quality of life.
While deep learning-based models have shown potential in diagnosing these
disorders, the use of sensitive data raises critical privacy concerns. Although
differential privacy (DP) has been explored in the medical imaging domain, its
application in pathological speech analysis remains largely unexplored despite
the equally critical privacy concerns. This study is the first to investigate
DP's impact on pathological speech data, focusing on the trade-offs between
privacy, diagnostic accuracy, and fairness. Using a large, real-world dataset
of 200 hours of recordings from 2,839 German-speaking participants, we observed
a maximum accuracy reduction of 3.85% when training with DP with a privacy
budget, denoted by {\epsilon}, of 7.51. To generalize our findings, we
validated our approach on a smaller dataset of Spanish-speaking Parkinson's
disease patients, demonstrating that careful pretraining on large-scale
task-specific datasets can maintain or even improve model accuracy under DP
constraints. We also conducted a comprehensive fairness analysis, revealing
that reasonable privacy levels (2<{\epsilon}<10) do not introduce significant
gender bias, though age-related disparities may require further attention. Our
results suggest that DP can effectively balance privacy and utility in speech
disorder detection, but also highlight the unique challenges in the speech
domain, particularly regarding the privacy-fairness trade-off. This provides a
foundation for future work to refine DP methodologies and address fairness
across diverse patient groups in real-world deployments.

ÊëòË¶ÅÔºö<paragraph>Ë®ÄË™ûÁóÖÁêÜÂ≠∏Â∞çÊ∫ùÈÄöËÉΩÂäõÂíåÁîüÊ¥ªÂìÅË≥™ÊúâÂΩ±Èüø„ÄÇ
ÂÑòÁÆ°Âü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÊ®°ÂûãÂú®Ë®∫Êñ∑ÈÄô‰∫õÁñæÁóÖÊñπÈù¢Â∑≤Â±ïÁèæÊΩõÂäõÔºå‰ΩÜÊïèÊÑüË≥áÊñôÁöÑ‰ΩøÁî®ÂºïÁôº‰∫ÜÂö¥ÈáçÁöÑÈö±ÁßÅÂïèÈ°å„ÄÇÂÑòÁÆ°Â∑ÆÂàÜÈö±ÁßÅ (DP) Â∑≤Âú®ÈÜ´Â≠∏ÂΩ±ÂÉèÈ†òÂüü‰∏≠ÂæóÂà∞Êé¢Ë®éÔºå‰ΩÜÂÖ∂Âú®ÁóÖÁêÜË™ûË®ÄÂàÜÊûê‰∏≠ÁöÑÊáâÁî®‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Ë®éÔºåÂÑòÁÆ°ÂÖ∂Èö±ÁßÅÂïèÈ°åÂêåÊ®£Âö¥Èáç„ÄÇÊú¨Á†îÁ©∂È¶ñÊ¨°Êé¢Ë®é‰∫Ü DP Â∞çÁóÖÁêÜË™ûË®ÄË≥áÊñôÁöÑÂΩ±ÈüøÔºåÈáçÈªûÈóúÊ≥®Èö±ÁßÅ„ÄÅË®∫Êñ∑Ê∫ñÁ¢∫ÊÄßÂíåÂÖ¨Âπ≥ÊÄß‰πãÈñìÁöÑÊ¨äË°°„ÄÇÊàëÂÄë‰ΩøÁî®‰∫Ü‰∏ÄÂÄãÂ§ßÂûãÁöÑÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜÔºåÂÖ∂‰∏≠ÂåÖÂê´‰æÜËá™ 2,839 ÂêçÂæ∑Ë™ûÂèÉËàáËÄÖÁöÑ 200 Â∞èÊôÇÈåÑÈü≥ÔºåÊàëÂÄëËßÄÂØüÂà∞Âú®‰ΩøÁî® DP ÈÄ≤Ë°åË®ìÁ∑¥ÊôÇÔºåÈö±ÁßÅÈ†êÁÆóÔºà‰ª• {\epsilon} Ë°®Á§∫ÔºâÁÇ∫ 7.51 ÊôÇÔºåÊ∫ñÁ¢∫Â∫¶ÊúÄÈ´òÈôç‰Ωé‰∫Ü 3.85%„ÄÇÁÇ∫‰∫ÜÊé®Âª£ÊàëÂÄëÁöÑÁôºÁèæÔºåÊàëÂÄëÂú®‰∏ÄÂÄãË¶èÊ®°ËºÉÂ∞èÁöÑË•øÁè≠ÁâôË™ûÂ∏ïÈáëÊ£ÆÁóÖÊÇ£ËÄÖË≥áÊñôÈõÜ‰∏äÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÂÅöÊ≥ïÔºåË≠âÊòé‰∫ÜÂú®Â§ßË¶èÊ®°ÁâπÂÆö‰ªªÂãôË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°å‰ªîÁ¥∞ÁöÑÈ†êË®ìÁ∑¥ÂèØ‰ª•Âú® DP Á¥ÑÊùü‰∏ãÁ∂≠ÊåÅÁîöËá≥ÊèêÈ´òÊ®°ÂûãÊ∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÈÇÑÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑÂÖ¨Âπ≥ÊÄßÂàÜÊûêÔºåÁµêÊûúÈ°ØÁ§∫ÂêàÁêÜÁöÑÈö±ÁßÅÁ≠âÁ¥öÔºà2<{\epsilon}<10Ôºâ‰∏çÊúÉÂºïÂÖ•È°ØËëóÁöÑÊÄßÂà•ÂÅèË¶ãÔºåÂÑòÁÆ°ËàáÂπ¥ÈΩ°Áõ∏ÈóúÁöÑÂ∑ÆÁï∞ÂèØËÉΩÈúÄË¶ÅÈÄ≤‰∏ÄÊ≠•ÈóúÊ≥®„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåDP ÂèØ‰ª•ÊúâÊïàÂú∞Âú®Ë™ûË®ÄÈöúÁ§ôÊ™¢Ê∏¨‰∏≠Âπ≥Ë°°Èö±ÁßÅÂíåÊïàÁî®Ôºå‰ΩÜ‰πüÁ™ÅÂá∫‰∫ÜË™ûË®ÄÈ†òÂüü‰∏≠Áç®ÁâπÁöÑÊåëÊà∞ÔºåÁâπÂà•ÊòØÈóúÊñºÈö±ÁßÅÂÖ¨Âπ≥ÊÄßÁöÑÊ¨äË°°„ÄÇÈÄôÁÇ∫Êú™‰æÜÁöÑÁ†îÁ©∂Êèê‰æõ‰∫ÜÂü∫Á§éÔºå‰ª•ÂÆåÂñÑ DP ÊñπÊ≥ï‰∏¶Âú®ÂØ¶ÈöõÈÉ®ÁΩ≤‰∏≠Ëß£Ê±∫‰∏çÂêåÊÇ£ËÄÖÁæ§È´î‰∏≠ÁöÑÂÖ¨Âπ≥ÊÄßÂïèÈ°å„ÄÇ</paragraph>

##### **AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow**
2409.18924v2 by Huizi Yu, Jiayan Zhou, Lingyao Li, Shan Chen, Jack Gallifant, Anye Shi, Xiang Li, Wenyue Hua, Mingyu Jin, Guang Chen, Yang Zhou, Zhao Li, Trisha Gupte, Ming-Li Chen, Zahra Azizi, Yongfeng Zhang, Themistocles L. Assimes, Xin Ma, Danielle S. Bitterman, Lin Lu, Lizhou Fan

Simulated patient systems play a crucial role in modern medical education and
research, providing safe, integrative learning environments and enabling
clinical decision-making simulations. Large Language Models (LLM) could advance
simulated patient systems by replicating medical conditions and patient-doctor
interactions with high fidelity and low cost. However, ensuring the
effectiveness and trustworthiness of these systems remains a challenge, as they
require a large, diverse, and precise patient knowledgebase, along with a
robust and stable knowledge diffusion to users. Here, we developed AIPatient,
an advanced simulated patient system with AIPatient Knowledge Graph (AIPatient
KG) as the input and the Reasoning Retrieval-Augmented Generation (Reasoning
RAG) agentic workflow as the generation backbone. AIPatient KG samples data
from Electronic Health Records (EHRs) in the Medical Information Mart for
Intensive Care (MIMIC)-III database, producing a clinically diverse and
relevant cohort of 1,495 patients with high knowledgebase validity (F1 0.89).
Reasoning RAG leverages six LLM powered agents spanning tasks including
retrieval, KG query generation, abstraction, checker, rewrite, and
summarization. This agentic framework reaches an overall accuracy of 94.15% in
EHR-based medical Question Answering (QA), outperforming benchmarks that use
either no agent or only partial agent integration. Our system also presents
high readability (median Flesch Reading Ease 77.23; median Flesch Kincaid Grade
5.6), robustness (ANOVA F-value 0.6126, p>0.1), and stability (ANOVA F-value
0.782, p>0.1). The promising performance of the AIPatient system highlights its
potential to support a wide range of applications, including medical education,
model evaluation, and system integration.

ÊëòË¶ÅÔºöÊ®°Êì¨ÁóÖ‰∫∫Á≥ªÁµ±Âú®Áèæ‰ª£ÈÜ´Â≠∏ÊïôËÇ≤ÂíåÁ†îÁ©∂‰∏≠ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤ÔºåÊèê‰æõÂÆâÂÖ®„ÄÅÊï¥ÂêàÁöÑÂ≠∏ÁøíÁí∞Â¢ÉÔºå‰∏¶ËÉΩÈÄ≤Ë°åËá®Â∫äÊ±∫Á≠ñÊ®°Êì¨„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËÉΩÈÄèÈÅéÈ´ò‰øùÁúüÂ∫¶Âíå‰ΩéÊàêÊú¨Ë§áË£ΩÈÜ´ÁôÇÁãÄÊ≥ÅÂíåÈÜ´ÁóÖ‰∫íÂãïÔºåÈÄ≤ËÄåÊèêÂçáÊ®°Êì¨ÁóÖ‰∫∫Á≥ªÁµ±„ÄÇÁÑ∂ËÄåÔºåÁ¢∫‰øùÈÄô‰∫õÁ≥ªÁµ±ÁöÑÊúâÊïàÊÄßÂíåÂèØ‰ø°Â∫¶‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÊåëÊà∞ÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÈúÄË¶Å‰∏ÄÂÄãÈæêÂ§ß„ÄÅÂ§öÂÖÉ‰∏îÁ≤æÁ¢∫ÁöÑÁóÖ‰∫∫Áü•Ë≠òÂ∫´Ôºå‰ª•ÂèäÁ©©ÂÅ•‰∏îÁ©©ÂÆöÁöÑÁü•Ë≠òÂÇ≥Êí≠Áµ¶‰ΩøÁî®ËÄÖ„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÈñãÁôº‰∫Ü AIPatientÔºå‰∏ÄÂÄãÈÄ≤ÈöéÁöÑÊ®°Êì¨ÁóÖ‰∫∫Á≥ªÁµ±Ôºå‰ª• AIPatient Áü•Ë≠òÂúñË≠ú (AIPatient KG) ‰ΩúÁÇ∫Ëº∏ÂÖ•Ôºå‰∏¶‰ª•Êé®ÁêÜÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (Reasoning RAG) ‰ª£ÁêÜÂ∑•‰ΩúÊµÅÁ®ã‰ΩúÁÇ∫ÁîüÊàê‰∏ªÂππ„ÄÇAIPatient KG ÂæûÈáçÁóáÁõ£Ë≠∑ÈÜ´Â≠∏Ë≥áË®ä‰∏≠ÂøÉ (MIMIC)-III Ë≥áÊñôÂ∫´‰∏≠ÁöÑÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) ‰∏≠ÊäΩÂèñË≥áÊñôÔºåÁî¢Áîü‰∏ÄÂÄãËá®Â∫äÂ§öÊ®£‰∏îÁõ∏ÈóúÁöÑ 1,495 ÂêçÁóÖÊÇ£Áæ§ÁµÑÔºåÂÖ∑ÊúâÂæàÈ´òÁöÑÁü•Ë≠òÂ∫´ÊïàÂ∫¶ (F1 0.89)„ÄÇÊé®ÁêÜ RAG ÊßìÊ°ø‰∫ÜÂÖ≠ÂÄã LLM È©ÖÂãïÁöÑ‰ª£ÁêÜÔºåË∑®Ë∂äÊ™¢Á¥¢„ÄÅKG Êü•Ë©¢Áî¢Áîü„ÄÅÊäΩË±°„ÄÅÊ™¢Êü•Âô®„ÄÅÈáçÂØ´ÂíåÊëòË¶ÅÁ≠â‰ªªÂãô„ÄÇÈÄôÂÄã‰ª£ÁêÜÊ°ÜÊû∂Âú®Âü∫Êñº EHR ÁöÑÈÜ´ÁôÇÂïèÁ≠î (QA) ‰∏≠ÈÅîÂà∞‰∫Ü 94.15% ÁöÑÊï¥È´îÊ∫ñÁ¢∫Â∫¶ÔºåÂÑ™Êñº‰∏ç‰ΩøÁî®‰ª£ÁêÜÊàñÂÉÖÈÉ®ÂàÜ‰ª£ÁêÜÊï¥ÂêàÁöÑÂü∫Ê∫ñ„ÄÇÊàëÂÄëÁöÑÁ≥ªÁµ±ÈÇÑÂÖ∑ÊúâÂæàÈ´òÁöÑÂèØËÆÄÊÄß (Flesch Èñ±ËÆÄÁ∞°‰æøÊÄß‰∏≠‰ΩçÊï∏ 77.23ÔºõFlesch Kincaid Á≠âÁ¥ö‰∏≠‰ΩçÊï∏ 5.6)„ÄÅÁ©©ÂÅ•ÊÄß (ANOVA F ÂÄº 0.6126Ôºåp>0.1) ÂíåÁ©©ÂÆöÊÄß (ANOVA F ÂÄº 0.782Ôºåp>0.1)„ÄÇAIPatient Á≥ªÁµ±ÁöÑÂá∫Ëâ≤Ë°®ÁèæÁ™ÅÈ°Ø‰∫ÜÂÆÉÂú®ÊîØÊè¥ÂêÑÁ®ÆÊáâÁî®Á®ãÂºèÁöÑÊΩõÂäõÔºåÂåÖÊã¨ÈÜ´Â≠∏ÊïôËÇ≤„ÄÅÊ®°ÂûãË©ï‰º∞ÂíåÁ≥ªÁµ±Êï¥Âêà„ÄÇ

##### **Suicide Phenotyping from Clinical Notes in Safety-Net Psychiatric Hospital Using Multi-Label Classification with Pre-Trained Language Models**
2409.18878v2 by Zehan Li, Yan Hu, Scott Lane, Salih Selek, Lokesh Shahani, Rodrigo Machado-Vieira, Jair Soares, Hua Xu, Hongfang Liu, Ming Huang

Accurate identification and categorization of suicidal events can yield
better suicide precautions, reducing operational burden, and improving care
quality in high-acuity psychiatric settings. Pre-trained language models offer
promise for identifying suicidality from unstructured clinical narratives. We
evaluated the performance of four BERT-based models using two fine-tuning
strategies (multiple single-label and single multi-label) for detecting
coexisting suicidal events from 500 annotated psychiatric evaluation notes. The
notes were labeled for suicidal ideation (SI), suicide attempts (SA), exposure
to suicide (ES), and non-suicidal self-injury (NSSI). RoBERTa outperformed
other models using multiple single-label classification strategy (acc=0.86,
F1=0.78). MentalBERT (acc=0.83, F1=0.74) also exceeded BioClinicalBERT
(acc=0.82, F1=0.72) which outperformed BERT (acc=0.80, F1=0.70). RoBERTa
fine-tuned with single multi-label classification further improved the model
performance (acc=0.88, F1=0.81). The findings highlight that the model
optimization, pretraining with domain-relevant data, and the single multi-label
classification strategy enhance the model performance of suicide phenotyping.
Keywords: EHR-based Phenotyping; Natural Language Processing; Secondary Use of
EHR Data; Suicide Classification; BERT-based Model; Psychiatry; Mental Health

ÊëòË¶ÅÔºö<paragraph>Ê∫ñÁ¢∫Ëæ®Ë≠òÂíåÂàÜÈ°ûËá™ÊÆ∫‰∫ã‰ª∂ÔºåÂèØ‰ª•Áî¢ÁîüÊõ¥Â•ΩÁöÑËá™ÊÆ∫È†êÈò≤Êé™ÊñΩÔºåÈôç‰ΩéÈÅã‰ΩúË≤†ÊìîÔºå‰∏¶ÊèêÂçáÈ´òÊïèÁ≤æÁ•ûÁßëÁí∞Â¢É‰∏≠ÁöÑÁÖßË≠∑ÂìÅË≥™„ÄÇÈ†êÂÖàË®ìÁ∑¥ÁöÑË™ûË®ÄÊ®°ÂûãÊúâÊúõÂæûÈùûÁµêÊßãÂåñÁöÑËá®Â∫äÊïòËø∞‰∏≠Ëæ®Ë≠òÂá∫Ëá™ÊÆ∫ÂÇæÂêë„ÄÇÊàëÂÄëË©ï‰º∞‰∫ÜÂõõÂÄã BERT Ê®°ÂûãÁöÑÊïàËÉΩÔºå‰ΩøÁî®ÂÖ©Á®ÆÂæÆË™øÁ≠ñÁï•ÔºàÂ§öÈáçÂñÆÊ®ôÁ±§ÂíåÂñÆ‰∏ÄÂ§öÊ®ôÁ±§Ôºâ‰æÜÂÅµÊ∏¨ 500 ÂÄãË®ªËß£ÁöÑÁ≤æÁ•ûÁßëË©ï‰º∞Ë®òÈåÑ‰∏≠‰∏¶Â≠òÁöÑËá™ÊÆ∫‰∫ã‰ª∂„ÄÇÈÄô‰∫õË®òÈåÑÊ®ôË®òÁÇ∫Ëá™ÊÆ∫ÊÑèÂøµÔºàSIÔºâ„ÄÅËá™ÊÆ∫‰ºÅÂúñÔºàSAÔºâ„ÄÅÊé•Ëß∏Ëá™ÊÆ∫ÔºàESÔºâÂíåÈùûËá™ÊÆ∫Ëá™ÂÇ∑ÔºàNSSIÔºâ„ÄÇRoBERTa ‰ΩøÁî®Â§öÈáçÂñÆÊ®ôÁ±§ÂàÜÈ°ûÁ≠ñÁï•Ë°®ÁèæÂÑ™ÊñºÂÖ∂‰ªñÊ®°ÂûãÔºàacc=0.86ÔºåF1=0.78Ôºâ„ÄÇMentalBERTÔºàacc=0.83ÔºåF1=0.74Ôºâ‰πüË∂ÖÈÅé BioClinicalBERTÔºàacc=0.82ÔºåF1=0.72ÔºâÔºåËÄå BioClinicalBERT ÂâáÂÑ™Êñº BERTÔºàacc=0.80ÔºåF1=0.70Ôºâ„ÄÇ‰ΩøÁî®ÂñÆ‰∏ÄÂ§öÊ®ôÁ±§ÂàÜÈ°ûÂæÆË™øÁöÑ RoBERTa ÈÄ≤‰∏ÄÊ≠•ÊèêÂçá‰∫ÜÊ®°ÂûãÊïàËÉΩÔºàacc=0.88ÔºåF1=0.81Ôºâ„ÄÇÁ†îÁ©∂ÁµêÊûúÂº∑Ë™øÔºåÊ®°ÂûãÊúÄ‰Ω≥Âåñ„ÄÅ‰ΩøÁî®ËàáÈ†òÂüüÁõ∏ÈóúË≥áÊñôÈÄ≤Ë°åÈ†êË®ìÁ∑¥Ôºå‰ª•ÂèäÂñÆ‰∏ÄÂ§öÊ®ôÁ±§ÂàÜÈ°ûÁ≠ñÁï•ÔºåÂèØ‰ª•ÊèêÂçáËá™ÊÆ∫Ë°®ÂûãÂàÜÊûêÁöÑÊ®°ÂûãÊïàËÉΩ„ÄÇÈóúÈçµÂ≠óÔºöÂü∫ÊñºÈõªÂ≠êÁóÖÊ≠∑ÁöÑË°®ÂûãÂàÜÊûêÔºõËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÔºõÈõªÂ≠êÁóÖÊ≠∑Ë≥áÊñôÁöÑ‰∫åÊ¨°‰ΩøÁî®ÔºõËá™ÊÆ∫ÂàÜÈ°ûÔºõÂü∫Êñº BERT ÁöÑÊ®°ÂûãÔºõÁ≤æÁ•ûÁßëÔºõÂøÉÁêÜÂÅ•Â∫∑</paragraph>

##### **Early diagnosis of Alzheimer's disease from MRI images with deep learning model**
2409.18814v1 by Sajjad Aghasi Javid, Mahmood Mohassel Feghhi

It is acknowledged that the most common cause of dementia worldwide is
Alzheimer's disease (AD). This condition progresses in severity from mild to
severe and interferes with people's everyday routines. Early diagnosis plays a
critical role in patient care and clinical trials. Convolutional neural
networks (CNN) are used to create a framework for identifying specific disease
features from MRI scans Classification of dementia involves approaches such as
medical history review, neuropsychological tests, and magnetic resonance
imaging (MRI). However, the image dataset obtained from Kaggle faces a
significant issue of class imbalance, which requires equal distribution of
samples from each class to address. In this article, to address this imbalance,
the Synthetic Minority Oversampling Technique (SMOTE) is utilized. Furthermore,
a pre-trained convolutional neural network has been applied to the DEMNET
dementia network to extract key features from AD images. The proposed model
achieved an impressive accuracy of 98.67%.

ÊëòË¶ÅÔºöÂÖ®ÁêÉÂÖ¨Ë™çÊúÄÂ∏∏Ë¶ãÁöÑÂ§±Êô∫ÁóáÊàêÂõ†ÊòØ
ÈòøËå≤Êµ∑ÈªòÁóáÔºàADÔºâ„ÄÇÈÄôÁ®ÆÁñæÁóÖÁöÑÂö¥ÈáçÁ®ãÂ∫¶ÂæûËºïÂ∫¶Âà∞ÈáçÂ∫¶Ôºå‰∏¶ÊúÉÂπ≤Êìæ‰∫∫ÂÄëÁöÑÊó•Â∏∏‰ΩúÊÅØ„ÄÇÊó©ÊúüË®∫Êñ∑Âú®ÊÇ£ËÄÖÁÖßË≠∑ÂíåËá®Â∫äË©¶È©ó‰∏≠ÊâÆÊºîËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤„ÄÇÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºàCNNÔºâÁî®ÊñºÂª∫Á´ã‰∏ÄÂÄãÊû∂ÊßãÔºå‰ª•Âæû MRI ÊéÉÊèè‰∏≠Ëæ®Ë≠òÁâπÂÆöÁöÑÁñæÁóÖÁâπÂæµ„ÄÇÂ§±Êô∫ÁóáÁöÑÂàÜÈ°ûÊ∂âÂèäÁóÖÊ≠∑ÂõûÈ°ß„ÄÅÁ•ûÁ∂ìÂøÉÁêÜÊ∏¨È©óÂíåÁ£ÅÊåØÈÄ†ÂΩ±ÔºàMRIÔºâÁ≠âÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÂæû Kaggle ÂèñÂæóÁöÑÂΩ±ÂÉèË≥áÊñôÈõÜÈù¢Ëá®È°ûÂà•‰∏çÂπ≥Ë°°ÁöÑÈáçÂ§ßÂïèÈ°åÔºåÈÄôÈúÄË¶ÅÊØèÂÄãÈ°ûÂà•ÁöÑÊ®£Êú¨Êï∏ÈáèÁõ∏Á≠âÊâçËÉΩËß£Ê±∫„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÁ®Æ‰∏çÂπ≥Ë°°Ôºå‰ΩøÁî®‰∫ÜÂêàÊàêÂ∞ëÊï∏ÈÅéÊé°Ê®£ÊäÄË°ìÔºàSMOTEÔºâ„ÄÇÊ≠§Â§ñÔºåÂ∑≤Â∞áÈ†êÂÖàË®ìÁ∑¥Â•ΩÁöÑÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÊáâÁî®Êñº DEMNET Â§±Êô∫ÁóáÁ∂≤Ë∑ØÔºå‰ª•Âæû AD ÂΩ±ÂÉè‰∏≠ËêÉÂèñÈóúÈçµÁâπÂæµ„ÄÇÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÈÅîÂà∞‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑ 98.67% Ê∫ñÁ¢∫Áéá„ÄÇ

##### **State-of-the-Art Periorbital Distance Prediction and Disease Classification Using Periorbital Features**
2409.18769v2 by George R. Nahass, Ghasem Yazdanpanah, Madison Cheung, Alex Palacios, Jeffery Peterson, Kevin Heinze, Sasha Hubschman, Chad A. Purnell, Pete Setabutr, Ann Q. Tran, Darvin Yi

Periorbital distances and features around the eyes and lids hold valuable
information for disease quantification and monitoring of surgical and medical
intervention. These distances are commonly measured manually, a process that is
both subjective and highly time-consuming. Here, we set out to developed three
deep-learning methods for segmentation and periorbital distance prediction, and
also evaluate the utility of periorbital distances for disease classification.
The MAE of our deep learning predicted distances was less than or very close to
the error observed between trained human annotators. We compared our models to
the current state-of-the-art (SOTA) method for periorbital distance prediction
and found that our methods outperformed SOTA on all of our datasets on all but
one periorbital measurement. We also show that robust segmentation can be
achieved on diseased eyes using models trained on open-source, healthy eyes,
and that periorbital distances have can be used as high-quality features in
downstream classification models. Leveraging segmentation networks as
intermediary steps in classification has broad implications for increasing the
generalizability of classification models in ophthalmic plastic and
craniofacial surgery by avoiding the out-of-distribution problem observed in
traditional convolutional neural networks.

ÊëòË¶ÅÔºöÁúºÁú∂Âë®ÂúçÁöÑË∑ùÈõ¢ÂíåÁâπÂæµ‰ª•ÂèäÁúºÁûºÂ∞çÊñºÁñæÁóÖÈáèÂåñÂíåÂ§ñÁßëÂíåÈÜ´ÁôÇÂπ≤È†êÁöÑÁõ£ÊéßÂÖ∑ÊúâÂØ∂Ë≤¥ÁöÑ‰ø°ÊÅØ„ÄÇÈÄô‰∫õË∑ùÈõ¢ÈÄöÂ∏∏ÊòØÊâãÂãïÊ∏¨ÈáèÁöÑÔºåÈÄôÊòØ‰∏ÄÂÄãÊó¢‰∏ªËßÄÂèàÈùûÂ∏∏ËÄóÊôÇÁöÑÈÅéÁ®ã„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëËëóÊâãÈñãÁôº‰∫Ü‰∏âÁ®ÆÁî®ÊñºÂàÜÂâ≤ÂíåÁúºÁú∂Âë®ÂúçË∑ùÈõ¢È†êÊ∏¨ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÔºå‰∏¶Ë©ï‰º∞‰∫ÜÁúºÁú∂Âë®ÂúçË∑ùÈõ¢Â∞çÁñæÁóÖÂàÜÈ°ûÁöÑÊïàÁî®„ÄÇÊàëÂÄëÁöÑÊ∑±Â∫¶Â≠∏ÁøíÈ†êÊ∏¨Ë∑ùÈõ¢ÁöÑ MAE Â∞èÊñºÊàñÈùûÂ∏∏Êé•ËøëË®ìÁ∑¥ÊúâÁ¥†ÁöÑ‰∫∫È°ûË®ªÈáãËÄÖ‰πãÈñìËßÄÂØüÂà∞ÁöÑË™§Â∑Æ„ÄÇÊàëÂÄëÂ∞áÊàëÂÄëÁöÑÊ®°ÂûãËàáÁúºÁú∂Âë®ÂúçË∑ùÈõ¢È†êÊ∏¨ÁöÑÁï∂ÂâçÊúÄÂÖàÈÄ≤ (SOTA) ÊñπÊ≥ïÈÄ≤Ë°å‰∫ÜÊØîËºÉÔºåÁôºÁèæÊàëÂÄëÁöÑÊ®°ÂûãÂú®ÊàëÂÄëÁöÑÊâÄÊúâÊï∏ÊìöÈõÜ‰∏äÈÉΩÂÑ™Êñº SOTAÔºåÂè™Êúâ‰∏ÄÂÄãÁúºÁú∂Âë®ÂúçÊ∏¨ÈáèÈô§Â§ñ„ÄÇÊàëÂÄëÈÇÑË°®ÊòéÔºå‰ΩøÁî®Âú®ÈñãÊîæÊ∫ê‰ª£Á¢º„ÄÅÂÅ•Â∫∑ÁöÑÁúºÁùõ‰∏äË®ìÁ∑¥ÁöÑÊ®°ÂûãÂèØ‰ª•Âú®ÊÇ£ÁóÖÁöÑÁúºÁùõ‰∏äÂØ¶ÁèæÁ©©ÂÅ•ÁöÑÂàÜÂâ≤Ôºå‰∏¶‰∏îÁúºÁú∂Âë®ÂúçË∑ùÈõ¢ÂèØÁî®‰Ωú‰∏ãÊ∏∏ÂàÜÈ°ûÊ®°Âûã‰∏≠ÁöÑÈ´òË≥™ÈáèÁâπÂæµ„ÄÇÂà©Áî®ÂàÜÂâ≤Á∂≤Áµ°‰ΩúÁÇ∫ÂàÜÈ°û‰∏≠ÁöÑ‰∏≠ÈñìÊ≠•È©üÂ∞çÊèêÈ´òÁúºÁßëÊï¥ÂΩ¢ÂíåÈ°±Èù¢Â§ñÁßë‰∏≠ÂàÜÈ°ûÊ®°ÂûãÁöÑÊ¶ÇÊã¨ÊÄßÂÖ∑ÊúâÂª£Ê≥õÁöÑÂΩ±ÈüøÔºåÂõ†ÁÇ∫ÂÆÉÈÅøÂÖç‰∫ÜÂú®ÂÇ≥Áµ±Âç∑Á©çÁ•ûÁ∂ìÁ∂≤Áµ°‰∏≠ËßÄÂØüÂà∞ÁöÑÂàÜÂ∏ÉÂ§ñÂïèÈ°å„ÄÇ

##### **Multi-modal Medical Image Fusion For Non-Small Cell Lung Cancer Classification**
2409.18715v1 by Salma Hassan, Hamad Al Hammadi, Ibrahim Mohammed, Muhammad Haris Khan

The early detection and nuanced subtype classification of non-small cell lung
cancer (NSCLC), a predominant cause of cancer mortality worldwide, is a
critical and complex issue. In this paper, we introduce an innovative
integration of multi-modal data, synthesizing fused medical imaging (CT and PET
scans) with clinical health records and genomic data. This unique fusion
methodology leverages advanced machine learning models, notably MedClip and
BEiT, for sophisticated image feature extraction, setting a new standard in
computational oncology. Our research surpasses existing approaches, as
evidenced by a substantial enhancement in NSCLC detection and classification
precision. The results showcase notable improvements across key performance
metrics, including accuracy, precision, recall, and F1-score. Specifically, our
leading multi-modal classifier model records an impressive accuracy of 94.04%.
We believe that our approach has the potential to transform NSCLC diagnostics,
facilitating earlier detection and more effective treatment planning and,
ultimately, leading to superior patient outcomes in lung cancer care.

ÊëòË¶ÅÔºöÊó©ÊúüÊ™¢Ê∏¨ÂíåÁ¥∞Á∑ªÁöÑÈùûÂ∞èÁ¥∞ËÉûËÇ∫Áôå (NSCLC) ‰∫ûÂûãÂàÜÈ°ûÔºåÊòØÂÖ®ÁêÉÁôåÁóáÊ≠ª‰∫°ÁéáÁöÑ‰∏ªË¶ÅÂéüÂõ†ÔºåÊòØ‰∏ÄÂÄãÈóúÈçµ‰∏îË§áÈõúÁöÑÂïèÈ°å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÂâµÊñ∞ÁöÑÂ§öÊ®°ÂºèÊï∏ÊìöÊï¥ÂêàÔºåÂ∞áËûçÂêàÁöÑÈÜ´Â≠∏ÂΩ±ÂÉè (CT Âíå PET ÊéÉÊèè) ËàáËá®Â∫äÂÅ•Â∫∑Ë®òÈåÑÂíåÂü∫Âõ†ÁµÑÊï∏ÊìöÂêàÊàê„ÄÇÈÄôÁ®ÆÁç®ÁâπÁöÑËûçÂêàÊñπÊ≥ïÂà©Áî®‰∫ÜÂÖàÈÄ≤ÁöÑÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÔºåÁâπÂà•ÊòØ MedClip Âíå BEiTÔºåÈÄ≤Ë°åË§áÈõúÁöÑÂΩ±ÂÉèÁâπÂæµÊèêÂèñÔºåÁÇ∫Ë®àÁÆóËÖ´Áò§Â≠∏Ë®≠ÂÆö‰∫ÜÊñ∞ÁöÑÊ®ôÊ∫ñ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Ë∂ÖË∂ä‰∫ÜÁèæÊúâÊñπÊ≥ïÔºåÈÄôÂæû NSCLC Ê™¢Ê∏¨ÂíåÂàÜÈ°ûÁ≤æÂ∫¶ÁöÑÈ°ØËëóÊèêÈ´ò‰∏≠ÂæóÂà∞Ë≠âÊòé„ÄÇÁµêÊûúÂ±ïÁ§∫‰∫ÜÂú®ÈóúÈçµÊïàËÉΩÊåáÊ®ôÔºàÂåÖÊã¨Ê∫ñÁ¢∫Â∫¶„ÄÅÁ≤æÁ¢∫Â∫¶„ÄÅÂè¨ÂõûÁéáÂíå F1 ÂàÜÊï∏Ôºâ‰∏äÁöÑÈ°ØËëóÊîπÈÄ≤„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈ†òÂÖàÁöÑÂ§öÊ®°ÂºèÂàÜÈ°ûÂô®Ê®°ÂûãË®òÈåÑ‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑ 94.04% Ê∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÁõ∏‰ø°ÊàëÂÄëÁöÑÂÅöÊ≥ïÊúâÊΩõÂäõËΩâËÆä NSCLC Ë®∫Êñ∑Ôºå‰øÉÈÄ≤Êó©ÊúüÊ™¢Ê∏¨ÂíåÊõ¥ÊúâÊïàÁöÑÊ≤ªÁôÇË®àÁï´Ôºå‰∏¶ÊúÄÁµÇÊîπÂñÑËÇ∫ÁôåÁÖßË≠∑‰∏≠ÁöÑÊÇ£ËÄÖÈ†êÂæå„ÄÇ

##### **Towards Integrating Epistemic Uncertainty Estimation into the Radiotherapy Workflow**
2409.18628v1 by Marvin Tom Teichmann, Manasi Datar, Lisa Kratzke, Fernando Vega, Florin C. Ghesu

The precision of contouring target structures and organs-at-risk (OAR) in
radiotherapy planning is crucial for ensuring treatment efficacy and patient
safety. Recent advancements in deep learning (DL) have significantly improved
OAR contouring performance, yet the reliability of these models, especially in
the presence of out-of-distribution (OOD) scenarios, remains a concern in
clinical settings. This application study explores the integration of epistemic
uncertainty estimation within the OAR contouring workflow to enable OOD
detection in clinically relevant scenarios, using specifically compiled data.
Furthermore, we introduce an advanced statistical method for OOD detection to
enhance the methodological framework of uncertainty estimation. Our empirical
evaluation demonstrates that epistemic uncertainty estimation is effective in
identifying instances where model predictions are unreliable and may require an
expert review. Notably, our approach achieves an AUC-ROC of 0.95 for OOD
detection, with a specificity of 0.95 and a sensitivity of 0.92 for implant
cases, underscoring its efficacy. This study addresses significant gaps in the
current research landscape, such as the lack of ground truth for uncertainty
estimation and limited empirical evaluations. Additionally, it provides a
clinically relevant application of epistemic uncertainty estimation in an
FDA-approved and widely used clinical solution for OAR segmentation from
Varian, a Siemens Healthineers company, highlighting its practical benefits.

ÊëòË¶ÅÔºö<paragraph>Âú®ÊîæÂ∞ÑÊ≤ªÁôÇË¶èÂäÉ‰∏≠ÔºåËº™ÂªìÂåñÊ®ôÈù∂ÁµêÊßãÂíåÂô®ÂÆòÈ¢®Èö™ÔºàOARÔºâÁöÑÁ≤æÁ¢∫Â∫¶Â∞çÊñºÁ¢∫‰øùÊ≤ªÁôÇÊïàÊûúÂíåÊÇ£ËÄÖÂÆâÂÖ®Ëá≥ÈóúÈáçË¶Å„ÄÇÊ∑±Â∫¶Â≠∏ÁøíÔºàDLÔºâÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÈ°ØËëóÊîπÂñÑ‰∫Ü OAR Ëº™ÂªìÂåñÊïàËÉΩÔºå‰ΩÜÈÄô‰∫õÊ®°ÂûãÁöÑÂèØÈù†ÊÄßÔºåÁâπÂà•ÊòØÂú®Âá∫ÁèæÂàÜÂ∏ÉÂ§ñÔºàOODÔºâÂ†¥ÊôØÊôÇÔºåÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠‰ªçÁÑ∂‰ª§‰∫∫ÊìîÊÜÇ„ÄÇÊú¨ÊáâÁî®Á†îÁ©∂Êé¢Ë®é‰∫ÜÂ∞áË™çË≠ò‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÊï¥ÂêàÂà∞ OAR Ëº™ÂªìÂåñÂ∑•‰ΩúÊµÅÁ®ã‰∏≠Ôºå‰ª•‰ΩøÁî®ÁâπÂà•Á∑®Ë≠ØÁöÑË≥áÊñôÂú®Ëá®Â∫ä‰∏äÁõ∏ÈóúÁöÑÂ†¥ÊôØ‰∏≠ÂïüÁî® OOD ÂÅµÊ∏¨„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÂÖàÈÄ≤ÁöÑÁµ±Ë®àÊñπÊ≥ïÈÄ≤Ë°å OOD ÂÅµÊ∏¨Ôºå‰ª•Â¢ûÂº∑‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÁöÑÊñπÊ≥ïË´ñÊû∂Êßã„ÄÇÊàëÂÄëÁöÑÂØ¶Ë≠âË©ï‰º∞Ë≠âÊòéÔºåË™çË≠ò‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÂú®Ë≠òÂà•Ê®°ÂûãÈ†êÊ∏¨‰∏çÂèØÈù†‰∏îÂèØËÉΩÈúÄË¶ÅÂ∞àÂÆ∂ÂØ©Êü•ÁöÑÊÉÖÊ≥ÅÊñπÈù¢ÊòØÊúâÊïàÁöÑ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂ∞çÊñºÊ§çÂÖ•Áâ©Ê°à‰æãÈÅîÂà∞‰∫Ü 0.95 ÁöÑ OOD ÂÅµÊ∏¨ AUC-ROCÔºåÁâπÁï∞ÊÄßÁÇ∫ 0.95ÔºåÈùàÊïèÂ∫¶ÁÇ∫ 0.92ÔºåÁ™ÅÈ°Ø‰∫ÜÂÖ∂ÂäüÊïà„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Ëß£Ê±∫‰∫ÜÁï∂ÂâçÁ†îÁ©∂È†òÂüü‰∏≠ÁöÑÈáçÂ§ßÂ∑ÆË∑ùÔºå‰æãÂ¶ÇÁº∫‰πè‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÁöÑÂü∫Êú¨ÂéüÁêÜÂíåÊúâÈôêÁöÑÂØ¶Ë≠âË©ï‰º∞„ÄÇÊ≠§Â§ñÔºåÂÆÉÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂú® FDA ÊâπÂáÜ‰∏îÂª£Ê≥õ‰ΩøÁî®ÁöÑËá®Â∫äËß£Ê±∫ÊñπÊ°à‰∏≠Ë™çË≠ò‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÂú® OAR ÂàÜÂâ≤ÊñπÈù¢ÁöÑËá®Â∫äÁõ∏ÈóúÊáâÁî®ÔºåË©≤Ëß£Ê±∫ÊñπÊ°à‰æÜËá™Ë•øÈñÄÂ≠êÈÜ´ÁôÇÂÖ¨Âè∏Êóó‰∏ãÁöÑ VarianÔºåÁ™ÅÈ°Ø‰∫ÜÂÖ∂ÂØ¶ÈöõÊïàÁõä„ÄÇ</paragraph>

##### **Leveraging Long-Context Large Language Models for Multi-Document Understanding and Summarization in Enterprise Applications**
2409.18454v1 by Aditi Godbole, Jabin Geevarghese George, Smita Shandilya

The rapid increase in unstructured data across various fields has made
multi-document comprehension and summarization a critical task. Traditional
approaches often fail to capture relevant context, maintain logical
consistency, and extract essential information from lengthy documents. This
paper explores the use of Long-context Large Language Models (LLMs) for
multi-document summarization, demonstrating their exceptional capacity to grasp
extensive connections, provide cohesive summaries, and adapt to various
industry domains and integration with enterprise applications/systems. The
paper discusses the workflow of multi-document summarization for effectively
deploying long-context LLMs, supported by case studies in legal applications,
enterprise functions such as HR, finance, and sourcing, as well as in the
medical and news domains. These case studies show notable enhancements in both
efficiency and accuracy. Technical obstacles, such as dataset diversity, model
scalability, and ethical considerations like bias mitigation and factual
accuracy, are carefully analyzed. Prospective research avenues are suggested to
augment the functionalities and applications of long-context LLMs, establishing
them as pivotal tools for transforming information processing across diverse
sectors and enterprise applications.

ÊëòË¶ÅÔºöÈö®ËëóÈùûÁµêÊßãÂåñË≥áÊñôÂú®ÂêÑÂÄãÈ†òÂüüÂø´ÈÄüÂ¢ûÂä†ÔºåÂ§öÊñá‰ª∂ÁêÜËß£ÂíåÊëòË¶ÅÂ∑≤ÊàêÁÇ∫‰∏ÄÈ†ÖÈáçË¶ÅÁöÑ‰ªªÂãô„ÄÇÂÇ≥Áµ±ÊñπÊ≥ïÈÄöÂ∏∏ÁÑ°Ê≥ïÊì∑ÂèñÁõ∏ÈóúËÑàÁµ°„ÄÅÁ∂≠ÊåÅÈÇèËºØ‰∏ÄËá¥ÊÄßÔºå‰ª•ÂèäÂæûÂÜóÈï∑ÁöÑÊñá‰ª∂‰∏≠ËêÉÂèñÂøÖË¶ÅË≥áË®ä„ÄÇÊú¨ÊñáÊé¢Ë®é‰ΩøÁî®Èï∑ËÑàÁµ°Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÈÄ≤Ë°åÂ§öÊñá‰ª∂ÊëòË¶ÅÔºåÂ±ïÁ§∫ÂÖ∂ÊéåÊè°Âª£Ê≥õÈóúËÅØ„ÄÅÊèê‰æõÊúâÂáùËÅöÂäõÁöÑÊëòË¶ÅÔºå‰ª•ÂèäÈÅ©ÊáâÂêÑÁ®ÆÁî¢Ê•≠È†òÂüüÂíåÊï¥Âêà‰ºÅÊ•≠ÊáâÁî®Á®ãÂºè/Á≥ªÁµ±ÁöÑÈùûÂá°ËÉΩÂäõ„ÄÇÊú¨ÊñáÊé¢Ë®éÂ§öÊñá‰ª∂ÊëòË¶ÅÁöÑÂ∑•‰ΩúÊµÅÁ®ãÔºå‰ª•ÊúâÊïàÈÉ®ÁΩ≤Èï∑ËÑàÁµ° LLMÔºå‰∏¶‰ª•Ê≥ïÂæãÊáâÁî®„ÄÅ‰ºÅÊ•≠ÂäüËÉΩÔºà‰æãÂ¶Ç‰∫∫ÂäõË≥áÊ∫ê„ÄÅË≤°ÂãôÂíåÊé°Ë≥ºÔºâÔºå‰ª•ÂèäÈÜ´ÁôÇÂíåÊñ∞ËÅûÈ†òÂüüÁöÑÊ°à‰æãÁ†îÁ©∂‰ΩúÁÇ∫‰ΩêË≠â„ÄÇÈÄô‰∫õÊ°à‰æãÁ†îÁ©∂È°ØÁ§∫Âá∫ÊïàÁéáÂíåÊ∫ñÁ¢∫ÊÄßÈÉΩÊúâÈ°ØËëóÁöÑÊèêÂçá„ÄÇÊäÄË°ìÈöúÁ§ôÔºå‰æãÂ¶ÇË≥áÊñôÈõÜÂ§öÊ®£ÊÄß„ÄÅÊ®°ÂûãÂèØÊì¥ÂÖÖÊÄßÔºå‰ª•ÂèäÈÅìÂæ∑ËÄÉÈáèÔºà‰æãÂ¶ÇÊ∏õËºïÂÅèÂ∑ÆÂíå‰∫ãÂØ¶Ê∫ñÁ¢∫ÊÄßÔºâÈÉΩÁ∂ìÈÅé‰ªîÁ¥∞ÂàÜÊûê„ÄÇÊú¨ÊñáÂª∫Ë≠∞Êú™‰æÜÁöÑÁ†îÁ©∂ÊñπÂêëÔºå‰ª•Êì¥ÂÖÖÈï∑ËÑàÁµ° LLM ÁöÑÂäüËÉΩÂíåÊáâÁî®Ôºå‰ΩøÂÖ∂ÊàêÁÇ∫ËΩâËÆä‰∏çÂêåÁî¢Ê•≠Âíå‰ºÅÊ•≠ÊáâÁî®Á®ãÂºèË≥áË®äËôïÁêÜÊñπÂºèÁöÑÈóúÈçµÂ∑•ÂÖ∑„ÄÇ

##### **Physics Augmented Tuple Transformer for Autism Severity Level Detection**
2409.18438v1 by Chinthaka Ranasingha, Harshala Gammulle, Tharindu Fernando, Sridha Sridharan, Clinton Fookes

Early diagnosis of Autism Spectrum Disorder (ASD) is an effective and
favorable step towards enhancing the health and well-being of children with
ASD. Manual ASD diagnosis testing is labor-intensive, complex, and prone to
human error due to several factors contaminating the results. This paper
proposes a novel framework that exploits the laws of physics for ASD severity
recognition. The proposed physics-informed neural network architecture encodes
the behaviour of the subject extracted by observing a part of the
skeleton-based motion trajectory in a higher dimensional latent space. Two
decoders, namely physics-based and non-physics-based decoder, use this latent
embedding and predict the future motion patterns. The physics branch leverages
the laws of physics that apply to a skeleton sequence in the prediction process
while the non-physics-based branch is optimised to minimise the difference
between the predicted and actual motion of the subject. A classifier also
leverages the same latent space embeddings to recognise the ASD severity. This
dual generative objective explicitly forces the network to compare the actual
behaviour of the subject with the general normal behaviour of children that are
governed by the laws of physics, aiding the ASD recognition task. The proposed
method attains state-of-the-art performance on multiple ASD diagnosis
benchmarks. To illustrate the utility of the proposed framework beyond the task
ASD diagnosis, we conduct a third experiment using a publicly available
benchmark for the task of fall prediction and demonstrate the superiority of
our model.

ÊëòË¶ÅÔºöËá™ÈñâÁóáË≠úÁ≥ªÈöúÁ§ô (ASD) ÁöÑÊó©ÊúüË®∫Êñ∑ÊòØÊîπÂñÑ ASD ÂÖíÁ´•ÂÅ•Â∫∑ÂíåÁ¶èÁ•âÁöÑÊúâÊïà‰∏îÊúâÂà©ÁöÑ‰∏ÄÊ≠•„ÄÇÊâãÂãï ASD Ë®∫Êñ∑Ê∏¨Ë©¶ÂãûÂãïÂØÜÈõÜ„ÄÅË§áÈõúÔºå‰∏îÂÆπÊòìÂõ†Â§öÁ®ÆÊ±°ÊüìÁµêÊûúÁöÑÂõ†Á¥†ËÄåÁî¢Áîü‰∫∫ÁÇ∫ÈåØË™§„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÊ°ÜÊû∂ÔºåÂà©Áî®Áâ©ÁêÜÂÆöÂæã‰æÜË≠òÂà• ASD ÁöÑÂö¥ÈáçÁ®ãÂ∫¶„ÄÇÊâÄÊèêÂá∫ÁöÑÁâ©ÁêÜË®äÊÅØÁ•ûÁ∂ìÁ∂≤Ë∑ØÊû∂ÊßãÁ∑®Á¢º‰∫ÜÈÄöÈÅéËßÄÂØüÂü∫ÊñºÈ™®Êû∂ÁöÑÈÅãÂãïËªåË∑°ÁöÑ‰∏ÄÈÉ®ÂàÜÂú®È´òÁ∂≠ÊΩõÂú®Á©∫Èñì‰∏≠ÊèêÂèñÁöÑ‰∏ªÈ´îË°åÁÇ∫„ÄÇÂÖ©ÂÄãËß£Á¢ºÂô®ÔºåÂç≥Âü∫ÊñºÁâ©ÁêÜÂíåÈùûÂü∫ÊñºÁâ©ÁêÜÁöÑËß£Á¢ºÂô®Ôºå‰ΩøÁî®Ê≠§ÊΩõÂú®ÂµåÂÖ•‰∏¶È†êÊ∏¨Êú™‰æÜÁöÑÈÅãÂãïÊ®°Âºè„ÄÇÁâ©ÁêÜÂàÜÊîØÂú®È†êÊ∏¨ÈÅéÁ®ã‰∏≠Âà©Áî®ÈÅ©Áî®ÊñºÈ™®Êû∂Â∫èÂàóÁöÑÁâ©ÁêÜÂÆöÂæãÔºåËÄåÈùûÂü∫ÊñºÁâ©ÁêÜÁöÑÂàÜÊîØÂâáÁ∂ìÈÅéÊúÄ‰Ω≥Âåñ‰ª•ÊúÄÂ∞èÂåñÂèóË©¶ËÄÖÈ†êÊ∏¨ÂíåÂØ¶ÈöõÈÅãÂãï‰πãÈñìÁöÑÂ∑ÆÁï∞„ÄÇÂàÜÈ°ûÂô®‰πüÂà©Áî®Áõ∏ÂêåÁöÑÊΩõÂú®Á©∫ÈñìÂµåÂÖ•‰æÜË≠òÂà• ASD ÁöÑÂö¥ÈáçÁ®ãÂ∫¶„ÄÇÈÄôÁ®ÆÈõôÈáçÁîüÊàêÁõÆÊ®ôÊòéÁ¢∫Âú∞Ëø´‰ΩøÁ∂≤Ë∑ØÂ∞áÂèóË©¶ËÄÖÁöÑÂØ¶ÈöõË°åÁÇ∫ËàáÂèóÁâ©ÁêÜÂÆöÂæãÊîØÈÖçÁöÑÂÖíÁ´•‰∏ÄËà¨Ê≠£Â∏∏Ë°åÁÇ∫ÈÄ≤Ë°åÊØîËºÉÔºåÂæûËÄåÊúâÂä©Êñº ASD Ë≠òÂà•‰ªªÂãô„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®Â§öÂÄã ASD Ë®∫Êñ∑Âü∫Ê∫ñ‰∏äÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇÁÇ∫‰∫ÜË™™ÊòéÊâÄÊèêÂá∫ÁöÑÊ°ÜÊû∂Âú® ASD Ë®∫Êñ∑‰ªªÂãô‰πãÂ§ñÁöÑÊïàÁî®ÔºåÊàëÂÄë‰ΩøÁî®ÂÖ¨ÈñãÂèØÁî®ÁöÑË∑åÂÄíÈ†êÊ∏¨‰ªªÂãôÂü∫Ê∫ñÈÄ≤Ë°å‰∫ÜÁ¨¨‰∏âÂÄãÂØ¶È©óÔºå‰∏¶Â±ïÁ§∫‰∫ÜÊàëÂÄëÊ®°ÂûãÁöÑÂÑ™Ë∂äÊÄß„ÄÇ

##### **LCMDC: Large-scale Chinese Medical Dialogue Corpora for Automatic Triage and Medical Consultation**
2410.03521v1 by Xinyuan Wang, Haozhou Li, Dingfang Zheng, Qinke Peng

The global COVID-19 pandemic underscored major deficiencies in traditional
healthcare systems, hastening the advancement of online medical services,
especially in medical triage and consultation. However, existing studies face
two main challenges. First, the scarcity of large-scale, publicly available,
domain-specific medical datasets due to privacy concerns, with current datasets
being small and limited to a few diseases, limiting the effectiveness of triage
methods based on Pre-trained Language Models (PLMs). Second, existing methods
lack medical knowledge and struggle to accurately understand professional terms
and expressions in patient-doctor consultations. To overcome these obstacles,
we construct the Large-scale Chinese Medical Dialogue Corpora (LCMDC),
comprising a Coarse-grained Triage dataset with 439,630 samples, a Fine-grained
Diagnosis dataset with 199,600 samples, and a Medical Consultation dataset with
472,418 items, thereby addressing the data shortage in this field. Moreover, we
further propose a novel triage system that combines BERT-based supervised
learning with prompt learning, as well as a GPT-based medical consultation
model using reinforcement learning. To enhance domain knowledge acquisition, we
pre-trained PLMs using our self-constructed background corpus. Experimental
results on the LCMDC demonstrate the efficacy of our proposed systems.

ÊëòË¶ÅÔºöÂÖ®ÁêÉ COVID-19 Â§ßÊµÅË°åÂá∏È°Ø‰∫ÜÂÇ≥Áµ±ÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±ÁöÑÈáçÂ§ßÁº∫Èô∑ÔºåÂä†ÈÄü‰∫ÜÁ∑ö‰∏äÈÜ´ÁôÇÊúçÂãôÁöÑÈÄ≤Â±ïÔºåÁâπÂà•ÊòØÂú®ÈÜ´ÁôÇÂàÜÊµÅÂíåË´ÆË©¢ÊñπÈù¢„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁ†îÁ©∂Èù¢Ëá®ÂÖ©È†Ö‰∏ªË¶ÅÊåëÊà∞„ÄÇÈ¶ñÂÖàÔºåÁî±ÊñºÈö±ÁßÅÂïèÈ°åÔºåÁº∫‰πèÂ§ßË¶èÊ®°„ÄÅÂÖ¨ÈñãÂèØÁî®„ÄÅÁâπÂÆöÈ†òÂüüÁöÑÈÜ´ÁôÇË≥áÊñôÈõÜÔºåËÄåÁï∂ÂâçË≥áÊñôÈõÜË¶èÊ®°Â∞è‰∏îÂÉÖÈôêÊñºÂ∞ëÊï∏ÁñæÁóÖÔºåÈÄôÈôêÂà∂‰∫ÜÂü∫ÊñºÈ†êÂÖàË®ìÁ∑¥Ë™ûË®ÄÊ®°Âûã (PLM) ÁöÑÂàÜÊµÅÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÂÖ∂Ê¨°ÔºåÁèæÊúâÊñπÊ≥ïÁº∫‰πèÈÜ´ÁôÇÁü•Ë≠òÔºåÈõ£‰ª•Ê∫ñÁ¢∫ÁêÜËß£ÊÇ£ËÄÖËàáÈÜ´ÁîüË´ÆË©¢‰∏≠ÁöÑÂ∞àÊ•≠Ë°ìË™ûÂíåË°®ÈÅîÊñπÂºè„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄô‰∫õÈöúÁ§ôÔºåÊàëÂÄëÊßãÂª∫‰∫ÜÂ§ßË¶èÊ®°‰∏≠ÊñáÈÜ´ÁôÇÂ∞çË©±Ë™ûÊñôÂ∫´ (LCMDC)ÔºåÂåÖÂê´‰∏ÄÂÄãÂåÖÂê´ 439,630 ÂÄãÊ®£Êú¨ÁöÑÁ≤óÁ≤íÂ∫¶ÂàÜÊµÅË≥áÊñôÈõÜ„ÄÅ‰∏ÄÂÄãÂåÖÂê´ 199,600 ÂÄãÊ®£Êú¨ÁöÑÁ¥∞Á≤íÂ∫¶Ë®∫Êñ∑Ë≥áÊñôÈõÜÔºå‰ª•Âèä‰∏ÄÂÄãÂåÖÂê´ 472,418 ÂÄãÊ¢ùÁõÆÁöÑÈÜ´ÁôÇË´ÆË©¢Ë≥áÊñôÈõÜÔºåÂæûËÄåËß£Ê±∫‰∫ÜË©≤È†òÂüüÁöÑË≥áÊñôÁü≠Áº∫ÂïèÈ°å„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂàÜÊµÅÁ≥ªÁµ±ÔºåÂÆÉÁµêÂêà‰∫ÜÂü∫Êñº BERT ÁöÑÁõ£Áù£ÂºèÂ≠∏ÁøíÂíåÊèêÁ§∫Â≠∏ÁøíÔºå‰ª•Âèä‰∏ÄÂÄã‰ΩøÁî®Âº∑ÂåñÂ≠∏ÁøíÁöÑÂü∫Êñº GPT ÁöÑÈÜ´ÁôÇË´ÆË©¢Ê®°Âûã„ÄÇÁÇ∫‰∫ÜÂ¢ûÂº∑È†òÂüüÁü•Ë≠òÁöÑÁç≤ÂèñÔºåÊàëÂÄë‰ΩøÁî®ÊàëÂÄëËá™Â∑±ÊßãÂª∫ÁöÑËÉåÊôØË™ûÊñôÂ∫´È†êÂÖàË®ìÁ∑¥‰∫Ü PLM„ÄÇÂú® LCMDC ‰∏äÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑÁ≥ªÁµ±ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **DRL-STNet: Unsupervised Domain Adaptation for Cross-modality Medical Image Segmentation via Disentangled Representation Learning**
2409.18340v1 by Hui Lin, Florian Schiffers, Santiago L√≥pez-Tapia, Neda Tavakoli, Daniel Kim, Aggelos K. Katsaggelos

Unsupervised domain adaptation (UDA) is essential for medical image
segmentation, especially in cross-modality data scenarios. UDA aims to transfer
knowledge from a labeled source domain to an unlabeled target domain, thereby
reducing the dependency on extensive manual annotations. This paper presents
DRL-STNet, a novel framework for cross-modality medical image segmentation that
leverages generative adversarial networks (GANs), disentangled representation
learning (DRL), and self-training (ST). Our method leverages DRL within a GAN
to translate images from the source to the target modality. Then, the
segmentation model is initially trained with these translated images and
corresponding source labels and then fine-tuned iteratively using a combination
of synthetic and real images with pseudo-labels and real labels. The proposed
framework exhibits superior performance in abdominal organ segmentation on the
FLARE challenge dataset, surpassing state-of-the-art methods by 11.4% in the
Dice similarity coefficient and by 13.1% in the Normalized Surface Dice metric,
achieving scores of 74.21% and 80.69%, respectively. The average running time
is 41 seconds, and the area under the GPU memory-time curve is 11,292 MB. These
results indicate the potential of DRL-STNet for enhancing cross-modality
medical image segmentation tasks.

ÊëòË¶ÅÔºöÁÑ°Áõ£Áù£ÂüüÈÅ©Êáâ (UDA) Â∞çÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤Ëá≥ÈóúÈáçË¶ÅÔºåÁâπÂà•ÊòØÂú®Ë∑®Ê®°ÊÖãÊï∏ÊìöÂ†¥ÊôØ‰∏≠„ÄÇUDA Êó®Âú®Â∞áÊ®ôË®ò‰æÜÊ∫êÂüüÁöÑÁü•Ë≠òËΩâÁßªÂà∞Êú™Ê®ôË®òÁõÆÊ®ôÂüüÔºåÂæûËÄåÊ∏õÂ∞ëÂ∞çÂ§ßÈáè‰∫∫Â∑•Ê®ôË®ªÁöÑ‰æùË≥¥„ÄÇÊú¨ÊñáÊèêÂá∫ DRL-STNetÔºåÈÄôÊòØ‰∏ÄÂÄãÁî®ÊñºË∑®Ê®°ÊÖãÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤ÁöÑÊñ∞Á©éÊû∂ÊßãÔºåÂÆÉÂà©Áî®ÁîüÊàêÂ∞çÊäóÁ∂≤Ë∑Ø (GAN)„ÄÅËß£Á≥æÁ∫èË°®Á§∫Â≠∏Áøí (DRL) ÂíåËá™ÊàëË®ìÁ∑¥ (ST)„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú® GAN ‰∏≠Âà©Áî® DRL Â∞áÂΩ±ÂÉèÂæû‰æÜÊ∫êËΩâÊèõÂà∞ÁõÆÊ®ôÊ®°ÊÖã„ÄÇÁÑ∂ÂæåÔºåÂàÜÂâ≤Ê®°ÂûãÊúÄÂàù‰ΩøÁî®ÈÄô‰∫õËΩâÊèõÂæåÁöÑÂΩ±ÂÉèÂíåÂ∞çÊáâÁöÑ‰æÜÊ∫êÊ®ôÁ±§ÈÄ≤Ë°åË®ìÁ∑¥ÔºåÁÑ∂Âæå‰ΩøÁî®ÂêàÊàêÂΩ±ÂÉèÂíåÂ∏∂ÊúâÂÅΩÊ®ôÁ±§ÂíåÁúüÂØ¶Ê®ôÁ±§ÁöÑÁúüÂØ¶ÂΩ±ÂÉèÁöÑÁµÑÂêàÈÄ≤Ë°åÂèçË¶ÜÂæÆË™ø„ÄÇÊâÄÊèêÂá∫ÁöÑÊû∂ÊßãÂú® FLARE ÊåëÊà∞Ë≥áÊñôÈõÜ‰∏äÁöÑËÖπÈÉ®Âô®ÂÆòÂàÜÂâ≤‰∏≠Ë°®ÁèæÂá∫ÂÑ™Áï∞ÁöÑÊïàËÉΩÔºåÂú® Dice Áõ∏‰ºº‰øÇÊï∏‰∏äË∂ÖË∂äÁèæÊúâÊäÄË°ì 11.4%ÔºåÂú®Ê®ôÊ∫ñÂåñË°®Èù¢ Dice ÊåáÊ®ô‰∏äË∂ÖË∂ä 13.1%ÔºåÂàÜÂà•ÈÅîÂà∞ 74.21% Âíå 80.69% ÁöÑÂàÜÊï∏„ÄÇÂπ≥ÂùáÂü∑Ë°åÊôÇÈñìÁÇ∫ 41 ÁßíÔºåGPU Ë®òÊÜ∂È´îÊôÇÈñìÊõ≤Á∑ö‰∏ãÁöÑÈù¢Á©çÁÇ∫ 11,292 MB„ÄÇÈÄô‰∫õÁµêÊûúË°®Êòé DRL-STNet Âú®Â¢ûÂº∑Ë∑®Ê®°ÊÖãÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤‰ªªÂãôÊñπÈù¢ÂÖ∑ÊúâÊΩõÂäõ„ÄÇ

##### **Cross-Institutional Structured Radiology Reporting for Lung Cancer Screening Using a Dynamic Template-Constrained Large Language Model**
2409.18319v1 by Chuang Niu, Parisa Kaviani, Qing Lyu, Mannudeep K. Kalra, Christopher T. Whitlow, Ge Wang

Structured radiology reporting is advantageous for optimizing clinical
workflows and patient outcomes. Current LLMs in creating structured reports
face the challenges of formatting errors, content hallucinations, and privacy
leakage concerns when uploaded to external servers. We aim to develop an
enhanced open-source LLM for creating structured and standardized LCS reports
from free-text descriptions. After institutional IRB approvals, 5,442
de-identified LCS reports from two institutions were retrospectively analyzed.
500 reports were randomly selected from the two institutions evenly and then
manually labeled for evaluation. Two radiologists from the two institutions
developed a standardized template including 29 features for lung nodule
reporting. We proposed template-constrained decoding to enhance
state-of-the-art open-source LLMs, including LLAMA, Qwen, and Mistral. The LLM
performance was extensively evaluated in terms of F1 score, confidence
interval, McNemar test, and z-test. Based on the structured reports created
from the large-scale dataset, a nodule-level retrieval system was prototyped
and an automatic statistical analysis was performed. Our software,
vLLM-structure, is publicly available for local deployment with enhanced LLMs.
Our template-constrained decoding approach consistently enhanced the LLM
performance on multi-institutional datasets, with neither formatting errors nor
content hallucinations. Our method improved the best open-source LLAMA-3.1 405B
by up to 10.42%, and outperformed GPT-4o by 17.19%. A novel nodule retrieval
system was successfully prototyped and demonstrated on a large-scale multimodal
database using our enhanced LLM technologies. The automatically derived
statistical distributions were closely consistent with the prior findings in
terms of nodule type, location, size, status, and Lung-RADS.

ÊëòË¶ÅÔºöÁµêÊßãÂåñÊîæÂ∞ÑÂ†±ÂëäÊúâÂà©ÊñºÂÑ™ÂåñËá®Â∫äÂ∑•‰ΩúÊµÅÁ®ãÂíåÊÇ£ËÄÖÁµêÊûú„ÄÇÁï∂Ââç LLM Âú®Âª∫Á´ãÁµêÊßãÂåñÂ†±ÂëäÊôÇÔºåÂú®Ê†ºÂºèÈåØË™§„ÄÅÂÖßÂÆπÂπªË¶∫ÂíåÈö±ÁßÅÊ¥©Èú≤ÂïèÈ°å‰∏äÔºåÈù¢Ëá®‰∏äÂÇ≥Ëá≥Â§ñÈÉ®‰º∫ÊúçÂô®ÁöÑÊåëÊà∞„ÄÇÊàëÂÄëÁöÑÁõÆÊ®ôÊòØÈñãÁôº‰∏ÄÂÄãÂ¢ûÂº∑ÁöÑÈñãÊ∫ê LLMÔºåÁî®ÊñºÊ†πÊìöËá™Áî±ÊñáÂ≠óË™™ÊòéÂª∫Á´ãÁµêÊßãÂåñ‰∏îÊ®ôÊ∫ñÂåñÁöÑ LCS Â†±Âëä„ÄÇÂú®Áç≤ÂæóÊ©üÊßã IRB ÊâπÂáÜÂæåÔºåÂõûÈ°ßÊÄßÂàÜÊûê‰∫Ü‰æÜËá™ÂÖ©ÂÄãÊ©üÊßãÁöÑ 5,442 ‰ªΩÂéªË≠òÂà•Âåñ LCS Â†±Âëä„ÄÇÂæûÂÖ©ÂÄãÊ©üÊßã‰∏≠Èö®Ê©üÈÅ∏Âèñ 500 ‰ªΩÂ†±ÂëäÔºåÁÑ∂ÂæåÊâãÂãïÊ®ôË®ò‰ª•ÈÄ≤Ë°åË©ï‰º∞„ÄÇ‰æÜËá™ÂÖ©ÂÄãÊ©üÊßãÁöÑÂÖ©ÂêçÊîæÂ∞ÑÁßëÈÜ´Â∏´ÈñãÁôº‰∫Ü‰∏ÄÂÄãÊ®ôÊ∫ñÂåñÁØÑÊú¨ÔºåÂÖ∂‰∏≠ÂåÖÂê´ 29 ÂÄãËÇ∫ÁµêÁØÄÂ†±ÂëäÂäüËÉΩ„ÄÇÊàëÂÄëÊèêÂá∫‰∫ÜÁØÑÊú¨Á¥ÑÊùüËß£Á¢ºÔºå‰ª•Â¢ûÂº∑ÊúÄÂÖàÈÄ≤ÁöÑÈñãÊ∫ê LLMÔºåÂåÖÊã¨ LLAMA„ÄÅQwen Âíå Mistral„ÄÇLLM ÊïàËÉΩÊ†πÊìö F1 ÂàÜÊï∏„ÄÅ‰ø°ÂøÉÂçÄÈñì„ÄÅMcNemar Ê™¢ÂÆöÂíå z Ê™¢ÂÆöÈÄ≤Ë°åÂª£Ê≥õË©ï‰º∞„ÄÇÊ†πÊìöÂæûÂ§ßÂûãË≥áÊñôÈõÜÂª∫Á´ãÁöÑÁµêÊßãÂåñÂ†±ÂëäÔºåÂª∫Á´ã‰∫ÜÁµêÁØÄÂ±§Á¥öÊ™¢Á¥¢Á≥ªÁµ±‰∏¶Âü∑Ë°åËá™ÂãïÁµ±Ë®àÂàÜÊûê„ÄÇÊàëÂÄëÁöÑËªüÈ´î vLLM-structure ÂèØÂÖ¨Èñã‰ΩøÁî®Ôºå‰∏¶ÂèØËàáÂ¢ûÂº∑ÁöÑ LLM Êê≠ÈÖçÈÄ≤Ë°åÊú¨Âú∞ÈÉ®ÁΩ≤„ÄÇÊàëÂÄëÁöÑÁØÑÊú¨Á¥ÑÊùüËß£Á¢ºÊñπÊ≥ïÊåÅÁ∫åÂ¢ûÂº∑ LLM Âú®Â§öÊ©üÊßãË≥áÊñôÈõÜ‰∏äÁöÑÊïàËÉΩÔºåÊó¢Ê≤íÊúâÊ†ºÂºèÈåØË™§Ôºå‰πüÊ≤íÊúâÂÖßÂÆπÂπªË¶∫„ÄÇÊàëÂÄëÁöÑÊäÄË°ìÂ∞áÊúÄ‰Ω≥ÈñãÊ∫ê LLAMA-3.1 405B ÊèêÂçá‰∫Ü 10.42%Ôºå‰∏¶Ë∂ÖË∂ä‰∫Ü GPT-4o 17.19%„ÄÇ‰ΩøÁî®ÊàëÂÄëÂ¢ûÂº∑ÁöÑ LLM ÊäÄË°ìÔºåÊàêÂäüÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÁµêÁØÄÊ™¢Á¥¢Á≥ªÁµ±Ôºå‰∏¶Âú®Â§ßÂûãÂ§öÊ®°ÂºèË≥áÊñôÂ∫´‰∏äÈÄ≤Ë°å‰∫ÜÂ±ïÁ§∫„ÄÇËá™ÂãïË°çÁîüÁöÑÁµ±Ë®àÂàÜ‰ΩàËàáÂÖàÂâçÁöÑÁôºÁèæÈùûÂ∏∏‰∏ÄËá¥ÔºåÂåÖÊã¨ÁµêÁØÄÈ°ûÂûã„ÄÅ‰ΩçÁΩÆ„ÄÅÂ§ßÂ∞è„ÄÅÁãÄÊÖãÂíå Lung-RADS„ÄÇ

##### **Retrospective Comparative Analysis of Prostate Cancer In-Basket Messages: Responses from Closed-Domain LLM vs. Clinical Teams**
2409.18290v1 by Yuexing Hao, Jason M. Holmes, Jared Hobson, Alexandra Bennett, Daniel K. Ebner, David M. Routman, Satomi Shiraishi, Samir H. Patel, Nathan Y. Yu, Chris L. Hallemeier, Brooke E. Ball, Mark R. Waddle, Wei Liu

In-basket message interactions play a crucial role in physician-patient
communication, occurring during all phases (pre-, during, and post) of a
patient's care journey. However, responding to these patients' inquiries has
become a significant burden on healthcare workflows, consuming considerable
time for clinical care teams. To address this, we introduce RadOnc-GPT, a
specialized Large Language Model (LLM) powered by GPT-4 that has been designed
with a focus on radiotherapeutic treatment of prostate cancer with advanced
prompt engineering, and specifically designed to assist in generating
responses. We integrated RadOnc-GPT with patient electronic health records
(EHR) from both the hospital-wide EHR database and an internal,
radiation-oncology-specific database. RadOnc-GPT was evaluated on 158
previously recorded in-basket message interactions. Quantitative natural
language processing (NLP) analysis and two grading studies with clinicians and
nurses were used to assess RadOnc-GPT's responses. Our findings indicate that
RadOnc-GPT slightly outperformed the clinical care team in "Clarity" and
"Empathy," while achieving comparable scores in "Completeness" and
"Correctness." RadOnc-GPT is estimated to save 5.2 minutes per message for
nurses and 2.4 minutes for clinicians, from reading the inquiry to sending the
response. Employing RadOnc-GPT for in-basket message draft generation has the
potential to alleviate the workload of clinical care teams and reduce
healthcare costs by producing high-quality, timely responses.

ÊëòË¶ÅÔºöÊî∂‰ª∂Âå£Ë®äÊÅØ‰∫íÂãïÂú®ÈÜ´Â∏´ËàáÁóÖÊÇ£Ê∫ùÈÄö‰∏≠ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤ÔºåÁôºÁîüÂú®ÁóÖÊÇ£ÁÖßË≠∑ÊóÖÁ®ãÁöÑÂêÑÂÄãÈöéÊÆµÔºà‰∫ãÂâç„ÄÅ‰∫ã‰∏≠Âíå‰∫ãÂæåÔºâ„ÄÇÁÑ∂ËÄåÔºåÂõûÊáâÈÄô‰∫õÁóÖÊÇ£ÁöÑË©¢ÂïèÂ∑≤ÊàêÁÇ∫ÈÜ´ÁôÇÂ∑•‰ΩúÊµÅÁ®ãÁöÑÈáçÂ§ßË≤†ÊìîÔºåËÄóË≤ªËá®Â∫äÁÖßË≠∑ÂúòÈöäÂ§ßÈáèÊôÇÈñì„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÈÄ≤ RadOnc-GPTÔºåÈÄôÊòØ‰∏ÄÂÄãÁî± GPT-4 Êèê‰æõÊäÄË°ìÊîØÊè¥ÁöÑÂ∞àÊ•≠Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)ÔºåÂÖ∂Ë®≠Ë®àÈáçÈªûÂú®ÊñºÈÄèÈÅéÈÄ≤ÈöéÊèêÁ§∫Â∑•Á®ãÊäÄË°ìÂ∞çÊîùË≠∑ËÖ∫ÁôåÈÄ≤Ë°åÊîæÂ∞ÑÊ≤ªÁôÇÔºå‰∏¶ÁâπÂà•Ë®≠Ë®àÁî®ÊñºÂçîÂä©Áî¢ÁîüÂõûÊáâ„ÄÇÊàëÂÄëÂ∞á RadOnc-GPT Êï¥ÂêàÂà∞ÁóÖÊÇ£ÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) ‰∏≠ÔºåÈÄô‰∫õÁ¥ÄÈåÑ‰æÜËá™ÊñºÂÖ®Èô¢ÁöÑ EHR Ë≥áÊñôÂ∫´Âíå‰∏ÄÂÄãÂÖßÈÉ®ÁöÑÊîæÂ∞ÑËÖ´Áò§Â∞àÁî®Ë≥áÊñôÂ∫´„ÄÇRadOnc-GPT ÈáùÂ∞ç 158 ÂâáÂÖàÂâçË®òÈåÑÁöÑÊî∂‰ª∂Âå£Ë®äÊÅØ‰∫íÂãïÈÄ≤Ë°åË©ï‰º∞„ÄÇÊàëÂÄë‰ΩøÁî®ÈáèÂåñËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÂàÜÊûêÂíåÂÖ©È†ÖË©ïÂàÜÁ†îÁ©∂ÔºàÁî±Ëá®Â∫äÈÜ´Â∏´ÂíåË≠∑ÁêÜÂ∏´ÈÄ≤Ë°åÔºâ‰æÜË©ï‰º∞ RadOnc-GPT ÁöÑÂõûÊáâ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåRadOnc-GPT Âú®„ÄåÊ∏ÖÊô∞Â∫¶„ÄçÂíå„ÄåÂêåÁêÜÂøÉ„ÄçÊñπÈù¢Ë°®ÁèæÁï•ÂÑ™ÊñºËá®Â∫äÁÖßË≠∑ÂúòÈöäÔºåÂêåÊôÇÂú®„ÄåÂÆåÊï¥ÊÄß„ÄçÂíå„ÄåÊ≠£Á¢∫ÊÄß„ÄçÊñπÈù¢ÈÅîÂà∞Áõ∏Áï∂ÁöÑÂàÜÊï∏„ÄÇ‰º∞Ë®à RadOnc-GPT ÂèØÁÇ∫Ë≠∑ÁêÜÂ∏´ÁØÄÁúÅÊØèÂâáË®äÊÅØ 5.2 ÂàÜÈêòÔºåÁÇ∫Ëá®Â∫äÈÜ´Â∏´ÁØÄÁúÅ 2.4 ÂàÜÈêòÔºåÂæûÈñ±ËÆÄË©¢ÂïèÂà∞ÁôºÈÄÅÂõûÊáâ„ÄÇÊé°Áî® RadOnc-GPT ‰æÜÁî¢ÁîüÊî∂‰ª∂Âå£Ë®äÊÅØËçâÁ®øÊúâÊΩõÂäõÊ∏õËºïËá®Â∫äÁÖßË≠∑ÂúòÈöäÁöÑÂ∑•‰ΩúË≤†ÊìîÔºå‰∏¶ÈÄèÈÅéÁî¢ÁîüÈ´òÂìÅË≥™„ÄÅÂèäÊôÇÁöÑÂõûÊáâ‰æÜÈôç‰ΩéÈÜ´ÁôÇ‰øùÂÅ•ÊàêÊú¨„ÄÇ

##### **Evaluation of Large Language Models for Summarization Tasks in the Medical Domain: A Narrative Review**
2409.18170v1 by Emma Croxford, Yanjun Gao, Nicholas Pellegrino, Karen K. Wong, Graham Wills, Elliot First, Frank J. Liao, Cherodeep Goswami, Brian Patterson, Majid Afshar

Large Language Models have advanced clinical Natural Language Generation,
creating opportunities to manage the volume of medical text. However, the
high-stakes nature of medicine requires reliable evaluation, which remains a
challenge. In this narrative review, we assess the current evaluation state for
clinical summarization tasks and propose future directions to address the
resource constraints of expert human evaluation.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã‰øÉÈÄ≤‰∫ÜËá®Â∫äËá™ÁÑ∂Ë™ûË®ÄÁîüÊàêÔºå
ÂâµÈÄ†‰∫ÜÁÆ°ÁêÜÂ§ßÈáèÈÜ´ÁôÇÊñáÊú¨ÁöÑÊ©üÊúÉ„ÄÇÁÑ∂ËÄåÔºå
ÈÜ´Â≠∏ÁöÑÈ´òÈ¢®Èö™ÊÄßË≥™ÈúÄË¶ÅÂèØÈù†ÁöÑË©ï‰º∞ÔºåÈÄô‰ªçÁÑ∂ÊòØ‰∏ÄÂÄã
ÊåëÊà∞„ÄÇÂú®ÈÄôÂÄãÊïòËø∞ÊÄßÂõûÈ°ß‰∏≠ÔºåÊàëÂÄëË©ï‰º∞‰∫Ü
Ëá®Â∫äÊëòË¶Å‰ªªÂãôÁöÑÁï∂ÂâçË©ï‰º∞ÁãÄÊÖãÔºå‰∏¶ÊèêÂá∫Êú™‰æÜÁöÑÊñπÂêëÔºå‰ª•Ëß£Ê±∫
Â∞àÂÆ∂‰∫∫È°ûË©ï‰º∞ÁöÑË≥áÊ∫êÈôêÂà∂„ÄÇ

##### **Multi-View and Multi-Scale Alignment for Contrastive Language-Image Pre-training in Mammography**
2409.18119v1 by Yuexi Du, John Onofrey, Nicha C. Dvornek

Contrastive Language-Image Pre-training (CLIP) shows promise in medical image
analysis but requires substantial data and computational resources. Due to
these restrictions, existing CLIP applications in medical imaging focus mainly
on modalities like chest X-rays that have abundant image-report data available,
leaving many other important modalities under-explored. Here, we propose the
first adaptation of the full CLIP model to mammography, which presents
significant challenges due to labeled data scarcity, high-resolution images
with small regions of interest, and data imbalance. We first develop a
specialized supervision framework for mammography that leverages its multi-view
nature. Furthermore, we design a symmetric local alignment module to better
focus on detailed features in high-resolution images. Lastly, we incorporate a
parameter-efficient fine-tuning approach for large language models pre-trained
with medical knowledge to address data limitations. Our multi-view and
multi-scale alignment (MaMA) method outperforms state-of-the-art baselines for
three different tasks on two large real-world mammography datasets, EMBED and
RSNA-Mammo, with only 52% model size compared with the largest baseline.

ÊëòË¶ÅÔºöÂ∞çÊØîË™ûË®ÄÂΩ±ÂÉèÈ†êË®ìÁ∑¥ (CLIP) Âú®ÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÊûê‰∏≠Â±ïÁèæÊΩõÂäõÔºå‰ΩÜÈúÄË¶ÅÂ§ßÈáèÁöÑË≥áÊñôÂíåÈÅãÁÆóË≥áÊ∫ê„ÄÇÁî±ÊñºÈÄô‰∫õÈôêÂà∂ÔºåÁèæÊúâÁöÑ CLIP Âú®ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÁöÑÊáâÁî®‰∏ªË¶ÅÈõÜ‰∏≠Âú®ËÉ∏ÈÉ® X ÂÖâÁ≠âÊúâË±êÂØåÂΩ±ÂÉèÂ†±ÂëäË≥áÊñôÁöÑÊ®°ÂºèÔºåÂ∞éËá¥Ë®±Â§öÂÖ∂‰ªñÈáçË¶ÅÁöÑÊ®°ÂºèÊú™Ë¢´ÂÖÖÂàÜÊé¢Á¥¢„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÊèêÂá∫Â∞áÂÆåÊï¥ÁöÑ CLIP Ê®°ÂûãÈ¶ñÊ¨°ÈÅ©ÊáâÊñº‰π≥ÊàøÊîùÂΩ±ÔºåÁî±ÊñºÊ®ôÁ±§Ë≥áÊñôÁ®ÄÂ∞ë„ÄÅÈ´òËß£ÊûêÂ∫¶ÂΩ±ÂÉè‰∏≠ÊÑüËààË∂£ÂçÄÂüüËºÉÂ∞èÔºå‰ª•ÂèäË≥áÊñô‰∏çÂπ≥Ë°°ÔºåÈÄôÊèêÂá∫‰∫ÜÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÊàëÂÄëÈ¶ñÂÖàÈñãÁôº‰∫Ü‰∏ÄÂÄãÂ∞àÈñÄÁöÑÁõ£Áù£Êû∂ÊßãÁî®Êñº‰π≥ÊàøÊîùÂΩ±ÔºåÂà©Áî®ÂÖ∂Â§öË¶ñÂúñÁöÑÁâπÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÂ∞çÁ®±Â±ÄÈÉ®Â∞çÈΩäÊ®°ÁµÑÔºå‰ª•Êõ¥Â•ΩÂú∞ËÅöÁÑ¶ÊñºÈ´òËß£ÊûêÂ∫¶ÂΩ±ÂÉè‰∏≠ÁöÑË©≥Á¥∞ÁâπÂæµ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÁµêÂêà‰∫Ü‰∏ÄÂÄãÂèÉÊï∏È´òÊïàÁöÑÂæÆË™øÊñπÊ≥ïÔºåÁî®ÊñºÈ†êÂÖàË®ìÁ∑¥ÂÖ∑ÊúâÈÜ´Â≠∏Áü•Ë≠òÁöÑÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºå‰ª•Ëß£Ê±∫Ë≥áÊñôÈôêÂà∂„ÄÇÊàëÂÄëÁöÑÂ§öË¶ñÂúñÂíåÂ§öÂ∞∫Â∫¶Â∞çÈΩä (MaMA) ÊñπÊ≥ïÂú®ÂÖ©ÂÄãÂ§ßÂûãÁúüÂØ¶‰∏ñÁïå‰π≥ÊàøÊîùÂΩ±Ë≥áÊñôÈõÜ EMBED Âíå RSNA-Mammo ÁöÑ‰∏âÂÄã‰∏çÂêå‰ªªÂãô‰∏≠ÂÑ™ÊñºÁèæÊúâÊäÄË°ìÂü∫Á∑öÔºåËÄåÊ®°ÂûãÂ§ßÂ∞èÂÉÖÁÇ∫ÊúÄÂ§ßÂü∫Á∑öÁöÑ 52%„ÄÇ

##### **CRoP: Context-wise Robust Static Human-Sensing Personalization**
2409.17994v2 by Sawinder Kaur, Avery Gump, Jingyu Xin, Yi Xiao, Harshit Sharma, Nina R Benway, Jonathan L Preston, Asif Salekin

The advancement in deep learning and internet-of-things have led to diverse
human sensing applications. However, distinct patterns in human sensing,
influenced by various factors or contexts, challenge generic neural network
model's performance due to natural distribution shifts. To address this,
personalization tailors models to individual users. Yet most personalization
studies overlook intra-user heterogeneity across contexts in sensory data,
limiting intra-user generalizability. This limitation is especially critical in
clinical applications, where limited data availability hampers both
generalizability and personalization. Notably, intra-user sensing attributes
are expected to change due to external factors such as treatment progression,
further complicating the challenges. This work introduces CRoP, a novel static
personalization approach using an off-the-shelf pre-trained model and pruning
to optimize personalization and generalization. CRoP shows superior
personalization effectiveness and intra-user robustness across four
human-sensing datasets, including two from real-world health domains,
highlighting its practical and social impact. Additionally, to support CRoP's
generalization ability and design choices, we provide empirical justification
through gradient inner product analysis, ablation studies, and comparisons
against state-of-the-art baselines.

ÊëòË¶ÅÔºöÊ∑±Â∫¶Â≠∏ÁøíÂíåÁâ©ËÅØÁ∂≤ÁöÑÈÄ≤Ê≠•Â∑≤Â∞éËá¥ÂêÑÁ®Æ‰∫∫È°ûÊÑüÊ∏¨ÊáâÁî®„ÄÇÁÑ∂ËÄåÔºåÂèóÂêÑÁ®ÆÂõ†Á¥†ÊàñÊÉÖÂ¢ÉÂΩ±ÈüøÁöÑ‰∫∫È°ûÊÑüÊ∏¨‰∏≠ÁöÑ‰∏çÂêåÊ®°ÂºèÔºåÁî±ÊñºËá™ÁÑ∂ÂàÜ‰ΩàËΩâÁßªÔºåÂ∞çÈÄöÁî®Á•ûÁ∂ìÁ∂≤Ë∑ØÊ®°ÂûãÁöÑÊïàËÉΩÊßãÊàêÊåëÊà∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÂÄã‰∫∫ÂåñÊúÉÊ†πÊìöÂÄãÂà•‰ΩøÁî®ËÄÖË™øÊï¥Ê®°Âûã„ÄÇÁÑ∂ËÄåÔºåÂ§ßÂ§öÊï∏ÂÄã‰∫∫ÂåñÁ†îÁ©∂ÂøΩÁï•‰∫ÜÊÑüÊ∏¨Ë≥áÊñô‰∏≠Ë∑®ÊÉÖÂ¢ÉÂÖßÁöÑ‰ΩøÁî®ËÄÖÂÖßÈÉ®Áï∞Ë≥™ÊÄßÔºåÈÄôÈôêÂà∂‰∫Ü‰ΩøÁî®ËÄÖÂÖßÈÉ®ÁöÑ‰∏ÄËà¨ÂåñËÉΩÂäõ„ÄÇÊ≠§ÈôêÂà∂Âú®Ëá®Â∫äÊáâÁî®‰∏≠ÁâπÂà•ÈóúÈçµÔºåÂõ†ÁÇ∫Ë≥áÊñôÂèØÁî®ÊÄßÊúâÈôêÊúÉÈòªÁ§ô‰∏ÄËà¨ÂåñËÉΩÂäõÂíåÂÄã‰∫∫Âåñ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÁî±ÊñºÊ≤ªÁôÇÈÄ≤Â±ïÁ≠âÂ§ñÈÉ®Âõ†Á¥†ÔºåÈ†êË®à‰ΩøÁî®ËÄÖÂÖßÈÉ®ÊÑüÊ∏¨Â±¨ÊÄßÊúÉÁôºÁîüËÆäÂåñÔºåÈÄ≤‰∏ÄÊ≠•‰ΩøÊåëÊà∞Ë§áÈõúÂåñ„ÄÇÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫Ü CRoPÔºå‰∏ÄÁ®Æ‰ΩøÁî®ÁèæÊàêÁöÑÈ†êË®ìÁ∑¥Ê®°ÂûãÂíåÂâ™Êûù‰æÜÊúÄ‰Ω≥ÂåñÂÄã‰∫∫ÂåñÂíå‰∏ÄËà¨ÂåñÁöÑÂâµÊñ∞ÈùúÊÖãÂÄã‰∫∫ÂåñÊñπÊ≥ï„ÄÇCRoP Âú®ÂõõÂÄã‰∫∫È°ûÊÑüÊ∏¨Ë≥áÊñôÈõÜÔºàÂåÖÊã¨ÂÖ©ÂÄã‰æÜËá™ÁúüÂØ¶‰∏ñÁïåÂÅ•Â∫∑È†òÂüüÁöÑË≥áÊñôÈõÜÔºâ‰∏≠Â±ïÁèæÂá∫ÂÑ™Áï∞ÁöÑÂÄã‰∫∫ÂåñÊïàËÉΩÂíå‰ΩøÁî®ËÄÖÂÖßÈÉ®Á©©ÂÅ•ÊÄßÔºåÁ™ÅÈ°ØÂÖ∂ÂØ¶Áî®ÊÄßÂíåÁ§æÊúÉÂΩ±Èüø„ÄÇÊ≠§Â§ñÔºåÁÇ∫‰∫ÜÊîØÊè¥ CRoP ÁöÑ‰∏ÄËà¨ÂåñËÉΩÂäõÂíåË®≠Ë®àÈÅ∏ÊìáÔºåÊàëÂÄëÈÄèÈÅéÊ¢ØÂ∫¶ÂÖßÁ©çÂàÜÊûê„ÄÅÊ∂àËûçÁ†îÁ©∂ÂíåËàáÊúÄÊñ∞Âü∫Ê∫ñÁöÑÊØîËºÉÊèê‰æõÁ∂ìÈ©ó‰æùÊìö„ÄÇ

##### **Supervised Learning Model for Key Frame Identification from Cow Teat Videos**
2409.18797v1 by Minghao Wang, Pinxue Lin

This paper proposes a method for improving the accuracy of mastitis risk
assessment in cows using neural networks and video analysis. Mastitis, an
infection of the udder tissue, is a critical health problem for cows and can be
detected by examining the cow's teat. Traditionally, veterinarians assess the
health of a cow's teat during the milking process, but this process is limited
in time and can weaken the accuracy of the assessment. In commercial farms,
cows are recorded by cameras when they are milked in the milking parlor. This
paper uses a neural network to identify key frames in the recorded video where
the cow's udder appears intact. These key frames allow veterinarians to have
more flexible time to perform health assessments on the teat, increasing their
efficiency and accuracy. However, there are challenges in using cow teat video
for mastitis risk assessment, such as complex environments, changing cow
positions and postures, and difficulty in identifying the udder from the video.
To address these challenges, a fusion distance and an ensemble model are
proposed to improve the performance (F-score) of identifying key frames from
cow teat videos. The results show that these two approaches improve performance
compared to using a single distance measure or model.

ÊëòË¶ÅÔºöÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂà©Áî®Á•ûÁªèÁΩëÁªúÂíåËßÜÈ¢ëÂàÜÊûêÊù•ÊèêÈ´ò‰π≥ÊàøÁÇéÈ£éÈô©ËØÑ‰º∞ÂáÜÁ°ÆÁéáÁöÑÊñπÊ≥ï„ÄÇ‰π≥ÊàøÁÇéÊòØÂ•∂ÁâõÁöÑ‰π≥ÊàøÁªÑÁªáÊÑüÊüìÔºåÊòØ‰∏ÄÁßçÂØπÂ•∂ÁâõÂÅ•Â∫∑ÈÄ†Êàê‰∏•ÈáçÂ®ÅËÉÅÁöÑÁñæÁóÖÔºåÂèØ‰ª•ÈÄöËøáÊ£ÄÊü•Â•∂ÁâõÁöÑ‰π≥Â§¥Êù•Ê£ÄÊµã„ÄÇ‰º†Áªü‰∏äÔºåÂÖΩÂåªÂú®Êå§Â•∂ËøáÁ®ã‰∏≠ËØÑ‰º∞Â•∂Áâõ‰π≥Â§¥ÁöÑÂÅ•Â∫∑Áä∂ÂÜµÔºå‰ΩÜËøôÁßçÊñπÊ≥ïÂèóÊó∂Èó¥ÈôêÂà∂ÔºåÂπ∂‰∏î‰ºöÈôç‰ΩéËØÑ‰º∞ÁöÑÂáÜÁ°ÆÊÄß„ÄÇÂú®ÂïÜ‰∏öÂåñÂÜúÂú∫‰∏≠ÔºåÂ•∂ÁâõÂú®Êå§Â•∂Êó∂‰ºöË¢´ÊëÑÂÉèÂ§¥ËÆ∞ÂΩï‰∏ãÊù•„ÄÇÊú¨Êñá‰ΩøÁî®Á•ûÁªèÁΩëÁªúÊù•ËØÜÂà´ËÆ∞ÂΩïÁöÑËßÜÈ¢ë‰∏≠Â•∂Áâõ‰π≥ÊàøÂÆåÂ•ΩÊó†ÊçüÁöÑÂÖ≥ÈîÆÂ∏ß„ÄÇËøô‰∫õÂÖ≥ÈîÆÂ∏ßÂÖÅËÆ∏ÂÖΩÂåªÊúâÊõ¥ÁÅµÊ¥ªÁöÑÊó∂Èó¥ÂØπ‰π≥Â§¥ËøõË°åÂÅ•Â∫∑ËØÑ‰º∞Ôºå‰ªéËÄåÊèêÈ´òÊïàÁéáÂíåÂáÜÁ°ÆÊÄß„ÄÇÁÑ∂ËÄåÔºåÂà©Áî®Â•∂Áâõ‰π≥Â§¥ËßÜÈ¢ëËøõË°å‰π≥ÊàøÁÇéÈ£éÈô©ËØÑ‰º∞Â≠òÂú®‰∏Ä‰∫õÊåëÊàòÔºå‰æãÂ¶ÇÂ§çÊùÇÁöÑÁéØÂ¢É„ÄÅ‰∏çÊñ≠ÂèòÂåñÁöÑÂ•∂Áâõ‰ΩçÁΩÆÂíåÂßøÂäøÔºå‰ª•Âèä‰ªéËßÜÈ¢ë‰∏≠ËØÜÂà´‰π≥ÊàøÁöÑÂõ∞Èöæ„ÄÇ‰∏∫‰∫ÜÂ∫îÂØπËøô‰∫õÊåëÊàòÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçËûçÂêàË∑ùÁ¶ªÂíåÈõÜÊàêÊ®°ÂûãÊù•ÊèêÈ´ò‰ªéÂ•∂Áâõ‰π≥Â§¥ËßÜÈ¢ë‰∏≠ËØÜÂà´ÂÖ≥ÈîÆÂ∏ßÁöÑÊÄßËÉΩÔºàF ÂÄºÔºâ„ÄÇÁªìÊûúË°®ÊòéÔºå‰∏é‰ΩøÁî®Âçï‰∏ÄË∑ùÁ¶ªÂ∫¶ÈáèÊàñÊ®°ÂûãÁõ∏ÊØîÔºåËøô‰∏§ÁßçÊñπÊ≥ïÈÉΩËÉΩÊèêÈ´òÊÄßËÉΩ„ÄÇ

##### **Implementing a Nordic-Baltic Federated Health Data Network: a case report**
2409.17865v1 by Taridzo Chomutare, Aleksandar Babic, Laura-Maria Peltonen, Silja Elunurm, Peter Lundberg, Arne J√∂nsson, Emma Eneling, Ciprian-Virgil Gerstenberger, Troels Siggaard, Raivo Kolde, Oskar Jerdhaf, Martin Hansson, Alexandra Makhlysheva, Miroslav Muzny, Erik Ylip√§√§, S√∏ren Brunak, Hercules Dalianis

Background: Centralized collection and processing of healthcare data across
national borders pose significant challenges, including privacy concerns, data
heterogeneity and legal barriers. To address some of these challenges, we
formed an interdisciplinary consortium to develop a feder-ated health data
network, comprised of six institutions across five countries, to facilitate
Nordic-Baltic cooperation on secondary use of health data. The objective of
this report is to offer early insights into our experiences developing this
network. Methods: We used a mixed-method ap-proach, combining both experimental
design and implementation science to evaluate the factors affecting the
implementation of our network. Results: Technically, our experiments indicate
that the network functions without significant performance degradation compared
to centralized simu-lation. Conclusion: While use of interdisciplinary
approaches holds a potential to solve challeng-es associated with establishing
such collaborative networks, our findings turn the spotlight on the uncertain
regulatory landscape playing catch up and the significant operational costs.

ÊëòË¶ÅÔºöËÉåÊôØÔºöË∑®ÂúãÁïåÈõÜ‰∏≠Êî∂ÈõÜÂíåËôïÁêÜÈÜ´ÁôÇ‰øùÂÅ•Êï∏ÊìöÊúÉÂ∏∂‰æÜÈáçÂ§ßÊåëÊà∞ÔºåÂåÖÊã¨Èö±ÁßÅÂïèÈ°å„ÄÅÊï∏ÊìöÁï∞Ë≥™ÊÄßÂíåÊ≥ïÂæãÈöúÁ§ô„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÂÖ∂‰∏≠‰∏Ä‰∫õÊåëÊà∞ÔºåÊàëÂÄëÁµÑÊàê‰∫Ü‰∏ÄÂÄãË∑®Â≠∏ÁßëËÅØÁõüÔºåÈñãÁôº‰∏ÄÂÄãËÅØÈÇ¶ÂºèÂÅ•Â∫∑Êï∏ÊìöÁ∂≤Ë∑ØÔºåÁî±‰∫îÂÄãÂúãÂÆ∂ÁöÑÂÖ≠ÂÄãÊ©üÊßãÁµÑÊàêÔºå‰ª•‰øÉÈÄ≤ÂåóÊ≠êÂíåÊ≥¢ÁæÖÁöÑÊµ∑ÂúãÂÆ∂Âú®ÂÅ•Â∫∑Êï∏Êìö‰∫åÊ¨°Âà©Áî®ÊñπÈù¢ÁöÑÂêà‰Ωú„ÄÇÊú¨Â†±ÂëäÁöÑÁõÆÁöÑÊòØÊèê‰æõÊàëÂÄëÂú®ÈñãÁôºÊ≠§Á∂≤Ë∑ØÊñπÈù¢ÁöÑÊó©ÊúüË¶ãËß£„ÄÇÊñπÊ≥ïÔºöÊàëÂÄë‰ΩøÁî®Ê∑∑ÂêàÊñπÊ≥ïÔºåÁµêÂêàÂØ¶È©óË®≠Ë®àÂíåÂØ¶ÊñΩÁßëÂ≠∏‰æÜË©ï‰º∞ÂΩ±ÈüøÊàëÂÄëÁ∂≤Ë∑ØÂØ¶ÊñΩÁöÑÂõ†Á¥†„ÄÇÁµêÊûúÔºöÂú®ÊäÄË°ì‰∏äÔºåÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåËàáÈõÜ‰∏≠ÂºèÊ®°Êì¨Áõ∏ÊØîÔºåË©≤Á∂≤Ë∑ØÂú®Ê≤íÊúâÈ°ØËëóÊïàËÉΩ‰∏ãÈôçÁöÑÊÉÖÊ≥Å‰∏ãÈÅã‰Ωú„ÄÇÁµêË´ñÔºöÈõñÁÑ∂‰ΩøÁî®Ë∑®Â≠∏ÁßëÊñπÊ≥ïÊúâÂèØËÉΩËß£Ê±∫ËàáÂª∫Á´ãÊ≠§È°ûÂêà‰ΩúÁ∂≤Ë∑ØÁõ∏ÈóúÁöÑÊåëÊà∞Ôºå‰ΩÜÊàëÂÄëÁöÑÁôºÁèæÂ∞áÁÑ¶ÈªûËΩâÁßªÂà∞‰∏çÁ¢∫ÂÆöÁöÑÁõ£ÁÆ°Áí∞Â¢É‰∏≠Ôºå‰ª•ËøéÈ†≠Ë∂ï‰∏ä‰∏¶Èôç‰ΩéÈ°ØËëóÁöÑÁáüÈÅãÊàêÊú¨„ÄÇ

##### **DREAMS: A python framework to train deep learning models with model card reporting for medical and health applications**
2409.17815v1 by Rabindra Khadka, Pedro G Lind, Anis Yazidi, Asma Belhadi

Electroencephalography (EEG) data provides a non-invasive method for
researchers and clinicians to observe brain activity in real time. The
integration of deep learning techniques with EEG data has significantly
improved the ability to identify meaningful patterns, leading to valuable
insights for both clinical and research purposes. However, most of the
frameworks so far, designed for EEG data analysis, are either too focused on
pre-processing or in deep learning methods per, making their use for both
clinician and developer communities problematic. Moreover, critical issues such
as ethical considerations, biases, uncertainties, and the limitations inherent
in AI models for EEG data analysis are frequently overlooked, posing challenges
to the responsible implementation of these technologies. In this paper, we
introduce a comprehensive deep learning framework tailored for EEG data
processing, model training and report generation. While constructed in way to
be adapted and developed further by AI developers, it enables to report,
through model cards, the outcome and specific information of use for both
developers and clinicians. In this way, we discuss how this framework can, in
the future, provide clinical researchers and developers with the tools needed
to create transparent and accountable AI models for EEG data analysis and
diagnosis.

ÊëòË¶ÅÔºöËÖ¶ÈõªÂúñ (EEG) Êï∏ÊìöÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÈùû‰æµÂÖ•ÂºèÊñπÊ≥ïÔºåËÆìÁ†îÁ©∂‰∫∫Âì°ÂíåËá®Â∫äÈÜ´ÁîüÂèØ‰ª•Âç≥ÊôÇËßÄÂØüÂ§ßËÖ¶Ê¥ªÂãï„ÄÇÊ∑±Â∫¶Â≠∏ÁøíÊäÄË°ìËàáËÖ¶ÈõªÂúñÊï∏ÊìöÁöÑÊï¥ÂêàÔºåÈ°ØËëóÊèêÂçá‰∫ÜË≠òÂà•ÊúâÊÑèÁæ©Ê®°ÂºèÁöÑËÉΩÂäõÔºåÈÄ≤ËÄåÁî¢Áîü‰∫ÜÊúâÂÉπÂÄºÁöÑË¶ãËß£ÔºåÂèØÁî®ÊñºËá®Â∫äÂíåÁ†îÁ©∂ÁõÆÁöÑ„ÄÇÁÑ∂ËÄåÔºåÂà∞ÁõÆÂâçÁÇ∫Ê≠¢ÔºåÂ§ßÂ§öÊï∏Â∞àÈñÄË®≠Ë®àÁî®ÊñºËÖ¶ÈõªÂúñÊï∏ÊìöÂàÜÊûêÁöÑÊû∂ÊßãÔºåÈÉΩÈÅéÊñºÂ∞àÊ≥®ÊñºÈ†êËôïÁêÜÊàñÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÔºåÂ∞éËá¥Ëá®Â∫äÈÜ´ÁîüÂíåÈñãÁôº‰∫∫Âì°Á§æÁæ§Èõ£‰ª•‰ΩøÁî®„ÄÇÊ≠§Â§ñÔºåËÖ¶ÈõªÂúñÊï∏ÊìöÂàÜÊûê‰∏≠ÁöÑ‰∫∫Â∑•Êô∫ÊÖßÊ®°ÂûãÂõ∫ÊúâÁöÑÂÄ´ÁêÜËÄÉÈáè„ÄÅÂÅèË¶ã„ÄÅ‰∏çÁ¢∫ÂÆöÊÄßÂíåÈôêÂà∂Á≠âÈóúÈçµÂïèÈ°åÔºåÁ∂ìÂ∏∏Ë¢´ÂøΩÁï•ÔºåÂ∞çÈÄô‰∫õÊäÄË°ìÁöÑË≤†Ë≤¨‰ªªÂØ¶‰ΩúÊßãÊàê‰∫ÜÊåëÊà∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÂ∞àÁÇ∫ËÖ¶ÈõªÂúñÊï∏ÊìöËôïÁêÜ„ÄÅÊ®°ÂûãË®ìÁ∑¥ÂíåÂ†±ÂëäÁî¢ÁîüÁöÑÁ∂úÂêàÊÄßÊ∑±Â∫¶Â≠∏ÁøíÊû∂Êßã„ÄÇÈÄôÂÄãÊû∂ÊßãÁöÑÂª∫ÊßãÊñπÂºèÔºåËÆì‰∫∫Â∑•Êô∫ÊÖßÈñãÁôº‰∫∫Âì°ÂèØ‰ª•ÈÄ≤‰∏ÄÊ≠•Ë™øÊï¥ÂíåÈñãÁôºÔºå‰∏¶ËÉΩÈÄèÈÅéÊ®°ÂûãÂç°Â†±ÂëäÁµêÊûúÂíåÁâπÂÆöË≥áË®äÔºå‰æõÈñãÁôº‰∫∫Âì°ÂíåËá®Â∫äÈÜ´Áîü‰ΩøÁî®„ÄÇÈÄèÈÅéÈÄôÁ®ÆÊñπÂºèÔºåÊàëÂÄëÊé¢Ë®éÈÄôÂÄãÊû∂ÊßãÂú®Êú™‰æÜÂ¶Ç‰ΩïËÉΩÁÇ∫Ëá®Â∫äÁ†îÁ©∂‰∫∫Âì°ÂíåÈñãÁôº‰∫∫Âì°Êèê‰æõÂøÖË¶ÅÁöÑÂ∑•ÂÖ∑Ôºå‰ª•Âª∫Á´ãÈÄèÊòé‰∏îË≤†Ë≤¨‰ªªÁöÑ‰∫∫Â∑•Êô∫ÊÖßÊ®°ÂûãÔºåÁî®ÊñºËÖ¶ÈõªÂúñÊï∏ÊìöÂàÜÊûêÂíåË®∫Êñ∑„ÄÇ

##### **Ophthalmic Biomarker Detection with Parallel Prediction of Transformer and Convolutional Architecture**
2409.17788v1 by Md. Touhidul Islam, Md. Abtahi Majeed Chowdhury, Mahmudul Hasan, Asif Quadir, Lutfa Aktar

Ophthalmic diseases represent a significant global health issue,
necessitating the use of advanced precise diagnostic tools. Optical Coherence
Tomography (OCT) imagery which offers high-resolution cross-sectional images of
the retina has become a pivotal imaging modality in ophthalmology.
Traditionally physicians have manually detected various diseases and biomarkers
from such diagnostic imagery. In recent times, deep learning techniques have
been extensively used for medical diagnostic tasks enabling fast and precise
diagnosis. This paper presents a novel approach for ophthalmic biomarker
detection using an ensemble of Convolutional Neural Network (CNN) and Vision
Transformer. While CNNs are good for feature extraction within the local
context of the image, transformers are known for their ability to extract
features from the global context of the image. Using an ensemble of both
techniques allows us to harness the best of both worlds. Our method has been
implemented on the OLIVES dataset to detect 6 major biomarkers from the OCT
images and shows significant improvement of the macro averaged F1 score on the
dataset.

ÊëòË¶ÅÔºöÁúºÁßëÁñæÁóÖÊòØÂÖ®ÁêÉÈáçË¶ÅÁöÑÂÅ•Â∫∑ÂïèÈ°åÔºåÂõ†Ê≠§ÈúÄË¶Å‰ΩøÁî®ÂÖàÈÄ≤‰∏îÁ≤æÁ¢∫ÁöÑË®∫Êñ∑Â∑•ÂÖ∑„ÄÇÂÖâÂ≠∏Áõ∏Âπ≤Êñ∑Â±§ÊéÉÊèè (OCT) ÂΩ±ÂÉèÂèØÊèê‰æõË¶ñÁ∂≤ËÜúÁöÑÈ´òËß£ÊûêÂ∫¶Ê©´Êñ∑Èù¢ÂΩ±ÂÉèÔºåÂ∑≤ÊàêÁÇ∫ÁúºÁßë‰∏≠Ëá≥ÈóúÈáçË¶ÅÁöÑÂΩ±ÂÉèÊ®°Âºè„ÄÇÂÇ≥Áµ±‰∏äÔºåÈÜ´ÁîüÊúÉÊâãÂãïÂæûÊ≠§È°ûË®∫Êñ∑ÂΩ±ÂÉè‰∏≠ÂÅµÊ∏¨ÂêÑÁ®ÆÁñæÁóÖÂíåÁîüÁâ©Ê®ôË®ò„ÄÇÊúÄËøëÔºåÊ∑±Â∫¶Â≠∏ÁøíÊäÄË°ìÂ∑≤Âª£Ê≥õÁî®ÊñºÈÜ´ÁôÇË®∫Êñ∑‰ªªÂãôÔºåÂèØÈÄ≤Ë°åÂø´ÈÄü‰∏îÁ≤æÁ¢∫ÁöÑË®∫Êñ∑„ÄÇÊú¨ÊñáÊèêÂá∫‰ΩøÁî®Âç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) ÂíåË¶ñË¶∫TransformerÁµÑÂêàÁöÑ‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ï‰æÜÈÄ≤Ë°åÁúºÁßëÁîüÁâ©Ê®ôË®òÂÅµÊ∏¨„ÄÇÈõñÁÑ∂ CNN ÊìÖÈï∑ÂæûÂΩ±ÂÉèÁöÑÂ±ÄÈÉ®ËÑàÁµ°‰∏≠ËêÉÂèñÁâπÂæµÔºå‰ΩÜTransformerÂâá‰ª•ËÉΩÂæûÂΩ±ÂÉèÁöÑÂÖ®Â±ÄËÑàÁµ°‰∏≠ËêÉÂèñÁâπÂæµËÄåËÅûÂêç„ÄÇÁµêÂêàÈÄôÂÖ©Á®ÆÊäÄË°ìÔºåËÆìÊàëÂÄëËÉΩÂ§†ÂêåÊôÇÂà©Áî®ÂÖ©ËÄÖÁöÑÂÑ™Èªû„ÄÇÊàëÂÄëÁöÑÊäÄË°ìÂ∑≤Âú® OLIVES Ë≥áÊñôÈõÜ‰∏äÂØ¶‰ΩúÔºåÁî®ÊñºÂæû OCT ÂΩ±ÂÉè‰∏≠ÂÅµÊ∏¨ÂÖ≠ÂÄã‰∏ªË¶ÅÁöÑÁîüÁâ©Ê®ôË®òÔºå‰∏¶È°ØÁ§∫Ë≥áÊñôÈõÜ‰∏äÁöÑÂ∑®Âπ≥Âùá F1 ÂàÜÊï∏ÊúâÈ°ØËëóÁöÑÊèêÂçá„ÄÇ

##### **Confidence intervals uncovered: Are we ready for real-world medical imaging AI?**
2409.17763v2 by Evangelia Christodoulou, Annika Reinke, Rola Houhou, Piotr Kalinowski, Selen Erkan, Carole H. Sudre, Ninon Burgos, Sofi√®ne Boutaj, Sophie Loizillon, Ma√´lys Solal, Nicola Rieke, Veronika Cheplygina, Michela Antonelli, Leon D. Mayer, Minu D. Tizabi, M. Jorge Cardoso, Amber Simpson, Paul F. J√§ger, Annette Kopp-Schneider, Ga√´l Varoquaux, Olivier Colliot, Lena Maier-Hein

Medical imaging is spearheading the AI transformation of healthcare.
Performance reporting is key to determine which methods should be translated
into clinical practice. Frequently, broad conclusions are simply derived from
mean performance values. In this paper, we argue that this common practice is
often a misleading simplification as it ignores performance variability. Our
contribution is threefold. (1) Analyzing all MICCAI segmentation papers (n =
221) published in 2023, we first observe that more than 50% of papers do not
assess performance variability at all. Moreover, only one (0.5%) paper reported
confidence intervals (CIs) for model performance. (2) To address the reporting
bottleneck, we show that the unreported standard deviation (SD) in segmentation
papers can be approximated by a second-order polynomial function of the mean
Dice similarity coefficient (DSC). Based on external validation data from 56
previous MICCAI challenges, we demonstrate that this approximation can
accurately reconstruct the CI of a method using information provided in
publications. (3) Finally, we reconstructed 95% CIs around the mean DSC of
MICCAI 2023 segmentation papers. The median CI width was 0.03 which is three
times larger than the median performance gap between the first and second
ranked method. For more than 60% of papers, the mean performance of the
second-ranked method was within the CI of the first-ranked method. We conclude
that current publications typically do not provide sufficient evidence to
support which models could potentially be translated into clinical practice.

ÊëòË¶ÅÔºöÈÜ´ÁôÇÂΩ±ÂÉèÊ≠£Â∏∂È†òËëóÈÜ´ÁôÇ‰øùÂÅ•ÁöÑ‰∫∫Â∑•Êô∫ÊÖßËΩâÂûã„ÄÇ
ÊïàËÉΩÂ†±ÂëäÂ∞çÊñºÊ±∫ÂÆöÂì™‰∫õÊñπÊ≥ïÊáâËΩâÊèõÁÇ∫Ëá®Â∫äÂØ¶ÂãôËá≥ÈóúÈáçË¶Å„ÄÇÈÄöÂ∏∏ÔºåÂª£Ê≥õÁöÑÁµêË´ñÂÉÖ‰æÜËá™ÊñºÂπ≥ÂùáÊïàËÉΩÂÄº„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰∏ªÂºµÈÄôÁ®ÆÂ∏∏Ë¶ãÂÅöÊ≥ïÈÄöÂ∏∏ÊòØ‰∏ÄÁ®ÆË™§Â∞éÊÄßÁöÑÁ∞°ÂåñÔºåÂõ†ÁÇ∫ÂÆÉÂøΩÁï•‰∫ÜÊïàËÉΩËÆäÁï∞ÊÄß„ÄÇÊàëÂÄëÁöÑË≤¢ÁçªÊúâ‰∏âÊñπÈù¢Ôºö(1) ÂàÜÊûê 2023 Âπ¥ÁôºË°®ÁöÑ 221 ÁØá MICCAI ÂàÜÂâ≤Ë´ñÊñáÔºåÊàëÂÄëÈ¶ñÂÖàËßÄÂØüÂà∞Ë∂ÖÈÅé 50% ÁöÑË´ñÊñáÊ†πÊú¨Ê≤íÊúâË©ï‰º∞ÊïàËÉΩËÆäÁï∞ÊÄß„ÄÇÊ≠§Â§ñÔºåÂè™Êúâ‰∏ÄÁØá (0.5%) Ë´ñÊñáÂ†±Âëä‰∫ÜÊ®°ÂûãÊïàËÉΩÁöÑ‰ø°ÂøÉÂçÄÈñì (CI)„ÄÇ(2) ÁÇ∫‰∫ÜËß£Ê±∫Â†±ÂëäÁì∂È†∏ÔºåÊàëÂÄëË°®ÊòéÂàÜÂâ≤Ë´ñÊñá‰∏≠Êú™Â†±ÂëäÁöÑÊ®ôÊ∫ñÂ∑Æ (SD) ÂèØ‰ª•Ëøë‰ººÁÇ∫Âπ≥Âùá Dice Áõ∏‰ººÊÄß‰øÇÊï∏ (DSC) ÁöÑ‰∫åÈöéÂ§öÈ†ÖÂºèÂáΩÊï∏„ÄÇÊ†πÊìö‰æÜËá™ 56 È†ÖÂÖàÂâç MICCAI ÊåëÊà∞ÁöÑÂ§ñÈÉ®È©óË≠âË≥áÊñôÔºåÊàëÂÄëË≠âÊòéÊ≠§Ëøë‰ººÂÄºÂèØ‰ª•‰ΩøÁî®Ë´ñÊñá‰∏≠Êèê‰æõÁöÑË≥áË®äÊ∫ñÁ¢∫ÈáçÂª∫ÊñπÊ≥ïÁöÑ CI„ÄÇ(3) ÊúÄÂæåÔºåÊàëÂÄëÈáçÂª∫‰∫Ü MICCAI 2023 ÂàÜÂâ≤Ë´ñÊñáÂπ≥Âùá DSC Âë®ÂúçÁöÑ 95% CI„ÄÇ‰∏≠‰ΩçÊï∏ CI ÂØ¨Â∫¶ÁÇ∫ 0.03ÔºåÊòØÁ¨¨‰∏ÄÂêçÂíåÁ¨¨‰∫åÂêçÊñπÊ≥ï‰πãÈñìÁöÑ‰∏≠‰ΩçÊï∏ÊïàËÉΩÂ∑ÆË∑ùÁöÑ‰∏âÂÄç„ÄÇÂ∞çÊñºË∂ÖÈÅé 60% ÁöÑË´ñÊñáÔºåÊéíÂêçÁ¨¨‰∫åÁöÑÊñπÊ≥ïÁöÑÂπ≥ÂùáÊïàËÉΩÈÉΩÂú®ÊéíÂêçÁ¨¨‰∏ÄÁöÑÊñπÊ≥ïÁöÑ CI ÂÖß„ÄÇÊàëÂÄëÂæóÂá∫ÁµêË´ñÔºåÁõÆÂâçÁöÑË´ñÊñáÈÄöÂ∏∏ÁÑ°Ê≥ïÊèê‰æõË∂≥Â§†ÁöÑË≠âÊìö‰æÜÊîØÊåÅÂì™‰∫õÊ®°ÂûãÊúâÂèØËÉΩËΩâÊèõÁÇ∫Ëá®Â∫äÂØ¶Âãô„ÄÇ

##### **Artificial Data Point Generation in Clustered Latent Space for Small Medical Datasets**
2409.17685v1 by Yasaman Haghbin, Hadi Moradi, Reshad Hosseini

One of the growing trends in machine learning is the use of data generation
techniques, since the performance of machine learning models is dependent on
the quantity of the training dataset. However, in many medical applications,
collecting large datasets is challenging due to resource constraints, which
leads to overfitting and poor generalization. This paper introduces a novel
method, Artificial Data Point Generation in Clustered Latent Space (AGCL),
designed to enhance classification performance on small medical datasets
through synthetic data generation. The AGCL framework involves feature
extraction, K-means clustering, cluster evaluation based on a class separation
metric, and the generation of synthetic data points from clusters with distinct
class representations. This method was applied to Parkinson's disease
screening, utilizing facial expression data, and evaluated across multiple
machine learning classifiers. Experimental results demonstrate that AGCL
significantly improves classification accuracy compared to baseline, GN and
kNNMTD. AGCL achieved the highest overall test accuracy of 83.33% and
cross-validation accuracy of 90.90% in majority voting over different emotions,
confirming its effectiveness in augmenting small datasets.

ÊëòË¶ÅÔºöÊ©üÂô®Â≠∏Áøí‰∏≠Êó•ÁõäÂ¢ûÈï∑ÁöÑË∂®Âã¢‰πã‰∏ÄÊòØ‰ΩøÁî®Ë≥áÊñôÁî¢ÁîüÊäÄË°ìÔºåÂõ†ÁÇ∫Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÁöÑÊïàËÉΩÂèñÊ±∫ÊñºË®ìÁ∑¥Ë≥áÊñôÈõÜÁöÑÊï∏Èáè„ÄÇÁÑ∂ËÄåÔºåÂú®Ë®±Â§öÈÜ´Â≠∏ÊáâÁî®‰∏≠ÔºåÁî±ÊñºË≥áÊ∫êÈôêÂà∂ÔºåÊî∂ÈõÜÂ§ßÂûãË≥áÊñôÈõÜÂÖ∑ÊúâÊåëÊà∞ÊÄßÔºåÈÄôÊúÉÂ∞éËá¥ÈÅéÂ∫¶Êì¨ÂêàÂíå‰∏çËâØÁöÑÊ≥õÂåñ„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÊñ∞ÊñπÊ≥ïÔºåÂç≥Âè¢ÈõÜÊΩõÂú®Á©∫Èñì‰∏≠ÁöÑ‰∫∫Â∑•Ë≥áÊñôÈªûÁî¢ÁîüÔºàAGCLÔºâÔºåÊó®Âú®ÈÄèÈÅéÂêàÊàêË≥áÊñôÁî¢Áîü‰æÜÂ¢ûÂº∑Â∞èÂûãÈÜ´Â≠∏Ë≥áÊñôÈõÜ‰∏äÁöÑÂàÜÈ°ûÊïàËÉΩ„ÄÇAGCL Ê°ÜÊû∂Ê∂âÂèäÁâπÂæµËêÉÂèñ„ÄÅK Âπ≥ÂùáÂè¢ÈõÜ„ÄÅÂü∫ÊñºÈ°ûÂà•ÂàÜÈõ¢Â∫¶ÈáèÊ®ôÊ∫ñÁöÑÂè¢ÈõÜË©ï‰º∞Ôºå‰ª•ÂèäÂæûÂÖ∑Êúâ‰∏çÂêåÈ°ûÂà•Ë°®Á§∫ÁöÑÂè¢ÈõÜ‰∏≠Áî¢ÁîüÂêàÊàêË≥áÊñôÈªû„ÄÇÊ≠§ÊñπÊ≥ïÊáâÁî®ÊñºÂ∏ïÈáëÊ£ÆÊ∞èÁóáÁØ©Ê™¢ÔºåÂà©Áî®Èù¢ÈÉ®Ë°®ÊÉÖË≥áÊñôÔºå‰∏¶Âú®Â§öÂÄãÊ©üÂô®Â≠∏ÁøíÂàÜÈ°ûÂô®‰∏≠ÈÄ≤Ë°åË©ï‰º∞„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåËàáÂü∫Á∑ö„ÄÅGN Âíå kNNMTD Áõ∏ÊØîÔºåAGCL Â§ßÂπÖÊèêÂçá‰∫ÜÂàÜÈ°ûÊ∫ñÁ¢∫Â∫¶„ÄÇÂú®Â∞ç‰∏çÂêåÊÉÖÁ∑íÈÄ≤Ë°åÂ§öÊï∏Ê±∫ÊäïÁ•®ÊôÇÔºåAGCL ÈÅîÂà∞‰∫ÜÊúÄÈ´òÁöÑÊï¥È´îÊ∏¨Ë©¶Ê∫ñÁ¢∫Â∫¶ 83.33% Âíå‰∫§ÂèâÈ©óË≠âÊ∫ñÁ¢∫Â∫¶ 90.90%ÔºåË≠âÂØ¶‰∫ÜÂÖ∂Âú®Êì¥ÂÖÖÂ∞èÂûãË≥áÊñôÈõÜÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

##### **Zero- and Few-shot Named Entity Recognition and Text Expansion in Medication Prescriptions using ChatGPT**
2409.17683v1 by Natthanaphop Isaradech, Andrea Riedel, Wachiranun Sirikul, Markus Kreuzthaler, Stefan Schulz

Introduction: Medication prescriptions are often in free text and include a
mix of two languages, local brand names, and a wide range of idiosyncratic
formats and abbreviations. Large language models (LLMs) have shown promising
ability to generate text in response to input prompts. We use ChatGPT 3.5 to
automatically structure and expand medication statements in discharge summaries
and thus make them easier to interpret for people and machines. Methods:
Named-entity Recognition (NER) and Text Expansion (EX) are used in a zero- and
few-shot setting with different prompt strategies. 100 medication statements
were manually annotated and curated. NER performance was measured by using
strict and partial matching. For the task EX, two experts interpreted the
results by assessing semantic equivalence between original and expanded
statements. The model performance was measured by precision, recall, and F1
score. Results: For NER, the best-performing prompt reached an average F1 score
of 0.94 in the test set. For EX, the few-shot prompt showed superior
performance among other prompts, with an average F1 score of 0.87. Conclusion:
Our study demonstrates good performance for NER and EX tasks in free-text
medication statements using ChatGPT. Compared to a zero-shot baseline, a
few-shot approach prevented the system from hallucinating, which would be
unacceptable when processing safety-relevant medication data.

ÊëòË¶ÅÔºö**ÂºïË®ÄÔºö**Ëó•Áâ©ËôïÊñπÈÄöÂ∏∏‰ª•Ëá™Áî±ÊñáÊú¨ÂΩ¢ÂºèÂëàÁèæÔºå‰∏¶ÂåÖÂê´ÂÖ©Á®ÆË™ûË®Ä„ÄÅÁï∂Âú∞ÂìÅÁâåÂêçÁ®±Ôºå‰ª•ÂèäÂêÑÁ®ÆÊÖ£Áî®Ê†ºÂºèÂíåÁ∏ÆÂØ´„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Â±ïÁèæÂá∫Ê•µ‰Ω≥ÁöÑÊñáÊú¨ÁîüÊàêËÉΩÂäõÔºåËÉΩÂõûÊáâËº∏ÂÖ•ÊèêÁ§∫„ÄÇÊàëÂÄë‰ΩøÁî® ChatGPT 3.5 Ëá™ÂãïÂª∫ÊßãÂíåÊì¥ÂÖÖÂá∫Èô¢ÊëòË¶Å‰∏≠ÁöÑËó•Áâ©Èô≥Ëø∞ÔºåËÆì‰∫∫È°ûÂíåÊ©üÂô®Êõ¥ÂÆπÊòìËß£ËÆÄ„ÄÇ**ÊñπÊ≥ïÔºö**ÂëΩÂêçÂØ¶È´îËæ®Ë≠ò (NER) ÂíåÊñáÂ≠óÊì¥ÂÖÖ (EX) Áî®ÊñºÈõ∂Ê¨°ÂíåÂ∞ëÈáèÊèêÁ§∫Á≠ñÁï•ÁöÑË®≠ÂÆö„ÄÇ100 ÂÄãËó•Áâ©Èô≥Ëø∞Á∂ìÈÅé‰∫∫Â∑•Ë®ªËß£ÂíåÊï¥ÁêÜ„ÄÇNER ÁöÑÊïàËÉΩÈÄèÈÅéÂö¥Ê†ºÂíåÈÉ®ÂàÜÊØîÂ∞çÈÄ≤Ë°åË°°Èáè„ÄÇÂ∞çÊñº EX ‰ªªÂãôÔºåÂÖ©‰ΩçÂ∞àÂÆ∂ÈÄèÈÅéË©ï‰º∞ÂéüÂßãÈô≥Ëø∞ÂíåÊì¥ÂÖÖÈô≥Ëø∞‰πãÈñìÁöÑË™ûÁæ©Á≠âÊïàÊÄß‰æÜËß£ËÆÄÁµêÊûú„ÄÇÊ®°ÂûãÊïàËÉΩÈÄèÈÅéÁ≤æÁ¢∫Â∫¶„ÄÅÂè¨ÂõûÁéáÂíå F1 ÂàÜÊï∏ÈÄ≤Ë°åË°°Èáè„ÄÇ**ÁµêÊûúÔºö**Â∞çÊñº NERÔºåÊïàËÉΩÊúÄ‰Ω≥ÁöÑÊèêÁ§∫Âú®Ê∏¨Ë©¶ÈõÜ‰∏≠ÈÅîÂà∞Âπ≥Âùá F1 ÂàÜÊï∏ 0.94„ÄÇÂ∞çÊñº EXÔºåÂ∞ëÈáèÊèêÁ§∫Âú®ÂÖ∂‰ªñÊèêÁ§∫‰∏≠Â±ïÁèæÂá∫ÂÑ™Áï∞ÊïàËÉΩÔºåÂπ≥Âùá F1 ÂàÜÊï∏ÁÇ∫ 0.87„ÄÇ**ÁµêË´ñÔºö**ÊàëÂÄëÁöÑÁ†îÁ©∂Ë≠âÊòéÔºå‰ΩøÁî® ChatGPT ËôïÁêÜËá™Áî±ÊñáÊú¨Ëó•Áâ©Èô≥Ëø∞‰∏≠ÁöÑ NER Âíå EX ‰ªªÂãôÂÖ∑ÊúâËâØÂ•ΩÁöÑÊïàËÉΩ„ÄÇËàáÈõ∂Ê¨°Âü∫Ê∫ñÁõ∏ÊØîÔºåÂ∞ëÈáèÊèêÁ§∫ÊñπÊ≥ïÂèØÈò≤Ê≠¢Á≥ªÁµ±Áî¢ÁîüÂπªË¶∫ÔºåÈÄôÂú®ËôïÁêÜËàáÂÆâÂÖ®ÊÄßÁõ∏ÈóúÁöÑËó•Áâ©Ë≥áÊñôÊôÇÊòØ‰∏çÂèØÊé•ÂèóÁöÑ„ÄÇ

##### **Digital Twin Ecosystem for Oncology Clinical Operations**
2409.17650v1 by Himanshu Pandey, Akhil Amod, Shivang, Kshitij Jaggi, Ruchi Garg, Abheet Jain, Vinayak Tantia

Artificial Intelligence (AI) and Large Language Models (LLMs) hold
significant promise in revolutionizing healthcare, especially in clinical
applications. Simultaneously, Digital Twin technology, which models and
simulates complex systems, has gained traction in enhancing patient care.
However, despite the advances in experimental clinical settings, the potential
of AI and digital twins to streamline clinical operations remains largely
untapped. This paper introduces a novel digital twin framework specifically
designed to enhance oncology clinical operations. We propose the integration of
multiple specialized digital twins, such as the Medical Necessity Twin, Care
Navigator Twin, and Clinical History Twin, to enhance workflow efficiency and
personalize care for each patient based on their unique data. Furthermore, by
synthesizing multiple data sources and aligning them with the National
Comprehensive Cancer Network (NCCN) guidelines, we create a dynamic Cancer Care
Path, a continuously evolving knowledge base that enables these digital twins
to provide precise, tailored clinical recommendations.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) ÂíåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÈÜ´ÁôÇ‰øùÂÅ•È†òÂüü‰∏≠ÔºåÁâπÂà•ÊòØÂú®Ëá®Â∫äÊáâÁî®‰∏≠ÔºåÂÖ∑ÊúâÈ°ØËëóÁöÑËÆäÈù©ÂâçÊôØ„ÄÇÂêåÊôÇÔºåÁî®ÊñºÊ®°Êì¨ÂíåÂª∫Ê®°Ë§áÈõúÁ≥ªÁµ±ÁöÑÊï∏‰ΩçÂ≠øÁîüÊäÄË°ìÔºåÂú®Â¢ûÂº∑ÊÇ£ËÄÖÁÖßË≠∑ÊñπÈù¢‰πüÁç≤Âæó‰∫ÜÈóúÊ≥®„ÄÇÁÑ∂ËÄåÔºåÂÑòÁÆ°Âú®ÂØ¶È©óÊÄßËá®Â∫äÁí∞Â¢É‰∏≠ÂèñÂæóÈÄ≤Â±ïÔºåAI ÂíåÊï∏‰ΩçÂ≠øÁîüÂú®Á∞°ÂåñËá®Â∫äÈÅã‰ΩúÊñπÈù¢ÁöÑÊΩõÂäõ‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÁôºÊèÆ„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÂ∞àÈñÄË®≠Ë®àÁî®ÊñºÂ¢ûÂº∑ËÖ´Áò§Â≠∏Ëá®Â∫äÈÅã‰ΩúÁöÑÊñ∞ÂûãÊï∏‰ΩçÂ≠øÁîüÊû∂Êßã„ÄÇÊàëÂÄëÂª∫Ë≠∞Êï¥ÂêàÂ§öÂÄãÂ∞àÊ•≠Êï∏‰ΩçÂ≠øÁîüÔºå‰æãÂ¶ÇÈÜ´ÁôÇÂøÖË¶ÅÊÄßÂ≠øÁîü„ÄÅÁÖßË≠∑È†òËà™Âì°Â≠øÁîüÂíåËá®Â∫äÁóÖÂè≤Â≠øÁîüÔºå‰ª•ÊèêÈ´òÂ∑•‰ΩúÊµÅÁ®ãÊïàÁéáÔºå‰∏¶Ê†πÊìöÊØèÂÄãÊÇ£ËÄÖÁöÑÁç®ÁâπË≥áÊñôÁÇ∫ÂÖ∂Êèê‰æõÂÄã‰∫∫ÂåñÁÖßË≠∑„ÄÇÊ≠§Â§ñÔºåÈÄèÈÅéÁ∂úÂêàÂ§öÂÄãË≥áÊñô‰æÜÊ∫ê‰∏¶Â∞áÂÖ∂ËàáÂúãÂÆ∂Á∂úÂêàÁôåÁóáÁ∂≤Ë∑Ø (NCCN) ÊåáÂçóÁõ∏Á¨¶ÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÂãïÊÖãÁôåÁóáÁÖßË≠∑Ë∑ØÂæëÔºå‰∏ÄÂÄãÊåÅÁ∫åÁôºÂ±ïÁöÑÁü•Ë≠òÂ∫´Ôºå‰ΩøÈÄô‰∫õÊï∏‰ΩçÂ≠øÁîüËÉΩÂ§†Êèê‰æõÁ≤æÁ¢∫‰∏îÂÆ¢Ë£ΩÂåñÁöÑËá®Â∫äÂª∫Ë≠∞„ÄÇ

##### **A Scalable Data-Driven Framework for Systematic Analysis of SEC 10-K Filings Using Large Language Models**
2409.17581v1 by Syed Affan Daimi, Asma Iqbal

The number of companies listed on the NYSE has been growing exponentially,
creating a significant challenge for market analysts, traders, and stockholders
who must monitor and assess the performance and strategic shifts of a large
number of companies regularly. There is an increasing need for a fast,
cost-effective, and comprehensive method to evaluate the performance and detect
and compare many companies' strategy changes efficiently. We propose a novel
data-driven approach that leverages large language models (LLMs) to
systematically analyze and rate the performance of companies based on their SEC
10-K filings. These filings, which provide detailed annual reports on a
company's financial performance and strategic direction, serve as a rich source
of data for evaluating various aspects of corporate health, including
confidence, environmental sustainability, innovation, and workforce management.
We also introduce an automated system for extracting and preprocessing 10-K
filings. This system accurately identifies and segments the required sections
as outlined by the SEC, while also isolating key textual content that contains
critical information about the company. This curated data is then fed into
Cohere's Command-R+ LLM to generate quantitative ratings across various
performance metrics. These ratings are subsequently processed and visualized to
provide actionable insights. The proposed scheme is then implemented on an
interactive GUI as a no-code solution for running the data pipeline and
creating the visualizations. The application showcases the rating results and
provides year-on-year comparisons of company performance.

ÊëòË¶ÅÔºöÁ¥êÁ¥ÑË≠âÂà∏‰∫§ÊòìÊâÄ‰∏äÂ∏ÇÁöÑÂÖ¨Âè∏Êï∏ÈáèÂëàÊåáÊï∏ÊàêÈï∑ÔºåÂ∞çÂøÖÈ†àÂÆöÊúüÁõ£ÊéßÂíåË©ï‰º∞Â§ßÈáèÂÖ¨Âè∏Á∏æÊïàÂíåÁ≠ñÁï•ËΩâËÆäÁöÑÂ∏ÇÂ†¥ÂàÜÊûêÂ∏´„ÄÅ‰∫§ÊòìÂì°ÂíåËÇ°Êù±‰æÜË™™ÔºåÈÄôÊòØ‰∏ÄÂÄãÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇÂ∞çÊñº‰∏ÄÁ®ÆÂø´ÈÄü„ÄÅÂÖ∑ÊàêÊú¨ÊïàÁõä‰∏îÂÖ®Èù¢ÁöÑÊñπÊ≥ïÔºåÊúâË∂ä‰æÜË∂äÈ´òÁöÑÈúÄÊ±ÇÔºå‰ª•Ë©ï‰º∞Á∏æÊïà‰∏¶ÊúâÊïàÂú∞ÂÅµÊ∏¨ÂíåÊØîËºÉË®±Â§öÂÖ¨Âè∏ÁöÑÁ≠ñÁï•ËÆäÂåñ„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑË≥áÊñôÈ©ÖÂãïÊñπÊ≥ïÔºåÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜÁ≥ªÁµ±ÊÄßÂú∞ÂàÜÊûêÂíåË©ïÊØîÂÖ¨Âè∏ÁöÑÁ∏æÊïàÔºåÂÖ∂Âü∫Á§éÊòØÂÖ¨Âè∏ÁöÑÁæéÂúãË≠âÂà∏‰∫§ÊòìÂßîÂì°ÊúÉ (SEC) 10-K Ê™î„ÄÇÈÄô‰∫õÁî≥Â†±Êèê‰æõÂÖ¨Âè∏Ë≤°ÂãôÁ∏æÊïàÂíåÁ≠ñÁï•ÊñπÂêëÁöÑË©≥Á¥∞Âπ¥Â∫¶Â†±ÂëäÔºå‰ΩúÁÇ∫Ë©ï‰º∞ÂÖ¨Âè∏ÂÅ•ÂÖ®Á®ãÂ∫¶ÂêÑÂÄãÈù¢ÂêëÁöÑË±êÂØåË≥áÊñô‰æÜÊ∫êÔºåÂåÖÊã¨‰ø°ÂøÉ„ÄÅÁí∞Â¢ÉÊ∞∏Á∫åÊÄß„ÄÅÂâµÊñ∞ÂíåÂì°Â∑•ÁÆ°ÁêÜ„ÄÇÊàëÂÄë‰πüÂ∞éÂÖ•‰∏ÄÂÄãËá™ÂãïÂåñÁ≥ªÁµ±ÔºåÁî®ÊñºÊì∑ÂèñÂíåÈ†êËôïÁêÜ 10-K Áî≥Â†±„ÄÇÊ≠§Á≥ªÁµ±Á≤æÁ¢∫Âú∞Ë≠òÂà•ÂíåÂçÄÈöîÁæéÂúãË≠âÂà∏‰∫§ÊòìÂßîÂì°ÊúÉÊâÄÊ¶ÇËø∞ÁöÑÂøÖË¶ÅÈÉ®ÂàÜÔºåÂêåÊôÇ‰πüÂ≠§Á´ãÂåÖÂê´ÂÖ¨Âè∏ÈóúÈçµË≥áË®äÁöÑÊñáÂ≠óÂÖßÂÆπ„ÄÇÊé•ËëóÂ∞áÈÄô‰∫õÊï¥ÁêÜÈÅéÁöÑË≥áÊñôËº∏ÂÖ• Cohere ÁöÑ Command-R+ LLMÔºå‰ª•Áî¢ÁîüÂêÑÁ®ÆÁ∏æÊïàÊåáÊ®ôÁöÑÈáèÂåñË©ïÂàÜ„ÄÇÊé•ËëóËôïÁêÜÂíåË¶ñË¶∫ÂåñÈÄô‰∫õË©ïÂàÜÔºå‰ª•Êèê‰æõÂèØË°åÁöÑË¶ãËß£„ÄÇÁÑ∂ÂæåÂú®‰∫íÂãïÂºè GUI ‰∏äÂØ¶‰ΩúÂª∫Ë≠∞ÁöÑÊû∂ÊßãÔºå‰ΩúÁÇ∫Âü∑Ë°åË≥áÊñôÁÆ°Á∑öÂíåÂª∫Á´ãË¶ñË¶∫ÂåñÁöÑÁÑ°Á®ãÂºèÁ¢ºËß£Ê±∫ÊñπÊ°à„ÄÇÊ≠§ÊáâÁî®Á®ãÂºèÂ±ïÁ§∫Ë©ïÂàÜÁµêÊûúÔºå‰∏¶Êèê‰æõÂÖ¨Âè∏Á∏æÊïàÁöÑÂπ¥Â∞çÂπ¥ÊØîËºÉ„ÄÇ

##### **Dr. GPT in Campus Counseling: Understanding Higher Education Students' Opinions on LLM-assisted Mental Health Services**
2409.17572v1 by Owen Xingjian Zhang, Shuyao Zhou, Jiayi Geng, Yuhan Liu, Sunny Xun Liu

In response to the increasing mental health challenges faced by college
students, we sought to understand their perspectives on how AI applications,
particularly Large Language Models (LLMs), can be leveraged to enhance their
mental well-being. Through pilot interviews with ten diverse students, we
explored their opinions on the use of LLMs across five fictional scenarios:
General Information Inquiry, Initial Screening, Reshaping Patient-Expert
Dynamics, Long-term Care, and Follow-up Care. Our findings revealed that
students' acceptance of LLMs varied by scenario, with participants highlighting
both potential benefits, such as proactive engagement and personalized
follow-up care, and concerns, including limitations in training data and
emotional support. These insights inform how AI technology should be designed
and implemented to effectively support and enhance students' mental well-being,
particularly in scenarios where LLMs can complement traditional methods, while
maintaining empathy and respecting individual preferences.

ÊëòË¶ÅÔºöÁÇ∫‰∫ÜÂõûÊáâÂ§ßÂ≠∏ÁîüÈù¢Ëá®Êó•ÁõäÂ¢ûÂä†ÁöÑÂøÉÁêÜÂÅ•Â∫∑ÊåëÊà∞ÔºåÊàëÂÄëË©¶Âúñ‰∫ÜËß£‰ªñÂÄëÂ∞ç AI ÊáâÁî®Á®ãÂºèÁöÑËßÄÈªûÔºåÁâπÂà•ÊòØÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â¶Ç‰ΩïËÉΩÊèêÂçá‰ªñÂÄëÁöÑÂøÉÁêÜÂÅ•Â∫∑„ÄÇÈÄèÈÅéÂ∞çÂçÅ‰Ωç‰∏çÂêåÂ≠∏ÁîüÁöÑË©¶ÈªûË®™Ë´áÔºåÊàëÂÄëÊé¢Ë®é‰∫Ü‰ªñÂÄëÂ∞ç LLM Âú®‰∫îÂÄãËôõÊßãÊÉÖÂ¢É‰∏≠ÁöÑ‰ΩøÁî®ÊÑèË¶ãÔºö‰∏ÄËà¨Ë≥áË®äË©¢Âïè„ÄÅÂàùÊ≠•ÁØ©ÈÅ∏„ÄÅÈáçÂ°ëÊÇ£ËÄÖËàáÂ∞àÂÆ∂ÁöÑ‰∫íÂãïÊ®°Âºè„ÄÅÈï∑ÊúüÁÖßË≠∑ÂíåÂæåÁ∫åÁÖßË≠∑„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåÂ≠∏ÁîüÂ∞ç LLM ÁöÑÊé•ÂèóÂ∫¶Âõ†ÊÉÖÂ¢ÉËÄåÁï∞ÔºåÂèÉËàáËÄÖÂº∑Ë™ø‰∫ÜÊΩõÂú®ÁöÑÂ•ΩËôïÔºå‰æãÂ¶Ç‰∏ªÂãïÂèÉËàáÂíåÂÄã‰∫∫ÂåñÁöÑÂæåÁ∫åÁÖßË≠∑Ôºå‰ª•ÂèäÁñëÊÖÆÔºåÂåÖÊã¨Ë®ìÁ∑¥Ë≥áÊñôÂíåÊÉÖÁ∑íÊîØÊåÅÁöÑÈôêÂà∂„ÄÇÈÄô‰∫õË¶ãËß£Ë™™Êòé‰∫Ü AI ÊäÄË°ìÊáâÂ¶Ç‰ΩïË®≠Ë®àÂíåÂØ¶ÊñΩÔºå‰ª•ÊúâÊïàÊîØÊè¥ÂíåÊèêÂçáÂ≠∏ÁîüÁöÑÂøÉÁêÜÂÅ•Â∫∑ÔºåÁâπÂà•ÊòØÂú® LLM ËÉΩË£úÂÖÖÂÇ≥Áµ±ÊñπÊ≥ïÁöÑÊÉÖÂ¢É‰∏≠ÔºåÂêåÊôÇ‰øùÊåÅÂêåÁêÜÂøÉ‰∏¶Â∞äÈáçÂÄã‰∫∫ÂÅèÂ•Ω„ÄÇ

##### **Uni-Med: A Unified Medical Generalist Foundation Model For Multi-Task Learning Via Connector-MoE**
2409.17508v1 by Xun Zhu, Ying Hu, Fanbin Mo, Miao Li, Ji Wu

Multi-modal large language models (MLLMs) have shown impressive capabilities
as a general-purpose interface for various visual and linguistic tasks.
However, building a unified MLLM for multi-task learning in the medical field
remains a thorny challenge. To mitigate the tug-of-war problem of multi-modal
multi-task optimization, recent advances primarily focus on improving the LLM
components, while neglecting the connector that bridges the gap between
modalities. In this paper, we introduce Uni-Med, a novel medical generalist
foundation model which consists of a universal visual feature extraction
module, a connector mixture-of-experts (CMoE) module, and an LLM. Benefiting
from the proposed CMoE that leverages a well-designed router with a mixture of
projection experts at the connector, Uni-Med achieves efficient solution to the
tug-of-war problem and can perform six different medical tasks including
question answering, visual question answering, report generation, referring
expression comprehension, referring expression generation and image
classification. To the best of our knowledge, Uni-Med is the first effort to
tackle multi-task interference at the connector. Extensive ablation experiments
validate the effectiveness of introducing CMoE under any configuration, with up
to an average 8% performance gains. We further provide interpretation analysis
of the tug-of-war problem from the perspective of gradient optimization and
parameter statistics. Compared to previous state-of-the-art medical MLLMs,
Uni-Med achieves competitive or superior evaluation metrics on diverse tasks.
Code, data and model will be soon available at GitHub.

ÊëòË¶ÅÔºö<paragraph>Â§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) Â∑≤Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑËÉΩÂäõÔºåÂèØ‰ΩúÁÇ∫ÂêÑÁ®ÆË¶ñË¶∫ÂíåË™ûË®Ä‰ªªÂãôÁöÑÈÄöÁî®‰ªãÈù¢„ÄÇÁÑ∂ËÄåÔºåÂª∫Á´ã‰∏ÄÂÄãÁµ±‰∏ÄÁöÑ MLLM ‰æÜÈÄ≤Ë°åÈÜ´Â≠∏È†òÂüüÁöÑÂ§ö‰ªªÂãôÂ≠∏Áøí‰ªçÁÑ∂ÊòØ‰∏ÄÂÄãÊ£òÊâãÁöÑÊåëÊà∞„ÄÇÁÇ∫‰∫ÜÊ∏õËºïÂ§öÊ®°ÊÖãÂ§ö‰ªªÂãôÊúÄ‰Ω≥ÂåñÁöÑÊãâÈã∏Êà∞ÂïèÈ°åÔºåÊúÄËøëÁöÑÈÄ≤Â±ï‰∏ªË¶ÅÈõÜ‰∏≠Âú®ÊîπÈÄ≤ LLM ÁµÑ‰ª∂ÔºåÂêåÊôÇÂøΩÁï•‰∫ÜÊ©ãÊé•‰∏çÂêåÊ®°ÊÖã‰πãÈñìÂ∑ÆË∑ùÁöÑÈÄ£Êé•Âô®„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü Uni-MedÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞Á©éÁöÑÈÜ´Â≠∏ÈÄöÊâçÂü∫Á§éÊ®°ÂûãÔºåÂÆÉÂåÖÂê´‰∏ÄÂÄãÈÄöÁî®Ë¶ñË¶∫ÁâπÂæµÊèêÂèñÊ®°ÁµÑ„ÄÅ‰∏ÄÂÄãÈÄ£Êé•Âô®Ê∑∑ÂêàÂ∞àÂÆ∂ (CMoE) Ê®°ÁµÑÂíå‰∏ÄÂÄã LLM„ÄÇÂèóÁõäÊñºÊèêË≠∞ÁöÑ CMoEÔºåÂÆÉÂà©Áî®‰∫Ü‰∏ÄÂÄãÁ∂ìÈÅéÁ≤æÂøÉË®≠Ë®àÁöÑË∑ØÁî±Âô®ÔºåÂÖ∂‰∏≠ÂåÖÂê´ÈÄ£Êé•Âô®‰∏äÁöÑÊ∑∑ÂêàÊäïÂΩ±Â∞àÂÆ∂ÔºåUni-Med Â∞çÊãâÈã∏Êà∞ÂïèÈ°åÂØ¶Áèæ‰∫ÜÈ´òÊïàÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰∏¶‰∏îÂèØ‰ª•Âü∑Ë°åÂÖ≠È†Ö‰∏çÂêåÁöÑÈÜ´ÁôÇ‰ªªÂãôÔºåÂåÖÊã¨ÂïèÁ≠î„ÄÅË¶ñË¶∫ÂïèÁ≠î„ÄÅÂ†±ÂëäÁîüÊàê„ÄÅÊåáÁ®±Ë°®ÈÅîÁêÜËß£„ÄÅÊåáÁ®±Ë°®ÈÅîÁîüÊàêÂíåÂΩ±ÂÉèÂàÜÈ°û„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåUni-Med ÊòØÁ¨¨‰∏ÄÂÄãÂú®ÈÄ£Êé•Âô®‰∏äËß£Ê±∫Â§ö‰ªªÂãôÂπ≤ÊìæÁöÑÂòóË©¶„ÄÇÂª£Ê≥õÁöÑÊ∂àËûçÂØ¶È©óÈ©óË≠â‰∫ÜÂú®‰ªª‰ΩïÁµÑÊÖã‰∏ãÂºïÂÖ• CMoE ÁöÑÊúâÊïàÊÄßÔºåÊïàËÉΩÊèêÂçáÂπÖÂ∫¶Âπ≥ÂùáÈ´òÈÅî 8%„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Êèê‰æõ‰∫ÜÂæûÊ¢ØÂ∫¶ÊúÄ‰Ω≥ÂåñÂíåÂèÉÊï∏Áµ±Ë®àÁöÑËßíÂ∫¶Â∞çÊãâÈã∏Êà∞ÂïèÈ°åÁöÑËß£ÈáãÂàÜÊûê„ÄÇËàáÂÖàÂâçÁöÑÈÜ´Â≠∏ MLLM ÊúÄÂÖàÈÄ≤ÊäÄË°ìÁõ∏ÊØîÔºåUni-Med Âú®‰∏çÂêåÁöÑ‰ªªÂãô‰∏äÂØ¶Áèæ‰∫ÜÂÖ∑ÊúâÁ´∂Áà≠ÂäõÊàñÊõ¥‰Ω≥ÁöÑË©ï‰º∞ÊåáÊ®ô„ÄÇÁ®ãÂºèÁ¢º„ÄÅË≥áÊñôÂíåÊ®°ÂûãÂ∞áÂæàÂø´Âú® GitHub ‰∏äÊèê‰æõ„ÄÇ</paragraph>

##### **Global-Local Medical SAM Adaptor Based on Full Adaption**
2409.17486v1 by Meng Wang, Yarong Feng, Yongwei Tang, Tian Zhang, Yuxin Liang, Chao Lv

Emerging of visual language models, such as the segment anything model (SAM),
have made great breakthroughs in the field of universal semantic segmentation
and significantly aid the improvements of medical image segmentation, in
particular with the help of Medical SAM adaptor (Med-SA). However, Med-SA still
can be improved, as it fine-tunes SAM in a partial adaption manner. To resolve
this problem, we present a novel global medical SAM adaptor (GMed-SA) with full
adaption, which can adapt SAM globally. We further combine GMed-SA and Med-SA
to propose a global-local medical SAM adaptor (GLMed-SA) to adapt SAM both
globally and locally. Extensive experiments have been performed on the
challenging public 2D melanoma segmentation dataset. The results show that
GLMed-SA outperforms several state-of-the-art semantic segmentation methods on
various evaluation metrics, demonstrating the superiority of our methods.

ÊëòË¶ÅÔºöË¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÁöÑÂá∫ÁèæÔºå‰æãÂ¶Ç‰ªª‰ΩïÂçÄÊÆµÊ®°Âûã (SAM)Ôºå
Âú®ÈÄöÁî®Ë™ûÊÑèÂàÜÂâ≤È†òÂüüÂèñÂæóÈáçÂ§ßÁ™ÅÁ†¥Ôºå
‰∏¶È°ØËëóÂπ´Âä©ÊîπÂñÑÈÜ´Â≠∏ÂΩ±ÂÉèÂàÜÂâ≤Ôºå
ÁâπÂà•ÊòØÂú®ÈÜ´Â≠∏ SAM ÈÅ©ÈÖçÂô® (Med-SA) ÁöÑÂπ´Âä©‰∏ã„ÄÇÁÑ∂ËÄåÔºåMed-SA ‰ªçÊúâÊîπÈÄ≤Á©∫ÈñìÔºåÂõ†ÁÇ∫ÂÆÉ‰ª•ÈÉ®ÂàÜÈÅ©ÊáâÁöÑÊñπÂºèÂæÆË™ø SAM„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂÖ∑ÊúâÂÆåÂÖ®ÈÅ©ÊáâËÉΩÂäõÁöÑÊñ∞ÂûãÂÖ®Â±ÄÈÜ´Â≠∏ SAM ÈÅ©ÈÖçÂô® (GMed-SA)ÔºåÂÆÉÂèØ‰ª•ÂÖ®Â±ÄÈÅ©Êáâ SAM„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÁµêÂêà GMed-SA Âíå Med-SA ‰æÜÊèêÂá∫‰∏ÄÂÄãÂÖ®Â±ÄÂ±ÄÈÉ®ÈÜ´Â≠∏ SAM ÈÅ©ÈÖçÂô® (GLMed-SA)Ôºå‰ª•ÂÖ®Â±ÄÂíåÂ±ÄÈÉ®ÁöÑÊñπÂºèÈÅ©Êáâ SAM„ÄÇÂú®ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÂÖ¨ÂÖ± 2D ÈªëËâ≤Á¥†Áò§ÂàÜÂâ≤Êï∏ÊìöÈõÜ‰∏äÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©ó„ÄÇÁµêÊûúË°®ÊòéÔºåGLMed-SA Âú®ÂêÑÁ®ÆË©ï‰º∞ÊåáÊ®ô‰∏äÂÑ™ÊñºÂ§öÁ®ÆÊúÄÂÖàÈÄ≤ÁöÑË™ûÊÑèÂàÜÂâ≤ÊñπÊ≥ïÔºåË≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÂÑ™Ë∂äÊÄß„ÄÇ

##### **Block Expanded DINORET: Adapting Natural Domain Foundation Models for Retinal Imaging Without Catastrophic Forgetting**
2409.17332v1 by Jay Zoellin, Colin Merk, Mischa Buob, Amr Saad, Samuel Giesser, Tahm Spitznagel, Ferhat Turgut, Rui Santos, Yukun Zhou, Sigfried Wagner, Pearse A. Keane, Yih Chung Tham, Delia Cabrera DeBuc, Matthias D. Becker, Gabor M. Somfai

Integrating deep learning into medical imaging is poised to greatly advance
diagnostic methods but it faces challenges with generalizability. Foundation
models, based on self-supervised learning, address these issues and improve
data efficiency. Natural domain foundation models show promise for medical
imaging, but systematic research evaluating domain adaptation, especially using
self-supervised learning and parameter-efficient fine-tuning, remains
underexplored. Additionally, little research addresses the issue of
catastrophic forgetting during fine-tuning of foundation models. We adapted the
DINOv2 vision transformer for retinal imaging classification tasks using
self-supervised learning and generated two novel foundation models termed
DINORET and BE DINORET. Publicly available color fundus photographs were
employed for model development and subsequent fine-tuning for diabetic
retinopathy staging and glaucoma detection. We introduced block expansion as a
novel domain adaptation strategy and assessed the models for catastrophic
forgetting. Models were benchmarked to RETFound, a state-of-the-art foundation
model in ophthalmology. DINORET and BE DINORET demonstrated competitive
performance on retinal imaging tasks, with the block expanded model achieving
the highest scores on most datasets. Block expansion successfully mitigated
catastrophic forgetting. Our few-shot learning studies indicated that DINORET
and BE DINORET outperform RETFound in terms of data-efficiency. This study
highlights the potential of adapting natural domain vision models to retinal
imaging using self-supervised learning and block expansion. BE DINORET offers
robust performance without sacrificing previously acquired capabilities. Our
findings suggest that these methods could enable healthcare institutions to
develop tailored vision models for their patient populations, enhancing global
healthcare inclusivity.

ÊëòË¶ÅÔºö<paragraph>Â∞áÊ∑±Â∫¶Â≠∏ÁøíÊï¥ÂêàÂà∞ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÔºåÊúâÊúõÂ§ßÂπÖÊèêÂçáË®∫Êñ∑ÊñπÊ≥ïÔºå‰ΩÜÂÆÉÂú®ÊôÆÈÅçÊÄßÊñπÈù¢Èù¢Ëá®ÊåëÊà∞„ÄÇÂü∫ÊñºËá™ÊàëÁõ£Áù£Â≠∏ÁøíÁöÑÂü∫Á§éÊ®°ÂûãÔºåËß£Ê±∫‰∫ÜÈÄô‰∫õÂïèÈ°å‰∏¶ÊèêÈ´ò‰∫ÜË≥áÊñôÊïàÁéá„ÄÇËá™ÁÑ∂È†òÂüüÂü∫Á§éÊ®°ÂûãÈ°ØÁ§∫Âá∫Âú®ÈÜ´Â≠∏ÂΩ±ÂÉèÊñπÈù¢ÁöÑÊΩõÂäõÔºå‰ΩÜË©ï‰º∞È†òÂüüÈÅ©ÊáâÁöÑÁ≥ªÁµ±ÊÄßÁ†îÁ©∂ÔºåÁâπÂà•ÊòØ‰ΩøÁî®Ëá™ÊàëÁõ£Áù£Â≠∏ÁøíÂíåÂèÉÊï∏ÊúâÊïàÂæÆË™øÔºå‰ªçÊú™Ë¢´ÂÖÖÂàÜÊé¢Ë®é„ÄÇÊ≠§Â§ñÔºåÂæàÂ∞ëÊúâÁ†îÁ©∂Êé¢Ë®éÂü∫Á§éÊ®°ÂûãÂæÆË™øÈÅéÁ®ã‰∏≠ÁÅΩÈõ£ÊÄßÈÅ∫ÂøòÁöÑÂïèÈ°å„ÄÇÊàëÂÄëÊé°Áî® DINOv2 Ë¶ñË¶∫ËΩâÊèõÂô®Ôºå‰ΩøÁî®Ëá™ÊàëÁõ£Áù£Â≠∏ÁøíÈÄ≤Ë°åË¶ñÁ∂≤ËÜúÂΩ±ÂÉèÂàÜÈ°û‰ªªÂãôÔºå‰∏¶ÁîüÊàê‰∫ÜÂÖ©ÂÄãÊñ∞ÁöÑÂü∫Á§éÊ®°ÂûãÔºåÁ®±ÁÇ∫ DINORET Âíå BE DINORET„ÄÇÂÖ¨ÈñãÂèØÁî®ÁöÑÂΩ©Ëâ≤ÁúºÂ∫ïÁÖßÁâáË¢´Áî®ÊñºÊ®°ÂûãÈñãÁôºÂíåÂæåÁ∫åÂæÆË™øÔºå‰ª•ÈÄ≤Ë°åÁ≥ñÂ∞øÁóÖË¶ñÁ∂≤ËÜúÁóÖËÆäÂàÜÊúüÂíåÈùíÂÖâÁúºÊ™¢Ê∏¨„ÄÇÊàëÂÄëÂºïÂÖ•‰∫ÜÂçÄÂ°äÊì¥Â±ï‰ΩúÁÇ∫‰∏ÄÁ®ÆÊñ∞ÁöÑÈ†òÂüüÈÅ©ÊáâÁ≠ñÁï•Ôºå‰∏¶Ë©ï‰º∞‰∫ÜÊ®°ÂûãÁöÑÁÅΩÈõ£ÊÄßÈÅ∫Âøò„ÄÇÈÄô‰∫õÊ®°ÂûãËàáÁúºÁßëÈ†òÂüüÊúÄÂÖàÈÄ≤ÁöÑÂü∫Á§éÊ®°Âûã RETFound ÈÄ≤Ë°å‰∫ÜÂü∫Ê∫ñÊ∏¨Ë©¶„ÄÇDINORET Âíå BE DINORET Âú®Ë¶ñÁ∂≤ËÜúÂΩ±ÂÉè‰ªªÂãô‰∏≠Ë°®ÁèæÂá∫Á´∂Áà≠ÂäõÔºåÂÖ∂‰∏≠ÂçÄÂ°äÊì¥Â±ïÊ®°ÂûãÂú®Â§ßÂ§öÊï∏Êï∏ÊìöÈõÜ‰∏äÁç≤Âæó‰∫ÜÊúÄÈ´òÂàÜ„ÄÇÂçÄÂ°äÊì¥Â±ïÊàêÂäüÂú∞Ê∏õËºï‰∫ÜÁÅΩÈõ£ÊÄßÈÅ∫Âøò„ÄÇÊàëÂÄëÁöÑ‰∏ÄÁôºÂ≠∏ÁøíÁ†îÁ©∂Ë°®ÊòéÔºåDINORET Âíå BE DINORET Âú®Ë≥áÊñôÊïàÁéáÊñπÈù¢ÂÑ™Êñº RETFound„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Âº∑Ë™ø‰∫Ü‰ΩøÁî®Ëá™ÊàëÁõ£Áù£Â≠∏ÁøíÂíåÂçÄÂ°äÊì¥Â±ïÂ∞áËá™ÁÑ∂È†òÂüüË¶ñË¶∫Ê®°ÂûãÈÅ©ÊáâÂà∞Ë¶ñÁ∂≤ËÜúÂΩ±ÂÉèÁöÑÊΩõÂäõ„ÄÇBE DINORET Âú®‰∏çÁäßÁâ≤ÂÖàÂâçÁç≤ÂæóÁöÑËÉΩÂäõÁöÑÊÉÖÊ≥Å‰∏ãÊèê‰æõ‰∫ÜÁ©©ÂÅ•ÁöÑÊÄßËÉΩ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÈÄô‰∫õÊñπÊ≥ïÂèØ‰ª•‰ΩøÈÜ´ÁôÇÊ©üÊßãÁÇ∫ÂÖ∂ÊÇ£ËÄÖÁæ§È´îÈñãÁôºÈáèË∫´ÂÆöÂà∂ÁöÑË¶ñË¶∫Ê®°ÂûãÔºåÂæûËÄåÂ¢ûÂº∑ÂÖ®ÁêÉÈÜ´ÁôÇ‰øùÂÅ•ÁöÑÂåÖÂÆπÊÄß„ÄÇ</paragraph>

##### **Data-Centric AI Governance: Addressing the Limitations of Model-Focused Policies**
2409.17216v1 by Ritwik Gupta, Leah Walker, Rodolfo Corona, Stephanie Fu, Suzanne Petryk, Janet Napolitano, Trevor Darrell, Andrew W. Reddie

Current regulations on powerful AI capabilities are narrowly focused on
"foundation" or "frontier" models. However, these terms are vague and
inconsistently defined, leading to an unstable foundation for governance
efforts. Critically, policy debates often fail to consider the data used with
these models, despite the clear link between data and model performance. Even
(relatively) "small" models that fall outside the typical definitions of
foundation and frontier models can achieve equivalent outcomes when exposed to
sufficiently specific datasets. In this work, we illustrate the importance of
considering dataset size and content as essential factors in assessing the
risks posed by models both today and in the future. More broadly, we emphasize
the risk posed by over-regulating reactively and provide a path towards
careful, quantitative evaluation of capabilities that can lead to a simplified
regulatory environment.

ÊëòË¶ÅÔºöÁï∂ÂâçÈáùÂ∞çÂº∑Â§ß AI ËÉΩÂäõÁöÑÊ≥ïË¶èÔºåÁãπÈöòÂú∞ËÅöÁÑ¶Âú®„ÄåÂü∫Á§é„ÄçÊàñ„ÄåÂâçÊ≤ø„ÄçÊ®°Âûã‰∏ä„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õË°ìË™ûÊ®°Á≥ä‰∏îÂÆöÁæ©‰∏ç‰∏ÄËá¥ÔºåÂ∞éËá¥Ê≤ªÁêÜÂ∑•‰ΩúÁº∫‰πèÁ©©Âõ∫ÁöÑÂü∫Á§é„ÄÇËá≥ÈóúÈáçË¶ÅÁöÑÊòØÔºåÊîøÁ≠ñËæØË´ñÁ∂ìÂ∏∏Êú™ËÉΩËÄÉÊÖÆËàáÈÄô‰∫õÊ®°Âûã‰∏ÄËµ∑‰ΩøÁî®ÁöÑË≥áÊñôÔºåÂÑòÁÆ°Ë≥áÊñôËàáÊ®°ÂûãÊïàËÉΩ‰πãÈñìÊúâÊòéÁ¢∫ÁöÑÈóúËÅØ„ÄÇÂç≥‰ΩøÊòØËêΩÂú®Âü∫Á§éÂíåÂâçÊ≤øÊ®°ÂûãÂÖ∏ÂûãÂÆöÁæ©‰πãÂ§ñÁöÑÔºàÁõ∏Â∞çÔºâ„ÄåÂ∞èÂûã„ÄçÊ®°ÂûãÔºåÂú®Êé•Ëß∏Âà∞Ë∂≥Â§†ÂÖ∑È´îÁöÑË≥áÊñôÈõÜÊôÇÔºå‰πüËÉΩÈÅîÊàêÂêåÁ≠âÁöÑÁµêÊûú„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëË™™Êòé‰∫ÜÂú®Ë©ï‰º∞Ê®°ÂûãÁï∂ÂâçÂíåÊú™‰æÜÂ∏∂‰æÜÁöÑÈ¢®Èö™ÊôÇÔºåËÄÉÈáèË≥áÊñôÈõÜÂ§ßÂ∞èÂíåÂÖßÂÆπÁÇ∫ÂøÖË¶ÅÂõ†Á¥†ÁöÑÈáçË¶ÅÊÄß„ÄÇÊõ¥Âª£Ê≥õÂú∞‰æÜË™™ÔºåÊàëÂÄëÂº∑Ë™ø‰∫ÜÈÅéÂ∫¶ÂèçÊáâÂºèÁõ£ÁÆ°ÊâÄÂ∏∂‰æÜÁöÑÈ¢®Èö™Ôºå‰∏¶Êèê‰æõ‰∫Ü‰∏ÄÊ¢ùÈÄöÂæÄÂØ©ÊÖé„ÄÅÈáèÂåñË©ï‰º∞ËÉΩÂäõÁöÑÈÅìË∑ØÔºåÈÄôÂ∞áÊúâÂä©ÊñºÁ∞°ÂåñÁõ£ÁÆ°Áí∞Â¢É„ÄÇ

##### **Ctrl-GenAug: Controllable Generative Augmentation for Medical Sequence Classification**
2409.17091v1 by Xinrui Zhou, Yuhao Huang, Haoran Dou, Shijing Chen, Ao Chang, Jia Liu, Weiran Long, Jian Zheng, Erjiao Xu, Jie Ren, Ruobing Huang, Jun Cheng, Wufeng Xue, Dong Ni

In the medical field, the limited availability of large-scale datasets and
labor-intensive annotation processes hinder the performance of deep models.
Diffusion-based generative augmentation approaches present a promising solution
to this issue, having been proven effective in advancing downstream medical
recognition tasks. Nevertheless, existing works lack sufficient semantic and
sequential steerability for challenging video/3D sequence generation, and
neglect quality control of noisy synthesized samples, resulting in unreliable
synthetic databases and severely limiting the performance of downstream tasks.
In this work, we present Ctrl-GenAug, a novel and general generative
augmentation framework that enables highly semantic- and sequential-customized
sequence synthesis and suppresses incorrectly synthesized samples, to aid
medical sequence classification. Specifically, we first design a multimodal
conditions-guided sequence generator for controllably synthesizing
diagnosis-promotive samples. A sequential augmentation module is integrated to
enhance the temporal/stereoscopic coherence of generated samples. Then, we
propose a noisy synthetic data filter to suppress unreliable cases at semantic
and sequential levels. Extensive experiments on 3 medical datasets, using 11
networks trained on 3 paradigms, comprehensively analyze the effectiveness and
generality of Ctrl-GenAug, particularly in underrepresented high-risk
populations and out-domain conditions.

ÊëòË¶ÅÔºöÂú®ÂåªÂ≠¶È†òÂüü‰∏≠ÔºåÂ§ßË¶èÊ®°Êï∏ÊìöÈõÜÁöÑÂèØÁî®ÊÄßÊúâÈôêÔºå‰∏î‰∫∫Â∑•Ê®ôË®ªÈÅéÁ®ãÁπÅÁë£ÔºåÈòªÁ§ô‰∫ÜÊ∑±Â∫¶Ê®°ÂûãÁöÑÂü∑Ë°å„ÄÇÂü∫ÊñºÊì¥Êï£ÁöÑÁîüÊàêÂºèÊì¥ÂÖÖÊñπÊ≥ïÁÇ∫Ê≠§ÂïèÈ°åÊèê‰æõ‰∫ÜÊúâÂâçÊôØÁöÑËß£Ê±∫ÊñπÊ°àÔºåÂ∑≤Ë¢´Ë≠âÂØ¶ËÉΩÊúâÊïàÊé®ÈÄ≤‰∏ãÊ∏∏ÈÜ´ÁôÇË≠òÂà•‰ªªÂãô„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÁèæÊúâ‰ΩúÂìÅÁº∫‰πèË∂≥Â§†ÁöÑË™ûÁæ©ÂíåÂ∫èÂàóÂèØÊéßÊÄßÔºåÈõ£‰ª•ÈÄ≤Ë°åÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑË¶ñË®ä/3D Â∫èÂàóÁîüÊàêÔºå‰∏îÂøΩÁï•‰∫ÜÂ∞çÊúâÈõúË®äÂêàÊàêÊ®£Êú¨ÁöÑÂìÅË≥™ÊéßÂà∂ÔºåÂ∞éËá¥ÂêàÊàêÂºèË≥áÊñôÂ∫´‰∏çÂèØÈù†Ôºå‰∏¶Âö¥ÈáçÈôêÂà∂‰∫Ü‰∏ãÊ∏∏‰ªªÂãôÁöÑÂü∑Ë°å„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü Ctrl-GenAugÔºå‰∏ÄÂÄãÊñ∞Á©é‰∏îÈÄöÁî®ÁöÑÁîüÊàêÂºèÊì¥ÂÖÖÊû∂ÊßãÔºåËÉΩÂØ¶ÁèæÈ´òÂ∫¶Ë™ûÁæ©ÂíåÂ∫èÂàóËá™Ë®ÇÁöÑÂ∫èÂàóÂêàÊàêÔºå‰∏¶ÊäëÂà∂ÈåØË™§ÂêàÊàêÁöÑÊ®£Êú¨Ôºå‰ª•ÂçîÂä©ÈÜ´ÁôÇÂ∫èÂàóÂàÜÈ°û„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈ¶ñÂÖàË®≠Ë®à‰∫Ü‰∏ÄÂÄãÂ§öÊ®°ÊÖãÊ¢ù‰ª∂ÂºïÂ∞éÂ∫èÂàóÁîüÊàêÂô®ÔºåÁî®ÊñºÂèØÊéßÂú∞ÂêàÊàê‰øÉÈÄ≤Ë®∫Êñ∑ÁöÑÊ®£Êú¨„ÄÇÊï¥Âêà‰∫Ü‰∏ÄÂÄãÂ∫èÂàóÊì¥ÂÖÖÊ®°ÁµÑÔºå‰ª•Â¢ûÂº∑ÁîüÊàêÊ®£Êú¨ÁöÑÊôÇÈñì/Á´ãÈ´î‰∏ÄËá¥ÊÄß„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊúâÈõúË®äÁöÑÂêàÊàêË≥áÊñôÊøæÊ≥¢Âô®Ôºå‰ª•ÊäëÂà∂Ë™ûÁæ©ÂíåÂ∫èÂàóÂ±§Á¥ö‰∏≠‰∏çÂèØÈù†ÁöÑÊ°à‰æã„ÄÇÂú® 3 ÂÄãÈÜ´ÁôÇÊï∏ÊìöÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óÔºå‰ΩøÁî®Âú® 3 ÂÄãÁØÑ‰æã‰∏≠Ë®ìÁ∑¥ÁöÑ 11 ÂÄãÁ∂≤Ë∑ØÔºåÂÖ®Èù¢ÂàÜÊûê‰∫Ü Ctrl-GenAug ÁöÑÊúâÊïàÊÄßÂíåÊôÆÈÅçÊÄßÔºåÁâπÂà•ÊòØÂú®‰ª£Ë°®ÊÄß‰∏çË∂≥ÁöÑÈ´òÈ¢®Èö™ÊóèÁæ§ÂíåÈ†òÂüüÂ§ñÊ¢ù‰ª∂‰∏≠„ÄÇ

##### **DRIM: Learning Disentangled Representations from Incomplete Multimodal Healthcare Data**
2409.17055v2 by Lucas Robinet, Ahmad Berjaoui, Ziad Kheil, Elizabeth Cohen-Jonathan Moyal

Real-life medical data is often multimodal and incomplete, fueling the
growing need for advanced deep learning models capable of integrating them
efficiently. The use of diverse modalities, including histopathology slides,
MRI, and genetic data, offers unprecedented opportunities to improve prognosis
prediction and to unveil new treatment pathways. Contrastive learning, widely
used for deriving representations from paired data in multimodal tasks, assumes
that different views contain the same task-relevant information and leverages
only shared information. This assumption becomes restrictive when handling
medical data since each modality also harbors specific knowledge relevant to
downstream tasks. We introduce DRIM, a new multimodal method for capturing
these shared and unique representations, despite data sparsity. More
specifically, given a set of modalities, we aim to encode a representation for
each one that can be divided into two components: one encapsulating
patient-related information common across modalities and the other,
encapsulating modality-specific details. This is achieved by increasing the
shared information among different patient modalities while minimizing the
overlap between shared and unique components within each modality. Our method
outperforms state-of-the-art algorithms on glioma patients survival prediction
tasks, while being robust to missing modalities. To promote reproducibility,
the code is made publicly available at https://github.com/Lucas-rbnt/DRIM

ÊëòË¶ÅÔºöÁúüÂØ¶‰∏ñÁïåÁöÑÈÜ´ÁôÇÊï∏ÊìöÈÄöÂ∏∏ÊòØÂ§öÊ®°ÊÖã‰∏î‰∏çÂÆåÊï¥ÁöÑÔºåÊé®Âãï‰∫ÜÂ∞çËÉΩÂ§†ÊúâÊïàÊï¥ÂêàÂÆÉÂÄëÁöÑÂÖàÈÄ≤Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑÈúÄÊ±Ç„ÄÇ‰ΩøÁî®Â§öÁ®ÆÊ®°ÂºèÔºåÂåÖÊã¨ÁµÑÁπîÁóÖÁêÜÂ≠∏ÂπªÁáàÁâá„ÄÅÊ†∏Á£ÅÂÖ±ÊåØÂíåÈÅ∫ÂÇ≥Êï∏ÊìöÔºåÊèê‰æõ‰∫ÜÂâçÊâÄÊú™ÊúâÁöÑÊ©üÊúÉ‰æÜÊîπÈÄ≤È†êÂæåÈ†êÊ∏¨‰∏¶Êè≠Á§∫Êñ∞ÁöÑÊ≤ªÁôÇÈÄîÂæë„ÄÇÂ∞çÊØîÂ≠∏ÁøíÂª£Ê≥õÁî®ÊñºÂæûÂ§öÊ®°ÊÖã‰ªªÂãô‰∏≠ÁöÑÈÖçÂ∞çÊï∏Êìö‰∏≠Êé®Â∞éË°®Á§∫ÔºåÂÅáË®≠‰∏çÂêåÁöÑË¶ñÂúñÂåÖÂê´Áõ∏ÂêåÁöÑËàá‰ªªÂãôÁõ∏ÈóúÁöÑ‰ø°ÊÅØÔºå‰∏¶‰∏îÂÉÖÂà©Áî®ÂÖ±‰∫´‰ø°ÊÅØ„ÄÇÂú®ËôïÁêÜÈÜ´ÁôÇÊï∏ÊìöÊôÇÔºåÈÄôÁ®ÆÂÅáË®≠ËÆäÂæóÂÖ∑ÊúâÈôêÂà∂ÊÄßÔºåÂõ†ÁÇ∫ÊØèÁ®ÆÊ®°Âºè‰πüÂåÖÂê´Ëàá‰∏ãÊ∏∏‰ªªÂãôÁõ∏ÈóúÁöÑÁâπÂÆöÁü•Ë≠ò„ÄÇÊàëÂÄë‰ªãÁ¥π‰∫Ü DRIMÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞ÁöÑÂ§öÊ®°ÊÖãÊñπÊ≥ïÔºåÁî®ÊñºÊçïÁç≤ÈÄô‰∫õÂÖ±‰∫´ÂíåÁç®ÁâπÁöÑË°®Á§∫ÔºåÂÑòÁÆ°Êï∏ÊìöÁ®ÄÁñè„ÄÇÊõ¥ÂÖ∑È´îÂú∞Ë™™ÔºåÁµ¶ÂÆö‰∏ÄÁµÑÊ®°ÂºèÔºåÊàëÂÄëÁöÑÁõÆÊ®ôÊòØÁÇ∫ÊØèÂÄãÊ®°ÂºèÁ∑®Á¢º‰∏ÄÂÄãË°®Á§∫ÔºåË©≤Ë°®Á§∫ÂèØ‰ª•ÂàÜÁÇ∫ÂÖ©ÂÄãÁµÑÊàêÈÉ®ÂàÜÔºö‰∏ÄÂÄãÂ∞ÅË£ùË∑®Ê®°ÂºèÂÖ±ÊúâÁöÑÊÇ£ËÄÖÁõ∏Èóú‰ø°ÊÅØÔºåÂè¶‰∏ÄÂÄãÂ∞ÅË£ùÁâπÂÆöÊñºÊ®°ÂºèÁöÑÁ¥∞ÁØÄ„ÄÇÈÄôÊòØÈÄöÈÅéÂ¢ûÂä†‰∏çÂêåÊÇ£ËÄÖÊ®°Âºè‰πãÈñìÁöÑÂÖ±‰∫´‰ø°ÊÅØÔºåÂêåÊôÇÊúÄÂ∞èÂåñÊØèÂÄãÊ®°ÂºèÂÖßÂÖ±‰∫´ÂíåÂîØ‰∏ÄÁµÑ‰ª∂‰πãÈñìÁöÑÈáçÁñä‰æÜÂØ¶ÁèæÁöÑ„ÄÇÊàëÂÄëÁöÑÁÆóÊ≥ïÂú®Á•ûÁ∂ìËÜ†Ë≥™Áò§ÊÇ£ËÄÖÁîüÂ≠òÈ†êÊ∏¨‰ªªÂãô‰∏≠ÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÁÆóÊ≥ïÔºåÂêåÊôÇÂ∞çÁº∫Â§±Ê®°ÂºèÂÖ∑ÊúâÈ≠ØÊ£íÊÄß„ÄÇÁÇ∫‰∫Ü‰øÉÈÄ≤ÂèØÈáçË§áÊÄßÔºå‰ª£Á¢ºÂ∑≤Âú® https://github.com/Lucas-rbnt/DRIM ‰∏äÂÖ¨Èñã„ÄÇ

##### **Using LLM for Real-Time Transcription and Summarization of Doctor-Patient Interactions into ePuskesmas in Indonesia**
2409.17054v1 by Azmul Asmar Irfan, Nur Ahmad Khatim, Mansur M. Arief

One of the key issues contributing to inefficiency in Puskesmas is the
time-consuming nature of doctor-patient interactions. Doctors need to conduct
thorough consultations, which include diagnosing the patient's condition,
providing treatment advice, and transcribing detailed notes into medical
records. In regions with diverse linguistic backgrounds, doctors often have to
ask clarifying questions, further prolonging the process. While diagnosing is
essential, transcription and summarization can often be automated using AI to
improve time efficiency and help doctors enhance care quality and enable early
diagnosis and intervention. This paper proposes a solution using a localized
large language model (LLM) to transcribe, translate, and summarize
doctor-patient conversations. We utilize the Whisper model for transcription
and GPT-3 to summarize them into the ePuskemas medical records format. This
system is implemented as an add-on to an existing web browser extension,
allowing doctors to fill out patient forms while talking. By leveraging this
solution for real-time transcription, translation, and summarization, doctors
can improve the turnaround time for patient care while enhancing the quality of
records, which become more detailed and insightful for future visits. This
innovation addresses challenges like overcrowded facilities and the
administrative burden on healthcare providers in Indonesia. We believe this
solution will help doctors save time, provide better care, and produce more
accurate medical records, representing a significant step toward modernizing
healthcare and ensuring patients receive timely, high-quality care, even in
resource-constrained settings.

ÊëòË¶ÅÔºö<paragraph>Â∞éËá¥ Puskesmas ÊïàÁéá‰Ωé‰∏ãÁöÑÈóúÈçµÂïèÈ°å‰πã‰∏ÄÊòØÔºåÈÜ´ÁîüÂíåÁóÖ‰∫∫‰∫íÂãïËÄóÊôÇ„ÄÇÈÜ´ÁîüÈúÄË¶ÅÈÄ≤Ë°åÂæπÂ∫ïÁöÑË´ÆË©¢ÔºåÂåÖÊã¨Ë®∫Êñ∑ÁóÖ‰∫∫ÁöÑÁóÖÊÉÖ„ÄÅÊèê‰æõÊ≤ªÁôÇÂª∫Ë≠∞Ôºå‰ª•ÂèäÂ∞áË©≥Á¥∞ÁöÑÁ≠ÜË®òË®òÈåÑÂú®ÈÜ´ÁôÇË®òÈåÑ‰∏≠„ÄÇÂú®Ë™ûË®ÄËÉåÊôØÂ§öÂÖÉÁöÑÂú∞ÂçÄÔºåÈÜ´ÁîüÁ∂ìÂ∏∏ÂøÖÈ†àÊèêÂá∫ÊæÑÊ∏ÖÂïèÈ°åÔºåÈÄ≤‰∏ÄÊ≠•Âª∂Èï∑ÊµÅÁ®ã„ÄÇÈõñÁÑ∂Ë®∫Êñ∑Ëá≥ÈóúÈáçË¶ÅÔºå‰ΩÜ‰ΩøÁî® AI ÈÄ≤Ë°åËΩâÈåÑÂíåÊëòË¶ÅÈÄöÂ∏∏ÂèØ‰ª•Ëá™ÂãïÂåñÔºå‰ª•ÊèêÈ´òÊôÇÈñìÊïàÁéáÔºå‰∏¶Âπ´Âä©ÈÜ´ÁîüÊèêÈ´òË≠∑ÁêÜÂìÅË≥™Ôºå‰∏¶ÂØ¶ÁèæÊó©ÊúüË®∫Êñ∑ÂíåÂπ≤È†ê„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄã‰ΩøÁî®Êú¨Âú∞ÂåñÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜËΩâÈåÑ„ÄÅÁøªË≠ØÂíåÊëòË¶ÅÈÜ´ÁîüËàáÁóÖ‰∫∫Â∞çË©±ÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇÊàëÂÄëÂà©Áî® Whisper Ê®°ÂûãÈÄ≤Ë°åËΩâÈåÑÔºå‰∏¶‰ΩøÁî® GPT-3 Â∞áÂÖ∂ÊëòË¶ÅÊàê ePuskemas ÈÜ´ÁôÇË®òÈåÑÊ†ºÂºè„ÄÇÊ≠§Á≥ªÁµ±ÂØ¶‰ΩúÁÇ∫ÁèæÊúâÁ∂≤Ë∑ØÁÄèË¶ΩÂô®Êì¥ÂÖÖÂäüËÉΩÁöÑÈôÑÂä†ÂÖÉ‰ª∂ÔºåËÆìÈÜ´ÁîüÂèØ‰ª•Âú®‰∫§Ë´áÊôÇÂ°´ÂØ´ÁóÖÊÇ£Ë°®ÂñÆ„ÄÇÈÄèÈÅéÂà©Áî®Ê≠§Ëß£Ê±∫ÊñπÊ°àÈÄ≤Ë°åÂç≥ÊôÇËΩâÈåÑ„ÄÅÁøªË≠ØÂíåÊëòË¶ÅÔºåÈÜ´ÁîüÂèØ‰ª•ÊîπÂñÑÁóÖÊÇ£ÁÖßË≠∑ÁöÑÂë®ËΩâÊôÇÈñìÔºåÂêåÊôÇÊèêÂçáË®òÈåÑÂìÅË≥™ÔºåËÆìË®òÈåÑËÆäÂæóÊõ¥Ë©≥Á¥∞‰∏îÊõ¥ÊúâÊ¥ûË¶ãÔºå‰ª•Âà©ÊñºÂæåÁ∫åÂ∞±Ë®∫„ÄÇÊ≠§ÂâµÊñ∞Ëß£Ê±∫‰∫ÜÂÉèÈÜ´ÁôÇÊ©üÊßã‰∫∫ÊªøÁÇ∫ÊÇ£ÂíåÂç∞Â∞ºÈÜ´ÁôÇ‰øùÂÅ•Êèê‰æõËÄÖÁöÑË°åÊîøË≤†ÊìîÁ≠âÊåëÊà∞„ÄÇÊàëÂÄëÁõ∏‰ø°Ê≠§Ëß£Ê±∫ÊñπÊ°àÂ∞áÂπ´Âä©ÈÜ´ÁîüÁØÄÁúÅÊôÇÈñì„ÄÅÊèê‰æõÊõ¥Â•ΩÁöÑÁÖßË≠∑Ôºå‰∏¶Áî¢ÁîüÊõ¥Ê∫ñÁ¢∫ÁöÑÈÜ´ÁôÇË®òÈåÑÔºå‰ª£Ë°®ËëóÁèæ‰ª£ÂåñÈÜ´ÁôÇ‰øùÂÅ•‰∏¶Á¢∫‰øùÁóÖ‰∫∫Âç≥‰ΩøÂú®Ë≥áÊ∫êÂèóÈôêÁöÑÁí∞Â¢É‰∏≠‰πüËÉΩÁç≤ÂæóÂèäÊôÇ„ÄÅÈ´òÂìÅË≥™ÁöÑÁÖßË≠∑ÁöÑÈáçË¶Å‰∏ÄÊ≠•„ÄÇ</paragraph>

##### **GeoBiked: A Dataset with Geometric Features and Automated Labeling Techniques to Enable Deep Generative Models in Engineering Design**
2409.17045v1 by Phillip Mueller, Sebastian Mueller, Lars Mikelsons

We provide a dataset for enabling Deep Generative Models (DGMs) in
engineering design and propose methods to automate data labeling by utilizing
large-scale foundation models. GeoBiked is curated to contain 4 355 bicycle
images, annotated with structural and technical features and is used to
investigate two automated labeling techniques: The utilization of consolidated
latent features (Hyperfeatures) from image-generation models to detect
geometric correspondences (e.g. the position of the wheel center) in structural
images and the generation of diverse text descriptions for structural images.
GPT-4o, a vision-language-model (VLM), is instructed to analyze images and
produce diverse descriptions aligned with the system-prompt. By representing
technical images as Diffusion-Hyperfeatures, drawing geometric correspondences
between them is possible. The detection accuracy of geometric points in unseen
samples is improved by presenting multiple annotated source images. GPT-4o has
sufficient capabilities to generate accurate descriptions of technical images.
Grounding the generation only on images leads to diverse descriptions but
causes hallucinations, while grounding it on categorical labels restricts the
diversity. Using both as input balances creativity and accuracy. Successfully
using Hyperfeatures for geometric correspondence suggests that this approach
can be used for general point-detection and annotation tasks in technical
images. Labeling such images with text descriptions using VLMs is possible, but
dependent on the models detection capabilities, careful prompt-engineering and
the selection of input information. Applying foundation models in engineering
design is largely unexplored. We aim to bridge this gap with a dataset to
explore training, finetuning and conditioning DGMs in this field and suggesting
approaches to bootstrap foundation models to process technical images.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãË≥áÊñôÈõÜÔºåÁî®ÊñºÂú®Â∑•Á®ãË®≠Ë®à‰∏≠ÂïüÁî®Ê∑±Â∫¶ÁîüÊàêÊ®°Âûã (DGM)Ôºå‰∏¶ÊèêÂá∫ÈÄèÈÅéÂà©Áî®Â§ßË¶èÊ®°Âü∫Á§éÊ®°ÂûãËá™ÂãïÂåñË≥áÊñôÊ®ôÁ±§ÁöÑÊñπÊ≥ï„ÄÇGeoBiked Á∂ìÈÅéÁ≠ñÂ±ïÔºåÂåÖÂê´ 4,355 ÂºµËá™Ë°åËªäÂΩ±ÂÉèÔºå‰∏¶ÈôÑÊúâÁµêÊßãÂíåÊäÄË°ìÁâπÂæµË®ªËß£Ôºå‰∏îÁî®ÊñºË™øÊü•ÂÖ©Á®ÆËá™ÂãïÂåñÊ®ôÁ±§ÊäÄË°ìÔºöÂà©Áî®ÂΩ±ÂÉèÁîüÊàêÊ®°ÂûãÁöÑÊï¥ÂêàÊΩõÂú®ÁâπÂæµÔºàË∂ÖÁâπÂæµÔºâ‰æÜÂÅµÊ∏¨ÁµêÊßãÂΩ±ÂÉè‰∏≠ÁöÑÂπæ‰ΩïÂ∞çÊáâÔºà‰æãÂ¶ÇËªäËº™‰∏≠ÂøÉÁöÑ‰ΩçÂ≠êÔºâÔºå‰ª•ÂèäÁÇ∫ÁµêÊßãÂΩ±ÂÉèÁî¢ÁîüÂ§öÊ®£ÂåñÁöÑÊñáÂ≠óÊèèËø∞„ÄÇGPT-4o ÊòØ‰∏ÄÂÄãË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM)ÔºåÊåáÁ§∫Ë¶ÅÂàÜÊûêÂΩ±ÂÉè‰∏¶Áî¢ÁîüËàáÁ≥ªÁµ±ÊèêÁ§∫‰∏ÄËá¥ÁöÑÂ§öÊ®£ÂåñÊèèËø∞„ÄÇÈÄèÈÅéÂ∞áÊäÄË°ìÂΩ±ÂÉèË°®Á§∫ÁÇ∫Êì¥Êï£Ë∂ÖÁâπÂæµÔºåÂ∞±ÂèØ‰ª•Áπ™Ë£ΩÂÆÉÂÄë‰πãÈñìÁöÑÂπæ‰ΩïÂ∞çÊáâ„ÄÇÈÄèÈÅéÂëàÁèæÂ§öÂÄãÂ∏∂Ë®ªËß£ÁöÑ‰æÜÊ∫êÂΩ±ÂÉèÔºåÂèØ‰ª•ÊîπÂñÑÂú®Êú™Ë¶ãÊ®£Êú¨‰∏≠Âπæ‰ΩïÈªûÁöÑÂÅµÊ∏¨Ê∫ñÁ¢∫Â∫¶„ÄÇGPT-4o ÂÖ∑ÊúâË∂≥Â§†ÁöÑËÉΩÂäõ‰æÜÁî¢ÁîüÊäÄË°ìÂΩ±ÂÉèÁöÑÊ∫ñÁ¢∫ÊèèËø∞„ÄÇÂÉÖÊ†πÊìöÂΩ±ÂÉèÈÄ≤Ë°åÂü∫Á§éÊúÉÁî¢ÁîüÂ§öÊ®£ÂåñÁöÑÊèèËø∞Ôºå‰ΩÜÊúÉÁî¢ÁîüÂπªË¶∫ÔºåËÄåÊ†πÊìöÂàÜÈ°ûÊ®ôÁ±§ÈÄ≤Ë°åÂü∫Á§éÂâáÊúÉÈôêÂà∂Â§öÊ®£ÊÄß„ÄÇÂ∞áÂÖ©ËÄÖÈÉΩÁî®‰ΩúËº∏ÂÖ•ÔºåÂèØ‰ª•Âπ≥Ë°°ÂâµÈÄ†ÂäõÂíåÊ∫ñÁ¢∫ÊÄß„ÄÇÊàêÂäüÂú∞Â∞áË∂ÖÁâπÂæµÁî®ÊñºÂπæ‰ΩïÂ∞çÊáâÔºåË°®Á§∫ÈÄôÁ®ÆÊñπÊ≥ïÂèØÁî®ÊñºÊäÄË°ìÂΩ±ÂÉè‰∏≠ÁöÑ‰∏ÄËà¨ÈªûÂÅµÊ∏¨ÂíåË®ªËß£‰ªªÂãô„ÄÇ‰ΩøÁî® VLM Ê®ôÁ±§Ê≠§È°ûÂΩ±ÂÉèÁöÑÊñáÂ≠óÊèèËø∞ÊòØÂèØË°åÁöÑÔºå‰ΩÜÂèñÊ±∫ÊñºÊ®°ÂûãÁöÑÂÅµÊ∏¨ËÉΩÂäõ„ÄÅ‰ªîÁ¥∞ÁöÑÊèêÁ§∫Â∑•Á®ãÂíåËº∏ÂÖ•Ë≥áË®äÁöÑÈÅ∏Êìá„ÄÇÂú®Â∑•Á®ãË®≠Ë®à‰∏≠ÊáâÁî®Âü∫Á§éÊ®°ÂûãÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂ∞öÊú™Êé¢Á¥¢„ÄÇÊàëÂÄëÊó®Âú®ÈÄèÈÅé‰∏ÄÂÄãË≥áÊñôÈõÜ‰æÜÂ°´Ë£úÈÄôÂÄãÁ©∫ÁôΩÔºå‰ª•Êé¢Á¥¢Âú®ÈÄôÂÄãÈ†òÂüüË®ìÁ∑¥„ÄÅÂæÆË™øÂíåË™øÊï¥ DGMÔºå‰∏¶Âª∫Ë≠∞ÂºïÂ∞éÂü∫Á§éÊ®°ÂûãËôïÁêÜÊäÄË°ìÂΩ±ÂÉèÁöÑÊñπÊ≥ï„ÄÇ</paragraph>

##### **AI-driven View Guidance System in Intra-cardiac Echocardiography Imaging**
2409.16898v2 by Jaeyoung Huh, Paul Klein, Gareth Funka-Lea, Puneet Sharma, Ankur Kapoor, Young-Ho Kim

Intra-cardiac Echocardiography (ICE) is a crucial imaging modality used in
electrophysiology (EP) and structural heart disease (SHD) interventions,
providing real-time, high-resolution views from within the heart. Despite its
advantages, effective manipulation of the ICE catheter requires significant
expertise, which can lead to inconsistent outcomes, particularly among less
experienced operators. To address this challenge, we propose an AI-driven
closed-loop view guidance system with human-in-the-loop feedback, designed to
assist users in navigating ICE imaging without requiring specialized knowledge.
Our method models the relative position and orientation vectors between
arbitrary views and clinically defined ICE views in a spatial coordinate
system, guiding users on how to manipulate the ICE catheter to transition from
the current view to the desired view over time. Operating in a closed-loop
configuration, the system continuously predicts and updates the necessary
catheter manipulations, ensuring seamless integration into existing clinical
workflows. The effectiveness of the proposed system is demonstrated through a
simulation-based evaluation, achieving an 89% success rate with the 6532 test
dataset, highlighting its potential to improve the accuracy and efficiency of
ICE imaging procedures.

ÊëòË¶ÅÔºöÂøÉÂÖßË∂ÖÈü≥Ê≥¢ (ICE) ÊòØ‰∏ÄÁ®ÆÈáçË¶ÅÁöÑÂΩ±ÂÉèÊ®°ÂºèÔºåÁî®ÊñºÈõªÁîüÁêÜ (EP) ÂíåÁµêÊßãÊÄßÂøÉËáüÁñæÁóÖ (SHD) ÁöÑ‰ªãÂÖ•Ê≤ªÁôÇÔºåÊèê‰æõ‰æÜËá™ÂøÉËáüÂÖßÈÉ®ÁöÑÈ´òËß£ÊûêÂ∫¶Âç≥ÊôÇÂΩ±ÂÉè„ÄÇÂÑòÁÆ°ÊúâÈÄô‰∫õÂÑ™ÈªûÔºå‰ΩÜÊúâÊïàÊìç‰Ωú ICE Â∞éÁÆ°ÈúÄË¶ÅÂ§ßÈáèÁöÑÂ∞àÊ•≠Áü•Ë≠òÔºåÈÄôÂèØËÉΩÊúÉÂ∞éËá¥‰∏ç‰∏ÄËá¥ÁöÑÁµêÊûúÔºåÂ∞§ÂÖ∂ÊòØÂú®Á∂ìÈ©óËºÉÂ∞ëÁöÑÊìç‰ΩúËÄÖ‰∏≠„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄôÂÄãÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®Æ‰ª• AI ÁÇ∫È©ÖÂãïÁöÑÈñâÁí∞Ë¶ñÂúñÂºïÂ∞éÁ≥ªÁµ±Ôºå‰∏¶ÁµêÂêà‰∫∫ÁÇ∫ÂõûÈ•ãÔºåÊó®Âú®ÂçîÂä©‰ΩøÁî®ËÄÖÂú®‰∏çÈúÄË¶ÅÂ∞àÊ•≠Áü•Ë≠òÁöÑÊÉÖÊ≥Å‰∏ãÂ∞éËà™ ICE ÂΩ±ÂÉè„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÊñπÊ≥ïÂú®Á©∫ÈñìÂ∫ßÊ®ôÁ≥ªÁµ±‰∏≠Âª∫Êßã‰ªªÊÑèË¶ñÂúñÂíåËá®Â∫äÂÆöÁæ©ÁöÑ ICE Ë¶ñÂúñ‰πãÈñìÁöÑÁõ∏Â∞ç‰ΩçÁΩÆÂíåÊñπÂêëÂêëÈáèÔºåÂºïÂ∞é‰ΩøÁî®ËÄÖÂ¶Ç‰ΩïÊìç‰Ωú ICE Â∞éÁÆ°Ôºå‰ª•Èö®ËëóÊôÇÈñìÊé®ÁßªÂæûÁõÆÂâçÁöÑË¶ñÂúñËΩâÊèõÂà∞ÊâÄÈúÄÁöÑË¶ñÂúñ„ÄÇÁ≥ªÁµ±Âú®ÈñâÁí∞ÈÖçÁΩÆ‰∏≠ÈÅã‰ΩúÔºåÊåÅÁ∫åÈ†êÊ∏¨ÂíåÊõ¥Êñ∞ÂøÖË¶ÅÁöÑÂ∞éÁÆ°Êìç‰ΩúÔºåÁ¢∫‰øùÁÑ°Á∏´Êï¥ÂêàÂà∞ÁèæÊúâÁöÑËá®Â∫äÂ∑•‰ΩúÊµÅÁ®ã‰∏≠„ÄÇÊâÄÊèêÂá∫ÁöÑÁ≥ªÁµ±ÁöÑÊúâÊïàÊÄßÈÄèÈÅéÂü∫ÊñºÊ®°Êì¨ÁöÑË©ï‰º∞ÂæóÂà∞Ë≠âÊòéÔºåÂú® 6532 ÂÄãÊ∏¨Ë©¶Êï∏ÊìöÈõÜ‰∏≠ÂØ¶Áèæ‰∫Ü 89% ÁöÑÊàêÂäüÁéáÔºåÁ™ÅÈ°Ø‰∫ÜÂÖ∂ÊîπÂñÑ ICE ÂΩ±ÂÉèÁ®ãÂ∫èÊ∫ñÁ¢∫ÊÄßÂíåÊïàÁéáÁöÑÊΩõÂäõ„ÄÇ

##### **The Role of Language Models in Modern Healthcare: A Comprehensive Review**
2409.16860v1 by Amna Khalid, Ayma Khalid, Umar Khalid

The application of large language models (LLMs) in healthcare has gained
significant attention due to their ability to process complex medical data and
provide insights for clinical decision-making. These models have demonstrated
substantial capabilities in understanding and generating natural language,
which is crucial for medical documentation, diagnostics, and patient
interaction. This review examines the trajectory of language models from their
early stages to the current state-of-the-art LLMs, highlighting their strengths
in healthcare applications and discussing challenges such as data privacy,
bias, and ethical considerations. The potential of LLMs to enhance healthcare
delivery is explored, alongside the necessary steps to ensure their ethical and
effective integration into medical practice.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÊáâÁî®Â∑≤Áç≤ÂæóÈ°ØËëóÈóúÊ≥®ÔºåÂõ†ÁÇ∫ÂÆÉÂÄëËÉΩÂ§†ËôïÁêÜË§áÈõúÁöÑÈÜ´ÁôÇÊï∏Êìö‰∏¶Êèê‰æõËá®Â∫äÊ±∫Á≠ñÁöÑË¶ãËß£„ÄÇÈÄô‰∫õÊ®°ÂûãÂ∑≤Â±ïÁ§∫Âá∫Âú®ÁêÜËß£ÂíåÁî¢ÁîüËá™ÁÑ∂Ë™ûË®ÄÊñπÈù¢ÁöÑÂØ¶Ë≥™ËÉΩÂäõÔºåÈÄôÂ∞çÊñºÈÜ´ÁôÇÊñá‰ª∂„ÄÅË®∫Êñ∑ÂíåÊÇ£ËÄÖ‰∫íÂãïËá≥ÈóúÈáçË¶Å„ÄÇÊú¨ÁØáË©ïË´ñÊé¢Ë®é‰∫ÜË™ûË®ÄÊ®°ÂûãÂæûÊó©ÊúüÈöéÊÆµÂà∞Áï∂ÂâçÊúÄÂÖàÈÄ≤ÁöÑ LLM ÁöÑËªåË∑°ÔºåÈáçÈªû‰ªãÁ¥π‰∫ÜÂÆÉÂÄëÂú®ÈÜ´ÁôÇ‰øùÂÅ•ÊáâÁî®‰∏≠ÁöÑÂÑ™Âã¢Ôºå‰∏¶Ë®éË´ñ‰∫ÜÊï∏ÊìöÈö±ÁßÅ„ÄÅÂÅèË¶ãÂíåÈÅìÂæ∑ËÄÉÈáèÁ≠âÊåëÊà∞„ÄÇÊé¢Ë®é‰∫Ü LLM ÊèêÂçáÈÜ´ÁôÇ‰øùÂÅ•ÊúçÂãôÁöÑÊΩõÂäõÔºå‰ª•ÂèäÁ¢∫‰øùÂÆÉÂÄëÈÅìÂæ∑‰∏îÊúâÊïàÊï¥ÂêàÂà∞ÈÜ´ÁôÇÂØ¶Âãô‰∏≠ÁöÑÂøÖË¶ÅÊ≠•È©ü„ÄÇ

##### **A Multi-Dataset Classification-Based Deep Learning Framework for Electronic Health Records and Predictive Analysis in Healthcare**
2409.16721v1 by Syed Mohd Faisal Malik, Md Tabrez Nafis, Mohd Abdul Ahad, Safdar Tanweer

In contemporary healthcare, to protect patient data, electronic health
records have become invaluable repositories, creating vast opportunities to
leverage deep learning techniques for predictive analysis. Retinal fundus
images, cirrhosis stages, and heart disease diagnostic predictions have shown
promising results through the integration of deep learning techniques for
classifying diverse datasets. This study proposes a novel deep learning
predictive analysis framework for classifying multiple datasets by
pre-processing data from three distinct sources. A hybrid deep learning model
combining Residual Networks and Artificial Neural Networks is proposed to
detect acute and chronic diseases such as heart diseases, cirrhosis, and
retinal conditions, outperforming existing models. Dataset preparation involves
aspects such as categorical data transformation, dimensionality reduction, and
missing data synthesis. Feature extraction is effectively performed using
scaler transformation for categorical datasets and ResNet architecture for
image datasets. The resulting features are integrated into a unified
classification model. Rigorous experimentation and evaluation resulted in high
accuracies of 93%, 99%, and 95% for retinal fundus images, cirrhosis stages,
and heart disease diagnostic predictions, respectively. The efficacy of the
proposed method is demonstrated through a detailed analysis of F1-score,
precision, and recall metrics. This study offers a comprehensive exploration of
methodologies and experiments, providing in-depth knowledge of deep learning
predictive analysis in electronic health records.

ÊëòË¶ÅÔºö<paragraph>Âú®Áï∂‰ª£ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÔºåÁÇ∫‰∫Ü‰øùË≠∑ÊÇ£ËÄÖÊï∏ÊìöÔºåÈõªÂ≠êÂÅ•Â∫∑Ë®òÈåÑÂ∑≤ÊàêÁÇ∫ÁÑ°ÂÉπÁöÑÂÑ≤Â≠òÂ∫´ÔºåÂâµÈÄ†‰∫ÜÂà©Áî®Ê∑±Â∫¶Â≠∏ÁøíÊäÄË°ìÈÄ≤Ë°åÈ†êÊ∏¨ÂàÜÊûêÁöÑÂª£ÈóäÊ©üÊúÉ„ÄÇË¶ñÁ∂≤ËÜúÁúºÂ∫ïÂúñÂÉè„ÄÅËÇùÁ°¨ÂåñÂàÜÊúüÂíåÂøÉËáüÁóÖË®∫Êñ∑È†êÊ∏¨Â∑≤ÈÄèÈÅéÊï¥ÂêàÊ∑±Â∫¶Â≠∏ÁøíÊäÄË°ì‰æÜÂàÜÈ°û‰∏çÂêåÁöÑÊï∏ÊìöÈõÜÔºåÈ°ØÁ§∫Âá∫ÊúâÂ∏åÊúõÁöÑÁµêÊûú„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÈ†êÊ∏¨ÂàÜÊûêÊû∂ÊßãÔºåÈÄèÈÅéÈ†êËôïÁêÜ‰æÜËá™‰∏âÂÄã‰∏çÂêå‰æÜÊ∫êÁöÑÊï∏Êìö‰æÜÂàÜÈ°ûÂ§öÂÄãÊï∏ÊìöÈõÜ„ÄÇÊèêÂá∫‰∫Ü‰∏ÄÂÄãÁµêÂêàÊÆòÂ∑ÆÁ∂≤Ë∑ØÂíå‰∫∫Â∑•Á•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÊ∑∑ÂêàÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºåÁî®ÊñºÊ™¢Ê∏¨ÊÄ•ÊÄßÁóÖÂíåÊÖ¢ÊÄßÁóÖÔºå‰æãÂ¶ÇÂøÉËáüÁóÖ„ÄÅËÇùÁ°¨ÂåñÂíåË¶ñÁ∂≤ËÜúÁñæÁóÖÔºåÂÖ∂ÊïàËÉΩÂÑ™ÊñºÁèæÊúâÁöÑÊ®°Âûã„ÄÇÊï∏ÊìöÈõÜÊ∫ñÂÇôÊ∂âÂèäÁØÑÁñáË≥áÊñôËΩâÊèõ„ÄÅÈôçÁ∂≠ÂíåÈÅ∫Â§±Ë≥áÊñôÂêàÊàêÁ≠âÊñπÈù¢„ÄÇÁâπÂæµËêÉÂèñ‰ΩøÁî®ÁØÑÁñáË≥áÊñôÈõÜÁöÑÁ∏ÆÊîæÂô®ËΩâÊèõÂíåÂΩ±ÂÉèË≥áÊñôÈõÜÁöÑ ResNet Êû∂Êßã‰æÜÊúâÊïàÂü∑Ë°å„ÄÇÁî¢ÁîüÁöÑÁâπÂæµË¢´Êï¥ÂêàÂà∞‰∏ÄÂÄãÁµ±‰∏ÄÁöÑÂàÜÈ°ûÊ®°Âûã‰∏≠„ÄÇÂö¥Ë¨πÁöÑÂØ¶È©óÂíåË©ï‰º∞Â∞éËá¥Ë¶ñÁ∂≤ËÜúÁúºÂ∫ïÂúñÂÉè„ÄÅËÇùÁ°¨ÂåñÂàÜÊúüÂíåÂøÉËáüÁóÖË®∫Êñ∑È†êÊ∏¨ÁöÑÊ∫ñÁ¢∫Â∫¶ÂàÜÂà•È´òÈÅî 93%„ÄÅ99% Âíå 95%„ÄÇÊâÄÊèêÂá∫ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÈÄèÈÅéÂ∞ç F1 ÂàÜÊï∏„ÄÅÁ≤æÁ¢∫Â∫¶ÂíåÂè¨ÂõûÁéáÊåáÊ®ôÁöÑË©≥Á¥∞ÂàÜÊûê‰æÜË≠âÊòé„ÄÇÊú¨Á†îÁ©∂Êèê‰æõ‰∫ÜÊñπÊ≥ïË´ñÂíåÂØ¶È©óÁöÑÂÖ®Èù¢Êé¢Ë®éÔºåÊ∑±ÂÖ•‰∫ÜËß£ÈõªÂ≠êÂÅ•Â∫∑Ë®òÈåÑ‰∏≠ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÈ†êÊ∏¨ÂàÜÊûê„ÄÇ</paragraph>

##### **Enhancing Guardrails for Safe and Secure Healthcare AI**
2409.17190v1 by Ananya Gangavarapu

Generative AI holds immense promise in addressing global healthcare access
challenges, with numerous innovative applications now ready for use across
various healthcare domains. However, a significant barrier to the widespread
adoption of these domain-specific AI solutions is the lack of robust safety
mechanisms to effectively manage issues such as hallucination, misinformation,
and ensuring truthfulness. Left unchecked, these risks can compromise patient
safety and erode trust in healthcare AI systems. While general-purpose
frameworks like Llama Guard are useful for filtering toxicity and harmful
content, they do not fully address the stringent requirements for truthfulness
and safety in healthcare contexts. This paper examines the unique safety and
security challenges inherent to healthcare AI, particularly the risk of
hallucinations, the spread of misinformation, and the need for factual accuracy
in clinical settings. I propose enhancements to existing guardrails frameworks,
such as Nvidia NeMo Guardrails, to better suit healthcare-specific needs. By
strengthening these safeguards, I aim to ensure the secure, reliable, and
accurate use of AI in healthcare, mitigating misinformation risks and improving
patient safety.

ÊëòË¶ÅÔºöÁîüÊàêÂºè AI Âú®Ëß£Ê±∫ÂÖ®ÁêÉÈÜ´ÁôÇ‰øùÂÅ•Â≠òÂèñÊåëÊà∞ÊñπÈù¢Ê•µÂÖ∑ÂâçÊôØÔºåË®±Â§öÂâµÊñ∞ÊáâÁî®ÁèæÂ∑≤Ê∫ñÂÇôÂ•ΩÂú®ÂêÑÁ®ÆÈÜ´ÁôÇ‰øùÂÅ•È†òÂüü‰ΩøÁî®„ÄÇÁÑ∂ËÄåÔºåÂª£Ê≥õÊé°Áî®ÈÄô‰∫õÁâπÂÆöÈ†òÂüüÁöÑ AI Ëß£Ê±∫ÊñπÊ°àÈù¢Ëá®ÁöÑ‰∏ÄÂ§ßÈöúÁ§ôÔºåÊòØÁº∫‰πèÂÅ•ÂÖ®ÁöÑÂÆâÂÖ®Ê©üÂà∂‰æÜÊúâÊïàÁÆ°ÁêÜÂπªË¶∫„ÄÅÈåØË™§Ë≥áË®äÁ≠âÂïèÈ°åÔºå‰∏¶Á¢∫‰øùÁúüÂØ¶ÊÄß„ÄÇÂ¶ÇÊûú‰∏çÂä†‰ª•ÊéßÂà∂ÔºåÈÄô‰∫õÈ¢®Èö™ÂèØËÉΩÊúÉÊêçÂÆ≥ÊÇ£ËÄÖÂÆâÂÖ®Ôºå‰∏¶‰æµËùïÂ∞çÈÜ´ÁôÇ‰øùÂÅ• AI Á≥ªÁµ±ÁöÑ‰ø°‰ªª„ÄÇÈõñÁÑ∂ÂÉè Llama Guard ÈÄôÊ®£ÁöÑÈÄöÁî®Ê°ÜÊû∂ÊúâÂä©ÊñºÈÅéÊøæÊúâÂÆ≥ÂíåÊúâÂÆ≥ÂÖßÂÆπÔºå‰ΩÜÂÆÉÂÄë‰∏¶Êú™ÂÆåÂÖ®ÊªøË∂≥ÈÜ´ÁôÇ‰øùÂÅ•Áí∞Â¢É‰∏≠Â∞çÁúüÂØ¶ÊÄßÂíåÂÆâÂÖ®ÊÄßÁöÑÂö¥Ê†ºË¶ÅÊ±Ç„ÄÇÊú¨ÊñáÊé¢Ë®é‰∫ÜÈÜ´ÁôÇ‰øùÂÅ• AI Âõ∫ÊúâÁöÑÁç®ÁâπÂÆâÂÖ®ÊÄßÂíåÂÆâÂÖ®ÊÄßÊåëÊà∞ÔºåÁâπÂà•ÊòØÂπªË¶∫ÁöÑÈ¢®Èö™„ÄÅÈåØË™§Ë≥áË®äÁöÑÂÇ≥Êí≠Ôºå‰ª•ÂèäÂú®Ëá®Â∫äÁí∞Â¢É‰∏≠Â∞ç‰∫ãÂØ¶Ê∫ñÁ¢∫ÊÄßÁöÑÈúÄÊ±Ç„ÄÇÊàëÂª∫Ë≠∞Â∞çÁèæÊúâÁöÑË≠∑Ê¨ÑÊ°ÜÊû∂Ôºà‰æãÂ¶Ç Nvidia NeMo GuardrailsÔºâÈÄ≤Ë°åÊîπÈÄ≤Ôºå‰ª•Êõ¥Â•ΩÂú∞ÊªøË∂≥ÈÜ´ÁôÇ‰øùÂÅ•ÁöÑÁâπÂÆöÈúÄÊ±Ç„ÄÇÈÄöÈÅéÂä†Âº∑ÈÄô‰∫õ‰øùÈöúÊé™ÊñΩÔºåÊàëÊó®Âú®Á¢∫‰øù AI Âú®ÈÜ´ÁôÇ‰øùÂÅ•‰∏≠ÁöÑÂÆâÂÖ®„ÄÅÂèØÈù†ÂíåÊ∫ñÁ¢∫‰ΩøÁî®ÔºåÈôç‰ΩéÈåØË™§Ë≥áË®äÈ¢®Èö™‰∏¶ÊèêÈ´òÊÇ£ËÄÖÂÆâÂÖ®ÊÄß„ÄÇ

##### **Enhancing disease detection in radiology reports through fine-tuning lightweight LLM on weak labels**
2409.16563v1 by Yishu Wei, Xindi Wang, Hanley Ong, Yiliang Zhou, Adam Flanders, George Shih, Yifan Peng

Despite significant progress in applying large language models (LLMs) to the
medical domain, several limitations still prevent them from practical
applications. Among these are the constraints on model size and the lack of
cohort-specific labeled datasets. In this work, we investigated the potential
of improving a lightweight LLM, such as Llama 3.1-8B, through fine-tuning with
datasets using synthetic labels. Two tasks are jointly trained by combining
their respective instruction datasets. When the quality of the task-specific
synthetic labels is relatively high (e.g., generated by GPT4- o), Llama 3.1-8B
achieves satisfactory performance on the open-ended disease detection task,
with a micro F1 score of 0.91. Conversely, when the quality of the
task-relevant synthetic labels is relatively low (e.g., from the MIMIC-CXR
dataset), fine-tuned Llama 3.1-8B is able to surpass its noisy teacher labels
(micro F1 score of 0.67 v.s. 0.63) when calibrated against curated labels,
indicating the strong inherent underlying capability of the model. These
findings demonstrate the potential of fine-tuning LLMs with synthetic labels,
offering a promising direction for future research on LLM specialization in the
medical domain.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â∞áÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊáâÁî®ÊñºÈÜ´ÁôÇÈ†òÂüüÂ∑≤ÂèñÂæóÈ°ØËëóÈÄ≤Â±ïÔºå‰ΩÜ‰ªçÊúâËã•Âπ≤ÈôêÂà∂ÈòªÁ§ôÂÆÉÂÄëÂØ¶ÈöõÊáâÁî®„ÄÇÂÖ∂‰∏≠ÂåÖÊã¨Ê®°ÂûãÂ§ßÂ∞èÁöÑÈôêÂà∂ÂíåÁº∫‰πèÁâπÂÆöÊñºÁæ§È´îÁöÑÊ®ôÁ±§Ë≥áÊñôÈõÜ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÈÄèÈÅé‰ΩøÁî®ÂêàÊàêÊ®ôÁ±§ÂæÆË™øË≥áÊñôÈõÜ‰æÜÊîπÂñÑËºïÈáèÁ¥ö LLMÔºà‰æãÂ¶Ç Llama 3.1-8BÔºâÁöÑÊΩõÂäõ„ÄÇÈÄèÈÅéÁµêÂêàÂêÑËá™ÁöÑÊåá‰ª§Ë≥áÊñôÈõÜÔºåÂÖ±ÂêåË®ìÁ∑¥ÂÖ©ÂÄã‰ªªÂãô„ÄÇÁï∂ÁâπÂÆöÊñº‰ªªÂãôÁöÑÂêàÊàêÊ®ôÁ±§ÂìÅË≥™Áõ∏Â∞çËºÉÈ´òÊôÇÔºà‰æãÂ¶ÇÔºåÁî± GPT4-o Áî¢ÁîüÔºâÔºåLlama 3.1-8B Âú®ÈñãÊîæÂºèÁñæÁóÖÂÅµÊ∏¨‰ªªÂãô‰∏≠ÂèñÂæó‰ª§‰∫∫ÊªøÊÑèÁöÑË°®ÁèæÔºåÂæÆËßÄ F1 ÂàÜÊï∏ÁÇ∫ 0.91„ÄÇÁõ∏ÂèçÂú∞ÔºåÁï∂Ëàá‰ªªÂãôÁõ∏ÈóúÁöÑÂêàÊàêÊ®ôÁ±§ÂìÅË≥™Áõ∏Â∞çËºÉ‰ΩéÊôÇÔºà‰æãÂ¶ÇÔºå‰æÜËá™ MIMIC-CXR Ë≥áÊñôÈõÜÔºâÔºåÂæÆË™øÂæåÁöÑ Llama 3.1-8B ËÉΩÂ§†Ë∂ÖË∂äÂÖ∂ÊúâÈõúË®äÁöÑÊïôÂ∏´Ê®ôÁ±§ÔºàÂæÆËßÄ F1 ÂàÜÊï∏ÁÇ∫ 0.67ÔºåÁõ∏ËºÉÊñº 0.63ÔºâÔºå‰∏¶Ê†πÊìöÁ∂ìÈÅéÊï¥ÁêÜÁöÑÊ®ôÁ±§ÈÄ≤Ë°åÊ†°Ê∫ñÔºåÈÄôË°®Á§∫Ë©≤Ê®°ÂûãÂÖ∑ÊúâÂº∑Â§ßÁöÑÂÖßÂú®ÊΩõÂú®ËÉΩÂäõ„ÄÇÈÄô‰∫õÁôºÁèæË≠âÊòé‰∫Ü‰ΩøÁî®ÂêàÊàêÊ®ôÁ±§ÂæÆË™ø LLM ÁöÑÊΩõÂäõÔºåÁÇ∫Êú™‰æÜÈáùÂ∞ç LLM Âú®ÈÜ´ÁôÇÈ†òÂüüÁöÑÂ∞àÈñÄÂåñÁ†îÁ©∂Êèê‰æõ‰∫ÜÊúâÂâçÊôØÁöÑÊñπÂêë„ÄÇ

##### **To Explore the Potential Inhibitors against Multitarget Proteins of COVID 19 using In Silico Study**
2409.16486v1 by Imra Aqeel

The global pandemic due to emergence of COVID 19 has created the unrivaled
public health crisis. It has huge morbidity rate never comprehended in the
recent decades. Researchers have made many efforts to find the optimal solution
of this pandemic. Progressively, drug repurposing is an emergent and powerful
strategy with saving cost, time, and labor. Lacking of identified repurposed
drug candidates against COVID 19 demands more efforts to explore the potential
inhibitors for effective cure. In this study, we used the combination of
molecular docking and machine learning regression approaches to explore the
potential inhibitors for the treatment of COVID 19. We calculated the binding
affinities of these drugs to multitarget proteins using molecular docking
process. We perform the QSAR modeling by employing various machine learning
regression approaches to identify the potential inhibitors against COVID 19.
Our findings with best scores of R2 and RMSE demonstrated that our proposed
Decision Tree Regression (DTR) model is the most appropriate model to explore
the potential inhibitors. We proposed five novel promising inhibitors with
their respective Zinc IDs ZINC (3873365, 85432544, 8214470, 85536956, and
261494640) within the range of -19.7 kcal/mol to -12.6 kcal/mol. We further
analyzed the physiochemical and pharmacokinetic properties of these most potent
inhibitors to examine their behavior. The analysis of these properties is the
key factor to promote an effective cure for public health. Our work constructs
an efficient structure with which to probe the potential inhibitors against
COVID-19, creating the combination of molecular docking with machine learning
regression approaches.

ÊëòË¶ÅÔºöÁî±Êñº COVID-19 ÁöÑÂá∫ÁèæÔºåÂÖ®ÁêÉÂ§ßÊµÅË°åÈÄ†Êàê‰∫ÜÁÑ°ËàáÂÄ´ÊØîÁöÑÂÖ¨ÂÖ±Ë°õÁîüÂç±Ê©ü„ÄÇÂÆÉÂú®ÊúÄËøëÂπæÂçÅÂπ¥‰æÜÂæûÊú™Ë¶ãÈÅéÂ¶ÇÊ≠§È´òÁöÑÁôºÁóÖÁéá„ÄÇÁ†îÁ©∂‰∫∫Âì°Â∑≤ÂÅöÂá∫Ë®±Â§öÂä™Âäõ‰æÜÂ∞ãÊâæÊ≠§‰∏ÄÊµÅË°åÁóÖÁöÑÊúÄ‰Ω≥Ëß£Ê±∫ÊñπÊ°à„ÄÇÊº∏ÈÄ≤ÂºèËó•Áâ©ÂÜçÂà©Áî®ÊòØ‰∏ÄÁ®ÆÊñ∞Ëàà‰∏îÂº∑Â§ßÁöÑÁ≠ñÁï•ÔºåÂèØÁØÄÁúÅÊàêÊú¨„ÄÅÊôÇÈñìÂíåÂãûÂäõ„ÄÇÁº∫‰πèÈáùÂ∞ç COVID-19 ÁöÑÂ∑≤Ë≠òÂà•ÂÜçÂà©Áî®Ëó•Áâ©ÂÄôÈÅ∏Ëó•Áâ©ÔºåÈúÄË¶ÅÊõ¥Â§öÂä™Âäõ‰æÜÊé¢Á¥¢ÊΩõÂú®ÁöÑÊäëÂà∂Âäë‰ª•ÈÄ≤Ë°åÊúâÊïàÊ≤ªÁôÇ„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÁµêÂêà‰∫ÜÂàÜÂ≠êÂ∞çÊé•ÂíåÊ©üÂô®Â≠∏ÁøíÂõûÊ≠∏ÊñπÊ≥ï‰æÜÊé¢Á¥¢Ê≤ªÁôÇ COVID-19 ÁöÑÊΩõÂú®ÊäëÂà∂Âäë„ÄÇÊàëÂÄë‰ΩøÁî®ÂàÜÂ≠êÂ∞çÊé•Á®ãÂ∫èË®àÁÆóÈÄô‰∫õËó•Áâ©ËàáÂ§öÁõÆÊ®ôËõãÁôΩÁöÑÁµêÂêàË¶™ÂíåÂäõ„ÄÇÊàëÂÄëÈÄèÈÅéÊé°Áî®ÂêÑÁ®ÆÊ©üÂô®Â≠∏ÁøíÂõûÊ≠∏ÊñπÊ≥ï‰æÜÂü∑Ë°å QSAR Âª∫Ê®°Ôºå‰ª•Ë≠òÂà•ÈáùÂ∞ç COVID-19 ÁöÑÊΩõÂú®ÊäëÂà∂Âäë„ÄÇÊàëÂÄëÂú® R2 Âíå RMSE ‰∏≠Áç≤ÂæóÁöÑÊúÄ‰Ω≥ÂàÜÊï∏ÁôºÁèæÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊ±∫Á≠ñÊ®πÂõûÊ≠∏ (DTR) Ê®°ÂûãÊòØÊúÄÂêàÈÅ©ÁöÑÊ®°ÂûãÔºåÂèØÊé¢Á¥¢ÊΩõÂú®ÁöÑÊäëÂà∂Âäë„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∫îÁ®ÆÊñ∞Á©é‰∏îÊúâÂ∏åÊúõÁöÑÊäëÂà∂ÂäëÔºåÂÆÉÂÄëÂêÑËá™ÁöÑ Zinc ID ÁÇ∫ ZINC (3873365„ÄÅ85432544„ÄÅ8214470„ÄÅ85536956 Âíå 261494640)ÔºåÁØÑÂúçÂú® -19.7 kcal/mol Ëá≥ -12.6 kcal/mol ‰πãÈñì„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÂàÜÊûê‰∫ÜÈÄô‰∫õÊúÄÂº∑ÊïàÊäëÂà∂ÂäëÁöÑÁêÜÂåñÂíåËó•‰ª£ÂãïÂäõÂ≠∏ÁâπÊÄßÔºå‰ª•Ê™¢È©óÂÆÉÂÄëÁöÑË°åÁÇ∫„ÄÇÈÄô‰∫õÁâπÊÄßÁöÑÂàÜÊûêÊòØ‰øÉÈÄ≤ÂÖ¨ÂÖ±Ë°õÁîüÊúâÊïàÊ≤ªÁôÇÁöÑÈóúÈçµÂõ†Á¥†„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Âª∫Á´ã‰∫Ü‰∏ÄÂÄãÊúâÊïàÁöÑÁµêÊßãÔºåÂèØÁî®ÊñºÊé¢Ê∏¨ÈáùÂ∞ç COVID-19 ÁöÑÊΩõÂú®ÊäëÂà∂ÂäëÔºåÁµêÂêàÂàÜÂ≠êÂ∞çÊé•ËàáÊ©üÂô®Â≠∏ÁøíÂõûÊ≠∏ÊñπÊ≥ï„ÄÇ

##### **Design and Evaluation of a CDSS for Drug Allergy Management Using LLMs and Pharmaceutical Data Integration**
2409.16395v1 by Gabriele De Vito, Filomena Ferrucci, Athanasios Angelakis

Medication errors significantly threaten patient safety, leading to adverse
drug events and substantial economic burdens on healthcare systems. Clinical
Decision Support Systems (CDSSs) aimed at mitigating these errors often face
limitations, including reliance on static databases and rule-based algorithms,
which can result in high false alert rates and alert fatigue among clinicians.
This paper introduces HELIOT, an innovative CDSS for drug allergy management,
integrating Large Language Models (LLMs) with a comprehensive pharmaceutical
data repository. HELIOT leverages advanced natural language processing
capabilities to interpret complex medical texts and synthesize unstructured
data, overcoming the limitations of traditional CDSSs. An empirical evaluation
using a synthetic patient dataset and expert-verified ground truth demonstrates
HELIOT's high accuracy, precision, recall, and F1 score, uniformly reaching
100\% across multiple experimental runs. The results underscore HELIOT's
potential to enhance decision support in clinical settings, offering a
scalable, efficient, and reliable solution for managing drug allergies.

ÊëòË¶ÅÔºöËó•Áâ©ÈåØË™§Âö¥ÈáçÂ®ÅËÑÖÊÇ£ËÄÖÂÆâÂÖ®ÔºåÂ∞éËá¥‰∏çËâØËó•Áâ©‰∫ã‰ª∂ÂíåÈÜ´ÁôÇÁ≥ªÁµ±ÁöÑÈáçÂ§ßÁ∂ìÊøüË≤†Êìî„ÄÇÊó®Âú®Ê∏õËºïÈÄô‰∫õÈåØË™§ÁöÑËá®Â∫äÊ±∫Á≠ñÊîØÊè¥Á≥ªÁµ± (CDSS) Á∂ìÂ∏∏Èù¢Ëá®ÈôêÂà∂ÔºåÂåÖÊã¨‰æùË≥¥ÈùúÊÖãË≥áÊñôÂ∫´ÂíåÂü∫ÊñºË¶èÂâáÁöÑÊºîÁÆóÊ≥ïÔºåÈÄôÂèØËÉΩÊúÉÂ∞éËá¥Ëá®Â∫äÈÜ´Áîü‰πãÈñìÁöÑÈ´òË™§Â†±ÁéáÂíåË≠¶Â†±Áñ≤Âãû„ÄÇÊú¨Êñá‰ªãÁ¥π HELIOTÔºå‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑËó•Áâ©ÈÅéÊïèÁÆ°ÁêÜ CDSSÔºåÂ∞áÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ËàáÂÖ®Èù¢ÁöÑËó•Áâ©Ë≥áÊñôÂ∫´Êï¥ÂêàÂú®‰∏ÄËµ∑„ÄÇHELIOT Âà©Áî®ÂÖàÈÄ≤ÁöÑËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜËÉΩÂäõ‰æÜËß£ÈáãË§áÈõúÁöÑÈÜ´Â≠∏ÊñáÊú¨‰∏¶Á∂úÂêàÈùûÁµêÊßãÂåñË≥áÊñôÔºåÂÖãÊúçÂÇ≥Áµ± CDSS ÁöÑÈôêÂà∂„ÄÇ‰ΩøÁî®ÂêàÊàêÊÇ£ËÄÖË≥áÊñôÈõÜÂíåÂ∞àÂÆ∂È©óË≠âÁöÑÂú∞Èù¢ÂØ¶Ê≥ÅÈÄ≤Ë°åÁöÑÁ∂ìÈ©óË©ï‰º∞Ë≠âÊòé‰∫Ü HELIOT ÁöÑÈ´òÊ∫ñÁ¢∫Â∫¶„ÄÅÁ≤æÁ¢∫Â∫¶„ÄÅÂè¨ÂõûÁéáÂíå F1 ÂàÜÊï∏ÔºåÂú®Â§öÊ¨°ÂØ¶È©óÈÅãË°å‰∏≠ÂùáÈÅîÂà∞ 100%„ÄÇÁµêÊûúÂº∑Ë™ø‰∫Ü HELIOT Âú®Ëá®Â∫äÁí∞Â¢É‰∏≠Â¢ûÂº∑Ê±∫Á≠ñÊîØÊè¥ÁöÑÊΩõÂäõÔºåÁÇ∫ÁÆ°ÁêÜËó•Áâ©ÈÅéÊïèÊèê‰æõÂèØÊì¥ÂÖÖ„ÄÅÈ´òÊïà‰∏îÂèØÈù†ÁöÑËß£Ê±∫ÊñπÊ°à„ÄÇ

##### **Future-Proofing Medical Imaging with Privacy-Preserving Federated Learning and Uncertainty Quantification: A Review**
2409.16340v1 by Nikolas Koutsoubis, Asim Waqas, Yasin Yilmaz, Ravi P. Ramachandran, Matthew Schabath, Ghulam Rasool

Artificial Intelligence (AI) has demonstrated significant potential in
automating various medical imaging tasks, which could soon become routine in
clinical practice for disease diagnosis, prognosis, treatment planning, and
post-treatment surveillance. However, the privacy concerns surrounding patient
data present a major barrier to the widespread adoption of AI in medical
imaging, as large, diverse training datasets are essential for developing
accurate, generalizable, and robust Artificial intelligence models. Federated
Learning (FL) offers a solution that enables organizations to train AI models
collaboratively without sharing sensitive data. federated learning exchanges
model training information, such as gradients, between the participating sites.
Despite its promise, federated learning is still in its developmental stages
and faces several challenges. Notably, sensitive information can still be
inferred from the gradients shared during model training. Quantifying AI
models' uncertainty is vital due to potential data distribution shifts
post-deployment, which can affect model performance. Uncertainty quantification
(UQ) in FL is particularly challenging due to data heterogeneity across
participating sites. This review provides a comprehensive examination of FL,
privacy-preserving FL (PPFL), and UQ in FL. We identify key gaps in current FL
methodologies and propose future research directions to enhance data privacy
and trustworthiness in medical imaging applications.

ÊëòË¶ÅÔºö‰∫∫Â∑•Êô∫ÊÖß (AI) Â∑≤Âú®Ëá™ÂãïÂåñÂêÑÁ®ÆÈÜ´Â≠∏ÂΩ±ÂÉè‰ªªÂãô‰∏≠Â±ïÁèæÂá∫È°ØËëóÁöÑÊΩõÂäõÔºåÈÄôÂèØËÉΩÂæàÂø´Â∞±ÊúÉÂú®ÁñæÁóÖË®∫Êñ∑„ÄÅÈ†êÂæå„ÄÅÊ≤ªÁôÇË¶èÂäÉÂíåÊ≤ªÁôÇÂæåÁõ£Ê∏¨ÁöÑËá®Â∫äÂØ¶Âãô‰∏≠ÊàêÁÇ∫‰æãË°åÂÖ¨‰∫ã„ÄÇÁÑ∂ËÄåÔºåÂúçÁπûËëóÁóÖÊÇ£Ë≥áÊñôÁöÑÈö±ÁßÅÁñëÊÖÆÂ∞ç AI Âú®ÈÜ´Â≠∏ÂΩ±ÂÉè‰∏≠ÁöÑÂª£Ê≥õÊé°Áî®ÊßãÊàê‰∫Ü‰∏ÄÈ†ÖÈáçÂ§ßÁöÑÈöúÁ§ôÔºåÂõ†ÁÇ∫ÈæêÂ§ß‰∏îÂ§öÊ®£ÂåñÁöÑË®ìÁ∑¥Ë≥áÊñôÈõÜÂ∞çÊñºÈñãÁôºÊ∫ñÁ¢∫„ÄÅÂèØÊ¶ÇÊã¨‰∏îÂº∑ÂÅ•ÁöÑ‰∫∫Â∑•Êô∫ÊÖßÊ®°ÂûãËá≥ÈóúÈáçË¶Å„ÄÇËÅØÂêàÂ≠∏Áøí (FL) Êèê‰æõ‰∫Ü‰∏ÄÈ†ÖËß£Ê±∫ÊñπÊ°àÔºåËÆìÁµÑÁπîËÉΩÂ§†Âú®‰∏çÂÖ±‰∫´ÊïèÊÑüË≥áÊñôÁöÑÊÉÖÊ≥Å‰∏ãÂçîÂêåË®ìÁ∑¥ AI Ê®°Âûã„ÄÇËÅØÂêàÂ≠∏ÁøíÊúÉÂú®ÂèÉËàáÁöÑÂêÑÂÄãÁ´ôÈªû‰πãÈñì‰∫§ÊèõÊ®°ÂûãË®ìÁ∑¥Ë≥áË®äÔºå‰æãÂ¶ÇÊ¢ØÂ∫¶„ÄÇÂÑòÁÆ°ËÅØÂêàÂ≠∏ÁøíÂâçÊôØÁúãÂ•ΩÔºå‰ΩÜÂÆÉ‰ªçËôïÊñºÈñãÁôºÈöéÊÆµÔºå‰∏¶Èù¢Ëá®ËëóËã•Âπ≤ÊåëÊà∞„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂç≥‰ΩøÂú®Ê®°ÂûãË®ìÁ∑¥ÊúüÈñìÂÖ±‰∫´ÔºåÊïèÊÑüË≥áË®ä‰ªçÂèØËÉΩË¢´Êé®Êñ∑Âá∫‰æÜ„ÄÇÁî±ÊñºÊ®°ÂûãÈÉ®ÁΩ≤ÂæåÊΩõÂú®ÁöÑË≥áÊñôÂàÜ‰ΩàËΩâÁßªÂèØËÉΩÊúÉÂΩ±ÈüøÊ®°ÂûãÊïàËÉΩÔºåÂõ†Ê≠§ÈáèÂåñ AI Ê®°ÂûãÁöÑ‰∏çÁ¢∫ÂÆöÊÄßËá≥ÈóúÈáçË¶Å„ÄÇÁî±ÊñºÂèÉËàáÁ´ôÈªû‰πãÈñìË≥áÊñôÁöÑÁï∞Ë≥™ÊÄßÔºåËÅØÂêàÂ≠∏Áøí‰∏≠ÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÈáèÂåñ (UQ) ÁâπÂà•ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊ≠§ÁØáË©ïË´ñÂ∞çËÅØÂêàÂ≠∏Áøí„ÄÅÈö±ÁßÅ‰øùË≠∑ËÅØÂêàÂ≠∏Áøí (PPFL) ÂíåËÅØÂêàÂ≠∏Áøí‰∏≠ÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÈáèÂåñÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑÊé¢Ë®é„ÄÇÊàëÂÄëÊâæÂá∫ÁõÆÂâçËÅØÂêàÂ≠∏ÁøíÊñπÊ≥ï‰∏≠ÁöÑÈóúÈçµÂ∑ÆË∑ùÔºå‰∏¶ÊèêÂá∫Êú™‰æÜÁöÑÁ†îÁ©∂ÊñπÂêëÔºå‰ª•Â¢ûÂº∑ÈÜ´Â≠∏ÂΩ±ÂÉèÊáâÁî®‰∏≠ÁöÑË≥áÊñôÈö±ÁßÅÂíåÂèØ‰ø°Â∫¶„ÄÇ

